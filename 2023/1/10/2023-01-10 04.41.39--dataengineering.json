{"kind": "Listing", "data": {"after": "t3_107jf2o", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have tried to work with this platform. I have given it every opportunity I can, but never have I seen so much trouble from a tool or framework I had to work with. I started the new year with a new years resolution: to write down every problem as I encounter them. I don't know if I should continue with it, since I might fill up my e-reader before the year is over.\n\nIn no particular order:\n\n1. Synapse expressions have no support for the case() function. Have fun chaining if else's!\n2. Not all activities have retries. What do you mean you want to put a retry on a pipeline? That's crazy talk!\n3. SQL scripts are saved as JSON. Not even JSON5. Fucking JSON. I hope you like diff checking one fucking long ass line of SQL!\n4. Browser IDE... Whoever thought this up deserves fish hooks up their ass. You can't even save properly in the stupid thing, because every single thing is counted as a commit. And before some asshat suggests committing after the work is done: you deserve the fish hook too.\n5. Pipeline variables do not include int's (and some other types for that matter) for whatever reason. Converting everything to string and back is fun isn't it?\n6. Pipelines don't have output parameters, so even if I wanted to make reusable modules for missing Synapse functionality I literally can't unless I start using them as error parameters (and if you try to suggest that I WILL shank you).\n7. No global parameters EVEN THOUGH DATA FACTORY HAD IT AND IT'S BEEN REQUESTED FOR ALMOST 2 YEARS.\n8. 2022 and still no dark mode. This has been requested for data factory in 2016. Yes you're old and so am I.\n9. The SQL editor has all the great functionalities notepad has.\n10. I hope you didn't name one of your workspaces incorrectly. Oh you did? RIP, time to remake it.\n11. Local timezones? You mean UTC? What do you mean + or -? You craycray!\n12. Nesting loops or if tests can't be done. You need to make separate pipelines for it and before someone asks: no, just because it's a nesting it REALLY doesn't mean it belongs in a separate pipeline.\n13. Speaking about nesting: if you use an if test in a foreach, you can't access the current item of the loop. Haven't you learned by now? You're using Synapse. Now eat shit.\n14. Self-Hosted Integration Runtimes cannot be shared, while you can actually do that in data factory. This means you need to run three separate runtimes just to get to on-premise sources.\n15. On the topic of self-hosted integration runtimes: why do you even need them at all? Why is it not possible to peer a vnet that contains synapse and be done with it?\n16. What's even the use of the SQL scripts if you can't access them from pipelines. You get the script activity, but that's just another fucking place to dump your SQL in. And if you dare to suggest to use the API to trigger/request the SQL script. I will adopt a dog just to feed you to it.\n17. Testing? HAHAHAHAHAHAHAHAHAHA- fuck you.\n18. You want to rename a variable? Lol you little shit now you have to search for every instance to rename it. Refactoring? Just become a 100x dev yo.\n19. Parameters in pipeline templates? Why would you want parameters in your pipeline templates? You talk like you want to reuse the code you wrote or something. Oh you do? ........oof.\n20. Git....lab? Sounds like a dangerous cocaine facility. Hope you weren't planning to attach that to synapse! Or like literally any other option since you have to attach git to synapse in the first place.\n\nThese are the ones from THIS year, so after one week. I have had the displeasure of using it for a year now. So here's my advice after this long-winded rant: use it for a quick prototype of anything and don't use it for anything bigger than that. If you do, you have learned nothing of all the improvements that people have brought to the art that is development and you should probably touch grass instead of sucking cock on LinkedIn.", "author_fullname": "t2_2pbhwnrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Analytics is absolute trash for anything bigger than a few extractions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107rt91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673302334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tried to work with this platform. I have given it every opportunity I can, but never have I seen so much trouble from a tool or framework I had to work with. I started the new year with a new years resolution: to write down every problem as I encounter them. I don&amp;#39;t know if I should continue with it, since I might fill up my e-reader before the year is over.&lt;/p&gt;\n\n&lt;p&gt;In no particular order:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Synapse expressions have no support for the case() function. Have fun chaining if else&amp;#39;s!&lt;/li&gt;\n&lt;li&gt;Not all activities have retries. What do you mean you want to put a retry on a pipeline? That&amp;#39;s crazy talk!&lt;/li&gt;\n&lt;li&gt;SQL scripts are saved as JSON. Not even JSON5. Fucking JSON. I hope you like diff checking one fucking long ass line of SQL!&lt;/li&gt;\n&lt;li&gt;Browser IDE... Whoever thought this up deserves fish hooks up their ass. You can&amp;#39;t even save properly in the stupid thing, because every single thing is counted as a commit. And before some asshat suggests committing after the work is done: you deserve the fish hook too.&lt;/li&gt;\n&lt;li&gt;Pipeline variables do not include int&amp;#39;s (and some other types for that matter) for whatever reason. Converting everything to string and back is fun isn&amp;#39;t it?&lt;/li&gt;\n&lt;li&gt;Pipelines don&amp;#39;t have output parameters, so even if I wanted to make reusable modules for missing Synapse functionality I literally can&amp;#39;t unless I start using them as error parameters (and if you try to suggest that I WILL shank you).&lt;/li&gt;\n&lt;li&gt;No global parameters EVEN THOUGH DATA FACTORY HAD IT AND IT&amp;#39;S BEEN REQUESTED FOR ALMOST 2 YEARS.&lt;/li&gt;\n&lt;li&gt;2022 and still no dark mode. This has been requested for data factory in 2016. Yes you&amp;#39;re old and so am I.&lt;/li&gt;\n&lt;li&gt;The SQL editor has all the great functionalities notepad has.&lt;/li&gt;\n&lt;li&gt;I hope you didn&amp;#39;t name one of your workspaces incorrectly. Oh you did? RIP, time to remake it.&lt;/li&gt;\n&lt;li&gt;Local timezones? You mean UTC? What do you mean + or -? You craycray!&lt;/li&gt;\n&lt;li&gt;Nesting loops or if tests can&amp;#39;t be done. You need to make separate pipelines for it and before someone asks: no, just because it&amp;#39;s a nesting it REALLY doesn&amp;#39;t mean it belongs in a separate pipeline.&lt;/li&gt;\n&lt;li&gt;Speaking about nesting: if you use an if test in a foreach, you can&amp;#39;t access the current item of the loop. Haven&amp;#39;t you learned by now? You&amp;#39;re using Synapse. Now eat shit.&lt;/li&gt;\n&lt;li&gt;Self-Hosted Integration Runtimes cannot be shared, while you can actually do that in data factory. This means you need to run three separate runtimes just to get to on-premise sources.&lt;/li&gt;\n&lt;li&gt;On the topic of self-hosted integration runtimes: why do you even need them at all? Why is it not possible to peer a vnet that contains synapse and be done with it?&lt;/li&gt;\n&lt;li&gt;What&amp;#39;s even the use of the SQL scripts if you can&amp;#39;t access them from pipelines. You get the script activity, but that&amp;#39;s just another fucking place to dump your SQL in. And if you dare to suggest to use the API to trigger/request the SQL script. I will adopt a dog just to feed you to it.&lt;/li&gt;\n&lt;li&gt;Testing? HAHAHAHAHAHAHAHAHAHA- fuck you.&lt;/li&gt;\n&lt;li&gt;You want to rename a variable? Lol you little shit now you have to search for every instance to rename it. Refactoring? Just become a 100x dev yo.&lt;/li&gt;\n&lt;li&gt;Parameters in pipeline templates? Why would you want parameters in your pipeline templates? You talk like you want to reuse the code you wrote or something. Oh you do? ........oof.&lt;/li&gt;\n&lt;li&gt;Git....lab? Sounds like a dangerous cocaine facility. Hope you weren&amp;#39;t planning to attach that to synapse! Or like literally any other option since you have to attach git to synapse in the first place.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;These are the ones from THIS year, so after one week. I have had the displeasure of using it for a year now. So here&amp;#39;s my advice after this long-winded rant: use it for a quick prototype of anything and don&amp;#39;t use it for anything bigger than that. If you do, you have learned nothing of all the improvements that people have brought to the art that is development and you should probably touch grass instead of sucking cock on LinkedIn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107rt91", "is_robot_indexable": true, "report_reasons": null, "author": "AirisuB", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107rt91/azure_synapse_analytics_is_absolute_trash_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107rt91/azure_synapse_analytics_is_absolute_trash_for/", "subreddit_subscribers": 85795, "created_utc": 1673302334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a career jumper since I was 18. I\u2019ve attempted to get into about almost every career possible out there. Finally I narrowed things down to tech. Even in tech, I\u2019ve been jumping around. I\u2019m down to 2 final choices that I\u2019m considering \u2014 DE or Sales.\n\nI\u2019m currently trying to learn DE, and it\u2019s really  overwhelming. As I\u2019m approaching the readings, etc, I keep thinking maybe I should just stop this and go into sales.. \ud83d\ude2c\ud83d\ude2c\n\nHow does an absolute beginner with a data analyst background get over the mental mountain, persevere, and make it through the end of landing a DE job?", "author_fullname": "t2_ht40qce8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting over the mental mountain when starting out learning DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107ipn6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673281792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a career jumper since I was 18. I\u2019ve attempted to get into about almost every career possible out there. Finally I narrowed things down to tech. Even in tech, I\u2019ve been jumping around. I\u2019m down to 2 final choices that I\u2019m considering \u2014 DE or Sales.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently trying to learn DE, and it\u2019s really  overwhelming. As I\u2019m approaching the readings, etc, I keep thinking maybe I should just stop this and go into sales.. \ud83d\ude2c\ud83d\ude2c&lt;/p&gt;\n\n&lt;p&gt;How does an absolute beginner with a data analyst background get over the mental mountain, persevere, and make it through the end of landing a DE job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "107ipn6", "is_robot_indexable": true, "report_reasons": null, "author": "phoot_in_the_door", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107ipn6/getting_over_the_mental_mountain_when_starting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107ipn6/getting_over_the_mental_mountain_when_starting/", "subreddit_subscribers": 85795, "created_utc": 1673281792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!I've  been tasked to evaluate whether we need dbt in our org and I have a\u00a0  feeling that either we need another\u00a0 approach or I am missing something.  \n\n\n**tldr:  Is there an out of the box solution for running heaviliy parametrized  queries with caching on different levels between them?**  \n\n\nHigh level view:  \nWe  do spatial data analysis, we have an algorithm to calculate a bunch of  metrics which accept a lot of parameters (area of calculation, different  weights for aggregation, etc.) which we currently calculate ina a LOT  of jupyter notebooks (so a lot of copypaste for each new  experiment/client).  \nWe want to move the calculation of these metrics into some DWH to:  \n\\- Keep track of all of the calculations  \n\\- Easily use the same code on the data from different providers (so it's transformed to the right format somehow)  \n\\- The calculations are multilayered - so some intermediate data can and should be reused between requests  \n\\- You have to be able to access intermediate data for calculations  \n\\-If  an analyst modifies some parameters it should be easy for them to pass  the new code for further generations such that they can compare this  version to the new ones.  \n\n\nSolution:  \nWe  can't just calculate this algorithm on all of the data with all of the  parameters - there are terrabytes of source data and it seems very  inefficient.  \nSo the algorithm is written as a series of dbt models  with a LOT of parameters passed during \\`dbt run\\` as a json object  through command line arguments. We also have a \\`request\\` table storing  the json of the requests and gives them certain ids.  \nThen for each  ongoing model we generate an sql request with dbt and add a cache\\_id  fully determined by the parameters. When we run other requests the  cache\\_id is calculated to be the same if the parameters that this model  depends on are the same and data is reused.  \n\n\nIt would be great to hear your thoughts. Cheers!", "author_fullname": "t2_8n7ze0vt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt the right tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107fi0c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673273887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!I&amp;#39;ve  been tasked to evaluate whether we need dbt in our org and I have a\u00a0  feeling that either we need another\u00a0 approach or I am missing something.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tldr:  Is there an out of the box solution for running heaviliy parametrized  queries with caching on different levels between them?&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;High level view:&lt;br/&gt;\nWe  do spatial data analysis, we have an algorithm to calculate a bunch of  metrics which accept a lot of parameters (area of calculation, different  weights for aggregation, etc.) which we currently calculate ina a LOT  of jupyter notebooks (so a lot of copypaste for each new  experiment/client).&lt;br/&gt;\nWe want to move the calculation of these metrics into some DWH to:&lt;br/&gt;\n- Keep track of all of the calculations&lt;br/&gt;\n- Easily use the same code on the data from different providers (so it&amp;#39;s transformed to the right format somehow)&lt;br/&gt;\n- The calculations are multilayered - so some intermediate data can and should be reused between requests&lt;br/&gt;\n- You have to be able to access intermediate data for calculations&lt;br/&gt;\n-If  an analyst modifies some parameters it should be easy for them to pass  the new code for further generations such that they can compare this  version to the new ones.  &lt;/p&gt;\n\n&lt;p&gt;Solution:&lt;br/&gt;\nWe  can&amp;#39;t just calculate this algorithm on all of the data with all of the  parameters - there are terrabytes of source data and it seems very  inefficient.&lt;br/&gt;\nSo the algorithm is written as a series of dbt models  with a LOT of parameters passed during `dbt run` as a json object  through command line arguments. We also have a `request` table storing  the json of the requests and gives them certain ids.&lt;br/&gt;\nThen for each  ongoing model we generate an sql request with dbt and add a cache_id  fully determined by the parameters. When we run other requests the  cache_id is calculated to be the same if the parameters that this model  depends on are the same and data is reused.  &lt;/p&gt;\n\n&lt;p&gt;It would be great to hear your thoughts. Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107fi0c", "is_robot_indexable": true, "report_reasons": null, "author": "Outside_Banana_2138", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107fi0c/is_dbt_the_right_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107fi0c/is_dbt_the_right_tool/", "subreddit_subscribers": 85795, "created_utc": 1673273887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's even a good answer for this?\n\nEdit: all great answers. Had this in a interview a few months ago while I am only beginning DE, so was wondering what was actually good lol", "author_fullname": "t2_8i81zdtc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Question: How fast are your ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107g616", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673314174.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673275643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s even a good answer for this?&lt;/p&gt;\n\n&lt;p&gt;Edit: all great answers. Had this in a interview a few months ago while I am only beginning DE, so was wondering what was actually good lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "107g616", "is_robot_indexable": true, "report_reasons": null, "author": "Particular-Sock5250", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107g616/interview_question_how_fast_are_your_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107g616/interview_question_how_fast_are_your_etl/", "subreddit_subscribers": 85795, "created_utc": 1673275643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently standing up a new data analytics shop and we are in the process of designing our data lake.  I have read through the past posts on data lake design and read as much as I could find online and I thought I had a good handle on my approach.\n\nMy current thinking is to have three zones.\n\n1. Landing (immutable)\n2. Raw (This can convert file formats, maybe deduplicate, put in correct data types)\n3. Curated (Data modeled/aggregated to produce some type of product)\n\nThis seems to be where a lot of the literature ends, the actual design within these zones/containers is quite sparse.  So my design within these zones is something I am calling \"as flat as reasonable\".  This means instead on something like  domain/application/item/yyyy/mm/dd/data I am doing  domain\\_application\\_item/yyyy/mm/dd/data.  This does not work for all cases, but I like a flat structure if it makes sense.  So my first questions are, does this make sense?  Are there any pitfalls to this approach?\n\n&amp;#x200B;\n\nNext, I am wondering what people do in the curated zone.  I was asked to put data for a dashboard on the data lake.  This is data that will eventually be put into a pipeline, but is on someone's computer pulled from an api.  I received the data and it is broken into 9 different datasets broken up from 3 or 4 different original datasets.  So my questions are:\n\n1. Do people let analysts create a curated section for their data products?  My fear is this will become messy.\n2. Do you think it is ok for a curated section to have multiple datasets within it if it is for a specific data product?\n3. Should I take a more hands on approach and see if I can create a better product with the analyst?  My fear here is that I will not have enough time to do this with every product and I could step on some toes, or just slow the process down.\n\nI know this is a lot, but I would appreciate any feedback on the above issues.\n\nThanks", "author_fullname": "t2_bkzx0bcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lake Design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107gt0x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673277208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently standing up a new data analytics shop and we are in the process of designing our data lake.  I have read through the past posts on data lake design and read as much as I could find online and I thought I had a good handle on my approach.&lt;/p&gt;\n\n&lt;p&gt;My current thinking is to have three zones.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Landing (immutable)&lt;/li&gt;\n&lt;li&gt;Raw (This can convert file formats, maybe deduplicate, put in correct data types)&lt;/li&gt;\n&lt;li&gt;Curated (Data modeled/aggregated to produce some type of product)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This seems to be where a lot of the literature ends, the actual design within these zones/containers is quite sparse.  So my design within these zones is something I am calling &amp;quot;as flat as reasonable&amp;quot;.  This means instead on something like  domain/application/item/yyyy/mm/dd/data I am doing  domain_application_item/yyyy/mm/dd/data.  This does not work for all cases, but I like a flat structure if it makes sense.  So my first questions are, does this make sense?  Are there any pitfalls to this approach?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Next, I am wondering what people do in the curated zone.  I was asked to put data for a dashboard on the data lake.  This is data that will eventually be put into a pipeline, but is on someone&amp;#39;s computer pulled from an api.  I received the data and it is broken into 9 different datasets broken up from 3 or 4 different original datasets.  So my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do people let analysts create a curated section for their data products?  My fear is this will become messy.&lt;/li&gt;\n&lt;li&gt;Do you think it is ok for a curated section to have multiple datasets within it if it is for a specific data product?&lt;/li&gt;\n&lt;li&gt;Should I take a more hands on approach and see if I can create a better product with the analyst?  My fear here is that I will not have enough time to do this with every product and I could step on some toes, or just slow the process down.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I know this is a lot, but I would appreciate any feedback on the above issues.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107gt0x", "is_robot_indexable": true, "report_reasons": null, "author": "SmothCerbrosoSimiae", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107gt0x/data_lake_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107gt0x/data_lake_design/", "subreddit_subscribers": 85795, "created_utc": 1673277208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data warehouse on Google Cloud that I ingest several data sources into. I am also hosting Apache Superset on Google Cloud to visualize data from this data warehouse. \n\nShould I have my data warehouse and Apache Superset deployment in a single project or is it best to split them into two different projects? One project makes sense in that everything is essentially in a single directory, but not sure this is the best practice as some of the data in the data warehouse may not be used in Superset.", "author_fullname": "t2_72tiq3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud Data Warehousing - Best Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107nzje", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673293820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data warehouse on Google Cloud that I ingest several data sources into. I am also hosting Apache Superset on Google Cloud to visualize data from this data warehouse. &lt;/p&gt;\n\n&lt;p&gt;Should I have my data warehouse and Apache Superset deployment in a single project or is it best to split them into two different projects? One project makes sense in that everything is essentially in a single directory, but not sure this is the best practice as some of the data in the data warehouse may not be used in Superset.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107nzje", "is_robot_indexable": true, "report_reasons": null, "author": "ROCKITZ15", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107nzje/google_cloud_data_warehousing_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107nzje/google_cloud_data_warehousing_best_practice/", "subreddit_subscribers": 85795, "created_utc": 1673293820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I dont have real DE experience but I learnt pyspark and pyarrow during my free time. So I wonder if that will help me to get my first DE job?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have good knowledge of pyspark and pyarrow. Are those skills demanded and will they help me to break through DE job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107b81e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673260508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I dont have real DE experience but I learnt pyspark and pyarrow during my free time. So I wonder if that will help me to get my first DE job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "107b81e", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107b81e/i_have_good_knowledge_of_pyspark_and_pyarrow_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107b81e/i_have_good_knowledge_of_pyspark_and_pyarrow_are/", "subreddit_subscribers": 85795, "created_utc": 1673260508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. After seeing /u/infiniteAggression- [pipeline for scraping Crinacle's headphone review site](https://www.reddit.com/r/dataengineering/comments/xyxpku/built_and_automated_a_complete_endtoend_elt/), I was inspired to do something similar to bolster my resume and hopefully upskill myself enough to land a better data-adjacent job! This is going to be the first \"real\" DE project that I will be working on, as well as learning about a cloud provider (GCP) from scratch. If anyone has pointers or advice they can share with me, I would greatly appreciate it. I've been reading around this subreddit for a while now, and I'm very excited to build something I can share with the fine folks here!  \n\nFor my project, I'm planning on creating a metabase dashboard (ironically, I work for one of their competitors \ud83d\ude06) that displays metrics from trending shows for each week and what streaming platforms they're **currently** available on. I don't exactly trust the trending sections from any of the streaming providers, so that's why I want to make my own. Also, it would be super helpful to know what's the hottest shows on each platform and whether or it's enough to justify resubbing to them. That way I don't need to sift through SEO garbage articles on /r/television.  \n\nI plan to host the dashboard on a micro-e2 VM; that way anyone looking at my resume can just click a link and interact with the dashboard without needing to `git clone` my repo and do any local setup.  \n\n### Pipeline\n1. make a weekly API request to fetch the top N trending TV shows from [TMDb](https://developers.themoviedb.org/3/trending/get-trending)\n2. dump the weekly trending shows into a Google cloud storage bucket\n3. append trending data files into a bigquery table. This will be a weekly grained fact table.\n4. run a `SELECT DISTINCT show_id` on the trending show table to get a list of unique show IDs that I can pass to this [endpoint](https://developers.themoviedb.org/3/tv/get-tv-details) to get all data needed to populate dimension tables (show details, genre, available watch providers, etc...)\n5. dump dimension table data into the same bucket from above and create the dimension tables in BQ\n6. use dbt to create models for Metabase to query on\n\n### Scalability Issues\nInitially, I was thinking of following /u/infiniteAggression- 's  idea of deploying an Airflow server on the micro-e2 VM that Metabase will be hosted on.  \n\nHowever, the list of unique show IDs from the fact table will grow O(n)--which means the number of API calls needed to fetch dimension table data will increase linearly. O(n) is the worst case, as the same show can show up this week and in any of the following weeks. Scalability probably won't be *too* terrible, but it's still something for me to keep in mind. This will probably? (still pretty new to this, excuse my lack of experience) overwhelm the VM from hosting Metabase and firing jobs in Airflow.\n### Workaround\nAfter more research, I think using Google's CRON scheduler+cloud functions to handle data ingestion would be a better idea. That way, resources are freed up for the VM to host Metabase and web traffic.  \n\nTo keep the number of API calls from blowing up, my idea is to delete records from my fact table after some condition is met. My two ideas are:\n\n1. delete records after N months from date of ingestion\n2. if the number of unique show IDs are &gt; some threshold, then delete records after N months from date of ingestion", "author_fullname": "t2_jk5r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline architecture advice for my first side project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107rpu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673302123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. After seeing &lt;a href=\"/u/infiniteAggression-\"&gt;/u/infiniteAggression-&lt;/a&gt; &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/xyxpku/built_and_automated_a_complete_endtoend_elt/\"&gt;pipeline for scraping Crinacle&amp;#39;s headphone review site&lt;/a&gt;, I was inspired to do something similar to bolster my resume and hopefully upskill myself enough to land a better data-adjacent job! This is going to be the first &amp;quot;real&amp;quot; DE project that I will be working on, as well as learning about a cloud provider (GCP) from scratch. If anyone has pointers or advice they can share with me, I would greatly appreciate it. I&amp;#39;ve been reading around this subreddit for a while now, and I&amp;#39;m very excited to build something I can share with the fine folks here!  &lt;/p&gt;\n\n&lt;p&gt;For my project, I&amp;#39;m planning on creating a metabase dashboard (ironically, I work for one of their competitors \ud83d\ude06) that displays metrics from trending shows for each week and what streaming platforms they&amp;#39;re &lt;strong&gt;currently&lt;/strong&gt; available on. I don&amp;#39;t exactly trust the trending sections from any of the streaming providers, so that&amp;#39;s why I want to make my own. Also, it would be super helpful to know what&amp;#39;s the hottest shows on each platform and whether or it&amp;#39;s enough to justify resubbing to them. That way I don&amp;#39;t need to sift through SEO garbage articles on &lt;a href=\"/r/television\"&gt;/r/television&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;I plan to host the dashboard on a micro-e2 VM; that way anyone looking at my resume can just click a link and interact with the dashboard without needing to &lt;code&gt;git clone&lt;/code&gt; my repo and do any local setup.  &lt;/p&gt;\n\n&lt;h3&gt;Pipeline&lt;/h3&gt;\n\n&lt;ol&gt;\n&lt;li&gt;make a weekly API request to fetch the top N trending TV shows from &lt;a href=\"https://developers.themoviedb.org/3/trending/get-trending\"&gt;TMDb&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;dump the weekly trending shows into a Google cloud storage bucket&lt;/li&gt;\n&lt;li&gt;append trending data files into a bigquery table. This will be a weekly grained fact table.&lt;/li&gt;\n&lt;li&gt;run a &lt;code&gt;SELECT DISTINCT show_id&lt;/code&gt; on the trending show table to get a list of unique show IDs that I can pass to this &lt;a href=\"https://developers.themoviedb.org/3/tv/get-tv-details\"&gt;endpoint&lt;/a&gt; to get all data needed to populate dimension tables (show details, genre, available watch providers, etc...)&lt;/li&gt;\n&lt;li&gt;dump dimension table data into the same bucket from above and create the dimension tables in BQ&lt;/li&gt;\n&lt;li&gt;use dbt to create models for Metabase to query on&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h3&gt;Scalability Issues&lt;/h3&gt;\n\n&lt;p&gt;Initially, I was thinking of following &lt;a href=\"/u/infiniteAggression-\"&gt;/u/infiniteAggression-&lt;/a&gt; &amp;#39;s  idea of deploying an Airflow server on the micro-e2 VM that Metabase will be hosted on.  &lt;/p&gt;\n\n&lt;p&gt;However, the list of unique show IDs from the fact table will grow O(n)--which means the number of API calls needed to fetch dimension table data will increase linearly. O(n) is the worst case, as the same show can show up this week and in any of the following weeks. Scalability probably won&amp;#39;t be &lt;em&gt;too&lt;/em&gt; terrible, but it&amp;#39;s still something for me to keep in mind. This will probably? (still pretty new to this, excuse my lack of experience) overwhelm the VM from hosting Metabase and firing jobs in Airflow.&lt;/p&gt;\n\n&lt;h3&gt;Workaround&lt;/h3&gt;\n\n&lt;p&gt;After more research, I think using Google&amp;#39;s CRON scheduler+cloud functions to handle data ingestion would be a better idea. That way, resources are freed up for the VM to host Metabase and web traffic.  &lt;/p&gt;\n\n&lt;p&gt;To keep the number of API calls from blowing up, my idea is to delete records from my fact table after some condition is met. My two ideas are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;delete records after N months from date of ingestion&lt;/li&gt;\n&lt;li&gt;if the number of unique show IDs are &amp;gt; some threshold, then delete records after N months from date of ingestion&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107rpu4", "is_robot_indexable": true, "report_reasons": null, "author": "bl4ckCloudz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107rpu4/pipeline_architecture_advice_for_my_first_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107rpu4/pipeline_architecture_advice_for_my_first_side/", "subreddit_subscribers": 85795, "created_utc": 1673302123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The coverage cutoff is set at 70% because that number is frequently used as a target point for \"good enough\" test coverage. \n\n[View Poll](https://www.reddit.com/poll/107g456)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What level of testing does your data engineering codebase have?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107g456", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673275508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The coverage cutoff is set at 70% because that number is frequently used as a target point for &amp;quot;good enough&amp;quot; test coverage. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/107g456\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107g456", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1673534708392, "options": [{"text": "Unit &amp; integration tests covering 70%+ of the codebase", "id": "20909852"}, {"text": "Any combination of unit &amp; integration Tests", "id": "20909853"}, {"text": "Some unit Tests", "id": "20909854"}, {"text": "Some integration Tests", "id": "20909855"}, {"text": "Tests... \ud83d\ude05", "id": "20909856"}, {"text": "See Results", "id": "20909857"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 221, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/107g456/what_level_of_testing_does_your_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/107g456/what_level_of_testing_does_your_data_engineering/", "subreddit_subscribers": 85795, "created_utc": 1673275508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The company I'm working at  has just received a project from an insurance firm to identify existing customers to approach for upselling/cross-selling. There willing to provide any data required, but they exist in silos without a data dictionary. \n\nBeen several months since I began my Data Engineering junior positon and wanted to ask where should I begin and what steps thats  needed to execute this . Client seems to want some \" Predict\" and \" Influence\" components within the project . \n\nWould help a lot in looking over on this.", "author_fullname": "t2_cl5vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding on Steps needed to help client for upselliing / cross-selling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107axl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673259490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The company I&amp;#39;m working at  has just received a project from an insurance firm to identify existing customers to approach for upselling/cross-selling. There willing to provide any data required, but they exist in silos without a data dictionary. &lt;/p&gt;\n\n&lt;p&gt;Been several months since I began my Data Engineering junior positon and wanted to ask where should I begin and what steps thats  needed to execute this . Client seems to want some &amp;quot; Predict&amp;quot; and &amp;quot; Influence&amp;quot; components within the project . &lt;/p&gt;\n\n&lt;p&gt;Would help a lot in looking over on this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107axl7", "is_robot_indexable": true, "report_reasons": null, "author": "Redxer", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107axl7/deciding_on_steps_needed_to_help_client_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107axl7/deciding_on_steps_needed_to_help_client_for/", "subreddit_subscribers": 85795, "created_utc": 1673259490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have always been a supporter of learning while doing and at 27 still support the idea that more or less you can do this job without a CS degree. That of course if you are motivated enough, like the job and don\u2019t mind losing your sleep over it from time to time because of learning and imposter syndrome.\n\nBut I (BD in finance and MD in Data science that were almost useless, with hindsight) also always felt like I\u2019m losing something without a CS degree. I\u2019m mulling over the idea of starting one, but i\u2019m pretty unsure about the benefits it gives compared to those I could get by using that time and money (about 6k \u20ac and maybe 5 years of studying while employed full time) for other activities (which ones?).\n\nAny thoughts or suggestions based on your experience?\n\nEDIT: forgot to mention that I work as a DE", "author_fullname": "t2_d0ifg2cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts about CS and similar degrees in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107m88k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673298604.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673289830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have always been a supporter of learning while doing and at 27 still support the idea that more or less you can do this job without a CS degree. That of course if you are motivated enough, like the job and don\u2019t mind losing your sleep over it from time to time because of learning and imposter syndrome.&lt;/p&gt;\n\n&lt;p&gt;But I (BD in finance and MD in Data science that were almost useless, with hindsight) also always felt like I\u2019m losing something without a CS degree. I\u2019m mulling over the idea of starting one, but i\u2019m pretty unsure about the benefits it gives compared to those I could get by using that time and money (about 6k \u20ac and maybe 5 years of studying while employed full time) for other activities (which ones?).&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or suggestions based on your experience?&lt;/p&gt;\n\n&lt;p&gt;EDIT: forgot to mention that I work as a DE&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107m88k", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Cupcake6219", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107m88k/thoughts_about_cs_and_similar_degrees_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107m88k/thoughts_about_cs_and_similar_degrees_in_de/", "subreddit_subscribers": 85795, "created_utc": 1673289830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Knowing that data is a vast field to discover, want to get insights upon how both of them differ precisely. examples will be much appreciated. Thanks", "author_fullname": "t2_5vfhflq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is Data Analytics different from Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1077mbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673247846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Knowing that data is a vast field to discover, want to get insights upon how both of them differ precisely. examples will be much appreciated. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1077mbf", "is_robot_indexable": true, "report_reasons": null, "author": "kajri", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1077mbf/how_is_data_analytics_different_from_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1077mbf/how_is_data_analytics_different_from_data_science/", "subreddit_subscribers": 85795, "created_utc": 1673247846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to jump from IT consulting to tech as data engineer. \n\nA little background of myself, working as data engineer for 3 years. mostly work is like using aws n azure to create pipeline etc. had change to actually design some data architecture/ pipelines.\n\nHad some interviews before new year. Felt like the gap is that \n\n1. not have much expose on the API part\n2. never did hadoop/mapreduce\n3. lots of enterprise de work is very niche where I actually have no idea how tech does its de work\n\nWould like some recommendations n insights on how to close my gap to leap into tech's de work.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_umw2vlyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a data engineer consultant to a senior data engineer in tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1074bw9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673237755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to jump from IT consulting to tech as data engineer. &lt;/p&gt;\n\n&lt;p&gt;A little background of myself, working as data engineer for 3 years. mostly work is like using aws n azure to create pipeline etc. had change to actually design some data architecture/ pipelines.&lt;/p&gt;\n\n&lt;p&gt;Had some interviews before new year. Felt like the gap is that &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;not have much expose on the API part&lt;/li&gt;\n&lt;li&gt;never did hadoop/mapreduce&lt;/li&gt;\n&lt;li&gt;lots of enterprise de work is very niche where I actually have no idea how tech does its de work&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Would like some recommendations n insights on how to close my gap to leap into tech&amp;#39;s de work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1074bw9", "is_robot_indexable": true, "report_reasons": null, "author": "alamamahuhuzado", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1074bw9/recommendations_for_a_data_engineer_consultant_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1074bw9/recommendations_for_a_data_engineer_consultant_to/", "subreddit_subscribers": 85795, "created_utc": 1673237755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019m new to the DE world and I\u2019ve been tasked with essentially creating a small scale MES for our plant (structured production data and a few dashboards). \n\nInitially I thought it made sense to collect data by machine because each machine has slightly different data that needs to be recorded. Then I realized there was also a metric I needed by line that could only be calculated using data from all machines. Which makes me believe the data should be organized by line.\n\n But then I realize sometimes machines switch lines which would mess up the whole table for that line. There\u2019s also some data like hit count which could easily be captured only once every hour whereas something like vibration needs to be captured every second. Any advice or sources discussing this topic?", "author_fullname": "t2_fgc39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is manufacturing IoT data typically organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107srly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673304479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m new to the DE world and I\u2019ve been tasked with essentially creating a small scale MES for our plant (structured production data and a few dashboards). &lt;/p&gt;\n\n&lt;p&gt;Initially I thought it made sense to collect data by machine because each machine has slightly different data that needs to be recorded. Then I realized there was also a metric I needed by line that could only be calculated using data from all machines. Which makes me believe the data should be organized by line.&lt;/p&gt;\n\n&lt;p&gt;But then I realize sometimes machines switch lines which would mess up the whole table for that line. There\u2019s also some data like hit count which could easily be captured only once every hour whereas something like vibration needs to be captured every second. Any advice or sources discussing this topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107srly", "is_robot_indexable": true, "report_reasons": null, "author": "TheOnlinePolak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107srly/how_is_manufacturing_iot_data_typically_organized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107srly/how_is_manufacturing_iot_data_typically_organized/", "subreddit_subscribers": 85795, "created_utc": 1673304479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey peeps, trying to find a good solution for a hash table in AWS Glue.\n\nDue to GDPR reasons, several tables will have to go through a hash to anonymize data from id to external_id.\n\n\nFor example: I have a table with several columns and an id column.\nThe external_id will be the new id in this table, but I need to map it first and drop the original column.\n\nI have some limitations that all of this transformation need to occur inside AWS, nothing touching anything beyond this. (Again, GDPR)\n\nI wonder if there is a better way to do this within Glue or other service. At the beginning I thought that Databrew recipes would take care of this, but apparently it\u2019s not dynamic enough to extend the services to multiple tables.\n\nMy approach now would be to construct a dictionary with the tables and columns and do a join between datasets, but I\u2019m a little bit skeptical and trying to find a more refined solution for this. \n\nAny ideas?", "author_fullname": "t2_4j9daz4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hash table with AWS Glue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107itn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673282036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey peeps, trying to find a good solution for a hash table in AWS Glue.&lt;/p&gt;\n\n&lt;p&gt;Due to GDPR reasons, several tables will have to go through a hash to anonymize data from id to external_id.&lt;/p&gt;\n\n&lt;p&gt;For example: I have a table with several columns and an id column.\nThe external_id will be the new id in this table, but I need to map it first and drop the original column.&lt;/p&gt;\n\n&lt;p&gt;I have some limitations that all of this transformation need to occur inside AWS, nothing touching anything beyond this. (Again, GDPR)&lt;/p&gt;\n\n&lt;p&gt;I wonder if there is a better way to do this within Glue or other service. At the beginning I thought that Databrew recipes would take care of this, but apparently it\u2019s not dynamic enough to extend the services to multiple tables.&lt;/p&gt;\n\n&lt;p&gt;My approach now would be to construct a dictionary with the tables and columns and do a join between datasets, but I\u2019m a little bit skeptical and trying to find a more refined solution for this. &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107itn0", "is_robot_indexable": true, "report_reasons": null, "author": "Dachsgp", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107itn0/hash_table_with_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107itn0/hash_table_with_aws_glue/", "subreddit_subscribers": 85795, "created_utc": 1673282036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nDoes anyone have a good study guide that they would be willing to provide me for the certification exam? Any help is appreciated.", "author_fullname": "t2_adn81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data Engineer Cert Study Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107g4pe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673275542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a good study guide that they would be willing to provide me for the certification exam? Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "107g4pe", "is_robot_indexable": true, "report_reasons": null, "author": "milehighmecked", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107g4pe/databricks_data_engineer_cert_study_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107g4pe/databricks_data_engineer_cert_study_guide/", "subreddit_subscribers": 85795, "created_utc": 1673275542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I would like to ask if anyone knows of or has any accounts on meta, google analytics, Pinterest, shopify, or any other platform measuring customer behaviour already loaded with any data at all. I am learning for a project that will have me work with data like this and I would like to try some concrete examples. Does any of this platforms provide dummy accounts with mock data? Thanks!", "author_fullname": "t2_vh5f084w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer behaviour accounts with data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107ctgw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673266030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I would like to ask if anyone knows of or has any accounts on meta, google analytics, Pinterest, shopify, or any other platform measuring customer behaviour already loaded with any data at all. I am learning for a project that will have me work with data like this and I would like to try some concrete examples. Does any of this platforms provide dummy accounts with mock data? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107ctgw", "is_robot_indexable": true, "report_reasons": null, "author": "XeloXelo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107ctgw/customer_behaviour_accounts_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107ctgw/customer_behaviour_accounts_with_data/", "subreddit_subscribers": 85795, "created_utc": 1673266030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello - I am looking to identify different storage services in SAP like S3, EBS, EFS in AWS. I found a lot of conflicting information and have come here for help.\n\nSo far I only have SAP Hana.", "author_fullname": "t2_uc7m4pgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the different storage services in SAP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107v9jf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673310550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello - I am looking to identify different storage services in SAP like S3, EBS, EFS in AWS. I found a lot of conflicting information and have come here for help.&lt;/p&gt;\n\n&lt;p&gt;So far I only have SAP Hana.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107v9jf", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Packer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107v9jf/what_are_the_different_storage_services_in_sap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107v9jf/what_are_the_different_storage_services_in_sap/", "subreddit_subscribers": 85795, "created_utc": 1673310550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone on this sub has any experience working in a full-time job and as a freelancer/contractor. What mode of employment would you prefer in the data engineering space?\n\nPersonally I'm working full time with lots of benefits, but seeing those juicy hourly rates on contracting jobs makes me think if I should jump ship.", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Full-Time Work Vs Freelance/Contracting Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107tpb1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673306663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone on this sub has any experience working in a full-time job and as a freelancer/contractor. What mode of employment would you prefer in the data engineering space?&lt;/p&gt;\n\n&lt;p&gt;Personally I&amp;#39;m working full time with lots of benefits, but seeing those juicy hourly rates on contracting jobs makes me think if I should jump ship.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "107tpb1", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107tpb1/fulltime_work_vs_freelancecontracting_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107tpb1/fulltime_work_vs_freelancecontracting_work/", "subreddit_subscribers": 85795, "created_utc": 1673306663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a Synapse Serverless Pool setup that I am using to create parquet files in a ADLSGen2 container.  Is there any way to have a PySpark Notebook create a database view in a Serverless Pool?  \n\nI've been creating the parquet, then using a stored proc to create the view (in a pipeline), but is there a way to create a view right after the parquet files are created?  Or am I SOL because the notebook is connected to a Spark pool and can't do anything on the regular Serverless SQL pool because it's outside of Spark (without JDBC)?\n\nAny ideas?  I haven't gotten it to work.  Curious if it's theoretically possible.", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synapse Analytics - PySpark Notebooks and DDL statements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107t6f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673305430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Synapse Serverless Pool setup that I am using to create parquet files in a ADLSGen2 container.  Is there any way to have a PySpark Notebook create a database view in a Serverless Pool?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been creating the parquet, then using a stored proc to create the view (in a pipeline), but is there a way to create a view right after the parquet files are created?  Or am I SOL because the notebook is connected to a Spark pool and can&amp;#39;t do anything on the regular Serverless SQL pool because it&amp;#39;s outside of Spark (without JDBC)?&lt;/p&gt;\n\n&lt;p&gt;Any ideas?  I haven&amp;#39;t gotten it to work.  Curious if it&amp;#39;s theoretically possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "107t6f0", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107t6f0/synapse_analytics_pyspark_notebooks_and_ddl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107t6f0/synapse_analytics_pyspark_notebooks_and_ddl/", "subreddit_subscribers": 85795, "created_utc": 1673305430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "let's say you want to pull rows from bigquery and put them into a redshift db - but you don't have access to gcp buckets.\n\nwhat would be the recommended methods to bring that data over, and how would they change with size in millions of rows: 1,10,50,100,500, 1billion, etc.\n\nif i hit bigquery for 15 million rows, put it in a polars dataframe, and then save that as a csv.  then load the csv to s3, then copy from redshift...that seems like a lot of moves, no?\n\nwould it be a good idea iterate over that bigquery result, and insert the data into redshift directly?\n\ntrying to understand how to design pipelines better rather than just getting it done.", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "intermediary storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107qs90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673300070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;let&amp;#39;s say you want to pull rows from bigquery and put them into a redshift db - but you don&amp;#39;t have access to gcp buckets.&lt;/p&gt;\n\n&lt;p&gt;what would be the recommended methods to bring that data over, and how would they change with size in millions of rows: 1,10,50,100,500, 1billion, etc.&lt;/p&gt;\n\n&lt;p&gt;if i hit bigquery for 15 million rows, put it in a polars dataframe, and then save that as a csv.  then load the csv to s3, then copy from redshift...that seems like a lot of moves, no?&lt;/p&gt;\n\n&lt;p&gt;would it be a good idea iterate over that bigquery result, and insert the data into redshift directly?&lt;/p&gt;\n\n&lt;p&gt;trying to understand how to design pipelines better rather than just getting it done.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107qs90", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107qs90/intermediary_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107qs90/intermediary_storage/", "subreddit_subscribers": 85795, "created_utc": 1673300070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI am doing my research on data engineering and I\u2019m very interested in becoming a healthcare-specific data engineer. I am passionate about healthcare and truly enjoy addressing the nuances of data engineering within the context of healthcare.\n\nI have a Bachelor\u2019s degree in Nursing &amp; a Master\u2019s degree in Data Analytics, the latter of which has afforded me the opportunity to get my current job as a business analyst (basically shifted from a medical biller to analyst before I even graduated grad school &amp; almost doubled my income).\n\nMy role currently involves creating &amp; maintaining Power BI dashboards, using basic Python to automate some things, pulling data from Snowflake &amp; doing analysis for revenue. In school, I did a lot of data modeling projects in Jupyter notebook in Python.\n\nMy research has led me to [awesomeengineering](https://awesomedataengineering.com/) so my plan is to follow that pathway, update my resume &amp; apply to jobs.\n\nWith that said, even with my master\u2019s I am a little concerned that my bachelor won\u2019t be sufficient in becoming competitive for the role. Should I consider getting a bachelor\u2019s in CS, IT or Software Dev on top of following the awesomeengineering pathway?", "author_fullname": "t2_alka6pjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Healthcare business analyst to data engineer - possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107jkt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673285972.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673283789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I am doing my research on data engineering and I\u2019m very interested in becoming a healthcare-specific data engineer. I am passionate about healthcare and truly enjoy addressing the nuances of data engineering within the context of healthcare.&lt;/p&gt;\n\n&lt;p&gt;I have a Bachelor\u2019s degree in Nursing &amp;amp; a Master\u2019s degree in Data Analytics, the latter of which has afforded me the opportunity to get my current job as a business analyst (basically shifted from a medical biller to analyst before I even graduated grad school &amp;amp; almost doubled my income).&lt;/p&gt;\n\n&lt;p&gt;My role currently involves creating &amp;amp; maintaining Power BI dashboards, using basic Python to automate some things, pulling data from Snowflake &amp;amp; doing analysis for revenue. In school, I did a lot of data modeling projects in Jupyter notebook in Python.&lt;/p&gt;\n\n&lt;p&gt;My research has led me to &lt;a href=\"https://awesomedataengineering.com/\"&gt;awesomeengineering&lt;/a&gt; so my plan is to follow that pathway, update my resume &amp;amp; apply to jobs.&lt;/p&gt;\n\n&lt;p&gt;With that said, even with my master\u2019s I am a little concerned that my bachelor won\u2019t be sufficient in becoming competitive for the role. Should I consider getting a bachelor\u2019s in CS, IT or Software Dev on top of following the awesomeengineering pathway?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a2ma3Lkie2EG-P-3gCgxSAWn7fKeMNOaVxbIoBBP908.jpg?auto=webp&amp;s=483e44ca7b0d86f177b188fbbd7371e4973bd0c4", "width": 818, "height": 428}, "resolutions": [{"url": "https://external-preview.redd.it/a2ma3Lkie2EG-P-3gCgxSAWn7fKeMNOaVxbIoBBP908.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37f7f44ffa34248c8ba16aec9cc214d9765998f0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/a2ma3Lkie2EG-P-3gCgxSAWn7fKeMNOaVxbIoBBP908.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=26f05f4d1f6d60cd5b5c27b29c2f25b6fad7da66", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/a2ma3Lkie2EG-P-3gCgxSAWn7fKeMNOaVxbIoBBP908.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6c8afa81863199ac1a6833dc2bdccdb543194733", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/a2ma3Lkie2EG-P-3gCgxSAWn7fKeMNOaVxbIoBBP908.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e4bb337267b5e9acea6c092069a236f2c8df831", "width": 640, "height": 334}], "variants": {}, "id": "YApHHMbWpuH_VtbxYcfIqoEZcUYceWRq4U5PDmRKJVw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107jkt9", "is_robot_indexable": true, "report_reasons": null, "author": "depressedbutsassy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107jkt9/healthcare_business_analyst_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107jkt9/healthcare_business_analyst_to_data_engineer/", "subreddit_subscribers": 85795, "created_utc": 1673283789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My thoughts are it could be useful to receive files to put into S3 or alike?", "author_fullname": "t2_a7nec5bo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Someone from work is showing me how to use FTP, does this have any relevance in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_107bel7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673261141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My thoughts are it could be useful to receive files to put into S3 or alike?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "107bel7", "is_robot_indexable": true, "report_reasons": null, "author": "TheCumCopter", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107bel7/someone_from_work_is_showing_me_how_to_use_ftp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/107bel7/someone_from_work_is_showing_me_how_to_use_ftp/", "subreddit_subscribers": 85795, "created_utc": 1673261141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I want to test different vendors against Spark (or other managed Spark solutions) about data preparation use cases. Meaning, taking raw data stored on a data lake and transforming it using SQL into analytics-ready data. Any suggestions for this kind of benchmark? I read a lot about the TPC benchmark but didn't find any information regarding the scenario I needed.", "author_fullname": "t2_v22qxq2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data preparation benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1078hdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673250788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to test different vendors against Spark (or other managed Spark solutions) about data preparation use cases. Meaning, taking raw data stored on a data lake and transforming it using SQL into analytics-ready data. Any suggestions for this kind of benchmark? I read a lot about the TPC benchmark but didn&amp;#39;t find any information regarding the scenario I needed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1078hdw", "is_robot_indexable": true, "report_reasons": null, "author": "All-is-data3891", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1078hdw/data_preparation_benchmark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1078hdw/data_preparation_benchmark/", "subreddit_subscribers": 85795, "created_utc": 1673250788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sppgx30r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Activity Selection Problem using Greedy Approach", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_107jf2o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/V0ZrLuIVzaY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/V0ZrLuIVzaY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/V0ZrLuIVzaY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/V0ZrLuIVzaY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/107jf2o", "height": 200}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KcmAZrUo4BKEYusPQuAHY2dHqA7bYV4cANCOMT-0OLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673283438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/V0ZrLuIVzaY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GZX4YmlcM_paZrWMc9X7YImUzJNMbGtbkdocoHHcyw8.jpg?auto=webp&amp;s=1ee0eb6e602aa06fbd351bb644ff29693e8517fa", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/GZX4YmlcM_paZrWMc9X7YImUzJNMbGtbkdocoHHcyw8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2cc70d549d19b062950e462892e866c27dee9ab5", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/GZX4YmlcM_paZrWMc9X7YImUzJNMbGtbkdocoHHcyw8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=667f5baa0ee0a1f68d171050f7c24a1d20943141", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/GZX4YmlcM_paZrWMc9X7YImUzJNMbGtbkdocoHHcyw8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=982d8c80afe44a9ed6c0e448a6b8fde0c0adcbe1", "width": 320, "height": 240}], "variants": {}, "id": "kn_DK6DZQnMoSFugEdYsIyTdOloZRZLcJNY1VFGStM4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "107jf2o", "is_robot_indexable": true, "report_reasons": null, "author": "thetech_learner", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/107jf2o/sql_activity_selection_problem_using_greedy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/V0ZrLuIVzaY", "subreddit_subscribers": 85795, "created_utc": 1673283438.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/V0ZrLuIVzaY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Activity Selection Problem using Greedy Algorithm Method | DSA Interview Question Solved\"&gt;&lt;/iframe&gt;", "author_name": " Code with Scaler", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/V0ZrLuIVzaY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@CodewithScaler"}}, "is_video": false}}], "before": null}}