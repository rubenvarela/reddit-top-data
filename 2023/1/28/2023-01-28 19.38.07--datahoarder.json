{"kind": "Listing", "data": {"after": "t3_10mvix0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure many have observed that High-capacity Blu-ray still represents a cost effective medium, if only someone would make a 2 meter stack of them and 'tap' the hole/lumen down the middle so that a threaded pole could be 'screwed' in from each end to a set point, to retract the undesired discs away from the desired disc, and allow it to be removed for data retrieval. Or a carousel; I'm not fussy.\n\nAnyway if I understand correctly, back in 2013, [Abbe](https://en.wikipedia.org/wiki/Ernst_Abbe)'s limit was circumvented (lay article [here](https://theconversation.com/more-data-storage-heres-how-to-fit-1-000-terabytes-on-a-dvd-15306), and the paper in Nature Communications [here](https://www.nature.com/articles/ncomms3061)), and the 500nm 'smallest defect' became 9nm. There was now only the matter of finding a physical medium that could reliably hold such fine etchings.\n\nWell, I'm here to moan about it. I've been waiting aaaaages. Where're my petabyte DVDs?? I figure if anyone knows the answer, they probably check in with this hive mind occasionally...", "author_fullname": "t2_92dedrzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where are my 1000TB DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10negvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674910663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure many have observed that High-capacity Blu-ray still represents a cost effective medium, if only someone would make a 2 meter stack of them and &amp;#39;tap&amp;#39; the hole/lumen down the middle so that a threaded pole could be &amp;#39;screwed&amp;#39; in from each end to a set point, to retract the undesired discs away from the desired disc, and allow it to be removed for data retrieval. Or a carousel; I&amp;#39;m not fussy.&lt;/p&gt;\n\n&lt;p&gt;Anyway if I understand correctly, back in 2013, &lt;a href=\"https://en.wikipedia.org/wiki/Ernst_Abbe\"&gt;Abbe&lt;/a&gt;&amp;#39;s limit was circumvented (lay article &lt;a href=\"https://theconversation.com/more-data-storage-heres-how-to-fit-1-000-terabytes-on-a-dvd-15306\"&gt;here&lt;/a&gt;, and the paper in Nature Communications &lt;a href=\"https://www.nature.com/articles/ncomms3061\"&gt;here&lt;/a&gt;), and the 500nm &amp;#39;smallest defect&amp;#39; became 9nm. There was now only the matter of finding a physical medium that could reliably hold such fine etchings.&lt;/p&gt;\n\n&lt;p&gt;Well, I&amp;#39;m here to moan about it. I&amp;#39;ve been waiting aaaaages. Where&amp;#39;re my petabyte DVDs?? I figure if anyone knows the answer, they probably check in with this hive mind occasionally...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?auto=webp&amp;v=enabled&amp;s=921f5aa8e880e95aba7d78d056e2e71712718f89", "width": 220, "height": 283}, "resolutions": [{"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0f0efa37fbdc98dd0d0d5650f9ee8c14352551e", "width": 108, "height": 138}, {"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d86b18bdd3f7f5e01af172eda13c182f172f3798", "width": 216, "height": 277}], "variants": {}, "id": "Hb8orkMr0s300pO9A1UwvFLeGs4I1Cq2gd3qkqXY-Oc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10negvg", "is_robot_indexable": true, "report_reasons": null, "author": "rackhamlerouge9", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/", "subreddit_subscribers": 667590, "created_utc": 1674910663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vlzdmewf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BBC Modi Documentary Removal - Internet Archive Blogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n7b7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674884062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/01/27/bbc-modi-documentary-removal/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n7b7t", "is_robot_indexable": true, "report_reasons": null, "author": "m8wt", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n7b7t/bbc_modi_documentary_removal_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.archive.org/2023/01/27/bbc-modi-documentary-removal/", "subreddit_subscribers": 667590, "created_utc": 1674884062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026", "author_fullname": "t2_2ks4hmij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think Seagate's HDD's will get to 50 TB by 2026 and 100 TB by 2030? Seagate thinks so.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mycpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674859128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026\"&gt;https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?auto=webp&amp;v=enabled&amp;s=9a866a9e666cb9b470144479b0ce80147ef6328c", "width": 708, "height": 403}, "resolutions": [{"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1125652338a094bda8ddb98629cb27bc56ca619e", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c825f0157b25486c48a43f765db7ac51fd70f5f1", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58ad253f01ca168c83b151a9581992675fd9e6dc", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13994f48412f5fc6a1b30e84dd626c2abc102d9b", "width": 640, "height": 364}], "variants": {}, "id": "xVFfmPtPmKPtrhKVVnMqwcuh4W-FVt4VbZZAlJLJcaI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mycpv", "is_robot_indexable": true, "report_reasons": null, "author": "jasonbaker125", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/", "subreddit_subscribers": 667590, "created_utc": 1674859128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So recently YouTube made some more changes to their rules and they seem to be retroactively applying them and striking channels. As of now this is mostly an issue with the 2A/Firearms communities of YouTube but I'm sure this will be affecting all channels breaking any of the new rules and old one, this is just another wave  content crackdown.\n\nI'm not sure how many of you saw, but [Garand Thumb got a content strike](https://twitter.com/GarandThumb1/status/1618748298550190083?t=HIExkVleJ258UaSlsNLWOw&amp;s=19) thanks to YouTube new policies on an old video, this means they are retroactively applying this and all of the firearms channels on YouTube are in danger of disappearing soon if they strike 3 videos, content creators will also be having to go through their backlog and remove videos that might be in violation of these new rules. \n\nI honestly think the ultimate goal in this new \"no showing assembly or disassembly of a firearm\" rule is to limit the information on the internet about caring for and maintaining firearms. If they ever do manage to destroy our 2A rights and attempt a gun grab, the weapons that manage to be stashed away will need to be well kept up and that why they're removing the info now, to damage the chances of future generations. Even if it is for a less ominous reason, we're still in danger of losing hours of entertainment and memories from our favorite creators.\n\nOur best way to fight this is kick into archival mode. We need to start downloading every video we care about especially anything involving the essentials like firearms basics, training, shooting tips, cleaning, maintainance, safety etc. I'm doing what I can to backup all the videos as well as their descriptions and the comments section so any useful information is saved, but I feel like I'm kinda overwhelmed and ill prepared for a backup task like this. I'm going to see what I can do about storage and how many channels I can back up. Now's where you guys come in!\n\n\n\n**If you want to help archive channels, here's the easiest way**\n\nI looked around for hours and the information on how to archive channels is very difficult to understand and near impossible to setup however I finally found a workaround and that's what I'm here to share with you! The most efficient and effective program I've found is [TarTube](https://tartube.sourceforge.io/) this application is an installer and GUI for the very popular yt-dlp and ffmpeg combo to download batch videos from YouTube. The only problem I found with those programs is because they run through command line it was basically impossible for me to get it to work, however TarTube takes care of all the setup and gets rid of the need for knowing command line prompts and replaces it with a relatively slick GUI. I'm going to break down the steps as quickly and easily as I can for anyome interested in helping preserve this Era of YouTube that may be coming to a close. \n\n\n**Step 1.** [Download the TarTube installer for your specific OS](https://tartube.sourceforge.io/#downloads)\n\n\n**Step 2.** Follow the on screen instructions for installing yt-dlp ffmpeg and the TarTube GUI program, it's relatively simple, you might need to run as admin depending on your settings.\n\n\n**Step 3.** (possibly optional) Give your PC a reboot to make sure the new files are installed in the system and will run properly. \n\n\n**Step 4.** Open Tar Tube and click on the \"Classic Mode\" tab that's 3 tabs in on the 3rd menu column \n\n\n**Step 5.** Select \"Edit\" from the main menu in the top left corner of the screen, then select \"General Download Preferences\"\n\n\n**Step 6.** Select the \"Post Processing\" tab then select \"Audio quality of the post processed file\" Change it from \"Medium VBR\" to 320kbps or 256kbps, 1080p YouTube videos have their audio tracks limited to 256kbps but by selecting 320kbps you're insuring that the rip maintains the highest possible quality even though your not upconverting it or anything. Select \"Okay\" and you should be back in the \"Classic Mode\" tab. Nows where we get rolling. \n\n\n**Step 7.** Grab the URL of the video or playlist you want to download from the web and paste it into the \"Enter URLs Below Box\"\n\n\n**Step 8.** Select the destination you want the videos to download to on your storage. Then click the \"Add URLs\" button to the right.\n\n\n**Step 9.** Select \"Download All\" in the bottom right corner and let the program work its magic.\n\nSo far I've ripped 3 playlist and am working on a whole channel now, the time has varied between 5 to 30 minutes but I'm on a decent speed connection. This is definitely a community job so if you have the storage and the free time help preserve the content we have today for future generations.", "author_fullname": "t2_5369s5y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easily Archive YouTube Channels and Videos - Classic YouTube videos in Danger after new rule changes. We need to start archiving our favorite content.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n0t7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674865187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So recently YouTube made some more changes to their rules and they seem to be retroactively applying them and striking channels. As of now this is mostly an issue with the 2A/Firearms communities of YouTube but I&amp;#39;m sure this will be affecting all channels breaking any of the new rules and old one, this is just another wave  content crackdown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure how many of you saw, but &lt;a href=\"https://twitter.com/GarandThumb1/status/1618748298550190083?t=HIExkVleJ258UaSlsNLWOw&amp;amp;s=19\"&gt;Garand Thumb got a content strike&lt;/a&gt; thanks to YouTube new policies on an old video, this means they are retroactively applying this and all of the firearms channels on YouTube are in danger of disappearing soon if they strike 3 videos, content creators will also be having to go through their backlog and remove videos that might be in violation of these new rules. &lt;/p&gt;\n\n&lt;p&gt;I honestly think the ultimate goal in this new &amp;quot;no showing assembly or disassembly of a firearm&amp;quot; rule is to limit the information on the internet about caring for and maintaining firearms. If they ever do manage to destroy our 2A rights and attempt a gun grab, the weapons that manage to be stashed away will need to be well kept up and that why they&amp;#39;re removing the info now, to damage the chances of future generations. Even if it is for a less ominous reason, we&amp;#39;re still in danger of losing hours of entertainment and memories from our favorite creators.&lt;/p&gt;\n\n&lt;p&gt;Our best way to fight this is kick into archival mode. We need to start downloading every video we care about especially anything involving the essentials like firearms basics, training, shooting tips, cleaning, maintainance, safety etc. I&amp;#39;m doing what I can to backup all the videos as well as their descriptions and the comments section so any useful information is saved, but I feel like I&amp;#39;m kinda overwhelmed and ill prepared for a backup task like this. I&amp;#39;m going to see what I can do about storage and how many channels I can back up. Now&amp;#39;s where you guys come in!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;If you want to help archive channels, here&amp;#39;s the easiest way&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I looked around for hours and the information on how to archive channels is very difficult to understand and near impossible to setup however I finally found a workaround and that&amp;#39;s what I&amp;#39;m here to share with you! The most efficient and effective program I&amp;#39;ve found is &lt;a href=\"https://tartube.sourceforge.io/\"&gt;TarTube&lt;/a&gt; this application is an installer and GUI for the very popular yt-dlp and ffmpeg combo to download batch videos from YouTube. The only problem I found with those programs is because they run through command line it was basically impossible for me to get it to work, however TarTube takes care of all the setup and gets rid of the need for knowing command line prompts and replaces it with a relatively slick GUI. I&amp;#39;m going to break down the steps as quickly and easily as I can for anyome interested in helping preserve this Era of YouTube that may be coming to a close. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; &lt;a href=\"https://tartube.sourceforge.io/#downloads\"&gt;Download the TarTube installer for your specific OS&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Follow the on screen instructions for installing yt-dlp ffmpeg and the TarTube GUI program, it&amp;#39;s relatively simple, you might need to run as admin depending on your settings.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; (possibly optional) Give your PC a reboot to make sure the new files are installed in the system and will run properly. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Open Tar Tube and click on the &amp;quot;Classic Mode&amp;quot; tab that&amp;#39;s 3 tabs in on the 3rd menu column &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Select &amp;quot;Edit&amp;quot; from the main menu in the top left corner of the screen, then select &amp;quot;General Download Preferences&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 6.&lt;/strong&gt; Select the &amp;quot;Post Processing&amp;quot; tab then select &amp;quot;Audio quality of the post processed file&amp;quot; Change it from &amp;quot;Medium VBR&amp;quot; to 320kbps or 256kbps, 1080p YouTube videos have their audio tracks limited to 256kbps but by selecting 320kbps you&amp;#39;re insuring that the rip maintains the highest possible quality even though your not upconverting it or anything. Select &amp;quot;Okay&amp;quot; and you should be back in the &amp;quot;Classic Mode&amp;quot; tab. Nows where we get rolling. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 7.&lt;/strong&gt; Grab the URL of the video or playlist you want to download from the web and paste it into the &amp;quot;Enter URLs Below Box&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 8.&lt;/strong&gt; Select the destination you want the videos to download to on your storage. Then click the &amp;quot;Add URLs&amp;quot; button to the right.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 9.&lt;/strong&gt; Select &amp;quot;Download All&amp;quot; in the bottom right corner and let the program work its magic.&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve ripped 3 playlist and am working on a whole channel now, the time has varied between 5 to 30 minutes but I&amp;#39;m on a decent speed connection. This is definitely a community job so if you have the storage and the free time help preserve the content we have today for future generations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?auto=webp&amp;v=enabled&amp;s=2fe2a8dce2671e8124f092fce8dbd6b1d12552de", "width": 1284, "height": 1848}, "resolutions": [{"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bec4ed2cde3782afca32f298921e6bd4a782035", "width": 108, "height": 155}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75b6edb44cdeb7b77ed6759b8f83044931688f53", "width": 216, "height": 310}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b468ad32242e1a500d7d9cd0268151bb6229d106", "width": 320, "height": 460}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36267f65375dc45657ed6523c5f53c2a5dd709d7", "width": 640, "height": 921}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21a308de6c128c48d87576a38b9a5279fa621b74", "width": 960, "height": 1381}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=839bbf45a8a3285b2b74953787060ae466d31e02", "width": 1080, "height": 1554}], "variants": {}, "id": "lLG9etVZmm_azac4y65McnTDTawlJWOxp4is6zpk7kE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n0t7i", "is_robot_indexable": true, "report_reasons": null, "author": "DepressMyCNS", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/", "subreddit_subscribers": 667590, "created_utc": 1674865187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mich90l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found 2 of these in an old NAS machine, if they work would these be good to use for my server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10mx37y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GTERfq0rZiZgmsLAXrzIXqm150-Pq03SrpVhxwMqJo4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674856056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/97ekw77fpnea1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?auto=webp&amp;v=enabled&amp;s=6b6a3f16857913476227a7688ad2ac391488d68f", "width": 2268, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84b4542bc688882c9bee9068c7f2a27d3a14c933", "width": 108, "height": 192}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9881179c665853d5d04c095eba6871ee61c6e2d", "width": 216, "height": 384}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d840c176bbe8293b4a0f15e264da0b307e96fc0", "width": 320, "height": 568}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19b88933b1779a696bc1aa0e27fbf07668d27bd4", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe0aa0056e23ae108565a2cb82f3133094a1dafb", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89748e18dffa6dd41dab8c9a0b44c60089ef7af2", "width": 1080, "height": 1920}], "variants": {}, "id": "qYpiJZbdEtR_ckv7m4qsJW_JRres1akYvRm7E5JCTCI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mx37y", "is_robot_indexable": true, "report_reasons": null, "author": "candroid_man", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mx37y/found_2_of_these_in_an_old_nas_machine_if_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/97ekw77fpnea1.jpg", "subreddit_subscribers": 667590, "created_utc": 1674856056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Created a script to use when moving large amounts of data between folders/servers and wanting to skip \\`Force Recheck\\` inside the torrent client.  \nYou just point it to your rTorrent \\`session\\` folder, specify the path to change and the new path and it'll replace all session data.\n\nFor example, when moving torrents from \\`/downloads/Temp\\` to \\`/downloads/Movies\\` you can use this script like so:\n\n    python torrent-mover.py --src /downloads/Temp/ --dst /downloads/Movies/ /config/rTorrent/session\n\nCurrently, it supports rTorrent only!\n\n[https://github.com/uraid/torrent-mover](https://github.com/uraid/torrent-mover)", "author_fullname": "t2_143yl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change the path for downloaded torrents without force recheck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ne0q5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674911788.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674909133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Created a script to use when moving large amounts of data between folders/servers and wanting to skip `Force Recheck` inside the torrent client.&lt;br/&gt;\nYou just point it to your rTorrent `session` folder, specify the path to change and the new path and it&amp;#39;ll replace all session data.&lt;/p&gt;\n\n&lt;p&gt;For example, when moving torrents from `/downloads/Temp` to `/downloads/Movies` you can use this script like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;python torrent-mover.py --src /downloads/Temp/ --dst /downloads/Movies/ /config/rTorrent/session\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Currently, it supports rTorrent only!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/uraid/torrent-mover\"&gt;https://github.com/uraid/torrent-mover&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?auto=webp&amp;v=enabled&amp;s=51b85ba3f64987861bd549f08ab8c8ac17a474af", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d119c95f59a80509e216817e519cd55a3c1e6ec5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa8fc2fe45076ce98033b3b5b6b86a51683d300a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb79c7da38a5d82f6ff57c265df3199ebe8eac22", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68e09c426f33abfcdc66b09e25f5bcc2be26df38", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74b3b3f11e5ee0d76c9452368c28862776d653de", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=632d10fb2755c892f973cd7611e848bb00b4b6fb", "width": 1080, "height": 540}], "variants": {}, "id": "IajE0zginlUFd7b6rlGhJLHs6Ojv0vv6JXrwVj0x30k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "59TB RAID6 | 43TB Usable", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ne0q5", "is_robot_indexable": true, "report_reasons": null, "author": "n0llbyte", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/", "subreddit_subscribers": 667590, "created_utc": 1674909133.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mwnmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674855010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10mwnmn", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/", "subreddit_subscribers": 667590, "created_utc": 1674855010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nCurrently, I have a DS220+ holding 2 8TB WD Reds, for my home NAS. I'm thinking about consolidating it to something rackmount, so I can move my random devices onto my mostly empty rack. I was wondering what would be a better decision for that consolidation. Should I get something like the Rackstation RS422+, since I'm already used to the Synology ecosystem (DS220+ NAS, RT2600ac router), or should I look into building a 1U server running Unraid, or something similar? \n\nMy main purpose for asking is I feel $700 is a bit pricy for a 1U 4-bay storage solution.\n\nSome additional context: I have plenty of experience with managing servers, building computers (still learning about server gear though), and have a massive willingness to learn.\n\nThanks in advance", "author_fullname": "t2_hk3d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synology Rackstation or build my own rackmount storage server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nj3qu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674923476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Currently, I have a DS220+ holding 2 8TB WD Reds, for my home NAS. I&amp;#39;m thinking about consolidating it to something rackmount, so I can move my random devices onto my mostly empty rack. I was wondering what would be a better decision for that consolidation. Should I get something like the Rackstation RS422+, since I&amp;#39;m already used to the Synology ecosystem (DS220+ NAS, RT2600ac router), or should I look into building a 1U server running Unraid, or something similar? &lt;/p&gt;\n\n&lt;p&gt;My main purpose for asking is I feel $700 is a bit pricy for a 1U 4-bay storage solution.&lt;/p&gt;\n\n&lt;p&gt;Some additional context: I have plenty of experience with managing servers, building computers (still learning about server gear though), and have a massive willingness to learn.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10nj3qu", "is_robot_indexable": true, "report_reasons": null, "author": "benetha619", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10nj3qu/synology_rackstation_or_build_my_own_rackmount/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10nj3qu/synology_rackstation_or_build_my_own_rackmount/", "subreddit_subscribers": 667590, "created_utc": 1674923476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Did someone manage to get a hold of Blindy.tv streams library before it got shut down few years ago? I just learned how great content it hosted - turning tv shows like Star Trek to audio episodes with additional commentary for the blind, which make it great for in car listening.", "author_fullname": "t2_iik18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blindy.tv anyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ncg5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674903277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did someone manage to get a hold of Blindy.tv streams library before it got shut down few years ago? I just learned how great content it hosted - turning tv shows like Star Trek to audio episodes with additional commentary for the blind, which make it great for in car listening.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ncg5h", "is_robot_indexable": true, "report_reasons": null, "author": "kanczug", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ncg5h/blindytv_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ncg5h/blindytv_anyone/", "subreddit_subscribers": 667590, "created_utc": 1674903277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Have a bunch of unorganized data on a number of devices + 2 external SSDs. Yes I know this is not ideal. Looking to back everything up to Google Drive, and a home server (already set up). Anything to consider going forward? Not sure if there's any software/services that would be able to kind of \"automagically\" sort files, or if I'd have to do everything manually.", "author_fullname": "t2_cv8radua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to begin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10nm7ek", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674931417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a bunch of unorganized data on a number of devices + 2 external SSDs. Yes I know this is not ideal. Looking to back everything up to Google Drive, and a home server (already set up). Anything to consider going forward? Not sure if there&amp;#39;s any software/services that would be able to kind of &amp;quot;automagically&amp;quot; sort files, or if I&amp;#39;d have to do everything manually.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10nm7ek", "is_robot_indexable": true, "report_reasons": null, "author": "TheHornedBandit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10nm7ek/where_to_begin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10nm7ek/where_to_begin/", "subreddit_subscribers": 667590, "created_utc": 1674931417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I'm trying to set up some one-way backups Jobs on GoodSync but can't figure out a way to make these two filters:\n\n1- Filter so that it's an one-way backup A&gt;B but ignore if file from B is newer (last last modified) than A.\n\n2- Sync C folder and ignore (exclude) all .mp4 files, except the ones in folders named D, which are inside C.  \n\n\nAny ideas? Thank you!", "author_fullname": "t2_cplanb9t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with GoodSync exclusion filters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10nlddv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674929299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;m trying to set up some one-way backups Jobs on GoodSync but can&amp;#39;t figure out a way to make these two filters:&lt;/p&gt;\n\n&lt;p&gt;1- Filter so that it&amp;#39;s an one-way backup A&amp;gt;B but ignore if file from B is newer (last last modified) than A.&lt;/p&gt;\n\n&lt;p&gt;2- Sync C folder and ignore (exclude) all .mp4 files, except the ones in folders named D, which are inside C.  &lt;/p&gt;\n\n&lt;p&gt;Any ideas? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10nlddv", "is_robot_indexable": true, "report_reasons": null, "author": "Desperate-Step4469", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10nlddv/help_with_goodsync_exclusion_filters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10nlddv/help_with_goodsync_exclusion_filters/", "subreddit_subscribers": 667590, "created_utc": 1674929299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i used to use the RipMeApp from here: [https://github.com/RipMeApp/ripme](https://github.com/RipMeApp/ripme)\n\nbut it's not working very good lately. and i saw this website: [https://redditdownloader.github.io/](https://redditdownloader.github.io/)\n\nhowever, i couldn't find mentions if this webstire is safe to use or not.", "author_fullname": "t2_45vvh8ho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is redditdownloader.github.io safe to use ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ngw05", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674917645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i used to use the RipMeApp from here: &lt;a href=\"https://github.com/RipMeApp/ripme\"&gt;https://github.com/RipMeApp/ripme&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;but it&amp;#39;s not working very good lately. and i saw this website: &lt;a href=\"https://redditdownloader.github.io/\"&gt;https://redditdownloader.github.io/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;however, i couldn&amp;#39;t find mentions if this webstire is safe to use or not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ngw05", "is_robot_indexable": true, "report_reasons": null, "author": "Miau64", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ngw05/is_redditdownloadergithubio_safe_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ngw05/is_redditdownloadergithubio_safe_to_use/", "subreddit_subscribers": 667590, "created_utc": 1674917645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently choosing 2 x 16TB hard disks for setting up TrueNAS Scale as a VM on Proxmox.\n\nI'm hesitating between 3 models :\n\n1/ Seagate Exos X18 (ST16000NM000J) for ~$155, this one is brand new, I'm not sure if it will have the 5 years warranty from manufacturer, but at this price I guess I can take the risk.\n\n2/ Toshiba MG08 (MG08ACA16TE) for ~$145, this one is second hand / reconditioned by manufacturer and have a 2 years warranty from the reseller.\n\n3/ Seagate Ironwolf Pro (ST16000NE000) for ~$189, same reseller as the Exos, so brand new.\n\nMy home server is located in my home office, so noise shouldn't be a big issue, even if I would prefer to work in silence.\n\nI was thinking to maybe choose 2 different models for my first pool to limit the risk of having 2 disk failures at the same time.\n\nAny recommendation ? Thank you.", "author_fullname": "t2_rywx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard choice for 16TB disks at this price", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ng4a5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674915508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently choosing 2 x 16TB hard disks for setting up TrueNAS Scale as a VM on Proxmox.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hesitating between 3 models :&lt;/p&gt;\n\n&lt;p&gt;1/ Seagate Exos X18 (ST16000NM000J) for ~$155, this one is brand new, I&amp;#39;m not sure if it will have the 5 years warranty from manufacturer, but at this price I guess I can take the risk.&lt;/p&gt;\n\n&lt;p&gt;2/ Toshiba MG08 (MG08ACA16TE) for ~$145, this one is second hand / reconditioned by manufacturer and have a 2 years warranty from the reseller.&lt;/p&gt;\n\n&lt;p&gt;3/ Seagate Ironwolf Pro (ST16000NE000) for ~$189, same reseller as the Exos, so brand new.&lt;/p&gt;\n\n&lt;p&gt;My home server is located in my home office, so noise shouldn&amp;#39;t be a big issue, even if I would prefer to work in silence.&lt;/p&gt;\n\n&lt;p&gt;I was thinking to maybe choose 2 different models for my first pool to limit the risk of having 2 disk failures at the same time.&lt;/p&gt;\n\n&lt;p&gt;Any recommendation ? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ng4a5", "is_robot_indexable": true, "report_reasons": null, "author": "barthmania", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ng4a5/hard_choice_for_16tb_disks_at_this_price/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ng4a5/hard_choice_for_16tb_disks_at_this_price/", "subreddit_subscribers": 667590, "created_utc": 1674915508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran DoD short on 5x 8tb disks prior to selling them. They had been running in my server for around 25-35k hours without errors, SMART OK. Now I get feedback from my first customer saying it\u2019s not working at all. Not recognized/errors. Did DoD short kill them?\n\nI did not run any tests after DoD. But it finished without errors.", "author_fullname": "t2_1gdbm4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for DBAN to destroy an HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ndn27", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674907807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran DoD short on 5x 8tb disks prior to selling them. They had been running in my server for around 25-35k hours without errors, SMART OK. Now I get feedback from my first customer saying it\u2019s not working at all. Not recognized/errors. Did DoD short kill them?&lt;/p&gt;\n\n&lt;p&gt;I did not run any tests after DoD. But it finished without errors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ndn27", "is_robot_indexable": true, "report_reasons": null, "author": "PessimisticHoarder", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/", "subreddit_subscribers": 667590, "created_utc": 1674907807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "3.5 Inch Hard Drive Case, PHIXERO HDD/SSD Portable Storage Box with Exclusive Note, Dustproof, Shockproof and Antistatic(5 Pack) https://a.co/d/8ZkGEmf\n\nCame across these and ordered a set and had my wife order a set too. $28.99 and has an 80% off coupon, making it roughly a little under $7 tax and all. Haven't gotten them in yet, but wanted to share before the coupon disappears.", "author_fullname": "t2_38fwickd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3.5\" Hard Drive Storage Case 5-pk - under $7", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n80gi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674886515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;3.5 Inch Hard Drive Case, PHIXERO HDD/SSD Portable Storage Box with Exclusive Note, Dustproof, Shockproof and Antistatic(5 Pack) &lt;a href=\"https://a.co/d/8ZkGEmf\"&gt;https://a.co/d/8ZkGEmf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Came across these and ordered a set and had my wife order a set too. $28.99 and has an 80% off coupon, making it roughly a little under $7 tax and all. Haven&amp;#39;t gotten them in yet, but wanted to share before the coupon disappears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10n80gi", "is_robot_indexable": true, "report_reasons": null, "author": "duckalufagus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n80gi/35_hard_drive_storage_case_5pk_under_7/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n80gi/35_hard_drive_storage_case_5pk_under_7/", "subreddit_subscribers": 667590, "created_utc": 1674886515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to be able to keep libvirt qcow2 virtual machine images synced via a cloud provider, encrypted, and synced incrementally so that if I will not have re-upload an entire 30/40GB virtual image just because I logged into a VM and made a very small change.\n\nA koofr dev has stated they had to choose zero knowledge encryption which apparently cannot work with incremental sync. If I were roling my own encryption with rclone perhaps there is a workaround. I read about restic but it seems to be for backup rather than sync.\n\nI have been using Cryptomator with Insync on GDrive for general cloud use but I would like to try rclone on a new provider and I am considering filen and koofr at the moment.\n\nIs client-side encrypted incremental sync possible, and if so can it work with those two providers or should I consider another?", "author_fullname": "t2_p61cyzvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental/block-level client-side encrypted sync of large files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mz8go", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674861316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to be able to keep libvirt qcow2 virtual machine images synced via a cloud provider, encrypted, and synced incrementally so that if I will not have re-upload an entire 30/40GB virtual image just because I logged into a VM and made a very small change.&lt;/p&gt;\n\n&lt;p&gt;A koofr dev has stated they had to choose zero knowledge encryption which apparently cannot work with incremental sync. If I were roling my own encryption with rclone perhaps there is a workaround. I read about restic but it seems to be for backup rather than sync.&lt;/p&gt;\n\n&lt;p&gt;I have been using Cryptomator with Insync on GDrive for general cloud use but I would like to try rclone on a new provider and I am considering filen and koofr at the moment.&lt;/p&gt;\n\n&lt;p&gt;Is client-side encrypted incremental sync possible, and if so can it work with those two providers or should I consider another?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mz8go", "is_robot_indexable": true, "report_reasons": null, "author": "AnonymousAardvark22", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/", "subreddit_subscribers": 667590, "created_utc": 1674861316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Could anyone kindly suggest a mac program that is able to either sync two folders together or best identify what files are missing between two folders.\n\nExample\n\nI have been trying to get an exact copy of a folder I currently have, which has all of my photos in it, and just do a plain, straightforward backup. I have used a lot of programs in the past but for some reason there is a discrepancy\\\\difference of 3 files between the two folders and for the life of me I can't figure out what they are, and can't get them to sync. \n\nCarbon Copy Cloner can't find them, even SyncTime can't find them. I have even tried Compare Folders but it takes way to long to populate.\n\nAny suggestions would be very helpful", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best organising\\syncing program for Mac to keep files the same", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10myt2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674860275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could anyone kindly suggest a mac program that is able to either sync two folders together or best identify what files are missing between two folders.&lt;/p&gt;\n\n&lt;p&gt;Example&lt;/p&gt;\n\n&lt;p&gt;I have been trying to get an exact copy of a folder I currently have, which has all of my photos in it, and just do a plain, straightforward backup. I have used a lot of programs in the past but for some reason there is a discrepancy\\difference of 3 files between the two folders and for the life of me I can&amp;#39;t figure out what they are, and can&amp;#39;t get them to sync. &lt;/p&gt;\n\n&lt;p&gt;Carbon Copy Cloner can&amp;#39;t find them, even SyncTime can&amp;#39;t find them. I have even tried Compare Folders but it takes way to long to populate.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be very helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10myt2p", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/", "subreddit_subscribers": 667590, "created_utc": 1674860275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all I'm working on a data archiving project and a guide for layman's as YouTube is cracking down once again and we need as many people archiving as possible. \n\nThe program I'm using is called TarTube, it's a GUI and installer based off of yt-dlp and ffmpeg, I was successfully able to bulk download an entire playlist easily, so it's great for capturing videos but I've been digging through the setting and was unable to find a way to easily capture the descriptions and comments for each video.\n\nIf anyone can help me figure out how to configure this it will be much appreciated!", "author_fullname": "t2_5369s5y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help capturing YouTube descriptions and comments.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mx890", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674856398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all I&amp;#39;m working on a data archiving project and a guide for layman&amp;#39;s as YouTube is cracking down once again and we need as many people archiving as possible. &lt;/p&gt;\n\n&lt;p&gt;The program I&amp;#39;m using is called TarTube, it&amp;#39;s a GUI and installer based off of yt-dlp and ffmpeg, I was successfully able to bulk download an entire playlist easily, so it&amp;#39;s great for capturing videos but I&amp;#39;ve been digging through the setting and was unable to find a way to easily capture the descriptions and comments for each video.&lt;/p&gt;\n\n&lt;p&gt;If anyone can help me figure out how to configure this it will be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mx890", "is_robot_indexable": true, "report_reasons": null, "author": "DepressMyCNS", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/", "subreddit_subscribers": 667590, "created_utc": 1674856398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nI have written firmware files for an old phone of mine onto a (albeit bargain bin) BD R a couple of months ago and the drive is refusing to read the disc, I looked at the surface and the ring near the center has white dots in the dye, almost as if the drive skipped a few bits of data while writing. ddrescue says media is not present and the drive stops reading after a few seconds\n\n\nI tossed the whole spindle after I got a few bad burns. I'll shell out for the more expensive Philips discs when I need them", "author_fullname": "t2_yi08dfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to recover data off of a BD R that's burnt with white \"spots\" on the surface?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvaoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674851685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I have written firmware files for an old phone of mine onto a (albeit bargain bin) BD R a couple of months ago and the drive is refusing to read the disc, I looked at the surface and the ring near the center has white dots in the dye, almost as if the drive skipped a few bits of data while writing. ddrescue says media is not present and the drive stops reading after a few seconds&lt;/p&gt;\n\n&lt;p&gt;I tossed the whole spindle after I got a few bad burns. I&amp;#39;ll shell out for the more expensive Philips discs when I need them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvaoc", "is_robot_indexable": true, "report_reasons": null, "author": "Logan_MacGyver", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvaoc/is_there_any_way_to_recover_data_off_of_a_bd_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvaoc/is_there_any_way_to_recover_data_off_of_a_bd_r/", "subreddit_subscribers": 667590, "created_utc": 1674851685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any thoughts on this drive?  It's currently steeply discounted at Best Buy and Amazon for $240.  Was thinking of picking one up just for some extra storage (in addition to my 20TB of HDD).", "author_fullname": "t2_qs1nsow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial X8 4TB external SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n2ngy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674870053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any thoughts on this drive?  It&amp;#39;s currently steeply discounted at Best Buy and Amazon for $240.  Was thinking of picking one up just for some extra storage (in addition to my 20TB of HDD).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n2ngy", "is_robot_indexable": true, "report_reasons": null, "author": "LazarusLong67", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/", "subreddit_subscribers": 667590, "created_utc": 1674870053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have a problem. My HDD somehow disconnected itself while defragmentation and now it shows up as RAW, is there any way to convert it to NTFS without losing data and folder structure? It\u2019s very important because there is 15yrs of my life on this disk.", "author_fullname": "t2_afmkspn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n1ii2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674867676.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674867025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a problem. My HDD somehow disconnected itself while defragmentation and now it shows up as RAW, is there any way to convert it to NTFS without losing data and folder structure? It\u2019s very important because there is 15yrs of my life on this disk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n1ii2", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Ad-9304", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n1ii2/data_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n1ii2/data_recovery/", "subreddit_subscribers": 667590, "created_utc": 1674867025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, apologies if this ends up being simple but this is slightly outside my normal IT wheelhouse. I am currently in the process of upgrading my company's public computer lab from HDD's to SSD's and soon I will have roughly \\~25 1Tb HDD's that will not be in use anymore. My idea is to create a file server since we don't currently have one and it could be very useful to us. It doesn't have to be anything particularly fancy we just want to be able to share and access files from within the building. So my question is, what is the easiest way to go about doing so? I haven't messed around with RAID configurations since college and that's been well over a decade ago so I'm a little rusty. I've seen a few articles about ZFS but I wanted to get some actual opinions as opposed to just doing the first thing a website says. The other issue is, how do I store and power that many drives? Any help is appreciated.", "author_fullname": "t2_15efey1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating Network File Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mxk8a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674857197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, apologies if this ends up being simple but this is slightly outside my normal IT wheelhouse. I am currently in the process of upgrading my company&amp;#39;s public computer lab from HDD&amp;#39;s to SSD&amp;#39;s and soon I will have roughly ~25 1Tb HDD&amp;#39;s that will not be in use anymore. My idea is to create a file server since we don&amp;#39;t currently have one and it could be very useful to us. It doesn&amp;#39;t have to be anything particularly fancy we just want to be able to share and access files from within the building. So my question is, what is the easiest way to go about doing so? I haven&amp;#39;t messed around with RAID configurations since college and that&amp;#39;s been well over a decade ago so I&amp;#39;m a little rusty. I&amp;#39;ve seen a few articles about ZFS but I wanted to get some actual opinions as opposed to just doing the first thing a website says. The other issue is, how do I store and power that many drives? Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mxk8a", "is_robot_indexable": true, "report_reasons": null, "author": "Jbales8990", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/", "subreddit_subscribers": 667590, "created_utc": 1674857197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone!  \nI am creating a loooong term archive using DVDs and Blu Rays.\n\n(I use my external drives and NAS for my current stuff but some of it has to be archived elsewhere and I got tired of replacing crashing hard drives every year or two)\n\nSo, the question is:  \nWhat is the best way to store them to make them last longer?\n\nAre plastic sleeves ok? Or should I get the rigid thin boxes? Could I simply burn them and put them back in the \"tower\" boxes? (spindle?) etc.\n\nNOTE:  Once they are in the correct case, they will go to an Archival Cabinet (fireproof and waterproof) with oxygen and humidity absorbers along with some other Archival stuff I have there.", "author_fullname": "t2_dindecgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ways to store DISCS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mwrud", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674855290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;br/&gt;\nI am creating a loooong term archive using DVDs and Blu Rays.&lt;/p&gt;\n\n&lt;p&gt;(I use my external drives and NAS for my current stuff but some of it has to be archived elsewhere and I got tired of replacing crashing hard drives every year or two)&lt;/p&gt;\n\n&lt;p&gt;So, the question is:&lt;br/&gt;\nWhat is the best way to store them to make them last longer?&lt;/p&gt;\n\n&lt;p&gt;Are plastic sleeves ok? Or should I get the rigid thin boxes? Could I simply burn them and put them back in the &amp;quot;tower&amp;quot; boxes? (spindle?) etc.&lt;/p&gt;\n\n&lt;p&gt;NOTE:  Once they are in the correct case, they will go to an Archival Cabinet (fireproof and waterproof) with oxygen and humidity absorbers along with some other Archival stuff I have there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mwrud", "is_robot_indexable": true, "report_reasons": null, "author": "arscorvinus", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mwrud/best_ways_to_store_discs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mwrud/best_ways_to_store_discs/", "subreddit_subscribers": 667590, "created_utc": 1674855290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Right now I'm all spinning rust on my NAS, but I'd like to upgrade to something a little peppier for my OS since my remote VNC sessions can be a little slow at times, especially Firefox.\n\nSo my bright idea was to get a dual-M.2 PCIE card for like $20-30 (or two cards, whatever), put two small SSDs on it/them in RAID1, and use those for my OS partitions. Then I can use my spinning rust just for data partitions.\n\nNAS is an Intel i7 2600k w/12GB RAM running Ubuntu 20.04, Plex, pyMedusa, NZBget, OpenVPN, MergerFS, and SnapRaid, with 3x8TB drives. I could probably use some more RAM too.", "author_fullname": "t2_52am0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS question. Is this a good idea? Dual NVMe SSDs in RAID1 as OS drive(s).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvq8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674852760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now I&amp;#39;m all spinning rust on my NAS, but I&amp;#39;d like to upgrade to something a little peppier for my OS since my remote VNC sessions can be a little slow at times, especially Firefox.&lt;/p&gt;\n\n&lt;p&gt;So my bright idea was to get a dual-M.2 PCIE card for like $20-30 (or two cards, whatever), put two small SSDs on it/them in RAID1, and use those for my OS partitions. Then I can use my spinning rust just for data partitions.&lt;/p&gt;\n\n&lt;p&gt;NAS is an Intel i7 2600k w/12GB RAM running Ubuntu 20.04, Plex, pyMedusa, NZBget, OpenVPN, MergerFS, and SnapRaid, with 3x8TB drives. I could probably use some more RAM too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvq8s", "is_robot_indexable": true, "report_reasons": null, "author": "KungFuHamster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvq8s/nas_question_is_this_a_good_idea_dual_nvme_ssds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvq8s/nas_question_is_this_a_good_idea_dual_nvme_ssds/", "subreddit_subscribers": 667590, "created_utc": 1674852760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys I have a problem. I just bought a WD RED PLUS 6TB and put it inside an external UGREEN box. The problem is that I noticed that if i dont use the hd, after a while it goes idle (i guess its idle), infact if i try to access it, it takes few seconds, and the start/stop count value in smart goes up.\n\nFrom what I know, its better to leave an hd always on, than spin on/off several times a day, so i was wondering, how do i make it so it doesnt go idle?\n\nI'm not sure if it's the HD itself or the UGREEN external box doing it to be honest, any idea what to check to get this fixed? Thank you!", "author_fullname": "t2_36427z1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set idle time in WD RED PLUS inside UGREEN external box", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvix0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674852253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys I have a problem. I just bought a WD RED PLUS 6TB and put it inside an external UGREEN box. The problem is that I noticed that if i dont use the hd, after a while it goes idle (i guess its idle), infact if i try to access it, it takes few seconds, and the start/stop count value in smart goes up.&lt;/p&gt;\n\n&lt;p&gt;From what I know, its better to leave an hd always on, than spin on/off several times a day, so i was wondering, how do i make it so it doesnt go idle?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if it&amp;#39;s the HD itself or the UGREEN external box doing it to be honest, any idea what to check to get this fixed? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvix0", "is_robot_indexable": true, "report_reasons": null, "author": "tharghans", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvix0/how_to_set_idle_time_in_wd_red_plus_inside_ugreen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvix0/how_to_set_idle_time_in_wd_red_plus_inside_ugreen/", "subreddit_subscribers": 667590, "created_utc": 1674852253.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}