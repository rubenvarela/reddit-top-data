{"kind": "Listing", "data": {"after": "t3_10mvix0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://twitter.com/HaloCEmaps/status/1614854187300552705\n\nThe Halomaps forums have tons of information on Halo Custom edition and Halo 2V modding, as well as tons of images and videos of mods and custom content that wasn't ever publicly released outside of those previews. It'd be an enormous blow if all of it was lost.\n\nI don't know enough about archiving websites to help out here (I'd love to learn, but not in the short timespan this requires), so I'm hoping people here can figure something out, I'm also gonna make a post on /r/Halo and will update the post here with a link when I do.\n\nI know @haloman30 on twitter is doing some archiving, but I don't know how complete it would be, so reaching out to them might be fruitful too.", "author_fullname": "t2_5cvxk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Halomaps, which has been the main hub for Halo modding content for almost 20 years, is having it's forums shut down on Feb 1st. A massive amount of content will be lost if it's not archived.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mswav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 462, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 462, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674846032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://twitter.com/HaloCEmaps/status/1614854187300552705\"&gt;https://twitter.com/HaloCEmaps/status/1614854187300552705&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Halomaps forums have tons of information on Halo Custom edition and Halo 2V modding, as well as tons of images and videos of mods and custom content that wasn&amp;#39;t ever publicly released outside of those previews. It&amp;#39;d be an enormous blow if all of it was lost.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know enough about archiving websites to help out here (I&amp;#39;d love to learn, but not in the short timespan this requires), so I&amp;#39;m hoping people here can figure something out, I&amp;#39;m also gonna make a post on &lt;a href=\"/r/Halo\"&gt;/r/Halo&lt;/a&gt; and will update the post here with a link when I do.&lt;/p&gt;\n\n&lt;p&gt;I know @haloman30 on twitter is doing some archiving, but I don&amp;#39;t know how complete it would be, so reaching out to them might be fruitful too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mswav", "is_robot_indexable": true, "report_reasons": null, "author": "jabberwockxeno", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mswav/halomaps_which_has_been_the_main_hub_for_halo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mswav/halomaps_which_has_been_the_main_hub_for_halo/", "subreddit_subscribers": 667565, "created_utc": 1674846032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So recently YouTube made some more changes to their rules and they seem to be retroactively applying them and striking channels. As of now this is mostly an issue with the 2A/Firearms communities of YouTube but I'm sure this will be affecting all channels breaking any of the new rules and old one, this is just another wave  content crackdown.\n\nI'm not sure how many of you saw, but [Garand Thumb got a content strike](https://twitter.com/GarandThumb1/status/1618748298550190083?t=HIExkVleJ258UaSlsNLWOw&amp;s=19) thanks to YouTube new policies on an old video, this means they are retroactively applying this and all of the firearms channels on YouTube are in danger of disappearing soon if they strike 3 videos, content creators will also be having to go through their backlog and remove videos that might be in violation of these new rules. \n\nI honestly think the ultimate goal in this new \"no showing assembly or disassembly of a firearm\" rule is to limit the information on the internet about caring for and maintaining firearms. If they ever do manage to destroy our 2A rights and attempt a gun grab, the weapons that manage to be stashed away will need to be well kept up and that why they're removing the info now, to damage the chances of future generations. Even if it is for a less ominous reason, we're still in danger of losing hours of entertainment and memories from our favorite creators.\n\nOur best way to fight this is kick into archival mode. We need to start downloading every video we care about especially anything involving the essentials like firearms basics, training, shooting tips, cleaning, maintainance, safety etc. I'm doing what I can to backup all the videos as well as their descriptions and the comments section so any useful information is saved, but I feel like I'm kinda overwhelmed and ill prepared for a backup task like this. I'm going to see what I can do about storage and how many channels I can back up. Now's where you guys come in!\n\n\n\n**If you want to help archive channels, here's the easiest way**\n\nI looked around for hours and the information on how to archive channels is very difficult to understand and near impossible to setup however I finally found a workaround and that's what I'm here to share with you! The most efficient and effective program I've found is [TarTube](https://tartube.sourceforge.io/) this application is an installer and GUI for the very popular yt-dlp and ffmpeg combo to download batch videos from YouTube. The only problem I found with those programs is because they run through command line it was basically impossible for me to get it to work, however TarTube takes care of all the setup and gets rid of the need for knowing command line prompts and replaces it with a relatively slick GUI. I'm going to break down the steps as quickly and easily as I can for anyome interested in helping preserve this Era of YouTube that may be coming to a close. \n\n\n**Step 1.** [Download the TarTube installer for your specific OS](https://tartube.sourceforge.io/#downloads)\n\n\n**Step 2.** Follow the on screen instructions for installing yt-dlp ffmpeg and the TarTube GUI program, it's relatively simple, you might need to run as admin depending on your settings.\n\n\n**Step 3.** (possibly optional) Give your PC a reboot to make sure the new files are installed in the system and will run properly. \n\n\n**Step 4.** Open Tar Tube and click on the \"Classic Mode\" tab that's 3 tabs in on the 3rd menu column \n\n\n**Step 5.** Select \"Edit\" from the main menu in the top left corner of the screen, then select \"General Download Preferences\"\n\n\n**Step 6.** Select the \"Post Processing\" tab then select \"Audio quality of the post processed file\" Change it from \"Medium VBR\" to 320kbps or 256kbps, 1080p YouTube videos have their audio tracks limited to 256kbps but by selecting 320kbps you're insuring that the rip maintains the highest possible quality even though your not upconverting it or anything. Select \"Okay\" and you should be back in the \"Classic Mode\" tab. Nows where we get rolling. \n\n\n**Step 7.** Grab the URL of the video or playlist you want to download from the web and paste it into the \"Enter URLs Below Box\"\n\n\n**Step 8.** Select the destination you want the videos to download to on your storage. Then click the \"Add URLs\" button to the right.\n\n\n**Step 9.** Select \"Download All\" in the bottom right corner and let the program work its magic.\n\nSo far I've ripped 3 playlist and am working on a whole channel now, the time has varied between 5 to 30 minutes but I'm on a decent speed connection. This is definitely a community job so if you have the storage and the free time help preserve the content we have today for future generations.", "author_fullname": "t2_5369s5y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easily Archive YouTube Channels and Videos - Classic YouTube videos in Danger after new rule changes. We need to start archiving our favorite content.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n0t7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674865187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So recently YouTube made some more changes to their rules and they seem to be retroactively applying them and striking channels. As of now this is mostly an issue with the 2A/Firearms communities of YouTube but I&amp;#39;m sure this will be affecting all channels breaking any of the new rules and old one, this is just another wave  content crackdown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure how many of you saw, but &lt;a href=\"https://twitter.com/GarandThumb1/status/1618748298550190083?t=HIExkVleJ258UaSlsNLWOw&amp;amp;s=19\"&gt;Garand Thumb got a content strike&lt;/a&gt; thanks to YouTube new policies on an old video, this means they are retroactively applying this and all of the firearms channels on YouTube are in danger of disappearing soon if they strike 3 videos, content creators will also be having to go through their backlog and remove videos that might be in violation of these new rules. &lt;/p&gt;\n\n&lt;p&gt;I honestly think the ultimate goal in this new &amp;quot;no showing assembly or disassembly of a firearm&amp;quot; rule is to limit the information on the internet about caring for and maintaining firearms. If they ever do manage to destroy our 2A rights and attempt a gun grab, the weapons that manage to be stashed away will need to be well kept up and that why they&amp;#39;re removing the info now, to damage the chances of future generations. Even if it is for a less ominous reason, we&amp;#39;re still in danger of losing hours of entertainment and memories from our favorite creators.&lt;/p&gt;\n\n&lt;p&gt;Our best way to fight this is kick into archival mode. We need to start downloading every video we care about especially anything involving the essentials like firearms basics, training, shooting tips, cleaning, maintainance, safety etc. I&amp;#39;m doing what I can to backup all the videos as well as their descriptions and the comments section so any useful information is saved, but I feel like I&amp;#39;m kinda overwhelmed and ill prepared for a backup task like this. I&amp;#39;m going to see what I can do about storage and how many channels I can back up. Now&amp;#39;s where you guys come in!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;If you want to help archive channels, here&amp;#39;s the easiest way&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I looked around for hours and the information on how to archive channels is very difficult to understand and near impossible to setup however I finally found a workaround and that&amp;#39;s what I&amp;#39;m here to share with you! The most efficient and effective program I&amp;#39;ve found is &lt;a href=\"https://tartube.sourceforge.io/\"&gt;TarTube&lt;/a&gt; this application is an installer and GUI for the very popular yt-dlp and ffmpeg combo to download batch videos from YouTube. The only problem I found with those programs is because they run through command line it was basically impossible for me to get it to work, however TarTube takes care of all the setup and gets rid of the need for knowing command line prompts and replaces it with a relatively slick GUI. I&amp;#39;m going to break down the steps as quickly and easily as I can for anyome interested in helping preserve this Era of YouTube that may be coming to a close. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; &lt;a href=\"https://tartube.sourceforge.io/#downloads\"&gt;Download the TarTube installer for your specific OS&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Follow the on screen instructions for installing yt-dlp ffmpeg and the TarTube GUI program, it&amp;#39;s relatively simple, you might need to run as admin depending on your settings.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; (possibly optional) Give your PC a reboot to make sure the new files are installed in the system and will run properly. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Open Tar Tube and click on the &amp;quot;Classic Mode&amp;quot; tab that&amp;#39;s 3 tabs in on the 3rd menu column &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Select &amp;quot;Edit&amp;quot; from the main menu in the top left corner of the screen, then select &amp;quot;General Download Preferences&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 6.&lt;/strong&gt; Select the &amp;quot;Post Processing&amp;quot; tab then select &amp;quot;Audio quality of the post processed file&amp;quot; Change it from &amp;quot;Medium VBR&amp;quot; to 320kbps or 256kbps, 1080p YouTube videos have their audio tracks limited to 256kbps but by selecting 320kbps you&amp;#39;re insuring that the rip maintains the highest possible quality even though your not upconverting it or anything. Select &amp;quot;Okay&amp;quot; and you should be back in the &amp;quot;Classic Mode&amp;quot; tab. Nows where we get rolling. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 7.&lt;/strong&gt; Grab the URL of the video or playlist you want to download from the web and paste it into the &amp;quot;Enter URLs Below Box&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 8.&lt;/strong&gt; Select the destination you want the videos to download to on your storage. Then click the &amp;quot;Add URLs&amp;quot; button to the right.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 9.&lt;/strong&gt; Select &amp;quot;Download All&amp;quot; in the bottom right corner and let the program work its magic.&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve ripped 3 playlist and am working on a whole channel now, the time has varied between 5 to 30 minutes but I&amp;#39;m on a decent speed connection. This is definitely a community job so if you have the storage and the free time help preserve the content we have today for future generations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?auto=webp&amp;v=enabled&amp;s=2fe2a8dce2671e8124f092fce8dbd6b1d12552de", "width": 1284, "height": 1848}, "resolutions": [{"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8bec4ed2cde3782afca32f298921e6bd4a782035", "width": 108, "height": 155}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75b6edb44cdeb7b77ed6759b8f83044931688f53", "width": 216, "height": 310}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b468ad32242e1a500d7d9cd0268151bb6229d106", "width": 320, "height": 460}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36267f65375dc45657ed6523c5f53c2a5dd709d7", "width": 640, "height": 921}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21a308de6c128c48d87576a38b9a5279fa621b74", "width": 960, "height": 1381}, {"url": "https://external-preview.redd.it/2z_7Tdo-C7dEl6NDRKxwUJtSNDDtuZe4R5OqI4r7ldw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=839bbf45a8a3285b2b74953787060ae466d31e02", "width": 1080, "height": 1554}], "variants": {}, "id": "lLG9etVZmm_azac4y65McnTDTawlJWOxp4is6zpk7kE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n0t7i", "is_robot_indexable": true, "report_reasons": null, "author": "DepressMyCNS", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/", "subreddit_subscribers": 667565, "created_utc": 1674865187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026", "author_fullname": "t2_2ks4hmij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think Seagate's HDD's will get to 50 TB by 2026 and 100 TB by 2030? Seagate thinks so.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mycpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674859128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026\"&gt;https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?auto=webp&amp;v=enabled&amp;s=9a866a9e666cb9b470144479b0ce80147ef6328c", "width": 708, "height": 403}, "resolutions": [{"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1125652338a094bda8ddb98629cb27bc56ca619e", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c825f0157b25486c48a43f765db7ac51fd70f5f1", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58ad253f01ca168c83b151a9581992675fd9e6dc", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/wR0MEVtmFMyWfxpFRjA1WC6OHTcDme_Z1IGkG6hAUvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13994f48412f5fc6a1b30e84dd626c2abc102d9b", "width": 640, "height": 364}], "variants": {}, "id": "xVFfmPtPmKPtrhKVVnMqwcuh4W-FVt4VbZZAlJLJcaI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mycpv", "is_robot_indexable": true, "report_reasons": null, "author": "jasonbaker125", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/", "subreddit_subscribers": 667565, "created_utc": 1674859128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_vlzdmewf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BBC Modi Documentary Removal - Internet Archive Blogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n7b7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674884062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/01/27/bbc-modi-documentary-removal/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n7b7t", "is_robot_indexable": true, "report_reasons": null, "author": "m8wt", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n7b7t/bbc_modi_documentary_removal_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.archive.org/2023/01/27/bbc-modi-documentary-removal/", "subreddit_subscribers": 667565, "created_utc": 1674884062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mich90l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found 2 of these in an old NAS machine, if they work would these be good to use for my server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10mx37y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/GTERfq0rZiZgmsLAXrzIXqm150-Pq03SrpVhxwMqJo4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674856056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/97ekw77fpnea1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?auto=webp&amp;v=enabled&amp;s=6b6a3f16857913476227a7688ad2ac391488d68f", "width": 2268, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84b4542bc688882c9bee9068c7f2a27d3a14c933", "width": 108, "height": 192}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9881179c665853d5d04c095eba6871ee61c6e2d", "width": 216, "height": 384}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d840c176bbe8293b4a0f15e264da0b307e96fc0", "width": 320, "height": 568}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19b88933b1779a696bc1aa0e27fbf07668d27bd4", "width": 640, "height": 1137}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe0aa0056e23ae108565a2cb82f3133094a1dafb", "width": 960, "height": 1706}, {"url": "https://preview.redd.it/97ekw77fpnea1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89748e18dffa6dd41dab8c9a0b44c60089ef7af2", "width": 1080, "height": 1920}], "variants": {}, "id": "qYpiJZbdEtR_ckv7m4qsJW_JRres1akYvRm7E5JCTCI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mx37y", "is_robot_indexable": true, "report_reasons": null, "author": "candroid_man", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mx37y/found_2_of_these_in_an_old_nas_machine_if_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/97ekw77fpnea1.jpg", "subreddit_subscribers": 667565, "created_utc": 1674856056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3payq0va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Popular Pirate Website Sci-Hub .Se Is Banned Now", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10mqrb8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NsKOHNYbmkXvmeg1EsKC7fD4DmT-BjOZaJMOtOvpnEo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674840977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theinsaneapp.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theinsaneapp.com/2023/01/scihub-banned.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?auto=webp&amp;v=enabled&amp;s=be6d4ccf75e4b81705bdb0ab8b8c1b5c2cf56a74", "width": 1280, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a53eed088a238ce0d87f517464cacf22a5c9e115", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eef45d720970b40d72ede8b54dcbfb6e4710b68a", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d932f0da93bc64e8abe5b615b4752d2b8510e5a7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3439843fed7cc4d0fd20cab1462c5b6e301f539c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b013af7d032f2544e943d38271c116fe930b62e5", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b68bbbf1e352d9ba2a86c1e3f638d389f5ccf88a", "width": 1080, "height": 607}], "variants": {}, "id": "0lJB0sF4z77fBtx50vQuZraLr3ptJiSUb7qDqSxo0QY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mqrb8", "is_robot_indexable": true, "report_reasons": null, "author": "vadhavaniyafaijan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mqrb8/popular_pirate_website_scihub_se_is_banned_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theinsaneapp.com/2023/01/scihub-banned.html", "subreddit_subscribers": 667565, "created_utc": 1674840977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure many have observed that High-capacity Blu-ray still represents a cost effective medium, if only someone would make a 2 meter stack of them and 'tap' the hole/lumen down the middle so that a threaded pole could be 'screwed' in from each end to a set point, to retract the undesired discs away from the desired disc, and allow it to be removed for data retrieval. Or a carousel; I'm not fussy.\n\nAnyway if I understand correctly, back in 2013, [Abbe](https://en.wikipedia.org/wiki/Ernst_Abbe)'s limit was circumvented (lay article [here](https://theconversation.com/more-data-storage-heres-how-to-fit-1-000-terabytes-on-a-dvd-15306), and the paper in Nature Communications [here](https://www.nature.com/articles/ncomms3061)), and the 500nm 'smallest defect' became 9nm. There was now only the matter of finding a physical medium that could reliably hold such fine etchings.\n\nWell, I'm here to moan about it. I've been waiting aaaaages. Where're my petabyte DVDs?? I figure if anyone knows the answer, they probably check in with this hive mind occasionally...", "author_fullname": "t2_92dedrzo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where are my 1000TB DVDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10negvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674910663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure many have observed that High-capacity Blu-ray still represents a cost effective medium, if only someone would make a 2 meter stack of them and &amp;#39;tap&amp;#39; the hole/lumen down the middle so that a threaded pole could be &amp;#39;screwed&amp;#39; in from each end to a set point, to retract the undesired discs away from the desired disc, and allow it to be removed for data retrieval. Or a carousel; I&amp;#39;m not fussy.&lt;/p&gt;\n\n&lt;p&gt;Anyway if I understand correctly, back in 2013, &lt;a href=\"https://en.wikipedia.org/wiki/Ernst_Abbe\"&gt;Abbe&lt;/a&gt;&amp;#39;s limit was circumvented (lay article &lt;a href=\"https://theconversation.com/more-data-storage-heres-how-to-fit-1-000-terabytes-on-a-dvd-15306\"&gt;here&lt;/a&gt;, and the paper in Nature Communications &lt;a href=\"https://www.nature.com/articles/ncomms3061\"&gt;here&lt;/a&gt;), and the 500nm &amp;#39;smallest defect&amp;#39; became 9nm. There was now only the matter of finding a physical medium that could reliably hold such fine etchings.&lt;/p&gt;\n\n&lt;p&gt;Well, I&amp;#39;m here to moan about it. I&amp;#39;ve been waiting aaaaages. Where&amp;#39;re my petabyte DVDs?? I figure if anyone knows the answer, they probably check in with this hive mind occasionally...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?auto=webp&amp;v=enabled&amp;s=921f5aa8e880e95aba7d78d056e2e71712718f89", "width": 220, "height": 283}, "resolutions": [{"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0f0efa37fbdc98dd0d0d5650f9ee8c14352551e", "width": 108, "height": 138}, {"url": "https://external-preview.redd.it/T16ecf3tCzQRu4BVwtejIUCASEhDULVT8wsXo9NxvDY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d86b18bdd3f7f5e01af172eda13c182f172f3798", "width": 216, "height": 277}], "variants": {}, "id": "Hb8orkMr0s300pO9A1UwvFLeGs4I1Cq2gd3qkqXY-Oc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10negvg", "is_robot_indexable": true, "report_reasons": null, "author": "rackhamlerouge9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/", "subreddit_subscribers": 667565, "created_utc": 1674910663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Created a script to use when moving large amounts of data between folders/servers and wanting to skip \\`Force Recheck\\` inside the torrent client.  \nYou just point it to your rTorrent \\`session\\` folder, specify the path to change and the new path and it'll replace all session data.\n\nFor example, when moving torrents from \\`/downloads/Temp\\` to \\`/downloads/Movies\\` you can use this script like so:\n\n    python torrent-mover.py --src /downloads/Temp/ --dst /downloads/Movies/ /config/rTorrent/session\n\nCurrently, it supports rTorrent only!\n\n[https://github.com/uraid/torrent-mover](https://github.com/uraid/torrent-mover)", "author_fullname": "t2_143yl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change the path for downloaded torrents without force recheck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ne0q5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674911788.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674909133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Created a script to use when moving large amounts of data between folders/servers and wanting to skip `Force Recheck` inside the torrent client.&lt;br/&gt;\nYou just point it to your rTorrent `session` folder, specify the path to change and the new path and it&amp;#39;ll replace all session data.&lt;/p&gt;\n\n&lt;p&gt;For example, when moving torrents from `/downloads/Temp` to `/downloads/Movies` you can use this script like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;python torrent-mover.py --src /downloads/Temp/ --dst /downloads/Movies/ /config/rTorrent/session\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Currently, it supports rTorrent only!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/uraid/torrent-mover\"&gt;https://github.com/uraid/torrent-mover&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?auto=webp&amp;v=enabled&amp;s=51b85ba3f64987861bd549f08ab8c8ac17a474af", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d119c95f59a80509e216817e519cd55a3c1e6ec5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa8fc2fe45076ce98033b3b5b6b86a51683d300a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb79c7da38a5d82f6ff57c265df3199ebe8eac22", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=68e09c426f33abfcdc66b09e25f5bcc2be26df38", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74b3b3f11e5ee0d76c9452368c28862776d653de", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Eqpx4dGJNdFurAW8D0xhmAz1ZAYkHyh8HDdDFU6aKTE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=632d10fb2755c892f973cd7611e848bb00b4b6fb", "width": 1080, "height": 540}], "variants": {}, "id": "IajE0zginlUFd7b6rlGhJLHs6Ojv0vv6JXrwVj0x30k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "59TB RAID6 | 43TB Usable", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ne0q5", "is_robot_indexable": true, "report_reasons": null, "author": "n0llbyte", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/", "subreddit_subscribers": 667565, "created_utc": 1674909133.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mwnmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674855010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10mwnmn", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/", "subreddit_subscribers": 667565, "created_utc": 1674855010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.irs.gov/individuals](https://www.irs.gov/individuals)\n\nI would like to keep offline tax &amp; tax related documents. What medium do you use and how long do you keep your documents?", "author_fullname": "t2_13yzwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need To Store Tax &amp; Tax Related Documents. Suggestions Given The IRS Guidance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mlkth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674828181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.irs.gov/individuals\"&gt;https://www.irs.gov/individuals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I would like to keep offline tax &amp;amp; tax related documents. What medium do you use and how long do you keep your documents?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mlkth", "is_robot_indexable": true, "report_reasons": null, "author": "m8r-jfqbw21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mlkth/need_to_store_tax_tax_related_documents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mlkth/need_to_store_tax_tax_related_documents/", "subreddit_subscribers": 667565, "created_utc": 1674828181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran DoD short on 5x 8tb disks prior to selling them. They had been running in my server for around 25-35k hours without errors, SMART OK. Now I get feedback from my first customer saying it\u2019s not working at all. Not recognized/errors. Did DoD short kill them?\n\nI did not run any tests after DoD. But it finished without errors.", "author_fullname": "t2_1gdbm4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for DBAN to destroy an HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ndn27", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674907807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran DoD short on 5x 8tb disks prior to selling them. They had been running in my server for around 25-35k hours without errors, SMART OK. Now I get feedback from my first customer saying it\u2019s not working at all. Not recognized/errors. Did DoD short kill them?&lt;/p&gt;\n\n&lt;p&gt;I did not run any tests after DoD. But it finished without errors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ndn27", "is_robot_indexable": true, "report_reasons": null, "author": "PessimisticHoarder", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/", "subreddit_subscribers": 667565, "created_utc": 1674907807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Did someone manage to get a hold of Blindy.tv streams library before it got shut down few years ago? I just learned how great content it hosted - turning tv shows like Star Trek to audio episodes with additional commentary for the blind, which make it great for in car listening.", "author_fullname": "t2_iik18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blindy.tv anyone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ncg5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674903277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did someone manage to get a hold of Blindy.tv streams library before it got shut down few years ago? I just learned how great content it hosted - turning tv shows like Star Trek to audio episodes with additional commentary for the blind, which make it great for in car listening.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ncg5h", "is_robot_indexable": true, "report_reasons": null, "author": "kanczug", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ncg5h/blindytv_anyone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ncg5h/blindytv_anyone/", "subreddit_subscribers": 667565, "created_utc": 1674903277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any thoughts on this drive?  It's currently steeply discounted at Best Buy and Amazon for $240.  Was thinking of picking one up just for some extra storage (in addition to my 20TB of HDD).", "author_fullname": "t2_qs1nsow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial X8 4TB external SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n2ngy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674870053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any thoughts on this drive?  It&amp;#39;s currently steeply discounted at Best Buy and Amazon for $240.  Was thinking of picking one up just for some extra storage (in addition to my 20TB of HDD).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n2ngy", "is_robot_indexable": true, "report_reasons": null, "author": "LazarusLong67", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/", "subreddit_subscribers": 667565, "created_utc": 1674870053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nI have written firmware files for an old phone of mine onto a (albeit bargain bin) BD R a couple of months ago and the drive is refusing to read the disc, I looked at the surface and the ring near the center has white dots in the dye, almost as if the drive skipped a few bits of data while writing. ddrescue says media is not present and the drive stops reading after a few seconds\n\n\nI tossed the whole spindle after I got a few bad burns. I'll shell out for the more expensive Philips discs when I need them", "author_fullname": "t2_yi08dfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to recover data off of a BD R that's burnt with white \"spots\" on the surface?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvaoc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674851685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I have written firmware files for an old phone of mine onto a (albeit bargain bin) BD R a couple of months ago and the drive is refusing to read the disc, I looked at the surface and the ring near the center has white dots in the dye, almost as if the drive skipped a few bits of data while writing. ddrescue says media is not present and the drive stops reading after a few seconds&lt;/p&gt;\n\n&lt;p&gt;I tossed the whole spindle after I got a few bad burns. I&amp;#39;ll shell out for the more expensive Philips discs when I need them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvaoc", "is_robot_indexable": true, "report_reasons": null, "author": "Logan_MacGyver", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvaoc/is_there_any_way_to_recover_data_off_of_a_bd_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvaoc/is_there_any_way_to_recover_data_off_of_a_bd_r/", "subreddit_subscribers": 667565, "created_utc": 1674851685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My current NAS is based on a whitebox I built specifically to store data, do some filesharing via Bittorrent, and back up data to external drives.  The system is built on a motherboard using a Pentium G3220 with 8GB of RAM.  I also have a LSI 9207-8i HBA flashed for IT mode.  I have been running various versions of OpenMediaVault for the whole time.  My primary storage is a pair of 2TB SATA drives in RAID1.  I have another array of 8 1TB drives in RAID5 for temporary storage.  Both are based on MDADM which has worked well for me as I could easily transition arrays as need be during OS upgrades.  This has worked fairly well for some time.  The caveat is that the CPU will peg during heavy file transfer operations like backups.  The other issue is that all of these drives are 10 years old now and are at the end of their life.  Finally this serves ISOs for my ESXi hosts.  I basically can only do one thing at a time with this server due to I/O constraints.\n\nI would like to consolidate this into something that can do more than just serve files and Bittorrent.  I have acquired a new server which I think will work for this.  It is a HPE DL160 G9 LFF with 64GB of RAM installed.  The server has 4 3.5\" SATA bays which are connected to the server's RAID card which is in SATA mode.  I have a PCI-E card which has 2 SATA NVME m.2 slots with 2 512GB drives and 1 PCI-E m.2 slot for boot / scratch space.  This server consumes much less power than the other servers in my rack so I am thinking it would work well for this need.  I'm looking at 4x 8TB Seagate IronWolf drives right now.  The final bit is the OS.  I'm looking at either TrueNAS or Unraid.  OMV uses MDADM which is okay, but RAID5 is not great and RAID60 would probably be inefficient for 4 drives.\n\nWhich NAS OS would you recommend and why?  Does the choice really boil down to ZFS vs no ZFS?  I have only used TrueNAS in my lab and have never used Unraid before so I'm not sure how well either works long term.  Any guidance would be appreciated!", "author_fullname": "t2_kclds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS redesign guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mlof2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674828446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current NAS is based on a whitebox I built specifically to store data, do some filesharing via Bittorrent, and back up data to external drives.  The system is built on a motherboard using a Pentium G3220 with 8GB of RAM.  I also have a LSI 9207-8i HBA flashed for IT mode.  I have been running various versions of OpenMediaVault for the whole time.  My primary storage is a pair of 2TB SATA drives in RAID1.  I have another array of 8 1TB drives in RAID5 for temporary storage.  Both are based on MDADM which has worked well for me as I could easily transition arrays as need be during OS upgrades.  This has worked fairly well for some time.  The caveat is that the CPU will peg during heavy file transfer operations like backups.  The other issue is that all of these drives are 10 years old now and are at the end of their life.  Finally this serves ISOs for my ESXi hosts.  I basically can only do one thing at a time with this server due to I/O constraints.&lt;/p&gt;\n\n&lt;p&gt;I would like to consolidate this into something that can do more than just serve files and Bittorrent.  I have acquired a new server which I think will work for this.  It is a HPE DL160 G9 LFF with 64GB of RAM installed.  The server has 4 3.5&amp;quot; SATA bays which are connected to the server&amp;#39;s RAID card which is in SATA mode.  I have a PCI-E card which has 2 SATA NVME m.2 slots with 2 512GB drives and 1 PCI-E m.2 slot for boot / scratch space.  This server consumes much less power than the other servers in my rack so I am thinking it would work well for this need.  I&amp;#39;m looking at 4x 8TB Seagate IronWolf drives right now.  The final bit is the OS.  I&amp;#39;m looking at either TrueNAS or Unraid.  OMV uses MDADM which is okay, but RAID5 is not great and RAID60 would probably be inefficient for 4 drives.&lt;/p&gt;\n\n&lt;p&gt;Which NAS OS would you recommend and why?  Does the choice really boil down to ZFS vs no ZFS?  I have only used TrueNAS in my lab and have never used Unraid before so I&amp;#39;m not sure how well either works long term.  Any guidance would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mlof2", "is_robot_indexable": true, "report_reasons": null, "author": "Sintaxia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mlof2/nas_redesign_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mlof2/nas_redesign_guidance/", "subreddit_subscribers": 667565, "created_utc": 1674828446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "DVD recorder - Magnavox MSR90D2.  Every Time I hit the record button it just records static. I've tried video in via VHS player and ive tried video in via a coax antenna and no matter what all I get is static when i I hit record  . I don't have the remote so I go to menu", "author_fullname": "t2_73xuvz9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "whats going wrong VHS to dvd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n2sle", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674870450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DVD recorder - Magnavox MSR90D2.  Every Time I hit the record button it just records static. I&amp;#39;ve tried video in via VHS player and ive tried video in via a coax antenna and no matter what all I get is static when i I hit record  . I don&amp;#39;t have the remote so I go to menu&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n2sle", "is_robot_indexable": true, "report_reasons": null, "author": "Theoneandonlyjustin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n2sle/whats_going_wrong_vhs_to_dvd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n2sle/whats_going_wrong_vhs_to_dvd/", "subreddit_subscribers": 667565, "created_utc": 1674870450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have a problem. My HDD somehow disconnected itself while defragmentation and now it shows up as RAW, is there any way to convert it to NTFS without losing data and folder structure? It\u2019s very important because there is 15yrs of my life on this disk.", "author_fullname": "t2_afmkspn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data recovery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10n1ii2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674867676.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674867025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a problem. My HDD somehow disconnected itself while defragmentation and now it shows up as RAW, is there any way to convert it to NTFS without losing data and folder structure? It\u2019s very important because there is 15yrs of my life on this disk.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10n1ii2", "is_robot_indexable": true, "report_reasons": null, "author": "Beautiful-Ad-9304", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10n1ii2/data_recovery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10n1ii2/data_recovery/", "subreddit_subscribers": 667565, "created_utc": 1674867025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to be able to keep libvirt qcow2 virtual machine images synced via a cloud provider, encrypted, and synced incrementally so that if I will not have re-upload an entire 30/40GB virtual image just because I logged into a VM and made a very small change.\n\nA koofr dev has stated they had to choose zero knowledge encryption which apparently cannot work with incremental sync. If I were roling my own encryption with rclone perhaps there is a workaround. I read about restic but it seems to be for backup rather than sync.\n\nI have been using Cryptomator with Insync on GDrive for general cloud use but I would like to try rclone on a new provider and I am considering filen and koofr at the moment.\n\nIs client-side encrypted incremental sync possible, and if so can it work with those two providers or should I consider another?", "author_fullname": "t2_p61cyzvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental/block-level client-side encrypted sync of large files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mz8go", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674861316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to be able to keep libvirt qcow2 virtual machine images synced via a cloud provider, encrypted, and synced incrementally so that if I will not have re-upload an entire 30/40GB virtual image just because I logged into a VM and made a very small change.&lt;/p&gt;\n\n&lt;p&gt;A koofr dev has stated they had to choose zero knowledge encryption which apparently cannot work with incremental sync. If I were roling my own encryption with rclone perhaps there is a workaround. I read about restic but it seems to be for backup rather than sync.&lt;/p&gt;\n\n&lt;p&gt;I have been using Cryptomator with Insync on GDrive for general cloud use but I would like to try rclone on a new provider and I am considering filen and koofr at the moment.&lt;/p&gt;\n\n&lt;p&gt;Is client-side encrypted incremental sync possible, and if so can it work with those two providers or should I consider another?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mz8go", "is_robot_indexable": true, "report_reasons": null, "author": "AnonymousAardvark22", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/", "subreddit_subscribers": 667565, "created_utc": 1674861316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Could anyone kindly suggest a mac program that is able to either sync two folders together or best identify what files are missing between two folders.\n\nExample\n\nI have been trying to get an exact copy of a folder I currently have, which has all of my photos in it, and just do a plain, straightforward backup. I have used a lot of programs in the past but for some reason there is a discrepancy\\\\difference of 3 files between the two folders and for the life of me I can't figure out what they are, and can't get them to sync. \n\nCarbon Copy Cloner can't find them, even SyncTime can't find them. I have even tried Compare Folders but it takes way to long to populate.\n\nAny suggestions would be very helpful", "author_fullname": "t2_d7675", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best organising\\syncing program for Mac to keep files the same", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10myt2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674860275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could anyone kindly suggest a mac program that is able to either sync two folders together or best identify what files are missing between two folders.&lt;/p&gt;\n\n&lt;p&gt;Example&lt;/p&gt;\n\n&lt;p&gt;I have been trying to get an exact copy of a folder I currently have, which has all of my photos in it, and just do a plain, straightforward backup. I have used a lot of programs in the past but for some reason there is a discrepancy\\difference of 3 files between the two folders and for the life of me I can&amp;#39;t figure out what they are, and can&amp;#39;t get them to sync. &lt;/p&gt;\n\n&lt;p&gt;Carbon Copy Cloner can&amp;#39;t find them, even SyncTime can&amp;#39;t find them. I have even tried Compare Folders but it takes way to long to populate.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions would be very helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10myt2p", "is_robot_indexable": true, "report_reasons": null, "author": "DrWho345", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/", "subreddit_subscribers": 667565, "created_utc": 1674860275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "***does anyone know what i can install on a buffalo nas? i want a media server like Emby to install but buffalo linkstations are never listed***", "author_fullname": "t2_kwu7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "buffalo linkstation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10myesc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674859269.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;does anyone know what i can install on a buffalo nas? i want a media server like Emby to install but buffalo linkstations are never listed&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10myesc", "is_robot_indexable": true, "report_reasons": null, "author": "EargasmicGiant", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10myesc/buffalo_linkstation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10myesc/buffalo_linkstation/", "subreddit_subscribers": 667565, "created_utc": 1674859269.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, apologies if this ends up being simple but this is slightly outside my normal IT wheelhouse. I am currently in the process of upgrading my company's public computer lab from HDD's to SSD's and soon I will have roughly \\~25 1Tb HDD's that will not be in use anymore. My idea is to create a file server since we don't currently have one and it could be very useful to us. It doesn't have to be anything particularly fancy we just want to be able to share and access files from within the building. So my question is, what is the easiest way to go about doing so? I haven't messed around with RAID configurations since college and that's been well over a decade ago so I'm a little rusty. I've seen a few articles about ZFS but I wanted to get some actual opinions as opposed to just doing the first thing a website says. The other issue is, how do I store and power that many drives? Any help is appreciated.", "author_fullname": "t2_15efey1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating Network File Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mxk8a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674857197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, apologies if this ends up being simple but this is slightly outside my normal IT wheelhouse. I am currently in the process of upgrading my company&amp;#39;s public computer lab from HDD&amp;#39;s to SSD&amp;#39;s and soon I will have roughly ~25 1Tb HDD&amp;#39;s that will not be in use anymore. My idea is to create a file server since we don&amp;#39;t currently have one and it could be very useful to us. It doesn&amp;#39;t have to be anything particularly fancy we just want to be able to share and access files from within the building. So my question is, what is the easiest way to go about doing so? I haven&amp;#39;t messed around with RAID configurations since college and that&amp;#39;s been well over a decade ago so I&amp;#39;m a little rusty. I&amp;#39;ve seen a few articles about ZFS but I wanted to get some actual opinions as opposed to just doing the first thing a website says. The other issue is, how do I store and power that many drives? Any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mxk8a", "is_robot_indexable": true, "report_reasons": null, "author": "Jbales8990", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/", "subreddit_subscribers": 667565, "created_utc": 1674857197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all I'm working on a data archiving project and a guide for layman's as YouTube is cracking down once again and we need as many people archiving as possible. \n\nThe program I'm using is called TarTube, it's a GUI and installer based off of yt-dlp and ffmpeg, I was successfully able to bulk download an entire playlist easily, so it's great for capturing videos but I've been digging through the setting and was unable to find a way to easily capture the descriptions and comments for each video.\n\nIf anyone can help me figure out how to configure this it will be much appreciated!", "author_fullname": "t2_5369s5y8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help capturing YouTube descriptions and comments.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mx890", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674856398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all I&amp;#39;m working on a data archiving project and a guide for layman&amp;#39;s as YouTube is cracking down once again and we need as many people archiving as possible. &lt;/p&gt;\n\n&lt;p&gt;The program I&amp;#39;m using is called TarTube, it&amp;#39;s a GUI and installer based off of yt-dlp and ffmpeg, I was successfully able to bulk download an entire playlist easily, so it&amp;#39;s great for capturing videos but I&amp;#39;ve been digging through the setting and was unable to find a way to easily capture the descriptions and comments for each video.&lt;/p&gt;\n\n&lt;p&gt;If anyone can help me figure out how to configure this it will be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "24TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mx890", "is_robot_indexable": true, "report_reasons": null, "author": "DepressMyCNS", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/", "subreddit_subscribers": 667565, "created_utc": 1674856398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been lurking on here for a while and watched lots of YouTube reviews/tutorials/guides, but still not quite certain of the best direction to take. I'm hoping to get some advice on best options for a NAS for my use case.\n\n**Context:**\n\nI work in audio &amp; video and the majority of my active projects run off 4x Crucial SSDs housed in a Blackmagic Multidock 10G. Here's a summary of my SSD setup for active projects.\n\n* 2TB MacBook Pro Internal SSD\n* 7TB across 4x Crucial MX500 SSDs \u2014 only one of the 2TB is regularly being written to.\n\nOnce completed, archived projects are migrated to various HDDs:\n\n* 6TB WD Elements (mirrored via Arq backup to a 6TB Seagate Backup Plus) \u2014 2.7TB currently free\n* 3TB Seagate Expansion\n* 1TB Toshiba (cold storage of images)\n\nA 12TB WD Elements then backs up as much of the SSD content (active) and archives as possible via Arq, but that's now full.\n\nI've got a (very cheap initial) year of 10TB iDrive for backing up priority files off-site, but this level of storage quickly becomes extremely expensive for offsite cloud-based backups.\n\n**Possible Solutions:**\n\nI was eyeing up a 20TB WD Elements for \u00a3290 but that's no longer available and I was on the fence about it as it won't slim down the total number of drives, or provide me with redundant storage if I use it exclusively. Having gone from 6 to 12TB in a few years, I'm also not confident that 20TB is going to be a long-term solution.\n\nI then started looking at Synology units, but there are a so many options and they're not cheap. Not really sure where to start...!\n\nAlthough I'm techie, I've never built my own PC. Following instructions I'm good at, though, so I don't think it's completely out of the question to do a DIY build! \ud83d\ude06 I've seen [LTT's Jonsbo N1 build](https://www.youtube.com/watch?v=boKmZKTKXHc), but sourcing that case is tricky. It comes to a similar price as some of the Synology units, but I quite like the idea of being able to do upgrades further down the line, but in terms of hardware and software.\n\nI'm not too worried about appearance. It's almost definitely going to end up out of sight.\n\n**Some preferred outcomes:**\n\n\u2611\ufe0f As low energy usage as possible (although not to the point of diminishing returns vs energy bills).  \n\u2611\ufe0f Suitable for (1) redundant data backup of archive projects not housed on active SSDs and (2) hourly/daily backups of active projects that are housed on SSDs (using Arq backup?).  \n\u2611\ufe0f Possibility of duplicating/having a similar system off-site to cut out 3rd party cloud storage subscriptions but still have an off-site backup.  \n\u2611\ufe0f Expandable  \n\u2611\ufe0f I have gigabit hardwired network (not wifi, just local)  \n\u2611\ufe0f Ideally a free management solution (TrueNAS)  \n\u274c I am not looking to edit off the NAS currently (I'm not sure there's a particular need, with the Crucial SSDs in the Multidock giving me plenty of quick storage). I also don't need to work with collaborators or other editors from shared storage via the NAS.  \n\ud83e\udd14 A quiet unit would be great, although it's not likely to be sat on my desk next to me so this is not essential.  \n\ud83e\udd14 I don't currently plan on using it for media storage, but it's not out of the question that a portion of the storage might be allocated to media storage in the future (assuming that's possible with the above considered).\n\nWhat would you suggest?\n\n*Also posted to /HomeServer*", "author_fullname": "t2_hjcpc47b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice needed: Prebuilt or DIY NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mx73h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674856319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been lurking on here for a while and watched lots of YouTube reviews/tutorials/guides, but still not quite certain of the best direction to take. I&amp;#39;m hoping to get some advice on best options for a NAS for my use case.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I work in audio &amp;amp; video and the majority of my active projects run off 4x Crucial SSDs housed in a Blackmagic Multidock 10G. Here&amp;#39;s a summary of my SSD setup for active projects.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2TB MacBook Pro Internal SSD&lt;/li&gt;\n&lt;li&gt;7TB across 4x Crucial MX500 SSDs \u2014 only one of the 2TB is regularly being written to.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Once completed, archived projects are migrated to various HDDs:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;6TB WD Elements (mirrored via Arq backup to a 6TB Seagate Backup Plus) \u2014 2.7TB currently free&lt;/li&gt;\n&lt;li&gt;3TB Seagate Expansion&lt;/li&gt;\n&lt;li&gt;1TB Toshiba (cold storage of images)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A 12TB WD Elements then backs up as much of the SSD content (active) and archives as possible via Arq, but that&amp;#39;s now full.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a (very cheap initial) year of 10TB iDrive for backing up priority files off-site, but this level of storage quickly becomes extremely expensive for offsite cloud-based backups.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Possible Solutions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I was eyeing up a 20TB WD Elements for \u00a3290 but that&amp;#39;s no longer available and I was on the fence about it as it won&amp;#39;t slim down the total number of drives, or provide me with redundant storage if I use it exclusively. Having gone from 6 to 12TB in a few years, I&amp;#39;m also not confident that 20TB is going to be a long-term solution.&lt;/p&gt;\n\n&lt;p&gt;I then started looking at Synology units, but there are a so many options and they&amp;#39;re not cheap. Not really sure where to start...!&lt;/p&gt;\n\n&lt;p&gt;Although I&amp;#39;m techie, I&amp;#39;ve never built my own PC. Following instructions I&amp;#39;m good at, though, so I don&amp;#39;t think it&amp;#39;s completely out of the question to do a DIY build! \ud83d\ude06 I&amp;#39;ve seen &lt;a href=\"https://www.youtube.com/watch?v=boKmZKTKXHc\"&gt;LTT&amp;#39;s Jonsbo N1 build&lt;/a&gt;, but sourcing that case is tricky. It comes to a similar price as some of the Synology units, but I quite like the idea of being able to do upgrades further down the line, but in terms of hardware and software.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not too worried about appearance. It&amp;#39;s almost definitely going to end up out of sight.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some preferred outcomes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;\u2611\ufe0f As low energy usage as possible (although not to the point of diminishing returns vs energy bills).&lt;br/&gt;\n\u2611\ufe0f Suitable for (1) redundant data backup of archive projects not housed on active SSDs and (2) hourly/daily backups of active projects that are housed on SSDs (using Arq backup?).&lt;br/&gt;\n\u2611\ufe0f Possibility of duplicating/having a similar system off-site to cut out 3rd party cloud storage subscriptions but still have an off-site backup.&lt;br/&gt;\n\u2611\ufe0f Expandable&lt;br/&gt;\n\u2611\ufe0f I have gigabit hardwired network (not wifi, just local)&lt;br/&gt;\n\u2611\ufe0f Ideally a free management solution (TrueNAS)&lt;br/&gt;\n\u274c I am not looking to edit off the NAS currently (I&amp;#39;m not sure there&amp;#39;s a particular need, with the Crucial SSDs in the Multidock giving me plenty of quick storage). I also don&amp;#39;t need to work with collaborators or other editors from shared storage via the NAS.&lt;br/&gt;\n\ud83e\udd14 A quiet unit would be great, although it&amp;#39;s not likely to be sat on my desk next to me so this is not essential.&lt;br/&gt;\n\ud83e\udd14 I don&amp;#39;t currently plan on using it for media storage, but it&amp;#39;s not out of the question that a portion of the storage might be allocated to media storage in the future (assuming that&amp;#39;s possible with the above considered).&lt;/p&gt;\n\n&lt;p&gt;What would you suggest?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Also posted to /HomeServer&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dml10oIuia66v3hp2lCUD_ioAHeTbOWpTGspXKOLNNs.jpg?auto=webp&amp;v=enabled&amp;s=957c6f6db89d3013ebde847f3ef35f58fe0a0eab", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dml10oIuia66v3hp2lCUD_ioAHeTbOWpTGspXKOLNNs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d978dbe81357fa1f2fc3c19dc0fd701cc8d90dc7", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dml10oIuia66v3hp2lCUD_ioAHeTbOWpTGspXKOLNNs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc31d92e1470744e4eb71d71ab0562db556d9044", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dml10oIuia66v3hp2lCUD_ioAHeTbOWpTGspXKOLNNs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7862c97405e58b738ae0c5c94deda9f32fac01a5", "width": 320, "height": 240}], "variants": {}, "id": "SHQ1eAp4vp5XctMefdnNCcA1Y3ytojWViqwHmee7sU0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mx73h", "is_robot_indexable": true, "report_reasons": null, "author": "peter-baumann", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mx73h/advice_needed_prebuilt_or_diy_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mx73h/advice_needed_prebuilt_or_diy_nas/", "subreddit_subscribers": 667565, "created_utc": 1674856319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Right now I'm all spinning rust on my NAS, but I'd like to upgrade to something a little peppier for my OS since my remote VNC sessions can be a little slow at times, especially Firefox.\n\nSo my bright idea was to get a dual-M.2 PCIE card for like $20-30 (or two cards, whatever), put two small SSDs on it/them in RAID1, and use those for my OS partitions. Then I can use my spinning rust just for data partitions.\n\nNAS is an Intel i7 2600k w/12GB RAM running Ubuntu 20.04, Plex, pyMedusa, NZBget, OpenVPN, MergerFS, and SnapRaid, with 3x8TB drives. I could probably use some more RAM too.", "author_fullname": "t2_52am0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS question. Is this a good idea? Dual NVMe SSDs in RAID1 as OS drive(s).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvq8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674852760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now I&amp;#39;m all spinning rust on my NAS, but I&amp;#39;d like to upgrade to something a little peppier for my OS since my remote VNC sessions can be a little slow at times, especially Firefox.&lt;/p&gt;\n\n&lt;p&gt;So my bright idea was to get a dual-M.2 PCIE card for like $20-30 (or two cards, whatever), put two small SSDs on it/them in RAID1, and use those for my OS partitions. Then I can use my spinning rust just for data partitions.&lt;/p&gt;\n\n&lt;p&gt;NAS is an Intel i7 2600k w/12GB RAM running Ubuntu 20.04, Plex, pyMedusa, NZBget, OpenVPN, MergerFS, and SnapRaid, with 3x8TB drives. I could probably use some more RAM too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvq8s", "is_robot_indexable": true, "report_reasons": null, "author": "KungFuHamster", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvq8s/nas_question_is_this_a_good_idea_dual_nvme_ssds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvq8s/nas_question_is_this_a_good_idea_dual_nvme_ssds/", "subreddit_subscribers": 667565, "created_utc": 1674852760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys I have a problem. I just bought a WD RED PLUS 6TB and put it inside an external UGREEN box. The problem is that I noticed that if i dont use the hd, after a while it goes idle (i guess its idle), infact if i try to access it, it takes few seconds, and the start/stop count value in smart goes up.\n\nFrom what I know, its better to leave an hd always on, than spin on/off several times a day, so i was wondering, how do i make it so it doesnt go idle?\n\nI'm not sure if it's the HD itself or the UGREEN external box doing it to be honest, any idea what to check to get this fixed? Thank you!", "author_fullname": "t2_36427z1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set idle time in WD RED PLUS inside UGREEN external box", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mvix0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674852253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys I have a problem. I just bought a WD RED PLUS 6TB and put it inside an external UGREEN box. The problem is that I noticed that if i dont use the hd, after a while it goes idle (i guess its idle), infact if i try to access it, it takes few seconds, and the start/stop count value in smart goes up.&lt;/p&gt;\n\n&lt;p&gt;From what I know, its better to leave an hd always on, than spin on/off several times a day, so i was wondering, how do i make it so it doesnt go idle?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if it&amp;#39;s the HD itself or the UGREEN external box doing it to be honest, any idea what to check to get this fixed? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mvix0", "is_robot_indexable": true, "report_reasons": null, "author": "tharghans", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mvix0/how_to_set_idle_time_in_wd_red_plus_inside_ugreen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mvix0/how_to_set_idle_time_in_wd_red_plus_inside_ugreen/", "subreddit_subscribers": 667565, "created_utc": 1674852253.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}