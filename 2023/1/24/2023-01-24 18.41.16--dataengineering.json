{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it's now fully automated.\n\nI used Python to extract data from [API-FOOTBALL](https://rapidapi.com/api-sports/api/API-FOOTBALL) which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery.\n\nThe API didn't have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run). I used [this guide](https://go.dev/doc/tutorial/web-service-gin) to build it.\n\nAll of the Python files are in a Docker container which is hosted on [Artifact Registry](https://cloud.google.com/artifact-registry).\n\nThe infrastructure takes places on Google Cloud. I use [Cloud Scheduler](https://cloud.google.com/scheduler) to trigger the execution of a Cloud Run Job which in turn runs `main.py` which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.\n\nI was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use [GitHub Actions](https://docs.github.com/en/actions) to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the `main` branch.\n\nOne caveat with the workflow is that it only supports deploying as a Service which didn't work for this project. Luckily, I found this [pull request](https://github.com/google-github-actions/deploy-cloudrun/pull/422) where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.\n\nHere is the [Streamlit dashboard](https://premierleague.streamlit.app/). It\u2019s not great but will continue to improve it now that the backbone is in place.\n\nHere is the [GitHub repo](https://github.com/digitalghost-dev/football-data-pipeline).\n\nHere is a more [detailed document](https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html) on what's needed to build it.\n\nFlowchart:\n\n(Sorry if it's a mess. It's the best design I could think of.\n\n&amp;#x200B;\n\n[flowchart](https://preview.redd.it/hfvokmmiy0ea1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=452bd21ae70a0ce0195d7c9cfb29c00f95eab88b)", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another data project, this time with Python, Go, (some SQL), Docker, Google Cloud Services, Streamlit, and GitHub Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hfvokmmiy0ea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28312c600619459ed14d5497376ea0a7a43d5e9d"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbab3482c37d41d0abb2d410e8e6ee21713a9020"}, {"y": 174, "x": 320, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b55f869967133d7889d56a0eda735425ee161d00"}, {"y": 348, "x": 640, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f42aed67c0595cb07b726b339f4618db8501c235"}, {"y": 522, "x": 960, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=765e14b438d093db281bfe616479e047cd03f064"}, {"y": 587, "x": 1080, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60406becb3998dd6e7fef94cfabd7dfa42de7f8b"}], "s": {"y": 1475, "x": 2711, "u": "https://preview.redd.it/hfvokmmiy0ea1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=452bd21ae70a0ce0195d7c9cfb29c00f95eab88b"}, "id": "hfvokmmiy0ea1"}}, "name": "t3_10jjsfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 99, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 99, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mkpyh46z0VaLg5mkjgN9j_MFq3OKShsA-WNkQ42eG7I.jpg", "edited": 1674580662.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674498997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it&amp;#39;s now fully automated.&lt;/p&gt;\n\n&lt;p&gt;I used Python to extract data from &lt;a href=\"https://rapidapi.com/api-sports/api/API-FOOTBALL\"&gt;API-FOOTBALL&lt;/a&gt; which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery.&lt;/p&gt;\n\n&lt;p&gt;The API didn&amp;#39;t have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on &lt;a href=\"https://cloud.google.com/run/docs/overview/what-is-cloud-run\"&gt;Cloud Run&lt;/a&gt;. I used &lt;a href=\"https://go.dev/doc/tutorial/web-service-gin\"&gt;this guide&lt;/a&gt; to build it.&lt;/p&gt;\n\n&lt;p&gt;All of the Python files are in a Docker container which is hosted on &lt;a href=\"https://cloud.google.com/artifact-registry\"&gt;Artifact Registry&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The infrastructure takes places on Google Cloud. I use &lt;a href=\"https://cloud.google.com/scheduler\"&gt;Cloud Scheduler&lt;/a&gt; to trigger the execution of a Cloud Run Job which in turn runs &lt;code&gt;main.py&lt;/code&gt; which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.&lt;/p&gt;\n\n&lt;p&gt;I was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use &lt;a href=\"https://docs.github.com/en/actions\"&gt;GitHub Actions&lt;/a&gt; to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the &lt;code&gt;main&lt;/code&gt; branch.&lt;/p&gt;\n\n&lt;p&gt;One caveat with the workflow is that it only supports deploying as a Service which didn&amp;#39;t work for this project. Luckily, I found this &lt;a href=\"https://github.com/google-github-actions/deploy-cloudrun/pull/422\"&gt;pull request&lt;/a&gt; where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://premierleague.streamlit.app/\"&gt;Streamlit dashboard&lt;/a&gt;. It\u2019s not great but will continue to improve it now that the backbone is in place.&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/digitalghost-dev/football-data-pipeline\"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is a more &lt;a href=\"https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html\"&gt;detailed document&lt;/a&gt; on what&amp;#39;s needed to build it.&lt;/p&gt;\n\n&lt;p&gt;Flowchart:&lt;/p&gt;\n\n&lt;p&gt;(Sorry if it&amp;#39;s a mess. It&amp;#39;s the best design I could think of.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hfvokmmiy0ea1.png?width=2711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=452bd21ae70a0ce0195d7c9cfb29c00f95eab88b\"&gt;flowchart&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10jjsfp", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "subreddit_subscribers": 87313, "created_utc": 1674498997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So now that the holidays are over and the implications of dbt Cloud\u2019s abrupt pricing model change have sunk in, what are people doing about dbt Cloud\u2019s last-minute pricing extortion? We vastly underestimated how much it was going to cost, and we learned pretty late that they want annual contracts for Enterprise. Until we figure out the long-term solution, we\u2019re removing our developer seats to just 8 and going month-by-month, as well as reconfiguring our jobs to only run 2 massive ones. There\u2019s zero chance we pay so much money to dbt, especially after how big of a trust breaker this abrupt news was.\n\nSo what is everybody doing? Moving to self hosting and dbt Core, or are there comparable dbt Cloud-esque products out there?\n\nEdit: here is the news for those who didn\u2019t see it: https://www.getdbt.com/blog/dbt-cloud-package-update/\n\nTLDR is price changes all around, and many accounts being forced to move to Enterprise Edition", "author_fullname": "t2_8rod9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud Alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jn7dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674507842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674507262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So now that the holidays are over and the implications of dbt Cloud\u2019s abrupt pricing model change have sunk in, what are people doing about dbt Cloud\u2019s last-minute pricing extortion? We vastly underestimated how much it was going to cost, and we learned pretty late that they want annual contracts for Enterprise. Until we figure out the long-term solution, we\u2019re removing our developer seats to just 8 and going month-by-month, as well as reconfiguring our jobs to only run 2 massive ones. There\u2019s zero chance we pay so much money to dbt, especially after how big of a trust breaker this abrupt news was.&lt;/p&gt;\n\n&lt;p&gt;So what is everybody doing? Moving to self hosting and dbt Core, or are there comparable dbt Cloud-esque products out there?&lt;/p&gt;\n\n&lt;p&gt;Edit: here is the news for those who didn\u2019t see it: &lt;a href=\"https://www.getdbt.com/blog/dbt-cloud-package-update/\"&gt;https://www.getdbt.com/blog/dbt-cloud-package-update/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TLDR is price changes all around, and many accounts being forced to move to Enterprise Edition&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;v=enabled&amp;s=d79b538f83c1d1d85f67027cb9fe8d40104143ee", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=406b0dbdfc36080ece4f08c5a16330a51da98e61", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8716eb8504848d6ced17131a496a366a342268d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b685cf520249fa03a382aed24a5a2b8318953c09", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=946db5724bca2d711e45f05182d67957f980b4e2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0a6168fcabfdc081ebef4ce5308a59ba70a5db3", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4995118b4ef77d74de7589c0d45bee01db934b2c", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10jn7dw", "is_robot_indexable": true, "report_reasons": null, "author": "FecesOfAtheism", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jn7dw/dbt_cloud_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jn7dw/dbt_cloud_alternatives/", "subreddit_subscribers": 87313, "created_utc": 1674507262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any openly available data engineering projects using Scala and Spark which follow industry conventions like proper folder/package structures and object oriented division of classes/concerns? Most examples I\u2019ve seen have everything in one file without proper separation of concerns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jyjej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674539522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jyjej", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "subreddit_subscribers": 87313, "created_utc": 1674539522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to map out all the new data tools out there:  \n\n\n* what they are uniquely good at?\n* what is the compelling change in the data landscape that justified their creation?\n* how the big industry vertical (observability &amp; quality, ETL/ELT, catalog, etc) evolved?\n\n&amp;#x200B;\n\nCan you help me identify the missing tools ? or share feedback to improve it? Still WIP\n\n[notion.castordoc.com](https://notion.castordoc.com)\n\nhttps://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping of modern data tools. is anything missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzgt871o2zda1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/DASHPlaylist.mpd?a=1677177676%2CMzM3YTYwZTEzZjU4ZDc0YWIxNjJjOThiNjYxZDFlYzU4NzNiYTEyYWNiYzIxMmVjNGExOTZmMjlkNWM0ZjRlZg%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 650, "hlsUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/HLSPlaylist.m3u8?a=1677177676%2CYzdmMDg1ZjNkMDkwNmI4NzYxNDQ1OTg5OTU4NmVmOTU1MjA4MjZmOWQ2OGY4MzY1MjVkYWIwODQzMmM3ZWRmNA%3D%3D&amp;v=1&amp;f=sd", "id": "lzgt871o2zda1", "isGif": false}}, "name": "t3_10k2xtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qcNush-DcKxbOl5jzV21hd4EmfaF2DW8BG8pzdZ1Lr4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674558065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to map out all the new data tools out there:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;what they are uniquely good at?&lt;/li&gt;\n&lt;li&gt;what is the compelling change in the data landscape that justified their creation?&lt;/li&gt;\n&lt;li&gt;how the big industry vertical (observability &amp;amp; quality, ETL/ELT, catalog, etc) evolved?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you help me identify the missing tools ? or share feedback to improve it? Still WIP&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://notion.castordoc.com\"&gt;notion.castordoc.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player\"&gt;https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?auto=webp&amp;v=enabled&amp;s=83cbc10fd4df6f44787372d68831810403aa9a14", "width": 1516, "height": 852}, "resolutions": [{"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b80a1518187141cbeddce8c9756f1c9630539e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9466ba8a631fd0e72dc07198853c267a5a92f5a8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a398acec2128e9e96f2ef215b665d8f774fe64c0", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c68957f80ec2e3e30ac9cbb7773659784a177240", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=254ca3886eca2742c0c53d83b75fa208349f348e", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=400e8d6d97cb1c16e9c69504055ac6fe3d72de26", "width": 1080, "height": 606}], "variants": {}, "id": "6Zrev7FNgQrSU-pVnPXLXOHk0ZVzaBxLXy4KWXRD8tI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k2xtm", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "subreddit_subscribers": 87313, "created_utc": 1674558065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. \n\nSome important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. \n\nThe current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.\n\nWhat I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.\n\nThe tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.\n\nI\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.\n\nThank you in advance!", "author_fullname": "t2_az62upwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas ETL - looking for thoughts on current process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jpjev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674512906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. &lt;/p&gt;\n\n&lt;p&gt;Some important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. &lt;/p&gt;\n\n&lt;p&gt;The current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp;amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.&lt;/p&gt;\n\n&lt;p&gt;What I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.&lt;/p&gt;\n\n&lt;p&gt;The tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp;amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jpjev", "is_robot_indexable": true, "report_reasons": null, "author": "hektar9987", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "subreddit_subscribers": 87313, "created_utc": 1674512906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.\n\nhttps://www.databricks.com/learn/certification/machine-learning-associate", "author_fullname": "t2_adn81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Scalable Machine Learning with Apache Spark Certification Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jtqzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674524169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification/machine-learning-associate\"&gt;https://www.databricks.com/learn/certification/machine-learning-associate&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jtqzb", "is_robot_indexable": true, "report_reasons": null, "author": "milehighmecked", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "subreddit_subscribers": 87313, "created_utc": 1674524169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI'm wondering what is the most common architecture to implement CDC (change data capture) at your company?  I've seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. ", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you implement CDC in your organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6sev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674571008.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674570721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what is the most common architecture to implement CDC (change data capture) at your company?  I&amp;#39;ve seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k6sev", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "subreddit_subscribers": 87313, "created_utc": 1674570721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week, I made a post in this sub\\[1\\] &amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.\n\nBased on the feedback (thanks, by the way!), I've updated my blog post\\[2\\] and included the example calculation I posted on Reddit.\n\nAnyway, here's the \"checklist\" that guided the calculations made in my previous Reddit post, with links at the bottom:\n\n\\-\n\n*When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).*\n\n## Up-front costs\n\n* software cost &amp; licensing, if applicable\n* learning &amp; education\n* implementation &amp; testing (including data migration costs)\n* documentation &amp; knowledge sharing\n* customization\n\n## Ongoing costs\n\n* direct infrastructure costs (e.g., hosting &amp; storage)\n* backup infrastructure costs (e.g., failover &amp; additional AZs)\n* supporting infrastructure costs (e.g., monitoring &amp; alerting)\n* maintenance, patches/upgrades, &amp; support\n* feature additions\n\n## Team &amp; opportunity costs\n\n* hiring to replace the engineers now working with the new software\n* time spent on infrastructure that could otherwise be spent on core product\n\n\\-\n\n\\[1\\]: [https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback\\_request\\_tco\\_calculation\\_for\\_apache\\_kafka](https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka) (link to the Reddit post in this sub if you're curious)\n\n\\[2\\]: [https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership](https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership) (link to the full blog post)", "author_fullname": "t2_fv515", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should you build or buy your infra? Checklist for calculating the costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8hwn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week, I made a post in this sub[1] &amp;amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.&lt;/p&gt;\n\n&lt;p&gt;Based on the feedback (thanks, by the way!), I&amp;#39;ve updated my blog post[2] and included the example calculation I posted on Reddit.&lt;/p&gt;\n\n&lt;p&gt;Anyway, here&amp;#39;s the &amp;quot;checklist&amp;quot; that guided the calculations made in my previous Reddit post, with links at the bottom:&lt;/p&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).&lt;/em&gt;&lt;/p&gt;\n\n&lt;h2&gt;Up-front costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;software cost &amp;amp; licensing, if applicable&lt;/li&gt;\n&lt;li&gt;learning &amp;amp; education&lt;/li&gt;\n&lt;li&gt;implementation &amp;amp; testing (including data migration costs)&lt;/li&gt;\n&lt;li&gt;documentation &amp;amp; knowledge sharing&lt;/li&gt;\n&lt;li&gt;customization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Ongoing costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;direct infrastructure costs (e.g., hosting &amp;amp; storage)&lt;/li&gt;\n&lt;li&gt;backup infrastructure costs (e.g., failover &amp;amp; additional AZs)&lt;/li&gt;\n&lt;li&gt;supporting infrastructure costs (e.g., monitoring &amp;amp; alerting)&lt;/li&gt;\n&lt;li&gt;maintenance, patches/upgrades, &amp;amp; support&lt;/li&gt;\n&lt;li&gt;feature additions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Team &amp;amp; opportunity costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;hiring to replace the engineers now working with the new software&lt;/li&gt;\n&lt;li&gt;time spent on infrastructure that could otherwise be spent on core product&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;[1]: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka\"&gt;https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka&lt;/a&gt; (link to the Reddit post in this sub if you&amp;#39;re curious)&lt;/p&gt;\n\n&lt;p&gt;[2]: &lt;a href=\"https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership\"&gt;https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership&lt;/a&gt; (link to the full blog post)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?auto=webp&amp;v=enabled&amp;s=bc75ae8dfc3a23aef5ce6c9c684b8c0ce4aadc9c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85db55ab11391be72234810a79e3dcc7b703e485", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb355f3b10a18334c292ab6e5f0bdea646415ddd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34774c95e96d5971688ba110ec64c5de89ddc031", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=756094fe0e52623c08186904a6093cbc205c7a4f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f0ca72492d9c7a61e0d93bd36d4b1835b76dfa6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13730358324cec31bf695d246eeaa64b772eea58", "width": 1080, "height": 567}], "variants": {}, "id": "vj-wMdrGC9Ek6GbFlDkgWr7MDOA5uPlbmoApWsvlMkU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8hwn", "is_robot_indexable": true, "report_reasons": null, "author": "propjames", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "subreddit_subscribers": 87313, "created_utc": 1674575369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post about the fundamentals of data modelling from my POV. I'd be really interested in people's opinions. \n\nTLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.", "author_fullname": "t2_7srfj4fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling blog post - thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6zd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674571279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dantelore.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post about the fundamentals of data modelling from my POV. I&amp;#39;d be really interested in people&amp;#39;s opinions. &lt;/p&gt;\n\n&lt;p&gt;TLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dantelore.com/posts/simplest-data-model/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k6zd1", "is_robot_indexable": true, "report_reasons": null, "author": "DanteLore1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6zd1/data_modelling_blog_post_thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dantelore.com/posts/simplest-data-model/", "subreddit_subscribers": 87313, "created_utc": 1674571279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started out as an analyst in a small company about a year ago with the keys to an AWS account. I've spent the year organising my team's data into an S3 bucket and using python scripts to create the necessary pipelines into and out of the bucket. The files are in parquet format and partitioned, with an Athena database sitting on top for querying. The metadata that manages what is in the bucket is sat in an SQL Server database. When I want to slice and process the files in the bucket, I query the metadata tables and use that to query the bucket.\n\nIt's all running nicely but I'm totally unaware of what I've built and how to contextualise it. Is it just an organised lake? I read about lakehouses but it doesn't seem to have a lot of what they seem to have. Currently, I only have SQL query ability into the data unless I pull it onto a server. Is there a way of doing more, i.e direct pandas sort of work? I've heard about Databricks and Spark and have a vague idea of distributing data and processing power across clusters, but don't know if that meshes with what I'm doing? As far as I know, S3 is a distributed file system but is a cluster somewhat different? I was asked why I didn't put my metadata in the bucket as well and I didn't have an answer. I just felt that the metadata seemed more warehousey than lakey; more CRUD. Is that me hanging on to a past I didn't know I had? The broader question is: how do I explain what I've done in the context of modern data architectures? Any book recommendations are also welcome.", "author_fullname": "t2_djdhkrg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a thing. What is it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jn42d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674507043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started out as an analyst in a small company about a year ago with the keys to an AWS account. I&amp;#39;ve spent the year organising my team&amp;#39;s data into an S3 bucket and using python scripts to create the necessary pipelines into and out of the bucket. The files are in parquet format and partitioned, with an Athena database sitting on top for querying. The metadata that manages what is in the bucket is sat in an SQL Server database. When I want to slice and process the files in the bucket, I query the metadata tables and use that to query the bucket.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s all running nicely but I&amp;#39;m totally unaware of what I&amp;#39;ve built and how to contextualise it. Is it just an organised lake? I read about lakehouses but it doesn&amp;#39;t seem to have a lot of what they seem to have. Currently, I only have SQL query ability into the data unless I pull it onto a server. Is there a way of doing more, i.e direct pandas sort of work? I&amp;#39;ve heard about Databricks and Spark and have a vague idea of distributing data and processing power across clusters, but don&amp;#39;t know if that meshes with what I&amp;#39;m doing? As far as I know, S3 is a distributed file system but is a cluster somewhat different? I was asked why I didn&amp;#39;t put my metadata in the bucket as well and I didn&amp;#39;t have an answer. I just felt that the metadata seemed more warehousey than lakey; more CRUD. Is that me hanging on to a past I didn&amp;#39;t know I had? The broader question is: how do I explain what I&amp;#39;ve done in the context of modern data architectures? Any book recommendations are also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jn42d", "is_robot_indexable": true, "report_reasons": null, "author": "user192034", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jn42d/i_made_a_thing_what_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jn42d/i_made_a_thing_what_is_it/", "subreddit_subscribers": 87313, "created_utc": 1674507043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. \n\nWe use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn't it an antipattern a little bit? Or its a \"normal\"/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).\n\nNot really sure, appreciate any comment. Thank you.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k977n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674577191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. &lt;/p&gt;\n\n&lt;p&gt;We use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn&amp;#39;t it an antipattern a little bit? Or its a &amp;quot;normal&amp;quot;/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).&lt;/p&gt;\n\n&lt;p&gt;Not really sure, appreciate any comment. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k977n", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k977n/streaming_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k977n/streaming_data_storage/", "subreddit_subscribers": 87313, "created_utc": 1674577191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ec0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Thoughts on which resume style is better and overall review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"krxbxso96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df3c4db70ae0334dd4f5808b18bca3c8aac2fd9d"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c05ec74c0a36553a3b792b1da8a6e4b536c50150"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42e5fdd1b4561f4991ce2362da81dc239e7e13b4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1151cbc4ef9a0ea1551e8fa87195d89bb3332412"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b53b42054defed670d2e446f5d14a1e06421cdb"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02304a91a7717067afb2fe626c113819ae04ec14"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=60422c57f70fbfd8c48ce38faa0a5c266ed1c5f4"}, "id": "krxbxso96xda1"}, "ugoxbuo96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3a75ce5f7dc4acdb2df9a230dc5090b0cf35783"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de64671d09ea2e020252f7ff132a2c7698fd81e3"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb23cae0e7e029680e8191770307f412740f9ee4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6758459d856a0537d67ebea09ed62f50da79a577"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7094667e97568393d73d765694ff8cd38e1dfe00"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b091c640f5ebb1189ae4f639c54a4d857e1e7bc5"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30d7f6de319107d1ca570d59af27ff0fed7ffd16"}, "id": "ugoxbuo96xda1"}}, "name": "t3_10jx7b5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "ups": 6, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "krxbxso96xda1", "id": 233003708}, {"media_id": "ugoxbuo96xda1", "id": 233003709}]}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lJx4kE5BiWPmNnteoQZf0C5TPgtI922M30_ZSyRpVw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674534864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10jx7b5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10jx7b5", "is_robot_indexable": true, "report_reasons": null, "author": "mistanervous", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10jx7b5/thoughts_on_which_resume_style_is_better_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10jx7b5", "subreddit_subscribers": 87313, "created_utc": 1674534864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you", "author_fullname": "t2_r509bej6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nested json and xml", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jwid4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674532607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jwid4", "is_robot_indexable": true, "report_reasons": null, "author": "mediocrX", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "subreddit_subscribers": 87313, "created_utc": 1674532607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!", "author_fullname": "t2_8e3c179e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workflows vs Airflow/Dagsterr/Prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10juwum", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674527635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10juwum", "is_robot_indexable": true, "report_reasons": null, "author": "jaredfromspacecamp", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "subreddit_subscribers": 87313, "created_utc": 1674527635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nLooking for an optimize/efficient way to extract data coming from an onprem mssql table to google bigquery. \nThe table schema type are all varchar which is being manage by other department and we only have a read only permission for the table. \n\nOur current setup is to use google dataflow to get the data coming from our on prem database. This is doable however, the data pull would be inefficient since there are no index and the timestamp column of the table has a schema of varchar.    \n\nI was thinking about Converting the timestamp column to timestamp/datetime  but i believe it would take too long as it would convert every row first before applying the filter. \n\nThe goal is to create a batch pipeline for the latest upload.   \n\nPlease advice,  \nThanks", "author_fullname": "t2_are11xb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EL for mssql db with no index all schema type are varchar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jlbyy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674502741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Looking for an optimize/efficient way to extract data coming from an onprem mssql table to google bigquery. \nThe table schema type are all varchar which is being manage by other department and we only have a read only permission for the table. &lt;/p&gt;\n\n&lt;p&gt;Our current setup is to use google dataflow to get the data coming from our on prem database. This is doable however, the data pull would be inefficient since there are no index and the timestamp column of the table has a schema of varchar.    &lt;/p&gt;\n\n&lt;p&gt;I was thinking about Converting the timestamp column to timestamp/datetime  but i believe it would take too long as it would convert every row first before applying the filter. &lt;/p&gt;\n\n&lt;p&gt;The goal is to create a batch pipeline for the latest upload.   &lt;/p&gt;\n\n&lt;p&gt;Please advice,&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jlbyy", "is_robot_indexable": true, "report_reasons": null, "author": "Sublime-01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jlbyy/el_for_mssql_db_with_no_index_all_schema_type_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jlbyy/el_for_mssql_db_with_no_index_all_schema_type_are/", "subreddit_subscribers": 87313, "created_utc": 1674502741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn't any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.", "author_fullname": "t2_84sa46kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jw0jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674531016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn&amp;#39;t any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jw0jc", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient-Bet-8513", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jw0jc/apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jw0jc/apache_spark/", "subreddit_subscribers": 87313, "created_utc": 1674531016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nJust gathering feedback on Cloud Data Integration service on IDMC. Any thoughts/comments on this ?\n\nThanks!", "author_fullname": "t2_4mdsqonb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on Cloud Data Integration service with Informatica's IDMC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jmyxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674506701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Just gathering feedback on Cloud Data Integration service on IDMC. Any thoughts/comments on this ?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10jmyxr", "is_robot_indexable": true, "report_reasons": null, "author": "vrakshith28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jmyxr/feedback_on_cloud_data_integration_service_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jmyxr/feedback_on_cloud_data_integration_service_with/", "subreddit_subscribers": 87313, "created_utc": 1674506701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first job and I am too excited/anxious.\n\nMy current skills - Python, SQL", "author_fullname": "t2_u33aam84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What responsibilities can I expect for a Data Integration Intern?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kb11a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674581759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first job and I am too excited/anxious.&lt;/p&gt;\n\n&lt;p&gt;My current skills - Python, SQL&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kb11a", "is_robot_indexable": true, "report_reasons": null, "author": "scanip", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "subreddit_subscribers": 87313, "created_utc": 1674581759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I'm familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): \n\n1.Pyspark\n\n 2.Pytorch /Pandas \n\nI don't have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?", "author_fullname": "t2_vh9qo8up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Preparation for Data Engineering in 15 days backend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kamzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I&amp;#39;m familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): &lt;/p&gt;\n\n&lt;p&gt;1.Pyspark&lt;/p&gt;\n\n&lt;p&gt;2.Pytorch /Pandas &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10kamzt", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Crazy-9444", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "subreddit_subscribers": 87313, "created_utc": 1674580842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are a technical team proficient in SWE skills, so we're happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I'm missing why we should use it?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs custom pyspark for transformations in databricks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kagoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a technical team proficient in SWE skills, so we&amp;#39;re happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I&amp;#39;m missing why we should use it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kagoh", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "subreddit_subscribers": 87313, "created_utc": 1674580409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.\n\nI was looking at this write up of Sql server's implementation https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\n\nAnd it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn't necessarily guaranteed. \n\nSo theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn't generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustered Index Lookup Efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8ftz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.&lt;/p&gt;\n\n&lt;p&gt;I was looking at this write up of Sql server&amp;#39;s implementation &lt;a href=\"https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\"&gt;https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn&amp;#39;t necessarily guaranteed. &lt;/p&gt;\n\n&lt;p&gt;So theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn&amp;#39;t generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?auto=webp&amp;v=enabled&amp;s=f68a5246a58720c9fc4a6173406989931fe0f17c", "width": 542, "height": 271}, "resolutions": [{"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76e0bbd89dd768d12decfc2099c8f4a1aace4fa2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc6e621801eed6fdbf7999dba6ca1a48512b4407", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b445e25cd760a4ec5b906a01ac8df66a015b862b", "width": 320, "height": 160}], "variants": {}, "id": "w5ngVr1pMtH7vZrtkUTkbaXCV87rbMoiKjqUpVh8oE4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8ftz", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "subreddit_subscribers": 87313, "created_utc": 1674575213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. \n\nDefinitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. \n\nWhat do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. \n\nOne rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. \n\nHow do you troubleshoot data issues in prod?", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debugging data errors and inconsistencies in downstream dashboards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8dtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. &lt;/p&gt;\n\n&lt;p&gt;Definitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. &lt;/p&gt;\n\n&lt;p&gt;What do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. &lt;/p&gt;\n\n&lt;p&gt;One rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. &lt;/p&gt;\n\n&lt;p&gt;How do you troubleshoot data issues in prod?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Applied Data &amp; ML Engineer | Developer Advocate", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8dtf", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "subreddit_subscribers": 87313, "created_utc": 1674575067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In late 2020, I published [the results](https://www.jesse-anderson.com/2020/12/data-teams-survey-results/) of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we're moving past COVID and into a post-COVID world. Please take some time to fill out [the survey](https://forms.gle/qEdXkB9N395HuAaN7). It shouldn't take more than five minutes to fill out.\n\nIn a bit, I'll write a post talking about the results and comparing them to the previous year's results. I expect we'll see some progression and some interesting correlation between value and teams present.", "author_fullname": "t2_5pxn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Teams Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k1htk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674551710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In late 2020, I published &lt;a href=\"https://www.jesse-anderson.com/2020/12/data-teams-survey-results/\"&gt;the results&lt;/a&gt; of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we&amp;#39;re moving past COVID and into a post-COVID world. Please take some time to fill out &lt;a href=\"https://forms.gle/qEdXkB9N395HuAaN7\"&gt;the survey&lt;/a&gt;. It shouldn&amp;#39;t take more than five minutes to fill out.&lt;/p&gt;\n\n&lt;p&gt;In a bit, I&amp;#39;ll write a post talking about the results and comparing them to the previous year&amp;#39;s results. I expect we&amp;#39;ll see some progression and some interesting correlation between value and teams present.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Mentor | Jesse Anderson", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k1htk", "is_robot_indexable": true, "report_reasons": null, "author": "eljefe6a", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k1htk/data_teams_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k1htk/data_teams_survey/", "subreddit_subscribers": 87313, "created_utc": 1674551710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14djpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need your help - Participants wanted for my Master Thesis Survey \u201cAnalysis of the influence of quality assurance on the development of machine learning products\u201d (Every single response is highly appreciated! Big thank you in advance!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10k2ham", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/s02o-QW_mCE9hMvS_5BMZd_56S0fA8IBrILuXugTAq0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674556094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?auto=webp&amp;v=enabled&amp;s=5a852038a417c71993d03dfe5a82ee34a1ebac18", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ae20ac3149db614ed4d486cf8683b6036918112", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a0727e8f0faa1a71800e22773b4294acdd97d41", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67fe3461c7ab76bfdc5133c3fc54deb28e93ed02", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9e3d2e22417812b255e1ca1fd95b61154283edc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c57bcf00f08616276535721247c89c74a8f82028", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b62c734080c67b2eebb34e1c4f9dd26b13ecbccb", "width": 1080, "height": 567}], "variants": {}, "id": "TuzIvYHgwjvuLzF64CS432uQ3fOCi2MJFLPDFLxrItg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k2ham", "is_robot_indexable": true, "report_reasons": null, "author": "felix-reddit", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2ham/need_your_help_participants_wanted_for_my_master/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "subreddit_subscribers": 87313, "created_utc": 1674556094.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}