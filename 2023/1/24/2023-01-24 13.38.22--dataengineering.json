{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it's now fully automated.\n\nI used Python to extract data from [API-FOOTBALL](https://rapidapi.com/api-sports/api/API-FOOTBALL) which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery. \n\nThe API didn't have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run). I used [this guide](https://go.dev/doc/tutorial/web-service-gin) to build it.\n\nAll of the Python files are in a Docker container which is hosted on [Artifact Registry](https://cloud.google.com/artifact-registry).\n\nThe infrastructure takes places on Google Cloud. I use [Cloud Scheduler](https://cloud.google.com/scheduler) to trigger the execution of a Cloud Run Job which in turn runs `main.py` which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.\n\nI was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use [GitHub Actions](https://docs.github.com/en/actions) to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the `main` branch.\n\nOne caveat with the workflow is that it only supports deploying as a Service which didn't work for this project. Luckily, I found this [pull request](https://github.com/google-github-actions/deploy-cloudrun/pull/422) where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.\n\nHere is the [Streamlit dashboard](https://premierleague.streamlit.app/). It\u2019s not great but will continue to improve it now that the backbone is in place. \n\nHere is the [GitHub repo](https://github.com/digitalghost-dev/football-data-pipeline).\n\nHere is a more [detailed document](https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html) on what's needed to build it.\n\nFlowchart:\n\n(Sorry if it's a mess. It's the best design I could think of.\n\nhttps://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26a41a431999b032e52f7529da2cb9493a02b92e", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another data project, this time with Python, Go, (some SQL), Docker, Google Cloud Services, Streamlit, and GitHub Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k3oz0nmm7uda1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9e507b23b0641f354fbf0147580c807885a5bdb"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9219e21b1aa10a9a19de1f17f3374c7c327768bf"}, {"y": 174, "x": 320, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4972b66ec4566b85953f8488dc15678c2b560e15"}, {"y": 348, "x": 640, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23ca2789cd5e1046bbbff6283df78055a2668238"}, {"y": 522, "x": 960, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adddab3cfceae9c54d00a7cbf61f3b76872571df"}, {"y": 587, "x": 1080, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79b011fe0354b7ebc0b043144bd38b7f6736cf2a"}], "s": {"y": 1475, "x": 2711, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26a41a431999b032e52f7529da2cb9493a02b92e"}, "id": "k3oz0nmm7uda1"}}, "name": "t3_10jjsfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/S_VhRppmfdheeScHxGjesOU_4jt49_t2WyC3BWhIhT8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674498997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it&amp;#39;s now fully automated.&lt;/p&gt;\n\n&lt;p&gt;I used Python to extract data from &lt;a href=\"https://rapidapi.com/api-sports/api/API-FOOTBALL\"&gt;API-FOOTBALL&lt;/a&gt; which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery. &lt;/p&gt;\n\n&lt;p&gt;The API didn&amp;#39;t have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on &lt;a href=\"https://cloud.google.com/run/docs/overview/what-is-cloud-run\"&gt;Cloud Run&lt;/a&gt;. I used &lt;a href=\"https://go.dev/doc/tutorial/web-service-gin\"&gt;this guide&lt;/a&gt; to build it.&lt;/p&gt;\n\n&lt;p&gt;All of the Python files are in a Docker container which is hosted on &lt;a href=\"https://cloud.google.com/artifact-registry\"&gt;Artifact Registry&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The infrastructure takes places on Google Cloud. I use &lt;a href=\"https://cloud.google.com/scheduler\"&gt;Cloud Scheduler&lt;/a&gt; to trigger the execution of a Cloud Run Job which in turn runs &lt;code&gt;main.py&lt;/code&gt; which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.&lt;/p&gt;\n\n&lt;p&gt;I was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use &lt;a href=\"https://docs.github.com/en/actions\"&gt;GitHub Actions&lt;/a&gt; to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the &lt;code&gt;main&lt;/code&gt; branch.&lt;/p&gt;\n\n&lt;p&gt;One caveat with the workflow is that it only supports deploying as a Service which didn&amp;#39;t work for this project. Luckily, I found this &lt;a href=\"https://github.com/google-github-actions/deploy-cloudrun/pull/422\"&gt;pull request&lt;/a&gt; where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://premierleague.streamlit.app/\"&gt;Streamlit dashboard&lt;/a&gt;. It\u2019s not great but will continue to improve it now that the backbone is in place. &lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/digitalghost-dev/football-data-pipeline\"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is a more &lt;a href=\"https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html\"&gt;detailed document&lt;/a&gt; on what&amp;#39;s needed to build it.&lt;/p&gt;\n\n&lt;p&gt;Flowchart:&lt;/p&gt;\n\n&lt;p&gt;(Sorry if it&amp;#39;s a mess. It&amp;#39;s the best design I could think of.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=26a41a431999b032e52f7529da2cb9493a02b92e\"&gt;https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=26a41a431999b032e52f7529da2cb9493a02b92e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?auto=webp&amp;v=enabled&amp;s=6598074286d59906d5c44247a4a696ed5b419537", "width": 2711, "height": 1475}, "resolutions": [{"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c1d3e1093d3e56d69e91a37697b7f5f240dcadb", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d7da8a2b5d6bb21afe4bd7f410416a08b2c233d", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e38ec4ed8e956c4cac666b17df282e74a488dc7", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9f0558b459b606ad122e78d3512a5710025a62c", "width": 640, "height": 348}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51f6dc574858c1fbf5d532628844b2a7f3d25add", "width": 960, "height": 522}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=547334d5b61f6d6ea203bd177c974c9f6069b393", "width": 1080, "height": 587}], "variants": {}, "id": "3uckV975S_JuS7Qnrom3RWIKq9VdiWq91CsXQwedgh8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10jjsfp", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "subreddit_subscribers": 87270, "created_utc": 1674498997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI\u2019ve made a few ETLs using pandas, for personal projects as well as for work and it has come very handy.\n\nPandas is very memory intensive so it\u2019s not a good solution for large datasets, which is something I\u2019m facing currently.\n\nI\u2019ve heard that using pure python is a good step before using Spark, but I can\u2019t find an example of ETL using just pure python.\n\nHow would that work? Is there an example script for an ETL without using pandas? \n\nAny help would be appreciated!", "author_fullname": "t2_pcb7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL using pure python (no Pandas)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jgwfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674492186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve made a few ETLs using pandas, for personal projects as well as for work and it has come very handy.&lt;/p&gt;\n\n&lt;p&gt;Pandas is very memory intensive so it\u2019s not a good solution for large datasets, which is something I\u2019m facing currently.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve heard that using pure python is a good step before using Spark, but I can\u2019t find an example of ETL using just pure python.&lt;/p&gt;\n\n&lt;p&gt;How would that work? Is there an example script for an ETL without using pandas? &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jgwfs", "is_robot_indexable": true, "report_reasons": null, "author": "IceStallion", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jgwfs/etl_using_pure_python_no_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jgwfs/etl_using_pure_python_no_pandas/", "subreddit_subscribers": 87270, "created_utc": 1674492186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ggio6wps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Is Databricks's autoscaling cost efficient?\" - We take a deep dive with the TPC-DS benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10jfgxm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b_KdZkJwiQj1rTbtg4P_c8pMtKT9rMq5YMn0KV5apTY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674488625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jeffchousync/is-databrickss-autoscaling-cost-efficient-610e6ece4831", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?auto=webp&amp;v=enabled&amp;s=704027bca845b6d95149fadbce17d0d317ac7686", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=784a1e2ed076a4f03aea5223529b76e9981496b6", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04fb76b375b06bd72fe8336444568f14dd5308a5", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e57d7113012a7b5cb6a4f13dde3852e8765662f5", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6e86017fc8279c8dc5f0f164538604e931d029c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fbf349392eed31e6c6c0f506689ec431f1bdca6", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e08f8c70f8e3ee514cf62bd39ff951a4e7c4a54", "width": 1080, "height": 720}], "variants": {}, "id": "jk_zmYBFc4Ic_fBVeBsjIZA9avp8JovVuVkJ7pxqlXk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10jfgxm", "is_robot_indexable": true, "report_reasons": null, "author": "gobstopper_chicken", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jfgxm/is_databrickss_autoscaling_cost_efficient_we_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jeffchousync/is-databrickss-autoscaling-cost-efficient-610e6ece4831", "subreddit_subscribers": 87270, "created_utc": 1674488625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So now that the holidays are over and the implications of dbt Cloud\u2019s abrupt pricing model change have sunk in, what are people doing about dbt Cloud\u2019s last-minute pricing extortion? We vastly underestimated how much it was going to cost, and we learned pretty late that they want annual contracts for Enterprise. Until we figure out the long-term solution, we\u2019re removing our developer seats to just 8 and going month-by-month, as well as reconfiguring our jobs to only run 2 massive ones. There\u2019s zero chance we pay so much money to dbt, especially after how big of a trust breaker this abrupt news was.\n\nSo what is everybody doing? Moving to self hosting and dbt Core, or are there comparable dbt Cloud-esque products out there?\n\nEdit: here is the news for those who didn\u2019t see it: https://www.getdbt.com/blog/dbt-cloud-package-update/\n\nTLDR is price changes all around, and many accounts being forced to move to Enterprise Edition", "author_fullname": "t2_8rod9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud Alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jn7dw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674507842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674507262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So now that the holidays are over and the implications of dbt Cloud\u2019s abrupt pricing model change have sunk in, what are people doing about dbt Cloud\u2019s last-minute pricing extortion? We vastly underestimated how much it was going to cost, and we learned pretty late that they want annual contracts for Enterprise. Until we figure out the long-term solution, we\u2019re removing our developer seats to just 8 and going month-by-month, as well as reconfiguring our jobs to only run 2 massive ones. There\u2019s zero chance we pay so much money to dbt, especially after how big of a trust breaker this abrupt news was.&lt;/p&gt;\n\n&lt;p&gt;So what is everybody doing? Moving to self hosting and dbt Core, or are there comparable dbt Cloud-esque products out there?&lt;/p&gt;\n\n&lt;p&gt;Edit: here is the news for those who didn\u2019t see it: &lt;a href=\"https://www.getdbt.com/blog/dbt-cloud-package-update/\"&gt;https://www.getdbt.com/blog/dbt-cloud-package-update/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TLDR is price changes all around, and many accounts being forced to move to Enterprise Edition&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?auto=webp&amp;v=enabled&amp;s=d79b538f83c1d1d85f67027cb9fe8d40104143ee", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=406b0dbdfc36080ece4f08c5a16330a51da98e61", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8716eb8504848d6ced17131a496a366a342268d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b685cf520249fa03a382aed24a5a2b8318953c09", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=946db5724bca2d711e45f05182d67957f980b4e2", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0a6168fcabfdc081ebef4ce5308a59ba70a5db3", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/ITlJY1p8Ro-HgmNZmcADzJBq6r4lbXLM7mMNYx9pXIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4995118b4ef77d74de7589c0d45bee01db934b2c", "width": 1080, "height": 607}], "variants": {}, "id": "1atsLEhqeX9kFaissrSt8acZk9ienTNBpjUXMcidAMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10jn7dw", "is_robot_indexable": true, "report_reasons": null, "author": "FecesOfAtheism", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jn7dw/dbt_cloud_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jn7dw/dbt_cloud_alternatives/", "subreddit_subscribers": 87270, "created_utc": 1674507262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any openly available data engineering projects using Scala and Spark which follow industry conventions like proper folder/package structures and object oriented division of classes/concerns? Most examples I\u2019ve seen have everything in one file without proper separation of concerns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jyjej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674539522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jyjej", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "subreddit_subscribers": 87270, "created_utc": 1674539522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. \n\nSome important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. \n\nThe current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.\n\nWhat I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.\n\nThe tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.\n\nI\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.\n\nThank you in advance!", "author_fullname": "t2_az62upwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas ETL - looking for thoughts on current process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jpjev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674512906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. &lt;/p&gt;\n\n&lt;p&gt;Some important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. &lt;/p&gt;\n\n&lt;p&gt;The current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp;amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.&lt;/p&gt;\n\n&lt;p&gt;What I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.&lt;/p&gt;\n\n&lt;p&gt;The tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp;amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jpjev", "is_robot_indexable": true, "report_reasons": null, "author": "hektar9987", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "subreddit_subscribers": 87270, "created_utc": 1674512906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.\n\nhttps://www.databricks.com/learn/certification/machine-learning-associate", "author_fullname": "t2_adn81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Scalable Machine Learning with Apache Spark Certification Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jtqzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674524169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification/machine-learning-associate\"&gt;https://www.databricks.com/learn/certification/machine-learning-associate&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jtqzb", "is_robot_indexable": true, "report_reasons": null, "author": "milehighmecked", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "subreddit_subscribers": 87270, "created_utc": 1674524169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Relataively new to DE so seeking advice:\n\nI have been in DE for a couple of months. Current organization uses IBM Datastage and will move to Azure Data Factory/Databricks in the future. 3 other people on the team with great knowledge and really helpful. It will possibly take a year or so to migrate. Things work slow here. \n\nI am in the middle of a process with another company (strong chances of a job offer by next week) that is currently using Pentaho Data Integration and migrating to ApacheHOP in the future. I will be the only DE and the Manager has been managing the workload by themselves until now. Smaller team and a lot more flexibility. \n\nAssuming salary is the same at both the places, does it make sense to take the new job? Which platform is more in demand in Canada/US? \n\nP.S. Salary is the same at both the places", "author_fullname": "t2_adckd9g5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career switch question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jo21k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674509312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Relataively new to DE so seeking advice:&lt;/p&gt;\n\n&lt;p&gt;I have been in DE for a couple of months. Current organization uses IBM Datastage and will move to Azure Data Factory/Databricks in the future. 3 other people on the team with great knowledge and really helpful. It will possibly take a year or so to migrate. Things work slow here. &lt;/p&gt;\n\n&lt;p&gt;I am in the middle of a process with another company (strong chances of a job offer by next week) that is currently using Pentaho Data Integration and migrating to ApacheHOP in the future. I will be the only DE and the Manager has been managing the workload by themselves until now. Smaller team and a lot more flexibility. &lt;/p&gt;\n\n&lt;p&gt;Assuming salary is the same at both the places, does it make sense to take the new job? Which platform is more in demand in Canada/US? &lt;/p&gt;\n\n&lt;p&gt;P.S. Salary is the same at both the places&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jo21k", "is_robot_indexable": true, "report_reasons": null, "author": "anonymously_666", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jo21k/career_switch_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jo21k/career_switch_question/", "subreddit_subscribers": 87270, "created_utc": 1674509312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everybody !\n\nI have a spark job that is composed as fellows:\n\n1. read static dataFrame from Delta Lake.\n2. read a stream of dataFrame from Delta Lake.\n3. join the stream with the static.\n4. do a flatMapGroupsWithState.\n5. write output.\n\nThe problem is I have a different output from what I expected, like I lost events on `flatMapGroupsWithState`. Not only that, but the output is random. When I re-run with the same input, I get different output.\n\nBut when I added `.coalesce(1)` in the writing operation I always got the desired output in LocalMode but not in ClusterMode.\n\nI also asked in [StackOverflow](https://stackoverflow.com/questions/75209721/spark-flatmapgroupswithstate-random-lost-events).\n\nThank you in advance !", "author_fullname": "t2_m0ecu4ky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark flatMapGroupsWithState random lost events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jc2is", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674487100.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674479227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody !&lt;/p&gt;\n\n&lt;p&gt;I have a spark job that is composed as fellows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;read static dataFrame from Delta Lake.&lt;/li&gt;\n&lt;li&gt;read a stream of dataFrame from Delta Lake.&lt;/li&gt;\n&lt;li&gt;join the stream with the static.&lt;/li&gt;\n&lt;li&gt;do a flatMapGroupsWithState.&lt;/li&gt;\n&lt;li&gt;write output.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problem is I have a different output from what I expected, like I lost events on &lt;code&gt;flatMapGroupsWithState&lt;/code&gt;. Not only that, but the output is random. When I re-run with the same input, I get different output.&lt;/p&gt;\n\n&lt;p&gt;But when I added &lt;code&gt;.coalesce(1)&lt;/code&gt; in the writing operation I always got the desired output in LocalMode but not in ClusterMode.&lt;/p&gt;\n\n&lt;p&gt;I also asked in &lt;a href=\"https://stackoverflow.com/questions/75209721/spark-flatmapgroupswithstate-random-lost-events\"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jc2is", "is_robot_indexable": true, "report_reasons": null, "author": "Dhia_lunar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jc2is/spark_flatmapgroupswithstate_random_lost_events/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jc2is/spark_flatmapgroupswithstate_random_lost_events/", "subreddit_subscribers": 87270, "created_utc": 1674479227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started out as an analyst in a small company about a year ago with the keys to an AWS account. I've spent the year organising my team's data into an S3 bucket and using python scripts to create the necessary pipelines into and out of the bucket. The files are in parquet format and partitioned, with an Athena database sitting on top for querying. The metadata that manages what is in the bucket is sat in an SQL Server database. When I want to slice and process the files in the bucket, I query the metadata tables and use that to query the bucket.\n\nIt's all running nicely but I'm totally unaware of what I've built and how to contextualise it. Is it just an organised lake? I read about lakehouses but it doesn't seem to have a lot of what they seem to have. Currently, I only have SQL query ability into the data unless I pull it onto a server. Is there a way of doing more, i.e direct pandas sort of work? I've heard about Databricks and Spark and have a vague idea of distributing data and processing power across clusters, but don't know if that meshes with what I'm doing? As far as I know, S3 is a distributed file system but is a cluster somewhat different? I was asked why I didn't put my metadata in the bucket as well and I didn't have an answer. I just felt that the metadata seemed more warehousey than lakey; more CRUD. Is that me hanging on to a past I didn't know I had? The broader question is: how do I explain what I've done in the context of modern data architectures? Any book recommendations are also welcome.", "author_fullname": "t2_djdhkrg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a thing. What is it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jn42d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674507043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started out as an analyst in a small company about a year ago with the keys to an AWS account. I&amp;#39;ve spent the year organising my team&amp;#39;s data into an S3 bucket and using python scripts to create the necessary pipelines into and out of the bucket. The files are in parquet format and partitioned, with an Athena database sitting on top for querying. The metadata that manages what is in the bucket is sat in an SQL Server database. When I want to slice and process the files in the bucket, I query the metadata tables and use that to query the bucket.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s all running nicely but I&amp;#39;m totally unaware of what I&amp;#39;ve built and how to contextualise it. Is it just an organised lake? I read about lakehouses but it doesn&amp;#39;t seem to have a lot of what they seem to have. Currently, I only have SQL query ability into the data unless I pull it onto a server. Is there a way of doing more, i.e direct pandas sort of work? I&amp;#39;ve heard about Databricks and Spark and have a vague idea of distributing data and processing power across clusters, but don&amp;#39;t know if that meshes with what I&amp;#39;m doing? As far as I know, S3 is a distributed file system but is a cluster somewhat different? I was asked why I didn&amp;#39;t put my metadata in the bucket as well and I didn&amp;#39;t have an answer. I just felt that the metadata seemed more warehousey than lakey; more CRUD. Is that me hanging on to a past I didn&amp;#39;t know I had? The broader question is: how do I explain what I&amp;#39;ve done in the context of modern data architectures? Any book recommendations are also welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jn42d", "is_robot_indexable": true, "report_reasons": null, "author": "user192034", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jn42d/i_made_a_thing_what_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jn42d/i_made_a_thing_what_is_it/", "subreddit_subscribers": 87270, "created_utc": 1674507043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to map out all the new data tools out there:  \n\n\n* what they are uniquely good at?\n* what is the compelling change in the data landscape that justified their creation?\n* how the big industry vertical (observability &amp; quality, ETL/ELT, catalog, etc) evolved?\n\n&amp;#x200B;\n\nCan you help me identify the missing tools ? or share feedback to improve it? Still WIP\n\n[notion.castordoc.com](https://notion.castordoc.com)\n\nhttps://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping of modern data tools. is anything missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzgt871o2zda1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/DASHPlaylist.mpd?a=1677159502%2CYzg4MjRmNzhlOTkwN2UxOWE0OTcwMzYzNzNkODZlMDNhN2Q4N2IxNWVhZmRjMzUyYmRiYTdkM2Y2NGQ2MDg0Nw%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 650, "hlsUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/HLSPlaylist.m3u8?a=1677159502%2CZTgxYjJmMGY4NjY2ODlhZmZmZjUwYTAxOGViMTE3NWIwOTIyZmUyZjM5NjJhNDE2YjMzMWJhZGU2ZjZmYTRjYw%3D%3D&amp;v=1&amp;f=sd", "id": "lzgt871o2zda1", "isGif": false}}, "name": "t3_10k2xtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qcNush-DcKxbOl5jzV21hd4EmfaF2DW8BG8pzdZ1Lr4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674558065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to map out all the new data tools out there:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;what they are uniquely good at?&lt;/li&gt;\n&lt;li&gt;what is the compelling change in the data landscape that justified their creation?&lt;/li&gt;\n&lt;li&gt;how the big industry vertical (observability &amp;amp; quality, ETL/ELT, catalog, etc) evolved?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you help me identify the missing tools ? or share feedback to improve it? Still WIP&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://notion.castordoc.com\"&gt;notion.castordoc.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player\"&gt;https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?auto=webp&amp;v=enabled&amp;s=83cbc10fd4df6f44787372d68831810403aa9a14", "width": 1516, "height": 852}, "resolutions": [{"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b80a1518187141cbeddce8c9756f1c9630539e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9466ba8a631fd0e72dc07198853c267a5a92f5a8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a398acec2128e9e96f2ef215b665d8f774fe64c0", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c68957f80ec2e3e30ac9cbb7773659784a177240", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=254ca3886eca2742c0c53d83b75fa208349f348e", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=400e8d6d97cb1c16e9c69504055ac6fe3d72de26", "width": 1080, "height": 606}], "variants": {}, "id": "6Zrev7FNgQrSU-pVnPXLXOHk0ZVzaBxLXy4KWXRD8tI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10k2xtm", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "subreddit_subscribers": 87270, "created_utc": 1674558065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ec0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Thoughts on which resume style is better and overall review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"krxbxso96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df3c4db70ae0334dd4f5808b18bca3c8aac2fd9d"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c05ec74c0a36553a3b792b1da8a6e4b536c50150"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42e5fdd1b4561f4991ce2362da81dc239e7e13b4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1151cbc4ef9a0ea1551e8fa87195d89bb3332412"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b53b42054defed670d2e446f5d14a1e06421cdb"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02304a91a7717067afb2fe626c113819ae04ec14"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=60422c57f70fbfd8c48ce38faa0a5c266ed1c5f4"}, "id": "krxbxso96xda1"}, "ugoxbuo96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3a75ce5f7dc4acdb2df9a230dc5090b0cf35783"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de64671d09ea2e020252f7ff132a2c7698fd81e3"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb23cae0e7e029680e8191770307f412740f9ee4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6758459d856a0537d67ebea09ed62f50da79a577"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7094667e97568393d73d765694ff8cd38e1dfe00"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b091c640f5ebb1189ae4f639c54a4d857e1e7bc5"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30d7f6de319107d1ca570d59af27ff0fed7ffd16"}, "id": "ugoxbuo96xda1"}}, "name": "t3_10jx7b5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": "transparent", "ups": 3, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "krxbxso96xda1", "id": 233003708}, {"media_id": "ugoxbuo96xda1", "id": 233003709}]}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lJx4kE5BiWPmNnteoQZf0C5TPgtI922M30_ZSyRpVw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674534864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10jx7b5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10jx7b5", "is_robot_indexable": true, "report_reasons": null, "author": "mistanervous", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10jx7b5/thoughts_on_which_resume_style_is_better_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10jx7b5", "subreddit_subscribers": 87270, "created_utc": 1674534864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you", "author_fullname": "t2_r509bej6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nested json and xml", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jwid4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674532607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jwid4", "is_robot_indexable": true, "report_reasons": null, "author": "mediocrX", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "subreddit_subscribers": 87270, "created_utc": 1674532607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!", "author_fullname": "t2_8e3c179e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workflows vs Airflow/Dagsterr/Prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10juwum", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674527635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10juwum", "is_robot_indexable": true, "report_reasons": null, "author": "jaredfromspacecamp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "subreddit_subscribers": 87270, "created_utc": 1674527635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nLooking for an optimize/efficient way to extract data coming from an onprem mssql table to google bigquery. \nThe table schema type are all varchar which is being manage by other department and we only have a read only permission for the table. \n\nOur current setup is to use google dataflow to get the data coming from our on prem database. This is doable however, the data pull would be inefficient since there are no index and the timestamp column of the table has a schema of varchar.    \n\nI was thinking about Converting the timestamp column to timestamp/datetime  but i believe it would take too long as it would convert every row first before applying the filter. \n\nThe goal is to create a batch pipeline for the latest upload.   \n\nPlease advice,  \nThanks", "author_fullname": "t2_are11xb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EL for mssql db with no index all schema type are varchar", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jlbyy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674502741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Looking for an optimize/efficient way to extract data coming from an onprem mssql table to google bigquery. \nThe table schema type are all varchar which is being manage by other department and we only have a read only permission for the table. &lt;/p&gt;\n\n&lt;p&gt;Our current setup is to use google dataflow to get the data coming from our on prem database. This is doable however, the data pull would be inefficient since there are no index and the timestamp column of the table has a schema of varchar.    &lt;/p&gt;\n\n&lt;p&gt;I was thinking about Converting the timestamp column to timestamp/datetime  but i believe it would take too long as it would convert every row first before applying the filter. &lt;/p&gt;\n\n&lt;p&gt;The goal is to create a batch pipeline for the latest upload.   &lt;/p&gt;\n\n&lt;p&gt;Please advice,&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jlbyy", "is_robot_indexable": true, "report_reasons": null, "author": "Sublime-01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jlbyy/el_for_mssql_db_with_no_index_all_schema_type_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jlbyy/el_for_mssql_db_with_no_index_all_schema_type_are/", "subreddit_subscribers": 87270, "created_utc": 1674502741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn't any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.", "author_fullname": "t2_84sa46kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jw0jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674531016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn&amp;#39;t any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jw0jc", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient-Bet-8513", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jw0jc/apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jw0jc/apache_spark/", "subreddit_subscribers": 87270, "created_utc": 1674531016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nJust gathering feedback on Cloud Data Integration service on IDMC. Any thoughts/comments on this ?\n\nThanks!", "author_fullname": "t2_4mdsqonb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on Cloud Data Integration service with Informatica's IDMC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jmyxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674506701.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Just gathering feedback on Cloud Data Integration service on IDMC. Any thoughts/comments on this ?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10jmyxr", "is_robot_indexable": true, "report_reasons": null, "author": "vrakshith28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jmyxr/feedback_on_cloud_data_integration_service_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jmyxr/feedback_on_cloud_data_integration_service_with/", "subreddit_subscribers": 87270, "created_utc": 1674506701.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In late 2020, I published [the results](https://www.jesse-anderson.com/2020/12/data-teams-survey-results/) of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we're moving past COVID and into a post-COVID world. Please take some time to fill out [the survey](https://forms.gle/qEdXkB9N395HuAaN7). It shouldn't take more than five minutes to fill out.\n\nIn a bit, I'll write a post talking about the results and comparing them to the previous year's results. I expect we'll see some progression and some interesting correlation between value and teams present.", "author_fullname": "t2_5pxn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Teams Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k1htk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674551710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In late 2020, I published &lt;a href=\"https://www.jesse-anderson.com/2020/12/data-teams-survey-results/\"&gt;the results&lt;/a&gt; of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we&amp;#39;re moving past COVID and into a post-COVID world. Please take some time to fill out &lt;a href=\"https://forms.gle/qEdXkB9N395HuAaN7\"&gt;the survey&lt;/a&gt;. It shouldn&amp;#39;t take more than five minutes to fill out.&lt;/p&gt;\n\n&lt;p&gt;In a bit, I&amp;#39;ll write a post talking about the results and comparing them to the previous year&amp;#39;s results. I expect we&amp;#39;ll see some progression and some interesting correlation between value and teams present.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Mentor | Jesse Anderson", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k1htk", "is_robot_indexable": true, "report_reasons": null, "author": "eljefe6a", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k1htk/data_teams_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k1htk/data_teams_survey/", "subreddit_subscribers": 87270, "created_utc": 1674551710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14djpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need your help - Participants wanted for my Master Thesis Survey \u201cAnalysis of the influence of quality assurance on the development of machine learning products\u201d (Every single response is highly appreciated! Big thank you in advance!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10k2ham", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/s02o-QW_mCE9hMvS_5BMZd_56S0fA8IBrILuXugTAq0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674556094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?auto=webp&amp;v=enabled&amp;s=5a852038a417c71993d03dfe5a82ee34a1ebac18", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ae20ac3149db614ed4d486cf8683b6036918112", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a0727e8f0faa1a71800e22773b4294acdd97d41", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67fe3461c7ab76bfdc5133c3fc54deb28e93ed02", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9e3d2e22417812b255e1ca1fd95b61154283edc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c57bcf00f08616276535721247c89c74a8f82028", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b62c734080c67b2eebb34e1c4f9dd26b13ecbccb", "width": 1080, "height": 567}], "variants": {}, "id": "TuzIvYHgwjvuLzF64CS432uQ3fOCi2MJFLPDFLxrItg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k2ham", "is_robot_indexable": true, "report_reasons": null, "author": "felix-reddit", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2ham/need_your_help_participants_wanted_for_my_master/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "subreddit_subscribers": 87270, "created_utc": 1674556094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a post about creating a CICD pipeline using Github Actions for ETL jobs. I wanted to share with folks here for feedback and suggestions on how to improve/optimize my recommendations.  [https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication](https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication)", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CICD for data pipelines using Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jcc8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674480046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a post about creating a CICD pipeline using Github Actions for ETL jobs. I wanted to share with folks here for feedback and suggestions on how to improve/optimize my recommendations.  &lt;a href=\"https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication\"&gt;https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?auto=webp&amp;v=enabled&amp;s=61f05f5efdaab9d2aadb67b4f8445aa456d39b88", "width": 1856, "height": 765}, "resolutions": [{"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=015542d9fc1aaec0d3e31d33b54fcecf121c5789", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e8b2ac637ca1fcb666232302c8041d6669c050c", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7c752c33f853c46268d2c351eb99cd1bf8688ee", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4616db014136813f2ec66d19a7725b794e6fe70", "width": 640, "height": 263}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c81d8aefcab4d7198ea1cff071cf1e2e11e6d81", "width": 960, "height": 395}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3386602bfced0f3c4ff23aae85924db63e9a9c0", "width": 1080, "height": 445}], "variants": {}, "id": "a2TEN80IVj95i-oqeVGuwTnpm5OLg60lPCujEK133ss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10jcc8l", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jcc8l/cicd_for_data_pipelines_using_github_actions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jcc8l/cicd_for_data_pipelines_using_github_actions/", "subreddit_subscribers": 87270, "created_utc": 1674480046.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}