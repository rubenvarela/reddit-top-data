{"kind": "Listing", "data": {"after": "t3_10k2ham", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any openly available data engineering projects using Scala and Spark which follow industry conventions like proper folder/package structures and object oriented division of classes/concerns? Most examples I\u2019ve seen have everything in one file without proper separation of concerns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jyjej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674539522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jyjej", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "subreddit_subscribers": 87324, "created_utc": 1674539522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to map out all the new data tools out there:  \n\n\n* what they are uniquely good at?\n* what is the compelling change in the data landscape that justified their creation?\n* how the big industry vertical (observability &amp; quality, ETL/ELT, catalog, etc) evolved?\n\n&amp;#x200B;\n\nCan you help me identify the missing tools ? or share feedback to improve it? Still WIP\n\n[notion.castordoc.com](https://notion.castordoc.com)\n\nhttps://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping of modern data tools. is anything missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzgt871o2zda1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/DASHPlaylist.mpd?a=1677188304%2CMjhlNmEzZTZlNjM2ZTU3MDQ1YjIwNmJkMWI4YzY4YzExM2Q2NjYzMjg3ZjEzMGJlNTgxMWRjMzg2YTFhMTAxYQ%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 650, "hlsUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/HLSPlaylist.m3u8?a=1677188304%2CODE4ZDg5NTJkYWE0OWRlY2RjOTgyNjljMmE3NzI2MjI3MTkxMGYwZTY4NzRmYjdkM2FjZWVhNDI5MTBkNjk2Yg%3D%3D&amp;v=1&amp;f=sd", "id": "lzgt871o2zda1", "isGif": false}}, "name": "t3_10k2xtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qcNush-DcKxbOl5jzV21hd4EmfaF2DW8BG8pzdZ1Lr4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674558065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to map out all the new data tools out there:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;what they are uniquely good at?&lt;/li&gt;\n&lt;li&gt;what is the compelling change in the data landscape that justified their creation?&lt;/li&gt;\n&lt;li&gt;how the big industry vertical (observability &amp;amp; quality, ETL/ELT, catalog, etc) evolved?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you help me identify the missing tools ? or share feedback to improve it? Still WIP&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://notion.castordoc.com\"&gt;notion.castordoc.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player\"&gt;https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?auto=webp&amp;v=enabled&amp;s=83cbc10fd4df6f44787372d68831810403aa9a14", "width": 1516, "height": 852}, "resolutions": [{"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b80a1518187141cbeddce8c9756f1c9630539e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9466ba8a631fd0e72dc07198853c267a5a92f5a8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a398acec2128e9e96f2ef215b665d8f774fe64c0", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c68957f80ec2e3e30ac9cbb7773659784a177240", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=254ca3886eca2742c0c53d83b75fa208349f348e", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=400e8d6d97cb1c16e9c69504055ac6fe3d72de26", "width": 1080, "height": 606}], "variants": {}, "id": "6Zrev7FNgQrSU-pVnPXLXOHk0ZVzaBxLXy4KWXRD8tI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k2xtm", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "subreddit_subscribers": 87324, "created_utc": 1674558065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI'm wondering what is the most common architecture to implement CDC (change data capture) at your company?  I've seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. ", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you implement CDC in your organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6sev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674571008.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674570721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what is the most common architecture to implement CDC (change data capture) at your company?  I&amp;#39;ve seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k6sev", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "subreddit_subscribers": 87324, "created_utc": 1674570721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week, I made a post in this sub\\[1\\] &amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.\n\nBased on the feedback (thanks, by the way!), I've updated my blog post\\[2\\] and included the example calculation I posted on Reddit.\n\nAnyway, here's the \"checklist\" that guided the calculations made in my previous Reddit post, with links at the bottom:\n\n\\-\n\n*When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).*\n\n## Up-front costs\n\n* software cost &amp; licensing, if applicable\n* learning &amp; education\n* implementation &amp; testing (including data migration costs)\n* documentation &amp; knowledge sharing\n* customization\n\n## Ongoing costs\n\n* direct infrastructure costs (e.g., hosting &amp; storage)\n* backup infrastructure costs (e.g., failover &amp; additional AZs)\n* supporting infrastructure costs (e.g., monitoring &amp; alerting)\n* maintenance, patches/upgrades, &amp; support\n* feature additions\n\n## Team &amp; opportunity costs\n\n* hiring to replace the engineers now working with the new software\n* time spent on infrastructure that could otherwise be spent on core product\n\n\\-\n\n\\[1\\]: [https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback\\_request\\_tco\\_calculation\\_for\\_apache\\_kafka](https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka) (link to the Reddit post in this sub if you're curious)\n\n\\[2\\]: [https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership](https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership) (link to the full blog post)", "author_fullname": "t2_fv515", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should you build or buy your infra? Checklist for calculating the costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8hwn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week, I made a post in this sub[1] &amp;amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.&lt;/p&gt;\n\n&lt;p&gt;Based on the feedback (thanks, by the way!), I&amp;#39;ve updated my blog post[2] and included the example calculation I posted on Reddit.&lt;/p&gt;\n\n&lt;p&gt;Anyway, here&amp;#39;s the &amp;quot;checklist&amp;quot; that guided the calculations made in my previous Reddit post, with links at the bottom:&lt;/p&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).&lt;/em&gt;&lt;/p&gt;\n\n&lt;h2&gt;Up-front costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;software cost &amp;amp; licensing, if applicable&lt;/li&gt;\n&lt;li&gt;learning &amp;amp; education&lt;/li&gt;\n&lt;li&gt;implementation &amp;amp; testing (including data migration costs)&lt;/li&gt;\n&lt;li&gt;documentation &amp;amp; knowledge sharing&lt;/li&gt;\n&lt;li&gt;customization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Ongoing costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;direct infrastructure costs (e.g., hosting &amp;amp; storage)&lt;/li&gt;\n&lt;li&gt;backup infrastructure costs (e.g., failover &amp;amp; additional AZs)&lt;/li&gt;\n&lt;li&gt;supporting infrastructure costs (e.g., monitoring &amp;amp; alerting)&lt;/li&gt;\n&lt;li&gt;maintenance, patches/upgrades, &amp;amp; support&lt;/li&gt;\n&lt;li&gt;feature additions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Team &amp;amp; opportunity costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;hiring to replace the engineers now working with the new software&lt;/li&gt;\n&lt;li&gt;time spent on infrastructure that could otherwise be spent on core product&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;[1]: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka\"&gt;https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka&lt;/a&gt; (link to the Reddit post in this sub if you&amp;#39;re curious)&lt;/p&gt;\n\n&lt;p&gt;[2]: &lt;a href=\"https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership\"&gt;https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership&lt;/a&gt; (link to the full blog post)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?auto=webp&amp;v=enabled&amp;s=bc75ae8dfc3a23aef5ce6c9c684b8c0ce4aadc9c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85db55ab11391be72234810a79e3dcc7b703e485", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb355f3b10a18334c292ab6e5f0bdea646415ddd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34774c95e96d5971688ba110ec64c5de89ddc031", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=756094fe0e52623c08186904a6093cbc205c7a4f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f0ca72492d9c7a61e0d93bd36d4b1835b76dfa6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13730358324cec31bf695d246eeaa64b772eea58", "width": 1080, "height": 567}], "variants": {}, "id": "vj-wMdrGC9Ek6GbFlDkgWr7MDOA5uPlbmoApWsvlMkU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8hwn", "is_robot_indexable": true, "report_reasons": null, "author": "propjames", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "subreddit_subscribers": 87324, "created_utc": 1674575369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. \n\nSome important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. \n\nThe current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.\n\nWhat I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.\n\nThe tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.\n\nI\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.\n\nThank you in advance!", "author_fullname": "t2_az62upwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas ETL - looking for thoughts on current process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jpjev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674512906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data  Engineers - long time lurker but first time poster here looking for some recommendations / thoughts. I\u2019m currently a data analyst but have been more interested in getting into the DE side of things for a while. Recently I was given a great opportunity to start my transition by reassessing how my team handles incoming data and essentially start from scratch with a new solution that I can implement. &lt;/p&gt;\n\n&lt;p&gt;Some important points to keep in mind: this process is not business critical and it only needs to run once a month. Data comes in from 3rd party company once a month in CSV file format. Typically between 150-200K rows each and 7/8 files. The files come in very messy and usually require some formatting, QC checks and minor cleaning before it makes any sense. &lt;/p&gt;\n\n&lt;p&gt;The current process:\n- Files stored in OneDrive and read into Alteryx where some transformations are done before writing to a SQL table. Each file has their own corresponding flattened table.\n- These tables are then used in another alteryx workflow which does quite a few transformations mainly involving column &amp;amp; row wise calculations and doesn\u2019t require many joins to other tables. The result of this workflow is stored in another table in the same database which is then used for BI.\n- The main issue with this is the Alteryx workflow takes 15/16 hours to complete and I just believe it\u2019s becoming a bit obsolete. It also involves a lot of manual updates each month to point to the new files.&lt;/p&gt;\n\n&lt;p&gt;What I\u2019ve brainstormed as a potential solution (please be kind, this is my first DE project).\n- Python script to run when the files come in which uses Pandas for some computations and cleansing such as adding columns, renaming, filling nulls and changing data types. \n- I dump the result of this Python script into SQL server using SQLAlchemy. I assume these tables function more like a data lake. Again each file has its own flat table. The files themselves don\u2019t have any relation to eachother so having fact and dim tables I\u2019m not sure makes sense here (?)\n- The plan is to then create Python scripts to read data out from these tables, do transformations on them and enhance the data mainly using lambdas and other custom functions. The output will be a table that the analysts can connect to and simply query for BI.&lt;/p&gt;\n\n&lt;p&gt;The tools available immediately that I\u2019d like to use mostly are obviously SQL (SQL Server) &amp;amp; Python. I\u2019ve also read about Polars which may be an alternative to doing all my transformations in Pandas. We currently don\u2019t have any S3 instances or anything cloud based.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d appreciate any thoughts, recommendations or resources that you think may be helpful. I\u2019m trying to learn as much as possible for this project and make it as automated and efficient as can be.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jpjev", "is_robot_indexable": true, "report_reasons": null, "author": "hektar9987", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jpjev/pandas_etl_looking_for_thoughts_on_current_process/", "subreddit_subscribers": 87324, "created_utc": 1674512906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.\n\nhttps://www.databricks.com/learn/certification/machine-learning-associate", "author_fullname": "t2_adn81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Scalable Machine Learning with Apache Spark Certification Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jtqzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674524169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone taken this certification exam? There are no practice tests available and the learning path is mediocre at best. Any tools, references, or insight to the exam would be helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/learn/certification/machine-learning-associate\"&gt;https://www.databricks.com/learn/certification/machine-learning-associate&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jtqzb", "is_robot_indexable": true, "report_reasons": null, "author": "milehighmecked", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jtqzb/databricks_scalable_machine_learning_with_apache/", "subreddit_subscribers": 87324, "created_utc": 1674524169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7ec0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Thoughts on which resume style is better and overall review?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"krxbxso96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df3c4db70ae0334dd4f5808b18bca3c8aac2fd9d"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c05ec74c0a36553a3b792b1da8a6e4b536c50150"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42e5fdd1b4561f4991ce2362da81dc239e7e13b4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1151cbc4ef9a0ea1551e8fa87195d89bb3332412"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b53b42054defed670d2e446f5d14a1e06421cdb"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02304a91a7717067afb2fe626c113819ae04ec14"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/krxbxso96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=60422c57f70fbfd8c48ce38faa0a5c266ed1c5f4"}, "id": "krxbxso96xda1"}, "ugoxbuo96xda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3a75ce5f7dc4acdb2df9a230dc5090b0cf35783"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de64671d09ea2e020252f7ff132a2c7698fd81e3"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb23cae0e7e029680e8191770307f412740f9ee4"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6758459d856a0537d67ebea09ed62f50da79a577"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7094667e97568393d73d765694ff8cd38e1dfe00"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b091c640f5ebb1189ae4f639c54a4d857e1e7bc5"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/ugoxbuo96xda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30d7f6de319107d1ca570d59af27ff0fed7ffd16"}, "id": "ugoxbuo96xda1"}}, "name": "t3_10jx7b5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": "transparent", "ups": 10, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "krxbxso96xda1", "id": 233003708}, {"media_id": "ugoxbuo96xda1", "id": 233003709}]}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/lJx4kE5BiWPmNnteoQZf0C5TPgtI922M30_ZSyRpVw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674534864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10jx7b5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10jx7b5", "is_robot_indexable": true, "report_reasons": null, "author": "mistanervous", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10jx7b5/thoughts_on_which_resume_style_is_better_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10jx7b5", "subreddit_subscribers": 87324, "created_utc": 1674534864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. \n\nWe use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn't it an antipattern a little bit? Or its a \"normal\"/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).\n\nNot really sure, appreciate any comment. Thank you.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k977n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674577191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. &lt;/p&gt;\n\n&lt;p&gt;We use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn&amp;#39;t it an antipattern a little bit? Or its a &amp;quot;normal&amp;quot;/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).&lt;/p&gt;\n\n&lt;p&gt;Not really sure, appreciate any comment. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k977n", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k977n/streaming_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k977n/streaming_data_storage/", "subreddit_subscribers": 87324, "created_utc": 1674577191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are a technical team proficient in SWE skills, so we're happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I'm missing why we should use it?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs custom pyspark for transformations in databricks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kagoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a technical team proficient in SWE skills, so we&amp;#39;re happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I&amp;#39;m missing why we should use it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kagoh", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "subreddit_subscribers": 87324, "created_utc": 1674580409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first job and I am too excited/anxious.\n\nMy current skills - Python, SQL", "author_fullname": "t2_u33aam84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What responsibilities can I expect for a Data Integration Intern?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kb11a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674581759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first job and I am too excited/anxious.&lt;/p&gt;\n\n&lt;p&gt;My current skills - Python, SQL&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kb11a", "is_robot_indexable": true, "report_reasons": null, "author": "scanip", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "subreddit_subscribers": 87324, "created_utc": 1674581759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post about the fundamentals of data modelling from my POV. I'd be really interested in people's opinions. \n\nTLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.", "author_fullname": "t2_7srfj4fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling blog post - thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6zd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674571279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dantelore.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post about the fundamentals of data modelling from my POV. I&amp;#39;d be really interested in people&amp;#39;s opinions. &lt;/p&gt;\n\n&lt;p&gt;TLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dantelore.com/posts/simplest-data-model/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k6zd1", "is_robot_indexable": true, "report_reasons": null, "author": "DanteLore1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6zd1/data_modelling_blog_post_thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dantelore.com/posts/simplest-data-model/", "subreddit_subscribers": 87324, "created_utc": 1674571279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.\n\nI was looking at this write up of Sql server's implementation https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\n\nAnd it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn't necessarily guaranteed. \n\nSo theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn't generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustered Index Lookup Efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8ftz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.&lt;/p&gt;\n\n&lt;p&gt;I was looking at this write up of Sql server&amp;#39;s implementation &lt;a href=\"https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\"&gt;https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn&amp;#39;t necessarily guaranteed. &lt;/p&gt;\n\n&lt;p&gt;So theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn&amp;#39;t generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?auto=webp&amp;v=enabled&amp;s=f68a5246a58720c9fc4a6173406989931fe0f17c", "width": 542, "height": 271}, "resolutions": [{"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76e0bbd89dd768d12decfc2099c8f4a1aace4fa2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc6e621801eed6fdbf7999dba6ca1a48512b4407", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b445e25cd760a4ec5b906a01ac8df66a015b862b", "width": 320, "height": 160}], "variants": {}, "id": "w5ngVr1pMtH7vZrtkUTkbaXCV87rbMoiKjqUpVh8oE4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8ftz", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "subreddit_subscribers": 87324, "created_utc": 1674575213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you", "author_fullname": "t2_r509bej6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nested json and xml", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jwid4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674532607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a tutorial (paid/free) or some resources which teach you how to handle nested json and xml in either glue or simple pyspark.\nI came across relationalize in glue but it creates new data frames and their collections. Plus the data gets doubled or something.\nLike how would I load the data into tables, what would be impact if my data was doubled. All this stuff is making me confused as hell.\nIf you know any chapter in book/video/article which can lesser my misery, please let me know.\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jwid4", "is_robot_indexable": true, "report_reasons": null, "author": "mediocrX", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jwid4/nested_json_and_xml/", "subreddit_subscribers": 87324, "created_utc": 1674532607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!", "author_fullname": "t2_8e3c179e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks workflows vs Airflow/Dagsterr/Prefect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10juwum", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674527635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what is the point of airflow etc when databricks workflows orchestrates python tasks? isn\u2019t airflow/dagster etc just orchestrators of python tasks? what do they offer that cant be done with databricks workflows? \nthank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10juwum", "is_robot_indexable": true, "report_reasons": null, "author": "jaredfromspacecamp", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10juwum/databricks_workflows_vs_airflowdagsterrprefect/", "subreddit_subscribers": 87324, "created_utc": 1674527635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of building a new data infrastructure for a small company. \n\nWould something like this make sense?\n\nData flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools\n\nI am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdz9e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674588909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of building a new data infrastructure for a small company. &lt;/p&gt;\n\n&lt;p&gt;Would something like this make sense?&lt;/p&gt;\n\n&lt;p&gt;Data flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools&lt;/p&gt;\n\n&lt;p&gt;I am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdz9e", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "subreddit_subscribers": 87324, "created_utc": 1674588909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. \n\nIt is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?\n\nI really like features of Delta but we do not want to use Spark :)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta without using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdje4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674587813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. &lt;/p&gt;\n\n&lt;p&gt;It is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?&lt;/p&gt;\n\n&lt;p&gt;I really like features of Delta but we do not want to use Spark :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdje4", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "subreddit_subscribers": 87324, "created_utc": 1674587813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. \n\nDefinitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. \n\nWhat do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. \n\nOne rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. \n\nHow do you troubleshoot data issues in prod?", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debugging data errors and inconsistencies in downstream dashboards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8dtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. &lt;/p&gt;\n\n&lt;p&gt;Definitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. &lt;/p&gt;\n\n&lt;p&gt;What do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. &lt;/p&gt;\n\n&lt;p&gt;One rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. &lt;/p&gt;\n\n&lt;p&gt;How do you troubleshoot data issues in prod?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Applied Data &amp; ML Engineer | Developer Advocate", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8dtf", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "subreddit_subscribers": 87324, "created_utc": 1674575067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn't any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.", "author_fullname": "t2_84sa46kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jw0jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674531016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is Apache Spark is a good skill for growing my income. I am a Backend Engineer . I know a bit of Distributed Systems as well, Redis and NoSQL databases as well. I felt that Apache Spark is a good skill to learn and it is  better to contribute to Spark on K8s open source  given my familiarity with kubernetes.  I thought that even though it doesn&amp;#39;t any immediate result, it might just make myself better engineer long term once I have that skill set also. Perhaps to break into ML infra in future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10jw0jc", "is_robot_indexable": true, "report_reasons": null, "author": "Sufficient-Bet-8513", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jw0jc/apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jw0jc/apache_spark/", "subreddit_subscribers": 87324, "created_utc": 1674531016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I break every part of my ETL script in functions? (functional decomposition)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kfjab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674595774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10kfjab", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "subreddit_subscribers": 87324, "created_utc": 1674592656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\nI am learning data engineering for quiet few months . I am personally finding it difficult to do end to end projects as i am getting scattered all over and couldn't able to concentrate on single thing .I would really like to have a partner or a team of members where we could practice and build project together.    Would really appreciate if any one is up for it .", "author_fullname": "t2_9f657ejs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal project help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kfe3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;I am learning data engineering for quiet few months . I am personally finding it difficult to do end to end projects as i am getting scattered all over and couldn&amp;#39;t able to concentrate on single thing .I would really like to have a partner or a team of members where we could practice and build project together.    Would really appreciate if any one is up for it .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfe3n", "is_robot_indexable": true, "report_reasons": null, "author": "TelephoneGlad8459", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfe3n/personal_project_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfe3n/personal_project_help_needed/", "subreddit_subscribers": 87324, "created_utc": 1674592311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.\n\n1. (ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.\n2. (ETL) Export already transformed data daily from data service, save to Google BigQuery.\n\nOption 1 would incur more storage costs but that should be mostly negligible as it's only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?", "author_fullname": "t2_72tiq3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help choosing ETL vs ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kfcr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;(ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.&lt;/li&gt;\n&lt;li&gt;(ETL) Export already transformed data daily from data service, save to Google BigQuery.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 1 would incur more storage costs but that should be mostly negligible as it&amp;#39;s only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfcr4", "is_robot_indexable": true, "report_reasons": null, "author": "ROCKITZ15", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "subreddit_subscribers": 87324, "created_utc": 1674592221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.\n\nIs there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings", "author_fullname": "t2_8jq30m4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trunk based development with SSIS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10kfb0p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfb0p", "is_robot_indexable": true, "report_reasons": null, "author": "patheticadam", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "subreddit_subscribers": 87324, "created_utc": 1674592109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I'm familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): \n\n1.Pyspark\n\n 2.Pytorch /Pandas \n\nI don't have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?", "author_fullname": "t2_vh9qo8up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Preparation for Data Engineering in 15 days backend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kamzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I&amp;#39;m familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): &lt;/p&gt;\n\n&lt;p&gt;1.Pyspark&lt;/p&gt;\n\n&lt;p&gt;2.Pytorch /Pandas &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10kamzt", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Crazy-9444", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "subreddit_subscribers": 87324, "created_utc": 1674580842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In late 2020, I published [the results](https://www.jesse-anderson.com/2020/12/data-teams-survey-results/) of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we're moving past COVID and into a post-COVID world. Please take some time to fill out [the survey](https://forms.gle/qEdXkB9N395HuAaN7). It shouldn't take more than five minutes to fill out.\n\nIn a bit, I'll write a post talking about the results and comparing them to the previous year's results. I expect we'll see some progression and some interesting correlation between value and teams present.", "author_fullname": "t2_5pxn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Teams Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k1htk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674551710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In late 2020, I published &lt;a href=\"https://www.jesse-anderson.com/2020/12/data-teams-survey-results/\"&gt;the results&lt;/a&gt; of my first survey\u00a0on data teams. I want to update this survey with the latest status, given that we&amp;#39;re moving past COVID and into a post-COVID world. Please take some time to fill out &lt;a href=\"https://forms.gle/qEdXkB9N395HuAaN7\"&gt;the survey&lt;/a&gt;. It shouldn&amp;#39;t take more than five minutes to fill out.&lt;/p&gt;\n\n&lt;p&gt;In a bit, I&amp;#39;ll write a post talking about the results and comparing them to the previous year&amp;#39;s results. I expect we&amp;#39;ll see some progression and some interesting correlation between value and teams present.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Mentor | Jesse Anderson", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k1htk", "is_robot_indexable": true, "report_reasons": null, "author": "eljefe6a", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k1htk/data_teams_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k1htk/data_teams_survey/", "subreddit_subscribers": 87324, "created_utc": 1674551710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14djpe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need your help - Participants wanted for my Master Thesis Survey \u201cAnalysis of the influence of quality assurance on the development of machine learning products\u201d (Every single response is highly appreciated! Big thank you in advance!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10k2ham", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/s02o-QW_mCE9hMvS_5BMZd_56S0fA8IBrILuXugTAq0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674556094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?auto=webp&amp;v=enabled&amp;s=5a852038a417c71993d03dfe5a82ee34a1ebac18", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ae20ac3149db614ed4d486cf8683b6036918112", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a0727e8f0faa1a71800e22773b4294acdd97d41", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67fe3461c7ab76bfdc5133c3fc54deb28e93ed02", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9e3d2e22417812b255e1ca1fd95b61154283edc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c57bcf00f08616276535721247c89c74a8f82028", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/F5eGCbSJyTpe5_hO3PpoiDFCA3TMr-ydY3w25k6XowM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b62c734080c67b2eebb34e1c4f9dd26b13ecbccb", "width": 1080, "height": 567}], "variants": {}, "id": "TuzIvYHgwjvuLzF64CS432uQ3fOCi2MJFLPDFLxrItg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10k2ham", "is_robot_indexable": true, "report_reasons": null, "author": "felix-reddit", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2ham/need_your_help_participants_wanted_for_my_master/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLScv3mfqxT3_4i1S5PIcGNlJIOfpRhBkWxaC5YJx6maaDzOydA/viewform", "subreddit_subscribers": 87324, "created_utc": 1674556094.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}