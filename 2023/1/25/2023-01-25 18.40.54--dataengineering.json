{"kind": "Listing", "data": {"after": "t3_10kv0er", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I did it! After 8 months of working as a budtender for minimum wage post-graduation, more than 400 job applications, and 12 interviews with different companies I finally landed a role as a data engineer. I still couldn't believe it till my first day, which was yesterday. Just got my laptop, fob, and ID card, still feels so unreal. Learned a lot from this sub and I'm forever grateful for you guys.", "author_fullname": "t2_mtxnq3u8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally got a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kl6lg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 303, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 303, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674606710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did it! After 8 months of working as a budtender for minimum wage post-graduation, more than 400 job applications, and 12 interviews with different companies I finally landed a role as a data engineer. I still couldn&amp;#39;t believe it till my first day, which was yesterday. Just got my laptop, fob, and ID card, still feels so unreal. Learned a lot from this sub and I&amp;#39;m forever grateful for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kl6lg", "is_robot_indexable": true, "report_reasons": null, "author": "1000gratitudepunches", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kl6lg/finally_got_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kl6lg/finally_got_a_job/", "subreddit_subscribers": 87431, "created_utc": 1674606710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I break every part of my ETL script in functions? (functional decomposition)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfjab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674595774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10kfjab", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "subreddit_subscribers": 87431, "created_utc": 1674592656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR: First day, had to ask what a pipeline was.\n\nI was a junior web dev, but I really wasn't feeling it, so I tried to talk with a few connections I had and managed to get a job as a junior data engineer, but I honestly have no idea how. I went in the completely opposite direction people recommend you to do in the interview and said (in the fanciest way possible) I was only in the dev area, and seriously never had much interaction with data engineering, expecting to not get the job after saying that. No idea how it worked.\n\nAnd now here I am, at my second week, rushing Azure and Databricks courses like my life depends on it. \n\nNo but seriously, all jokes aside, it's been really fun. I honestly don't have much idea of what's going on, but my team was pretty aware of this and are helping me a lot. Wouldn't mind some general beginner tips, if possible. I'm already a mid level dev so only the new stuff is confusing me, like jobs and pipelines. Wish me luck :)", "author_fullname": "t2_105rol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got a job in data engineering. I have no idea what I am doing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kmmw7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674610797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: First day, had to ask what a pipeline was.&lt;/p&gt;\n\n&lt;p&gt;I was a junior web dev, but I really wasn&amp;#39;t feeling it, so I tried to talk with a few connections I had and managed to get a job as a junior data engineer, but I honestly have no idea how. I went in the completely opposite direction people recommend you to do in the interview and said (in the fanciest way possible) I was only in the dev area, and seriously never had much interaction with data engineering, expecting to not get the job after saying that. No idea how it worked.&lt;/p&gt;\n\n&lt;p&gt;And now here I am, at my second week, rushing Azure and Databricks courses like my life depends on it. &lt;/p&gt;\n\n&lt;p&gt;No but seriously, all jokes aside, it&amp;#39;s been really fun. I honestly don&amp;#39;t have much idea of what&amp;#39;s going on, but my team was pretty aware of this and are helping me a lot. Wouldn&amp;#39;t mind some general beginner tips, if possible. I&amp;#39;m already a mid level dev so only the new stuff is confusing me, like jobs and pipelines. Wish me luck :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kmmw7", "is_robot_indexable": true, "report_reasons": null, "author": "garfield3222", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kmmw7/i_got_a_job_in_data_engineering_i_have_no_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kmmw7/i_got_a_job_in_data_engineering_i_have_no_idea/", "subreddit_subscribers": 87431, "created_utc": 1674610797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a data engineer at a consulting firm and lately I\u2019m seeing many clients interested in moving their workloads to follow the data Lakehouse paradigm to get the best out of data lake and data warehouse (Usually Databricks with delta lake being the most preferred option). How does this affect cloud data warehouse vendors like Snowflake? Is Snowflake embracing Lakehouse?", "author_fullname": "t2_33bbwdty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Lakehouse a threat to Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kjilb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674602347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a data engineer at a consulting firm and lately I\u2019m seeing many clients interested in moving their workloads to follow the data Lakehouse paradigm to get the best out of data lake and data warehouse (Usually Databricks with delta lake being the most preferred option). How does this affect cloud data warehouse vendors like Snowflake? Is Snowflake embracing Lakehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kjilb", "is_robot_indexable": true, "report_reasons": null, "author": "Maiden_666", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kjilb/is_data_lakehouse_a_threat_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kjilb/is_data_lakehouse_a_threat_to_snowflake/", "subreddit_subscribers": 87431, "created_utc": 1674602347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_97hu3nt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can this \"BI developer\" role be a stepping stone to DE? (read comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10knjkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fJwurrK52ucNP8Lw3UvJ75pNb2vsU_ebUuxDDz_kD2Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674613410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yb142luf55ea1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yb142luf55ea1.jpg?auto=webp&amp;v=enabled&amp;s=d7df9119be9dbe0d6f13490c1c20f2d5532184b6", "width": 720, "height": 1480}, "resolutions": [{"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc06709cd9cc24150bd616eecc21f678e0233369", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d779272b26ce4bebe165fee255b4cc1f5027aaa0", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ba4166a5de44f969559cf201d9b8e47ecb48f13", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7275c22a9b414064e28d0ad5c6c9e1db06688c48", "width": 640, "height": 1280}], "variants": {}, "id": "BjOmXSv3kzWLcOvi0uU3VMaBRUoguBwLtNL14sQvWdY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10knjkv", "is_robot_indexable": true, "report_reasons": null, "author": "AmbitiousCase4992", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10knjkv/can_this_bi_developer_role_be_a_stepping_stone_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yb142luf55ea1.jpg", "subreddit_subscribers": 87431, "created_utc": 1674613410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "AWS defines a data lake as 'a centralised repository that allows you to store all your structure and unstructured data at any scale'. \n\nIf I put a bunch of files in Google Drive, have I created a data lake or is there something special about S3? I'm still struggling to pin down all the terminology for different types of data store.", "author_fullname": "t2_djdhkrg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Google Drive a data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10l1kxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674661332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AWS defines a data lake as &amp;#39;a centralised repository that allows you to store all your structure and unstructured data at any scale&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;If I put a bunch of files in Google Drive, have I created a data lake or is there something special about S3? I&amp;#39;m still struggling to pin down all the terminology for different types of data store.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10l1kxb", "is_robot_indexable": true, "report_reasons": null, "author": "user192034", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l1kxb/is_google_drive_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10l1kxb/is_google_drive_a_data_lake/", "subreddit_subscribers": 87431, "created_utc": 1674661332.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n I have to work on a project implemented with Azure Synapse Analytics Dedicated SQL. \nDo you have a book teaching all the best practices to put in place for the project?\n An example of an end to end datalake project developed with best practices?", "author_fullname": "t2_j68sac68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End to end project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kvmxa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674642547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello\n I have to work on a project implemented with Azure Synapse Analytics Dedicated SQL. \nDo you have a book teaching all the best practices to put in place for the project?\n An example of an end to end datalake project developed with best practices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kvmxa", "is_robot_indexable": true, "report_reasons": null, "author": "Playful-Sprinkles-27", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kvmxa/end_to_end_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kvmxa/end_to_end_project/", "subreddit_subscribers": 87431, "created_utc": 1674642547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Is a CS Minor worth the cost if it means that I stay in school 1.5 extra semesters when I already have an entry level DE job/opportunity lined up if I decide to graduate in May? Will it be beneficial long term to have that on resume (my major is Information Systems) - Both in terms of time and money - as I'd spend that time focusing on more specific foundational skills. Just not sure if that would at all be a big bonus to have for future (the CS minor)", "author_fullname": "t2_5rdbxa5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is CS Minor worth the cost for 1.5 extra semesters in school if already have entry level opportunity lined up? (Information Systems major) - both in terms of time and money - as I'd spend that time to focus on more specific foundational skills. Not sure the CS minor would be beneficial longterm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kh2ys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674596381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is a CS Minor worth the cost if it means that I stay in school 1.5 extra semesters when I already have an entry level DE job/opportunity lined up if I decide to graduate in May? Will it be beneficial long term to have that on resume (my major is Information Systems) - Both in terms of time and money - as I&amp;#39;d spend that time focusing on more specific foundational skills. Just not sure if that would at all be a big bonus to have for future (the CS minor)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kh2ys", "is_robot_indexable": true, "report_reasons": null, "author": "BDproximity7", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kh2ys/is_cs_minor_worth_the_cost_for_15_extra_semesters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kh2ys/is_cs_minor_worth_the_cost_for_15_extra_semesters/", "subreddit_subscribers": 87431, "created_utc": 1674596381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of building a new data infrastructure for a small company. \n\nWould something like this make sense?\n\nData flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools\n\nI am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdz9e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674588909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of building a new data infrastructure for a small company. &lt;/p&gt;\n\n&lt;p&gt;Would something like this make sense?&lt;/p&gt;\n\n&lt;p&gt;Data flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools&lt;/p&gt;\n\n&lt;p&gt;I am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdz9e", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "subreddit_subscribers": 87431, "created_utc": 1674588909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This morning I called in a plumber to fix my toilet that was clogged yet again (I live in an old building, infrastructure is pretty bad or deteriorated). The whole process took less than an hour. I watched him equip very long service gloves and shove a pressure spray down the toilet. He said if it didn't work he would use a professional toilet snake. It did work, so I paid for 4 \"uses of the pressure tool\" (wtf is this pricing model) and he left. \n\nLet me tell you, he charged a copious amount of money to do it. And it is the average price for this service in my area. I did the math and, if he visited one client per day, he would be making FOUR TIMES more than me, working as a junior data engineer.\n\nSo I'm thinking that I average around 10h per day in working my actual job and keeping up with new de technologies, coding exercises, solving bugs in personal projects etc. Also worrying about if my company will fire me in the next quarter or whether AI will halve job openings in the next 5 years.\n\nMeanwhile this guy can work 1 hour per day, and make four times my salary.\n\nI'm the real clown here.", "author_fullname": "t2_1fice0pt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of start fixing (real) pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kz9ag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674655214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This morning I called in a plumber to fix my toilet that was clogged yet again (I live in an old building, infrastructure is pretty bad or deteriorated). The whole process took less than an hour. I watched him equip very long service gloves and shove a pressure spray down the toilet. He said if it didn&amp;#39;t work he would use a professional toilet snake. It did work, so I paid for 4 &amp;quot;uses of the pressure tool&amp;quot; (wtf is this pricing model) and he left. &lt;/p&gt;\n\n&lt;p&gt;Let me tell you, he charged a copious amount of money to do it. And it is the average price for this service in my area. I did the math and, if he visited one client per day, he would be making FOUR TIMES more than me, working as a junior data engineer.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m thinking that I average around 10h per day in working my actual job and keeping up with new de technologies, coding exercises, solving bugs in personal projects etc. Also worrying about if my company will fire me in the next quarter or whether AI will halve job openings in the next 5 years.&lt;/p&gt;\n\n&lt;p&gt;Meanwhile this guy can work 1 hour per day, and make four times my salary.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the real clown here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kz9ag", "is_robot_indexable": true, "report_reasons": null, "author": "brotherkaramasov", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kz9ag/thinking_of_start_fixing_real_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kz9ag/thinking_of_start_fixing_real_pipelines/", "subreddit_subscribers": 87431, "created_utc": 1674655214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If it were up to me, I would say \u201c2 sprints every quarter to work on tech debt\u201d for the data teams. \n\nWishful thinking- I know!\n\nWhat would be your team\u2019s?", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you are to come up with one new year resolution for your data team, what would it be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kuct1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674637159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If it were up to me, I would say \u201c2 sprints every quarter to work on tech debt\u201d for the data teams. &lt;/p&gt;\n\n&lt;p&gt;Wishful thinking- I know!&lt;/p&gt;\n\n&lt;p&gt;What would be your team\u2019s?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Applied Data &amp; ML Engineer | Developer Advocate", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kuct1", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10kuct1/if_you_are_to_come_up_with_one_new_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kuct1/if_you_are_to_come_up_with_one_new_year/", "subreddit_subscribers": 87431, "created_utc": 1674637159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. \n\nIt is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?\n\nI really like features of Delta but we do not want to use Spark :)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta without using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdje4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674587813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. &lt;/p&gt;\n\n&lt;p&gt;It is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?&lt;/p&gt;\n\n&lt;p&gt;I really like features of Delta but we do not want to use Spark :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdje4", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "subreddit_subscribers": 87431, "created_utc": 1674587813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.\n\n1. (ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.\n2. (ETL) Export already transformed data daily from data service, save to Google BigQuery.\n\nOption 1 would incur more storage costs but that should be mostly negligible as it's only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?", "author_fullname": "t2_72tiq3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help choosing ETL vs ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfcr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;(ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.&lt;/li&gt;\n&lt;li&gt;(ETL) Export already transformed data daily from data service, save to Google BigQuery.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 1 would incur more storage costs but that should be mostly negligible as it&amp;#39;s only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfcr4", "is_robot_indexable": true, "report_reasons": null, "author": "ROCKITZ15", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "subreddit_subscribers": 87431, "created_utc": 1674592221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Right now I\u2019m an Analyst but for the past year or so at my company I\u2019ve been doing data engineering work like extracting data from different types of sources (API endpoints, files), writing code in python/sql to build data pipelines, use tools like airflow and AWS, deploying code to GitHub using git, refactoring the codebase, and collaborating with data engineers to do the previously stated.\n\nShould I ask for a title change to include \u2018engineer\u2019? I know data analysts do this work somewhat but I spend like 90% of my time doing the above stuff.\n\nI\u2019m concerned about when I go to look for a new job they won\u2019t sersiously consider me for a data engineering role.\n\nIf so, I am not sure how to go about that conversation in terms of potentially dealing with pushback from mamangement, so any advice/pointers on that would be greatly appreciated.", "author_fullname": "t2_f2plcmjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I ask for \u2018Engineer\u2019 in my title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10l17ui", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674660658.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674660410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now I\u2019m an Analyst but for the past year or so at my company I\u2019ve been doing data engineering work like extracting data from different types of sources (API endpoints, files), writing code in python/sql to build data pipelines, use tools like airflow and AWS, deploying code to GitHub using git, refactoring the codebase, and collaborating with data engineers to do the previously stated.&lt;/p&gt;\n\n&lt;p&gt;Should I ask for a title change to include \u2018engineer\u2019? I know data analysts do this work somewhat but I spend like 90% of my time doing the above stuff.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned about when I go to look for a new job they won\u2019t sersiously consider me for a data engineering role.&lt;/p&gt;\n\n&lt;p&gt;If so, I am not sure how to go about that conversation in terms of potentially dealing with pushback from mamangement, so any advice/pointers on that would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10l17ui", "is_robot_indexable": true, "report_reasons": null, "author": "Tough_Bag_458", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l17ui/should_i_ask_for_engineer_in_my_title/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10l17ui/should_i_ask_for_engineer_in_my_title/", "subreddit_subscribers": 87431, "created_utc": 1674660410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to build a service that is always up, consumes messages from Kafka, writes files to blob storage, and produces events to a different Kafka topic. And in addition, serves a \"health\" endpoint for Kubernetes health checks. \n\nDo you know of any open-source project or an example of how one would structure this?", "author_fullname": "t2_u8nde1tz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "example project structure for Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kv2tt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674640234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to build a service that is always up, consumes messages from Kafka, writes files to blob storage, and produces events to a different Kafka topic. And in addition, serves a &amp;quot;health&amp;quot; endpoint for Kubernetes health checks. &lt;/p&gt;\n\n&lt;p&gt;Do you know of any open-source project or an example of how one would structure this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kv2tt", "is_robot_indexable": true, "report_reasons": null, "author": "topdownAC", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kv2tt/example_project_structure_for_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kv2tt/example_project_structure_for_kafka/", "subreddit_subscribers": 87431, "created_utc": 1674640234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I get asked these questions a lot by prospects inquiring about Materialize, and I wanted to share a nice writeup that includes a nifty interactive diagram. I hope you enjoy, and I look forward to any follow-on questions you might have!\n\n- https://materialize.com/guides/streaming-database/\n\nps: I genuinely enjoy these kind of data architecture discussions and I like the tech my company sells. Please keep me honest if my posts feel too \u201cself-promote-y\u201d. Materialize is not the only streaming database, so I\u2019m down to discuss the broader approach.", "author_fullname": "t2_5p00kusf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a Streaming Database? When would I use one? When would I use a data warehouse instead?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10l22ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674662546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I get asked these questions a lot by prospects inquiring about Materialize, and I wanted to share a nice writeup that includes a nifty interactive diagram. I hope you enjoy, and I look forward to any follow-on questions you might have!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://materialize.com/guides/streaming-database/\"&gt;https://materialize.com/guides/streaming-database/&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;ps: I genuinely enjoy these kind of data architecture discussions and I like the tech my company sells. Please keep me honest if my posts feel too \u201cself-promote-y\u201d. Materialize is not the only streaming database, so I\u2019m down to discuss the broader approach.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?auto=webp&amp;v=enabled&amp;s=40e1d7827c1f41c748842c4edb067120d4c0e3b7", "width": 1636, "height": 655}, "resolutions": [{"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12bb7a41e0ff8c5ef406e4cbe219cb91bfcf33da", "width": 108, "height": 43}, {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93c910c6ced6adac0f7afa5b37921b7015226440", "width": 216, "height": 86}, {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=207d1ac9f0dd7b83882224f64eb7368849966b57", "width": 320, "height": 128}, {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3878ba477aa0e814b91e7cb04a91e0a97fb65008", "width": 640, "height": 256}, {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35dcc539f73f59941578e866906e5a2df3ea8ea9", "width": 960, "height": 384}, {"url": "https://external-preview.redd.it/LiDJ9PkviuuQkUbeVlrTNFpxVsqOBjF3okg1teYxg20.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b575979e39651709e02748d4678d1ea3df058cf7", "width": 1080, "height": 432}], "variants": {}, "id": "nER1gh_5MePRyoU3PJ4PPG59EB1QJLfOZ0p2ljidJPk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10l22ku", "is_robot_indexable": true, "report_reasons": null, "author": "Chuck-Alt-Delete", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l22ku/what_is_a_streaming_database_when_would_i_use_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10l22ku/what_is_a_streaming_database_when_would_i_use_one/", "subreddit_subscribers": 87431, "created_utc": 1674662546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I\u2019m looking for a performant low latency framework where you can develop stream processing applications in python which can integrate with the asyncio event loop.\n\nSo far here are the option I found, although not sure of all these integrate with asyncio.\n\n- PyFlink\n- Statefun with flink \n- Spark Streaming\n- Faust Streaming \n\nI\u2019m curious what you folks use if using the asyncio loop is a requirement for your applications.", "author_fullname": "t2_2ssq137", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performant low latency stream processing framework for python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10klqpa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674608288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I\u2019m looking for a performant low latency framework where you can develop stream processing applications in python which can integrate with the asyncio event loop.&lt;/p&gt;\n\n&lt;p&gt;So far here are the option I found, although not sure of all these integrate with asyncio.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;PyFlink&lt;/li&gt;\n&lt;li&gt;Statefun with flink &lt;/li&gt;\n&lt;li&gt;Spark Streaming&lt;/li&gt;\n&lt;li&gt;Faust Streaming &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m curious what you folks use if using the asyncio loop is a requirement for your applications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10klqpa", "is_robot_indexable": true, "report_reasons": null, "author": "curiouskafka", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10klqpa/performant_low_latency_stream_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10klqpa/performant_low_latency_stream_processing/", "subreddit_subscribers": 87431, "created_utc": 1674608288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently reading this [website](https://use-the-index-luke.com/sql/anatomy/the-leaf-nodes) about indexing in relational databases and I'm having trouble understanding what the author means by the following:\n\n\"The primary purpose of an index is to provide an ordered representation of the indexed data. It is, however, not possible to store the data sequentially because an `insert` statement would need to move the following entries to make room for the new one. Moving large amounts of data is very time-consuming so the `insert` statement would be very slow. The solution to the problem is to establish a logical order that is independent of physical order in memory. \"\n\nHow does he mean that data can't be stored sequentially? I assume he means the physical storage on disk but I'm just drawing a blank as to why exactly it can't be stored sequentially? What does physical order in memory mean?", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help explain this sentence regarding indexing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10klkcz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674608049.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674607784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently reading this &lt;a href=\"https://use-the-index-luke.com/sql/anatomy/the-leaf-nodes\"&gt;website&lt;/a&gt; about indexing in relational databases and I&amp;#39;m having trouble understanding what the author means by the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The primary purpose of an index is to provide an ordered representation of the indexed data. It is, however, not possible to store the data sequentially because an &lt;code&gt;insert&lt;/code&gt; statement would need to move the following entries to make room for the new one. Moving large amounts of data is very time-consuming so the &lt;code&gt;insert&lt;/code&gt; statement would be very slow. The solution to the problem is to establish a logical order that is independent of physical order in memory. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;How does he mean that data can&amp;#39;t be stored sequentially? I assume he means the physical storage on disk but I&amp;#39;m just drawing a blank as to why exactly it can&amp;#39;t be stored sequentially? What does physical order in memory mean?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tv7Eh-0EZGilGMAielV-NqTSUVRNJOpW7T9iYUUpQMY.jpg?auto=webp&amp;v=enabled&amp;s=aab6ef4a15099557be236a99e0afd40764f8477c", "width": 120, "height": 120}, "resolutions": [{"url": "https://external-preview.redd.it/tv7Eh-0EZGilGMAielV-NqTSUVRNJOpW7T9iYUUpQMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1543458b8f5813abe3c628ab300303f5911bf7b", "width": 108, "height": 108}], "variants": {}, "id": "FhZfCCdfSTP9aexAMhYJ9U_wg2OJsZhNpOWfm7ZrI6Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10klkcz", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10klkcz/can_someone_help_explain_this_sentence_regarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10klkcz/can_someone_help_explain_this_sentence_regarding/", "subreddit_subscribers": 87431, "created_utc": 1674607784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.\n\nIs there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings", "author_fullname": "t2_8jq30m4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trunk based development with SSIS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfb0p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfb0p", "is_robot_indexable": true, "report_reasons": null, "author": "patheticadam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "subreddit_subscribers": 87431, "created_utc": 1674592109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there I'm a new data engineer and this is my first task at my new job so please bear with me if it sounds dumb. \n\nI am tasked to build a test pipeline in Synapse which should copy historical data from an Azure SQL DB and then load it into my test container in ADLS2. The historical data has to be stored in a YYYY/YYYYMM/YYYYMMDD format in the ADLS2 container as Json files. I have a column in the table called the datekey which is an integer in YYYYMMDD format. They already have an incremental pipeline run that takes care of all current data from December 2022 so they want me to export all data before December 2022. \n\nI am only familiar with Blob storage so any pointers to resources or tips would be appreciated. Thank you.", "author_fullname": "t2_mtxnq3u8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10l3s2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674666712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there I&amp;#39;m a new data engineer and this is my first task at my new job so please bear with me if it sounds dumb. &lt;/p&gt;\n\n&lt;p&gt;I am tasked to build a test pipeline in Synapse which should copy historical data from an Azure SQL DB and then load it into my test container in ADLS2. The historical data has to be stored in a YYYY/YYYYMM/YYYYMMDD format in the ADLS2 container as Json files. I have a column in the table called the datekey which is an integer in YYYYMMDD format. They already have an incremental pipeline run that takes care of all current data from December 2022 so they want me to export all data before December 2022. &lt;/p&gt;\n\n&lt;p&gt;I am only familiar with Blob storage so any pointers to resources or tips would be appreciated. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10l3s2y", "is_robot_indexable": true, "report_reasons": null, "author": "1000gratitudepunches", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l3s2y/azure_synapse_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10l3s2y/azure_synapse_question/", "subreddit_subscribers": 87431, "created_utc": 1674666712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "#TrueDataOps Podcast with Kent Graziano and Cynthia Meyersohn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 64, "top_awarded_type": null, "hide_score": false, "name": "t3_10l26y4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 64, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8t7rKfLuWoPw2lsEIluUc7_LIF5aAiixmBHG8kUrlm8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674662832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/video/event/urn:li:ugcPost:7022215454584705024/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZI7oL3JTPPt59G0vTfOaQMHvka17QCAdFnF87leUeA.jpg?auto=webp&amp;v=enabled&amp;s=751b05e77b1c50dfc8477f4c599cb33affc7e2fc", "width": 64, "height": 64}, "resolutions": [], "variants": {}, "id": "QqSY3F9i2BgB-OdT_JpQr1vBqr2oq4spYNzkghHXwCM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10l26y4", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l26y4/truedataops_podcast_with_kent_graziano_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/video/event/urn:li:ugcPost:7022215454584705024/", "subreddit_subscribers": 87431, "created_utc": 1674662832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We ingest geospatial data from the internet in a lot of different sources.\n\nData is bad in two ways\n\n1. Geospatially incorrect: coordinates or elevation value is incorrect. Some of this just requires expertise.\n2. Metadata incorrect.\n\nThis geospatial data is transformed to one common coordinate system, other things are done to it, and it becomes compiled with other geospatial data to create singular products over a given region before it goes out of the door. In that compiling, it is effecting other geospatial data because we need to decide which of all the geospatial data at any given location is selected.\n\nThe whole process is a bit longer and more complicated.\n\nWhat I've found issues with is that we have manual review but at any given point, there's so much data that things are going to be missed. We have compliance checks in code but things come in so many different ways that things could be missed. And finally we end up having done many things to the data but at any given point in the pipeline we likely end up finding out that something in one of the geospatial sources is incorrect. At this point it's in our database records, it's locally stored, it's been manipulated, it's even effected other data during the compiling process.\n\nJust wanted to know if you guys have any advice, experience, or wisdom to deal with this type of scenario as I'm generally pretty green and learning as I go.", "author_fullname": "t2_vp6b3ibw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for creating pipelines when there's high amounts of bad data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10l1tca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674661930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We ingest geospatial data from the internet in a lot of different sources.&lt;/p&gt;\n\n&lt;p&gt;Data is bad in two ways&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Geospatially incorrect: coordinates or elevation value is incorrect. Some of this just requires expertise.&lt;/li&gt;\n&lt;li&gt;Metadata incorrect.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This geospatial data is transformed to one common coordinate system, other things are done to it, and it becomes compiled with other geospatial data to create singular products over a given region before it goes out of the door. In that compiling, it is effecting other geospatial data because we need to decide which of all the geospatial data at any given location is selected.&lt;/p&gt;\n\n&lt;p&gt;The whole process is a bit longer and more complicated.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;ve found issues with is that we have manual review but at any given point, there&amp;#39;s so much data that things are going to be missed. We have compliance checks in code but things come in so many different ways that things could be missed. And finally we end up having done many things to the data but at any given point in the pipeline we likely end up finding out that something in one of the geospatial sources is incorrect. At this point it&amp;#39;s in our database records, it&amp;#39;s locally stored, it&amp;#39;s been manipulated, it&amp;#39;s even effected other data during the compiling process.&lt;/p&gt;\n\n&lt;p&gt;Just wanted to know if you guys have any advice, experience, or wisdom to deal with this type of scenario as I&amp;#39;m generally pretty green and learning as I go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10l1tca", "is_robot_indexable": true, "report_reasons": null, "author": "PossibleMine1247", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10l1tca/advice_for_creating_pipelines_when_theres_high/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10l1tca/advice_for_creating_pipelines_when_theres_high/", "subreddit_subscribers": 87431, "created_utc": 1674661930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nSo I'm evaluating replacing some of our ingestion tech with airbyte.  Working through some local testing with it, however I'm hoping to get anyone who has experience with the tool's take.  Thanks in advance.  \n\n\n1. What's your overall impression on usability, particularly I need it for simple extract from source and sink to s3.\n2. How alpha are the alpha connectors?  Some of our big sources only have alpha connectors so curious if they're extremely buggy or its more like a public preview and has some quirks but is overall stable.", "author_fullname": "t2_pg4xpqjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte/ Airbyte Alpha connectors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kzzn4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674657208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m evaluating replacing some of our ingestion tech with airbyte.  Working through some local testing with it, however I&amp;#39;m hoping to get anyone who has experience with the tool&amp;#39;s take.  Thanks in advance.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What&amp;#39;s your overall impression on usability, particularly I need it for simple extract from source and sink to s3.&lt;/li&gt;\n&lt;li&gt;How alpha are the alpha connectors?  Some of our big sources only have alpha connectors so curious if they&amp;#39;re extremely buggy or its more like a public preview and has some quirks but is overall stable.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kzzn4", "is_robot_indexable": true, "report_reasons": null, "author": "LowOwl2591", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kzzn4/airbyte_airbyte_alpha_connectors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kzzn4/airbyte_airbyte_alpha_connectors/", "subreddit_subscribers": 87431, "created_utc": 1674657208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi! The product is a serverless platform to easily build and distribute continuous insights as streams (to power real-time actions and live analytics).\n\nThe rationale is that it\u2019s been a nightmare for teams to easily deliver on stream processing use cases, mainly due to the lack of good/serverless tooling and we\u2019re trying to close that gap. We\u2019ve been running a private beta for some time and the platform is now looking very stable so I want to open it up to more people - especially individuals with projects (mostly been testing with enterprise users). Would love to hear your thoughts and am happy to open an instance if you have something you want to try.", "author_fullname": "t2_jmkgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for beta testers for an event-driven analytics platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kyjwf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674653097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! The product is a serverless platform to easily build and distribute continuous insights as streams (to power real-time actions and live analytics).&lt;/p&gt;\n\n&lt;p&gt;The rationale is that it\u2019s been a nightmare for teams to easily deliver on stream processing use cases, mainly due to the lack of good/serverless tooling and we\u2019re trying to close that gap. We\u2019ve been running a private beta for some time and the platform is now looking very stable so I want to open it up to more people - especially individuals with projects (mostly been testing with enterprise users). Would love to hear your thoughts and am happy to open an instance if you have something you want to try.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kyjwf", "is_robot_indexable": true, "report_reasons": null, "author": "n0user", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kyjwf/looking_for_beta_testers_for_an_eventdriven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kyjwf/looking_for_beta_testers_for_an_eventdriven/", "subreddit_subscribers": 87431, "created_utc": 1674653097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_pnk8gu7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building an Infrastructure Data Lake with Athena", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kv0er", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674639947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudquery.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.cloudquery.io/how-to-guides/how-to-load-infrastructure-data-into-athena", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10kv0er", "is_robot_indexable": true, "report_reasons": null, "author": "WarmStrike176", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kv0er/building_an_infrastructure_data_lake_with_athena/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.cloudquery.io/how-to-guides/how-to-load-infrastructure-data-into-athena", "subreddit_subscribers": 87431, "created_utc": 1674639947.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}