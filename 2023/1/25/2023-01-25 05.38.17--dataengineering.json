{"kind": "Listing", "data": {"after": "t3_10klqpa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I did it! After 8 months of working as a budtender for minimum wage post-graduation, more than 400 job applications, and 12 interviews with different companies I finally landed a role as a data engineer. I still couldn't believe it till my first day, which was yesterday. Just got my laptop, fob, and ID card, still feels so unreal. Learned a lot from this sub and I'm forever grateful for you guys.", "author_fullname": "t2_mtxnq3u8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally got a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kl6lg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674606710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I did it! After 8 months of working as a budtender for minimum wage post-graduation, more than 400 job applications, and 12 interviews with different companies I finally landed a role as a data engineer. I still couldn&amp;#39;t believe it till my first day, which was yesterday. Just got my laptop, fob, and ID card, still feels so unreal. Learned a lot from this sub and I&amp;#39;m forever grateful for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kl6lg", "is_robot_indexable": true, "report_reasons": null, "author": "1000gratitudepunches", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kl6lg/finally_got_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kl6lg/finally_got_a_job/", "subreddit_subscribers": 87367, "created_utc": 1674606710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any openly available data engineering projects using Scala and Spark which follow industry conventions like proper folder/package structures and object oriented division of classes/concerns? Most examples I\u2019ve seen have everything in one file without proper separation of concerns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jyjej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674539522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently joined a data engineering team. I\u2019m from a web development background. I\u2019m trying to understand/learn the proper way of writing DE code. I\u2019ve just learnt the basics of Scala and Spark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jyjej", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jyjej/are_there_any_openly_available_data_engineering/", "subreddit_subscribers": 87367, "created_utc": 1674539522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to map out all the new data tools out there:  \n\n\n* what they are uniquely good at?\n* what is the compelling change in the data landscape that justified their creation?\n* how the big industry vertical (observability &amp; quality, ETL/ELT, catalog, etc) evolved?\n\n&amp;#x200B;\n\nCan you help me identify the missing tools ? or share feedback to improve it? Still WIP\n\n[notion.castordoc.com](https://notion.castordoc.com)\n\nhttps://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mapping of modern data tools. is anything missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lzgt871o2zda1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/DASHPlaylist.mpd?a=1677217097%2CMDhkOWI2ZmJhNjNlYmMzNzdmYWE3NDMxMWZkNmI4Njk3MzgxY2JjZTc1ZjEzZDQzMDZmYTdmOTg4NTgxODIwNA%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 650, "hlsUrl": "https://v.redd.it/link/10k2xtm/asset/lzgt871o2zda1/HLSPlaylist.m3u8?a=1677217097%2CMTIxODRkNDU1NjA0ZTYyNTYyOTFiNjRhMGU2ZjMxMzY3MTJlY2RlZmY1NzY0ZjkwYTc3OGI4NzQ4YWFlN2M3Mw%3D%3D&amp;v=1&amp;f=sd", "id": "lzgt871o2zda1", "isGif": false}}, "name": "t3_10k2xtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qcNush-DcKxbOl5jzV21hd4EmfaF2DW8BG8pzdZ1Lr4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674558065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to map out all the new data tools out there:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;what they are uniquely good at?&lt;/li&gt;\n&lt;li&gt;what is the compelling change in the data landscape that justified their creation?&lt;/li&gt;\n&lt;li&gt;how the big industry vertical (observability &amp;amp; quality, ETL/ELT, catalog, etc) evolved?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can you help me identify the missing tools ? or share feedback to improve it? Still WIP&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://notion.castordoc.com\"&gt;notion.castordoc.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player\"&gt;https://reddit.com/link/10k2xtm/video/lzgt871o2zda1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?auto=webp&amp;v=enabled&amp;s=83cbc10fd4df6f44787372d68831810403aa9a14", "width": 1516, "height": 852}, "resolutions": [{"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4b80a1518187141cbeddce8c9756f1c9630539e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9466ba8a631fd0e72dc07198853c267a5a92f5a8", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a398acec2128e9e96f2ef215b665d8f774fe64c0", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c68957f80ec2e3e30ac9cbb7773659784a177240", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=254ca3886eca2742c0c53d83b75fa208349f348e", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/NfKqb4tJiFBD-cJBhDNxE1SMPSq82yzU3oiqrgKCAjo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=400e8d6d97cb1c16e9c69504055ac6fe3d72de26", "width": 1080, "height": 606}], "variants": {}, "id": "6Zrev7FNgQrSU-pVnPXLXOHk0ZVzaBxLXy4KWXRD8tI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k2xtm", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k2xtm/mapping_of_modern_data_tools_is_anything_missing/", "subreddit_subscribers": 87367, "created_utc": 1674558065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I break every part of my ETL script in functions? (functional decomposition)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfjab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674595774.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have decomposed everty part of my Python script into functions which run sequentially, is this approach wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10kfjab", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfjab/should_i_break_every_part_of_my_etl_script_in/", "subreddit_subscribers": 87367, "created_utc": 1674592656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last week, I made a post in this sub\\[1\\] &amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.\n\nBased on the feedback (thanks, by the way!), I've updated my blog post\\[2\\] and included the example calculation I posted on Reddit.\n\nAnyway, here's the \"checklist\" that guided the calculations made in my previous Reddit post, with links at the bottom:\n\n\\-\n\n*When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).*\n\n## Up-front costs\n\n* software cost &amp; licensing, if applicable\n* learning &amp; education\n* implementation &amp; testing (including data migration costs)\n* documentation &amp; knowledge sharing\n* customization\n\n## Ongoing costs\n\n* direct infrastructure costs (e.g., hosting &amp; storage)\n* backup infrastructure costs (e.g., failover &amp; additional AZs)\n* supporting infrastructure costs (e.g., monitoring &amp; alerting)\n* maintenance, patches/upgrades, &amp; support\n* feature additions\n\n## Team &amp; opportunity costs\n\n* hiring to replace the engineers now working with the new software\n* time spent on infrastructure that could otherwise be spent on core product\n\n\\-\n\n\\[1\\]: [https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback\\_request\\_tco\\_calculation\\_for\\_apache\\_kafka](https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka) (link to the Reddit post in this sub if you're curious)\n\n\\[2\\]: [https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership](https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership) (link to the full blog post)", "author_fullname": "t2_fv515", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should you build or buy your infra? Checklist for calculating the costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8hwn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last week, I made a post in this sub[1] &amp;amp; a couple of others requesting feedback on my calculation of the total cost of ownership for Apache Kafka when building/managing it yourself vs. buying it.&lt;/p&gt;\n\n&lt;p&gt;Based on the feedback (thanks, by the way!), I&amp;#39;ve updated my blog post[2] and included the example calculation I posted on Reddit.&lt;/p&gt;\n\n&lt;p&gt;Anyway, here&amp;#39;s the &amp;quot;checklist&amp;quot; that guided the calculations made in my previous Reddit post, with links at the bottom:&lt;/p&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;When calculating the TCO, be sure you calculate the cost for each team involved (e.g., if you have separate infrastructure and development teams, consider the TCO for both independently).&lt;/em&gt;&lt;/p&gt;\n\n&lt;h2&gt;Up-front costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;software cost &amp;amp; licensing, if applicable&lt;/li&gt;\n&lt;li&gt;learning &amp;amp; education&lt;/li&gt;\n&lt;li&gt;implementation &amp;amp; testing (including data migration costs)&lt;/li&gt;\n&lt;li&gt;documentation &amp;amp; knowledge sharing&lt;/li&gt;\n&lt;li&gt;customization&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Ongoing costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;direct infrastructure costs (e.g., hosting &amp;amp; storage)&lt;/li&gt;\n&lt;li&gt;backup infrastructure costs (e.g., failover &amp;amp; additional AZs)&lt;/li&gt;\n&lt;li&gt;supporting infrastructure costs (e.g., monitoring &amp;amp; alerting)&lt;/li&gt;\n&lt;li&gt;maintenance, patches/upgrades, &amp;amp; support&lt;/li&gt;\n&lt;li&gt;feature additions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Team &amp;amp; opportunity costs&lt;/h2&gt;\n\n&lt;ul&gt;\n&lt;li&gt;hiring to replace the engineers now working with the new software&lt;/li&gt;\n&lt;li&gt;time spent on infrastructure that could otherwise be spent on core product&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;[1]: &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka\"&gt;https://www.reddit.com/r/dataengineering/comments/10gaucp/feedback_request_tco_calculation_for_apache_kafka&lt;/a&gt; (link to the Reddit post in this sub if you&amp;#39;re curious)&lt;/p&gt;\n\n&lt;p&gt;[2]: &lt;a href=\"https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership\"&gt;https://blog.mergent.co/building-vs-buying-software-infrastructure-the-true-total-cost-of-ownership&lt;/a&gt; (link to the full blog post)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?auto=webp&amp;v=enabled&amp;s=bc75ae8dfc3a23aef5ce6c9c684b8c0ce4aadc9c", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85db55ab11391be72234810a79e3dcc7b703e485", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb355f3b10a18334c292ab6e5f0bdea646415ddd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34774c95e96d5971688ba110ec64c5de89ddc031", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=756094fe0e52623c08186904a6093cbc205c7a4f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f0ca72492d9c7a61e0d93bd36d4b1835b76dfa6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LnIbu93t5knqFcNfzjV0WfYsX2mUNiTHPdwzS8sacj4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13730358324cec31bf695d246eeaa64b772eea58", "width": 1080, "height": 567}], "variants": {}, "id": "vj-wMdrGC9Ek6GbFlDkgWr7MDOA5uPlbmoApWsvlMkU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8hwn", "is_robot_indexable": true, "report_reasons": null, "author": "propjames", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8hwn/should_you_build_or_buy_your_infra_checklist_for/", "subreddit_subscribers": 87367, "created_utc": 1674575369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI'm wondering what is the most common architecture to implement CDC (change data capture) at your company?  I've seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. ", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you implement CDC in your organization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6sev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674571008.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674570721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what is the most common architecture to implement CDC (change data capture) at your company?  I&amp;#39;ve seen direct replications (Fivetran, AWS DMS), event-streaming (Kafka Connect + Debezium + Kafka streams), Outbox pattern. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k6sev", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 26, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k6sev/how_do_you_implement_cdc_in_your_organization/", "subreddit_subscribers": 87367, "created_utc": 1674570721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. \n\nWe use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn't it an antipattern a little bit? Or its a \"normal\"/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).\n\nNot really sure, appreciate any comment. Thank you.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k977n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674577191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How/where do you store your realtime data? And how do you provide access to it to end users? We are probably going to store the realtime that into the datalake, but I am not sure how to provide user-friendly access to the end users. &lt;/p&gt;\n\n&lt;p&gt;We use relational database for the batch data so users can easily interact with this data and maybe it would be great to ingest real-time data in this database as well, but idk.. Isn&amp;#39;t it an antipattern a little bit? Or its a &amp;quot;normal&amp;quot;/usual way? Or maybe keep batch data in the RDMBS and use e.g. Trino to provide access to the realtime data in the datalake? But then again - users would have to query 2 data sources.. Or maybe join both (RDBMS and datalake) into Trino? (We use PostgreSQL + S3 as datalake).&lt;/p&gt;\n\n&lt;p&gt;Not really sure, appreciate any comment. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k977n", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k977n/streaming_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k977n/streaming_data_storage/", "subreddit_subscribers": 87367, "created_utc": 1674577191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a data engineer at a consulting firm and lately I\u2019m seeing many clients interested in moving their workloads to follow the data Lakehouse paradigm to get the best out of data lake and data warehouse (Usually Databricks with delta lake being the most preferred option). How does this affect cloud data warehouse vendors like Snowflake? Is Snowflake embracing Lakehouse?", "author_fullname": "t2_33bbwdty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Data Lakehouse a threat to Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kjilb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674602347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a data engineer at a consulting firm and lately I\u2019m seeing many clients interested in moving their workloads to follow the data Lakehouse paradigm to get the best out of data lake and data warehouse (Usually Databricks with delta lake being the most preferred option). How does this affect cloud data warehouse vendors like Snowflake? Is Snowflake embracing Lakehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kjilb", "is_robot_indexable": true, "report_reasons": null, "author": "Maiden_666", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kjilb/is_data_lakehouse_a_threat_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kjilb/is_data_lakehouse_a_threat_to_snowflake/", "subreddit_subscribers": 87367, "created_utc": 1674602347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Is a CS Minor worth the cost if it means that I stay in school 1.5 extra semesters when I already have an entry level DE job/opportunity lined up if I decide to graduate in May? Will it be beneficial long term to have that on resume (my major is Information Systems) - Both in terms of time and money - as I'd spend that time focusing on more specific foundational skills. Just not sure if that would at all be a big bonus to have for future (the CS minor)", "author_fullname": "t2_5rdbxa5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is CS Minor worth the cost for 1.5 extra semesters in school if already have entry level opportunity lined up? (Information Systems major) - both in terms of time and money - as I'd spend that time to focus on more specific foundational skills. Not sure the CS minor would be beneficial longterm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kh2ys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674596381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is a CS Minor worth the cost if it means that I stay in school 1.5 extra semesters when I already have an entry level DE job/opportunity lined up if I decide to graduate in May? Will it be beneficial long term to have that on resume (my major is Information Systems) - Both in terms of time and money - as I&amp;#39;d spend that time focusing on more specific foundational skills. Just not sure if that would at all be a big bonus to have for future (the CS minor)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kh2ys", "is_robot_indexable": true, "report_reasons": null, "author": "BDproximity7", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kh2ys/is_cs_minor_worth_the_cost_for_15_extra_semesters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kh2ys/is_cs_minor_worth_the_cost_for_15_extra_semesters/", "subreddit_subscribers": 87367, "created_utc": 1674596381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are a technical team proficient in SWE skills, so we're happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I'm missing why we should use it?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs custom pyspark for transformations in databricks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kagoh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a technical team proficient in SWE skills, so we&amp;#39;re happy working in python and managing deployment etc and currently work in the latter way. Never tried it but I get the impression dbt is more aimed at people from a SQL background, are there any compelling reasons I&amp;#39;m missing why we should use it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kagoh", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kagoh/dbt_vs_custom_pyspark_for_transformations_in/", "subreddit_subscribers": 87367, "created_utc": 1674580409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of building a new data infrastructure for a small company. \n\nWould something like this make sense?\n\nData flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools\n\nI am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdz9e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674588909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of building a new data infrastructure for a small company. &lt;/p&gt;\n\n&lt;p&gt;Would something like this make sense?&lt;/p&gt;\n\n&lt;p&gt;Data flow from start to end:\nExternal data sources - Python downloaders scheduled using Airflow - Raw data saved into S3 - Trino engine over S3 to query the data easily - Python transformations using Dask scheduled using Airflow - Transformed data saved into Postgres database - Business users access, Data catalog, BI tools&lt;/p&gt;\n\n&lt;p&gt;I am not really sure about Trino setup and following Python transformations and transformed data saved into the DB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdz9e", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdz9e/data_architecture_opinion/", "subreddit_subscribers": 87367, "created_utc": 1674588909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR: First day, had to ask what a pipeline was.\n\nI was a junior web dev, but I really wasn't feeling it, so I tried to talk with a few connections I had and managed to get a job as a junior data engineer, but I honestly have no idea how. I went in the completely opposite direction people recommend you to do in the interview and said (in the fanciest way possible) I was only in the dev area, and seriously never had much interaction with data engineering, expecting to not get the job after saying that. No idea how it worked.\n\nAnd now here I am, at my second week, rushing Azure and Databricks courses like my life depends on it. \n\nNo but seriously, all jokes aside, it's been really fun. I honestly don't have much idea of what's going on, but my team was pretty aware of this and are helping me a lot. Wouldn't mind some general beginner tips, if possible. I'm already a mid level dev so only the new stuff is confusing me, like jobs and pipelines. Wish me luck :)", "author_fullname": "t2_105rol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I got a job in data engineering. I have no idea what I am doing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kmmw7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674610797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: First day, had to ask what a pipeline was.&lt;/p&gt;\n\n&lt;p&gt;I was a junior web dev, but I really wasn&amp;#39;t feeling it, so I tried to talk with a few connections I had and managed to get a job as a junior data engineer, but I honestly have no idea how. I went in the completely opposite direction people recommend you to do in the interview and said (in the fanciest way possible) I was only in the dev area, and seriously never had much interaction with data engineering, expecting to not get the job after saying that. No idea how it worked.&lt;/p&gt;\n\n&lt;p&gt;And now here I am, at my second week, rushing Azure and Databricks courses like my life depends on it. &lt;/p&gt;\n\n&lt;p&gt;No but seriously, all jokes aside, it&amp;#39;s been really fun. I honestly don&amp;#39;t have much idea of what&amp;#39;s going on, but my team was pretty aware of this and are helping me a lot. Wouldn&amp;#39;t mind some general beginner tips, if possible. I&amp;#39;m already a mid level dev so only the new stuff is confusing me, like jobs and pipelines. Wish me luck :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kmmw7", "is_robot_indexable": true, "report_reasons": null, "author": "garfield3222", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kmmw7/i_got_a_job_in_data_engineering_i_have_no_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kmmw7/i_got_a_job_in_data_engineering_i_have_no_idea/", "subreddit_subscribers": 87367, "created_utc": 1674610797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a blog post about the fundamentals of data modelling from my POV. I'd be really interested in people's opinions. \n\nTLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.", "author_fullname": "t2_7srfj4fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling blog post - thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k6zd1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674571279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dantelore.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a blog post about the fundamentals of data modelling from my POV. I&amp;#39;d be really interested in people&amp;#39;s opinions. &lt;/p&gt;\n\n&lt;p&gt;TLDR: The database/warehouse/tech you use is way less important than the fundamentals of a good data model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dantelore.com/posts/simplest-data-model/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10k6zd1", "is_robot_indexable": true, "report_reasons": null, "author": "DanteLore1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k6zd1/data_modelling_blog_post_thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dantelore.com/posts/simplest-data-model/", "subreddit_subscribers": 87367, "created_utc": 1674571279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. \n\nIt is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?\n\nI really like features of Delta but we do not want to use Spark :)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta without using Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kdje4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674587813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone successfully implemented Delta lake without using Spark? I mean, I know it is possible but I am curious about actually accessing and working with the data stored in Delta without using Spark. &lt;/p&gt;\n\n&lt;p&gt;It is efficient/fast to use e.g. pandas? Or I thought maybe Polars? Or Dask? Or it does not make much sense and it is better to use Spark?&lt;/p&gt;\n\n&lt;p&gt;I really like features of Delta but we do not want to use Spark :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kdje4", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kdje4/delta_without_using_spark/", "subreddit_subscribers": 87367, "created_utc": 1674587813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first job and I am too excited/anxious.\n\nMy current skills - Python, SQL", "author_fullname": "t2_u33aam84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What responsibilities can I expect for a Data Integration Intern?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kb11a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674581759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first job and I am too excited/anxious.&lt;/p&gt;\n\n&lt;p&gt;My current skills - Python, SQL&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kb11a", "is_robot_indexable": true, "report_reasons": null, "author": "scanip", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kb11a/what_responsibilities_can_i_expect_for_a_data/", "subreddit_subscribers": 87367, "created_utc": 1674581759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. \n\nDefinitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. \n\nWhat do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. \n\nOne rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. \n\nHow do you troubleshoot data issues in prod?", "author_fullname": "t2_msviuy1p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debugging data errors and inconsistencies in downstream dashboards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8dtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to understand what\u2019s the best way to troubleshoot and debug data inconsistency in prod or downstream applications. &lt;/p&gt;\n\n&lt;p&gt;Definitely live debugging and tinkering around prod data is not an option, although I\u2019m guilty of having done that on few occasions. &lt;/p&gt;\n\n&lt;p&gt;What do you folks do? What does the process look like? Reproducing is not exactly possible bcz the state of data keeps changing and you never know which data caused the error. &lt;/p&gt;\n\n&lt;p&gt;One rogue way of dealing with it is blindly rerunning that pipeline hoping and praying it writes clean data this time. &lt;/p&gt;\n\n&lt;p&gt;How do you troubleshoot data issues in prod?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Applied Data &amp; ML Engineer | Developer Advocate", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8dtf", "is_robot_indexable": true, "report_reasons": null, "author": "vino_and_data", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8dtf/debugging_data_errors_and_inconsistencies_in/", "subreddit_subscribers": 87367, "created_utc": 1674575067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I'm a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.\n\n1. (ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.\n2. (ETL) Export already transformed data daily from data service, save to Google BigQuery.\n\nOption 1 would incur more storage costs but that should be mostly negligible as it's only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?", "author_fullname": "t2_72tiq3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help choosing ETL vs ELT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfcr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m a new-ish data engineer and would love some advice on whether ETL or ELT best fits my use case.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;(ELT) Export raw data from data service, save to Google BigQuery, append new data rows daily, transform data in BigQuery.&lt;/li&gt;\n&lt;li&gt;(ETL) Export already transformed data daily from data service, save to Google BigQuery.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 1 would incur more storage costs but that should be mostly negligible as it&amp;#39;s only a few GBs. It would also be easier to add new transformations as I only need to make a new SQL query rather than another pipeline like in option 2. If the costs of the data service are negligible, which is the better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfcr4", "is_robot_indexable": true, "report_reasons": null, "author": "ROCKITZ15", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfcr4/help_choosing_etl_vs_elt/", "subreddit_subscribers": 87367, "created_utc": 1674592221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.\n\nIs there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings", "author_fullname": "t2_8jq30m4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trunk based development with SSIS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kfb0p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674592109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is wanting us to switch to trunk based development. So instead of having DEV, QA, PROD, etc branches, we will just have one main branch. However we still have several different environments that need to connect to different data sources.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy way to manage SSIS connection managers in a trunk based approach so that each environment has the appropriate connection manager settings&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10kfb0p", "is_robot_indexable": true, "report_reasons": null, "author": "patheticadam", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kfb0p/trunk_based_development_with_ssis/", "subreddit_subscribers": 87367, "created_utc": 1674592109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.\n\nI was looking at this write up of Sql server's implementation https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\n\nAnd it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn't necessarily guaranteed. \n\nSo theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn't generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clustered Index Lookup Efficiency", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10k8ftz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674575213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question for anyone knowledgable of the inner workings of query engines: what is the time complexity of a query selecting a single row, identified by the primary key, assuming it is the clustered index of the table.&lt;/p&gt;\n\n&lt;p&gt;I was looking at this write up of Sql server&amp;#39;s implementation &lt;a href=\"https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/\"&gt;https://www.sqlshack.com/sql-server-clustered-indexes-internals-with-examples/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And it looks like the data structure and access method is more or less the same as finding an integer in a sorted list using a binary search tree, which would mean O(logN) time complexity. And yet a hashmap should have a lookup time of O(1)-- though I understand this isn&amp;#39;t necessarily guaranteed. &lt;/p&gt;\n\n&lt;p&gt;So theoretically, could the query engine speed up retrieval of our clustered index values if we turned the column into a hashmap? In which case I would assume the reason this isn&amp;#39;t generally done is that it would incur a large overhead space investment (and, generally the improvement in performance would probably be negligable for most implementations).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?auto=webp&amp;v=enabled&amp;s=f68a5246a58720c9fc4a6173406989931fe0f17c", "width": 542, "height": 271}, "resolutions": [{"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76e0bbd89dd768d12decfc2099c8f4a1aace4fa2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc6e621801eed6fdbf7999dba6ca1a48512b4407", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/cNNH2FW2p2d4tZq6nLxVCPiK0_g8zaP5l_K2YrxZ1ZI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b445e25cd760a4ec5b906a01ac8df66a015b862b", "width": 320, "height": 160}], "variants": {}, "id": "w5ngVr1pMtH7vZrtkUTkbaXCV87rbMoiKjqUpVh8oE4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10k8ftz", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10k8ftz/clustered_index_lookup_efficiency/", "subreddit_subscribers": 87367, "created_utc": 1674575213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_97hu3nt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can this \"BI developer\" role be a stepping stone to DE? (read comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10knjkv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fJwurrK52ucNP8Lw3UvJ75pNb2vsU_ebUuxDDz_kD2Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674613410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yb142luf55ea1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yb142luf55ea1.jpg?auto=webp&amp;v=enabled&amp;s=d7df9119be9dbe0d6f13490c1c20f2d5532184b6", "width": 720, "height": 1480}, "resolutions": [{"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc06709cd9cc24150bd616eecc21f678e0233369", "width": 108, "height": 216}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d779272b26ce4bebe165fee255b4cc1f5027aaa0", "width": 216, "height": 432}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ba4166a5de44f969559cf201d9b8e47ecb48f13", "width": 320, "height": 640}, {"url": "https://preview.redd.it/yb142luf55ea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7275c22a9b414064e28d0ad5c6c9e1db06688c48", "width": 640, "height": 1280}], "variants": {}, "id": "BjOmXSv3kzWLcOvi0uU3VMaBRUoguBwLtNL14sQvWdY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10knjkv", "is_robot_indexable": true, "report_reasons": null, "author": "AmbitiousCase4992", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10knjkv/can_this_bi_developer_role_be_a_stepping_stone_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yb142luf55ea1.jpg", "subreddit_subscribers": 87367, "created_utc": 1674613410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently reading this [website](https://use-the-index-luke.com/sql/anatomy/the-leaf-nodes) about indexing in relational databases and I'm having trouble understanding what the author means by the following:\n\n\"The primary purpose of an index is to provide an ordered representation of the indexed data. It is, however, not possible to store the data sequentially because an `insert` statement would need to move the following entries to make room for the new one. Moving large amounts of data is very time-consuming so the `insert` statement would be very slow. The solution to the problem is to establish a logical order that is independent of physical order in memory. \"\n\nHow does he mean that data can't be stored sequentially? I assume he means the physical storage on disk but I'm just drawing a blank as to why exactly it can't be stored sequentially? What does physical order in memory mean?", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone help explain this sentence regarding indexing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10klkcz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674608049.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674607784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently reading this &lt;a href=\"https://use-the-index-luke.com/sql/anatomy/the-leaf-nodes\"&gt;website&lt;/a&gt; about indexing in relational databases and I&amp;#39;m having trouble understanding what the author means by the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The primary purpose of an index is to provide an ordered representation of the indexed data. It is, however, not possible to store the data sequentially because an &lt;code&gt;insert&lt;/code&gt; statement would need to move the following entries to make room for the new one. Moving large amounts of data is very time-consuming so the &lt;code&gt;insert&lt;/code&gt; statement would be very slow. The solution to the problem is to establish a logical order that is independent of physical order in memory. &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;How does he mean that data can&amp;#39;t be stored sequentially? I assume he means the physical storage on disk but I&amp;#39;m just drawing a blank as to why exactly it can&amp;#39;t be stored sequentially? What does physical order in memory mean?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tv7Eh-0EZGilGMAielV-NqTSUVRNJOpW7T9iYUUpQMY.jpg?auto=webp&amp;v=enabled&amp;s=aab6ef4a15099557be236a99e0afd40764f8477c", "width": 120, "height": 120}, "resolutions": [{"url": "https://external-preview.redd.it/tv7Eh-0EZGilGMAielV-NqTSUVRNJOpW7T9iYUUpQMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1543458b8f5813abe3c628ab300303f5911bf7b", "width": 108, "height": 108}], "variants": {}, "id": "FhZfCCdfSTP9aexAMhYJ9U_wg2OJsZhNpOWfm7ZrI6Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10klkcz", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10klkcz/can_someone_help_explain_this_sentence_regarding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10klkcz/can_someone_help_explain_this_sentence_regarding/", "subreddit_subscribers": 87367, "created_utc": 1674607784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I'm familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): \n\n1.Pyspark\n\n 2.Pytorch /Pandas \n\nI don't have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?", "author_fullname": "t2_vh9qo8up", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Preparation for Data Engineering in 15 days backend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kamzt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674580842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Dot Net Core developer (backend total 1 year of experience) recently, I contacted by the well-known company recruiter regarding Data Engineering position sounds interesting to me .I already passed initial 2 interview (Recruiter and Team Lead- 30 mins). I have  another round of technical interview in 2 weeks, I&amp;#39;m familiar with python and good at SQL These are the item team lead motioned for technical interview (Live Coding): &lt;/p&gt;\n\n&lt;p&gt;1.Pyspark&lt;/p&gt;\n\n&lt;p&gt;2.Pytorch /Pandas &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much idea within of this ,could anyone explain how I should be prepare for the interview .He also mention they will check clean code and Unit test during interview . How I should prepare for myself and quickest way to catch up with PySpark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10kamzt", "is_robot_indexable": true, "report_reasons": null, "author": "Maximum-Crazy-9444", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kamzt/interview_preparation_for_data_engineering_in_15/", "subreddit_subscribers": 87367, "created_utc": 1674580842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I am trying to understand the internals shuffle hash join. I want to check if my understanding of it is correct. Let\u2019s say I have two tables t1 and t2 joined on column country (8 distinct values).\u00a0 If I set the number of shuffle partitions as 4 with two executors. In this case, data from t1 on both the executors is first split into 4 partitions (let\u2019s say part 0 - part 3)/files (stored in disk or memory as an intermediate step) using a hash of key % 4, and the same is done with data from t2 across two executors.\u00a0 In the reduce phase,\u00a0 data from the same partitions are merged which finally results in 4 partitions (eg: part 0 data from t1 and t2 from both the executors is merged into one big part 0 ) before performing the join. Is my understanding of it correct? Thanks for the help!", "author_fullname": "t2_2adeipr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Hash Shuffle Join", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kna43", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674612647.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I am trying to understand the internals shuffle hash join. I want to check if my understanding of it is correct. Let\u2019s say I have two tables t1 and t2 joined on column country (8 distinct values).\u00a0 If I set the number of shuffle partitions as 4 with two executors. In this case, data from t1 on both the executors is first split into 4 partitions (let\u2019s say part 0 - part 3)/files (stored in disk or memory as an intermediate step) using a hash of key % 4, and the same is done with data from t2 across two executors.\u00a0 In the reduce phase,\u00a0 data from the same partitions are merged which finally results in 4 partitions (eg: part 0 data from t1 and t2 from both the executors is merged into one big part 0 ) before performing the join. Is my understanding of it correct? Thanks for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10kna43", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Outlandishness-74", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kna43/understanding_hash_shuffle_join/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kna43/understanding_hash_shuffle_join/", "subreddit_subscribers": 87367, "created_utc": 1674612647.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to get a Summer 2023 internship in the US. Currently pursuing an MS degree on F1 student visa. I've applied to many companies but have seen resume rejects, no response and 3 HireVue interviews so far. \n\nCould anyone here please help mentoring me for landing an internship? I'd be grateful to discuss my profile and learn where I can improve and how should I approach or where to apply. If you can refer me to any positions if my profile is suitable for an intern that would be very helpful for me as well.", "author_fullname": "t2_iascmrib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internship help needed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10kmfa3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674610201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a Summer 2023 internship in the US. Currently pursuing an MS degree on F1 student visa. I&amp;#39;ve applied to many companies but have seen resume rejects, no response and 3 HireVue interviews so far. &lt;/p&gt;\n\n&lt;p&gt;Could anyone here please help mentoring me for landing an internship? I&amp;#39;d be grateful to discuss my profile and learn where I can improve and how should I approach or where to apply. If you can refer me to any positions if my profile is suitable for an intern that would be very helpful for me as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10kmfa3", "is_robot_indexable": true, "report_reasons": null, "author": "catchereye22", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10kmfa3/internship_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10kmfa3/internship_help_needed/", "subreddit_subscribers": 87367, "created_utc": 1674610201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I\u2019m looking for a performant low latency framework where you can develop stream processing applications in python which can integrate with the asyncio event loop.\n\nSo far here are the option I found, although not sure of all these integrate with asyncio.\n\n- PyFlink\n- Statefun with flink \n- Spark Streaming\n- Faust Streaming \n\nI\u2019m curious what you folks use if using the asyncio loop is a requirement for your applications.", "author_fullname": "t2_2ssq137", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performant low latency stream processing framework for python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10klqpa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674608288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I\u2019m looking for a performant low latency framework where you can develop stream processing applications in python which can integrate with the asyncio event loop.&lt;/p&gt;\n\n&lt;p&gt;So far here are the option I found, although not sure of all these integrate with asyncio.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;PyFlink&lt;/li&gt;\n&lt;li&gt;Statefun with flink &lt;/li&gt;\n&lt;li&gt;Spark Streaming&lt;/li&gt;\n&lt;li&gt;Faust Streaming &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I\u2019m curious what you folks use if using the asyncio loop is a requirement for your applications.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10klqpa", "is_robot_indexable": true, "report_reasons": null, "author": "curiouskafka", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10klqpa/performant_low_latency_stream_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10klqpa/performant_low_latency_stream_processing/", "subreddit_subscribers": 87367, "created_utc": 1674608288.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}