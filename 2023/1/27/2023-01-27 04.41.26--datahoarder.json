{"kind": "Listing", "data": {"after": "t3_10mag26", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_e5284", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive Takes Down BBC\u2019s Documentary on PM Modi: Report", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10ljuzv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 704, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 704, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/K6V7EuXr7ZCl5r7Cn6CwgLke5H8YE71sFiVkHwvR4ag.jpg", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674708803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news18.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.news18.com/news/world/internet-archive-takes-down-bbcs-documentary-on-pm-modi-report-6902791.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?auto=webp&amp;v=enabled&amp;s=b751158f1df7f2285ee5a9c39710c36caab028ae", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0448062dee605a90935e274f226cdf59f4f2481", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18a2b1fb166f81a5aac676ca4e97aaf588818b40", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0842b15cb969a99cba5d217ccaffb98d6c886289", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8949449bdef46cafc8d0ee111a44f7c589102391", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faed891adb85a555a1f0724656bed17d94a79d25", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q1MkiHXxisVUIhdKEkn3HjUUNLh_5JlUVUM5Shwl6dY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d01ae99ddc89c505a1afcb4f174d707ec36c5c1", "width": 1080, "height": 607}], "variants": {}, "id": "Rgt6fY6_wdAJjOw5kSHXtqQ45m4URk8RKeU0iwn97Ew"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "RIPPING DVDs", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ljuzv", "is_robot_indexable": true, "report_reasons": null, "author": "6jarjar6", "discussion_type": null, "num_comments": 140, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10ljuzv/internet_archive_takes_down_bbcs_documentary_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.news18.com/news/world/internet-archive-takes-down-bbcs-documentary-on-pm-modi-report-6902791.html", "subreddit_subscribers": 667389, "created_utc": 1674708803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've recently been given a 3.5\" 4TB HDD for free that I'd like to use as additional storage for my PC (Plex Server) however my desktop tower can only fit one HDD which I've already got a 4TB HDD in. What is the most affordable way to permanently have this HDD connected to by PC externally whilst remaining safe? I read docking stations can cause heating issues and are only good for temporary HDD swaps. So would an enclosure be sufficient (does plastic vs aluminium matter)? Any affordable recommendations, please?\n\nAlternatively, should I just get a USB to SATA converter and use this HDD as a backup (which I'll then store somewhere else) and purchase a proper external HD? (this would be more costly so ideally don't want to do this).\n\nEdit: In response to some of the comments - I can't change the desktop case, the dell optiplex's have a lot of propriety parts that make it very difficult to change. It's also not my goal here, trying to keep this as simple as possible.\n\nUpdate: Going with an aluminium enclosure.", "author_fullname": "t2_528b7jda", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to use a spare external HDD as storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m7hwu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674783374.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674780036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently been given a 3.5&amp;quot; 4TB HDD for free that I&amp;#39;d like to use as additional storage for my PC (Plex Server) however my desktop tower can only fit one HDD which I&amp;#39;ve already got a 4TB HDD in. What is the most affordable way to permanently have this HDD connected to by PC externally whilst remaining safe? I read docking stations can cause heating issues and are only good for temporary HDD swaps. So would an enclosure be sufficient (does plastic vs aluminium matter)? Any affordable recommendations, please?&lt;/p&gt;\n\n&lt;p&gt;Alternatively, should I just get a USB to SATA converter and use this HDD as a backup (which I&amp;#39;ll then store somewhere else) and purchase a proper external HD? (this would be more costly so ideally don&amp;#39;t want to do this).&lt;/p&gt;\n\n&lt;p&gt;Edit: In response to some of the comments - I can&amp;#39;t change the desktop case, the dell optiplex&amp;#39;s have a lot of propriety parts that make it very difficult to change. It&amp;#39;s also not my goal here, trying to keep this as simple as possible.&lt;/p&gt;\n\n&lt;p&gt;Update: Going with an aluminium enclosure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10m7hwu", "is_robot_indexable": true, "report_reasons": null, "author": "descavenger", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10m7hwu/best_way_to_use_a_spare_external_hdd_as_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10m7hwu/best_way_to_use_a_spare_external_hdd_as_storage/", "subreddit_subscribers": 667389, "created_utc": 1674780036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an old Crucial 256GB m.2 SSD (an M550) I pressed into service temporarily in a place it doesn't really belong.  I checked the smart data to see how it's doing, and saw this:\n\n    202 Percent_Lifetime_Remain 0x0031   199   199   000    Pre-fail  Offline      -       157\n\nOdd.  I thought it ought to be nearing the end of its life, and instead it's got double its original life!\n\nDid the math on the blocks written.  I'm at 157 TBW out of the drive's estimated life of... 72 TBW.  Or 36TBW; Crucial wasn't super clear on how this applied to various models.\n\nI guess it's finally time to let this drive retire lol.\n\nBut smart doesn't show failure, because it's got more life left than it started with, according to the numbers.  I guess I've got something new to watch out for.", "author_fullname": "t2_4d7rn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Fun\" fact: older Crucial SSDs have smart data wrap around below zero. 199% life remaining lol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lw96b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674751531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an old Crucial 256GB m.2 SSD (an M550) I pressed into service temporarily in a place it doesn&amp;#39;t really belong.  I checked the smart data to see how it&amp;#39;s doing, and saw this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;202 Percent_Lifetime_Remain 0x0031   199   199   000    Pre-fail  Offline      -       157\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Odd.  I thought it ought to be nearing the end of its life, and instead it&amp;#39;s got double its original life!&lt;/p&gt;\n\n&lt;p&gt;Did the math on the blocks written.  I&amp;#39;m at 157 TBW out of the drive&amp;#39;s estimated life of... 72 TBW.  Or 36TBW; Crucial wasn&amp;#39;t super clear on how this applied to various models.&lt;/p&gt;\n\n&lt;p&gt;I guess it&amp;#39;s finally time to let this drive retire lol.&lt;/p&gt;\n\n&lt;p&gt;But smart doesn&amp;#39;t show failure, because it&amp;#39;s got more life left than it started with, according to the numbers.  I guess I&amp;#39;ve got something new to watch out for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lw96b", "is_robot_indexable": true, "report_reasons": null, "author": "TheFeshy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lw96b/fun_fact_older_crucial_ssds_have_smart_data_wrap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lw96b/fun_fact_older_crucial_ssds_have_smart_data_wrap/", "subreddit_subscribers": 667389, "created_utc": 1674751531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll be frank, this is probably the third or fourth time I've tried coming to ask for help and I am always overwhelmed by the amount of technical jargon being thrown around so I'm hoping someone can help point me in the right direction for starting off fresh. My local store has DS920+ for sale and I want to set up a NAS for media files. I have well over 15 terabytes of data and I'm basically capped out until I can expand onto a neat set like a NAS.\n\nMy main question starting off is what kind of hard drive should I be buying or what requirements should be met for installing drives into the Synology unit. I'm honestly open to someone just name dropping specific models. I hope to expand my storage to the 30 - 50 terabyte range with RAID also included.\n\nDiscussions about setting up Raspberry Pis often has me lost so unless I can find a sherpa to discuss it in laymans terms, I'm avoiding on figuring that out for now as my main priority is to get this Synology unit up and running so I can back up my external drives to it. I have recently experienced a scare and am in need of backing up everything on something built for the long long run. \n\nPlease help\n\nedit1: If there are any additional suggestions as to what is most important to purchase in the beginning of starting of, please let me know. The only thing I can think of is a back up power supply unit to ensure the Synology won't shut off suddenly during a black out. Plus I plan to set it up for automatic shut off + automatic run when power is received.", "author_fullname": "t2_g2gyo6kn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low IQ datahoarder here. Need advice on purchasing a Synology DS920+ and additional drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lsvha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674745314.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674742855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be frank, this is probably the third or fourth time I&amp;#39;ve tried coming to ask for help and I am always overwhelmed by the amount of technical jargon being thrown around so I&amp;#39;m hoping someone can help point me in the right direction for starting off fresh. My local store has DS920+ for sale and I want to set up a NAS for media files. I have well over 15 terabytes of data and I&amp;#39;m basically capped out until I can expand onto a neat set like a NAS.&lt;/p&gt;\n\n&lt;p&gt;My main question starting off is what kind of hard drive should I be buying or what requirements should be met for installing drives into the Synology unit. I&amp;#39;m honestly open to someone just name dropping specific models. I hope to expand my storage to the 30 - 50 terabyte range with RAID also included.&lt;/p&gt;\n\n&lt;p&gt;Discussions about setting up Raspberry Pis often has me lost so unless I can find a sherpa to discuss it in laymans terms, I&amp;#39;m avoiding on figuring that out for now as my main priority is to get this Synology unit up and running so I can back up my external drives to it. I have recently experienced a scare and am in need of backing up everything on something built for the long long run. &lt;/p&gt;\n\n&lt;p&gt;Please help&lt;/p&gt;\n\n&lt;p&gt;edit1: If there are any additional suggestions as to what is most important to purchase in the beginning of starting of, please let me know. The only thing I can think of is a back up power supply unit to ensure the Synology won&amp;#39;t shut off suddenly during a black out. Plus I plan to set it up for automatic shut off + automatic run when power is received.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lsvha", "is_robot_indexable": true, "report_reasons": null, "author": "Ronin_Ghost_", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lsvha/low_iq_datahoarder_here_need_advice_on_purchasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lsvha/low_iq_datahoarder_here_need_advice_on_purchasing/", "subreddit_subscribers": 667389, "created_utc": 1674742855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planning out downloading a fairly large (~4TB, ~2100 videos) download of every GamesDoneQuick speedrun. I really want to get the flags right so that I don't end up having to do this more than once. I will probably end up writing a custom downloader that invokes `yt-dlp` per-video so that I can download a few videos per-hour as part of a cronjob to avoid getting rate-limited by YT as well as making it easier to resume if interrupted  \n\nDoes anyone have tips / tricks for getting all of the extra metadata / making sure to grab the highest quality / anything else I should know when using yt-dlp?", "author_fullname": "t2_13bsp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimal yt-dlp flags for downloading a large video archive from YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10llx59", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674716232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planning out downloading a fairly large (~4TB, ~2100 videos) download of every GamesDoneQuick speedrun. I really want to get the flags right so that I don&amp;#39;t end up having to do this more than once. I will probably end up writing a custom downloader that invokes &lt;code&gt;yt-dlp&lt;/code&gt; per-video so that I can download a few videos per-hour as part of a cronjob to avoid getting rate-limited by YT as well as making it easier to resume if interrupted  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have tips / tricks for getting all of the extra metadata / making sure to grab the highest quality / anything else I should know when using yt-dlp?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10llx59", "is_robot_indexable": true, "report_reasons": null, "author": "kitanokikori", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10llx59/optimal_ytdlp_flags_for_downloading_a_large_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10llx59/optimal_ytdlp_flags_for_downloading_a_large_video/", "subreddit_subscribers": 667389, "created_utc": 1674716232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So i have a flashdrive plugged into a router that I use to play music and slide shows on a near 24 hour basis to a tv in a small store. I have another copy of the data at home, but often I will stick images and video of events we do in the store right on the drive, and then back it up at a later date. I know constant writes to a flash drive or ssd can cause them to die faster but I am unsure if reads work the same way. I would think the actual memory cells would be fine, but what about the controler chip?", "author_fullname": "t2_df17g1cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Longevity of a flash drive doing read only tasks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lsbny", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674741285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i have a flashdrive plugged into a router that I use to play music and slide shows on a near 24 hour basis to a tv in a small store. I have another copy of the data at home, but often I will stick images and video of events we do in the store right on the drive, and then back it up at a later date. I know constant writes to a flash drive or ssd can cause them to die faster but I am unsure if reads work the same way. I would think the actual memory cells would be fine, but what about the controler chip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lsbny", "is_robot_indexable": true, "report_reasons": null, "author": "Fred_Wilkins", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lsbny/longevity_of_a_flash_drive_doing_read_only_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lsbny/longevity_of_a_flash_drive_doing_read_only_tasks/", "subreddit_subscribers": 667389, "created_utc": 1674741285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I figured you guys would know, but I just got a quote from Dell for some new Enterprise class SSD's, I'm like 90% sure these are just rebranded WD drives (I suspect Ultrastar), but this price seems just bonkers for 2 SSD's. \n\n\n\n\nDell 1.92TB SSD SATA Read Intensive 6Gbps 512e 2.5in with 3.5in Hybrid Carrier | $1,250.21 | \n---|---|----|----\nDell 1.92TB SSD SATA Read Intensive 6Gbps 512e 2.5in with 3.5in Hybrid Carrier | $1,250.21 |\nSubtotal: $2,500.42 \n\n\n\nI wasn't going to really bat an eye at like 600-800 or so, but this just seems WAY above what I was expecting. \n\n\n\nAnyone know if these prices are right, or if they are wack, what model drives they are using?", "author_fullname": "t2_6abdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I being had here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lvkty", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674749862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I figured you guys would know, but I just got a quote from Dell for some new Enterprise class SSD&amp;#39;s, I&amp;#39;m like 90% sure these are just rebranded WD drives (I suspect Ultrastar), but this price seems just bonkers for 2 SSD&amp;#39;s. &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Dell 1.92TB SSD SATA Read Intensive 6Gbps 512e 2.5in with 3.5in Hybrid Carrier&lt;/th&gt;\n&lt;th&gt;$1,250.21&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Dell 1.92TB SSD SATA Read Intensive 6Gbps 512e 2.5in with 3.5in Hybrid Carrier&lt;/td&gt;\n&lt;td&gt;$1,250.21&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Subtotal: $2,500.42 &lt;/p&gt;\n\n&lt;p&gt;I wasn&amp;#39;t going to really bat an eye at like 600-800 or so, but this just seems WAY above what I was expecting. &lt;/p&gt;\n\n&lt;p&gt;Anyone know if these prices are right, or if they are wack, what model drives they are using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lvkty", "is_robot_indexable": true, "report_reasons": null, "author": "Carobu", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lvkty/am_i_being_had_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lvkty/am_i_being_had_here/", "subreddit_subscribers": 667389, "created_utc": 1674749862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,  \n\n\nDoes anyone have any experience with say about 1PB of storage or so in their homelab?  \nI'm running out of upgrades for my current unRAID due to the limit of # of HDD's. Most of my use case is Write-Once Read-Many and wouldn't need to be spinning 24/7. I'm storing a TON of personal home movies lets say.  \n\n\nThinking ahead a little bit my \"unlimited\" cloud storage will be coming to an end at some point, but I haven't received a notice yet. Just moved to the $20/month plan and have been solid this whole time.  \n\n\nBut eventually Google and others will crack down on the few using WAY more than intended and I want to start migrating things back home. With consolidating local storage and bringing home cloud storage, I need to start planning the machines needed to cover my new needs. I'm breaking out my servers into individual tasks, so this server in question would only be used to serve files. I'll be automating my personal movie collection through other devices. Just dumping the end results here for Plex or something to pick up.  \n\n\nThings I'm considering but having a hard time finding more on is:  \n\n\nCPU - What is necessary but accomplishes 100% HDD speeds. I know this can be HBA/Expander dependent but assuming those are not the bottlenecks, what's the minimum CPU for say 60-90 drive arrays. hoping for low idle power too, but that might be a big ask in addition to everything else  \nRAM - I know ZFS needs all the memory it can get, but IDK if I need ZFS for my needs. I don't need to run any DB's or anything off this storage. Most read speeds I'll need is for any kind of parity calculation or similar for the FS.  \nFileSystem - I'll be interfacing with this machine or these machines primarily through SMB/NFS shares. Does anyone have any good advice what I should go with? I'd even do something like MergerFS+SnapRAID if anyone has a good long-term experience with this. I'm prioritizing capacity over redundancy and speed. I'll have good backups on the stuff I can't live without.  \n\n\nDisaster recovery - Given that I'm used to unRAID for 7+ years now I'm pretty familiar with it's quirks, but it's limits are starting to bother me. I'll take any other solution if there's a lot of documentation /community behind it.  \n\n\nAny tips or advice would be helpful. I just don't want to spend tens of thousands of dollars just to get a 45Drives or JellyFish setup here. Even Supermicro or Dell sell solutions to this and everyone is charging $15k before the HDDS to get this going. Wanting to go more of a DIY route and put that money into the HDDs.\n\n&amp;#x200B;\n\nThanks in advance", "author_fullname": "t2_jtl8q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Petabyte for Personal Use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m6iiu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": "", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674777353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,  &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience with say about 1PB of storage or so in their homelab?&lt;br/&gt;\nI&amp;#39;m running out of upgrades for my current unRAID due to the limit of # of HDD&amp;#39;s. Most of my use case is Write-Once Read-Many and wouldn&amp;#39;t need to be spinning 24/7. I&amp;#39;m storing a TON of personal home movies lets say.  &lt;/p&gt;\n\n&lt;p&gt;Thinking ahead a little bit my &amp;quot;unlimited&amp;quot; cloud storage will be coming to an end at some point, but I haven&amp;#39;t received a notice yet. Just moved to the $20/month plan and have been solid this whole time.  &lt;/p&gt;\n\n&lt;p&gt;But eventually Google and others will crack down on the few using WAY more than intended and I want to start migrating things back home. With consolidating local storage and bringing home cloud storage, I need to start planning the machines needed to cover my new needs. I&amp;#39;m breaking out my servers into individual tasks, so this server in question would only be used to serve files. I&amp;#39;ll be automating my personal movie collection through other devices. Just dumping the end results here for Plex or something to pick up.  &lt;/p&gt;\n\n&lt;p&gt;Things I&amp;#39;m considering but having a hard time finding more on is:  &lt;/p&gt;\n\n&lt;p&gt;CPU - What is necessary but accomplishes 100% HDD speeds. I know this can be HBA/Expander dependent but assuming those are not the bottlenecks, what&amp;#39;s the minimum CPU for say 60-90 drive arrays. hoping for low idle power too, but that might be a big ask in addition to everything else&lt;br/&gt;\nRAM - I know ZFS needs all the memory it can get, but IDK if I need ZFS for my needs. I don&amp;#39;t need to run any DB&amp;#39;s or anything off this storage. Most read speeds I&amp;#39;ll need is for any kind of parity calculation or similar for the FS.&lt;br/&gt;\nFileSystem - I&amp;#39;ll be interfacing with this machine or these machines primarily through SMB/NFS shares. Does anyone have any good advice what I should go with? I&amp;#39;d even do something like MergerFS+SnapRAID if anyone has a good long-term experience with this. I&amp;#39;m prioritizing capacity over redundancy and speed. I&amp;#39;ll have good backups on the stuff I can&amp;#39;t live without.  &lt;/p&gt;\n\n&lt;p&gt;Disaster recovery - Given that I&amp;#39;m used to unRAID for 7+ years now I&amp;#39;m pretty familiar with it&amp;#39;s quirks, but it&amp;#39;s limits are starting to bother me. I&amp;#39;ll take any other solution if there&amp;#39;s a lot of documentation /community behind it.  &lt;/p&gt;\n\n&lt;p&gt;Any tips or advice would be helpful. I just don&amp;#39;t want to spend tens of thousands of dollars just to get a 45Drives or JellyFish setup here. Even Supermicro or Dell sell solutions to this and everyone is charging $15k before the HDDS to get this going. Wanting to go more of a DIY route and put that money into the HDDs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10m6iiu", "is_robot_indexable": true, "report_reasons": null, "author": "intertet", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "", "permalink": "/r/DataHoarder/comments/10m6iiu/petabyte_for_personal_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10m6iiu/petabyte_for_personal_use/", "subreddit_subscribers": 667389, "created_utc": 1674777353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a mdadm raid5 with 4 x 3GB in my home lab. I'm out of diskspace and I'm planning to move to the big drives \\~20TB. I have about 1TiB of extremely valuable data that I've sent to AWS glacier. Another 1TiB is valuable and the rest is something that I can probably acquire or reproduce again if I loose it.\n\nMy plan is to buy a 20TiB drive once a year for the next few years as my need for space increases. I'm also willing to sacrifice the data integrity buy first having no redundancy during the first year, add a mirror on year 2, go to raid5 on year 3 and retire my old raid5 and grow that to 3 + 1 RAID5 on year 4.\n\nI know I can do this with mdadm. It seems like BTRFS has only an experimental raid5 support that they do not seem to be putting an effort to fixing. ZFS might be getting RAID5 growing during the next few years but that is a bit uncertain.\n\nWhat I would like to hear is your opinions on what would be the best strategy for me?", "author_fullname": "t2_58m616ld", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best strategy for growing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lm7k8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674717361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mdadm raid5 with 4 x 3GB in my home lab. I&amp;#39;m out of diskspace and I&amp;#39;m planning to move to the big drives ~20TB. I have about 1TiB of extremely valuable data that I&amp;#39;ve sent to AWS glacier. Another 1TiB is valuable and the rest is something that I can probably acquire or reproduce again if I loose it.&lt;/p&gt;\n\n&lt;p&gt;My plan is to buy a 20TiB drive once a year for the next few years as my need for space increases. I&amp;#39;m also willing to sacrifice the data integrity buy first having no redundancy during the first year, add a mirror on year 2, go to raid5 on year 3 and retire my old raid5 and grow that to 3 + 1 RAID5 on year 4.&lt;/p&gt;\n\n&lt;p&gt;I know I can do this with mdadm. It seems like BTRFS has only an experimental raid5 support that they do not seem to be putting an effort to fixing. ZFS might be getting RAID5 growing during the next few years but that is a bit uncertain.&lt;/p&gt;\n\n&lt;p&gt;What I would like to hear is your opinions on what would be the best strategy for me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lm7k8", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric_Air5109", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lm7k8/best_strategy_for_growing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lm7k8/best_strategy_for_growing/", "subreddit_subscribers": 667389, "created_utc": 1674717361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Keep your eyes open over the coming months, this will be incredibly beautiful artwork to add to any collection.", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Colorado landscape photographer John Fielder donates entire life's work to public domain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_10mazgf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_21a3iylx", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l-42RpNdc8uSyLrqgXPTP_KxYtXYmW9szY4HdFLG0rc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Colorado", "selftext": "", "author_fullname": "t2_jvnx8xd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Colorado landscape photographer John Fielder donates entire life's work to public domain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Colorado", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10lyfgc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 406, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 406, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l-42RpNdc8uSyLrqgXPTP_KxYtXYmW9szY4HdFLG0rc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1674756936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "petapixel.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://petapixel.com/2023/01/26/celebrated-nature-photographer-donates-lifes-work-to-public-domain/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?auto=webp&amp;v=enabled&amp;s=c50a50e67471f361785cdf3f9f6b99f603aa763c", "width": 1600, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bbc4ab7b60bbb3f0ab4f73832e26bdc7e37d102", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a435a3c0efd7d8245fb3234ffd6fb443b6ff9341", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51376c2bdbd57b81436b4336bf4756fb22ec50b9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5438fb78ded20384f928f2e7cba6eba0ea9702bd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6cf2231954ca52de340fdc7002b5a62d5ebf9e6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc4066d65ef29b4852e8b1a18e3ea5ed33d8926e", "width": 1080, "height": 567}], "variants": {}, "id": "aq2gPWhzBmyTehFXVJaG6hnvy7E21-n_wlsqnnooncg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qhkb", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lyfgc", "is_robot_indexable": true, "report_reasons": null, "author": "ObviousGuess7078", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Colorado/comments/10lyfgc/colorado_landscape_photographer_john_fielder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://petapixel.com/2023/01/26/celebrated-nature-photographer-donates-lifes-work-to-public-domain/", "subreddit_subscribers": 308746, "created_utc": 1674756936.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1674790327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "petapixel.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keep your eyes open over the coming months, this will be incredibly beautiful artwork to add to any collection.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://petapixel.com/2023/01/26/celebrated-nature-photographer-donates-lifes-work-to-public-domain/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?auto=webp&amp;v=enabled&amp;s=c50a50e67471f361785cdf3f9f6b99f603aa763c", "width": 1600, "height": 840}, "resolutions": [{"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bbc4ab7b60bbb3f0ab4f73832e26bdc7e37d102", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a435a3c0efd7d8245fb3234ffd6fb443b6ff9341", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51376c2bdbd57b81436b4336bf4756fb22ec50b9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5438fb78ded20384f928f2e7cba6eba0ea9702bd", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6cf2231954ca52de340fdc7002b5a62d5ebf9e6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc4066d65ef29b4852e8b1a18e3ea5ed33d8926e", "width": 1080, "height": 567}], "variants": {}, "id": "aq2gPWhzBmyTehFXVJaG6hnvy7E21-n_wlsqnnooncg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mazgf", "is_robot_indexable": true, "report_reasons": null, "author": "HopeThisIsUnique", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10lyfgc", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mazgf/colorado_landscape_photographer_john_fielder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://petapixel.com/2023/01/26/celebrated-nature-photographer-donates-lifes-work-to-public-domain/", "subreddit_subscribers": 667389, "created_utc": 1674790327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Using Debian docker in UnRAID to successfully control the fans on the PowerVault MD1200 via the built in serial port on the Dell R720", "author_fullname": "t2_ymehjtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerVault MD1200 Fan Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10m05qd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FGNQKug_rk-pAGmK-euxiMol9-GtJX-qnfBfL1OasxI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674761266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using Debian docker in UnRAID to successfully control the fans on the PowerVault MD1200 via the built in serial port on the Dell R720&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/x2rzpfe3dhea1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?auto=webp&amp;v=enabled&amp;s=44fe0c5830d9948d3a60dae2ca0a32c152bce43c", "width": 3000, "height": 4000}, "resolutions": [{"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8feeedcc1e8186490872d49b765764678c05b5c", "width": 108, "height": 144}, {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14fe78e124a2a981bec3f241ff7a863e06c70cd4", "width": 216, "height": 288}, {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=964d40bd31bbe44cf0b6f197766a64576cfbff4f", "width": 320, "height": 426}, {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4eb47b89018b4c497e03a06188047f1daf6e3764", "width": 640, "height": 853}, {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448290c840d995d5eca9303b7f570328cb7dc39f", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/x2rzpfe3dhea1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20a514ac69dfb7c3b96f880e78ec901edcbb1b5c", "width": 1080, "height": 1440}], "variants": {}, "id": "7czIRe7qgRLivdvepDdU3TKYnwmdvskqJfFzfiMzkEg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10m05qd", "is_robot_indexable": true, "report_reasons": null, "author": "DeanbonianTheGreat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10m05qd/powervault_md1200_fan_control/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/x2rzpfe3dhea1.jpg", "subreddit_subscribers": 667389, "created_utc": 1674761266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is this possible? (with a playable format) With spotify premium. And maybe that songs that are deleted from a spotify playlist get moved to a \u201e[playlist name]_deleted songs\u201c folder on NAS.", "author_fullname": "t2_mtlt0enh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically download Spotify playlist songs to synology (e.g mp3)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lxnhd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674754987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this possible? (with a playable format) With spotify premium. And maybe that songs that are deleted from a spotify playlist get moved to a \u201e[playlist name]_deleted songs\u201c folder on NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lxnhd", "is_robot_indexable": true, "report_reasons": null, "author": "tbfpv", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lxnhd/automatically_download_spotify_playlist_songs_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lxnhd/automatically_download_spotify_playlist_songs_to/", "subreddit_subscribers": 667389, "created_utc": 1674754987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After only buying disks of amazon and feeling confident thay are good by good i mean new and with warenty. I payed \u00a320/tb kinda bad.\n\nWas wondering where can i get good but low cost per tb drives\n\nOr just alternate websites that sell good disks\n\nEdit:\n\nAm in the uk lol", "author_fullname": "t2_r311oil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best place to get hdd", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10maz9d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674793727.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674790311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After only buying disks of amazon and feeling confident thay are good by good i mean new and with warenty. I payed \u00a320/tb kinda bad.&lt;/p&gt;\n\n&lt;p&gt;Was wondering where can i get good but low cost per tb drives&lt;/p&gt;\n\n&lt;p&gt;Or just alternate websites that sell good disks&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;Am in the uk lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10maz9d", "is_robot_indexable": true, "report_reasons": null, "author": "hiiambobthebob", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10maz9d/best_place_to_get_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10maz9d/best_place_to_get_hdd/", "subreddit_subscribers": 667389, "created_utc": 1674790311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a Synology 1821+. It will have (6) 12TB drives. (2) of which are brand new, and the other (4) I will be using from my existing primary NAS. I have all my data on a backup NAS. My initial plan was to put all 6 drives in the new Synology, then migrate from the backup NAS. But...\n\nTo relieve some anxiety about know having all my eggs in one basket, I was thinking of installing the 2 brand new 12TB drives and filling those up with my most precious data first, and then installing the (4) drives from the old NAS, then migrating the remaining data from the backup NAS. \n\nIs this a smart way to do this? And regarding data transfer itself, is there a method I should be using to ensure the transfer goes smoothly? Does the Synology have some kind of fail safe transfer method built in? Sorry for the sophomoric questions, I haven't owned a Synology before, and have not done a large migration like this.", "author_fullname": "t2_9u63n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for migrating 40TB of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m8t6m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674783888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a Synology 1821+. It will have (6) 12TB drives. (2) of which are brand new, and the other (4) I will be using from my existing primary NAS. I have all my data on a backup NAS. My initial plan was to put all 6 drives in the new Synology, then migrate from the backup NAS. But...&lt;/p&gt;\n\n&lt;p&gt;To relieve some anxiety about know having all my eggs in one basket, I was thinking of installing the 2 brand new 12TB drives and filling those up with my most precious data first, and then installing the (4) drives from the old NAS, then migrating the remaining data from the backup NAS. &lt;/p&gt;\n\n&lt;p&gt;Is this a smart way to do this? And regarding data transfer itself, is there a method I should be using to ensure the transfer goes smoothly? Does the Synology have some kind of fail safe transfer method built in? Sorry for the sophomoric questions, I haven&amp;#39;t owned a Synology before, and have not done a large migration like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10m8t6m", "is_robot_indexable": true, "report_reasons": null, "author": "bee_ryan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10m8t6m/best_practices_for_migrating_40tb_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10m8t6m/best_practices_for_migrating_40tb_of_data/", "subreddit_subscribers": 667389, "created_utc": 1674783888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought some  Samsung SM863a SSD's from ebay, because I need some drives with PLP.  Unfortunately, they sat around on my desk for about 6 months before I got around to testing them, and in the seller's warehouse for an unknown amount of time before that.\n\nI've heard that SSDs that are unpowered - especially enterprise drives because of the assumption that they will be running 24/7 - can lose data if left unpowered.  And, having gotten a bit suspicious, I read the whole drive with dd.  It had about two dozen sectors it couldn't read.  smartctl's long test showed the same thing, reporting read errors.\n\nThinking it might be just from having sat, I wrote 0 to the whole drive, again with dd, and then repeated both tests.  This time, there were no errors from either reading the drive or the smartctl long test.\n\nThe smart attribute \"reallocated sectors\" increased after writing to the disk, however.\n\nSo my question is this:  are these drives fine, and just sat idle long enough to get read errors that are now corrected, as the cells that had too much charge leakage have now been written to and the drives are powered?\n\nOr, are these drives just failing?  Am I fooling myself by thinking I have an explanation for the reallocated sector count?  They have a high total bytes written - around a petabyte - but are rated even higher, around five petabytes.\n\nThe worst of them has these values:\n\n    5 Reallocated_Sector_Ct   0x0033   042   042   010    Pre-fail  Always       -       1900", "author_fullname": "t2_4d7rn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reallocated sector count on enterprise SSD that's been sitting without power for a while - am I crazy to use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m6bkv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674776812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought some  Samsung SM863a SSD&amp;#39;s from ebay, because I need some drives with PLP.  Unfortunately, they sat around on my desk for about 6 months before I got around to testing them, and in the seller&amp;#39;s warehouse for an unknown amount of time before that.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard that SSDs that are unpowered - especially enterprise drives because of the assumption that they will be running 24/7 - can lose data if left unpowered.  And, having gotten a bit suspicious, I read the whole drive with dd.  It had about two dozen sectors it couldn&amp;#39;t read.  smartctl&amp;#39;s long test showed the same thing, reporting read errors.&lt;/p&gt;\n\n&lt;p&gt;Thinking it might be just from having sat, I wrote 0 to the whole drive, again with dd, and then repeated both tests.  This time, there were no errors from either reading the drive or the smartctl long test.&lt;/p&gt;\n\n&lt;p&gt;The smart attribute &amp;quot;reallocated sectors&amp;quot; increased after writing to the disk, however.&lt;/p&gt;\n\n&lt;p&gt;So my question is this:  are these drives fine, and just sat idle long enough to get read errors that are now corrected, as the cells that had too much charge leakage have now been written to and the drives are powered?&lt;/p&gt;\n\n&lt;p&gt;Or, are these drives just failing?  Am I fooling myself by thinking I have an explanation for the reallocated sector count?  They have a high total bytes written - around a petabyte - but are rated even higher, around five petabytes.&lt;/p&gt;\n\n&lt;p&gt;The worst of them has these values:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;5 Reallocated_Sector_Ct   0x0033   042   042   010    Pre-fail  Always       -       1900\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10m6bkv", "is_robot_indexable": true, "report_reasons": null, "author": "TheFeshy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10m6bkv/reallocated_sector_count_on_enterprise_ssd_thats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10m6bkv/reallocated_sector_count_on_enterprise_ssd_thats/", "subreddit_subscribers": 667389, "created_utc": 1674776812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came across a brand new WD 120GB IDE drive. I don't have a use for it so I looked on ebay to sell it. There are multiple listings with prices all over the map, even up to $200. Is there a market for this tech? This makes no sense, given the prices of newer tech.", "author_fullname": "t2_8p0xhqi1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market for IDE drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10llavm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674713869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across a brand new WD 120GB IDE drive. I don&amp;#39;t have a use for it so I looked on ebay to sell it. There are multiple listings with prices all over the map, even up to $200. Is there a market for this tech? This makes no sense, given the prices of newer tech.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10llavm", "is_robot_indexable": true, "report_reasons": null, "author": "HelpfulPuppydog", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10llavm/market_for_ide_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10llavm/market_for_ide_drive/", "subreddit_subscribers": 667389, "created_utc": 1674713869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there Data Hoarders!\n\nLike many of you, I've tried building my own tracking tools, but I always found the process to be tedious and ultimately, I didn't use them consistently. Is there any other effortless way to track with minimal effort?\n\nAt the same time, I became increasingly aware of the vast amount of data that's being collected about us by big tech companies and started wondering if there was a way to put that data to good use, for our own understanding and well-being. As a designer, I believe there needs to be a product that puts our privacy and control first.\n\nInspired by the work of the community, I've been working on a new tool that allows you to store, organize, and understand your digital footprint from a central and secure place, using data exported from apps like Facebook. The tool also offers personalized reports that help you understand yourself better and make better decisions for your control and privacy.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/02s46jilibea1.png?width=1201&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=009b068c9b5cd324af0b45f0c825575c32cc7f0a\n\nI would love to get your feedback and thoughts on this project, and if you're interested, you can [sign up for early access on the landing page](https://unself.app).\n\n[Link](https://unself.app)\n\nThank you!", "author_fullname": "t2_9jj06w8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal Archiving App (Facebook, Google, Instagram, etc.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"02s46jilibea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/02s46jilibea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fc9c732a7db7fb7afb08fc6d11e31824110d73c"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/02s46jilibea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46d990898b9681348fd70ae63f61ff1109d7608d"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/02s46jilibea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=718c862103f2480646169e365b91ab2e41bbae8b"}, {"y": 336, "x": 640, "u": "https://preview.redd.it/02s46jilibea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1c3f1355e3e4f0afa8f96a59e5e95d0787bbfc0"}, {"y": 504, "x": 960, "u": "https://preview.redd.it/02s46jilibea1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26139759e88caa78d650cb4832360c10a1fa3835"}, {"y": 567, "x": 1080, "u": "https://preview.redd.it/02s46jilibea1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82e26592c0f1b2bd5a12c842ae8be9b1618e9d27"}], "s": {"y": 631, "x": 1201, "u": "https://preview.redd.it/02s46jilibea1.png?width=1201&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=009b068c9b5cd324af0b45f0c825575c32cc7f0a"}, "id": "02s46jilibea1"}}, "name": "t3_10ljtac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/g3_xEITXE-FSP3tykakhIBJBGm8kixE5kdcZgiBkzRg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674708642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there Data Hoarders!&lt;/p&gt;\n\n&lt;p&gt;Like many of you, I&amp;#39;ve tried building my own tracking tools, but I always found the process to be tedious and ultimately, I didn&amp;#39;t use them consistently. Is there any other effortless way to track with minimal effort?&lt;/p&gt;\n\n&lt;p&gt;At the same time, I became increasingly aware of the vast amount of data that&amp;#39;s being collected about us by big tech companies and started wondering if there was a way to put that data to good use, for our own understanding and well-being. As a designer, I believe there needs to be a product that puts our privacy and control first.&lt;/p&gt;\n\n&lt;p&gt;Inspired by the work of the community, I&amp;#39;ve been working on a new tool that allows you to store, organize, and understand your digital footprint from a central and secure place, using data exported from apps like Facebook. The tool also offers personalized reports that help you understand yourself better and make better decisions for your control and privacy.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/02s46jilibea1.png?width=1201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=009b068c9b5cd324af0b45f0c825575c32cc7f0a\"&gt;https://preview.redd.it/02s46jilibea1.png?width=1201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=009b068c9b5cd324af0b45f0c825575c32cc7f0a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I would love to get your feedback and thoughts on this project, and if you&amp;#39;re interested, you can &lt;a href=\"https://unself.app\"&gt;sign up for early access on the landing page&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://unself.app\"&gt;Link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?auto=webp&amp;v=enabled&amp;s=c7bfc08544fa9c44f760dad43fd1cf49e0796612", "width": 1201, "height": 631}, "resolutions": [{"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2536bf106cd34c12def39055c29b295f62a1e33e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72ed9670bfbf86af355d8d3e13713deb9d06ae65", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13a5dbec0618aa129da0dbe1e2de4986ce0f6e6f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c627ae3f315eb0713a8efdc2b18fdff6043583d1", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5c8fadac84e23bde92d7131f792c6fa8ae68c7e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/jWKa1gcd9NyJbXS7cChtZUwNLt9cfDoneaufVdjTU-8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad6bc7629b774db036222415479ca1279b9e2170", "width": 1080, "height": 567}], "variants": {}, "id": "QXiva9FDioxlJJKPXGzkoWbrLPEFmsSuCxfSEBLGcTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ljtac", "is_robot_indexable": true, "report_reasons": null, "author": "Sea-Slide7899", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ljtac/personal_archiving_app_facebook_google_instagram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ljtac/personal_archiving_app_facebook_google_instagram/", "subreddit_subscribers": 667389, "created_utc": 1674708642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just purchased two 18TB WD Easystore USB hard drives (rebadged WD Ultrastar DC HC550).\n\nDuring a copy today of a lot of data it started at 45 degrees C and reached 52 degrees C after an hour or so. I then pointed a large room fan at it, which dropped temps to the 37 degrees C range )before I stopped checking), so I do not know if it would have gotten warmer than 52 degrees.\n\nThese 18TB drives are officially rated to 60 degrees max.\n\n**Given that 60 degrees is the max: If the drive gets to 52 degrees C in use (or say even 55, assuming it would have continued to increase a bit, if I had not pointed the fan at it), would it be safe enough to run at 52 or 55 degrees for longevity?**\n\n**Or, if not, would one of these 120mm USB fans (placed under the drive) be worth it / make any difference for drive longevity?**\n\n[https://www.amazon.com/gp/product/B00JLV4BWC/ref=ppx\\_yo\\_dt\\_b\\_asin\\_title\\_o00\\_s00?ie=UTF8&amp;psc=1](https://www.amazon.com/gp/product/B00JLV4BWC/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1)\n\nI have read some reports recently that drive temperatures may not have a big impact on longevity (assuming of course they do not exceed the drive's rated max temperature).\n\nThanks for any feedback!\n\n*Side note - I have 2 8TB WD USB hard drives that were even warmer than that 53-54-55 at idle!.*\n\n*My Seagate 8TB USB hard drives (slower than WD) both run cooler 45 degrees or so at idle.*", "author_fullname": "t2_53b4nkd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is 52 or 55 degrees C a safe temperature for a WD EasyStore 18TB USB HDD (WD Ultrastar DC HC550)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10maaxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674788326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just purchased two 18TB WD Easystore USB hard drives (rebadged WD Ultrastar DC HC550).&lt;/p&gt;\n\n&lt;p&gt;During a copy today of a lot of data it started at 45 degrees C and reached 52 degrees C after an hour or so. I then pointed a large room fan at it, which dropped temps to the 37 degrees C range )before I stopped checking), so I do not know if it would have gotten warmer than 52 degrees.&lt;/p&gt;\n\n&lt;p&gt;These 18TB drives are officially rated to 60 degrees max.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Given that 60 degrees is the max: If the drive gets to 52 degrees C in use (or say even 55, assuming it would have continued to increase a bit, if I had not pointed the fan at it), would it be safe enough to run at 52 or 55 degrees for longevity?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Or, if not, would one of these 120mm USB fans (placed under the drive) be worth it / make any difference for drive longevity?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/gp/product/B00JLV4BWC/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;amp;psc=1\"&gt;https://www.amazon.com/gp/product/B00JLV4BWC/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have read some reports recently that drive temperatures may not have a big impact on longevity (assuming of course they do not exceed the drive&amp;#39;s rated max temperature).&lt;/p&gt;\n\n&lt;p&gt;Thanks for any feedback!&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Side note - I have 2 8TB WD USB hard drives that were even warmer than that 53-54-55 at idle!.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;My Seagate 8TB USB hard drives (slower than WD) both run cooler 45 degrees or so at idle.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10maaxo", "is_robot_indexable": true, "report_reasons": null, "author": "njuser66", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10maaxo/is_52_or_55_degrees_c_a_safe_temperature_for_a_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10maaxo/is_52_or_55_degrees_c_a_safe_temperature_for_a_wd/", "subreddit_subscribers": 667389, "created_utc": 1674788326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently found a webcomic I used to read a loooong time ago Surprisingly enough, it's continued to be updated up until last year. Being it's on a personal site, I'm not sure how I would go about archiving this so it's not another 10+ years before I loose and find it again. Maybe someone else has already done it and I just don't know. I'm also only interested in pulling the images of each page, not so much the whole site. [Here's](https://www.flipsidecomics.com/archive.php) the link to the site's archive page. Any help is appreciated!", "author_fullname": "t2_2yo9if6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How could I go about archiving an old webcomic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ma10d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674787487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently found a webcomic I used to read a loooong time ago Surprisingly enough, it&amp;#39;s continued to be updated up until last year. Being it&amp;#39;s on a personal site, I&amp;#39;m not sure how I would go about archiving this so it&amp;#39;s not another 10+ years before I loose and find it again. Maybe someone else has already done it and I just don&amp;#39;t know. I&amp;#39;m also only interested in pulling the images of each page, not so much the whole site. &lt;a href=\"https://www.flipsidecomics.com/archive.php\"&gt;Here&amp;#39;s&lt;/a&gt; the link to the site&amp;#39;s archive page. Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ma10d", "is_robot_indexable": true, "report_reasons": null, "author": "DeckardTBechard", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ma10d/how_could_i_go_about_archiving_an_old_webcomic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ma10d/how_could_i_go_about_archiving_an_old_webcomic/", "subreddit_subscribers": 667389, "created_utc": 1674787487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve seen tape, bdr, and libraries mentioned - I\u2019ve already added 1tb collecting the past week again, and I\u2019m getting the \u201ccompleteness\u201d bug - like I\u2019m looking at archiving 35 years, 25 years etc of my favorites like South Park, simpsons, hell even sponge bob is pretty big. \n\nAre there any management technologies I should look at for management? I also have many TBs of Roms, 400k commercial music releases and try to stay current. Is there any kind of data management software I should look at? Something to help? Excel documents are getting tired. The numerous drives are getting frustrating too.\n\nI breed reptiles and have management software - let\u2019s me visually see my collection, which has which genes etc, was hoping something existed for data management", "author_fullname": "t2_3xunvi1q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ordering 2 8tb drives payday - this will allow me to retire decade old 4tb drives. I\u2019ve started collecting again in anticipation of the upgrade - but for movies music and TV - what long term setup / management solutions should I google and get into?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m1o6r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674765329.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674765075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve seen tape, bdr, and libraries mentioned - I\u2019ve already added 1tb collecting the past week again, and I\u2019m getting the \u201ccompleteness\u201d bug - like I\u2019m looking at archiving 35 years, 25 years etc of my favorites like South Park, simpsons, hell even sponge bob is pretty big. &lt;/p&gt;\n\n&lt;p&gt;Are there any management technologies I should look at for management? I also have many TBs of Roms, 400k commercial music releases and try to stay current. Is there any kind of data management software I should look at? Something to help? Excel documents are getting tired. The numerous drives are getting frustrating too.&lt;/p&gt;\n\n&lt;p&gt;I breed reptiles and have management software - let\u2019s me visually see my collection, which has which genes etc, was hoping something existed for data management&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10m1o6r", "is_robot_indexable": true, "report_reasons": null, "author": "PythonsByX", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10m1o6r/ordering_2_8tb_drives_payday_this_will_allow_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10m1o6r/ordering_2_8tb_drives_payday_this_will_allow_me/", "subreddit_subscribers": 667389, "created_utc": 1674765075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Thanks", "author_fullname": "t2_yhqqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have five 2.5' external hdd. Can I use hard drive bay and merge them into raid recognizable by my laptop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lwzir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674753322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26.5TB+4TB Cloud", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lwzir", "is_robot_indexable": true, "report_reasons": null, "author": "nbcs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10lwzir/i_have_five_25_external_hdd_can_i_use_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lwzir/i_have_five_25_external_hdd_can_i_use_hard_drive/", "subreddit_subscribers": 667389, "created_utc": 1674753322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Lenovo PX4-400D, and I initially set it up with 3 drives, 14 TB each in RAID5. Creating the RAID took about 30 hours. I copied my stuff onto the NAS and it works fine. I thought I might as well throw another $200 at it and get the 4th drive. Expanding the RAID took 3 days, wow.\n\nNow when I look at my drive management, it shows all 4 disks. The capacity of my storage pool is show correctly, 38.14 TB but unfortunately, the newly added drive shows as \"Unallocated 12.71 TB\".\n\nI look at my volumes, and it says:  \nThis Volume: 25.43 TB  \nAllocated: 25.43 TB  \nUnallocated: 12.71 TB\n\nThere is a field where it shows the size of the volume in GB, 26037.72. This field is editable, and when I try to change the size to add the unallocated space and click Apply, it gives me an error saying \" The specified size is too big. \". OK, so I am using a smaller value, same error. Even when just adding 1 GB to the volume size, I get that error. At the same time, while entering a value, the volume sizes change correctly. When I go over the allocatable value, it corrects itself to the maximum available which is 39056.5859375 GB but as soon as I click Apply, I get that error again.\n\nI googled for the error and the only Lenovo result I get is for iSCSI.  \nWhat am I doing wrong? How can I resize the volume to use the full capacity of my storage pool?", "author_fullname": "t2_5ai3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lenovo PX4: Need help resizing volume after adding drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10luqc1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674747745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Lenovo PX4-400D, and I initially set it up with 3 drives, 14 TB each in RAID5. Creating the RAID took about 30 hours. I copied my stuff onto the NAS and it works fine. I thought I might as well throw another $200 at it and get the 4th drive. Expanding the RAID took 3 days, wow.&lt;/p&gt;\n\n&lt;p&gt;Now when I look at my drive management, it shows all 4 disks. The capacity of my storage pool is show correctly, 38.14 TB but unfortunately, the newly added drive shows as &amp;quot;Unallocated 12.71 TB&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I look at my volumes, and it says:&lt;br/&gt;\nThis Volume: 25.43 TB&lt;br/&gt;\nAllocated: 25.43 TB&lt;br/&gt;\nUnallocated: 12.71 TB&lt;/p&gt;\n\n&lt;p&gt;There is a field where it shows the size of the volume in GB, 26037.72. This field is editable, and when I try to change the size to add the unallocated space and click Apply, it gives me an error saying &amp;quot; The specified size is too big. &amp;quot;. OK, so I am using a smaller value, same error. Even when just adding 1 GB to the volume size, I get that error. At the same time, while entering a value, the volume sizes change correctly. When I go over the allocatable value, it corrects itself to the maximum available which is 39056.5859375 GB but as soon as I click Apply, I get that error again.&lt;/p&gt;\n\n&lt;p&gt;I googled for the error and the only Lenovo result I get is for iSCSI.&lt;br/&gt;\nWhat am I doing wrong? How can I resize the volume to use the full capacity of my storage pool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10luqc1", "is_robot_indexable": true, "report_reasons": null, "author": "saldridge", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10luqc1/lenovo_px4_need_help_resizing_volume_after_adding/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10luqc1/lenovo_px4_need_help_resizing_volume_after_adding/", "subreddit_subscribers": 667389, "created_utc": 1674747745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey I was wondering if anyone could help. I have turned on my Quantum LTO6 half height machine this morning but the enclosure power light is flickering. I have tried new cables etc but it doesn\u2019t seem to be starting, no being seen by windows.\nLink to video showing what I mean: \nhttps://imgur.com/a/j42bswa", "author_fullname": "t2_14genp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO 6 reader error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lreab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674738472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I was wondering if anyone could help. I have turned on my Quantum LTO6 half height machine this morning but the enclosure power light is flickering. I have tried new cables etc but it doesn\u2019t seem to be starting, no being seen by windows.\nLink to video showing what I mean: \n&lt;a href=\"https://imgur.com/a/j42bswa\"&gt;https://imgur.com/a/j42bswa&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KAbKUa51zTnaYfH1cmONLpr4ugZkH2aeocK412l_25M.jpg?auto=webp&amp;v=enabled&amp;s=4d6567b583de8ab61c4dda77c64ea29bba5ba6fe", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/KAbKUa51zTnaYfH1cmONLpr4ugZkH2aeocK412l_25M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f465fa5f5b3d479d15681678fb92ce498f2f541a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KAbKUa51zTnaYfH1cmONLpr4ugZkH2aeocK412l_25M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2c25b3428ecb3c43314d5a95658284dc7213ba4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KAbKUa51zTnaYfH1cmONLpr4ugZkH2aeocK412l_25M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da1656afbaa021f6a2bd58e81e8b6de1826b239b", "width": 320, "height": 168}], "variants": {}, "id": "EFnIBg2k8ngbHLy46g0ezi4hoRQi_y8GokgTbLk64Pc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10lreab", "is_robot_indexable": true, "report_reasons": null, "author": "rozza591", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10lreab/lto_6_reader_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10lreab/lto_6_reader_error/", "subreddit_subscribers": 667389, "created_utc": 1674738472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are There Protective Cases For External HDD\u2019s **With Cables?** (Against Impacts (Dropping vs.))\n\n&amp;#x200B;\n\n(I don\u2019t want to remove the cable off and put It to the case then make It ready to use again.)", "author_fullname": "t2_4rs6ei0p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are There Protective Cases For External HDD\u2019s With Cables? (Against Impacts)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ll6k2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674713441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are There Protective Cases For External HDD\u2019s &lt;strong&gt;With Cables?&lt;/strong&gt; (Against Impacts (Dropping vs.))&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(I don\u2019t want to remove the cable off and put It to the case then make It ready to use again.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ll6k2", "is_robot_indexable": true, "report_reasons": null, "author": "mainecoon364", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ll6k2/are_there_protective_cases_for_external_hdds_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ll6k2/are_there_protective_cases_for_external_hdds_with/", "subreddit_subscribers": 667389, "created_utc": 1674713441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a WD EX4100 with 4 WD 4TB red drives in a RAID 5 that is around 7 years old. I just bought a WD red pro 12TB for a cold storage backup. What is the best way to transfer 9TB of data to the 12TB cold storage drive? Do I just copy, paste to the new drive like a USB flash drive? I have never tried to transfer terabytes of data before. I don't do anything advanced with my NAS, I just store important personal and work files. I would like to not have to buy anything else, but I am open to anything.", "author_fullname": "t2_77uak", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up my small NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10mag26", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674788737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a WD EX4100 with 4 WD 4TB red drives in a RAID 5 that is around 7 years old. I just bought a WD red pro 12TB for a cold storage backup. What is the best way to transfer 9TB of data to the 12TB cold storage drive? Do I just copy, paste to the new drive like a USB flash drive? I have never tried to transfer terabytes of data before. I don&amp;#39;t do anything advanced with my NAS, I just store important personal and work files. I would like to not have to buy anything else, but I am open to anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10mag26", "is_robot_indexable": true, "report_reasons": null, "author": "Ainadaf", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10mag26/backing_up_my_small_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10mag26/backing_up_my_small_nas/", "subreddit_subscribers": 667389, "created_utc": 1674788737.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}