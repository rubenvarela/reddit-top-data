{"kind": "Listing", "data": {"after": "t3_10lwral", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data professional with 20 years of experience, I've seen repeated terms in tech over and over again. Today, I discovered \"**Personalized API**\", yet another new term for something that already existed. It's similar to an **Analytics API**, **Semantic Layer**, and other existing technologies.\n\nIt's important to remember that just because a term is new, doesn't mean the technology is. Data modeling with **Kimball/Inmon**, Reverse ETL, Data Mesh, and Data Lakes are just a few examples of familiar concepts that are being rebranded as new innovations.\n\n**One Big Table (OBT)**, mainly a big denormalized table, is the same as core and data marts **Dimensional Modeling** by Kimball/Inmon, published initially in February 1996, using **Materialized Views** to persist them.\n\n**Reverse ETL** is just an additional step to the existing data pipeline, or you might call it **Master Data Management (MDM)**, where Business people in typically \"stewardship\" add business data back to the DWH. **Semantic Layers** have been here since the beginning of Business Intelligence tools (called BO Universe); one could say it's also a fancy term for **OLAP Cubes**. Highly praised, although they have existed since the beginning of BI with SSAS (MS), OBIEE (Oracle), and SAP BI/BW (SAP).\n\n**Data Mesh** is another hyped term and another name for microservices, which we fought a couple of years back, breaking out of monolithic **Data Warehouses** or B**usiness Intelligence** applications. And if you want to add another buzzword here, **software-defined assets**, try a similar thing with defining each **Data Product** as an asset. **Data Contracts**, haven't we validated schemas and data types all our life? \ud83d\ude09 Encoding data tests in our applications, sometimes through creating an abstraction in-between with an API, sometimes within the ETL tool as part of **Data Governance**.\n\n**Data Lake** is another term for a **Data Warehouse** on top of distributed files. A **Lakehouse** is a data warehouse based on open standards.\n\nLet's not get caught up in buzzwords and hype. Let's focus on understanding the technology and its capabilities, rather than the name it's given. Have you encountered similar situations in your career, or what terms reminded you of something you learned long ago?", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Don't Fall for the Hype: A Data Professional's Perspective on Familiar Concepts Rebranded as Innovations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lsa27", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 189, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 189, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674741154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data professional with 20 years of experience, I&amp;#39;ve seen repeated terms in tech over and over again. Today, I discovered &amp;quot;&lt;strong&gt;Personalized API&lt;/strong&gt;&amp;quot;, yet another new term for something that already existed. It&amp;#39;s similar to an &lt;strong&gt;Analytics API&lt;/strong&gt;, &lt;strong&gt;Semantic Layer&lt;/strong&gt;, and other existing technologies.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s important to remember that just because a term is new, doesn&amp;#39;t mean the technology is. Data modeling with &lt;strong&gt;Kimball/Inmon&lt;/strong&gt;, Reverse ETL, Data Mesh, and Data Lakes are just a few examples of familiar concepts that are being rebranded as new innovations.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;One Big Table (OBT)&lt;/strong&gt;, mainly a big denormalized table, is the same as core and data marts &lt;strong&gt;Dimensional Modeling&lt;/strong&gt; by Kimball/Inmon, published initially in February 1996, using &lt;strong&gt;Materialized Views&lt;/strong&gt; to persist them.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Reverse ETL&lt;/strong&gt; is just an additional step to the existing data pipeline, or you might call it &lt;strong&gt;Master Data Management (MDM)&lt;/strong&gt;, where Business people in typically &amp;quot;stewardship&amp;quot; add business data back to the DWH. &lt;strong&gt;Semantic Layers&lt;/strong&gt; have been here since the beginning of Business Intelligence tools (called BO Universe); one could say it&amp;#39;s also a fancy term for &lt;strong&gt;OLAP Cubes&lt;/strong&gt;. Highly praised, although they have existed since the beginning of BI with SSAS (MS), OBIEE (Oracle), and SAP BI/BW (SAP).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Mesh&lt;/strong&gt; is another hyped term and another name for microservices, which we fought a couple of years back, breaking out of monolithic &lt;strong&gt;Data Warehouses&lt;/strong&gt; or B&lt;strong&gt;usiness Intelligence&lt;/strong&gt; applications. And if you want to add another buzzword here, &lt;strong&gt;software-defined assets&lt;/strong&gt;, try a similar thing with defining each &lt;strong&gt;Data Product&lt;/strong&gt; as an asset. &lt;strong&gt;Data Contracts&lt;/strong&gt;, haven&amp;#39;t we validated schemas and data types all our life? \ud83d\ude09 Encoding data tests in our applications, sometimes through creating an abstraction in-between with an API, sometimes within the ETL tool as part of &lt;strong&gt;Data Governance&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data Lake&lt;/strong&gt; is another term for a &lt;strong&gt;Data Warehouse&lt;/strong&gt; on top of distributed files. A &lt;strong&gt;Lakehouse&lt;/strong&gt; is a data warehouse based on open standards.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s not get caught up in buzzwords and hype. Let&amp;#39;s focus on understanding the technology and its capabilities, rather than the name it&amp;#39;s given. Have you encountered similar situations in your career, or what terms reminded you of something you learned long ago?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lsa27", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10lsa27/dont_fall_for_the_hype_a_data_professionals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lsa27/dont_fall_for_the_hype_a_data_professionals/", "subreddit_subscribers": 87574, "created_utc": 1674741154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good News, Everyone! \n\nSince September of last year I have sent hundreds of applications, been interviewing regularly, and turned down a few lackluster offers. This morning I received an offer from the best company I have interviewed with over this entire endeavor. \n\nI interviewed with \\~10 people from the company from recruiter to director over the past couple of weeks. All of which have shown themselves to be intelligent and enjoy the work that they do, which is shockingly uncommon.  \n\nThe company mission is not just vapid corporate-speak, but something I believe in and it seems the entirety of the team gets behind. Without doxing myself, I can say they do research and analytics for Government entities and foundations with an overarching goal of public welfare.\n\nThe company has work on all three cloud platforms, has mature+modern tech infrastructure, and offers the ability to learn and experiment with building solutions from scratch. \n\nI couldn't be more ecstatic to move to get away from the \"use &lt;ETL Tool&gt; to move data from this place to &lt;Datawarehouse&gt; and create a view for analysts to access it\" type of *engineering*\\--and I use that term loosely*--*work I was relegated to previously. \n\nMe: 2YOE, BA in Philosophy, M.Sc. in Information Management\n\nJob: Software Engineer (Cloud Data Platform), Full Remote (USA), 106k , 4 weeks PTO, Casual down-to-earth work culture\n\nA big thanks to this community for all of the advice and guidance over the past 2 years!", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got The Job!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lyfl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674756945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good News, Everyone! &lt;/p&gt;\n\n&lt;p&gt;Since September of last year I have sent hundreds of applications, been interviewing regularly, and turned down a few lackluster offers. This morning I received an offer from the best company I have interviewed with over this entire endeavor. &lt;/p&gt;\n\n&lt;p&gt;I interviewed with ~10 people from the company from recruiter to director over the past couple of weeks. All of which have shown themselves to be intelligent and enjoy the work that they do, which is shockingly uncommon.  &lt;/p&gt;\n\n&lt;p&gt;The company mission is not just vapid corporate-speak, but something I believe in and it seems the entirety of the team gets behind. Without doxing myself, I can say they do research and analytics for Government entities and foundations with an overarching goal of public welfare.&lt;/p&gt;\n\n&lt;p&gt;The company has work on all three cloud platforms, has mature+modern tech infrastructure, and offers the ability to learn and experiment with building solutions from scratch. &lt;/p&gt;\n\n&lt;p&gt;I couldn&amp;#39;t be more ecstatic to move to get away from the &amp;quot;use &amp;lt;ETL Tool&amp;gt; to move data from this place to &amp;lt;Datawarehouse&amp;gt; and create a view for analysts to access it&amp;quot; type of &lt;em&gt;engineering&lt;/em&gt;--and I use that term loosely&lt;em&gt;--&lt;/em&gt;work I was relegated to previously. &lt;/p&gt;\n\n&lt;p&gt;Me: 2YOE, BA in Philosophy, M.Sc. in Information Management&lt;/p&gt;\n\n&lt;p&gt;Job: Software Engineer (Cloud Data Platform), Full Remote (USA), 106k , 4 weeks PTO, Casual down-to-earth work culture&lt;/p&gt;\n\n&lt;p&gt;A big thanks to this community for all of the advice and guidance over the past 2 years!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10lyfl0", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lyfl0/got_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lyfl0/got_the_job/", "subreddit_subscribers": 87574, "created_utc": 1674756945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_11542k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte makes 100+ alpha / beta connectors free on Airbyte Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10lv9ga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UiT67c1DbFk3YPcaOWSdGEb4winn4lQ8MXgnW4djQDs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674749071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/why-airbyte-made-alpha-and-beta-connectors-free", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?auto=webp&amp;v=enabled&amp;s=30db1e097009b139d4f02815f1bd8bb68e94c26e", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07cb505f61cff44401dc8f507f51fb010daf1a67", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73ace3010dc34d5a4382df01f98b0949a8ff625c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f5820170915dfd25c51b84f38bd743ca782313c", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b61eef819ed6b7e70ae15bca9db07572b635c5ce", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2025f03516744854ab239926498717dbd5c7033", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Z2N_Ek5dt4L8cztaMpHcapmNv6pfKTWQ2FER0ji3BNc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90bbf85b8d1819e1fdb7b38a3ca25a53d86122e9", "width": 1080, "height": 565}], "variants": {}, "id": "2ezVreeCm3y-mWbeFajqySxGl9hca14MtLCSd0cqHKo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10lv9ga", "is_robot_indexable": true, "report_reasons": null, "author": "jeanlaf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lv9ga/airbyte_makes_100_alpha_beta_connectors_free_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/why-airbyte-made-alpha-and-beta-connectors-free", "subreddit_subscribers": 87574, "created_utc": 1674749071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Like a good tracking plan I could share with my manager to create a plan against ( I have a background in Data/analytics/ Engineering of 8 years , I think I need a bit more swe expertise then want to go into leadership). Any ideas on how I could setup this conversation well ?", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a good roadmap for getting into data engineering/ data platform management?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ltwdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674745604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like a good tracking plan I could share with my manager to create a plan against ( I have a background in Data/analytics/ Engineering of 8 years , I think I need a bit more swe expertise then want to go into leadership). Any ideas on how I could setup this conversation well ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10ltwdp", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ltwdp/does_anyone_have_a_good_roadmap_for_getting_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ltwdp/does_anyone_have_a_good_roadmap_for_getting_into/", "subreddit_subscribers": 87574, "created_utc": 1674745604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked at a few companies now where I have been able to get Snowflake brought in as the data warehouse solution. But what I always seem to run into is a few people in the organization that claim its so much more expensive than something like Azure SQL. I try to show that Snowflake maybe more expensive from a pure software cost but requires less engineers to get going (this might not be true for some but has been for my use cases). The time to value is short. Meaning a solution to the end user can be delivered quickly. I have also found ways to commercialize the built in functionality of Snowflake so its not just a added cost to our product but is a revenue generator. \n\nMost of the time when someone says something like Azure data warehouse tools are cheaper I ask them to model it but the result doesn't really show significant decreases in cost. I'm curious what others have experienced and how they have challenged some of the shade thrown at Snowflake and its cost.", "author_fullname": "t2_pm59e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of Snowflake vs alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m33yx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674768665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked at a few companies now where I have been able to get Snowflake brought in as the data warehouse solution. But what I always seem to run into is a few people in the organization that claim its so much more expensive than something like Azure SQL. I try to show that Snowflake maybe more expensive from a pure software cost but requires less engineers to get going (this might not be true for some but has been for my use cases). The time to value is short. Meaning a solution to the end user can be delivered quickly. I have also found ways to commercialize the built in functionality of Snowflake so its not just a added cost to our product but is a revenue generator. &lt;/p&gt;\n\n&lt;p&gt;Most of the time when someone says something like Azure data warehouse tools are cheaper I ask them to model it but the result doesn&amp;#39;t really show significant decreases in cost. I&amp;#39;m curious what others have experienced and how they have challenged some of the shade thrown at Snowflake and its cost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10m33yx", "is_robot_indexable": true, "report_reasons": null, "author": "carbongixxer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10m33yx/cost_of_snowflake_vs_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10m33yx/cost_of_snowflake_vs_alternatives/", "subreddit_subscribers": 87574, "created_utc": 1674768665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any AWS+Databricks users out there? If so, what are the benefits to this pairing beyond just a pure AWS implementation?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS vs AWS+Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lnnp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674723685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any AWS+Databricks users out there? If so, what are the benefits to this pairing beyond just a pure AWS implementation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lnnp7", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lnnp7/aws_vs_awsdatabricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lnnp7/aws_vs_awsdatabricks/", "subreddit_subscribers": 87574, "created_utc": 1674723685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been researching how to test properly. Since dbt requires you to actually run a model to be able to test it after, I was looking for a way to do this without running the model on prod tables.\n\nI came upon a snowflake feature of creating a zero copy clone of the prod table and run and test the model there first, and if test pass, run the model in prod. This copy should be identical to prod before running and testing. After the test pass I can drop the cloned table. \n\nMy question is. Is this over engineering? Can\u2019t I just create a view of the prod table and do this? Maybe create an incremental model or snapshot to just test new entries? Don\u2019t really know where to go. Or best solution. \n\nSeems doing a zero copy clone is the best practice here but don\u2019t know why (aside from speed and cost). Any other tips or ideas would be welcomed", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake zero copy clone for testing in prod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lpb7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674730965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been researching how to test properly. Since dbt requires you to actually run a model to be able to test it after, I was looking for a way to do this without running the model on prod tables.&lt;/p&gt;\n\n&lt;p&gt;I came upon a snowflake feature of creating a zero copy clone of the prod table and run and test the model there first, and if test pass, run the model in prod. This copy should be identical to prod before running and testing. After the test pass I can drop the cloned table. &lt;/p&gt;\n\n&lt;p&gt;My question is. Is this over engineering? Can\u2019t I just create a view of the prod table and do this? Maybe create an incremental model or snapshot to just test new entries? Don\u2019t really know where to go. Or best solution. &lt;/p&gt;\n\n&lt;p&gt;Seems doing a zero copy clone is the best practice here but don\u2019t know why (aside from speed and cost). Any other tips or ideas would be welcomed&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lpb7u", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lpb7u/snowflake_zero_copy_clone_for_testing_in_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lpb7u/snowflake_zero_copy_clone_for_testing_in_prod/", "subreddit_subscribers": 87574, "created_utc": 1674730965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm a DE setting up Databricks' for the first time at our org, collecting data from Azure Data Lake Gen2.\n\nI know the benefits of version control and have set up Git integration with GitHub so we can vc notebooks easily. I was going to keep all notebooks and dev, prod datasets in the same workspace but have come across articles like [this](https://medium.com/@kosmafuawka/what-ive-learned-setting-up-12-databricks-environments-81d7331d41b6) where the author has created 12 different workspaces for his one org. What's the benefit of doing this? Should I be doing the same (creating a dev, test, prod) workspace for me and my small team (&lt;5 people)?\n\nThanks,", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why would I need more than one Databricks workspace?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lthgc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674744536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a DE setting up Databricks&amp;#39; for the first time at our org, collecting data from Azure Data Lake Gen2.&lt;/p&gt;\n\n&lt;p&gt;I know the benefits of version control and have set up Git integration with GitHub so we can vc notebooks easily. I was going to keep all notebooks and dev, prod datasets in the same workspace but have come across articles like &lt;a href=\"https://medium.com/@kosmafuawka/what-ive-learned-setting-up-12-databricks-environments-81d7331d41b6\"&gt;this&lt;/a&gt; where the author has created 12 different workspaces for his one org. What&amp;#39;s the benefit of doing this? Should I be doing the same (creating a dev, test, prod) workspace for me and my small team (&amp;lt;5 people)?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ejB1ZqCIl4iaIU4xdFwp5_5XVg3vKG7avpC0zKHtdw.jpg?auto=webp&amp;v=enabled&amp;s=390ce3667b4247e3370f9c41213c528c63a44b43", "width": 772, "height": 721}, "resolutions": [{"url": "https://external-preview.redd.it/9ejB1ZqCIl4iaIU4xdFwp5_5XVg3vKG7avpC0zKHtdw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce7cd258f1aa9b0d3be0b059b07c0c7a6870e4bf", "width": 108, "height": 100}, {"url": "https://external-preview.redd.it/9ejB1ZqCIl4iaIU4xdFwp5_5XVg3vKG7avpC0zKHtdw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a4dcb91f36f3f0635665e88bfd0a651c1ac8b8c", "width": 216, "height": 201}, {"url": "https://external-preview.redd.it/9ejB1ZqCIl4iaIU4xdFwp5_5XVg3vKG7avpC0zKHtdw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe2b813d9f86d508a3f8dc6274ead93485e1385c", "width": 320, "height": 298}, {"url": "https://external-preview.redd.it/9ejB1ZqCIl4iaIU4xdFwp5_5XVg3vKG7avpC0zKHtdw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37974d5fa5b0d7ea3b8dd1ab6e00ee518b586af2", "width": 640, "height": 597}], "variants": {}, "id": "W425fV2y2yRESVll_9a-AFv_613ZlYI_M3HL64tmSvc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lthgc", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lthgc/why_would_i_need_more_than_one_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lthgc/why_would_i_need_more_than_one_databricks/", "subreddit_subscribers": 87574, "created_utc": 1674744536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there. I am using airflow (2.2.3) on an on Premise ec2 instance (and also locally) with docker for etl processes. Among other things I use amazon's SqlToS3Operator to transfer SQL Tables from my SQL Server to S3. For Most of the tables this works fine but there are some tables which are bigger than 1 GB (but below s3's Limit of 5 GB) i think my memory is too small to transfer these big files. \nUnfortunately there is no \"chunk\" parameter or Something similar available for this Operator. \nWhat would you do to tackle this issue? \nRewrite the standard Operator or loop over the table? Use Something Else than airflow in the First place? Buy more.memory? ;)\nLooking forward to your responses.", "author_fullname": "t2_as1vw8gf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow: Transfer Data from SQL Server to s3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lsolv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674744411.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674742310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. I am using airflow (2.2.3) on an on Premise ec2 instance (and also locally) with docker for etl processes. Among other things I use amazon&amp;#39;s SqlToS3Operator to transfer SQL Tables from my SQL Server to S3. For Most of the tables this works fine but there are some tables which are bigger than 1 GB (but below s3&amp;#39;s Limit of 5 GB) i think my memory is too small to transfer these big files. \nUnfortunately there is no &amp;quot;chunk&amp;quot; parameter or Something similar available for this Operator. \nWhat would you do to tackle this issue? \nRewrite the standard Operator or loop over the table? Use Something Else than airflow in the First place? Buy more.memory? ;)\nLooking forward to your responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lsolv", "is_robot_indexable": true, "report_reasons": null, "author": "One_Indication_6921", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lsolv/airflow_transfer_data_from_sql_server_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lsolv/airflow_transfer_data_from_sql_server_to_s3/", "subreddit_subscribers": 87574, "created_utc": 1674742310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently an year into my career and my experience has been a mixture of some DE(airflow,beam,nifi, Object stores, Hive) and a traditional Java backend engineer(Spring MVC,Spring Secuirty). I've tried to switch jobs but I'm not proficient enough in either to be hired either as a dedicated DE or Backend SE. \n\nThe place I work at is a DE shop with who expect me to fully transition to a more DE focused role towards the end of this year. I have my reservations regarding this because I fear I won't get to program as much as I would as a plain old Java BE. \n\nLast few months I've worked excessively with Bigquery, nifi and prebaked Data Connectors where there has been little to no procedural/OOP/functional programming (Except An occasional  groovy or bash script) and a lot of more of declarative programming(Query writing,k8 deployments etc).\n\nI basically want to figure out the most code intensive specialization/tech stack/design pattern in DE where i can continue to write software, without being limited  to a  SQL intensive  or low code role. If I can figure that out, I can devote my free time to learning it and implementing a project.\n\nCurrently I'm learning Hadoop,yarn and pySpark in my free time. Any help would be appreciated, thanks.", "author_fullname": "t2_3ucivv3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the skillset and technologies used by a Software engineer specializing in Data intensive applications rather than a full on DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lr5iv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674737710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently an year into my career and my experience has been a mixture of some DE(airflow,beam,nifi, Object stores, Hive) and a traditional Java backend engineer(Spring MVC,Spring Secuirty). I&amp;#39;ve tried to switch jobs but I&amp;#39;m not proficient enough in either to be hired either as a dedicated DE or Backend SE. &lt;/p&gt;\n\n&lt;p&gt;The place I work at is a DE shop with who expect me to fully transition to a more DE focused role towards the end of this year. I have my reservations regarding this because I fear I won&amp;#39;t get to program as much as I would as a plain old Java BE. &lt;/p&gt;\n\n&lt;p&gt;Last few months I&amp;#39;ve worked excessively with Bigquery, nifi and prebaked Data Connectors where there has been little to no procedural/OOP/functional programming (Except An occasional  groovy or bash script) and a lot of more of declarative programming(Query writing,k8 deployments etc).&lt;/p&gt;\n\n&lt;p&gt;I basically want to figure out the most code intensive specialization/tech stack/design pattern in DE where i can continue to write software, without being limited  to a  SQL intensive  or low code role. If I can figure that out, I can devote my free time to learning it and implementing a project.&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m learning Hadoop,yarn and pySpark in my free time. Any help would be appreciated, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10lr5iv", "is_robot_indexable": true, "report_reasons": null, "author": "forneptune", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lr5iv/what_would_be_the_skillset_and_technologies_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lr5iv/what_would_be_the_skillset_and_technologies_used/", "subreddit_subscribers": 87574, "created_utc": 1674737710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im leaning twards taking it but I'd like to know what I am getting myself into.", "author_fullname": "t2_lbwr665a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got offered a position as a data engineer: What are the pros and cons of this career move from software dev?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m73hf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674778912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im leaning twards taking it but I&amp;#39;d like to know what I am getting myself into.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10m73hf", "is_robot_indexable": true, "report_reasons": null, "author": "PM_ME_YOUR_PUZZLE", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10m73hf/got_offered_a_position_as_a_data_engineer_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10m73hf/got_offered_a_position_as_a_data_engineer_what/", "subreddit_subscribers": 87574, "created_utc": 1674778912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have recently came upon a company that use dbt-cloud for analysts / analytical engineers.  \nThey also use AirFlow for the data-engineers.  \n\n\nI wonder if this constellation is common, until recently I was under the impression that if a company made a migration to dbt-cloud then they would drop AirFlow / Dagster / Prefect / etc completely.\n\n&amp;#x200B;\n\nI would love to hear your thoughts on this scenario. Is it something that happens in companies you know as well? Can you share use cases in which you see value for having both dbt-cloud and AirFlow instance in the same organiztion? \n\n[View Poll](https://www.reddit.com/poll/10lnxn4)", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt-cloud along side orchestrator (like AirFlow) in the same company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lnxn4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674724948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently came upon a company that use dbt-cloud for analysts / analytical engineers.&lt;br/&gt;\nThey also use AirFlow for the data-engineers.  &lt;/p&gt;\n\n&lt;p&gt;I wonder if this constellation is common, until recently I was under the impression that if a company made a migration to dbt-cloud then they would drop AirFlow / Dagster / Prefect / etc completely.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this scenario. Is it something that happens in companies you know as well? Can you share use cases in which you see value for having both dbt-cloud and AirFlow instance in the same organiztion? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10lnxn4\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lnxn4", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674811348637, "options": [{"text": "Data engineers keep using AirFlow while AE use dbt cloud", "id": "21245203"}, {"text": "We migrated our entire flow to dbt-cloud", "id": "21245204"}, {"text": "We use dbt-core and AirFlow for scheduling only", "id": "21245205"}, {"text": "I just want to see the results", "id": "21245206"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 93, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lnxn4/dbtcloud_along_side_orchestrator_like_airflow_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10lnxn4/dbtcloud_along_side_orchestrator_like_airflow_in/", "subreddit_subscribers": 87574, "created_utc": 1674724948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With recent price increases for dbt cloud, will dbt drop support of the self-hosted version or start charging for it?\n\nIf so will it continue separately as a fully open source project from the latest freely available version?", "author_fullname": "t2_11bm9f4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt self-hosted - will dbt end support some time soon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10mbke6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674792112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With recent price increases for dbt cloud, will dbt drop support of the self-hosted version or start charging for it?&lt;/p&gt;\n\n&lt;p&gt;If so will it continue separately as a fully open source project from the latest freely available version?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10mbke6", "is_robot_indexable": true, "report_reasons": null, "author": "ar405", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10mbke6/dbt_selfhosted_will_dbt_end_support_some_time_soon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10mbke6/dbt_selfhosted_will_dbt_end_support_some_time_soon/", "subreddit_subscribers": 87574, "created_utc": 1674792112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrading Data Warehouse Infrastructure at Airbnb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10lxuyk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BoLxU0DjiTi00AUbhcCFBGwBxK_jwh8bS_A1Ei-N4iw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674755518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/airbnb-engineering/upgrading-data-warehouse-infrastructure-at-airbnb-a4e18f09b6d5", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?auto=webp&amp;v=enabled&amp;s=a4d02667f979c7167014afa25822f491eeca7d17", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0dda83a74126d4d030c74e3c783e73b0fd761857", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a83872d64498777a9dfc0f0dc0faee1d7e626df0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=224c0d57c4380bda4da28a3ae10c250e35d62948", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39b6d2d10ee92ec30691588f718fba33671fd551", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43c6fa2d2d68c52ba13dfab76205f23d3aac5a46", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/RcMM8otuY8cHFqdf3qseukZhgYWpScPrIvvjvYAA4eA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7aa8cda09064cdb6320f3bd6bb25a0ef3a04bc9", "width": 1080, "height": 720}], "variants": {}, "id": "KirUN9Dpbyi3ARjKQggW2FaqhoRtseffY0C3-FVuKNY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10lxuyk", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lxuyk/upgrading_data_warehouse_infrastructure_at_airbnb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/airbnb-engineering/upgrading-data-warehouse-infrastructure-at-airbnb-a4e18f09b6d5", "subreddit_subscribers": 87574, "created_utc": 1674755518.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the best centralised tool paid or open source that can run etl(iics/Matillion/airflow), python and shell scripts. \nLooking for a tool that can handle these variety of scripts such that the dependencies can be defined in a structured way.", "author_fullname": "t2_8rc5owyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Centralised Scheduler you use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lwl4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674752343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the best centralised tool paid or open source that can run etl(iics/Matillion/airflow), python and shell scripts. \nLooking for a tool that can handle these variety of scripts such that the dependencies can be defined in a structured way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lwl4y", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Wheel_78", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lwl4y/centralised_scheduler_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lwl4y/centralised_scheduler_you_use/", "subreddit_subscribers": 87574, "created_utc": 1674752343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Discussion topic incoming\u2026\n\nAs I advance in my career, the more I tend toward pedantic on the topic of names and standardization.\n\nDone poorly, names introduce unnecessary complexity prone to errors. And often persist in perpetuity \u2014 forever! Done well, reduce the ambiguity that leads to errors. (Hopefully forever).\n\nEasy, but requires discipline to *really think through all the implications*, versus whatever conscious thought happens to produce in 3 seconds, while rushing through an open dialog box.\n\nI\u2019d like to get practical perspective from others here on the sub:\n\n* Does your workplace have a strict, standardized naming policy? Are you really happy with it?\n\n* Even better\u2014 if you have a policy and happen to know the history, *how did the policy come about*?\n\n* Have you ever seen or been part of initiatives that address this topic for legacy environments? What was that like?\n\nFeel free to respond to any of the questions. Genuinely curious.\n\n\n\u2014\n\n\n\n*Bonus: reading material I found interesting and helpful:*\nhttps://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Naming resources: Do you have a rigorous standard/process/policy for naming new resources? (DBs, compute, storage, etc.)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lv904", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674749039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Discussion topic incoming\u2026&lt;/p&gt;\n\n&lt;p&gt;As I advance in my career, the more I tend toward pedantic on the topic of names and standardization.&lt;/p&gt;\n\n&lt;p&gt;Done poorly, names introduce unnecessary complexity prone to errors. And often persist in perpetuity \u2014 forever! Done well, reduce the ambiguity that leads to errors. (Hopefully forever).&lt;/p&gt;\n\n&lt;p&gt;Easy, but requires discipline to &lt;em&gt;really think through all the implications&lt;/em&gt;, versus whatever conscious thought happens to produce in 3 seconds, while rushing through an open dialog box.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to get practical perspective from others here on the sub:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Does your workplace have a strict, standardized naming policy? Are you really happy with it?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Even better\u2014 if you have a policy and happen to know the history, &lt;em&gt;how did the policy come about&lt;/em&gt;?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Have you ever seen or been part of initiatives that address this topic for legacy environments? What was that like?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Feel free to respond to any of the questions. Genuinely curious.&lt;/p&gt;\n\n&lt;p&gt;\u2014&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Bonus: reading material I found interesting and helpful:&lt;/em&gt;\n&lt;a href=\"https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming\"&gt;https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lv904", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lv904/naming_resources_do_you_have_a_rigorous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lv904/naming_resources_do_you_have_a_rigorous/", "subreddit_subscribers": 87574, "created_utc": 1674749039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi people, I hope you are doing well.\n\nIn the past I found some aws re:invent videos that shown different companies architectural designs. I lost those videos and I would like to revisit some case studies to improve my understanding of complex architectures for data ingestion, analysis and modeling.\n\nAny of you have somewhat related content?\n\nKindly post them here if you are able", "author_fullname": "t2_yybbc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Case studies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lu2hi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674746037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people, I hope you are doing well.&lt;/p&gt;\n\n&lt;p&gt;In the past I found some aws re:invent videos that shown different companies architectural designs. I lost those videos and I would like to revisit some case studies to improve my understanding of complex architectures for data ingestion, analysis and modeling.&lt;/p&gt;\n\n&lt;p&gt;Any of you have somewhat related content?&lt;/p&gt;\n\n&lt;p&gt;Kindly post them here if you are able&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lu2hi", "is_robot_indexable": true, "report_reasons": null, "author": "dataninsha", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lu2hi/case_studies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lu2hi/case_studies/", "subreddit_subscribers": 87574, "created_utc": 1674746037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! I'm new here and I'm sorry if I missed a similar question as I have. So basically, I want to learn data engineering but I find it hard to find a resource. I have a bit of background on AWS but mainly on the ML side of things and I barely touched some data engineering stuff. I just deploy and monitor our models and call it a day. I would love to hear your recommendations and ideally if there are resources that mainly works with AWS that would be awesome. Thank you!", "author_fullname": "t2_vih6a7g5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn data engineering for free (or at least cheaply)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lt1ek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674743335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! I&amp;#39;m new here and I&amp;#39;m sorry if I missed a similar question as I have. So basically, I want to learn data engineering but I find it hard to find a resource. I have a bit of background on AWS but mainly on the ML side of things and I barely touched some data engineering stuff. I just deploy and monitor our models and call it a day. I would love to hear your recommendations and ideally if there are resources that mainly works with AWS that would be awesome. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lt1ek", "is_robot_indexable": true, "report_reasons": null, "author": "bravaddude", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lt1ek/how_to_learn_data_engineering_for_free_or_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lt1ek/how_to_learn_data_engineering_for_free_or_at/", "subreddit_subscribers": 87574, "created_utc": 1674743335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replace your Airflow Sensors with that \ud83d\udc47", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_10lspqm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/45seCWMA7pweCyY_9VGASPO6mHtQReuaRbzbmbZnbp4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674742400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/feed/update/urn:li:activity:7024375498122125312/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8Ivs9Z8Pm-ucRFfXhWX_2cbefj61cQrflrIYAnmtmfY.jpg?auto=webp&amp;v=enabled&amp;s=d3927efe13918259fccb91037771f0938ce08599", "width": 800, "height": 416}, "resolutions": [{"url": "https://external-preview.redd.it/8Ivs9Z8Pm-ucRFfXhWX_2cbefj61cQrflrIYAnmtmfY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=473c9a901c15c2b9b06914e624dc3975cacab6c0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/8Ivs9Z8Pm-ucRFfXhWX_2cbefj61cQrflrIYAnmtmfY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b8ee3aa270baa31abb6d36e047d90ef376cbf59", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/8Ivs9Z8Pm-ucRFfXhWX_2cbefj61cQrflrIYAnmtmfY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ffbaa645a0bbd3ba000fc3af99f03e4792ee329", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/8Ivs9Z8Pm-ucRFfXhWX_2cbefj61cQrflrIYAnmtmfY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=873c8612b638e1be56f946d61125f2842d6f41fd", "width": 640, "height": 332}], "variants": {}, "id": "HfV5LkeyBSVFiZRCEfyFw4NKG6mfv_UIlIHwlDOretc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10lspqm", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lspqm/replace_your_airflow_sensors_with_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/feed/update/urn:li:activity:7024375498122125312/", "subreddit_subscribers": 87574, "created_utc": 1674742400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\nI am a fresher who joined the team that works on data governance, we work on various tools like snowflake, datahub, etc. I am new to this area, I will soon have discussion in manager that would determine my role in the team from what all I got to know it is an interesting field that helps defining rules for better management. Please highlight scope of various tools used for data governance. \nWould be grateful for help..", "author_fullname": "t2_66513e19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the scope of data governance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ls6b9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674740847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,\nI am a fresher who joined the team that works on data governance, we work on various tools like snowflake, datahub, etc. I am new to this area, I will soon have discussion in manager that would determine my role in the team from what all I got to know it is an interesting field that helps defining rules for better management. Please highlight scope of various tools used for data governance. \nWould be grateful for help..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ls6b9", "is_robot_indexable": true, "report_reasons": null, "author": "nikiii_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ls6b9/what_is_the_scope_of_data_governance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ls6b9/what_is_the_scope_of_data_governance/", "subreddit_subscribers": 87574, "created_utc": 1674740847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks,\n\nas per title, my question is very straightforward: we all know DevOps best practices recommend having multiple environments to test our code before pushing to production, rightfully so.\n\nWhile in a traditional application the approach and benefits are quite obvious, I'm not sure when it comes to building a data stack.\n\nFor starters, because staging and prod data are not the same, e.g. usually staging data is much smaller than prod data.\n\nA second doubt I have regards data warehouses: do you have a single database with multiple schemas that represent different envs? Do you create multiple databases or even multiple dwh instances to separate the environments?\n\nAnyway, generically speaking, how do you apply this concept when it comes to building data stacks?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage multiple environments for your data stacks (e.g. dev, staging, prod) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lrt1k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674739739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks,&lt;/p&gt;\n\n&lt;p&gt;as per title, my question is very straightforward: we all know DevOps best practices recommend having multiple environments to test our code before pushing to production, rightfully so.&lt;/p&gt;\n\n&lt;p&gt;While in a traditional application the approach and benefits are quite obvious, I&amp;#39;m not sure when it comes to building a data stack.&lt;/p&gt;\n\n&lt;p&gt;For starters, because staging and prod data are not the same, e.g. usually staging data is much smaller than prod data.&lt;/p&gt;\n\n&lt;p&gt;A second doubt I have regards data warehouses: do you have a single database with multiple schemas that represent different envs? Do you create multiple databases or even multiple dwh instances to separate the environments?&lt;/p&gt;\n\n&lt;p&gt;Anyway, generically speaking, how do you apply this concept when it comes to building data stacks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10lrt1k", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lrt1k/how_do_you_manage_multiple_environments_for_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lrt1k/how_do_you_manage_multiple_environments_for_your/", "subreddit_subscribers": 87574, "created_utc": 1674739739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  \n\nHi,\n\nI\u2019m not sure if this is the right place to ask this question, but I guess I\u2019ll find out soon enough. \n\nI currently do the bulk of the development-work for a new multi-tenant SaaS application that provides users with a GUI for monitoring a multitude of IOT-sensors. As the amount of sensors and data is growing, we\u2019re running into some scaling problems (not the data itself per se, more the managing of it all).\n\nMy main question is: Does any of you guys have any recommendations on tools or best practices we could investigate? Or see ways to improve our current setup? There are a lot of tools available, and solutions can of course be made in a multitude of ways. Before I dive blindly into everything myself and probably waste a lot of time, I\u2019d like to pick the collective Reddit brain.\n\nSome contexts:\n\nI\u2019m a developer with experience mainly in front- and backend development, but not particularly in data-engineering. I did however do a fair amount of ETL with python in the past and am comfortable using SQL/PostgreSQL. \n\nOur SaaS allows users to do simple CRUD operations and some very basic analytics (find data/sensors between start and end date with tags). The backend makes use of a PostgreSQL database via Flask (I guess this is called OLTP). \n\nNext to this we have a separate PostgreSQL database (I think this is called OLAP) that stores all the sensor-data. This database has one table with all the raw data of all the sensors (smallest time interval is 15 minutes) and 4 aggregate tables which store the sensor-data per hour, day, month, and year. The raw data gets imported, parsed, enriched, and aggregated via cron-python scripts. We import (poll) the data from multiple 3rd parties. \n\nI have the following concerns:\n\n\\- It feels like storing all sensor-data in one table (raw and per aggregate) must eventually cause performance issues. Especially given the multi-tenant nature of the application.\n\n\\- It feels like the cron-python scripts need to be managed and monitored all the time. Schema changes for example break the scripts.\n\n\\- Because our only option with some 3rd parties is polling for data (i.e., requesting data from the 3rd party API between a provided start- and end-date, sometimes with a limited window size of for example 60 days) synchronising this data with the database feels finnicky. The current system for example looks for the latest measurement timestamp in the database, then requests 3rd party-API with that timestamp as start date (with now as end date) and syncs the data. If data is found, the latest timestamp is stored for the next request. If no data is found, now() is inserted. Since data can be missed this way if the 3rd party provider has an outage, or when there are late arrivals, this solution doesn\u2019t feel robust. It feels like there must be a solution out there that does this (syncing data between vendor API and our own database) in a simpler way right out of the box.\n\nSome added complexity is that some of the data-enrichment needs to be done manually (for example adding address, geolocation or sensor-type) and some of these enrichments decide how the data is parsed (sensor-type).\n\nWhile this system did work good enough for the startup-phase of our SaaS, we need to find a more robust solution that requires less baby-sitting. I have looked into Snowflake and Databricks, the latter of which looks very promising as we already have a lot of the parsing logic that can be easily integrated via notebooks. Databricks might though be overkill. I think what I\u2019m looking for is a solution that is (mostly) managed. As I\u2019m currently doing most of the software-engineering work myself, I really can\u2019t spend too much time on the infrastructure/hosting side of things.\n\nThanks in advance!", "author_fullname": "t2_a8reuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on DE strategy/tools for our growing business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lnftv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674722716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure if this is the right place to ask this question, but I guess I\u2019ll find out soon enough. &lt;/p&gt;\n\n&lt;p&gt;I currently do the bulk of the development-work for a new multi-tenant SaaS application that provides users with a GUI for monitoring a multitude of IOT-sensors. As the amount of sensors and data is growing, we\u2019re running into some scaling problems (not the data itself per se, more the managing of it all).&lt;/p&gt;\n\n&lt;p&gt;My main question is: Does any of you guys have any recommendations on tools or best practices we could investigate? Or see ways to improve our current setup? There are a lot of tools available, and solutions can of course be made in a multitude of ways. Before I dive blindly into everything myself and probably waste a lot of time, I\u2019d like to pick the collective Reddit brain.&lt;/p&gt;\n\n&lt;p&gt;Some contexts:&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a developer with experience mainly in front- and backend development, but not particularly in data-engineering. I did however do a fair amount of ETL with python in the past and am comfortable using SQL/PostgreSQL. &lt;/p&gt;\n\n&lt;p&gt;Our SaaS allows users to do simple CRUD operations and some very basic analytics (find data/sensors between start and end date with tags). The backend makes use of a PostgreSQL database via Flask (I guess this is called OLTP). &lt;/p&gt;\n\n&lt;p&gt;Next to this we have a separate PostgreSQL database (I think this is called OLAP) that stores all the sensor-data. This database has one table with all the raw data of all the sensors (smallest time interval is 15 minutes) and 4 aggregate tables which store the sensor-data per hour, day, month, and year. The raw data gets imported, parsed, enriched, and aggregated via cron-python scripts. We import (poll) the data from multiple 3rd parties. &lt;/p&gt;\n\n&lt;p&gt;I have the following concerns:&lt;/p&gt;\n\n&lt;p&gt;- It feels like storing all sensor-data in one table (raw and per aggregate) must eventually cause performance issues. Especially given the multi-tenant nature of the application.&lt;/p&gt;\n\n&lt;p&gt;- It feels like the cron-python scripts need to be managed and monitored all the time. Schema changes for example break the scripts.&lt;/p&gt;\n\n&lt;p&gt;- Because our only option with some 3rd parties is polling for data (i.e., requesting data from the 3rd party API between a provided start- and end-date, sometimes with a limited window size of for example 60 days) synchronising this data with the database feels finnicky. The current system for example looks for the latest measurement timestamp in the database, then requests 3rd party-API with that timestamp as start date (with now as end date) and syncs the data. If data is found, the latest timestamp is stored for the next request. If no data is found, now() is inserted. Since data can be missed this way if the 3rd party provider has an outage, or when there are late arrivals, this solution doesn\u2019t feel robust. It feels like there must be a solution out there that does this (syncing data between vendor API and our own database) in a simpler way right out of the box.&lt;/p&gt;\n\n&lt;p&gt;Some added complexity is that some of the data-enrichment needs to be done manually (for example adding address, geolocation or sensor-type) and some of these enrichments decide how the data is parsed (sensor-type).&lt;/p&gt;\n\n&lt;p&gt;While this system did work good enough for the startup-phase of our SaaS, we need to find a more robust solution that requires less baby-sitting. I have looked into Snowflake and Databricks, the latter of which looks very promising as we already have a lot of the parsing logic that can be easily integrated via notebooks. Databricks might though be overkill. I think what I\u2019m looking for is a solution that is (mostly) managed. As I\u2019m currently doing most of the software-engineering work myself, I really can\u2019t spend too much time on the infrastructure/hosting side of things.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lnftv", "is_robot_indexable": true, "report_reasons": null, "author": "Mapital", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lnftv/looking_for_advice_on_de_strategytools_for_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lnftv/looking_for_advice_on_de_strategytools_for_our/", "subreddit_subscribers": 87574, "created_utc": 1674722716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nWe're starting to build our data pipelines and have considered moving to Airflow as the orchestrator.\n\nUntil today, for each ETL, we've used a 1 specific lambda function which takes a configuration file to distinguish between data sources and was triggered via an eventbridge schedule.\n\nThe pros of this was CI/CD and version control, each time we had an update we simply updated this lambda.\n\nThe cons are that the possibility of having a bug caused by 1 specific ETL can damage other ETL's, so we want to move to a non-monolithic approach i.e. distribute the workload to different lambdas.\n\nConsidering the fact that we'll have 30+ different type of ETL's, do you think this approach is suitable? the downside of this in my opinion is that we'll have to create a different lambda for each ETL to prevent it from having any dependency of other ETL's code\n\nThanks! :)", "author_fullname": "t2_lnj0ynrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow w/ dockerized AWS lambda pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lzqbg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674760204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re starting to build our data pipelines and have considered moving to Airflow as the orchestrator.&lt;/p&gt;\n\n&lt;p&gt;Until today, for each ETL, we&amp;#39;ve used a 1 specific lambda function which takes a configuration file to distinguish between data sources and was triggered via an eventbridge schedule.&lt;/p&gt;\n\n&lt;p&gt;The pros of this was CI/CD and version control, each time we had an update we simply updated this lambda.&lt;/p&gt;\n\n&lt;p&gt;The cons are that the possibility of having a bug caused by 1 specific ETL can damage other ETL&amp;#39;s, so we want to move to a non-monolithic approach i.e. distribute the workload to different lambdas.&lt;/p&gt;\n\n&lt;p&gt;Considering the fact that we&amp;#39;ll have 30+ different type of ETL&amp;#39;s, do you think this approach is suitable? the downside of this in my opinion is that we&amp;#39;ll have to create a different lambda for each ETL to prevent it from having any dependency of other ETL&amp;#39;s code&lt;/p&gt;\n\n&lt;p&gt;Thanks! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lzqbg", "is_robot_indexable": true, "report_reasons": null, "author": "GiladHecht", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lzqbg/airflow_w_dockerized_aws_lambda_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lzqbg/airflow_w_dockerized_aws_lambda_pipeline/", "subreddit_subscribers": 87574, "created_utc": 1674760204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nLess than a year ago I co-founded a real estate startup and, in spite of our tools being limited to Google Drive and Microsoft Office, we are still in business (phew!). My professional background is in finance, which just means I was an Excel technician who built large financial models &amp; data analysis workbooks (.xlsx files) to facilitate investment decisions.\n\nTo date, my technical expertise with Excel has kept the business afloat from the standpoints of data standardization and analysis. However, we can no longer scale our business on Excel and Google Drive (i.e. time to move to the cloud), and are ready to begin developing custom applications to automate workflows and improve our customers' digital experience.\n\nBefore committing to a database management system such as MySQL, MongoDB, or PostgreSQL, I want to ask the r/dataengineering community about recommendations for which DBMS I should consider and the skills I should learn? (if it makes a difference, I have spent most of my time thus far on the Google Cloud platform)\n\nWe are not at a stage where I can hire a full-time data or software engineer, but I am committed to learning enough about these systems to start us off on the right track and become an effective manager when the time comes. The specific challenge I am facing right now is as follows:\n\n* All property data is stored in an Excel file on Google Drive. This data is pasted into a larger Excel workbook that acts as our booking, pricing, and inventory tracking engine. As you'd imagine, this workbook contains many interconnected tabs, hundreds of linked formulas, and thousands of columns/lines (and I am slightly proud of it);\n* I need to transform this offline 'booking engine' to something that is cloud-based and can communicate with JavaScript frameworks such as Node.js and React (i.e. to develop a web-based booking engine with pretty UI); \n* Finally, I do not have enough DE experience to understand (i) how I would move my Excel workbook / booking engine to the cloud, (ii) which DBMS would be best for the job, and (iii) what skills I will need to complete the project.\n\nAny input you guys have would be hugely appreciated.", "author_fullname": "t2_dlnv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Engineering. What tools &amp; skills are necessary to migrate a complex model (built in Excel) to the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lxvjc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674755559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;Less than a year ago I co-founded a real estate startup and, in spite of our tools being limited to Google Drive and Microsoft Office, we are still in business (phew!). My professional background is in finance, which just means I was an Excel technician who built large financial models &amp;amp; data analysis workbooks (.xlsx files) to facilitate investment decisions.&lt;/p&gt;\n\n&lt;p&gt;To date, my technical expertise with Excel has kept the business afloat from the standpoints of data standardization and analysis. However, we can no longer scale our business on Excel and Google Drive (i.e. time to move to the cloud), and are ready to begin developing custom applications to automate workflows and improve our customers&amp;#39; digital experience.&lt;/p&gt;\n\n&lt;p&gt;Before committing to a database management system such as MySQL, MongoDB, or PostgreSQL, I want to ask the &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; community about recommendations for which DBMS I should consider and the skills I should learn? (if it makes a difference, I have spent most of my time thus far on the Google Cloud platform)&lt;/p&gt;\n\n&lt;p&gt;We are not at a stage where I can hire a full-time data or software engineer, but I am committed to learning enough about these systems to start us off on the right track and become an effective manager when the time comes. The specific challenge I am facing right now is as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;All property data is stored in an Excel file on Google Drive. This data is pasted into a larger Excel workbook that acts as our booking, pricing, and inventory tracking engine. As you&amp;#39;d imagine, this workbook contains many interconnected tabs, hundreds of linked formulas, and thousands of columns/lines (and I am slightly proud of it);&lt;/li&gt;\n&lt;li&gt;I need to transform this offline &amp;#39;booking engine&amp;#39; to something that is cloud-based and can communicate with JavaScript frameworks such as Node.js and React (i.e. to develop a web-based booking engine with pretty UI); &lt;/li&gt;\n&lt;li&gt;Finally, I do not have enough DE experience to understand (i) how I would move my Excel workbook / booking engine to the cloud, (ii) which DBMS would be best for the job, and (iii) what skills I will need to complete the project.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any input you guys have would be hugely appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lxvjc", "is_robot_indexable": true, "report_reasons": null, "author": "Salubriously_Moist", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lxvjc/new_to_data_engineering_what_tools_skills_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lxvjc/new_to_data_engineering_what_tools_skills_are/", "subreddit_subscribers": 87574, "created_utc": 1674755559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a function to modify data, let's call it modifyFunction.\n\nWe are getting an error when modifying several specific columns, and I need to identify all of them. I don't have access to change the function, otherwise I could simply change the function to return 'error' as a string. Instead, the statement is cancelled after the first error is encountered (expected behavior).\n\n&amp;#x200B;\n\nIdeally, I would want something like this:\n\n**Statement:**\n\n`select`\n\n`decryptFunction(column_name1)`\n\n,`decryptFunction(column_name2)`\n\n`....`\n\n`from myTable.`\n\n**Desired Output:**\n\n`'abc', 'kej', 'ERROR', 'kje', 'wer', 'ERROR'`\n\n**Actual Output:**\n\n`Statement Failed: column &lt;column_name&gt; could not be converted (something like that).`\n\nMy ideas for solutions have been:\n\n* Find something similar to `coalesce(modifyFunction(column_name), 'error')` for errors, not NULLs.\n* Create a stored proc to go through each column (feels brutally inefficient.)\n* Find a way to use a case statement (can't find any way to do so)\n\nWithout access to the underlying function, what approach would you take?", "author_fullname": "t2_714yyvua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coalesce, but for errors in SQL (Snowflake) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lwral", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674752742.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a function to modify data, let&amp;#39;s call it modifyFunction.&lt;/p&gt;\n\n&lt;p&gt;We are getting an error when modifying several specific columns, and I need to identify all of them. I don&amp;#39;t have access to change the function, otherwise I could simply change the function to return &amp;#39;error&amp;#39; as a string. Instead, the statement is cancelled after the first error is encountered (expected behavior).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would want something like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Statement:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;select&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;decryptFunction(column_name1)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;,&lt;code&gt;decryptFunction(column_name2)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;....&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;from myTable.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Desired Output:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;&amp;#39;abc&amp;#39;, &amp;#39;kej&amp;#39;, &amp;#39;ERROR&amp;#39;, &amp;#39;kje&amp;#39;, &amp;#39;wer&amp;#39;, &amp;#39;ERROR&amp;#39;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Actual Output:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Statement Failed: column &amp;lt;column_name&amp;gt; could not be converted (something like that).&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;My ideas for solutions have been:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Find something similar to &lt;code&gt;coalesce(modifyFunction(column_name), &amp;#39;error&amp;#39;)&lt;/code&gt; for errors, not NULLs.&lt;/li&gt;\n&lt;li&gt;Create a stored proc to go through each column (feels brutally inefficient.)&lt;/li&gt;\n&lt;li&gt;Find a way to use a case statement (can&amp;#39;t find any way to do so)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Without access to the underlying function, what approach would you take?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10lwral", "is_robot_indexable": true, "report_reasons": null, "author": "amtobin33", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10lwral/coalesce_but_for_errors_in_sql_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10lwral/coalesce_but_for_errors_in_sql_snowflake/", "subreddit_subscribers": 87574, "created_utc": 1674752742.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}