{"kind": "Listing", "data": {"after": "t3_10lya3g", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have just wrapped up first round interviews for an open position on my team. I work in banking and most of my career involves building regression or logistic regression models.\n\nOne of the trends I've seen since the tech data science boom started is that there just seems to be a drop in the technical level for peoples with masters degree on fundamentals. It seems too many candidates with masters degrees  do not understand mathematical assumptions of most of the models they are using even at a conceptual level.   For example, during the interview I asked most candidates about regression and what assumptions are required.\n\nNearly every single masters level candidate didn't know why the specific assumptions were made (even if they could correctly list them), could not answer questions on what happens when you violate an assumption, and did not know how to test violation of those assumptions or how to address those issues. Whats disconcerting is these are candidates coming out of professional masters programs from the worlds leading universities and most of them will end up in jobs where modeling error can have multi-million dollar impacts.\n\nFor some additional context: The comment here is explicitly here about standard of candidates I interviewed for people with masters degrees. Most of the Ph.D jobs met standards we expect, even though the job does not require one. The job is one that is very specifically related to regression modeling, time series.", "author_fullname": "t2_je0a2jeu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm a tired of interviewing fresh graduates that don't know fundamentals.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m6kpq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 257, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 257, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674786789.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674777528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have just wrapped up first round interviews for an open position on my team. I work in banking and most of my career involves building regression or logistic regression models.&lt;/p&gt;\n\n&lt;p&gt;One of the trends I&amp;#39;ve seen since the tech data science boom started is that there just seems to be a drop in the technical level for peoples with masters degree on fundamentals. It seems too many candidates with masters degrees  do not understand mathematical assumptions of most of the models they are using even at a conceptual level.   For example, during the interview I asked most candidates about regression and what assumptions are required.&lt;/p&gt;\n\n&lt;p&gt;Nearly every single masters level candidate didn&amp;#39;t know why the specific assumptions were made (even if they could correctly list them), could not answer questions on what happens when you violate an assumption, and did not know how to test violation of those assumptions or how to address those issues. Whats disconcerting is these are candidates coming out of professional masters programs from the worlds leading universities and most of them will end up in jobs where modeling error can have multi-million dollar impacts.&lt;/p&gt;\n\n&lt;p&gt;For some additional context: The comment here is explicitly here about standard of candidates I interviewed for people with masters degrees. Most of the Ph.D jobs met standards we expect, even though the job does not require one. The job is one that is very specifically related to regression modeling, time series.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 70, "id": "award_b1b44fa1-8179-4d84-a9ed-f25bb81f1c5f", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=a6f300e1309aa93756b3a36593bd8f606520e508", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=1af1af2596ad64df163b8b17cad4eee836939c2c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=b0237705862865dce1a1db3ea40064155eb14d58", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=54dde5ae7d66ed63151707df52341663e3d9669e", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=2d0a1a9b902c3b3acaf3560c9d3662c19d3cd0cf", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "*Lowers face into palm*", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Facepalm", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=a6f300e1309aa93756b3a36593bd8f606520e508", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=1af1af2596ad64df163b8b17cad4eee836939c2c", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=b0237705862865dce1a1db3ea40064155eb14d58", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=54dde5ae7d66ed63151707df52341663e3d9669e", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=2d0a1a9b902c3b3acaf3560c9d3662c19d3cd0cf", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/ey2iodron2s41_Facepalm.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m6kpq", "is_robot_indexable": true, "report_reasons": null, "author": "nanashiaoe2de", "discussion_type": null, "num_comments": 328, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m6kpq/im_a_tired_of_interviewing_fresh_graduates_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m6kpq/im_a_tired_of_interviewing_fresh_graduates_that/", "subreddit_subscribers": 841501, "created_utc": 1674777528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am DS director. I have 8 YOE in analytics and 6 YOE in DS. My base is 175k and I get 20% bonus which fluctuates. No equity, RSU, or ESPP.\n\nI don\u2019t want to move up because I don\u2019t want to do more management tasks. I see people on here talking about making 200k+.\n\nAny ideas on how to make more without moving further into management?", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I make more money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lsdyo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674741472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am DS director. I have 8 YOE in analytics and 6 YOE in DS. My base is 175k and I get 20% bonus which fluctuates. No equity, RSU, or ESPP.&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t want to move up because I don\u2019t want to do more management tasks. I see people on here talking about making 200k+.&lt;/p&gt;\n\n&lt;p&gt;Any ideas on how to make more without moving further into management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lsdyo", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 134, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10lsdyo/how_do_i_make_more_money/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10lsdyo/how_do_i_make_more_money/", "subreddit_subscribers": 841501, "created_utc": 1674741472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data analyst and have a physics background, and to be honest I\u2019ve always had a relatively pragmatic approach to statistical programming. I\u2019ll write functions when it seems like I\u2019m going to be doing something a lot, otherwise I won\u2019t.\n\nIn my work I\u2019ll quite often start a new R script, or SQL script, and rather than write *everything* from scratch, I\u2019ll typically copy and paste the code across from previous scripts - E.g. package loading in R, functions I use a lot, things like read_csv but just change the file path. Even though a lot of this is just lazy stuff that I probably know how to do, I feel like I don\u2019t have the time to just write it all out from scratch again.\n\nJust wondering if anyone else does things like this?", "author_fullname": "t2_1x2kyanz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often do you copy and paste code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lz6vf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674758887.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data analyst and have a physics background, and to be honest I\u2019ve always had a relatively pragmatic approach to statistical programming. I\u2019ll write functions when it seems like I\u2019m going to be doing something a lot, otherwise I won\u2019t.&lt;/p&gt;\n\n&lt;p&gt;In my work I\u2019ll quite often start a new R script, or SQL script, and rather than write &lt;em&gt;everything&lt;/em&gt; from scratch, I\u2019ll typically copy and paste the code across from previous scripts - E.g. package loading in R, functions I use a lot, things like read_csv but just change the file path. Even though a lot of this is just lazy stuff that I probably know how to do, I feel like I don\u2019t have the time to just write it all out from scratch again.&lt;/p&gt;\n\n&lt;p&gt;Just wondering if anyone else does things like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lz6vf", "is_robot_indexable": true, "report_reasons": null, "author": "JLane1996", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10lz6vf/how_often_do_you_copy_and_paste_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10lz6vf/how_often_do_you_copy_and_paste_code/", "subreddit_subscribers": 841501, "created_utc": 1674758887.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been job searching since November 2022 and my severance just ran out.\n\nI received an official offer letter from company A over a week ago and today learned that another, company B, wants to make an offer, but probably won\u2019t have it until next week.\n\nFrom the quoted figures, I believe company B won\u2019t be able to match my current offer (they are also not yet public, whereas A), and I\u2019m already tired of negotiating/interviewing.\n\nIs there a way to gracefully withdraw with company B? I told them I already got an offer and it\u2019s a difficult decision. I just don\u2019t want to wait anymore to secure a job given the market conditions.", "author_fullname": "t2_3gi52xce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to withdraw from job offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m4ois", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674772497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been job searching since November 2022 and my severance just ran out.&lt;/p&gt;\n\n&lt;p&gt;I received an official offer letter from company A over a week ago and today learned that another, company B, wants to make an offer, but probably won\u2019t have it until next week.&lt;/p&gt;\n\n&lt;p&gt;From the quoted figures, I believe company B won\u2019t be able to match my current offer (they are also not yet public, whereas A), and I\u2019m already tired of negotiating/interviewing.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to gracefully withdraw with company B? I told them I already got an offer and it\u2019s a difficult decision. I just don\u2019t want to wait anymore to secure a job given the market conditions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10m4ois", "is_robot_indexable": true, "report_reasons": null, "author": "questforthrowaway", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m4ois/how_to_withdraw_from_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m4ois/how_to_withdraw_from_job_offer/", "subreddit_subscribers": 841501, "created_utc": 1674772497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Could you give some practical examples of when this question has come up in your work and why you made your decision? Sorry if this is very vague I feel as though I'm missing a piece of information that makes the answer to this question very obvious", "author_fullname": "t2_aghpz5g9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When would you choose to conduct a hypothesis test vs run a linear regression?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m1b5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674764144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could you give some practical examples of when this question has come up in your work and why you made your decision? Sorry if this is very vague I feel as though I&amp;#39;m missing a piece of information that makes the answer to this question very obvious&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m1b5l", "is_robot_indexable": true, "report_reasons": null, "author": "Careless-Tailor-2317", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m1b5l/when_would_you_choose_to_conduct_a_hypothesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m1b5l/when_would_you_choose_to_conduct_a_hypothesis/", "subreddit_subscribers": 841501, "created_utc": 1674764144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title mentions, I\u2019ve been in this sub for around 5 months. Hoping to see more in-depth data science discussion rather than students trying to justify that data science is worth going into or how to break into data science from another career. I don\u2019t think I\u2019ve seen another sub quite like this one with the degree of questions asked like this from people outside of the field. Especially how many duplicate/repeat questions I see every day.\n\nAre there better sub reddits to be in besides this where more advanced topics are discussed?", "author_fullname": "t2_t3mak0w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this sub only for new grads, students, and career swaps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mf4gx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674804509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title mentions, I\u2019ve been in this sub for around 5 months. Hoping to see more in-depth data science discussion rather than students trying to justify that data science is worth going into or how to break into data science from another career. I don\u2019t think I\u2019ve seen another sub quite like this one with the degree of questions asked like this from people outside of the field. Especially how many duplicate/repeat questions I see every day.&lt;/p&gt;\n\n&lt;p&gt;Are there better sub reddits to be in besides this where more advanced topics are discussed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mf4gx", "is_robot_indexable": true, "report_reasons": null, "author": "801Fluidity", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mf4gx/is_this_sub_only_for_new_grads_students_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mf4gx/is_this_sub_only_for_new_grads_students_and/", "subreddit_subscribers": 841501, "created_utc": 1674804509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a full time insurtech data scientist for over a year, and looking to switch, what are some topics I should most definitely study for?", "author_fullname": "t2_tq6mxkv8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientist hiring managers, what is something you ask in an interview that makes or breaks the deal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m9qtz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674786643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a full time insurtech data scientist for over a year, and looking to switch, what are some topics I should most definitely study for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10m9qtz", "is_robot_indexable": true, "report_reasons": null, "author": "notmynameduh", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m9qtz/data_scientist_hiring_managers_what_is_something/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m9qtz/data_scientist_hiring_managers_what_is_something/", "subreddit_subscribers": 841501, "created_utc": 1674786643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm following 2 papers by Fader et al. for calculating LTV for a subscription based business. \n\nI even found a post that breaks the method down in simpler terms. \n\nhttps://towardsdatascience.com/customer-lifetime-value-in-a-discrete-time-contractual-setting-math-and-python-implementation-af3ef606cefe\n\nFollowing the paper found below, the author picks a single imaginary yearly cohort and uses that to calculate LTV. It all makes sense and I get it, but what I don't understand is how do we account for multiple cohorts using this method? Would we perform the calculation for each yearly cohort and take an average result for the LTV? Or randomly sample users from all cohorts and perform survival calculations based on this.\n\nHas anybody got experience using this method? If you could provide any insight it would be much appreciated.\n\nhttp://brucehardie.com/notes/032/", "author_fullname": "t2_2gzsok4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modelling LTV in a discrete time contractual setting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m379s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674768881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m following 2 papers by Fader et al. for calculating LTV for a subscription based business. &lt;/p&gt;\n\n&lt;p&gt;I even found a post that breaks the method down in simpler terms. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/customer-lifetime-value-in-a-discrete-time-contractual-setting-math-and-python-implementation-af3ef606cefe\"&gt;https://towardsdatascience.com/customer-lifetime-value-in-a-discrete-time-contractual-setting-math-and-python-implementation-af3ef606cefe&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Following the paper found below, the author picks a single imaginary yearly cohort and uses that to calculate LTV. It all makes sense and I get it, but what I don&amp;#39;t understand is how do we account for multiple cohorts using this method? Would we perform the calculation for each yearly cohort and take an average result for the LTV? Or randomly sample users from all cohorts and perform survival calculations based on this.&lt;/p&gt;\n\n&lt;p&gt;Has anybody got experience using this method? If you could provide any insight it would be much appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://brucehardie.com/notes/032/\"&gt;http://brucehardie.com/notes/032/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pXzYZYo4O7BfVBtyY-LFOXgKFpgK205LDtsV5IBdAaw.jpg?auto=webp&amp;v=enabled&amp;s=82068897da034df431f9bc4b5e4bae7cd520b185", "width": 612, "height": 390}, "resolutions": [{"url": "https://external-preview.redd.it/pXzYZYo4O7BfVBtyY-LFOXgKFpgK205LDtsV5IBdAaw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82d0f73815f3b97fd963f24044046de566a10d16", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/pXzYZYo4O7BfVBtyY-LFOXgKFpgK205LDtsV5IBdAaw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a43a7a8a4d6b5c77ecc4b2d28ce2368161b1254", "width": 216, "height": 137}, {"url": "https://external-preview.redd.it/pXzYZYo4O7BfVBtyY-LFOXgKFpgK205LDtsV5IBdAaw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcd8c094f575c7411dd7f03666f617bbd78da933", "width": 320, "height": 203}], "variants": {}, "id": "is0nRhFUvVstxQPK9TAy3PJgeakQufJMQw2tfVCBmFg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m379s", "is_robot_indexable": true, "report_reasons": null, "author": "ciarandeceol1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m379s/modelling_ltv_in_a_discrete_time_contractual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m379s/modelling_ltv_in_a_discrete_time_contractual/", "subreddit_subscribers": 841501, "created_utc": 1674768881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a senior data analyst and I regularly pull out data and make dashboards - basically grunt work. I'm curious as to what BI managers do? In my org, all analysts are just a part of the department they're in, there's no separate BI department. \n\nDo BI Managers just sit around and write a strategy document that says this is how requests will be fulfilled, dashboards should have these KPIs, models should be x etc?", "author_fullname": "t2_8uvbqmtb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do BI Managers do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m2viw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674768073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a senior data analyst and I regularly pull out data and make dashboards - basically grunt work. I&amp;#39;m curious as to what BI managers do? In my org, all analysts are just a part of the department they&amp;#39;re in, there&amp;#39;s no separate BI department. &lt;/p&gt;\n\n&lt;p&gt;Do BI Managers just sit around and write a strategy document that says this is how requests will be fulfilled, dashboards should have these KPIs, models should be x etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m2viw", "is_robot_indexable": true, "report_reasons": null, "author": "informatica6", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m2viw/what_do_bi_managers_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m2viw/what_do_bi_managers_do/", "subreddit_subscribers": 841501, "created_utc": 1674768073.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hbglt7lp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An interesting major project idea for college level related to data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mg9op", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674809272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mg9op", "is_robot_indexable": true, "report_reasons": null, "author": "mukeshpilane", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mg9op/an_interesting_major_project_idea_for_college/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mg9op/an_interesting_major_project_idea_for_college/", "subreddit_subscribers": 841501, "created_utc": 1674809272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! Im working on a project with huge amounts of data, actually, the model we are using is xgboost, im trying to increase the performance of my model and I came up with the idea of clusterize my data in an unsupervised way (with out the target in the dataset) and use the clusterization results as a new feature. So I fit several k means (k=3, k= 7, k= 10 and k = 15) to my training dataset and use the clusters as new features to try to improve my xgboost.\n\nDo you think my approach has sense?", "author_fullname": "t2_8j69r4rr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "K-means clusters as features for more complex models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mc1mz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674793633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Im working on a project with huge amounts of data, actually, the model we are using is xgboost, im trying to increase the performance of my model and I came up with the idea of clusterize my data in an unsupervised way (with out the target in the dataset) and use the clusterization results as a new feature. So I fit several k means (k=3, k= 7, k= 10 and k = 15) to my training dataset and use the clusters as new features to try to improve my xgboost.&lt;/p&gt;\n\n&lt;p&gt;Do you think my approach has sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mc1mz", "is_robot_indexable": true, "report_reasons": null, "author": "_bmph_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mc1mz/kmeans_clusters_as_features_for_more_complex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mc1mz/kmeans_clusters_as_features_for_more_complex/", "subreddit_subscribers": 841501, "created_utc": 1674793633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vb57b4y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quantum Machine Learning: An Advanced End-to-End Project Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10m8aq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BO7YH2pvkQn7B9NooCFQmTdn1vzzIfBj9cJVJQ7Rw6w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674782361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/3316c542226d", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?auto=webp&amp;v=enabled&amp;s=37499d290de5e0be1d980df91710e4b85fee2fe9", "width": 960, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26e62a1280b3aa27203d8154d9874ea4b535a931", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5da7a188277092155d2cee431e6d10528b6accfb", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cef08db1caab416657c9941a55fa60124c8c9f11", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=beaf1fa7dfb012773e11b7c47299f2722b165e6b", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/SVIx_UjYXatXGelCdaKd7katZKHIKg7PvZYaIK_OvKU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52bbf7d1c1ed5a065bd17bba637dcb18bbeb50e3", "width": 960, "height": 640}], "variants": {}, "id": "hwO60Vy8qz7fzvS6lzOlw0e8uT-9LJaux15ofFCZjoE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m8aq0", "is_robot_indexable": true, "report_reasons": null, "author": "Historical-Pen9653", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m8aq0/quantum_machine_learning_an_advanced_endtoend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/3316c542226d", "subreddit_subscribers": 841501, "created_utc": 1674782361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good morning \n\nI am working on an interesting report for management. I am taking all the usage and cost reports for all mobile devices (hotspots, tablets, cell phones) in the organization (by cost center) and creating a dashboard to show utilization. The initial request was for a report to show outliers. But the more I dig into the data, the more I\u2019m convinced it isn\u2019t the outliers so much, it\u2019s the un/under utilization of devices that is noteworthy. \n\nIf an employee is using their company cell phone for thousands of minutes a month, but we are paying a standard flat rate for an unlimited plan, that is less meaningful to know than a user who isn\u2019t using their phone at all. \n\nUnused lines are easy, because it\u2019s a simple measure. Underutilized could be easy by simply taking everything below the average, but how do you qualify those lines that are underutilized is less valuable?\n\nSo question one is, how would you go about identifying and assigning a value to \u201cunderutilized\u201d lines?\n\nUnused lines are tricky as well. It would be easy to say, \u201cget rid of any device where minutes or data = 0.\u201d But what happens if a device needs to be replaced? And usage is a point in time measurement. A device could have 0 usage one month, and then above average the next. So it\u2019s really the duration the device is unused. \n\nSecond question is, what should that duration be? \n\nFinally, all the devices have upgrade eligibility dates. There are high demand users on very old devices and a few old, unused devices, and a few newer way underutilized devices. \n\nFinal question, how would you create a report/model that recommends a replacement?\n\nI appreciate any insight. \n\nThanks!", "author_fullname": "t2_9pmoyw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mobile Device Inventory Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lssd2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674742613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning &lt;/p&gt;\n\n&lt;p&gt;I am working on an interesting report for management. I am taking all the usage and cost reports for all mobile devices (hotspots, tablets, cell phones) in the organization (by cost center) and creating a dashboard to show utilization. The initial request was for a report to show outliers. But the more I dig into the data, the more I\u2019m convinced it isn\u2019t the outliers so much, it\u2019s the un/under utilization of devices that is noteworthy. &lt;/p&gt;\n\n&lt;p&gt;If an employee is using their company cell phone for thousands of minutes a month, but we are paying a standard flat rate for an unlimited plan, that is less meaningful to know than a user who isn\u2019t using their phone at all. &lt;/p&gt;\n\n&lt;p&gt;Unused lines are easy, because it\u2019s a simple measure. Underutilized could be easy by simply taking everything below the average, but how do you qualify those lines that are underutilized is less valuable?&lt;/p&gt;\n\n&lt;p&gt;So question one is, how would you go about identifying and assigning a value to \u201cunderutilized\u201d lines?&lt;/p&gt;\n\n&lt;p&gt;Unused lines are tricky as well. It would be easy to say, \u201cget rid of any device where minutes or data = 0.\u201d But what happens if a device needs to be replaced? And usage is a point in time measurement. A device could have 0 usage one month, and then above average the next. So it\u2019s really the duration the device is unused. &lt;/p&gt;\n\n&lt;p&gt;Second question is, what should that duration be? &lt;/p&gt;\n\n&lt;p&gt;Finally, all the devices have upgrade eligibility dates. There are high demand users on very old devices and a few old, unused devices, and a few newer way underutilized devices. &lt;/p&gt;\n\n&lt;p&gt;Final question, how would you create a report/model that recommends a replacement?&lt;/p&gt;\n\n&lt;p&gt;I appreciate any insight. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lssd2", "is_robot_indexable": true, "report_reasons": null, "author": "dat0dat", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10lssd2/mobile_device_inventory_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10lssd2/mobile_device_inventory_management/", "subreddit_subscribers": 841501, "created_utc": 1674742613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/35vtxrwnekea1.png?width=720&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=95e113299668b569f64ca6ecaa095b948a15e78b)\n\nMicrosoft is investing $10B into OpenAI!\n\nThere is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.\n\nThe fear is that OpenAI\u2019s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.\n\nHowever, the specifics of the deal tell a different story.\n\nTo understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!\n\nTo appreciate better why there is some three-dimensional chess going on, let\u2019s first look at Sam Altman\u2019s backstory.\n\n*Let\u2019s go!*\n\n# A Stellar Rise\n\nBack in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.\n\nInstead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.\n\nBy YC standards, this was a pretty unimpressive outcome.\n\nHowever, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.\n\nHe listed young Sam Altman next to Steve Jobs, Larry &amp; Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.\n\nAnd Sam Altman played his hand well!\n\nHe parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \\[2\\]. In addition, Paul Graham made him his successor as president of YC in 2014.\n\nWithin one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.\n\nToday, he is the CEO of OpenAI \u2014 one of the most exciting and impactful organizations in all of tech.\n\nHowever, OpenAI \u2014 the rocket ship of AI innovation \u2014 is in dire straights.\n\n# OpenAI is Bleeding Cash\n\nBack in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.\n\nThat money is long gone.\n\nIn 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost &gt;$500M over the last year alone.\n\nThis is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.\n\nIn addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \\[4\\].\n\nSo, where does this leave them today?\n\nBefore the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn\u2019t take a genius to figure out that they are running low on cash.\n\nIt would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can\u2019t they just lease them and make a killing?\n\nYes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.\n\n*Here are some reasons why!*\n\n# The Tough Business Of Machine Learning\n\nMachine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.\n\nTo start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \\[7\\].\n\nOn the one hand, the massive compute requirements and thorny data management problems drive up costs.\n\nOn the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.\n\nTo illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT\u2019s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.\n\n*Alright, alright, alright! Machine learning is hard.*\n\n*OpenAI already has ChatGPT working. That\u2019s gotta be worth something?*\n\n# Foundation Models Might Become Commodities:\n\nIn order to monetize GPT or any of their other models, OpenAI can go two different routes.\n\nFirst, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.\n\nThis is not going to happen. Reasons for it include:\n\n1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.\n2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.\n3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.\n\nThe second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.\n\nThis approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.\n\nAs an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.\n\nAs a result GPT inference would become a common good. This would melt OpenAI\u2019s profits down to a tiny bit of nothing.\n\nIn this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI\u2019s API control the interface to the customer, they would likely end up capturing all of the value.\n\nAn argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).\n\nTo sum it up:\n\n* They don\u2019t have a way to sustainably monetize their models.\n* They do not want and probably should not build up internal sales and marketing teams to capture verticals\n* They need a lot of money to keep funding their research without getting bogged down by details of specific product development\n\n*So, what should they do?*\n\n# The Microsoft Deal\n\nOpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.\n\nAt this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.\n\nHowever, the astounding size is not the only extraordinary thing about this deal.\n\nFirst off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.\n\nIf OpenAI starts making money, the profits are distributed differently across four stages:\n\n1. First, early investors (probably Khosla Ventures and Reid Hoffman\u2019s foundation) get their money back with interest.\n2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid\n3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.\n4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \\[3\\]\n\n# What This Means\n\nThis is absolutely crazy!\n\nOpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.\n\nOn top of that, they solved their distribution problem. They now have access to Microsoft\u2019s sales teams and their models will be integrated into MS Office products.\n\nMicrosoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.\n\nThe synergies do not stop there.\n\nOpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).\n\nThe deal creates a beautiful win-win situation, but that is not even the best part.\n\nSam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.\n\nHowever, if OpenAI creates something in the direction of AGI \u2014 whatever that looks like \u2014 the value of it will likely be huge.\n\nIn that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.\n\n*Wow!*\n\nWhether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.\n\n*This deal is an absolute power move!*\n\nI look forward to the future. Such exciting times to be alive!\n\nAs always, I really enjoyed making this for you and I sincerely hope you found it useful!\n\n*Thank you for reading!*\n\nWould you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** \u2b55.\n\nI send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)\n\n**References:**\n\n\\[1\\] [https://golden.com/wiki/Sam\\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)\u200b\n\n\\[2\\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)\u200b\n\n\\[3\\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&amp;_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)\u200b\n\n\\[4\\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG\n\n\\[5\\] [https://www.crunchbase.com/organization/openai/company\\_financials](https://www.crunchbase.com/organization/openai/company_financials)\u200b\n\n\\[6\\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)\u200b\n\n\\[7\\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)", "author_fullname": "t2_az3v2qdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2b55 What People Are Missing About Microsoft\u2019s $10B Investment In OpenAI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": true, "media_metadata": {"35vtxrwnekea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/35vtxrwnekea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=082dc82e65b35970135a934c57e90b55a004787f"}, {"y": 97, "x": 216, "u": "https://preview.redd.it/35vtxrwnekea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d5d0f9648e2f425532d921c12b33b4ce13e7aa1a"}, {"y": 144, "x": 320, "u": "https://preview.redd.it/35vtxrwnekea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63de83664f9f15bbbb86175d00eaf49a6438c2d8"}, {"y": 289, "x": 640, "u": "https://preview.redd.it/35vtxrwnekea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=668a0b50d7b55d8cc08e4d895ecb40a25284e7e1"}], "s": {"y": 326, "x": 720, "u": "https://preview.redd.it/35vtxrwnekea1.png?width=720&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=95e113299668b569f64ca6ecaa095b948a15e78b"}, "id": "35vtxrwnekea1"}}, "name": "t3_10mi1x8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bJbLo-Bw93fhTswEwZSKq8-8NuwXyBeZ4LhAR5DUbXg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674816738.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/35vtxrwnekea1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=95e113299668b569f64ca6ecaa095b948a15e78b\"&gt;Sam Altman Might Have Just Pulled Off The Coup Of The Decade&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Microsoft is investing $10B into OpenAI!&lt;/p&gt;\n\n&lt;p&gt;There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, &lt;a href=\"https://openai.com/blog/introducing-openai/\"&gt;free&lt;/a&gt; of economic pressures.&lt;/p&gt;\n\n&lt;p&gt;The fear is that OpenAI\u2019s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.&lt;/p&gt;\n\n&lt;p&gt;However, the specifics of the deal tell a different story.&lt;/p&gt;\n\n&lt;p&gt;To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!&lt;/p&gt;\n\n&lt;p&gt;To appreciate better why there is some three-dimensional chess going on, let\u2019s first look at Sam Altman\u2019s backstory.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Let\u2019s go!&lt;/em&gt;&lt;/p&gt;\n\n&lt;h1&gt;A Stellar Rise&lt;/h1&gt;\n\n&lt;p&gt;Back in 2005, Sam Altman founded &lt;a href=\"https://en.wikipedia.org/wiki/Loopt\"&gt;Loopt&lt;/a&gt; and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.&lt;/p&gt;\n\n&lt;p&gt;Instead of caving, he managed to sell his startup for $&lt;a href=\"https://golden.com/wiki/Sam_Altman-J5GKK5\"&gt;43M&lt;/a&gt; to the finTech company &lt;a href=\"https://www.greendot.com/\"&gt;Green Dot&lt;/a&gt;. Investors got their money back and he personally made $5M from the sale.&lt;/p&gt;\n\n&lt;p&gt;By YC standards, this was a pretty unimpressive outcome.&lt;/p&gt;\n\n&lt;p&gt;However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 &lt;a href=\"http://www.paulgraham.com/5founders.html?viewfullsite=1\"&gt;essay&lt;/a&gt; about the five founders who influenced him the most.&lt;/p&gt;\n\n&lt;p&gt;He listed young Sam Altman next to Steve Jobs, Larry &amp;amp; Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.&lt;/p&gt;\n\n&lt;p&gt;And Sam Altman played his hand well!&lt;/p&gt;\n\n&lt;p&gt;He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money [2]. In addition, Paul Graham made him his successor as president of YC in 2014.&lt;/p&gt;\n\n&lt;p&gt;Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.&lt;/p&gt;\n\n&lt;p&gt;Today, he is the CEO of OpenAI \u2014 one of the most exciting and impactful organizations in all of tech.&lt;/p&gt;\n\n&lt;p&gt;However, OpenAI \u2014 the rocket ship of AI innovation \u2014 is in dire straights.&lt;/p&gt;\n\n&lt;h1&gt;OpenAI is Bleeding Cash&lt;/h1&gt;\n\n&lt;p&gt;Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.&lt;/p&gt;\n\n&lt;p&gt;That money is long gone.&lt;/p&gt;\n\n&lt;p&gt;In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost &amp;gt;$500M over the last year alone.&lt;/p&gt;\n\n&lt;p&gt;This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.&lt;/p&gt;\n\n&lt;p&gt;In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well [4].&lt;/p&gt;\n\n&lt;p&gt;So, where does this leave them today?&lt;/p&gt;\n\n&lt;p&gt;Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn\u2019t take a genius to figure out that they are running low on cash.&lt;/p&gt;\n\n&lt;p&gt;It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can\u2019t they just lease them and make a killing?&lt;/p&gt;\n\n&lt;p&gt;Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Here are some reasons why!&lt;/em&gt;&lt;/p&gt;\n\n&lt;h1&gt;The Tough Business Of Machine Learning&lt;/h1&gt;\n\n&lt;p&gt;Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.&lt;/p&gt;\n\n&lt;p&gt;To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% [7].&lt;/p&gt;\n\n&lt;p&gt;On the one hand, the massive compute requirements and thorny data management problems drive up costs.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.&lt;/p&gt;\n\n&lt;p&gt;To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT\u2019s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Alright, alright, alright! Machine learning is hard.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;OpenAI already has ChatGPT working. That\u2019s gotta be worth something?&lt;/em&gt;&lt;/p&gt;\n\n&lt;h1&gt;Foundation Models Might Become Commodities:&lt;/h1&gt;\n\n&lt;p&gt;In order to monetize GPT or any of their other models, OpenAI can go two different routes.&lt;/p&gt;\n\n&lt;p&gt;First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow &lt;a href=\"https://app.convertkit.com/campaigns/10748016/jasper.ai\"&gt;Jasper&lt;/a&gt; or &lt;a href=\"https://app.convertkit.com/campaigns/10748016/copy.ai\"&gt;copy.ai&lt;/a&gt; out of the water.&lt;/p&gt;\n\n&lt;p&gt;This is not going to happen. Reasons for it include:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.&lt;/li&gt;\n&lt;li&gt;They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.&lt;/li&gt;\n&lt;li&gt;They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a &lt;a href=\"https://www.searchenginejournal.com/openai-chatgpt-professional/476244/\"&gt;pro version&lt;/a&gt; of ChatGPT is a step in this direction.&lt;/p&gt;\n\n&lt;p&gt;This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.&lt;/p&gt;\n\n&lt;p&gt;As an example, last week Andrej Karpathy released a &lt;a href=\"https://www.youtube.com/watch?v=kCc8FmEb1nY\"&gt;video&lt;/a&gt; of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.&lt;/p&gt;\n\n&lt;p&gt;As a result GPT inference would become a common good. This would melt OpenAI\u2019s profits down to a tiny bit of nothing.&lt;/p&gt;\n\n&lt;p&gt;In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI\u2019s API control the interface to the customer, they would likely end up capturing all of the value.&lt;/p&gt;\n\n&lt;p&gt;An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the &lt;a href=\"https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/\"&gt;steel industry&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;To sum it up:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;They don\u2019t have a way to sustainably monetize their models.&lt;/li&gt;\n&lt;li&gt;They do not want and probably should not build up internal sales and marketing teams to capture verticals&lt;/li&gt;\n&lt;li&gt;They need a lot of money to keep funding their research without getting bogged down by details of specific product development&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;So, what should they do?&lt;/em&gt;&lt;/p&gt;\n\n&lt;h1&gt;The Microsoft Deal&lt;/h1&gt;\n\n&lt;p&gt;OpenAI and Microsoft &lt;a href=\"https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/\"&gt;announced&lt;/a&gt; the extension of their partnership with a $10B investment, on Monday.&lt;/p&gt;\n\n&lt;p&gt;At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.&lt;/p&gt;\n\n&lt;p&gt;However, the astounding size is not the only extraordinary thing about this deal.&lt;/p&gt;\n\n&lt;p&gt;First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.&lt;/p&gt;\n\n&lt;p&gt;If OpenAI starts making money, the profits are distributed differently across four stages:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;First, early investors (probably Khosla Ventures and Reid Hoffman\u2019s foundation) get their money back with interest.&lt;/li&gt;\n&lt;li&gt;After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid&lt;/li&gt;\n&lt;li&gt;When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.&lt;/li&gt;\n&lt;li&gt;Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. [3]&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;What This Means&lt;/h1&gt;\n\n&lt;p&gt;This is absolutely crazy!&lt;/p&gt;\n\n&lt;p&gt;OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.&lt;/p&gt;\n\n&lt;p&gt;On top of that, they solved their distribution problem. They now have access to Microsoft\u2019s sales teams and their models will be integrated into MS Office products.&lt;/p&gt;\n\n&lt;p&gt;Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a &lt;a href=\"https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401\"&gt;bitter cloud war&lt;/a&gt; against AWS.&lt;/p&gt;\n\n&lt;p&gt;The synergies do not stop there.&lt;/p&gt;\n\n&lt;p&gt;OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop&lt;a href=\"https://github.com/features/copilot\"&gt; GitHub Copilot&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The deal creates a beautiful win-win situation, but that is not even the best part.&lt;/p&gt;\n\n&lt;p&gt;Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.&lt;/p&gt;\n\n&lt;p&gt;However, if OpenAI creates something in the direction of AGI \u2014 whatever that looks like \u2014 the value of it will likely be huge.&lt;/p&gt;\n\n&lt;p&gt;In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Wow!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;This deal is an absolute power move!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I look forward to the future. Such exciting times to be alive!&lt;/p&gt;\n\n&lt;p&gt;As always, I really enjoyed making this for you and I sincerely hope you found it useful!&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for reading!&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for &lt;strong&gt;The Decoding&lt;/strong&gt; \u2b55.&lt;/p&gt;\n\n&lt;p&gt;I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. &lt;a href=\"https://thedecoding.net/\"&gt;Click here to sign up!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;[1] &lt;a href=\"https://golden.com/wiki/Sam_Altman-J5GKK5\"&gt;https://golden.com/wiki/Sam_Altman-J5GKK5&lt;/a&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;[2] &lt;a href=\"https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny\"&gt;https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny&lt;/a&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;[3] &lt;a href=\"https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&amp;amp;_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA\"&gt;Article in Fortune magazine &lt;/a&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;[4] &lt;a href=\"https://arxiv.org/abs/2104.04473\"&gt;https://arxiv.org/abs/2104.04473&lt;/a&gt; Megatron NLG&lt;/p&gt;\n\n&lt;p&gt;[5] &lt;a href=\"https://www.crunchbase.com/organization/openai/company_financials\"&gt;https://www.crunchbase.com/organization/openai/company_financials&lt;/a&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;[6] Elon Musk donation &lt;a href=\"https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research\"&gt;https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research&lt;/a&gt;\u200b&lt;/p&gt;\n\n&lt;p&gt;[7] &lt;a href=\"https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/\"&gt;https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mi1x8", "is_robot_indexable": true, "report_reasons": null, "author": "LesleyFair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mi1x8/what_people_are_missing_about_microsofts_10b/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mi1x8/what_people_are_missing_about_microsofts_10b/", "subreddit_subscribers": 841501, "created_utc": 1674816738.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, \n\nI am trying to find the best multidimensional combination of parameters for an application based on a given metric by using bayesian optimisation to search the parameter space and efficiently find the most optimal parameters with the fewest number of evaluations. The model gives some sets of parameters, some that it has a high prediction of the metric, and others it has high uncertainty about. \n\nThese 2-300 outputs per cycle are then experimentally validated, and the accumulated results fed back into the model to get a better set of parameters for the next iterations for a total of about 6 iterations (12-1500 data points total) . The search space is large, and there are a limited amount of iterations that can be performed. \n\nBecause of this, I need to evaluate several surrogate models on their performance within this search space. I need to evaluate the search efficiency (how quickly can each one find the most optimal candidates e.g one will take 3 cycles, the other 8, other 20 etc) and the theoretical proportion of the search space that each model can search given the same data e.g 20% of the search space given 3% experimentally validated data from the search space.\n\nI am using the BoTorch library to build the bayesian optimisation model. I also already have a set of real world experimental data from different cycles from the first model I tried. \n\nI would like to know how to go about evaluating these models for the search efficiency and design space uncertainty, any thoughts are welcome. \n\nThanks.", "author_fullname": "t2_9zwp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating Bayesian Optimisation search efficiency and uncertainty", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10mhggd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674814310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I am trying to find the best multidimensional combination of parameters for an application based on a given metric by using bayesian optimisation to search the parameter space and efficiently find the most optimal parameters with the fewest number of evaluations. The model gives some sets of parameters, some that it has a high prediction of the metric, and others it has high uncertainty about. &lt;/p&gt;\n\n&lt;p&gt;These 2-300 outputs per cycle are then experimentally validated, and the accumulated results fed back into the model to get a better set of parameters for the next iterations for a total of about 6 iterations (12-1500 data points total) . The search space is large, and there are a limited amount of iterations that can be performed. &lt;/p&gt;\n\n&lt;p&gt;Because of this, I need to evaluate several surrogate models on their performance within this search space. I need to evaluate the search efficiency (how quickly can each one find the most optimal candidates e.g one will take 3 cycles, the other 8, other 20 etc) and the theoretical proportion of the search space that each model can search given the same data e.g 20% of the search space given 3% experimentally validated data from the search space.&lt;/p&gt;\n\n&lt;p&gt;I am using the BoTorch library to build the bayesian optimisation model. I also already have a set of real world experimental data from different cycles from the first model I tried. &lt;/p&gt;\n\n&lt;p&gt;I would like to know how to go about evaluating these models for the search efficiency and design space uncertainty, any thoughts are welcome. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mhggd", "is_robot_indexable": true, "report_reasons": null, "author": "ogola89", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mhggd/evaluating_bayesian_optimisation_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mhggd/evaluating_bayesian_optimisation_search/", "subreddit_subscribers": 841501, "created_utc": 1674814310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/dj5wz3966kea1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bbb9149ccc073763d10ca39bdc227956e8612e0", "author_fullname": "t2_u7000tjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role will data science play and why is it important?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "media_metadata": {"dj5wz3966kea1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1d85b1b501423e432d3e45182c9488fae2716b"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9091f4cfaa6afa6aa3b1c534b69a9258d6510e8"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=565b3648c53c0886e9570092a1ef0f408e593699"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa2f3cc080adeb93e486a9e46a9106d7a2697f0a"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=142a5a8c43147d4f41426e12fe1e6f6bb10a5d1c"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b7911558c8e21ad2bad50dbd4c900621f8a496"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/dj5wz3966kea1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0bbb9149ccc073763d10ca39bdc227956e8612e0"}, "id": "dj5wz3966kea1"}}, "name": "t3_10mh84v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/35TJtJT6aEzAohNxAuJp6nfjM4oHQp2gMUiEZNmocLw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674813362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dj5wz3966kea1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bbb9149ccc073763d10ca39bdc227956e8612e0\"&gt;https://preview.redd.it/dj5wz3966kea1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0bbb9149ccc073763d10ca39bdc227956e8612e0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mh84v", "is_robot_indexable": true, "report_reasons": null, "author": "growexx", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mh84v/what_role_will_data_science_play_and_why_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mh84v/what_role_will_data_science_play_and_why_is_it/", "subreddit_subscribers": 841501, "created_utc": 1674813362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just started browsing this sub again for the first time in maybe 6 months. I noticed all the hot threads had no users with mod-confirmed jobs or education. I recall the largerly popular and trusted posts/responses that helped me get into this field being from PhDs and highly experienced individuals. Is this practice still advertised by the mods?", "author_fullname": "t2_jfue2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low prevalence of user education/job mod tags.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mc40o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674793843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started browsing this sub again for the first time in maybe 6 months. I noticed all the hot threads had no users with mod-confirmed jobs or education. I recall the largerly popular and trusted posts/responses that helped me get into this field being from PhDs and highly experienced individuals. Is this practice still advertised by the mods?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "MS | Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mc40o", "is_robot_indexable": true, "report_reasons": null, "author": "skeerp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/10mc40o/low_prevalence_of_user_educationjob_mod_tags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mc40o/low_prevalence_of_user_educationjob_mod_tags/", "subreddit_subscribers": 841501, "created_utc": 1674793843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019d like to brainstorm a problem I\u2019ve been mulling. I\u2019m working with a very large transactional database. (Billions of rows/ 30+ columns). \n\nEach row represents a single action from a user (e.g. one row for attempting to log in, another if the user buys a product, another if the user modifies their profile).\n\nI want to create stories (groupings) of events (rows) to summarize user activity better. E.g. this user logged in and searched, but never bought anything and made no changes to their profile. \n\nThere are dual goals with this project. One is to create a repeatable process (or potentially a new database) that categorizes user events. The second is to eventually build an algorithm (probably k-means, maybe others) to evaluate outlying activity trends. Eventually the algorithm would feed into a MLM, but that\u2019s a bit far off at the moment. \n\nI was going to do the grunt work of if/case statements based on understanding the different columns in the database. But I\u2019d like to brainstorm with others. Are there other methods that you\u2019d recommend?", "author_fullname": "t2_uyoinwrz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Categorizing groups of events in a transactional database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mbewe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674791659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d like to brainstorm a problem I\u2019ve been mulling. I\u2019m working with a very large transactional database. (Billions of rows/ 30+ columns). &lt;/p&gt;\n\n&lt;p&gt;Each row represents a single action from a user (e.g. one row for attempting to log in, another if the user buys a product, another if the user modifies their profile).&lt;/p&gt;\n\n&lt;p&gt;I want to create stories (groupings) of events (rows) to summarize user activity better. E.g. this user logged in and searched, but never bought anything and made no changes to their profile. &lt;/p&gt;\n\n&lt;p&gt;There are dual goals with this project. One is to create a repeatable process (or potentially a new database) that categorizes user events. The second is to eventually build an algorithm (probably k-means, maybe others) to evaluate outlying activity trends. Eventually the algorithm would feed into a MLM, but that\u2019s a bit far off at the moment. &lt;/p&gt;\n\n&lt;p&gt;I was going to do the grunt work of if/case statements based on understanding the different columns in the database. But I\u2019d like to brainstorm with others. Are there other methods that you\u2019d recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mbewe", "is_robot_indexable": true, "report_reasons": null, "author": "Nerdy_birdy747", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mbewe/categorizing_groups_of_events_in_a_transactional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mbewe/categorizing_groups_of_events_in_a_transactional/", "subreddit_subscribers": 841501, "created_utc": 1674791659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a project where data is naturally and necessarily collected in a row-by-row tabular format. I have a strong suspicious that analysis and exploitation of the data could be revolutionised if it were transposed into a graphDB, but I don't really have any direct experience or good examples to back this up.\n\nHas anyone here made a similar transition and made some kind of step change in either analysis efficiency or in terms of the value that can be extracted from a dataset?\n\nI know there are classic examples of where network analysis can be well utilized (social network analysis comes to the top of my mind), but I'd love to hear from anyone with direct industry experience. If it's an unexpected angle, all the better.", "author_fullname": "t2_82ygfecl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone transitioned a project from a relational DB to a graphDB and realised major improvements in performance or efficiency?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10mazhm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674790330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project where data is naturally and necessarily collected in a row-by-row tabular format. I have a strong suspicious that analysis and exploitation of the data could be revolutionised if it were transposed into a graphDB, but I don&amp;#39;t really have any direct experience or good examples to back this up.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here made a similar transition and made some kind of step change in either analysis efficiency or in terms of the value that can be extracted from a dataset?&lt;/p&gt;\n\n&lt;p&gt;I know there are classic examples of where network analysis can be well utilized (social network analysis comes to the top of my mind), but I&amp;#39;d love to hear from anyone with direct industry experience. If it&amp;#39;s an unexpected angle, all the better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10mazhm", "is_robot_indexable": true, "report_reasons": null, "author": "recovering_physicist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10mazhm/has_anyone_transitioned_a_project_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10mazhm/has_anyone_transitioned_a_project_from_a/", "subreddit_subscribers": 841501, "created_utc": 1674790330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Explain Open Source != Security Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m95dq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_8hvlbe2j", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "rstats", "selftext": "TDLR: IT is panicked from a recent hack and thinks open source software is a security concern. What can I say / do to calm their nerves.\n\nI'm a data analyst for state government in the US (ie a boring bureaucrat paper pusher). For the last 2 years I've been building R scripts to pull our agency source data to build reports and statistical analysis. I've taken what used to take months to build in excel, now takes minutes with R. My direct management team has been all on board for my efforts.\n\nNow comes the monkey wrench. Our agency was recently the subject of a hack. Our IT department has gone full lockdown in response. Now everything is being nitpicked and our IT director is concerned with R being open source as a security risk.\n\nWhat can I say or do to show R is not a risk? How can I minimize their concerns? I have an opportunity to plead my case next week and am looking for support for my position.\n\nI truly appreciate any ideas or help you can offer. I don't want 2 years of my life to be trashed because of a nervous Nelly.", "author_fullname": "t2_8hvlbe2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Explain Open Source != Security Issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/rstats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m91iz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674784590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TDLR: IT is panicked from a recent hack and thinks open source software is a security concern. What can I say / do to calm their nerves.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data analyst for state government in the US (ie a boring bureaucrat paper pusher). For the last 2 years I&amp;#39;ve been building R scripts to pull our agency source data to build reports and statistical analysis. I&amp;#39;ve taken what used to take months to build in excel, now takes minutes with R. My direct management team has been all on board for my efforts.&lt;/p&gt;\n\n&lt;p&gt;Now comes the monkey wrench. Our agency was recently the subject of a hack. Our IT department has gone full lockdown in response. Now everything is being nitpicked and our IT director is concerned with R being open source as a security risk.&lt;/p&gt;\n\n&lt;p&gt;What can I say or do to show R is not a risk? How can I minimize their concerns? I have an opportunity to plead my case next week and am looking for support for my position.&lt;/p&gt;\n\n&lt;p&gt;I truly appreciate any ideas or help you can offer. I don&amp;#39;t want 2 years of my life to be trashed because of a nervous Nelly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8n0", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m91iz", "is_robot_indexable": true, "report_reasons": null, "author": "QuantumScribs", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/rstats/comments/10m91iz/how_to_explain_open_source_security_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/rstats/comments/10m91iz/how_to_explain_open_source_security_issue/", "subreddit_subscribers": 69898, "created_utc": 1674784590.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1674784904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.rstats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/rstats/comments/10m91iz/how_to_explain_open_source_security_issue/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m95dq", "is_robot_indexable": true, "report_reasons": null, "author": "QuantumScribs", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10m91iz", "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m95dq/how_to_explain_open_source_security_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/rstats/comments/10m91iz/how_to_explain_open_source_security_issue/", "subreddit_subscribers": 841501, "created_utc": 1674784904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I would like to ask if someone of you has ever faced a problem in which the main available data are a combination between time series and static variables.\nAlso the anomaly has to be predicted in advance with respect to its occurring (i.e. predictive maintenance problem)\n\nLet\u2019s say that both of the type of data (dynamic-time series and static-fixed) are strictly important because based on information in static variables there are different behaviors in the time series for the same channel.\n\nWhat state of the art approaches could be used to manage early anomaly detection on this kind of data?", "author_fullname": "t2_i6lyoywf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "early anomaly detection on time series and additional static variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m6t3i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674778140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I would like to ask if someone of you has ever faced a problem in which the main available data are a combination between time series and static variables.\nAlso the anomaly has to be predicted in advance with respect to its occurring (i.e. predictive maintenance problem)&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say that both of the type of data (dynamic-time series and static-fixed) are strictly important because based on information in static variables there are different behaviors in the time series for the same channel.&lt;/p&gt;\n\n&lt;p&gt;What state of the art approaches could be used to manage early anomaly detection on this kind of data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m6t3i", "is_robot_indexable": true, "report_reasons": null, "author": "ginotherhino1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m6t3i/early_anomaly_detection_on_time_series_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m6t3i/early_anomaly_detection_on_time_series_and/", "subreddit_subscribers": 841501, "created_utc": 1674778140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've spent this entire month so far refactoring code that relies on dependencies that broke in the new year. The carnage ranges from our highest-level internal libraries, all the way down to the basic development infrastructure we rely on. I've even had to troubleshoot critical new bugs in Zoom, Outlook, and OneDrive.\n\nIs there any clever phrase to describe this phenomenon, where every coder on the planet chooses to push breaking changes at the turn of the year? And then every broken dependency fix creates a domino effect of dependency conflicts.", "author_fullname": "t2_u0krl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Everything Breaks\" January", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m6aq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674776744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve spent this entire month so far refactoring code that relies on dependencies that broke in the new year. The carnage ranges from our highest-level internal libraries, all the way down to the basic development infrastructure we rely on. I&amp;#39;ve even had to troubleshoot critical new bugs in Zoom, Outlook, and OneDrive.&lt;/p&gt;\n\n&lt;p&gt;Is there any clever phrase to describe this phenomenon, where every coder on the planet chooses to push breaking changes at the turn of the year? And then every broken dependency fix creates a domino effect of dependency conflicts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m6aq0", "is_robot_indexable": true, "report_reasons": null, "author": "TBSchemer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m6aq0/everything_breaks_january/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10m6aq0/everything_breaks_january/", "subreddit_subscribers": 841501, "created_utc": 1674776744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ua2sv57p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video recording of the webinar about dstack and reproducible ML workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10m1ajt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/CKhD0DNFj0U?start=59&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Webinar &amp;quot;dstack \u2013 a command-line utility to provision infrastructure for ML workflows&amp;quot;\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Webinar \"dstack \u2013 a command-line utility to provision infrastructure for ML workflows\"", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/CKhD0DNFj0U?start=59&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Webinar &amp;quot;dstack \u2013 a command-line utility to provision infrastructure for ML workflows&amp;quot;\"&gt;&lt;/iframe&gt;", "author_name": "Data Phoenix Events", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/CKhD0DNFj0U/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataPhoenixEvents"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/CKhD0DNFj0U?start=59&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Webinar &amp;quot;dstack \u2013 a command-line utility to provision infrastructure for ML workflows&amp;quot;\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10m1ajt", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9Vz9d-M0pymvuNUK6WxH6FZILuwnB2VPG3Y_dzPvyvQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674764105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=CKhD0DNFj0U&amp;t=59s", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3WiHMxY_9y4J0c6CUlJqIBLgg5jxUSucDkHDjWyl_WU.jpg?auto=webp&amp;v=enabled&amp;s=79e2200e4031c514ac4b58855b344f00bb5cdad9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/3WiHMxY_9y4J0c6CUlJqIBLgg5jxUSucDkHDjWyl_WU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f73dc814e2810e75c808a9e42feed825dd387baa", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/3WiHMxY_9y4J0c6CUlJqIBLgg5jxUSucDkHDjWyl_WU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb80a6ad321c0363b4bd1d2b3b9eabdfea228d9c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/3WiHMxY_9y4J0c6CUlJqIBLgg5jxUSucDkHDjWyl_WU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74aa0995e6182c05a373169152b0e75eab425d27", "width": 320, "height": 240}], "variants": {}, "id": "mSXNRMpG4EaGaSmq32wZoI-_R3xwSBL-8v1dmgoZPpA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m1ajt", "is_robot_indexable": true, "report_reasons": null, "author": "dmitryspodarets", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10m1ajt/video_recording_of_the_webinar_about_dstack_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=CKhD0DNFj0U&amp;t=59s", "subreddit_subscribers": 841501, "created_utc": 1674764105.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Webinar \"dstack \u2013 a command-line utility to provision infrastructure for ML workflows\"", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/CKhD0DNFj0U?start=59&amp;feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Webinar &amp;quot;dstack \u2013 a command-line utility to provision infrastructure for ML workflows&amp;quot;\"&gt;&lt;/iframe&gt;", "author_name": "Data Phoenix Events", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/CKhD0DNFj0U/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataPhoenixEvents"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody!\n\nI am going to graduate in MSc Data Science in a month here in Italy and I've already finished my internship as a data scientist in a public institution that cannot hire me because there are no exams at the moment nor in the near future. I currently work as a teacher in Humanities but plan to switch my career definitively in September. Up until this date I want to keep learning things and applying what I know. I've already looked for intern on Linkedin but they are full time and not allowing remote job. I am considering to collaborate with startups or doing an intern for free, since my school contract doesn't allow me to be paid and now switching is impossible to me. \n\nWorking on my projects could be a solution, but I feel that I want to have feedbacks and dialogue with people with deeper understanding in this field. Plus, an intern or a collaboration are considered as more valuable in the CV. \n\nWhere can I find some startups or projects to practice my skills? Any suggestions is extremely valued. Thank you for your time!", "author_fullname": "t2_dukqcpgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "gain experience in DS and related roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lym1l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674757396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody!&lt;/p&gt;\n\n&lt;p&gt;I am going to graduate in MSc Data Science in a month here in Italy and I&amp;#39;ve already finished my internship as a data scientist in a public institution that cannot hire me because there are no exams at the moment nor in the near future. I currently work as a teacher in Humanities but plan to switch my career definitively in September. Up until this date I want to keep learning things and applying what I know. I&amp;#39;ve already looked for intern on Linkedin but they are full time and not allowing remote job. I am considering to collaborate with startups or doing an intern for free, since my school contract doesn&amp;#39;t allow me to be paid and now switching is impossible to me. &lt;/p&gt;\n\n&lt;p&gt;Working on my projects could be a solution, but I feel that I want to have feedbacks and dialogue with people with deeper understanding in this field. Plus, an intern or a collaboration are considered as more valuable in the CV. &lt;/p&gt;\n\n&lt;p&gt;Where can I find some startups or projects to practice my skills? Any suggestions is extremely valued. Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lym1l", "is_robot_indexable": true, "report_reasons": null, "author": "Similar-Year4215", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10lym1l/gain_experience_in_ds_and_related_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10lym1l/gain_experience_in_ds_and_related_roles/", "subreddit_subscribers": 841501, "created_utc": 1674757396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Link](https://cdso.utexas.edu/msai) First term appears to be in a year with spring 2024.\n\n&gt; The Master of Science in Artificial Intelligence\u00a0(MSAI) will be the first large-scale degree program of its kind and the only master\u2019s degree program in AI from a top-ranked institution to be priced close to $10,000. The master\u2019s degree covers about two years\u2019 worth of course content, to be taken at the learner\u2019s own pace, and master\u2019s degree will be delivered in partnership with online course provider edX.\n\n&gt; AI master\u2019s programs from peer institutions carry costs five to 10 times as high as UT Austin\u2019s and serve only dozens of students \u2014 not the hundreds or thousands the Texas team projects it will reach annually within five years. Similarly priced online master\u2019s programs from the university, in\u00a0computer science and\u00a0data science, enroll 2,500 students within less than five years of their launch. Like those programs, the fully online MSAI program is both flexible and accessible.\n\n&gt; Enrolled students will receive advanced training in natural language processing, reinforcement learning, computer vision, deep learning and related topics, and will provide a critical framework for understanding the ethical implications of AI technologies. The degree will equip students for an array of potential career opportunities \u2014 from engineering to research and development, and product management to consulting...", "author_fullname": "t2_n90rekd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UT Austin Announcncing New AI Masters Program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10lya3g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674756577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://cdso.utexas.edu/msai\"&gt;Link&lt;/a&gt; First term appears to be in a year with spring 2024.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The Master of Science in Artificial Intelligence\u00a0(MSAI) will be the first large-scale degree program of its kind and the only master\u2019s degree program in AI from a top-ranked institution to be priced close to $10,000. The master\u2019s degree covers about two years\u2019 worth of course content, to be taken at the learner\u2019s own pace, and master\u2019s degree will be delivered in partnership with online course provider edX.&lt;/p&gt;\n\n&lt;p&gt;AI master\u2019s programs from peer institutions carry costs five to 10 times as high as UT Austin\u2019s and serve only dozens of students \u2014 not the hundreds or thousands the Texas team projects it will reach annually within five years. Similarly priced online master\u2019s programs from the university, in\u00a0computer science and\u00a0data science, enroll 2,500 students within less than five years of their launch. Like those programs, the fully online MSAI program is both flexible and accessible.&lt;/p&gt;\n\n&lt;p&gt;Enrolled students will receive advanced training in natural language processing, reinforcement learning, computer vision, deep learning and related topics, and will provide a critical framework for understanding the ethical implications of AI technologies. The degree will equip students for an array of potential career opportunities \u2014 from engineering to research and development, and product management to consulting...&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10lya3g", "is_robot_indexable": true, "report_reasons": null, "author": "TapirTamer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10lya3g/ut_austin_announcncing_new_ai_masters_program/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10lya3g/ut_austin_announcncing_new_ai_masters_program/", "subreddit_subscribers": 841501, "created_utc": 1674756577.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}