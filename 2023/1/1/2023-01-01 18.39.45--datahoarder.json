{"kind": "Listing", "data": {"after": "t3_1005exs", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Good evening, datahoarders.\n\nOver the years I have posted here under various accounts, and lived various extremes of data hoarding. \n\nI have now reduced myself to a positively conservative 30TB in my main server, and 12 or so on my clients.\n\nIn the last 10 years I've used first Kodi and then Plex for my media server needs. Both worked, mostly.\n\nI remember checking in on this open-source flash in the pan called Jellyfin a few years back and moving back to Plex in a jiffy.\n\nWell, if you haven't tried it in a while...holy heck!\n\nI spent an hour or so today setting up a Jellyfin server and deployed the client app on all my TV's and computers etc.\n\nWow! That's about all I've got to say right now. I now have hardware acceleration. I now have the vast majority of my media playing with no transcoding whatsoever. I now have a client interface that is as fast as lightning and makes paid streaming services look like something for children.\n\nIn short, I'm blown away and so excited and nobody in my life really cares; you guys were the only people i could think of that might actually give half a rats.\n\nAnyway, if you haven't done so in a while - check out Jellyfin again. It's a whole new beast!", "author_fullname": "t2_r0lf8zqt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time to revisit Jellyfin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100hye7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 274, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 274, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672573313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening, datahoarders.&lt;/p&gt;\n\n&lt;p&gt;Over the years I have posted here under various accounts, and lived various extremes of data hoarding. &lt;/p&gt;\n\n&lt;p&gt;I have now reduced myself to a positively conservative 30TB in my main server, and 12 or so on my clients.&lt;/p&gt;\n\n&lt;p&gt;In the last 10 years I&amp;#39;ve used first Kodi and then Plex for my media server needs. Both worked, mostly.&lt;/p&gt;\n\n&lt;p&gt;I remember checking in on this open-source flash in the pan called Jellyfin a few years back and moving back to Plex in a jiffy.&lt;/p&gt;\n\n&lt;p&gt;Well, if you haven&amp;#39;t tried it in a while...holy heck!&lt;/p&gt;\n\n&lt;p&gt;I spent an hour or so today setting up a Jellyfin server and deployed the client app on all my TV&amp;#39;s and computers etc.&lt;/p&gt;\n\n&lt;p&gt;Wow! That&amp;#39;s about all I&amp;#39;ve got to say right now. I now have hardware acceleration. I now have the vast majority of my media playing with no transcoding whatsoever. I now have a client interface that is as fast as lightning and makes paid streaming services look like something for children.&lt;/p&gt;\n\n&lt;p&gt;In short, I&amp;#39;m blown away and so excited and nobody in my life really cares; you guys were the only people i could think of that might actually give half a rats.&lt;/p&gt;\n\n&lt;p&gt;Anyway, if you haven&amp;#39;t done so in a while - check out Jellyfin again. It&amp;#39;s a whole new beast!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100hye7", "is_robot_indexable": true, "report_reasons": null, "author": "stopbanningmeplzfoo", "discussion_type": null, "num_comments": 141, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100hye7/time_to_revisit_jellyfin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100hye7/time_to_revisit_jellyfin/", "subreddit_subscribers": 663216, "created_utc": 1672573313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_f6rxi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi guys, I'm just starting here. 4x8TB, RAID5, for my terramaster nas. I'll put linux on it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1009h4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 100, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 100, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/u7nsiU8ZkiYm08JfnxEM9-fFELHaW3b5fgQ2fCLid50.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672538901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/afkn3m1cbc9a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?auto=webp&amp;s=07d6b1e1c1036c7830bd6db0b7f0ca8a67b92b40", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5beccf0dd9ea1562e8b6ccdffb7bacafb017d68a", "width": 108, "height": 144}, {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2e4ed379ce58c7973e47fc3858e4a8c86de103e9", "width": 216, "height": 288}, {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=03d290ae8f0ed14711374f7e227e28e9a4871232", "width": 320, "height": 426}, {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e3a7e91064bd348137cc84ce293e7a4c25e6878", "width": 640, "height": 853}, {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a8a1830f6178de94e86be843e45ea05eae31071b", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/afkn3m1cbc9a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1501bce34f91b1406aa404f5cffab51b1b26d28c", "width": 1080, "height": 1440}], "variants": {}, "id": "4UsOfBjvoMFASt_nvGrBt7xBAzxsmQPbtlkmn2_8Vos"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1009h4u", "is_robot_indexable": true, "report_reasons": null, "author": "TheCharon77", "discussion_type": null, "num_comments": 26, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1009h4u/hi_guys_im_just_starting_here_4x8tb_raid5_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/afkn3m1cbc9a1.jpg", "subreddit_subscribers": 663216, "created_utc": 1672538901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_98m1og82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Canada] Is this too good to be true?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_10076nf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iGQCiZNGZAMDruKUcSrqjJrLnDNkdYure4PUR2pS9_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672531409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1sgndwxhob9a1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1sgndwxhob9a1.png?auto=webp&amp;s=e89515c467b7444c786ee7c4b52f94643bca129c", "width": 915, "height": 455}, "resolutions": [{"url": "https://preview.redd.it/1sgndwxhob9a1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=749613691394a8f89d1a7dd6a0f1b04ed44b09ea", "width": 108, "height": 53}, {"url": "https://preview.redd.it/1sgndwxhob9a1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=13a38269a0d014bee7248c8d84e7c953d9faa703", "width": 216, "height": 107}, {"url": "https://preview.redd.it/1sgndwxhob9a1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=57c24ba1241730f422f4faee446e2d33fd0d30cc", "width": 320, "height": 159}, {"url": "https://preview.redd.it/1sgndwxhob9a1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a756bb94382e20774f8155624593bbe1ca335fa7", "width": 640, "height": 318}], "variants": {}, "id": "l4qgNQrTQ845Hjyg_hFTog8RkgVXzrdFATgRVT6jH60"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10076nf", "is_robot_indexable": true, "report_reasons": null, "author": "cseye420", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10076nf/canada_is_this_too_good_to_be_true/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1sgndwxhob9a1.png", "subreddit_subscribers": 663216, "created_utc": 1672531409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was researching NAS options and came across an offer for cloud storage priced at $1200 for 10TB lifetime. One time payment. By comparison that cost will get you 2 years of Google Drive storage. Based on that alone it looks like a win but what other factors do you consider when gauging the cost of data storage. I'm not talking about the pros and cons of cloud vs. local storage. I already get that. I'm asking, IF cloud storage could work for you, how valuable will 10TB be in 5, 10, 20 years. As media file sizes get bigger with 8K and photos grow in megapixels, will 10TB in the future get you what 500GB gets you today? Will the failure rate of NAS drives become a non issue when pricing storage? I have no use for 10TB of cloud storage now but down the line I probably will. If so, is this deal worth it?", "author_fullname": "t2_5xpb2e4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Put 10TB lifetime in perspective for me", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100e0xk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672556255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was researching NAS options and came across an offer for cloud storage priced at $1200 for 10TB lifetime. One time payment. By comparison that cost will get you 2 years of Google Drive storage. Based on that alone it looks like a win but what other factors do you consider when gauging the cost of data storage. I&amp;#39;m not talking about the pros and cons of cloud vs. local storage. I already get that. I&amp;#39;m asking, IF cloud storage could work for you, how valuable will 10TB be in 5, 10, 20 years. As media file sizes get bigger with 8K and photos grow in megapixels, will 10TB in the future get you what 500GB gets you today? Will the failure rate of NAS drives become a non issue when pricing storage? I have no use for 10TB of cloud storage now but down the line I probably will. If so, is this deal worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100e0xk", "is_robot_indexable": true, "report_reasons": null, "author": "Jaded-Function", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100e0xk/put_10tb_lifetime_in_perspective_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100e0xk/put_10tb_lifetime_in_perspective_for_me/", "subreddit_subscribers": 663216, "created_utc": 1672556255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Our research group has about 150TB of data we're currently storing with some cloud service that's costing us a lot monthly.  We also have a new project starting in 2025 which will generate a similar amount of data.  I've been tasked with building a file server to be housed somewhere on campus to hold this data.\n\n**Data access pattern:**\n\n1. Copy a 500GB chunk of data to the campus compute cluster (about 1h transfer time at 1Gb/s)\n2. Do some computation on the cluster over this 500GB of data (takes about 30h)\n3. Delete the 500GB chunk from the cluster and move on to the next chunk\n\n**Purchase list:**\n\n- Data hosting ($12000)\n  - 45Drives Storinator Q30 ($7000)\n  - 14x 16TB Seagate Exos drives w/ RAID-Z2 ($5000)\n\n- Data backup ($5750)\n   - Symplypro SYPRO-DT3L8H1B-A0 desktop tape drive ($5000)\n   - 14x 12TB HPE LTO-8 tapes ($750)\n\nI've left half the drive bays empty for building another array a few years from now.\n\n**Questions:**\n\n- Approximately what's the likelihood that a drive will fail in 5 years?\n- How complex is the replacement?  I may not always be around to fix the server\n- About how long would a rebuild take if a drive fails, and is double-parity enough to prevent another drive from failing during this time?", "author_fullname": "t2_l9r9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to host 150TB for my research group. Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1000qsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672512727.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672512299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our research group has about 150TB of data we&amp;#39;re currently storing with some cloud service that&amp;#39;s costing us a lot monthly.  We also have a new project starting in 2025 which will generate a similar amount of data.  I&amp;#39;ve been tasked with building a file server to be housed somewhere on campus to hold this data.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data access pattern:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Copy a 500GB chunk of data to the campus compute cluster (about 1h transfer time at 1Gb/s)&lt;/li&gt;\n&lt;li&gt;Do some computation on the cluster over this 500GB of data (takes about 30h)&lt;/li&gt;\n&lt;li&gt;Delete the 500GB chunk from the cluster and move on to the next chunk&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Purchase list:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Data hosting ($12000)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;45Drives Storinator Q30 ($7000)&lt;/li&gt;\n&lt;li&gt;14x 16TB Seagate Exos drives w/ RAID-Z2 ($5000)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data backup ($5750)&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Symplypro SYPRO-DT3L8H1B-A0 desktop tape drive ($5000)&lt;/li&gt;\n&lt;li&gt;14x 12TB HPE LTO-8 tapes ($750)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve left half the drive bays empty for building another array a few years from now.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Approximately what&amp;#39;s the likelihood that a drive will fail in 5 years?&lt;/li&gt;\n&lt;li&gt;How complex is the replacement?  I may not always be around to fix the server&lt;/li&gt;\n&lt;li&gt;About how long would a rebuild take if a drive fails, and is double-parity enough to prevent another drive from failing during this time?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1000qsc", "is_robot_indexable": true, "report_reasons": null, "author": "Evidlo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1000qsc/need_to_host_150tb_for_my_research_group/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1000qsc/need_to_host_150tb_for_my_research_group/", "subreddit_subscribers": 663216, "created_utc": 1672512299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "and there are no CMR.", "author_fullname": "t2_ao2zj3p2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I understand correctly that all *recent* 4TB 2.5inch HDDs are SMR only?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1005jr0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672526318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;and there are no CMR.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1005jr0", "is_robot_indexable": true, "report_reasons": null, "author": "Rude-Engine440", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1005jr0/do_i_understand_correctly_that_all_recent_4tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1005jr0/do_i_understand_correctly_that_all_recent_4tb/", "subreddit_subscribers": 663216, "created_utc": 1672526318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello sub\nPlease advise what's a cheap Nas adapter that can help me put my 16tb wdd USB HDD on my own as a network drive?\n\nI'd eventually like to use rclone on my PCs/phone to backup content into it.\n\nThanks", "author_fullname": "t2_72g3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advise : home backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100h1bm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672569280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello sub\nPlease advise what&amp;#39;s a cheap Nas adapter that can help me put my 16tb wdd USB HDD on my own as a network drive?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d eventually like to use rclone on my PCs/phone to backup content into it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100h1bm", "is_robot_indexable": true, "report_reasons": null, "author": "justbflat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100h1bm/need_advise_home_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100h1bm/need_advise_home_backup/", "subreddit_subscribers": 663216, "created_utc": 1672569280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hiya, I'm looking for any tool that downloads all images from a Reddit account, cheers", "author_fullname": "t2_ccp6tq5p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit account scraper?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100gw0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672568632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiya, I&amp;#39;m looking for any tool that downloads all images from a Reddit account, cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100gw0k", "is_robot_indexable": true, "report_reasons": null, "author": "LunaKindaExists", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100gw0k/reddit_account_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100gw0k/reddit_account_scraper/", "subreddit_subscribers": 663216, "created_utc": 1672568632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have audio, video, notes, project files, random files, etc. scattered in multiple places and it's been driving me crazy. Is there a platform or program that can help solve this? I want a homebase for all of my data, all in one place where I can easily access it.", "author_fullname": "t2_n8pzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to organize everything into one place? Is it possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1009pph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672539715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have audio, video, notes, project files, random files, etc. scattered in multiple places and it&amp;#39;s been driving me crazy. Is there a platform or program that can help solve this? I want a homebase for all of my data, all in one place where I can easily access it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1009pph", "is_robot_indexable": true, "report_reasons": null, "author": "Ty505", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1009pph/how_to_organize_everything_into_one_place_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1009pph/how_to_organize_everything_into_one_place_is_it/", "subreddit_subscribers": 663216, "created_utc": 1672539715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Over the years I have amassed music &amp; audiobooks and have saved them places willy- nilly. I\u2019ve started to corral them in one place to weed out duplicates and keep the best versions, but I\u2019m stuck on one thing. How do I download things I\u2019ve purchased from various sites that are hosted on those sites and not my device. For example, I buy audiobooks from Chirp. I can listen to them using their app, but I want to get them saved so I can listen to them even if I don\u2019t have an internet connection.", "author_fullname": "t2_1ylgs4b8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Audio hoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1002831", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672516580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the years I have amassed music &amp;amp; audiobooks and have saved them places willy- nilly. I\u2019ve started to corral them in one place to weed out duplicates and keep the best versions, but I\u2019m stuck on one thing. How do I download things I\u2019ve purchased from various sites that are hosted on those sites and not my device. For example, I buy audiobooks from Chirp. I can listen to them using their app, but I want to get them saved so I can listen to them even if I don\u2019t have an internet connection.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1002831", "is_robot_indexable": true, "report_reasons": null, "author": "CoveredInBeez", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1002831/audio_hoarder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1002831/audio_hoarder/", "subreddit_subscribers": 663216, "created_utc": 1672516580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I receive a few different periodic emails that I would like to use as input to automations like downloading data provided in a link in the email, or adding a newsletter to my wallabag.\n\nI could (but would rather not) write a python script to poll my actual email account, but I'd rather find free email account that I can automatically forward the emails to and then pull from that, then run an automation for each new email that comes in.  There must be a solution out there already, how are people getting this done?  I don't want to run an email server myself, that's a whole can of worms I don't want to deal with, and I don't need to be event-based; polling a couple times a day would be enough.\n\nI did a bit of searching here and /r/selfhosted, but mostly people are talking about syncing/archiving emails, which is not what I'm trying to solve; as soon as I grab the input and launch the automation I'll trash the email.", "author_fullname": "t2_14wfe6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to launch automations based on incoming emails?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100271m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672516497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I receive a few different periodic emails that I would like to use as input to automations like downloading data provided in a link in the email, or adding a newsletter to my wallabag.&lt;/p&gt;\n\n&lt;p&gt;I could (but would rather not) write a python script to poll my actual email account, but I&amp;#39;d rather find free email account that I can automatically forward the emails to and then pull from that, then run an automation for each new email that comes in.  There must be a solution out there already, how are people getting this done?  I don&amp;#39;t want to run an email server myself, that&amp;#39;s a whole can of worms I don&amp;#39;t want to deal with, and I don&amp;#39;t need to be event-based; polling a couple times a day would be enough.&lt;/p&gt;\n\n&lt;p&gt;I did a bit of searching here and &lt;a href=\"/r/selfhosted\"&gt;/r/selfhosted&lt;/a&gt;, but mostly people are talking about syncing/archiving emails, which is not what I&amp;#39;m trying to solve; as soon as I grab the input and launch the automation I&amp;#39;ll trash the email.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100271m", "is_robot_indexable": true, "report_reasons": null, "author": "often_wears_pants", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100271m/how_to_launch_automations_based_on_incoming_emails/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100271m/how_to_launch_automations_based_on_incoming_emails/", "subreddit_subscribers": 663216, "created_utc": 1672516497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**First, a disclaimer:** I'm aware media is generally already compress. Storage capacity is not an issue currently, but it's something I'm curious about and want to learn. \n\n**1)** Do any of you use compression, in any form, for either backups, local storage, or cloud?\n\n####Files I'm considering compressing:\n \n**2)** I have a LOT of games downloaded, which I do not *currently* play, but plan on returning to. One example would me Skyrim +150 Mods, which took weeks to figure out the right combination of mods \n\n**3)** I have about 500 GB - 1TB or so of old data that I'm **slowly** going through, and deleting or saving anything that's personally important. The data is from either: My old harddrives, my deceased dad's PC, an old WD passport, and an old backup folder that is partially corrupt but has some salvigable important files\n\n**4)** I'm not sure if RAR or 7-zip compression does anything for lossless media, so this part might not be relevant: but I have a lot of upscaled photos and videos; some of which are saved as PNG or ProRes, and are essentially lossless. Some pictures are 150mb each. I'm still fairly new at upscaling, and later on this will probably be less of an issue, but the reason some files are lossless is because:\n\n* Some select, important media I used ProRes or PNG for that I may plan on printing, or using in other software like Premiere and Photoshop. \n* Some photos had very small artifacts on the JPG Codec that weren't in PNG\n* some upscaling issues on various codec formats (either software-side errors, or time)\n* some issues at the time with using h.265 or vp9 format (software issue that was patched and fixed). But as a result I used h.264 or ProRes on\n* poor knowledge on compatibility issues when using various codecs (h.265, h.264, av1, vp9, etc) on supported devices (android, windows, Apple), transferring them, uploading to a cloud service (g.drive, g.photos), supported programs, etc.\n\nHopefully when I learn a bit more about the above, and with some software issues patched, I'll be able to use the right codec to compress files.", "author_fullname": "t2_cs86j6jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some questions on compression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ikdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672575819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;First, a disclaimer:&lt;/strong&gt; I&amp;#39;m aware media is generally already compress. Storage capacity is not an issue currently, but it&amp;#39;s something I&amp;#39;m curious about and want to learn. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; Do any of you use compression, in any form, for either backups, local storage, or cloud?&lt;/p&gt;\n\n&lt;h4&gt;Files I&amp;#39;m considering compressing:&lt;/h4&gt;\n\n&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; I have a LOT of games downloaded, which I do not &lt;em&gt;currently&lt;/em&gt; play, but plan on returning to. One example would me Skyrim +150 Mods, which took weeks to figure out the right combination of mods &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; I have about 500 GB - 1TB or so of old data that I&amp;#39;m &lt;strong&gt;slowly&lt;/strong&gt; going through, and deleting or saving anything that&amp;#39;s personally important. The data is from either: My old harddrives, my deceased dad&amp;#39;s PC, an old WD passport, and an old backup folder that is partially corrupt but has some salvigable important files&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;4)&lt;/strong&gt; I&amp;#39;m not sure if RAR or 7-zip compression does anything for lossless media, so this part might not be relevant: but I have a lot of upscaled photos and videos; some of which are saved as PNG or ProRes, and are essentially lossless. Some pictures are 150mb each. I&amp;#39;m still fairly new at upscaling, and later on this will probably be less of an issue, but the reason some files are lossless is because:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some select, important media I used ProRes or PNG for that I may plan on printing, or using in other software like Premiere and Photoshop. &lt;/li&gt;\n&lt;li&gt;Some photos had very small artifacts on the JPG Codec that weren&amp;#39;t in PNG&lt;/li&gt;\n&lt;li&gt;some upscaling issues on various codec formats (either software-side errors, or time)&lt;/li&gt;\n&lt;li&gt;some issues at the time with using h.265 or vp9 format (software issue that was patched and fixed). But as a result I used h.264 or ProRes on&lt;/li&gt;\n&lt;li&gt;poor knowledge on compatibility issues when using various codecs (h.265, h.264, av1, vp9, etc) on supported devices (android, windows, Apple), transferring them, uploading to a cloud service (g.drive, g.photos), supported programs, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hopefully when I learn a bit more about the above, and with some software issues patched, I&amp;#39;ll be able to use the right codec to compress files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ikdy", "is_robot_indexable": true, "report_reasons": null, "author": "NegativelyMagnetic", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ikdy/some_questions_on_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ikdy/some_questions_on_compression/", "subreddit_subscribers": 663216, "created_utc": 1672575819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Update: In digging I found [this chart](https://www.sonnettech.com/support/downloads/manuals/u2_ssds.pdf) in a different thread about U.2 PCIe cards for Mac Pros. Turns out WD doesn\u2019t make a drive compatible with Macs.\n\n___\n\nI'm a video editor and have been trying to find the best solution for high speed external storage. With some help from this subreddit I thought I hit the mark when I was turned towards using U.2 NVMe SSDs. I got the [OWC Helios 3S](https://eshop.macsales.com/shop/owc-mercury-helios-3s/thunderbolt-3). It's an external thunderbolt 3 PCIe card adapter that they sell with a caddy to mount U.2 NVMe SSDs.\n\nSo I get a 7.68TB WD SN640 U.2 SSD, stick it in the Helios and the machine sees the drive, I initialize it and try to format it. Couldn't do it between AFPS, MacOS Journaled, EXFAT, FAT, but I was able to do it on one of my machines into NTFS.\n\nOn that same machine it allowed me to reformat that into a MacOS Journaled drive and I thought I was good to go.\n\nTried to copy a file, system hangs and then them the drive is disconnected. Try to run a disk speed test, system hangs and drive is disconnected. Then I tried to reformat it to something else, hang and then disconnect on both my machines.\n\nI have no idea how to troubleshoot next. I read some stuff about compatibility issues with some drive manufacturers and Apple because of NVMe protocols, but WD seems to use the same one as Apple.\n\nAny ideas?\n\nMacBook Pro M1Max\n\niMac (2019) Core i9", "author_fullname": "t2_1bt7fjmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble using external PCIe Adapter with U.2 NVMe SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100byw0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672553801.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672547941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Update: In digging I found &lt;a href=\"https://www.sonnettech.com/support/downloads/manuals/u2_ssds.pdf\"&gt;this chart&lt;/a&gt; in a different thread about U.2 PCIe cards for Mac Pros. Turns out WD doesn\u2019t make a drive compatible with Macs.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;I&amp;#39;m a video editor and have been trying to find the best solution for high speed external storage. With some help from this subreddit I thought I hit the mark when I was turned towards using U.2 NVMe SSDs. I got the &lt;a href=\"https://eshop.macsales.com/shop/owc-mercury-helios-3s/thunderbolt-3\"&gt;OWC Helios 3S&lt;/a&gt;. It&amp;#39;s an external thunderbolt 3 PCIe card adapter that they sell with a caddy to mount U.2 NVMe SSDs.&lt;/p&gt;\n\n&lt;p&gt;So I get a 7.68TB WD SN640 U.2 SSD, stick it in the Helios and the machine sees the drive, I initialize it and try to format it. Couldn&amp;#39;t do it between AFPS, MacOS Journaled, EXFAT, FAT, but I was able to do it on one of my machines into NTFS.&lt;/p&gt;\n\n&lt;p&gt;On that same machine it allowed me to reformat that into a MacOS Journaled drive and I thought I was good to go.&lt;/p&gt;\n\n&lt;p&gt;Tried to copy a file, system hangs and then them the drive is disconnected. Try to run a disk speed test, system hangs and drive is disconnected. Then I tried to reformat it to something else, hang and then disconnect on both my machines.&lt;/p&gt;\n\n&lt;p&gt;I have no idea how to troubleshoot next. I read some stuff about compatibility issues with some drive manufacturers and Apple because of NVMe protocols, but WD seems to use the same one as Apple.&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n\n&lt;p&gt;MacBook Pro M1Max&lt;/p&gt;\n\n&lt;p&gt;iMac (2019) Core i9&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100byw0", "is_robot_indexable": true, "report_reasons": null, "author": "Canadian__Tired", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100byw0/trouble_using_external_pcie_adapter_with_u2_nvme/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100byw0/trouble_using_external_pcie_adapter_with_u2_nvme/", "subreddit_subscribers": 663216, "created_utc": 1672547941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've just been moving the top image \"text\" from one page to another, deleting the background, then moving it back. Does anyone know if there's a quicker and more efficient way to do this?\n\nAlso (different but related question) -- is there a way to download pdfs from IA at higher image quality or as such that the pages don't get separated into mulitple separate \"layers\" in the case for books with a lot of pictures or illustrations?", "author_fullname": "t2_53xbirqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to delete the background page image from Internet Archive pdfs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1002wnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672518549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just been moving the top image &amp;quot;text&amp;quot; from one page to another, deleting the background, then moving it back. Does anyone know if there&amp;#39;s a quicker and more efficient way to do this?&lt;/p&gt;\n\n&lt;p&gt;Also (different but related question) -- is there a way to download pdfs from IA at higher image quality or as such that the pages don&amp;#39;t get separated into mulitple separate &amp;quot;layers&amp;quot; in the case for books with a lot of pictures or illustrations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1002wnm", "is_robot_indexable": true, "report_reasons": null, "author": "fiocobra", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1002wnm/any_way_to_delete_the_background_page_image_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1002wnm/any_way_to_delete_the_background_page_image_from/", "subreddit_subscribers": 663216, "created_utc": 1672518549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am hoping to digitize/archive some old photos but my laser printer also just went kaput. \n\nI am looking around to no avail and wondering if anyone knows of an ADF scanner and printer?\n\nTIA", "author_fullname": "t2_73b79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for ADF Scanner + Laser Printer Combo. Unicorn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1001coy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672514046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am hoping to digitize/archive some old photos but my laser printer also just went kaput. &lt;/p&gt;\n\n&lt;p&gt;I am looking around to no avail and wondering if anyone knows of an ADF scanner and printer?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1001coy", "is_robot_indexable": true, "report_reasons": null, "author": "MILFHunterHearstHelm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1001coy/looking_for_adf_scanner_laser_printer_combo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1001coy/looking_for_adf_scanner_laser_printer_combo/", "subreddit_subscribers": 663216, "created_utc": 1672514046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.\n\nBelow is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.\n\n# There are a number of external factors that can impact or influence the availability of information on the internet. \n\n&amp;#x200B;\n\n* Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo \\[[1](https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/)\\] \\[[2](https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480)\\] \\[[3](https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/)\\] \\[[4](https://www.wired.co.uk/article/lets-play-youtube-crackdown)\\], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. \n* Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. \n* Environmental disasters or internal societal discourse leading to the destruction or [sabotage](https://en.wikipedia.org/wiki/2021_South_African_unrest) of local and state infrastructure. \n* User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. \n* Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. \n\n&amp;#x200B;", "author_fullname": "t2_o8wjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reasons for why data hoarding is important and why you should start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_100o9fo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672593652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.&lt;/p&gt;\n\n&lt;p&gt;Below is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.&lt;/p&gt;\n\n&lt;h1&gt;There are a number of external factors that can impact or influence the availability of information on the internet.&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo [&lt;a href=\"https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/\"&gt;1&lt;/a&gt;] [&lt;a href=\"https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480\"&gt;2&lt;/a&gt;] [&lt;a href=\"https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/\"&gt;3&lt;/a&gt;] [&lt;a href=\"https://www.wired.co.uk/article/lets-play-youtube-crackdown\"&gt;4&lt;/a&gt;], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. &lt;/li&gt;\n&lt;li&gt;Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. &lt;/li&gt;\n&lt;li&gt;Environmental disasters or internal societal discourse leading to the destruction or &lt;a href=\"https://en.wikipedia.org/wiki/2021_South_African_unrest\"&gt;sabotage&lt;/a&gt; of local and state infrastructure. &lt;/li&gt;\n&lt;li&gt;User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. &lt;/li&gt;\n&lt;li&gt;Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?auto=webp&amp;s=c387f574702b9ed7c68f698f7fa60d3c32211671", "width": 1800, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb9ab3549c9f5cc04cb293a047279f42604c60fd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7290288a77475dc5eb9e611bf255005806be1f4f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a84b6bc449101a95d8f26aba49a1e373c5f7f05b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41b14dbcff1f1c5660bbb986002af4d35c724c77", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4eb9f48e1255ec76179e227b7f255cae2381d077", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39312c08074837719f03b915499b7495eeb170f7", "width": 1080, "height": 540}], "variants": {}, "id": "8L_qxpBRz4_edl-TBfsKsZva8bCq3Eo_1KrJqCdCbVo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100o9fo", "is_robot_indexable": true, "report_reasons": null, "author": "ReclusiveEagle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "subreddit_subscribers": 663216, "created_utc": 1672593652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings, apologies if this or similar questions have been asked already, but I wanted some sanity check with the community that specializes in data storage.\n\nI have a Minisforum UM300 box that I currently use to run Proxmox and virtualized pfSense as 1Gbps home network router. And now, I would like it to provide some storage capabilities. So my plan is to have a virtualized NAS, that will only be exposed to LAN. Now hooking up the storage drives to the box is where I'm having some difficulties to make the right choices. \n\nI do photography for a hoby and the storage would mostly be used as photo archive. My plan was to get 2x4-6TB drives and use RAID1 and also setup daily backups to something like AWS S3 or Backblaze B2 for impotant stuff. My data needs don't grow by a lot, ~20-40Gb a month. This should be enough for at least a few years and then I could decide what to do next\n\nI would like to keep the whole setup low power, the electricity here is 0.65\u20ac / kwh, so running a lot of power hungry hardware is eh... not pleasant. Also, ideally, I would like to keep the whole setup low profile and easy to transport, I move a lot, sometimes to different EU countries (the next move is in 2-3 months, same country though).\n\nNow about hooking up the drives to the box. The box has 3 x USB 3.1 ports.\n- I could use individual external 3.5 HDDs. The con is that it's messy. Lots of unnecessary wiring and no expansion options.\n- I could use individual external 2.5 HDDs or SSDs. Less wiring, because there is no need for PSU, but no expansion. The SSDs are actually attractive choice, because there will be much more reading than writing to the drives and those could potentially outlasts HDDs also less prone to accidental impact damage when moving.\n- I could get something like 2-4 bay fantec or yottamaster DAS. USB 3.0 model with built-in RAID should be enough for 4 drives. Quite compact and I could add 2x drives later on.\n- Maybe someone could also recommend some 2x or 4x 2.5 enclosure with USB 3.1? I know that the interface would become a bottleneck in case of 4 SSDs, for HDD it would be plenty of bandwidth though.\n\nMaybe also some recommendations on filesystem to use. My thought was using btrfs and raid1.", "author_fullname": "t2_9rdt91h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minisforum UM300 as home NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100i6bi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672574255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, apologies if this or similar questions have been asked already, but I wanted some sanity check with the community that specializes in data storage.&lt;/p&gt;\n\n&lt;p&gt;I have a Minisforum UM300 box that I currently use to run Proxmox and virtualized pfSense as 1Gbps home network router. And now, I would like it to provide some storage capabilities. So my plan is to have a virtualized NAS, that will only be exposed to LAN. Now hooking up the storage drives to the box is where I&amp;#39;m having some difficulties to make the right choices. &lt;/p&gt;\n\n&lt;p&gt;I do photography for a hoby and the storage would mostly be used as photo archive. My plan was to get 2x4-6TB drives and use RAID1 and also setup daily backups to something like AWS S3 or Backblaze B2 for impotant stuff. My data needs don&amp;#39;t grow by a lot, ~20-40Gb a month. This should be enough for at least a few years and then I could decide what to do next&lt;/p&gt;\n\n&lt;p&gt;I would like to keep the whole setup low power, the electricity here is 0.65\u20ac / kwh, so running a lot of power hungry hardware is eh... not pleasant. Also, ideally, I would like to keep the whole setup low profile and easy to transport, I move a lot, sometimes to different EU countries (the next move is in 2-3 months, same country though).&lt;/p&gt;\n\n&lt;p&gt;Now about hooking up the drives to the box. The box has 3 x USB 3.1 ports.\n- I could use individual external 3.5 HDDs. The con is that it&amp;#39;s messy. Lots of unnecessary wiring and no expansion options.\n- I could use individual external 2.5 HDDs or SSDs. Less wiring, because there is no need for PSU, but no expansion. The SSDs are actually attractive choice, because there will be much more reading than writing to the drives and those could potentially outlasts HDDs also less prone to accidental impact damage when moving.\n- I could get something like 2-4 bay fantec or yottamaster DAS. USB 3.0 model with built-in RAID should be enough for 4 drives. Quite compact and I could add 2x drives later on.\n- Maybe someone could also recommend some 2x or 4x 2.5 enclosure with USB 3.1? I know that the interface would become a bottleneck in case of 4 SSDs, for HDD it would be plenty of bandwidth though.&lt;/p&gt;\n\n&lt;p&gt;Maybe also some recommendations on filesystem to use. My thought was using btrfs and raid1.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100i6bi", "is_robot_indexable": true, "report_reasons": null, "author": "No-Significance2877", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100i6bi/minisforum_um300_as_home_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100i6bi/minisforum_um300_as_home_nas/", "subreddit_subscribers": 663216, "created_utc": 1672574255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to get our list of joined communities / subreddddits from gallery-dl ? I can't find anything from my side", "author_fullname": "t2_3zmmj0so", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-download - Getting list of communities/subreddits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100f3bf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672560730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to get our list of joined communities / subreddddits from gallery-dl ? I can&amp;#39;t find anything from my side&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100f3bf", "is_robot_indexable": true, "report_reasons": null, "author": "Tyranoc4", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100f3bf/gallerydownload_getting_list_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100f3bf/gallerydownload_getting_list_of/", "subreddit_subscribers": 663216, "created_utc": 1672560730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I realized that I'm subscribed to Google One, Dropbox, iCloud, and one drive. I would like to move all my files to one cloud. What's the easiest, fastest way to do it?", "author_fullname": "t2_80viwyd5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest wayto transfer cloud files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100du0w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672555431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I realized that I&amp;#39;m subscribed to Google One, Dropbox, iCloud, and one drive. I would like to move all my files to one cloud. What&amp;#39;s the easiest, fastest way to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100du0w", "is_robot_indexable": true, "report_reasons": null, "author": "Used-Shift9107", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100du0w/easiest_wayto_transfer_cloud_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100du0w/easiest_wayto_transfer_cloud_files/", "subreddit_subscribers": 663216, "created_utc": 1672555431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I want to transfer some photos from my iPhone to my computer. I found an online tool called qrcp ([https://github.com/claudiodangelis/qrcp](https://github.com/claudiodangelis/qrcp)). Downloaded it and ran it on my computer (Linux user). Then, I accessed it from my iPhone and uploaded a few files to test it out.\n\nWhile the content does get transferred over, the filesystem date isn't preserved. Roughly 1,000 photos to transfer so keying in the dates manually isn't an option.\n\nWhat can I do? I want to preserve the dates and times the photos were taken.", "author_fullname": "t2_20uo12nk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transfer photos from iphone to linux computer while preserving date and time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100au5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672543687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want to transfer some photos from my iPhone to my computer. I found an online tool called qrcp (&lt;a href=\"https://github.com/claudiodangelis/qrcp\"&gt;https://github.com/claudiodangelis/qrcp&lt;/a&gt;). Downloaded it and ran it on my computer (Linux user). Then, I accessed it from my iPhone and uploaded a few files to test it out.&lt;/p&gt;\n\n&lt;p&gt;While the content does get transferred over, the filesystem date isn&amp;#39;t preserved. Roughly 1,000 photos to transfer so keying in the dates manually isn&amp;#39;t an option.&lt;/p&gt;\n\n&lt;p&gt;What can I do? I want to preserve the dates and times the photos were taken.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W2thSUPQl9oaNAWB1ls8eUZe5HoGkIiIpTGZSyEs-7c.jpg?auto=webp&amp;s=1cb65063aa2b9b03dfd62b542ee3617103ef653f", "width": 794, "height": 684}, "resolutions": [{"url": "https://external-preview.redd.it/W2thSUPQl9oaNAWB1ls8eUZe5HoGkIiIpTGZSyEs-7c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6ebe5f9322f58bbf7fd9032740fd4cedcfb852cb", "width": 108, "height": 93}, {"url": "https://external-preview.redd.it/W2thSUPQl9oaNAWB1ls8eUZe5HoGkIiIpTGZSyEs-7c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=900a97acbaa891ed56ef43c03ebee49b47d58c0d", "width": 216, "height": 186}, {"url": "https://external-preview.redd.it/W2thSUPQl9oaNAWB1ls8eUZe5HoGkIiIpTGZSyEs-7c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4ae546be4b1e47e2a29ef2cd3ee09df7dbdcaec", "width": 320, "height": 275}, {"url": "https://external-preview.redd.it/W2thSUPQl9oaNAWB1ls8eUZe5HoGkIiIpTGZSyEs-7c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a07702bc744ecace0d53282ad4c3bfba280d832d", "width": 640, "height": 551}], "variants": {}, "id": "rpd_tYMw3lHAI6xoCn3I_mwj-r6ZhF9Nv6uESMFkEVM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100au5n", "is_robot_indexable": true, "report_reasons": null, "author": "CrazybloxianEmpireNS", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100au5n/how_to_transfer_photos_from_iphone_to_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100au5n/how_to_transfer_photos_from_iphone_to_linux/", "subreddit_subscribers": 663216, "created_utc": 1672543687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dell Vostro 2510\n\nBelieve battery is dead, it doesn't turn on, don't have the charger, but I could purchase either\n\nBefore I do, though: Is there a way to extract the files from its hard drive? I might be open to home surgery.\n\nThanks in advance - and happy new year.", "author_fullname": "t2_lq5izo2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to extract files from dead laptop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1009czv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672538519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dell Vostro 2510&lt;/p&gt;\n\n&lt;p&gt;Believe battery is dead, it doesn&amp;#39;t turn on, don&amp;#39;t have the charger, but I could purchase either&lt;/p&gt;\n\n&lt;p&gt;Before I do, though: Is there a way to extract the files from its hard drive? I might be open to home surgery.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance - and happy new year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1009czv", "is_robot_indexable": true, "report_reasons": null, "author": "PrimaryCombination26", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1009czv/how_to_extract_files_from_dead_laptop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1009czv/how_to_extract_files_from_dead_laptop/", "subreddit_subscribers": 663216, "created_utc": 1672538519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am automating some alerts and want to figure how to read smartctl.\n\n&amp;#x200B;\n\nDoes this section ever actually change?\n\n=== START OF READ SMART DATA SECTION ===\n\nSMART overall-health self-assessment test result: PASSED\n\nMy current plan is to run short tests once a week and check that passed.  I know this will mean not paying attention to things like increasing read or write errors but seems to be something I can reasonably automate.\n\nIn more detail I'll be looking at:\n\nsmartctl -j -a /dev/sda|jq .smart\\_status\n\n{\n\n  \"passed\": true\n\n}\n\n&amp;#x200B;\n\nAnyone have any thoughts?", "author_fullname": "t2_3jp1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to read smartctl", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1008ih5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672535710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am automating some alerts and want to figure how to read smartctl.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does this section ever actually change?&lt;/p&gt;\n\n&lt;p&gt;=== START OF READ SMART DATA SECTION ===&lt;/p&gt;\n\n&lt;p&gt;SMART overall-health self-assessment test result: PASSED&lt;/p&gt;\n\n&lt;p&gt;My current plan is to run short tests once a week and check that passed.  I know this will mean not paying attention to things like increasing read or write errors but seems to be something I can reasonably automate.&lt;/p&gt;\n\n&lt;p&gt;In more detail I&amp;#39;ll be looking at:&lt;/p&gt;\n\n&lt;p&gt;smartctl -j -a /dev/sda|jq .smart_status&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;passed&amp;quot;: true&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone have any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1008ih5", "is_robot_indexable": true, "report_reasons": null, "author": "fireduck", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1008ih5/how_to_read_smartctl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1008ih5/how_to_read_smartctl/", "subreddit_subscribers": 663216, "created_utc": 1672535710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellow Hoarders,\n\nA couple of year-ish back, the WD Blue SN550 with the go-to, with a nice fast 1.2TB or so per second write, and sustaining a respectable 850MBps post cache.\n\nEver since the chip swap in 2021, it remains fast (faster, in fact) for the SLC portion, then drops to 370MBps. Not acceptable.\n\n\nDoes anyone know who the budget king of NVME currently is?\n\nI'm really only looking for one key feature:\n\n**sustained writes that are notably faster than SATA, after cache is exhausted**\n\n750MB-1000MB would be nice. Price is a key factor.\n\nThanks all!", "author_fullname": "t2_ye03j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which cheap NVME, large writes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1007ooi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Drive Choice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672533003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Hoarders,&lt;/p&gt;\n\n&lt;p&gt;A couple of year-ish back, the WD Blue SN550 with the go-to, with a nice fast 1.2TB or so per second write, and sustaining a respectable 850MBps post cache.&lt;/p&gt;\n\n&lt;p&gt;Ever since the chip swap in 2021, it remains fast (faster, in fact) for the SLC portion, then drops to 370MBps. Not acceptable.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know who the budget king of NVME currently is?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really only looking for one key feature:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;sustained writes that are notably faster than SATA, after cache is exhausted&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;750MB-1000MB would be nice. Price is a key factor.&lt;/p&gt;\n\n&lt;p&gt;Thanks all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "18TB-RaidZ2", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1007ooi", "is_robot_indexable": true, "report_reasons": null, "author": "Master_Scythe", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1007ooi/which_cheap_nvme_large_writes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1007ooi/which_cheap_nvme_large_writes/", "subreddit_subscribers": 663216, "created_utc": 1672533003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Hello everyone,\n\nIm thinking of buying a NAS for sometime now i was going to buy the DS920+ but i saw a reddit post talking about a new one releasing soon so i waited.\n\nNow the DS923+ was released a few weeks ago and im reading that it dosent have a integrated gpu and i need some help with that my main purpose of buying a NAS is to backup my phone pics vids and backup my pc documents.\n\n1. What does not having a integrated gpu mean? what cant i do with that?\n2. Between DS923+ and the Asustor Lockerstor 4 Gen 2 what is the best? Does the Synology software so ahead of the competition?\n3. What HDDs should i get for the DS923+ ive read somewhere that the compatibility list is short but i cant find that list.\n\nThanks in advance!", "author_fullname": "t2_2xz2krxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New NAS buyer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1006eb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672528917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Im thinking of buying a NAS for sometime now i was going to buy the DS920+ but i saw a reddit post talking about a new one releasing soon so i waited.&lt;/p&gt;\n\n&lt;p&gt;Now the DS923+ was released a few weeks ago and im reading that it dosent have a integrated gpu and i need some help with that my main purpose of buying a NAS is to backup my phone pics vids and backup my pc documents.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What does not having a integrated gpu mean? what cant i do with that?&lt;/li&gt;\n&lt;li&gt;Between DS923+ and the Asustor Lockerstor 4 Gen 2 what is the best? Does the Synology software so ahead of the competition?&lt;/li&gt;\n&lt;li&gt;What HDDs should i get for the DS923+ ive read somewhere that the compatibility list is short but i cant find that list.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1006eb0", "is_robot_indexable": true, "report_reasons": null, "author": "wdquarenta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1006eb0/new_nas_buyer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1006eb0/new_nas_buyer/", "subreddit_subscribers": 663216, "created_utc": 1672528917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a Dell MD1000 and a Perc H800. I have 8 x 3tb drives, seagate SAS. Can I add additional drives to the raid 10 as I acquire these drives or should I buy all fifteen now ? For future expansion can I replace a 3tb with a 10tb drive with no downtime?", "author_fullname": "t2_ignbsfvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive Shucking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1005exs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672525919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a Dell MD1000 and a Perc H800. I have 8 x 3tb drives, seagate SAS. Can I add additional drives to the raid 10 as I acquire these drives or should I buy all fifteen now ? For future expansion can I replace a 3tb with a 10tb drive with no downtime?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1005exs", "is_robot_indexable": true, "report_reasons": null, "author": "gimpygoat498", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1005exs/drive_shucking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1005exs/drive_shucking/", "subreddit_subscribers": 663216, "created_utc": 1672525919.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}