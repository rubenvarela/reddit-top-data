{"kind": "Listing", "data": {"after": null, "dist": 16, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have been working as a data engineer for 3 years, and my day-to-day work ranging from creating data warehouse, optimizing cost and infrastructure, creating in-house tooling and automation, and creating dashboards for business users. \n\nI'm not the best of dealing with business stakeholders directly, especially when talking about business metrics and initiative, so I'm not performing (and not enjoying) well when working closely with them to create dashboards or data warehouse.\n\nMeanwhile I am comfortable enough to work with code and infrastructures, building tools based on business/products requirement as well as creating more initiatives related to optimizing infras and cost. \n\nI'm aware that in the end we will faced the business stakeholders for the final product, but I felt that I am more comfortable and confidence to build and present software products rather than data products at this moment. \n\nAt first I planned to become a specialist in data infra and platform, but I found that kind of job is pretty rare, as most of DE jobs available here is a more generalist position. That's why I have a second thought to move into a more software engineering position like backend engineer or maybe MLE (I can code in golang and doing IaC, also some part of the DE tasks are creating APIs) so I can capitalize my strong point where I perform best at.\n\nWould it be a bold move if switching career to a more SE role for that case? Or would it be better to overcome my weak point and stay as a DE (with hope that I can be a T-shaped skill DE)?", "author_fullname": "t2_1q71lc7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch career to a more software engineering position or stay as DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bfwue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673681589.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673672256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been working as a data engineer for 3 years, and my day-to-day work ranging from creating data warehouse, optimizing cost and infrastructure, creating in-house tooling and automation, and creating dashboards for business users. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not the best of dealing with business stakeholders directly, especially when talking about business metrics and initiative, so I&amp;#39;m not performing (and not enjoying) well when working closely with them to create dashboards or data warehouse.&lt;/p&gt;\n\n&lt;p&gt;Meanwhile I am comfortable enough to work with code and infrastructures, building tools based on business/products requirement as well as creating more initiatives related to optimizing infras and cost. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that in the end we will faced the business stakeholders for the final product, but I felt that I am more comfortable and confidence to build and present software products rather than data products at this moment. &lt;/p&gt;\n\n&lt;p&gt;At first I planned to become a specialist in data infra and platform, but I found that kind of job is pretty rare, as most of DE jobs available here is a more generalist position. That&amp;#39;s why I have a second thought to move into a more software engineering position like backend engineer or maybe MLE (I can code in golang and doing IaC, also some part of the DE tasks are creating APIs) so I can capitalize my strong point where I perform best at.&lt;/p&gt;\n\n&lt;p&gt;Would it be a bold move if switching career to a more SE role for that case? Or would it be better to overcome my weak point and stay as a DE (with hope that I can be a T-shaped skill DE)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10bfwue", "is_robot_indexable": true, "report_reasons": null, "author": "srodinger18", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bfwue/switch_career_to_a_more_software_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bfwue/switch_career_to_a_more_software_engineering/", "subreddit_subscribers": 86287, "created_utc": 1673672256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At what point would you consider utilizing\n- a specialized modern data stack (e.g. Fivetran + dbt + Snowflake) to build a data lake and warehouse vs.\n- just following a KISS principle and using an RDBMS (e.g. Postgres) and a free ETL tool or Postgres+FDW+java/python/whatever code? \n\nI understand that it is impossible to give a simple answer and that many other factors are at play here (data governance requirements...), but without complicating things, what is your dividing line or rule of thumb (if any)?\n\nContext: I have 10+ years of sw engineering experience and have dabbled in data engineering ~6-7 years ago while very complex and glued-together-with-a-bubbleum Big Data solutions were all the rage. Now I got myself into a project where I am required to give my input from both data engineering and software engineering perspectives. The customer has a small number of applications (3-5) from which it needs to make data available for analytics. The total (multiple-year worth) amount of data is currently around ~100GB and I don't see a potential for exponential growth from there. Because of this, my instinct is to go for a KISS solution of simply using Postgres plus something to transfer data into it. Also, the customer's software engineering team is currently used to using outdated technologies and I think introducing an entirely new stack on them would be very complex and cumbersome.\n\nI would be especially interested to hear from people that got burned by their approach. Either by utilizing a too-complicated stack that was not needed or utilizing a too-simple stack that they outgrew and wish they used a more complicated one from the start.", "author_fullname": "t2_hlvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complex vs KISS data pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bnt19", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673700957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At what point would you consider utilizing\n- a specialized modern data stack (e.g. Fivetran + dbt + Snowflake) to build a data lake and warehouse vs.\n- just following a KISS principle and using an RDBMS (e.g. Postgres) and a free ETL tool or Postgres+FDW+java/python/whatever code? &lt;/p&gt;\n\n&lt;p&gt;I understand that it is impossible to give a simple answer and that many other factors are at play here (data governance requirements...), but without complicating things, what is your dividing line or rule of thumb (if any)?&lt;/p&gt;\n\n&lt;p&gt;Context: I have 10+ years of sw engineering experience and have dabbled in data engineering ~6-7 years ago while very complex and glued-together-with-a-bubbleum Big Data solutions were all the rage. Now I got myself into a project where I am required to give my input from both data engineering and software engineering perspectives. The customer has a small number of applications (3-5) from which it needs to make data available for analytics. The total (multiple-year worth) amount of data is currently around ~100GB and I don&amp;#39;t see a potential for exponential growth from there. Because of this, my instinct is to go for a KISS solution of simply using Postgres plus something to transfer data into it. Also, the customer&amp;#39;s software engineering team is currently used to using outdated technologies and I think introducing an entirely new stack on them would be very complex and cumbersome.&lt;/p&gt;\n\n&lt;p&gt;I would be especially interested to hear from people that got burned by their approach. Either by utilizing a too-complicated stack that was not needed or utilizing a too-simple stack that they outgrew and wish they used a more complicated one from the start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bnt19", "is_robot_indexable": true, "report_reasons": null, "author": "frula00", "discussion_type": null, "num_comments": 20, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bnt19/complex_vs_kiss_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bnt19/complex_vs_kiss_data_pipeline/", "subreddit_subscribers": 86287, "created_utc": 1673700957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have:\n\n- ETL: Extract, transform in the pipeline, load to the destination;\n- ELT: Extract, load to destination \u2018as is\u2019 and then transform;\n- EtLT: same as ELT except de-identification in the pipeline to reduce audit &amp; risk issues;\n\nThen we have a pipeline that is Transformed in source (the data warehouse), then Extracted, then Loaded to the destination. And what do we call it? Not TEL, but Reverse ETL.\n\nSerious question: was this naming a marketing thing? Does anyone know the history behind it? Genuinely curious.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone explain why it\u2019s Reverse ETL not TEL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bjhvr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673685149.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673684909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ETL: Extract, transform in the pipeline, load to the destination;&lt;/li&gt;\n&lt;li&gt;ELT: Extract, load to destination \u2018as is\u2019 and then transform;&lt;/li&gt;\n&lt;li&gt;EtLT: same as ELT except de-identification in the pipeline to reduce audit &amp;amp; risk issues;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then we have a pipeline that is Transformed in source (the data warehouse), then Extracted, then Loaded to the destination. And what do we call it? Not TEL, but Reverse ETL.&lt;/p&gt;\n\n&lt;p&gt;Serious question: was this naming a marketing thing? Does anyone know the history behind it? Genuinely curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bjhvr", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bjhvr/can_someone_explain_why_its_reverse_etl_not_tel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bjhvr/can_someone_explain_why_its_reverse_etl_not_tel/", "subreddit_subscribers": 86287, "created_utc": 1673684909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to understand if other folk experience same **pain points/time consuming activities** in the process of creating the pipeline. \n\nI am currently working with Airflow. My DB is in BigQuery.  \nWhen building a pipeline from scratch I'd estimate my time is divided as follows (given I have the pipeline's business requirements):  \n\\- 20% of the time is spent on designing the pipeline's flow logic.  \n\\- 40% of the time is spent on building the initial code (that should cover 80+% of the cases)  \n\\- 40% of the time is spent to adjust the code to handle edge cases found in the data (unexpected data behavior/contaminated data/missing values...).  \nI'd be happy to know how others split their time, and if there are any suggestions on **how to reduce the time spent on initially generating and adjusting the code** (this part can take me between a few days and a few weeks)?\n\n1. What's the **most time consuming** step for you (ex.  Data cleaning, structuring, modeling, etc)?   \nIf you could dive into more specifics on what's the exact struggle you have/had that would be awesome.  \n2. Also, which tools/strategies do you use and can recommend to make the process more efficient?\n\nThanks!", "author_fullname": "t2_ft0j766", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear, pipeline builders! Which step in your role is the most time consuming?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bm148", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673698636.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673694592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to understand if other folk experience same &lt;strong&gt;pain points/time consuming activities&lt;/strong&gt; in the process of creating the pipeline. &lt;/p&gt;\n\n&lt;p&gt;I am currently working with Airflow. My DB is in BigQuery.&lt;br/&gt;\nWhen building a pipeline from scratch I&amp;#39;d estimate my time is divided as follows (given I have the pipeline&amp;#39;s business requirements):&lt;br/&gt;\n- 20% of the time is spent on designing the pipeline&amp;#39;s flow logic.&lt;br/&gt;\n- 40% of the time is spent on building the initial code (that should cover 80+% of the cases)&lt;br/&gt;\n- 40% of the time is spent to adjust the code to handle edge cases found in the data (unexpected data behavior/contaminated data/missing values...).&lt;br/&gt;\nI&amp;#39;d be happy to know how others split their time, and if there are any suggestions on &lt;strong&gt;how to reduce the time spent on initially generating and adjusting the code&lt;/strong&gt; (this part can take me between a few days and a few weeks)?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What&amp;#39;s the &lt;strong&gt;most time consuming&lt;/strong&gt; step for you (ex.  Data cleaning, structuring, modeling, etc)?&lt;br/&gt;\nIf you could dive into more specifics on what&amp;#39;s the exact struggle you have/had that would be awesome.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Also, which tools/strategies do you use and can recommend to make the process more efficient?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bm148", "is_robot_indexable": true, "report_reasons": null, "author": "Dzimkaf", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bm148/dear_pipeline_builders_which_step_in_your_role_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bm148/dear_pipeline_builders_which_step_in_your_role_is/", "subreddit_subscribers": 86287, "created_utc": 1673694592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Designing a single source of truth for data coming from multiple sources. The scale of data is enormous more than PB and the solution needs to be deployed on premise, there could be multiple end goals [ Executive Reporting, ML/Al use case, etc]. What could be the to be state architecture? \n\nDo you think SSIS could be a fit? Or I should stick to medallion architecture? How to define the landing zone if cloud is not an option keeping in mind ease of scalability. What should be the target warehouse or Lakehouse...", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a single source of truth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bbjt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673659223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Designing a single source of truth for data coming from multiple sources. The scale of data is enormous more than PB and the solution needs to be deployed on premise, there could be multiple end goals [ Executive Reporting, ML/Al use case, etc]. What could be the to be state architecture? &lt;/p&gt;\n\n&lt;p&gt;Do you think SSIS could be a fit? Or I should stick to medallion architecture? How to define the landing zone if cloud is not an option keeping in mind ease of scalability. What should be the target warehouse or Lakehouse...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bbjt1", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bbjt1/designing_a_single_source_of_truth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bbjt1/designing_a_single_source_of_truth/", "subreddit_subscribers": 86287, "created_utc": 1673659223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im trying to use cloud functions to process streaming data from pub sub. Since we get random unexpected spikes from the source (iOS apps) hard to predict when users will be active etc\n\nThe function is written In Python. It takes a record does a bunch of validation on the fields and forwards it to another queue. \n\nIt\u2019s pretty slow, execution time is ~1min per message.\n\nSince it\u2019s the compute time you pay for my first hunch is to re write it using Golang which we know is much faster.\n\nBut is there anything else I could do to reduce the cost? \n\nMaybe have a function convert the JSON record to avro format or something first?", "author_fullname": "t2_ggg0wfmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reducing Cloud Functions Cost - Ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bou0k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673704067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im trying to use cloud functions to process streaming data from pub sub. Since we get random unexpected spikes from the source (iOS apps) hard to predict when users will be active etc&lt;/p&gt;\n\n&lt;p&gt;The function is written In Python. It takes a record does a bunch of validation on the fields and forwards it to another queue. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s pretty slow, execution time is ~1min per message.&lt;/p&gt;\n\n&lt;p&gt;Since it\u2019s the compute time you pay for my first hunch is to re write it using Golang which we know is much faster.&lt;/p&gt;\n\n&lt;p&gt;But is there anything else I could do to reduce the cost? &lt;/p&gt;\n\n&lt;p&gt;Maybe have a function convert the JSON record to avro format or something first?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bou0k", "is_robot_indexable": true, "report_reasons": null, "author": "camelCaseInsensitive", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bou0k/reducing_cloud_functions_cost_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bou0k/reducing_cloud_functions_cost_ideas/", "subreddit_subscribers": 86287, "created_utc": 1673704067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "1. Python/Pyspark/PyArrow/Pandas\n2. r/tidyverse/SparkR/ Arrow in R\n3. Java/Scala\n4. etc...", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which programming languages (or framework) skills will be recession-proof and worth learning in 2023 Data Engineering or Data science job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bw5jp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673722426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;Python/Pyspark/PyArrow/Pandas&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/tidyverse/SparkR/\"&gt;r/tidyverse/SparkR/&lt;/a&gt; Arrow in R&lt;/li&gt;\n&lt;li&gt;Java/Scala&lt;/li&gt;\n&lt;li&gt;etc...&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10bw5jp", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bw5jp/which_programming_languages_or_framework_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bw5jp/which_programming_languages_or_framework_skills/", "subreddit_subscribers": 86287, "created_utc": 1673722426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm a non trad(psychology degree). joining a web dev bootcamp next month. I know many that graduated and found a good paying job, it seems that web dev has a really low entry barrier.\n\nHowever, I'm thinking of switching and studying DE, the issue is that there is no DE bootcamps in Lebanon. And doing a CS degree is not feasible. I found some online courses and the bootcamp offered here but I'm wondering whether I can find a remote job after completing it.\n\nTl;Dr: does de has the same entry barrier compared to web dev", "author_fullname": "t2_6801ehfn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "entry barrier for non traditional", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bias6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673680373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a non trad(psychology degree). joining a web dev bootcamp next month. I know many that graduated and found a good paying job, it seems that web dev has a really low entry barrier.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m thinking of switching and studying DE, the issue is that there is no DE bootcamps in Lebanon. And doing a CS degree is not feasible. I found some online courses and the bootcamp offered here but I&amp;#39;m wondering whether I can find a remote job after completing it.&lt;/p&gt;\n\n&lt;p&gt;Tl;Dr: does de has the same entry barrier compared to web dev&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10bias6", "is_robot_indexable": true, "report_reasons": null, "author": "ezio313", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bias6/entry_barrier_for_non_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bias6/entry_barrier_for_non_traditional/", "subreddit_subscribers": 86287, "created_utc": 1673680373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "so, basically i hit a bigquery db for only 10 rows and then only 1,000 as a test:\n\nfrom there, i tried two different approaches\n\n1. first, turned the result into arrow, and then into polars dataframe (bigquery only has a pandas version of `\\`to_dataframe`\\` so --&gt; \\``pl.from_arrow(result.to_arrow())`\\`), and from polars i used s3fs to write a parquet file to an s3 bucket\n2. then...i was like maybe i can just cut out the middle-men and turned the result into arrow, then into a string which i encoded to bytes (arrow doesn't seem to have direct to bytes?) \\``result.to_arrow()`\\` then \\``aws.put_object(Body=bytes(result1_arrow.to_string(),encoding='utf-8')`\\`\n\n&amp;#x200B;\n\n* for the arrow approach, both times i got  230.0 B of size\n* for the dataframe approach, 10 rows gave me 3 KB and 1k rows gave me 13 KB\n* &amp;#x200B;\n\nnow, maybe if i just used boto3 for the dataframe approach i would get a different result, but i couldnt figure out how to do the following with a context manager -- that's why i used s3fs:\n\n    with fs.open(f's3://{bucket}/{file.parquet}', 'wb') as f:\n    df.write_parquet(f)\n\ninterested in your guys thoughts.", "author_fullname": "t2_5qteskd9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can anyone explain the reason for the difference in size for these two parquet conversions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bgiv2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673674200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so, basically i hit a bigquery db for only 10 rows and then only 1,000 as a test:&lt;/p&gt;\n\n&lt;p&gt;from there, i tried two different approaches&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;first, turned the result into arrow, and then into polars dataframe (bigquery only has a pandas version of &lt;code&gt;\\&lt;/code&gt;to_dataframe&lt;code&gt;\\&lt;/code&gt; so --&amp;gt; `&lt;code&gt;pl.from_arrow(result.to_arrow())&lt;/code&gt;`), and from polars i used s3fs to write a parquet file to an s3 bucket&lt;/li&gt;\n&lt;li&gt;then...i was like maybe i can just cut out the middle-men and turned the result into arrow, then into a string which i encoded to bytes (arrow doesn&amp;#39;t seem to have direct to bytes?) `&lt;code&gt;result.to_arrow()&lt;/code&gt;` then `&lt;code&gt;aws.put_object(Body=bytes(result1_arrow.to_string(),encoding=&amp;#39;utf-8&amp;#39;)&lt;/code&gt;`&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;for the arrow approach, both times i got  230.0 B of size&lt;/li&gt;\n&lt;li&gt;for the dataframe approach, 10 rows gave me 3 KB and 1k rows gave me 13 KB&lt;/li&gt;\n&lt;li&gt;&amp;#x200B;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;now, maybe if i just used boto3 for the dataframe approach i would get a different result, but i couldnt figure out how to do the following with a context manager -- that&amp;#39;s why i used s3fs:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with fs.open(f&amp;#39;s3://{bucket}/{file.parquet}&amp;#39;, &amp;#39;wb&amp;#39;) as f:\ndf.write_parquet(f)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;interested in your guys thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bgiv2", "is_robot_indexable": true, "report_reasons": null, "author": "iseestupid", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bgiv2/can_anyone_explain_the_reason_for_the_difference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bgiv2/can_anyone_explain_the_reason_for_the_difference/", "subreddit_subscribers": 86287, "created_utc": 1673674200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever quit big tech to do contracting work? How was that both time and salary wise?", "author_fullname": "t2_3p620rl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Contractor work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bdxyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673666155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever quit big tech to do contracting work? How was that both time and salary wise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DE @ Amazon/Lyft/Author of Ace DE Interview", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bdxyl", "is_robot_indexable": true, "report_reasons": null, "author": "chrisgarzon19", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10bdxyl/contractor_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bdxyl/contractor_work/", "subreddit_subscribers": 86287, "created_utc": 1673666155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on how others handle this.\n\nWe have Kafka event data, Salesforce data that is snapshotted each day, Segment data etc.\n\nCustomer attributes in both Kafka customer event and Salesforce account table. Both sides get updates by the business, and so we end up with the equivalent of a Type2 SCD source for each, with valid to and from dates that overlap.\n\nWhen bringing the two together in the silver layer, would you try to blend the date ranges and keep a full change history across all source \u2018SCD2\u2019 tables that are used, or would you only me pulling forward the current version of the customer?\n\nFurther, if you would persist the history, and the Customer dataset came from 5 source tables across 2 source systems, each with changes at different times, is there a simple way to achieve that join?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medallion Architecture - persist history in Silver?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bbrsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673659849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on how others handle this.&lt;/p&gt;\n\n&lt;p&gt;We have Kafka event data, Salesforce data that is snapshotted each day, Segment data etc.&lt;/p&gt;\n\n&lt;p&gt;Customer attributes in both Kafka customer event and Salesforce account table. Both sides get updates by the business, and so we end up with the equivalent of a Type2 SCD source for each, with valid to and from dates that overlap.&lt;/p&gt;\n\n&lt;p&gt;When bringing the two together in the silver layer, would you try to blend the date ranges and keep a full change history across all source \u2018SCD2\u2019 tables that are used, or would you only me pulling forward the current version of the customer?&lt;/p&gt;\n\n&lt;p&gt;Further, if you would persist the history, and the Customer dataset came from 5 source tables across 2 source systems, each with changes at different times, is there a simple way to achieve that join?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bbrsb", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bbrsb/medallion_architecture_persist_history_in_silver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bbrsb/medallion_architecture_persist_history_in_silver/", "subreddit_subscribers": 86287, "created_utc": 1673659849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "CONSTRAINT: Inhouse deployment\n\nWhat could be your to be state architecture ? and why ? \\[Keep in mind a data LakeHouse architecture along with BI\\]\n\nWhat are the industry tech stack design patterns", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End Goal: Executive Dashboard ( PetaByte scale of Data coming from multiple sources)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10c4x82", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673741087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;CONSTRAINT: Inhouse deployment&lt;/p&gt;\n\n&lt;p&gt;What could be your to be state architecture ? and why ? [Keep in mind a data LakeHouse architecture along with BI]&lt;/p&gt;\n\n&lt;p&gt;What are the industry tech stack design patterns&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10c4x82", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10c4x82/end_goal_executive_dashboard_petabyte_scale_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10c4x82/end_goal_executive_dashboard_petabyte_scale_of/", "subreddit_subscribers": 86287, "created_utc": 1673741087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm looking at about 3 years worth of Pushshift reddit archive files.   These are very large line delimited json files that have been compressed with zstd.  There are 72 of them (3 years of monthly submissions files and 3 years of monthly comment files).  Compressed each one is between 8-10 GB for submissions and 15-30GB for comments.\n\nGiven that storage isn't an issue, part of me wanted to decompress these and store the raw data (wouldn't change a thing) as daily parquet files (instead of monthly json).   But....   whatever format the raw files end up in, I will be extracting a subset of the columns, doing a bunch of clean up, and saving the resulting data to an (as yet unspecifed) DB - likely BigQuery.   \n\nSounds like a job for parquet, right?  Except I will probably only ever do this once.  It is very unlikely that I, or anyone else, will ever go back and extract different columns from the raw data.  So.... I have a decent script that can pull data from the zstd files in chunks, run the data munging and save the relevant data to the DB.  Is there really any value in adding the extra step of saving to parquet?\n\nI'm kinda torn.  I have to iteratively load the data from zstd files anyway, either to save it to parquet or to the DB after munging.   I could presumably combine the munging with saving to parquet before also sending to the DB, but I'm struggling to come up with a rationale for the parquet files.\n\nAm I just way overthinking this?", "author_fullname": "t2_syav4clo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to decide whether to keep raw files in compressed state or save to parquet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bxkxq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673725908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m looking at about 3 years worth of Pushshift reddit archive files.   These are very large line delimited json files that have been compressed with zstd.  There are 72 of them (3 years of monthly submissions files and 3 years of monthly comment files).  Compressed each one is between 8-10 GB for submissions and 15-30GB for comments.&lt;/p&gt;\n\n&lt;p&gt;Given that storage isn&amp;#39;t an issue, part of me wanted to decompress these and store the raw data (wouldn&amp;#39;t change a thing) as daily parquet files (instead of monthly json).   But....   whatever format the raw files end up in, I will be extracting a subset of the columns, doing a bunch of clean up, and saving the resulting data to an (as yet unspecifed) DB - likely BigQuery.   &lt;/p&gt;\n\n&lt;p&gt;Sounds like a job for parquet, right?  Except I will probably only ever do this once.  It is very unlikely that I, or anyone else, will ever go back and extract different columns from the raw data.  So.... I have a decent script that can pull data from the zstd files in chunks, run the data munging and save the relevant data to the DB.  Is there really any value in adding the extra step of saving to parquet?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kinda torn.  I have to iteratively load the data from zstd files anyway, either to save it to parquet or to the DB after munging.   I could presumably combine the munging with saving to parquet before also sending to the DB, but I&amp;#39;m struggling to come up with a rationale for the parquet files.&lt;/p&gt;\n\n&lt;p&gt;Am I just way overthinking this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bxkxq", "is_robot_indexable": true, "report_reasons": null, "author": "Malignant-Koala", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bxkxq/struggling_to_decide_whether_to_keep_raw_files_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bxkxq/struggling_to_decide_whether_to_keep_raw_files_in/", "subreddit_subscribers": 86287, "created_utc": 1673725908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically, as the title says. I have an exam on data-acquisition in about a week from now and the professor's slides are just garbage. I can't seem to wrap my head around the basic concepts of data management, and every time I try to search it online I get just more terms i've never heard of. There is no textbook available and his lessons aren't recorded so I cannot watch them again. This is kind of reallly my last resort (as you will have probably guessed by now:'))   \nFor those who want to help, thanks in advance!", "author_fullname": "t2_369qm6d1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Searching for someone who can explain to me in plain english what the difference is between MRAA, SMBus2 and UPM.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bwl2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673723457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, as the title says. I have an exam on data-acquisition in about a week from now and the professor&amp;#39;s slides are just garbage. I can&amp;#39;t seem to wrap my head around the basic concepts of data management, and every time I try to search it online I get just more terms i&amp;#39;ve never heard of. There is no textbook available and his lessons aren&amp;#39;t recorded so I cannot watch them again. This is kind of reallly my last resort (as you will have probably guessed by now:&amp;#39;))&lt;br/&gt;\nFor those who want to help, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10bwl2f", "is_robot_indexable": true, "report_reasons": null, "author": "no-meme-lord69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bwl2f/searching_for_someone_who_can_explain_to_me_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bwl2f/searching_for_someone_who_can_explain_to_me_in/", "subreddit_subscribers": 86287, "created_utc": 1673723457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With many questions about project ideas I began to wonder. For those who have made projects, which one are you most proud of and what does it do/how does it work?", "author_fullname": "t2_eewd4f26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bfwyl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673672267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With many questions about project ideas I began to wonder. For those who have made projects, which one are you most proud of and what does it do/how does it work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bfwyl", "is_robot_indexable": true, "report_reasons": null, "author": "Jaketastic85", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bfwyl/de_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bfwyl/de_projects/", "subreddit_subscribers": 86287, "created_utc": 1673672267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone recently appeared at Tradebyte, Germany for a data engineer position?\n\nWould like to understand what kind of task they give in the last round of interviews?", "author_fullname": "t2_b4meoomb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tradebyte, Germany data engineer interview!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bjc4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673684272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone recently appeared at Tradebyte, Germany for a data engineer position?&lt;/p&gt;\n\n&lt;p&gt;Would like to understand what kind of task they give in the last round of interviews?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10bjc4n", "is_robot_indexable": true, "report_reasons": null, "author": "Monika_Chavan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bjc4n/tradebyte_germany_data_engineer_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bjc4n/tradebyte_germany_data_engineer_interview/", "subreddit_subscribers": 86287, "created_utc": 1673684272.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}