{"kind": "Listing", "data": {"after": "t3_10edrdl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9dxlqti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job search for Data Engineering in Stockholm (2yoe)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_10e5fus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 159, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 159, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KWb-EpGGvqMXYoLxdOISXGN8R9YkzrsLCqciUiu8Br4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673938154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ifsbknzovjca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ifsbknzovjca1.png?auto=webp&amp;v=enabled&amp;s=720f7b32784f54d3bb3be371bbb1e652c1956ad0", "width": 1400, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/ifsbknzovjca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ac145d3321fa37ab01a484ecad8ead58d5e7370", "width": 108, "height": 92}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92e3a8a9c1c53bd3712a871226ed1610907bb255", "width": 216, "height": 185}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44af5b1a49dcf11f6b0fe2675eb407a42f2d936c", "width": 320, "height": 274}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91c9c67fbb4c909a9a15213cd9098a2e3c744fbc", "width": 640, "height": 548}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b577c5e292a7d360544b94e7e24cfde374222490", "width": 960, "height": 822}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ac8e1ba984d1f3276c8d53531d14ee5300dde46", "width": 1080, "height": 925}], "variants": {}, "id": "oEqP3_RncsejmRRJuZHYeUQOfr5_BmGtyTp0iByY3ig"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e5fus", "is_robot_indexable": true, "report_reasons": null, "author": "aleda145", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e5fus/job_search_for_data_engineering_in_stockholm_2yoe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ifsbknzovjca1.png", "subreddit_subscribers": 86546, "created_utc": 1673938154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For engineers who primarily work in a data warehouse environment mainly using SQL (and very little python), what are your career goals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dr0r4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673901676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dr0r4", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "subreddit_subscribers": 86546, "created_utc": 1673901676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Requesting advice on my resume, looking for an Azure DE position. Appreciate any help or advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10dzq9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": "transparent", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DZHfLU9Qc0KJQVwzHWxUfKjtPGbft-XglNYVJscYgXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673921049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sqy3r131hica1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sqy3r131hica1.png?auto=webp&amp;v=enabled&amp;s=afbd78607939952cb83bd7ab5e68b8f3ec259ab6", "width": 1190, "height": 1684}, "resolutions": [{"url": "https://preview.redd.it/sqy3r131hica1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=484f87ca7afaba5d436931099d6d9f53b487cbaf", "width": 108, "height": 152}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=961694d998c07e4f7292bef01c721093b78bf422", "width": 216, "height": 305}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b63854c94b7976ea5ee5e45267093d3cefd9f199", "width": 320, "height": 452}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b5face555d5422d514e04f3ce60db7df21e1e40", "width": 640, "height": 905}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caf26642c5fdc8ac53627cf118f120533c95b7eb", "width": 960, "height": 1358}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf6c4d075d84cb79e7ec72eaa8a8e9ba7e9edc46", "width": 1080, "height": 1528}], "variants": {}, "id": "UExNL13Iw5kNELwpC4FprwQjx7_jgRM2-S0ZMXswi90"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10dzq9y", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10dzq9y/requesting_advice_on_my_resume_looking_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sqy3r131hica1.png", "subreddit_subscribers": 86546, "created_utc": 1673921049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I am a 27F data engineer, I studied computer science at a well known engineering school, I have had great grades, I started my career as a Salesforce developer (nothing to do with data engineering) then got back to something closer to my major which is data related.\nI worker two years as a salesforce developer, and now I have been working as a data engineer for two years.\nWhen I am at work, I always feel like I lack confidence, I lack knowledge and experience compared to my peers, so I am kind of always on edge feeling like I am about to get caught and accused of \u00ab\u00a0faking\u00a0\u00bb being apt to do my job.\n\nI still feel like a junior DE even though I have worked two years in this field, I still feel like I master none of the technologies I use, how do I gain confidence? More training? Personal projects? More learning? \nShould I give up DE because of this feeling? Knowing that I never felt this in my previous Salesforce related position, it felt way too easy and that\u2019s what I didn\u2019t like about it", "author_fullname": "t2_6jles2jd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I am a fraud at work and that I am always one the verge of \u00ab getting caught \u00bb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6lb0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673942302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I am a 27F data engineer, I studied computer science at a well known engineering school, I have had great grades, I started my career as a Salesforce developer (nothing to do with data engineering) then got back to something closer to my major which is data related.\nI worker two years as a salesforce developer, and now I have been working as a data engineer for two years.\nWhen I am at work, I always feel like I lack confidence, I lack knowledge and experience compared to my peers, so I am kind of always on edge feeling like I am about to get caught and accused of \u00ab\u00a0faking\u00a0\u00bb being apt to do my job.&lt;/p&gt;\n\n&lt;p&gt;I still feel like a junior DE even though I have worked two years in this field, I still feel like I master none of the technologies I use, how do I gain confidence? More training? Personal projects? More learning? \nShould I give up DE because of this feeling? Knowing that I never felt this in my previous Salesforce related position, it felt way too easy and that\u2019s what I didn\u2019t like about it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e6lb0", "is_robot_indexable": true, "report_reasons": null, "author": "barbapapalone", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6lb0/i_feel_like_i_am_a_fraud_at_work_and_that_i_am/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6lb0/i_feel_like_i_am_a_fraud_at_work_and_that_i_am/", "subreddit_subscribers": 86546, "created_utc": 1673942302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Threw out my previous resume and came up with this one based on your advice. How can I improve it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10e35o3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xOH3zY4eiF2cWcDl_WvPLhrJsv1U8M-o-BZsIvD53Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673930802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sfdpt174ajca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sfdpt174ajca1.png?auto=webp&amp;v=enabled&amp;s=582956fc9c5d5e674dff5f31890c76990c52f13c", "width": 893, "height": 1249}, "resolutions": [{"url": "https://preview.redd.it/sfdpt174ajca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1a182b0e6992b5bc8413766328c4a6bffa97540", "width": 108, "height": 151}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f380775e7e5928fbf6f52db1a8d9d891b040db6f", "width": 216, "height": 302}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd42c6724f3d4959f4b1118ed45235ddacf50b95", "width": 320, "height": 447}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b479eeda9f72478d57f5652c11a13e0c8c4dd362", "width": 640, "height": 895}], "variants": {}, "id": "CjQTqHDjmpkc7v_82mRT1SyoSMpxJWmn8YWEao7DHWc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10e35o3", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10e35o3/threw_out_my_previous_resume_and_came_up_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sfdpt174ajca1.png", "subreddit_subscribers": 86546, "created_utc": 1673930802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negatives / criticisms of the databricks platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpzpa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dpzpa", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "subreddit_subscribers": 86546, "created_utc": 1673899757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven't used either, but am familiar with the high level concept at least. \n\nDoes anyone have any guidance on the overlap or strengths or weaknesses of one over the other?\n\nI know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I'd be interested in hearing if there was any strengths of EMR over databricks jobs.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Athena + EMR vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10duvps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673908839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven&amp;#39;t used either, but am familiar with the high level concept at least. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any guidance on the overlap or strengths or weaknesses of one over the other?&lt;/p&gt;\n\n&lt;p&gt;I know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I&amp;#39;d be interested in hearing if there was any strengths of EMR over databricks jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10duvps", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "subreddit_subscribers": 86546, "created_utc": 1673908839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  [https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link](https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link)\n\nThe only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.\n\nIs there a better way (that does not require a dedicated sql pool)?", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync Azure SQL with ADLS gen. 2 storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dv441", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673909382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  &lt;a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link\"&gt;https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way (that does not require a dedicated sql pool)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dv441", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "subreddit_subscribers": 86546, "created_utc": 1673909382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have a mission proposal for a DATA Engineer position on databricks.\n\n I spoke to the manager in fact it would mostly be about DBT and not pyspark.\n \nI have seen here particularly bad returns on full DBT positions. \n\n I was wondering what were the disadvantages of such a position? \nknowing that I am currently on a mission where I am doing full pyspark.", "author_fullname": "t2_8nkhucjj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT SQL heavy position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6izh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673942051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have a mission proposal for a DATA Engineer position on databricks.&lt;/p&gt;\n\n&lt;p&gt;I spoke to the manager in fact it would mostly be about DBT and not pyspark.&lt;/p&gt;\n\n&lt;p&gt;I have seen here particularly bad returns on full DBT positions. &lt;/p&gt;\n\n&lt;p&gt;I was wondering what were the disadvantages of such a position? \nknowing that I am currently on a mission where I am doing full pyspark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e6izh", "is_robot_indexable": true, "report_reasons": null, "author": "MLBets", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6izh/dbt_sql_heavy_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6izh/dbt_sql_heavy_position/", "subreddit_subscribers": 86546, "created_utc": 1673942051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all!\n\nFor context, I've been working as a DA for years now and recently landed a job at a series A startup as a DE. I'm fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I'll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.\n\nThey hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I'm more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I'd likely take that approach. I was thinking of building out a stack like: MySQL -&gt; Fivetran -&gt; GBQ/Snowflake -&gt; DBT/Airflow -&gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.\n\nI understand this might be too vague to give a complete response to, but I'd love to hear some thoughts on this situation from more experienced folks.\n\nThanks!\n\n&amp;#x200B;\n\nFOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I'd be way over paid though\n\nI forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Engineering Job Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dxyrs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673922921.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673916361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all!&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;ve been working as a DA for years now and recently landed a job at a series A startup as a DE. I&amp;#39;m fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I&amp;#39;ll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.&lt;/p&gt;\n\n&lt;p&gt;They hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I&amp;#39;m more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I&amp;#39;d likely take that approach. I was thinking of building out a stack like: MySQL -&amp;gt; Fivetran -&amp;gt; GBQ/Snowflake -&amp;gt; DBT/Airflow -&amp;gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.&lt;/p&gt;\n\n&lt;p&gt;I understand this might be too vague to give a complete response to, but I&amp;#39;d love to hear some thoughts on this situation from more experienced folks.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;FOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I&amp;#39;d be way over paid though&lt;/p&gt;\n\n&lt;p&gt;I forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dxyrs", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "subreddit_subscribers": 86546, "created_utc": 1673916361.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends,\n\nI have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.\n\nI'm curious what the life of the other part of the world is. I'm sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)", "author_fullname": "t2_clsgf4j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a distinct difference between OLAP DE and OLTP DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e0rix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673923903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends,&lt;/p&gt;\n\n&lt;p&gt;I have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what the life of the other part of the world is. I&amp;#39;m sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e0rix", "is_robot_indexable": true, "report_reasons": null, "author": "redditthrowaway0315", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "subreddit_subscribers": 86546, "created_utc": 1673923903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Suppose I'm trying to create a data lake, and I need to ingest data from an external source into this lake. I have a task that runs daily to extract this external data into the data lake. I can think of five different solutions:\n\n1. Ignore state, download everything from the external source every time, overwrite duplicate data in data lake\n2. Ignore state, download everything from the external source every time, create copies of duplicate data in data lake, only expose most recent files in gold lake\n3. Use state of external source (timestamps where available) to only download files created since last run\n4. Use state of both external source and data lake (file name, or some combo of file name/timestamp/etc.) to only download files not present in data lake\n5. Same as #4, but keep the data lake state in some external location, like a SQL database\n\nI've been doing #4 for almost everything so far, but I'm curious if others are using different logic. The only negative I can see with #4 currently is that you're basically doing a giant diff on all external/internal data, so time-wise, it would scale with both.", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to avoid ingesting duplicate external datasets into data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10doamm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673895860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose I&amp;#39;m trying to create a data lake, and I need to ingest data from an external source into this lake. I have a task that runs daily to extract this external data into the data lake. I can think of five different solutions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ignore state, download everything from the external source every time, overwrite duplicate data in data lake&lt;/li&gt;\n&lt;li&gt;Ignore state, download everything from the external source every time, create copies of duplicate data in data lake, only expose most recent files in gold lake&lt;/li&gt;\n&lt;li&gt;Use state of external source (timestamps where available) to only download files created since last run&lt;/li&gt;\n&lt;li&gt;Use state of both external source and data lake (file name, or some combo of file name/timestamp/etc.) to only download files not present in data lake&lt;/li&gt;\n&lt;li&gt;Same as #4, but keep the data lake state in some external location, like a SQL database&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve been doing #4 for almost everything so far, but I&amp;#39;m curious if others are using different logic. The only negative I can see with #4 currently is that you&amp;#39;re basically doing a giant diff on all external/internal data, so time-wise, it would scale with both.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10doamm", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10doamm/whats_the_best_way_to_avoid_ingesting_duplicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10doamm/whats_the_best_way_to_avoid_ingesting_duplicate/", "subreddit_subscribers": 86546, "created_utc": 1673895860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an external websocket APIs, some of them produce \\~1k events / second. My goal is to save them in database and don't lose any of the events. Currently I have only 1 listener for each API, that pushes the events to redis queue (with disk persistence ) and then I have 1 worker for each q to write to Postgres.\n\n&amp;#x200B;\n\nIt works fine, but when restarting the listener (pulling new commit or simple power outage problem) - I lose some events during this time. So I was thinking to run at least 2 separate nodes with listener for each API. That way I can restart them one by one and dont lose any events. But that means that redis q will have almost all events duplicated. What if I will run 4 listeners instead of 2? Writing this q to db with cause a lot of vacuum. Probably I can just leave the job of deduplicaiton to a worker, that remove all dups from batch he receive, before writing to db.\n\n&amp;#x200B;\n\nWhat is the way to handle that? As far as I understood Kafka and pulsar does only have message ID deduplication. And you can't set custom ids based on your content", "author_fullname": "t2_3ppayh15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Queue with content deduplication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ei41t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673978808.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673976948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an external websocket APIs, some of them produce ~1k events / second. My goal is to save them in database and don&amp;#39;t lose any of the events. Currently I have only 1 listener for each API, that pushes the events to redis queue (with disk persistence ) and then I have 1 worker for each q to write to Postgres.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It works fine, but when restarting the listener (pulling new commit or simple power outage problem) - I lose some events during this time. So I was thinking to run at least 2 separate nodes with listener for each API. That way I can restart them one by one and dont lose any events. But that means that redis q will have almost all events duplicated. What if I will run 4 listeners instead of 2? Writing this q to db with cause a lot of vacuum. Probably I can just leave the job of deduplicaiton to a worker, that remove all dups from batch he receive, before writing to db.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is the way to handle that? As far as I understood Kafka and pulsar does only have message ID deduplication. And you can&amp;#39;t set custom ids based on your content&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ei41t", "is_robot_indexable": true, "report_reasons": null, "author": "dotaleaker", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ei41t/queue_with_content_deduplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ei41t/queue_with_content_deduplication/", "subreddit_subscribers": 86546, "created_utc": 1673976948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/10eceg8)", "author_fullname": "t2_14i1sz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a Bachelors, Masters, or PhD in computer science or another STEM discipline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eceg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673962480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10eceg8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10eceg8", "is_robot_indexable": true, "report_reasons": null, "author": "pescennius", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674221680279, "options": [{"text": "Yes", "id": "21069065"}, {"text": "No, but bootcamp or other certification", "id": "21069066"}, {"text": "No", "id": "21069067"}, {"text": "See Results", "id": "21069068"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 97, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eceg8/do_you_have_a_bachelors_masters_or_phd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10eceg8/do_you_have_a_bachelors_masters_or_phd_in/", "subreddit_subscribers": 86546, "created_utc": 1673962480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a customer dimension, and a new subject area is being integrated into DWH, with its own customer base. Like good data engineers we are, we follow best industry practices and start conforming new customer data into existing customer dimension. Since we're conforming different systems we can't match customers by id, so we decide to match them by next best thing, which is customer\\_name. Some customer\\_names in two systems are obviously the same customers in real world but have slighthly different names in our systems, for example \"Acme\" in our existing dimension and  \"Acme Inc.\" in new subject area. The way to reconcile the values during development is to manually review such cases and rename them in order to match them.\n\nHere are my questions to you guys:\n\n* Inevitably, such cases will keep occuring after development is done, with production data pipeline happily loading the DWH without any manual intervention. How on earth to reconcile such similar values automatically?\n* Can this even be automated? Or there MUST be a a person who will manually check such rows?\n* I've tried Fuzzy Lookup and it works OK for reducing the amount of manual work, but still there are rows that algorith didn't pick up but should've, so again there's a need for manual intervention, and it doesn't solve the fundamental problem\n* What happens where there are hundreds or thousands or rows to compare?\n\nThanks guys!", "author_fullname": "t2_vkq0hftr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conformed Dimensions problem that keeps recurring on every project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eac4a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673956085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a customer dimension, and a new subject area is being integrated into DWH, with its own customer base. Like good data engineers we are, we follow best industry practices and start conforming new customer data into existing customer dimension. Since we&amp;#39;re conforming different systems we can&amp;#39;t match customers by id, so we decide to match them by next best thing, which is customer_name. Some customer_names in two systems are obviously the same customers in real world but have slighthly different names in our systems, for example &amp;quot;Acme&amp;quot; in our existing dimension and  &amp;quot;Acme Inc.&amp;quot; in new subject area. The way to reconcile the values during development is to manually review such cases and rename them in order to match them.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions to you guys:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inevitably, such cases will keep occuring after development is done, with production data pipeline happily loading the DWH without any manual intervention. How on earth to reconcile such similar values automatically?&lt;/li&gt;\n&lt;li&gt;Can this even be automated? Or there MUST be a a person who will manually check such rows?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve tried Fuzzy Lookup and it works OK for reducing the amount of manual work, but still there are rows that algorith didn&amp;#39;t pick up but should&amp;#39;ve, so again there&amp;#39;s a need for manual intervention, and it doesn&amp;#39;t solve the fundamental problem&lt;/li&gt;\n&lt;li&gt;What happens where there are hundreds or thousands or rows to compare?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks guys!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10eac4a", "is_robot_indexable": true, "report_reasons": null, "author": "moj_nick", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eac4a/conformed_dimensions_problem_that_keeps_recurring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10eac4a/conformed_dimensions_problem_that_keeps_recurring/", "subreddit_subscribers": 86546, "created_utc": 1673956085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As part of an automation project at work, I need to carry out webscrapping on my data bricks notebook.\n\nUnfortunately I need to utilize Selenium for this task.\nI am getting an error while initializing the driver, any suggestions on how to solve this?", "author_fullname": "t2_1rwrd73n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Selenium on Databricks notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6f64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673941657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As part of an automation project at work, I need to carry out webscrapping on my data bricks notebook.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately I need to utilize Selenium for this task.\nI am getting an error while initializing the driver, any suggestions on how to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e6f64", "is_robot_indexable": true, "report_reasons": null, "author": "RedBlackBluer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6f64/using_selenium_on_databricks_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6f64/using_selenium_on_databricks_notebooks/", "subreddit_subscribers": 86546, "created_utc": 1673941657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "General availability of Azure OpenAI Service expands access to large, advanced AI models with added enterprise benefits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10e4kcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nnN7zGm94DELpT9Gieni903R6cunGxESsEGJ7DAgAg0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673935202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "azure.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?auto=webp&amp;v=enabled&amp;s=12e5c4658509b5caafda3d7cadf58478a503fd92", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee4c871aab3a3a21a0445f14d3494d638acedec4", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1ef4debacdd87a67a586964e9ce3758de5127c2", "width": 216, "height": 216}], "variants": {}, "id": "Ln1lNDqLGYB-op_KKWkMJ3CIwoutiembrNZnyFULkZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10e4kcj", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e4kcj/general_availability_of_azure_openai_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "subreddit_subscribers": 86546, "created_utc": 1673935202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Didn't see anything on this topic in the wiki so I'm making a post. I'm trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.\n\nI have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I've overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn't a complete knowledge right now.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good tutorials teaching spark structured streaming within the databricks &amp; Azure ecosystem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e14wa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673924944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Didn&amp;#39;t see anything on this topic in the wiki so I&amp;#39;m making a post. I&amp;#39;m trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.&lt;/p&gt;\n\n&lt;p&gt;I have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I&amp;#39;ve overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn&amp;#39;t a complete knowledge right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e14wa", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "subreddit_subscribers": 86546, "created_utc": 1673924944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?\n\n&amp;#x200B;\n\n1. Local Financial Bank\n\n\\- they are migrating from on-prem to cloud\n\n\\- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.\n\n&amp;#x200B;\n\n2. Consulting company (One of the Big 4)\n\n\\- project-based so tech stack will vary a lot\n\n\\- company name looks good in resume", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me decide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpz36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Local Financial Bank&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- they are migrating from on-prem to cloud&lt;/p&gt;\n\n&lt;p&gt;- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Consulting company (One of the Big 4)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- project-based so tech stack will vary a lot&lt;/p&gt;\n\n&lt;p&gt;- company name looks good in resume&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dpz36", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpz36/help_me_decide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpz36/help_me_decide/", "subreddit_subscribers": 86546, "created_utc": 1673899717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've mostly been web dev in my career and only recently joined a team that is data eng. In web dev Blue Green deployments are super easy, since you just can route requests between blue and green at DNS or load balancer.   \n\n\nHowever most of the data pipeline stuff I've seen in my team is something like:   \n1. Poll or listen for new data  \n2. Do stuff  \n3. Write new data somewhere else  \n\n\nBlue/Green doesn't work here as much because the instances themselves are reading and writing continuously. So there is no external control mechanism like DNS, so you need internal controls which could work but may be brittle.  \n\n\nWhat patterns have you found successful for bringing up and swapping new versions of running pipeline services?  \n\n\nExtra context: Everything is pretty homegrown, ec2 style deployments.", "author_fullname": "t2_gn2ff6o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Green Blue Style deployments for continuous data pipeline services?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10egxfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673974134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve mostly been web dev in my career and only recently joined a team that is data eng. In web dev Blue Green deployments are super easy, since you just can route requests between blue and green at DNS or load balancer.   &lt;/p&gt;\n\n&lt;p&gt;However most of the data pipeline stuff I&amp;#39;ve seen in my team is something like:&lt;br/&gt;\n1. Poll or listen for new data&lt;br/&gt;\n2. Do stuff&lt;br/&gt;\n3. Write new data somewhere else  &lt;/p&gt;\n\n&lt;p&gt;Blue/Green doesn&amp;#39;t work here as much because the instances themselves are reading and writing continuously. So there is no external control mechanism like DNS, so you need internal controls which could work but may be brittle.  &lt;/p&gt;\n\n&lt;p&gt;What patterns have you found successful for bringing up and swapping new versions of running pipeline services?  &lt;/p&gt;\n\n&lt;p&gt;Extra context: Everything is pretty homegrown, ec2 style deployments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10egxfp", "is_robot_indexable": true, "report_reasons": null, "author": "fthb1000000", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10egxfp/green_blue_style_deployments_for_continuous_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10egxfp/green_blue_style_deployments_for_continuous_data/", "subreddit_subscribers": 86546, "created_utc": 1673974134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uo96pc9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume advice needed. Applying for Data Engineering roles. I have mentioned a couple of projects in my portfolio (70milan.github.io) to avoid mentioning it on my resume yet cant get all the information on a single page. Reduced font size to 10.5-11 pts, more suggestions appreciated.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10egk6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T0N6_lfidPVS48rX80qr0wpSGrW4PYmlfvvNLg3do8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673973224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g1mevnbu9oca1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g1mevnbu9oca1.png?auto=webp&amp;v=enabled&amp;s=3e596692bec3a08e2b341393ad293a9b84a6697f", "width": 1080, "height": 2109}, "resolutions": [{"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02625a9372ce393e8c2cb92b5bfce88411f77097", "width": 108, "height": 210}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2f181323f1414795b240f10e18f6dbdd862aa9a", "width": 216, "height": 421}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73c23182414f17420323af47065bbb41310d4201", "width": 320, "height": 624}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67a7cfe8d623389adfd606b527435833afc71144", "width": 640, "height": 1249}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f157e0da899ce434d2440d624158ed36fa832b9c", "width": 960, "height": 1874}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91110b26c772afb5c571e34f0c302097547b4c5d", "width": 1080, "height": 2109}], "variants": {}, "id": "zGs4iRzbDByVHiSEeV-DzXrD3k8sLiwSYbRqDk5n1vQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10egk6a", "is_robot_indexable": true, "report_reasons": null, "author": "purplexed247", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10egk6a/resume_advice_needed_applying_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/g1mevnbu9oca1.png", "subreddit_subscribers": 86546, "created_utc": 1673973224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_7m65ddby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello!Long time lurker here.I have been in the same team for the past 4 years. First as a third party client and then got onboarded directly.Please critique my resume and give advice as it's been awhile since I stepped into jobsearch market.I'm also looking for anyone interested in mentoring me.Thnx", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10efcva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AKgDXYNTpD1Jg8ZmtGbifv1jIXPWUUAPCoBA64qzJ2w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673970249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/403zvyhgimca1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/403zvyhgimca1.jpg?auto=webp&amp;v=enabled&amp;s=4b56fb6ced56a6c01b3b919c1fbbf7d4f945fdcc", "width": 1275, "height": 1650}, "resolutions": [{"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5041a3d29851faa868eeba65b30162d2a6ee8964", "width": 108, "height": 139}, {"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a44f194c6138a5402574c1eaecd18cf60e3caf58", "width": 216, "height": 279}, {"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f9a74f887a00689a8d2708580b065eb2e0c191f", "width": 320, "height": 414}, {"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb2134164d4b4158e52346f9f05167c5f37b3f14", "width": 640, "height": 828}, {"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6914230bcddacce5369210865337df2d8a7e1678", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/403zvyhgimca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c0785a7f2f3cafefa4b43cba32d99a0ccbb76fd", "width": 1080, "height": 1397}], "variants": {}, "id": "OaA2Q8gdn0nTL1p4-wL_cBJ9nte5JA8_XasuNcdkQ4Y"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10efcva", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Ball_965", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10efcva/hellolong_time_lurker_herei_have_been_in_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/403zvyhgimca1.jpg", "subreddit_subscribers": 86546, "created_utc": 1673970249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I worked in ETL for a hospital for 3 years and left the job to become a Data Engineer and work in snowflake. However within 2 weeks of me getting to the new company they had massive layoffs and after a bit longer than that i was told my new position will not be retained. \n\nI have tons of experience with SQL and have worked in datastacks with Microsoft, IBM, Oracle, and Snowflake including datastage and SSIS. \n\n\nI was looking to broaden my horizons at my new position and go from being purely ETL to more of a catch all data guy and found a great fit for it until they had their layoffs.\n\nNow it seems like every position im applying for wants AWS or Azure experience which i just dont have. Does anyone have any recommendations for courses or certifications for me? Or just any general career advice? I am at a bit of a crossroads and have never done any sort of online certifications", "author_fullname": "t2_6ra3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best certifications for my current career trajectory.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10efafg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673970072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I worked in ETL for a hospital for 3 years and left the job to become a Data Engineer and work in snowflake. However within 2 weeks of me getting to the new company they had massive layoffs and after a bit longer than that i was told my new position will not be retained. &lt;/p&gt;\n\n&lt;p&gt;I have tons of experience with SQL and have worked in datastacks with Microsoft, IBM, Oracle, and Snowflake including datastage and SSIS. &lt;/p&gt;\n\n&lt;p&gt;I was looking to broaden my horizons at my new position and go from being purely ETL to more of a catch all data guy and found a great fit for it until they had their layoffs.&lt;/p&gt;\n\n&lt;p&gt;Now it seems like every position im applying for wants AWS or Azure experience which i just dont have. Does anyone have any recommendations for courses or certifications for me? Or just any general career advice? I am at a bit of a crossroads and have never done any sort of online certifications&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10efafg", "is_robot_indexable": true, "report_reasons": null, "author": "deemerritt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10efafg/best_certifications_for_my_current_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10efafg/best_certifications_for_my_current_career/", "subreddit_subscribers": 86546, "created_utc": 1673970072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just asking this question conceptually as I don't have experience in this area yet, trying to do my research but i dont fully understand how this works yet.\n\nI'm imagining you have something like Debezium + Kafka stream doing CDC from some rdbms. When this arrives in your dwh im guessing you get a sequence of some kind of SQL DML statements (UPDATE, INSERT etc), or the equivalent in another format? Do you then have to parse and execute these line-by-line to reconstruct the current state in a raw dwh table? How does it work?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you reconstruct current state in DWh from a stream of CDC events?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ef640", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673969748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just asking this question conceptually as I don&amp;#39;t have experience in this area yet, trying to do my research but i dont fully understand how this works yet.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m imagining you have something like Debezium + Kafka stream doing CDC from some rdbms. When this arrives in your dwh im guessing you get a sequence of some kind of SQL DML statements (UPDATE, INSERT etc), or the equivalent in another format? Do you then have to parse and execute these line-by-line to reconstruct the current state in a raw dwh table? How does it work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ef640", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ef640/how_do_you_reconstruct_current_state_in_dwh_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ef640/how_do_you_reconstruct_current_state_in_dwh_from/", "subreddit_subscribers": 86546, "created_utc": 1673969748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 evaluation criteria for Data Orchestrators", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10edrdl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1673966147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/posts/marclamberti_dataengineering-dataengineer-data-activity-7021114084053917696-3CAF?utm_source=share&amp;utm_medium=member_desktop", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10edrdl", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10edrdl/10_evaluation_criteria_for_data_orchestrators/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/posts/marclamberti_dataengineering-dataengineer-data-activity-7021114084053917696-3CAF?utm_source=share&amp;utm_medium=member_desktop", "subreddit_subscribers": 86546, "created_utc": 1673966147.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}