{"kind": "Listing", "data": {"after": "t3_10egk6a", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9dxlqti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job search for Data Engineering in Stockholm (2yoe)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_10e5fus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 191, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 191, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KWb-EpGGvqMXYoLxdOISXGN8R9YkzrsLCqciUiu8Br4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673938154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ifsbknzovjca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ifsbknzovjca1.png?auto=webp&amp;v=enabled&amp;s=720f7b32784f54d3bb3be371bbb1e652c1956ad0", "width": 1400, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/ifsbknzovjca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ac145d3321fa37ab01a484ecad8ead58d5e7370", "width": 108, "height": 92}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92e3a8a9c1c53bd3712a871226ed1610907bb255", "width": 216, "height": 185}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44af5b1a49dcf11f6b0fe2675eb407a42f2d936c", "width": 320, "height": 274}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91c9c67fbb4c909a9a15213cd9098a2e3c744fbc", "width": 640, "height": 548}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b577c5e292a7d360544b94e7e24cfde374222490", "width": 960, "height": 822}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ac8e1ba984d1f3276c8d53531d14ee5300dde46", "width": 1080, "height": 925}], "variants": {}, "id": "oEqP3_RncsejmRRJuZHYeUQOfr5_BmGtyTp0iByY3ig"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e5fus", "is_robot_indexable": true, "report_reasons": null, "author": "aleda145", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e5fus/job_search_for_data_engineering_in_stockholm_2yoe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ifsbknzovjca1.png", "subreddit_subscribers": 86558, "created_utc": 1673938154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For engineers who primarily work in a data warehouse environment mainly using SQL (and very little python), what are your career goals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dr0r4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673901676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dr0r4", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 81, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "subreddit_subscribers": 86558, "created_utc": 1673901676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Requesting advice on my resume, looking for an Azure DE position. Appreciate any help or advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10dzq9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DZHfLU9Qc0KJQVwzHWxUfKjtPGbft-XglNYVJscYgXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673921049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sqy3r131hica1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sqy3r131hica1.png?auto=webp&amp;v=enabled&amp;s=afbd78607939952cb83bd7ab5e68b8f3ec259ab6", "width": 1190, "height": 1684}, "resolutions": [{"url": "https://preview.redd.it/sqy3r131hica1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=484f87ca7afaba5d436931099d6d9f53b487cbaf", "width": 108, "height": 152}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=961694d998c07e4f7292bef01c721093b78bf422", "width": 216, "height": 305}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b63854c94b7976ea5ee5e45267093d3cefd9f199", "width": 320, "height": 452}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b5face555d5422d514e04f3ce60db7df21e1e40", "width": 640, "height": 905}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caf26642c5fdc8ac53627cf118f120533c95b7eb", "width": 960, "height": 1358}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf6c4d075d84cb79e7ec72eaa8a8e9ba7e9edc46", "width": 1080, "height": 1528}], "variants": {}, "id": "UExNL13Iw5kNELwpC4FprwQjx7_jgRM2-S0ZMXswi90"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10dzq9y", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10dzq9y/requesting_advice_on_my_resume_looking_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sqy3r131hica1.png", "subreddit_subscribers": 86558, "created_utc": 1673921049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I am a 27F data engineer, I studied computer science at a well known engineering school, I have had great grades, I started my career as a Salesforce developer (nothing to do with data engineering) then got back to something closer to my major which is data related.\nI worker two years as a salesforce developer, and now I have been working as a data engineer for two years.\nWhen I am at work, I always feel like I lack confidence, I lack knowledge and experience compared to my peers, so I am kind of always on edge feeling like I am about to get caught and accused of \u00ab\u00a0faking\u00a0\u00bb being apt to do my job.\n\nI still feel like a junior DE even though I have worked two years in this field, I still feel like I master none of the technologies I use, how do I gain confidence? More training? Personal projects? More learning? \nShould I give up DE because of this feeling? Knowing that I never felt this in my previous Salesforce related position, it felt way too easy and that\u2019s what I didn\u2019t like about it", "author_fullname": "t2_6jles2jd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I am a fraud at work and that I am always one the verge of \u00ab getting caught \u00bb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6lb0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673942302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I am a 27F data engineer, I studied computer science at a well known engineering school, I have had great grades, I started my career as a Salesforce developer (nothing to do with data engineering) then got back to something closer to my major which is data related.\nI worker two years as a salesforce developer, and now I have been working as a data engineer for two years.\nWhen I am at work, I always feel like I lack confidence, I lack knowledge and experience compared to my peers, so I am kind of always on edge feeling like I am about to get caught and accused of \u00ab\u00a0faking\u00a0\u00bb being apt to do my job.&lt;/p&gt;\n\n&lt;p&gt;I still feel like a junior DE even though I have worked two years in this field, I still feel like I master none of the technologies I use, how do I gain confidence? More training? Personal projects? More learning? \nShould I give up DE because of this feeling? Knowing that I never felt this in my previous Salesforce related position, it felt way too easy and that\u2019s what I didn\u2019t like about it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e6lb0", "is_robot_indexable": true, "report_reasons": null, "author": "barbapapalone", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6lb0/i_feel_like_i_am_a_fraud_at_work_and_that_i_am/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6lb0/i_feel_like_i_am_a_fraud_at_work_and_that_i_am/", "subreddit_subscribers": 86558, "created_utc": 1673942302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Threw out my previous resume and came up with this one based on your advice. How can I improve it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10e35o3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xOH3zY4eiF2cWcDl_WvPLhrJsv1U8M-o-BZsIvD53Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673930802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sfdpt174ajca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sfdpt174ajca1.png?auto=webp&amp;v=enabled&amp;s=582956fc9c5d5e674dff5f31890c76990c52f13c", "width": 893, "height": 1249}, "resolutions": [{"url": "https://preview.redd.it/sfdpt174ajca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1a182b0e6992b5bc8413766328c4a6bffa97540", "width": 108, "height": 151}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f380775e7e5928fbf6f52db1a8d9d891b040db6f", "width": 216, "height": 302}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd42c6724f3d4959f4b1118ed45235ddacf50b95", "width": 320, "height": 447}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b479eeda9f72478d57f5652c11a13e0c8c4dd362", "width": 640, "height": 895}], "variants": {}, "id": "CjQTqHDjmpkc7v_82mRT1SyoSMpxJWmn8YWEao7DHWc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10e35o3", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10e35o3/threw_out_my_previous_resume_and_came_up_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sfdpt174ajca1.png", "subreddit_subscribers": 86558, "created_utc": 1673930802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negatives / criticisms of the databricks platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpzpa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dpzpa", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "subreddit_subscribers": 86558, "created_utc": 1673899757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven't used either, but am familiar with the high level concept at least. \n\nDoes anyone have any guidance on the overlap or strengths or weaknesses of one over the other?\n\nI know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I'd be interested in hearing if there was any strengths of EMR over databricks jobs.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Athena + EMR vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10duvps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673908839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven&amp;#39;t used either, but am familiar with the high level concept at least. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any guidance on the overlap or strengths or weaknesses of one over the other?&lt;/p&gt;\n\n&lt;p&gt;I know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I&amp;#39;d be interested in hearing if there was any strengths of EMR over databricks jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10duvps", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "subreddit_subscribers": 86558, "created_utc": 1673908839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  [https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link](https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link)\n\nThe only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.\n\nIs there a better way (that does not require a dedicated sql pool)?", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync Azure SQL with ADLS gen. 2 storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dv441", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673909382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  &lt;a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link\"&gt;https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way (that does not require a dedicated sql pool)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dv441", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "subreddit_subscribers": 86558, "created_utc": 1673909382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have a mission proposal for a DATA Engineer position on databricks.\n\n I spoke to the manager in fact it would mostly be about DBT and not pyspark.\n \nI have seen here particularly bad returns on full DBT positions. \n\n I was wondering what were the disadvantages of such a position? \nknowing that I am currently on a mission where I am doing full pyspark.", "author_fullname": "t2_8nkhucjj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT SQL heavy position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6izh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673942051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have a mission proposal for a DATA Engineer position on databricks.&lt;/p&gt;\n\n&lt;p&gt;I spoke to the manager in fact it would mostly be about DBT and not pyspark.&lt;/p&gt;\n\n&lt;p&gt;I have seen here particularly bad returns on full DBT positions. &lt;/p&gt;\n\n&lt;p&gt;I was wondering what were the disadvantages of such a position? \nknowing that I am currently on a mission where I am doing full pyspark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e6izh", "is_robot_indexable": true, "report_reasons": null, "author": "MLBets", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6izh/dbt_sql_heavy_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6izh/dbt_sql_heavy_position/", "subreddit_subscribers": 86558, "created_utc": 1673942051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all!\n\nFor context, I've been working as a DA for years now and recently landed a job at a series A startup as a DE. I'm fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I'll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.\n\nThey hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I'm more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I'd likely take that approach. I was thinking of building out a stack like: MySQL -&gt; Fivetran -&gt; GBQ/Snowflake -&gt; DBT/Airflow -&gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.\n\nI understand this might be too vague to give a complete response to, but I'd love to hear some thoughts on this situation from more experienced folks.\n\nThanks!\n\n&amp;#x200B;\n\nFOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I'd be way over paid though\n\nI forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Engineering Job Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dxyrs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673922921.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673916361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all!&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;ve been working as a DA for years now and recently landed a job at a series A startup as a DE. I&amp;#39;m fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I&amp;#39;ll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.&lt;/p&gt;\n\n&lt;p&gt;They hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I&amp;#39;m more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I&amp;#39;d likely take that approach. I was thinking of building out a stack like: MySQL -&amp;gt; Fivetran -&amp;gt; GBQ/Snowflake -&amp;gt; DBT/Airflow -&amp;gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.&lt;/p&gt;\n\n&lt;p&gt;I understand this might be too vague to give a complete response to, but I&amp;#39;d love to hear some thoughts on this situation from more experienced folks.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;FOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I&amp;#39;d be way over paid though&lt;/p&gt;\n\n&lt;p&gt;I forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dxyrs", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "subreddit_subscribers": 86558, "created_utc": 1673916361.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends,\n\nI have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.\n\nI'm curious what the life of the other part of the world is. I'm sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)", "author_fullname": "t2_clsgf4j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a distinct difference between OLAP DE and OLTP DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e0rix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673923903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends,&lt;/p&gt;\n\n&lt;p&gt;I have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what the life of the other part of the world is. I&amp;#39;m sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e0rix", "is_robot_indexable": true, "report_reasons": null, "author": "redditthrowaway0315", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "subreddit_subscribers": 86558, "created_utc": 1673923903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m planning on moving next spring. Number one choice right now is Southern California but open to pretty much anywhere. I\u2019m currently a Business Analyst (~1 year, 2.5 years as IT HelpDesk before) doing some light work in SQL, Python and bash. \n\nI\u2019ve built a couple projects with GCP (BigQuery, Compute Engine, Cloud Storage, Cloud Run), GitHub Actions, Docker, SQL, Python, Go (built my own API). \n\nI\u2019m in a small city and there are zero jobs so I have to move (plus, I want to leave anyway). \n\nWhat would your suggestion be?\n\nEdit: Looking in the US only. Forgot that other countries exist.", "author_fullname": "t2_a4wvyz1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best cities for a job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10elso5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1673985880.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673985590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m planning on moving next spring. Number one choice right now is Southern California but open to pretty much anywhere. I\u2019m currently a Business Analyst (~1 year, 2.5 years as IT HelpDesk before) doing some light work in SQL, Python and bash. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve built a couple projects with GCP (BigQuery, Compute Engine, Cloud Storage, Cloud Run), GitHub Actions, Docker, SQL, Python, Go (built my own API). &lt;/p&gt;\n\n&lt;p&gt;I\u2019m in a small city and there are zero jobs so I have to move (plus, I want to leave anyway). &lt;/p&gt;\n\n&lt;p&gt;What would your suggestion be?&lt;/p&gt;\n\n&lt;p&gt;Edit: Looking in the US only. Forgot that other countries exist.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10elso5", "is_robot_indexable": true, "report_reasons": null, "author": "HeavyFuckingMetalx", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10elso5/best_cities_for_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10elso5/best_cities_for_a_job/", "subreddit_subscribers": 86558, "created_utc": 1673985590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an external websocket APIs, some of them produce \\~1k events / second. My goal is to save them in database and don't lose any of the events. Currently I have only 1 listener for each API, that pushes the events to redis queue (with disk persistence ) and then I have 1 worker for each q to write to Postgres.\n\n&amp;#x200B;\n\nIt works fine, but when restarting the listener (pulling new commit or simple power outage problem) - I lose some events during this time. So I was thinking to run at least 2 separate nodes with listener for each API. That way I can restart them one by one and dont lose any events. But that means that redis q will have almost all events duplicated. What if I will run 4 listeners instead of 2? Writing this q to db with cause a lot of vacuum. Probably I can just leave the job of deduplicaiton to a worker, that remove all dups from batch he receive, before writing to db.\n\n&amp;#x200B;\n\nWhat is the way to handle that? As far as I understood Kafka and pulsar does only have message ID deduplication. And you can't set custom ids based on your content", "author_fullname": "t2_3ppayh15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Queue with content deduplication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ei41t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673978808.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673976948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an external websocket APIs, some of them produce ~1k events / second. My goal is to save them in database and don&amp;#39;t lose any of the events. Currently I have only 1 listener for each API, that pushes the events to redis queue (with disk persistence ) and then I have 1 worker for each q to write to Postgres.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It works fine, but when restarting the listener (pulling new commit or simple power outage problem) - I lose some events during this time. So I was thinking to run at least 2 separate nodes with listener for each API. That way I can restart them one by one and dont lose any events. But that means that redis q will have almost all events duplicated. What if I will run 4 listeners instead of 2? Writing this q to db with cause a lot of vacuum. Probably I can just leave the job of deduplicaiton to a worker, that remove all dups from batch he receive, before writing to db.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is the way to handle that? As far as I understood Kafka and pulsar does only have message ID deduplication. And you can&amp;#39;t set custom ids based on your content&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ei41t", "is_robot_indexable": true, "report_reasons": null, "author": "dotaleaker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ei41t/queue_with_content_deduplication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ei41t/queue_with_content_deduplication/", "subreddit_subscribers": 86558, "created_utc": 1673976948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/10eceg8)", "author_fullname": "t2_14i1sz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a Bachelors, Masters, or PhD in computer science or another STEM discipline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eceg8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673962480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10eceg8\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10eceg8", "is_robot_indexable": true, "report_reasons": null, "author": "pescennius", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674221680279, "options": [{"text": "Yes", "id": "21069065"}, {"text": "No, but bootcamp or other certification", "id": "21069066"}, {"text": "No", "id": "21069067"}, {"text": "See Results", "id": "21069068"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 122, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eceg8/do_you_have_a_bachelors_masters_or_phd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10eceg8/do_you_have_a_bachelors_masters_or_phd_in/", "subreddit_subscribers": 86558, "created_utc": 1673962480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a customer dimension, and a new subject area is being integrated into DWH, with its own customer base. Like good data engineers we are, we follow best industry practices and start conforming new customer data into existing customer dimension. Since we're conforming different systems we can't match customers by id, so we decide to match them by next best thing, which is customer\\_name. Some customer\\_names in two systems are obviously the same customers in real world but have slighthly different names in our systems, for example \"Acme\" in our existing dimension and  \"Acme Inc.\" in new subject area. The way to reconcile the values during development is to manually review such cases and rename them in order to match them.\n\nHere are my questions to you guys:\n\n* Inevitably, such cases will keep occuring after development is done, with production data pipeline happily loading the DWH without any manual intervention. How on earth to reconcile such similar values automatically?\n* Can this even be automated? Or there MUST be a a person who will manually check such rows?\n* I've tried Fuzzy Lookup and it works OK for reducing the amount of manual work, but still there are rows that algorith didn't pick up but should've, so again there's a need for manual intervention, and it doesn't solve the fundamental problem\n* What happens where there are hundreds or thousands or rows to compare?\n\nThanks guys!", "author_fullname": "t2_vkq0hftr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Conformed Dimensions problem that keeps recurring on every project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eac4a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673956085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a customer dimension, and a new subject area is being integrated into DWH, with its own customer base. Like good data engineers we are, we follow best industry practices and start conforming new customer data into existing customer dimension. Since we&amp;#39;re conforming different systems we can&amp;#39;t match customers by id, so we decide to match them by next best thing, which is customer_name. Some customer_names in two systems are obviously the same customers in real world but have slighthly different names in our systems, for example &amp;quot;Acme&amp;quot; in our existing dimension and  &amp;quot;Acme Inc.&amp;quot; in new subject area. The way to reconcile the values during development is to manually review such cases and rename them in order to match them.&lt;/p&gt;\n\n&lt;p&gt;Here are my questions to you guys:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inevitably, such cases will keep occuring after development is done, with production data pipeline happily loading the DWH without any manual intervention. How on earth to reconcile such similar values automatically?&lt;/li&gt;\n&lt;li&gt;Can this even be automated? Or there MUST be a a person who will manually check such rows?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve tried Fuzzy Lookup and it works OK for reducing the amount of manual work, but still there are rows that algorith didn&amp;#39;t pick up but should&amp;#39;ve, so again there&amp;#39;s a need for manual intervention, and it doesn&amp;#39;t solve the fundamental problem&lt;/li&gt;\n&lt;li&gt;What happens where there are hundreds or thousands or rows to compare?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks guys!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10eac4a", "is_robot_indexable": true, "report_reasons": null, "author": "moj_nick", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eac4a/conformed_dimensions_problem_that_keeps_recurring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10eac4a/conformed_dimensions_problem_that_keeps_recurring/", "subreddit_subscribers": 86558, "created_utc": 1673956085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As part of an automation project at work, I need to carry out webscrapping on my data bricks notebook.\n\nUnfortunately I need to utilize Selenium for this task.\nI am getting an error while initializing the driver, any suggestions on how to solve this?", "author_fullname": "t2_1rwrd73n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Selenium on Databricks notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e6f64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673941657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As part of an automation project at work, I need to carry out webscrapping on my data bricks notebook.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately I need to utilize Selenium for this task.\nI am getting an error while initializing the driver, any suggestions on how to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e6f64", "is_robot_indexable": true, "report_reasons": null, "author": "RedBlackBluer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e6f64/using_selenium_on_databricks_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e6f64/using_selenium_on_databricks_notebooks/", "subreddit_subscribers": 86558, "created_utc": 1673941657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "General availability of Azure OpenAI Service expands access to large, advanced AI models with added enterprise benefits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10e4kcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nnN7zGm94DELpT9Gieni903R6cunGxESsEGJ7DAgAg0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673935202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "azure.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?auto=webp&amp;v=enabled&amp;s=12e5c4658509b5caafda3d7cadf58478a503fd92", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee4c871aab3a3a21a0445f14d3494d638acedec4", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1ef4debacdd87a67a586964e9ce3758de5127c2", "width": 216, "height": 216}], "variants": {}, "id": "Ln1lNDqLGYB-op_KKWkMJ3CIwoutiembrNZnyFULkZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10e4kcj", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e4kcj/general_availability_of_azure_openai_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "subreddit_subscribers": 86558, "created_utc": 1673935202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Didn't see anything on this topic in the wiki so I'm making a post. I'm trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.\n\nI have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I've overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn't a complete knowledge right now.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good tutorials teaching spark structured streaming within the databricks &amp; Azure ecosystem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e14wa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673924944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Didn&amp;#39;t see anything on this topic in the wiki so I&amp;#39;m making a post. I&amp;#39;m trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.&lt;/p&gt;\n\n&lt;p&gt;I have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I&amp;#39;ve overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn&amp;#39;t a complete knowledge right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e14wa", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "subreddit_subscribers": 86558, "created_utc": 1673924944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?\n\n&amp;#x200B;\n\n1. Local Financial Bank\n\n\\- they are migrating from on-prem to cloud\n\n\\- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.\n\n&amp;#x200B;\n\n2. Consulting company (One of the Big 4)\n\n\\- project-based so tech stack will vary a lot\n\n\\- company name looks good in resume", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me decide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpz36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Local Financial Bank&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- they are migrating from on-prem to cloud&lt;/p&gt;\n\n&lt;p&gt;- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Consulting company (One of the Big 4)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- project-based so tech stack will vary a lot&lt;/p&gt;\n\n&lt;p&gt;- company name looks good in resume&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dpz36", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpz36/help_me_decide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpz36/help_me_decide/", "subreddit_subscribers": 86558, "created_utc": 1673899717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some time series data coming from different sources that have different levels of granularity/frequency\n\nSome data comes in monthly, some daily, some hourly \n\nIs it possible to store all this in one time series database? We like the querying benefits a time series db provides for time series but I wasn\u2019t sure if all the data has to be the same level of granularity", "author_fullname": "t2_7nbpziqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series databases with different granularity or multiple time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10elmce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673985168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some time series data coming from different sources that have different levels of granularity/frequency&lt;/p&gt;\n\n&lt;p&gt;Some data comes in monthly, some daily, some hourly &lt;/p&gt;\n\n&lt;p&gt;Is it possible to store all this in one time series database? We like the querying benefits a time series db provides for time series but I wasn\u2019t sure if all the data has to be the same level of granularity&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10elmce", "is_robot_indexable": true, "report_reasons": null, "author": "Affectionate_Shine55", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10elmce/time_series_databases_with_different_granularity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10elmce/time_series_databases_with_different_granularity/", "subreddit_subscribers": 86558, "created_utc": 1673985168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you document data products? I mean e.g. we use mainly Python for ETL jobs and our documentation consists of README in the git repo and sometimes (depending on the transformation complexity) also a Google Document describing the app, calculations, input and outputs etc. \n\nDo you have any better approach? I would really like to have some \u201cdocumentation framework\u201d that would have all data products described and explorable in one place. It would be nice to see products dependencies/lineage similar way you see in Airflow. I am thinking of some custom data catalog maybe, but firstly I would like to know what others do/have out there.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you document data products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ekhrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673982550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you document data products? I mean e.g. we use mainly Python for ETL jobs and our documentation consists of README in the git repo and sometimes (depending on the transformation complexity) also a Google Document describing the app, calculations, input and outputs etc. &lt;/p&gt;\n\n&lt;p&gt;Do you have any better approach? I would really like to have some \u201cdocumentation framework\u201d that would have all data products described and explorable in one place. It would be nice to see products dependencies/lineage similar way you see in Airflow. I am thinking of some custom data catalog maybe, but firstly I would like to know what others do/have out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ekhrq", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ekhrq/how_do_you_document_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ekhrq/how_do_you_document_data_products/", "subreddit_subscribers": 86558, "created_utc": 1673982550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Come join the first [Seattle Spark Meetup](https://www.meetup.com/Seattle-Spark-Meetup/events/290865855/?response=3&amp;action=rsvp&amp;utm_medium=email&amp;utm_source=braze_canvas&amp;utm_campaign=mmrk_alleng_event_announcement_prod_v7_en&amp;utm_term=promo&amp;utm_content=lp_meetup) of 2023 on Jan 31!\n\nhttps://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4", "author_fullname": "t2_5dvfu5m2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seattle Spark Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": true, "media_metadata": {"p065ppb4inca1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd9eb36775709b68eaee28f59ef7034a2892dba3"}, {"y": 130, "x": 216, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92f406cec1da38d5a0a4a69addb38148a1b27cc9"}, {"y": 192, "x": 320, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ecdb676d3374bcac03cad41c5a995896b60d556"}], "s": {"y": 369, "x": 612, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4"}, "id": "p065ppb4inca1"}}, "name": "t3_10ek8ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5XJvvvK19Bd24JizxyEjIfnJoXEDbapKMQAvQ-ji-ck.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673981977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Come join the first &lt;a href=\"https://www.meetup.com/Seattle-Spark-Meetup/events/290865855/?response=3&amp;amp;action=rsvp&amp;amp;utm_medium=email&amp;amp;utm_source=braze_canvas&amp;amp;utm_campaign=mmrk_alleng_event_announcement_prod_v7_en&amp;amp;utm_term=promo&amp;amp;utm_content=lp_meetup\"&gt;Seattle Spark Meetup&lt;/a&gt; of 2023 on Jan 31!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4\"&gt;https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10ek8ut", "is_robot_indexable": true, "report_reasons": null, "author": "bp_ryan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10ek8ut/seattle_spark_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ek8ut/seattle_spark_meetup/", "subreddit_subscribers": 86558, "created_utc": 1673981977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nTL;DR\n\nSole Data Engineer in the company is to propose a new architecture to gradually connect 30 ERP systems. There is a failed Data Vault project because it was designed as a Source System Data Vault and there are also errors in the technical implementation.\n\nThe existing technologies are Snowflake and Wherescape.\n\nThe question is whether another Data Vault project should be set up or whether the new DWH should be set up differently.\n\n&amp;#x200B;\n\nI am new in a company, the only one who has anything to do with data engineering/BI. The previous developer left, leaving behind a failed Data Vault project. I am Data Vault 2.0 certified, but have never had to implement it in practice. I say failed Data Vault project because it is 1:1 to the source system and the historisation does not work. So there is a source data vault (Anti Pattern) that does not even historise the data.\n\nThis was implemented with Wherescape as the automation tool and Snowflake as the database. No upstream data lake or anything similar.\n\n&amp;#x200B;\n\nI have been using Informatica PowerCenter and have strong SQL skills and know dimensional modelling, but I am no longer interested in no code tools like PowerCenter, Talent, SSIS etc. and would be happy to leave them behind.\n\n&amp;#x200B;\n\nThe company is based in the manufacturing sector and has a total of over 30 more or less small sites, the largest of which run their own ERP systems.\n\nThe goal is (and was) to first integrate the ERP systems of the two largest sites into one DWH and then connect other sites. The larger locations each use the same ERP system (MS Dynamics NAV on-prem) and the smaller locations, for example, MS Dynamics 365 Business Central (Cloud). The departments only need daily updated data, which is good because CDC mechanisms are not active in the ERP databases and the DB responsibles have not had anything to do with it yet.\n\nAs far as I can see, only Azure AD and VMs are used in Azure.\n\n&amp;#x200B;\n\nThe question for me now is how to proceed, as my supervisor has asked me to suggest which architecture and data model we want to use.\n\nHow would you approach the issue?\n\nI see the possibility of creating the DV model again with the help of external support and implementing it using Wherescape.\n\nAlternatively, it would be conceivable to load the data into Snowflake and build a persistent staging area (PSA) there and transform the whole thing using dbt. I would find dbt interesting because it is essentially SQL. But then it would have to be decided which tools would be used for extraction and orchestration.", "author_fullname": "t2_uyjws4s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH architecture for the integration of 30 sites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ejp50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673980681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;TL;DR&lt;/p&gt;\n\n&lt;p&gt;Sole Data Engineer in the company is to propose a new architecture to gradually connect 30 ERP systems. There is a failed Data Vault project because it was designed as a Source System Data Vault and there are also errors in the technical implementation.&lt;/p&gt;\n\n&lt;p&gt;The existing technologies are Snowflake and Wherescape.&lt;/p&gt;\n\n&lt;p&gt;The question is whether another Data Vault project should be set up or whether the new DWH should be set up differently.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am new in a company, the only one who has anything to do with data engineering/BI. The previous developer left, leaving behind a failed Data Vault project. I am Data Vault 2.0 certified, but have never had to implement it in practice. I say failed Data Vault project because it is 1:1 to the source system and the historisation does not work. So there is a source data vault (Anti Pattern) that does not even historise the data.&lt;/p&gt;\n\n&lt;p&gt;This was implemented with Wherescape as the automation tool and Snowflake as the database. No upstream data lake or anything similar.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been using Informatica PowerCenter and have strong SQL skills and know dimensional modelling, but I am no longer interested in no code tools like PowerCenter, Talent, SSIS etc. and would be happy to leave them behind.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The company is based in the manufacturing sector and has a total of over 30 more or less small sites, the largest of which run their own ERP systems.&lt;/p&gt;\n\n&lt;p&gt;The goal is (and was) to first integrate the ERP systems of the two largest sites into one DWH and then connect other sites. The larger locations each use the same ERP system (MS Dynamics NAV on-prem) and the smaller locations, for example, MS Dynamics 365 Business Central (Cloud). The departments only need daily updated data, which is good because CDC mechanisms are not active in the ERP databases and the DB responsibles have not had anything to do with it yet.&lt;/p&gt;\n\n&lt;p&gt;As far as I can see, only Azure AD and VMs are used in Azure.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The question for me now is how to proceed, as my supervisor has asked me to suggest which architecture and data model we want to use.&lt;/p&gt;\n\n&lt;p&gt;How would you approach the issue?&lt;/p&gt;\n\n&lt;p&gt;I see the possibility of creating the DV model again with the help of external support and implementing it using Wherescape.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, it would be conceivable to load the data into Snowflake and build a persistent staging area (PSA) there and transform the whole thing using dbt. I would find dbt interesting because it is essentially SQL. But then it would have to be decided which tools would be used for extraction and orchestration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ejp50", "is_robot_indexable": true, "report_reasons": null, "author": "Individual-Detail286", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ejp50/dwh_architecture_for_the_integration_of_30_sites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ejp50/dwh_architecture_for_the_integration_of_30_sites/", "subreddit_subscribers": 86558, "created_utc": 1673980681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've mostly been web dev in my career and only recently joined a team that is data eng. In web dev Blue Green deployments are super easy, since you just can route requests between blue and green at DNS or load balancer.   \n\n\nHowever most of the data pipeline stuff I've seen in my team is something like:   \n1. Poll or listen for new data  \n2. Do stuff  \n3. Write new data somewhere else  \n\n\nBlue/Green doesn't work here as much because the instances themselves are reading and writing continuously. So there is no external control mechanism like DNS, so you need internal controls which could work but may be brittle.  \n\n\nWhat patterns have you found successful for bringing up and swapping new versions of running pipeline services?  \n\n\nExtra context: Everything is pretty homegrown, ec2 style deployments.", "author_fullname": "t2_gn2ff6o9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Green Blue Style deployments for continuous data pipeline services?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10egxfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673974134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve mostly been web dev in my career and only recently joined a team that is data eng. In web dev Blue Green deployments are super easy, since you just can route requests between blue and green at DNS or load balancer.   &lt;/p&gt;\n\n&lt;p&gt;However most of the data pipeline stuff I&amp;#39;ve seen in my team is something like:&lt;br/&gt;\n1. Poll or listen for new data&lt;br/&gt;\n2. Do stuff&lt;br/&gt;\n3. Write new data somewhere else  &lt;/p&gt;\n\n&lt;p&gt;Blue/Green doesn&amp;#39;t work here as much because the instances themselves are reading and writing continuously. So there is no external control mechanism like DNS, so you need internal controls which could work but may be brittle.  &lt;/p&gt;\n\n&lt;p&gt;What patterns have you found successful for bringing up and swapping new versions of running pipeline services?  &lt;/p&gt;\n\n&lt;p&gt;Extra context: Everything is pretty homegrown, ec2 style deployments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10egxfp", "is_robot_indexable": true, "report_reasons": null, "author": "fthb1000000", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10egxfp/green_blue_style_deployments_for_continuous_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10egxfp/green_blue_style_deployments_for_continuous_data/", "subreddit_subscribers": 86558, "created_utc": 1673974134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uo96pc9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume advice needed. Applying for Data Engineering roles. I have mentioned a couple of projects in my portfolio (70milan.github.io) to avoid mentioning it on my resume yet cant get all the information on a single page. Reduced font size to 10.5-11 pts, more suggestions appreciated.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10egk6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T0N6_lfidPVS48rX80qr0wpSGrW4PYmlfvvNLg3do8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673973224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g1mevnbu9oca1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g1mevnbu9oca1.png?auto=webp&amp;v=enabled&amp;s=3e596692bec3a08e2b341393ad293a9b84a6697f", "width": 1080, "height": 2109}, "resolutions": [{"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02625a9372ce393e8c2cb92b5bfce88411f77097", "width": 108, "height": 210}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2f181323f1414795b240f10e18f6dbdd862aa9a", "width": 216, "height": 421}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73c23182414f17420323af47065bbb41310d4201", "width": 320, "height": 624}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67a7cfe8d623389adfd606b527435833afc71144", "width": 640, "height": 1249}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f157e0da899ce434d2440d624158ed36fa832b9c", "width": 960, "height": 1874}, {"url": "https://preview.redd.it/g1mevnbu9oca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91110b26c772afb5c571e34f0c302097547b4c5d", "width": 1080, "height": 2109}], "variants": {}, "id": "zGs4iRzbDByVHiSEeV-DzXrD3k8sLiwSYbRqDk5n1vQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10egk6a", "is_robot_indexable": true, "report_reasons": null, "author": "purplexed247", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10egk6a/resume_advice_needed_applying_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/g1mevnbu9oca1.png", "subreddit_subscribers": 86558, "created_utc": 1673973224.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}