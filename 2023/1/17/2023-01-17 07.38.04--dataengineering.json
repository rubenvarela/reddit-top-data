{"kind": "Listing", "data": {"after": "t3_10dfvql", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For engineers who primarily work in a data warehouse environment mainly using SQL (and very little python), what are your career goals?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dr0r4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673901676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an analytics engineer who is confused on what to learn next or where to take my career, so I am curious about like-kind professionals who are in the same boat. Have used python but 95% of my day is spent performing transformations using dbt in a cloud data warehouse environment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dr0r4", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dr0r4/for_engineers_who_primarily_work_in_a_data/", "subreddit_subscribers": 86503, "created_utc": 1673901676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, it\u2019s me again, now asking questions for data quality engineers (if there are any here). \n\nWhen I was an intern a couple of years ago, I used to work with a team that had a DQE. Since I was an intern I was not really exposed to what they were doing but I remember that every time we ingested a new data source, they ran a quality check script on the data (guessing its freshness, schema check, and other qc stuff).\n\nI also know they had a testing dwh with a copy of 3 day old prod data, where they ran daily QC checks and I\u2019m guessing trying to catch any anomaly or error. \n\nDo understand the first type of testing, but don\u2019t really know what they are doing in the second one. Why 3 day old data? is that data refreshed daily? How will they catch anomalies? Are those tests hardcoded to the most minuscule detail to catch anything that\u2019s different? \n\nI came upon a friend working at a unicorn that did something like this with 2/3 day old data. He told me that they did this at every level of their data lake. Is this best practices for qc then? \n\nMy company severely lack QC in data and there is no real expertise. Trying to learn best practices to implement in our data products", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality engineering best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10d9nhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673859083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, it\u2019s me again, now asking questions for data quality engineers (if there are any here). &lt;/p&gt;\n\n&lt;p&gt;When I was an intern a couple of years ago, I used to work with a team that had a DQE. Since I was an intern I was not really exposed to what they were doing but I remember that every time we ingested a new data source, they ran a quality check script on the data (guessing its freshness, schema check, and other qc stuff).&lt;/p&gt;\n\n&lt;p&gt;I also know they had a testing dwh with a copy of 3 day old prod data, where they ran daily QC checks and I\u2019m guessing trying to catch any anomaly or error. &lt;/p&gt;\n\n&lt;p&gt;Do understand the first type of testing, but don\u2019t really know what they are doing in the second one. Why 3 day old data? is that data refreshed daily? How will they catch anomalies? Are those tests hardcoded to the most minuscule detail to catch anything that\u2019s different? &lt;/p&gt;\n\n&lt;p&gt;I came upon a friend working at a unicorn that did something like this with 2/3 day old data. He told me that they did this at every level of their data lake. Is this best practices for qc then? &lt;/p&gt;\n\n&lt;p&gt;My company severely lack QC in data and there is no real expertise. Trying to learn best practices to implement in our data products&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10d9nhf", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10d9nhf/data_quality_engineering_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10d9nhf/data_quality_engineering_best_practices/", "subreddit_subscribers": 86503, "created_utc": 1673859083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v34fx7jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Junior DE role is appropriate for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10dbt8b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6oxeQP-5WT5tZc0h06rd0OIE9H4jW-LnjNKWQgYEGFg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673867069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/d6whsjyg0eca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/d6whsjyg0eca1.png?auto=webp&amp;v=enabled&amp;s=8e73a90196a98cb199b459ede6c2949d0b50f4e6", "width": 1700, "height": 2200}, "resolutions": [{"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92477f2494956e2002354709585cfa22d0c740cd", "width": 108, "height": 139}, {"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc21b318bd42644c52e1cfac82a5a812f86759d0", "width": 216, "height": 279}, {"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14a81e0bf091a81e2355cc67d0555ff57a5b3a95", "width": 320, "height": 414}, {"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b94b90b3bf17fbc7b1d33f8ecb898bcc4957a81a", "width": 640, "height": 828}, {"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c449c232d0c7f0ac1ee36d61ff5403b1814ae166", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/d6whsjyg0eca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ecd660f443773c572b867ab1ae5780430f80edc8", "width": 1080, "height": 1397}], "variants": {}, "id": "Tj8LOKz5UDDX7FFgRrZfWWn4ONsdy5kvnsOxA-es6QI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10dbt8b", "is_robot_indexable": true, "report_reasons": null, "author": "Fit_Drop8459", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dbt8b/is_a_junior_de_role_is_appropriate_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/d6whsjyg0eca1.png", "subreddit_subscribers": 86503, "created_utc": 1673867069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys.\n\nMy company is recently trying to get rid of every python ETL processes to unify all our stack around IICS. I'm not very experienced on IICS as I'm starting to learn it. I haven't seen many job offers that ask for knowledge in it, so I'm a bit worried about if it is worth it to give it a try.\n\nWhat do you think of it? Is it worth it to learn it?", "author_fullname": "t2_7husrqi1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your opinion on Informatica (IICS)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dm1ef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673891579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys.&lt;/p&gt;\n\n&lt;p&gt;My company is recently trying to get rid of every python ETL processes to unify all our stack around IICS. I&amp;#39;m not very experienced on IICS as I&amp;#39;m starting to learn it. I haven&amp;#39;t seen many job offers that ask for knowledge in it, so I&amp;#39;m a bit worried about if it is worth it to give it a try.&lt;/p&gt;\n\n&lt;p&gt;What do you think of it? Is it worth it to learn it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dm1ef", "is_robot_indexable": true, "report_reasons": null, "author": "ElMiticoTonto", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dm1ef/whats_your_opinion_on_informatica_iics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dm1ef/whats_your_opinion_on_informatica_iics/", "subreddit_subscribers": 86503, "created_utc": 1673891579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are building a new data warehouse and I am thinking of defining the data structures and migrations using SQLAlchemy and Alembic.\n\nIs it a good approach? I mean is it reasonable to use such tools for defining potentially large warehouse with potentially a lot of relationships? Or are these tools rather for smaller databases? If so, what tools would be a better alternative?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQLAlchemy for DWH definition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dm08j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673891529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are building a new data warehouse and I am thinking of defining the data structures and migrations using SQLAlchemy and Alembic.&lt;/p&gt;\n\n&lt;p&gt;Is it a good approach? I mean is it reasonable to use such tools for defining potentially large warehouse with potentially a lot of relationships? Or are these tools rather for smaller databases? If so, what tools would be a better alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dm08j", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dm08j/sqlalchemy_for_dwh_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dm08j/sqlalchemy_for_dwh_definition/", "subreddit_subscribers": 86503, "created_utc": 1673891529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negatives / criticisms of the databricks platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpzpa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Medium sized business deciding on whether to invest in the databricks platform. The databricks team do a great job of presenting all of the positives. What are the negatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dpzpa", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpzpa/negatives_criticisms_of_the_databricks_platform/", "subreddit_subscribers": 86503, "created_utc": 1673899757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Observability: The Next Frontier of Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10defl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VC04oAHnrxPHHD_ivI1peKUMpIzZoshL2eq2zeMRRn4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673875342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?auto=webp&amp;v=enabled&amp;s=6763ef0071a893ed732b2a289485d0bdf0e98618", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=506669e8aba350ec60db312a299d11d854854ce0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a68bb5121d235cf07cbe7a8cf9bbd4eec717f061", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c7b2aef8c79fed9b52ddfa1562b3c869e97076", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/yR-rHk64TUPjSsMGkvB-WWjc9u3oBgzvto_C7bJyl5s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a26d98a4fc7fa34d512862b1611b96d81a02dd61", "width": 640, "height": 336}], "variants": {}, "id": "JGhC9b9qhHNJ4eh7-qMHVcYJNdZfz1K-5VoSz-ZvhQY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10defl7", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10defl7/data_observability_the_next_frontier_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-observability-the-next-frontier-of-data-engineering", "subreddit_subscribers": 86503, "created_utc": 1673875342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven't used either, but am familiar with the high level concept at least. \n\nDoes anyone have any guidance on the overlap or strengths or weaknesses of one over the other?\n\nI know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I'd be interested in hearing if there was any strengths of EMR over databricks jobs.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Athena + EMR vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10duvps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673908839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new engineer joined a team adjacent to mine. We already have Databricks and Snowflake. They were asking about Athena and EMR. I haven&amp;#39;t used either, but am familiar with the high level concept at least. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any guidance on the overlap or strengths or weaknesses of one over the other?&lt;/p&gt;\n\n&lt;p&gt;I know from a spark performance perspective Databricks (and doubly so with photon now) seems to spank EMR performance. But I&amp;#39;d be interested in hearing if there was any strengths of EMR over databricks jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10duvps", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10duvps/aws_athena_emr_vs_databricks/", "subreddit_subscribers": 86503, "created_utc": 1673908839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  [https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link](https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link)\n\nThe only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.\n\nIs there a better way (that does not require a dedicated sql pool)?", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync Azure SQL with ADLS gen. 2 storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dv441", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673909382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Soon, I will be entering a project where I need to sync several Azure SQL tables with files in ADLS gen. 2 storage.  My co-worker found this article recently, which looks promising:  &lt;a href=\"https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link\"&gt;https://learn.microsoft.com/en-us/azure/synapse-analytics/synapse-link/sql-server-2022-synapse-link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The only issue is we are using Synapse serverless pools, and not dedicated SQL pools.  Does anyone have any idea what the simplest, most elegant, way to sync an Azure SQL database (handful of tables) with files in ADLS gen. 2?  If this was a few years ago, I would probably implement some sort of CDC process on sql to dump any changed records over to flat files on the data lake.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way (that does not require a dedicated sql pool)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?auto=webp&amp;v=enabled&amp;s=8e9dd29e55be5f9d4be03f8a2ca6dc669418c160", "width": 400, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c681715b246565ff9e7dfd8843f18ead842afeb2", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b70c2ce2562a35082ef9647f1b3db65e880827dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YH8gNap4KoGcFgyFYrNZ86fXmYfRn6pa7uuwIlZkjEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448b5cac6633b9e14f4209e70d3996bf0d0f97b6", "width": 320, "height": 320}], "variants": {}, "id": "LVmzWMJU1UZwRubzQYJZSar-z-Rq8ntUH65yhQyfxB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dv441", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dv441/sync_azure_sql_with_adls_gen_2_storage/", "subreddit_subscribers": 86503, "created_utc": 1673909382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Till now I have basically only worked on internal dashboards, where the target group were basically me and my colleagues - for ML and other monitoring. My new employer creates a product which is basically a dashboard for anyone (potential clients) in our business domain. As such, the dashboard mainly consists of charts with some (ML) forecasts. What is a Dashboard solution you guys can recommend for that use case? We're still in prototype phase and tableau just doesn't seem right. We are using GCP. Im thinking of Grafana mainly, or maybe Google Looker?", "author_fullname": "t2_c7p9a8et", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consumer-facing dashboards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dklbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673889464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Till now I have basically only worked on internal dashboards, where the target group were basically me and my colleagues - for ML and other monitoring. My new employer creates a product which is basically a dashboard for anyone (potential clients) in our business domain. As such, the dashboard mainly consists of charts with some (ML) forecasts. What is a Dashboard solution you guys can recommend for that use case? We&amp;#39;re still in prototype phase and tableau just doesn&amp;#39;t seem right. We are using GCP. Im thinking of Grafana mainly, or maybe Google Looker?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dklbm", "is_robot_indexable": true, "report_reasons": null, "author": "Routine_Parsley_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dklbm/consumerfacing_dashboards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dklbm/consumerfacing_dashboards/", "subreddit_subscribers": 86503, "created_utc": 1673889464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9dxlqti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job search for Data Engineering in Stockholm (2yoe)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": true, "name": "t3_10e5fus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KWb-EpGGvqMXYoLxdOISXGN8R9YkzrsLCqciUiu8Br4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673938154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ifsbknzovjca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ifsbknzovjca1.png?auto=webp&amp;v=enabled&amp;s=720f7b32784f54d3bb3be371bbb1e652c1956ad0", "width": 1400, "height": 1200}, "resolutions": [{"url": "https://preview.redd.it/ifsbknzovjca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ac145d3321fa37ab01a484ecad8ead58d5e7370", "width": 108, "height": 92}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92e3a8a9c1c53bd3712a871226ed1610907bb255", "width": 216, "height": 185}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44af5b1a49dcf11f6b0fe2675eb407a42f2d936c", "width": 320, "height": 274}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91c9c67fbb4c909a9a15213cd9098a2e3c744fbc", "width": 640, "height": 548}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b577c5e292a7d360544b94e7e24cfde374222490", "width": 960, "height": 822}, {"url": "https://preview.redd.it/ifsbknzovjca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ac8e1ba984d1f3276c8d53531d14ee5300dde46", "width": 1080, "height": 925}], "variants": {}, "id": "oEqP3_RncsejmRRJuZHYeUQOfr5_BmGtyTp0iByY3ig"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e5fus", "is_robot_indexable": true, "report_reasons": null, "author": "aleda145", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e5fus/job_search_for_data_engineering_in_stockholm_2yoe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ifsbknzovjca1.png", "subreddit_subscribers": 86503, "created_utc": 1673938154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Threw out my previous resume and came up with this one based on your advice. How can I improve it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10e35o3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xOH3zY4eiF2cWcDl_WvPLhrJsv1U8M-o-BZsIvD53Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673930802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sfdpt174ajca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sfdpt174ajca1.png?auto=webp&amp;v=enabled&amp;s=582956fc9c5d5e674dff5f31890c76990c52f13c", "width": 893, "height": 1249}, "resolutions": [{"url": "https://preview.redd.it/sfdpt174ajca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1a182b0e6992b5bc8413766328c4a6bffa97540", "width": 108, "height": 151}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f380775e7e5928fbf6f52db1a8d9d891b040db6f", "width": 216, "height": 302}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd42c6724f3d4959f4b1118ed45235ddacf50b95", "width": 320, "height": 447}, {"url": "https://preview.redd.it/sfdpt174ajca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b479eeda9f72478d57f5652c11a13e0c8c4dd362", "width": 640, "height": 895}], "variants": {}, "id": "CjQTqHDjmpkc7v_82mRT1SyoSMpxJWmn8YWEao7DHWc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10e35o3", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10e35o3/threw_out_my_previous_resume_and_came_up_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sfdpt174ajca1.png", "subreddit_subscribers": 86503, "created_utc": 1673930802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Requesting advice on my resume, looking for an Azure DE position. Appreciate any help or advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10dzq9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DZHfLU9Qc0KJQVwzHWxUfKjtPGbft-XglNYVJscYgXo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673921049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sqy3r131hica1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sqy3r131hica1.png?auto=webp&amp;v=enabled&amp;s=afbd78607939952cb83bd7ab5e68b8f3ec259ab6", "width": 1190, "height": 1684}, "resolutions": [{"url": "https://preview.redd.it/sqy3r131hica1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=484f87ca7afaba5d436931099d6d9f53b487cbaf", "width": 108, "height": 152}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=961694d998c07e4f7292bef01c721093b78bf422", "width": 216, "height": 305}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b63854c94b7976ea5ee5e45267093d3cefd9f199", "width": 320, "height": 452}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b5face555d5422d514e04f3ce60db7df21e1e40", "width": 640, "height": 905}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caf26642c5fdc8ac53627cf118f120533c95b7eb", "width": 960, "height": 1358}, {"url": "https://preview.redd.it/sqy3r131hica1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf6c4d075d84cb79e7ec72eaa8a8e9ba7e9edc46", "width": 1080, "height": 1528}], "variants": {}, "id": "UExNL13Iw5kNELwpC4FprwQjx7_jgRM2-S0ZMXswi90"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10dzq9y", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10dzq9y/requesting_advice_on_my_resume_looking_for_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sqy3r131hica1.png", "subreddit_subscribers": 86503, "created_utc": 1673921049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all!\n\nFor context, I've been working as a DA for years now and recently landed a job at a series A startup as a DE. I'm fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I'll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.\n\nThey hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I'm more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I'd likely take that approach. I was thinking of building out a stack like: MySQL -&gt; Fivetran -&gt; GBQ/Snowflake -&gt; DBT/Airflow -&gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.\n\nI understand this might be too vague to give a complete response to, but I'd love to hear some thoughts on this situation from more experienced folks.\n\nThanks!\n\n&amp;#x200B;\n\nFOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I'd be way over paid though\n\nI forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Data Engineering Job Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dxyrs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673922921.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673916361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all!&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;ve been working as a DA for years now and recently landed a job at a series A startup as a DE. I&amp;#39;m fairly technical (really strong SQL, decent Python), but have never worked as a designated data engineer in the past. In this role I&amp;#39;ll be the first data hire at the company. I havent started yet, so I cant give too much detail, but it sounds like they currently use a MySQL database to store everything. I cant imagine the tables being large enough to demand a full fledged data warehouse, however in terms of scaling id like to get some advice on what the best approach is here.&lt;/p&gt;\n\n&lt;p&gt;They hired me to eventually build out a BI platform to better understand their business through KPIs that we will presumably determine together. Admittedly, I&amp;#39;m more interested in developing my DE skills in this role, rather than building out a bunch of dashboards, so if I could realistically justify setting up a more robust system, I&amp;#39;d likely take that approach. I was thinking of building out a stack like: MySQL -&amp;gt; Fivetran -&amp;gt; GBQ/Snowflake -&amp;gt; DBT/Airflow -&amp;gt; Tableau. I feel like this would be a good stack for a more novice engineer as it is easier to setup and maintain.&lt;/p&gt;\n\n&lt;p&gt;I understand this might be too vague to give a complete response to, but I&amp;#39;d love to hear some thoughts on this situation from more experienced folks.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;FOLLOW UP QUESTION: Is it possible that a role like this might not even involve any DE work? I guess my main concern would be walking in day one and realizing theres already a few frontend tables that just need dashboards build on top of them lol. In that case I&amp;#39;d be way over paid though&lt;/p&gt;\n\n&lt;p&gt;I forgot to mention, there are 2 instances of MySQL currently. Theres the main instance that pulls from a rails application which is real time synced to a second MySQL instance for read-only reporting&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dxyrs", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dxyrs/new_data_engineering_job_question/", "subreddit_subscribers": 86503, "created_utc": 1673916361.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Suppose I'm trying to create a data lake, and I need to ingest data from an external source into this lake. I have a task that runs daily to extract this external data into the data lake. I can think of five different solutions:\n\n1. Ignore state, download everything from the external source every time, overwrite duplicate data in data lake\n2. Ignore state, download everything from the external source every time, create copies of duplicate data in data lake, only expose most recent files in gold lake\n3. Use state of external source (timestamps where available) to only download files created since last run\n4. Use state of both external source and data lake (file name, or some combo of file name/timestamp/etc.) to only download files not present in data lake\n5. Same as #4, but keep the data lake state in some external location, like a SQL database\n\nI've been doing #4 for almost everything so far, but I'm curious if others are using different logic. The only negative I can see with #4 currently is that you're basically doing a giant diff on all external/internal data, so time-wise, it would scale with both.", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to avoid ingesting duplicate external datasets into data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10doamm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673895860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose I&amp;#39;m trying to create a data lake, and I need to ingest data from an external source into this lake. I have a task that runs daily to extract this external data into the data lake. I can think of five different solutions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ignore state, download everything from the external source every time, overwrite duplicate data in data lake&lt;/li&gt;\n&lt;li&gt;Ignore state, download everything from the external source every time, create copies of duplicate data in data lake, only expose most recent files in gold lake&lt;/li&gt;\n&lt;li&gt;Use state of external source (timestamps where available) to only download files created since last run&lt;/li&gt;\n&lt;li&gt;Use state of both external source and data lake (file name, or some combo of file name/timestamp/etc.) to only download files not present in data lake&lt;/li&gt;\n&lt;li&gt;Same as #4, but keep the data lake state in some external location, like a SQL database&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve been doing #4 for almost everything so far, but I&amp;#39;m curious if others are using different logic. The only negative I can see with #4 currently is that you&amp;#39;re basically doing a giant diff on all external/internal data, so time-wise, it would scale with both.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10doamm", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10doamm/whats_the_best_way_to_avoid_ingesting_duplicate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10doamm/whats_the_best_way_to_avoid_ingesting_duplicate/", "subreddit_subscribers": 86503, "created_utc": 1673895860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Didn't see anything on this topic in the wiki so I'm making a post. I'm trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.\n\nI have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I've overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn't a complete knowledge right now.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good tutorials teaching spark structured streaming within the databricks &amp; Azure ecosystem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e14wa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673924944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Didn&amp;#39;t see anything on this topic in the wiki so I&amp;#39;m making a post. I&amp;#39;m trying to read in from IoTHub, perform ETL (standardize, combine stream with batch processing, etc.), and then read out to a delta lake.&lt;/p&gt;\n\n&lt;p&gt;I have no knowledge of Spark or delta tables/delta lake. Any suggested videos/tutorials. I think I&amp;#39;ve overleveraged myself at work and would like to learn this fairly quickly if possible even if it isn&amp;#39;t a complete knowledge right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e14wa", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e14wa/any_good_tutorials_teaching_spark_structured/", "subreddit_subscribers": 86503, "created_utc": 1673924944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends,\n\nI have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.\n\nI'm curious what the life of the other part of the world is. I'm sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)", "author_fullname": "t2_clsgf4j4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a distinct difference between OLAP DE and OLTP DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e0rix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673923903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends,&lt;/p&gt;\n\n&lt;p&gt;I have been working as a DE for a few years, all of which dedicated to internal clients -- that is, dealing with OLAP data, setting up data warehouses and writing ETLs for them.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what the life of the other part of the world is. I&amp;#39;m sure there are also DEs that deal with distributed OLTP too (our upstream). What are your challenges? How can I transfer to the other side? What skills do I need to learn? (I found that a lot of positions use MySQL)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10e0rix", "is_robot_indexable": true, "report_reasons": null, "author": "redditthrowaway0315", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e0rix/is_there_a_distinct_difference_between_olap_de/", "subreddit_subscribers": 86503, "created_utc": 1673923903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?\n\n&amp;#x200B;\n\n1. Local Financial Bank\n\n\\- they are migrating from on-prem to cloud\n\n\\- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.\n\n&amp;#x200B;\n\n2. Consulting company (One of the Big 4)\n\n\\- project-based so tech stack will vary a lot\n\n\\- company name looks good in resume", "author_fullname": "t2_gzg678i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me decide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dpz36", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673899717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got 2 job offers. I know both are not the best out there but these are the only ones which gave me an offer. Which one will you choose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Local Financial Bank&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- they are migrating from on-prem to cloud&lt;/p&gt;\n\n&lt;p&gt;- work is highly divided by teams so you cannot get exposed to different stages of the DE pipeline. For example, a different team handles the framework, another team handles the codebase, etc.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Consulting company (One of the Big 4)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- project-based so tech stack will vary a lot&lt;/p&gt;\n\n&lt;p&gt;- company name looks good in resume&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10dpz36", "is_robot_indexable": true, "report_reasons": null, "author": "ryandane123", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dpz36/help_me_decide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dpz36/help_me_decide/", "subreddit_subscribers": 86503, "created_utc": 1673899717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nIs it possible to use an opensource dataviz Tool (e.g. Superset, Metabase ...) alongside Tableau for viewers ?\n\nThe goal is to use the same vizualisation in both tools", "author_fullname": "t2_98269xyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using an opensource Data Viz Tool alongside Tableau", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dhyqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673884338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Is it possible to use an opensource dataviz Tool (e.g. Superset, Metabase ...) alongside Tableau for viewers ?&lt;/p&gt;\n\n&lt;p&gt;The goal is to use the same vizualisation in both tools&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dhyqt", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Mountain9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dhyqt/using_an_opensource_data_viz_tool_alongside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dhyqt/using_an_opensource_data_viz_tool_alongside/", "subreddit_subscribers": 86503, "created_utc": 1673884338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dpzgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing Loan Application Data Using Python | Free Masterclass", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_10e4sgv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LX0WcC9Mj8-Mg3vS6Tl-3ACcbsZvpUknA-7KQYXvOTQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673935900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "eventbrite.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.eventbrite.com/e/analyzing-loan-application-data-using-python-free-masterclass-tickets-511366509997?aff=Reddit", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?auto=webp&amp;v=enabled&amp;s=68bd5f8864bb4dcbea0d0b21ab95b3285964281e", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=592e6a85c81fe6838f5c579969e317234202e530", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fa9cc3e6e835bf8a90df2de508f9c55756cb5be", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d03bb68be97ac12d03234140e0cf17a2bffc909", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44bf1595a20d7f68dd3c1decfcafac093cdfc869", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bukSdPDzC6NbW1r7x-VWDTqfxhmwsdMCewL6kPOB94s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1614b6958581bc04402c7c9353487046e3629399", "width": 960, "height": 480}], "variants": {}, "id": "eleiT-Q5jDwo9tmGUmJOCafJjcYlJcc-Ng5hXCfKVHs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10e4sgv", "is_robot_indexable": true, "report_reasons": null, "author": "Reginald_Martin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e4sgv/analyzing_loan_application_data_using_python_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.eventbrite.com/e/analyzing-loan-application-data-using-python-free-masterclass-tickets-511366509997?aff=Reddit", "subreddit_subscribers": 86503, "created_utc": 1673935900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "General availability of Azure OpenAI Service expands access to large, advanced AI models with added enterprise benefits", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10e4kcj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nnN7zGm94DELpT9Gieni903R6cunGxESsEGJ7DAgAg0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673935202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "azure.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?auto=webp&amp;v=enabled&amp;s=12e5c4658509b5caafda3d7cadf58478a503fd92", "width": 250, "height": 250}, "resolutions": [{"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee4c871aab3a3a21a0445f14d3494d638acedec4", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ol9FZT8FcQfRfADTU8teH6pU_nlSqvd5CC7kJ40sCDk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1ef4debacdd87a67a586964e9ce3758de5127c2", "width": 216, "height": 216}], "variants": {}, "id": "Ln1lNDqLGYB-op_KKWkMJ3CIwoutiembrNZnyFULkZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10e4kcj", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e4kcj/general_availability_of_azure_openai_service/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/", "subreddit_subscribers": 86503, "created_utc": 1673935202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI stumbled upon the following problem/case.\n\nWe have a CRM system (Salesforce) and a subscription management system (like Stripe), and we just saw that the connection between our different ontologies is vague to the rest of the employees. \n\nDo you have any idea how could we approach that case?\n\nFor example, each CRM account can be connected to only one Stripe account, one CRM contact can be connected with multiple CRM accounts etc..\n\nWe have a very big and not documented ontology business logic and we do not feel sure yet what should be the connection between these ontologies. e.g. If a SQL Query returns two Stripe Accounts connected to one CRM Account, how could we be sure that our analysts know that this is an invalid case?", "author_fullname": "t2_2vzl4xqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to make an ontology business model understandable to everyone in a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10e1gm0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673925867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I stumbled upon the following problem/case.&lt;/p&gt;\n\n&lt;p&gt;We have a CRM system (Salesforce) and a subscription management system (like Stripe), and we just saw that the connection between our different ontologies is vague to the rest of the employees. &lt;/p&gt;\n\n&lt;p&gt;Do you have any idea how could we approach that case?&lt;/p&gt;\n\n&lt;p&gt;For example, each CRM account can be connected to only one Stripe account, one CRM contact can be connected with multiple CRM accounts etc..&lt;/p&gt;\n\n&lt;p&gt;We have a very big and not documented ontology business logic and we do not feel sure yet what should be the connection between these ontologies. e.g. If a SQL Query returns two Stripe Accounts connected to one CRM Account, how could we be sure that our analysts know that this is an invalid case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10e1gm0", "is_robot_indexable": true, "report_reasons": null, "author": "gianniskks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10e1gm0/how_to_make_an_ontology_business_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10e1gm0/how_to_make_an_ontology_business_model/", "subreddit_subscribers": 86503, "created_utc": 1673925867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm working with a start up on their data pipeline and one of the tasks is to get the new data from BQ and sync it with MongoDB, our operational database for the backend of our client facing application. We don't get new data very frequently, once a day at most in larger batches. Assume a batch of max 10M rows, no more than 1GB in logical bytes. No transformations needed there, just moving and syncing. \n\nCurrently our flow of data kind of looks like this:\n\nRaw data from various sources -&gt; Google Cloud Storage (Data lake) -&gt; BQ (Data warehouse) -&gt; BQ (Data marts/integration) -&gt; MongoDB (operational DB)\n\nMostly everything is completed by previous work besides some automation of the pipeline and the movement of data from BQ to MongoDB.\n\nI am a fairly inexperienced data engineer with a little over a year of experience in a completely different stack of AWS/Spark/Hadoop/Databricks (also did more standard web development the last few years) so I'm still getting familiar. I am our only full time data engineer hire, we have some contractors work before me but most of the work is done.\n\nHowever I do have some experience and general software engineering experience so I feel good about being able to find a solution, just got to do my research. So originally I was thinking I could just use MongoAPI and just use cloud functions but given how fast CF's time out I thought there could be a better way. I came across the below video which looked interesting (Dataflow with Pubsub) - granted we don't need real time syncing nor does it have to be bidirectional, but I could implement for one direction and it felt very straightforward. Costs wise it doesn't seem very expensive when I looked at the pricing for dataflow but I'm not going to pretend like I fully understand how costs work in the Google Cloud ecosystem.\n\nhttps://www.youtube.com/watch?v=9MFv8J7Smws\n\nI guess I'm not necessarily asking for answers to my problem, but would love to hear any suggestions from what you could get from my short description or if there's any potential pitfalls I'm missing. Since I don't have a more senior engineer working with me I'm more or less trying to reach other more senior engineers out there for opinions ha. Thanks in advance.", "author_fullname": "t2_21k74213", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving data from BigQuery to MongoDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dya0s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673917213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working with a start up on their data pipeline and one of the tasks is to get the new data from BQ and sync it with MongoDB, our operational database for the backend of our client facing application. We don&amp;#39;t get new data very frequently, once a day at most in larger batches. Assume a batch of max 10M rows, no more than 1GB in logical bytes. No transformations needed there, just moving and syncing. &lt;/p&gt;\n\n&lt;p&gt;Currently our flow of data kind of looks like this:&lt;/p&gt;\n\n&lt;p&gt;Raw data from various sources -&amp;gt; Google Cloud Storage (Data lake) -&amp;gt; BQ (Data warehouse) -&amp;gt; BQ (Data marts/integration) -&amp;gt; MongoDB (operational DB)&lt;/p&gt;\n\n&lt;p&gt;Mostly everything is completed by previous work besides some automation of the pipeline and the movement of data from BQ to MongoDB.&lt;/p&gt;\n\n&lt;p&gt;I am a fairly inexperienced data engineer with a little over a year of experience in a completely different stack of AWS/Spark/Hadoop/Databricks (also did more standard web development the last few years) so I&amp;#39;m still getting familiar. I am our only full time data engineer hire, we have some contractors work before me but most of the work is done.&lt;/p&gt;\n\n&lt;p&gt;However I do have some experience and general software engineering experience so I feel good about being able to find a solution, just got to do my research. So originally I was thinking I could just use MongoAPI and just use cloud functions but given how fast CF&amp;#39;s time out I thought there could be a better way. I came across the below video which looked interesting (Dataflow with Pubsub) - granted we don&amp;#39;t need real time syncing nor does it have to be bidirectional, but I could implement for one direction and it felt very straightforward. Costs wise it doesn&amp;#39;t seem very expensive when I looked at the pricing for dataflow but I&amp;#39;m not going to pretend like I fully understand how costs work in the Google Cloud ecosystem.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=9MFv8J7Smws\"&gt;https://www.youtube.com/watch?v=9MFv8J7Smws&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I guess I&amp;#39;m not necessarily asking for answers to my problem, but would love to hear any suggestions from what you could get from my short description or if there&amp;#39;s any potential pitfalls I&amp;#39;m missing. Since I don&amp;#39;t have a more senior engineer working with me I&amp;#39;m more or less trying to reach other more senior engineers out there for opinions ha. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Au7qrtzotAJff7gO739Hs_g4JACuLpYacjHNQzI-UxA.jpg?auto=webp&amp;v=enabled&amp;s=bf211dcfe0f6c6dbd9d545d76413999784cb464a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Au7qrtzotAJff7gO739Hs_g4JACuLpYacjHNQzI-UxA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e6c4d91ca515c7ff95adb4503c9fed63c2fcfac", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Au7qrtzotAJff7gO739Hs_g4JACuLpYacjHNQzI-UxA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c995756576c8708d6954b296932fc63fd24ccfbe", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Au7qrtzotAJff7gO739Hs_g4JACuLpYacjHNQzI-UxA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=944f18bd8e832a69f4aa18823d8508f20cd70b24", "width": 320, "height": 240}], "variants": {}, "id": "y86FJsJ6tX7tn9Z0esMUqVWiXcWVuSNXxaMZTUsjGc4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10dya0s", "is_robot_indexable": true, "report_reasons": null, "author": "adgjl12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dya0s/moving_data_from_bigquery_to_mongodb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dya0s/moving_data_from_bigquery_to_mongodb/", "subreddit_subscribers": 86503, "created_utc": 1673917213.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi experts,\n\nWorking as a DE and code reviewer for the BI team, I noticed that our Airflow DAGs are our of control. A typical BI DAG repo contains hundreds of small-medium size DAGs that somehow interweave with each other. But eventually there are a few \"central\" DAGs that everything else depend on, so it's crucial to make sure that those central DAGs complete before their dependancies.\n\nThere are a few ways to deal with this issue, none is perfect:\n\n- Add every dependant task into the central DAG it depends on. Fortunately, most DAGs depend only on one central DAG so at least it is not too difficult to move things around. But the con is that it will make the central DAGs too huge -- just imagine each of the central DAGs contains hundreds of tasks!\n\n- Use sensors or whatever tools to check the depending central DAGs before executing the other tasks. The con is every BI developer is writing their own checks so quickly a lot of small queries are hitting the tables generated by the central DAGs. The sensors also burdens Airflow but that's a minor issue because we can always reschedule the sensors. Another issue is that not every BI developer is careful enough to assess the situation and write checks, can't blame them as it's a complicated data warehouse, but it does raise issues when they forgot to write a check and code reviewers also forgot about them.\n\nWhat is your recommendation?", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow 1.X: How do you implement very large data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dxus5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673916058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi experts,&lt;/p&gt;\n\n&lt;p&gt;Working as a DE and code reviewer for the BI team, I noticed that our Airflow DAGs are our of control. A typical BI DAG repo contains hundreds of small-medium size DAGs that somehow interweave with each other. But eventually there are a few &amp;quot;central&amp;quot; DAGs that everything else depend on, so it&amp;#39;s crucial to make sure that those central DAGs complete before their dependancies.&lt;/p&gt;\n\n&lt;p&gt;There are a few ways to deal with this issue, none is perfect:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Add every dependant task into the central DAG it depends on. Fortunately, most DAGs depend only on one central DAG so at least it is not too difficult to move things around. But the con is that it will make the central DAGs too huge -- just imagine each of the central DAGs contains hundreds of tasks!&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use sensors or whatever tools to check the depending central DAGs before executing the other tasks. The con is every BI developer is writing their own checks so quickly a lot of small queries are hitting the tables generated by the central DAGs. The sensors also burdens Airflow but that&amp;#39;s a minor issue because we can always reschedule the sensors. Another issue is that not every BI developer is careful enough to assess the situation and write checks, can&amp;#39;t blame them as it&amp;#39;s a complicated data warehouse, but it does raise issues when they forgot to write a check and code reviewers also forgot about them.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What is your recommendation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dxus5", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dxus5/airflow_1x_how_do_you_implement_very_large_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dxus5/airflow_1x_how_do_you_implement_very_large_data/", "subreddit_subscribers": 86503, "created_utc": 1673916058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Distributed systems are related to DWH projects? I am asking because I don't know that exist literature combines these two aspects. Maybe someone working as solution architect/ data architect and you used knowledge distributed systems in DWH project.\nThanks for answers :)", "author_fullname": "t2_12lh3k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relationship between distributed systems and DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10dfvql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673879252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Distributed systems are related to DWH projects? I am asking because I don&amp;#39;t know that exist literature combines these two aspects. Maybe someone working as solution architect/ data architect and you used knowledge distributed systems in DWH project.\nThanks for answers :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10dfvql", "is_robot_indexable": true, "report_reasons": null, "author": "toberson", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10dfvql/relationship_between_distributed_systems_and_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10dfvql/relationship_between_distributed_systems_and_dwh/", "subreddit_subscribers": 86503, "created_utc": 1673879252.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}