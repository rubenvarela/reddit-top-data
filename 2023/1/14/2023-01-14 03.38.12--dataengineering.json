{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will go first, how debugging works in IDE and how to use it? \nI\u2019ve been coding for awhile but never debug anything or never thought of doing it\u2026", "author_fullname": "t2_4v8di1j8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the things that you want to know but it\u2019s too late now to ask\u2026?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10awbwj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673621323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will go first, how debugging works in IDE and how to use it? \nI\u2019ve been coding for awhile but never debug anything or never thought of doing it\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10awbwj", "is_robot_indexable": true, "report_reasons": null, "author": "Tumbleweed-Afraid", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10awbwj/what_are_the_things_that_you_want_to_know_but_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10awbwj/what_are_the_things_that_you_want_to_know_but_its/", "subreddit_subscribers": 86209, "created_utc": 1673621323.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am in a bit of a conundrum at the moment and looking for some help. I am building a data platform that essentially fetches data from an RDS source DB to Snowflake data warehouse using tools such as AWS DMS, S3, airflow, and dbt.\n\nI am currently using external tables as the entry point to SNowflake and these tables store the raw data in a single VARIANT column as semi-structured data before being processed further by dbt. As time goes, the structure of this data may change as changes happen in the source tables.\n\nIs there a way to validate incoming data against a known schema and run it as part of our ELT process? The idea is to stop/fail the job when the ELT detects new structure that gives us time to update the schema by introducing new version and transformation logic to handle the new structure. \n\nThanks, all ideas are welcomed.", "author_fullname": "t2_8n43xmar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to validate incoming data against schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ajxbi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673580648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am in a bit of a conundrum at the moment and looking for some help. I am building a data platform that essentially fetches data from an RDS source DB to Snowflake data warehouse using tools such as AWS DMS, S3, airflow, and dbt.&lt;/p&gt;\n\n&lt;p&gt;I am currently using external tables as the entry point to SNowflake and these tables store the raw data in a single VARIANT column as semi-structured data before being processed further by dbt. As time goes, the structure of this data may change as changes happen in the source tables.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to validate incoming data against a known schema and run it as part of our ELT process? The idea is to stop/fail the job when the ELT detects new structure that gives us time to update the schema by introducing new version and transformation logic to handle the new structure. &lt;/p&gt;\n\n&lt;p&gt;Thanks, all ideas are welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ajxbi", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-River1467", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ajxbi/how_to_validate_incoming_data_against_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ajxbi/how_to_validate_incoming_data_against_schema/", "subreddit_subscribers": 86209, "created_utc": 1673580648.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For jobs in my area, I'm noticing a trend where most positions are using more tools that automate the steps that have been typically done by spark in the past, so almost all work is being done in SQL now.\n\n\n\nWhen I started in data engineering, my position was about 60% python/spark and 40% SQL.  Now I notice that most positions near me are over 90% SQL.\n\n\n\n\nWhat kind of jobs should I be applying for in the future if I don't want to do over 90% of my work in SQL?", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career suggestions for a data engineer who likes to work in Python/Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10at7ei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673612419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For jobs in my area, I&amp;#39;m noticing a trend where most positions are using more tools that automate the steps that have been typically done by spark in the past, so almost all work is being done in SQL now.&lt;/p&gt;\n\n&lt;p&gt;When I started in data engineering, my position was about 60% python/spark and 40% SQL.  Now I notice that most positions near me are over 90% SQL.&lt;/p&gt;\n\n&lt;p&gt;What kind of jobs should I be applying for in the future if I don&amp;#39;t want to do over 90% of my work in SQL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10at7ei", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10at7ei/career_suggestions_for_a_data_engineer_who_likes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10at7ei/career_suggestions_for_a_data_engineer_who_likes/", "subreddit_subscribers": 86209, "created_utc": 1673612419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to get a better sense of the typical operating costs of a Redshift/Snowflake/BigQuery/etc data warehouse. My background is pretty much purely technical, and I don't have a huge amount of experience or knowledge of the pricing (/administrative) side of things.\n\nTaking my company's DWH as an example, would you say this is fairly typical? Light? Or are we massively overspending?\n\n* Tech startup (headcount 50-100)\n* DWH primarily used to power BI dashboards &amp; allow analysts to run ad-hoc queries.\n* At any given time there'll be a handful of users running queries\n* We're using Redshift (2x ra3.xlplus nodes)\n* Ingesting 165M rows each day, total DB size is \\~7TB\n* Total Redshift spend is \\~$2k per month\n\nIs that somewhat typical for an organisation of our size?", "author_fullname": "t2_9noqp0py", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much does your Data Warehouse cost each month?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10azr2p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673629852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to get a better sense of the typical operating costs of a Redshift/Snowflake/BigQuery/etc data warehouse. My background is pretty much purely technical, and I don&amp;#39;t have a huge amount of experience or knowledge of the pricing (/administrative) side of things.&lt;/p&gt;\n\n&lt;p&gt;Taking my company&amp;#39;s DWH as an example, would you say this is fairly typical? Light? Or are we massively overspending?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tech startup (headcount 50-100)&lt;/li&gt;\n&lt;li&gt;DWH primarily used to power BI dashboards &amp;amp; allow analysts to run ad-hoc queries.&lt;/li&gt;\n&lt;li&gt;At any given time there&amp;#39;ll be a handful of users running queries&lt;/li&gt;\n&lt;li&gt;We&amp;#39;re using Redshift (2x ra3.xlplus nodes)&lt;/li&gt;\n&lt;li&gt;Ingesting 165M rows each day, total DB size is ~7TB&lt;/li&gt;\n&lt;li&gt;Total Redshift spend is ~$2k per month&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is that somewhat typical for an organisation of our size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10azr2p", "is_robot_indexable": true, "report_reasons": null, "author": "nangaparbat1", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10azr2p/how_much_does_your_data_warehouse_cost_each_month/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10azr2p/how_much_does_your_data_warehouse_cost_each_month/", "subreddit_subscribers": 86209, "created_utc": 1673629852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bullshit graph database performance benchmarks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10atdy7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1673613005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=34342371", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10atdy7", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10atdy7/bullshit_graph_database_performance_benchmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=34342371", "subreddit_subscribers": 86209, "created_utc": 1673613005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Fargate? EKS? EC2? Managed?\n\nAirflow itself won't be doing any heavy lifting it will just be triggering other stuff, mainly databricks jobs but various other things as well.\n\nInitially the workload will be quite light but it's only going to grow over time.", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best way to set up airflow on aws to keep costs low?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10atq0i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673614061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Fargate? EKS? EC2? Managed?&lt;/p&gt;\n\n&lt;p&gt;Airflow itself won&amp;#39;t be doing any heavy lifting it will just be triggering other stuff, mainly databricks jobs but various other things as well.&lt;/p&gt;\n\n&lt;p&gt;Initially the workload will be quite light but it&amp;#39;s only going to grow over time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10atq0i", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10atq0i/best_way_to_set_up_airflow_on_aws_to_keep_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10atq0i/best_way_to_set_up_airflow_on_aws_to_keep_costs/", "subreddit_subscribers": 86209, "created_utc": 1673614061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\n&amp;#x200B;\n\nSo I  have been a data analyst for the past five years and my tech stack currently looks like this:\n\nSQL\n\nPython (mostly pandas)\n\nPowerBI\n\n&amp;#x200B;\n\nVery recently, I had to undertake a project for a small area of the business that I work at, and for a number of reasons that I won't get it into, I ended up having to build a SQLite database to get automate the PowerBI reporting we do for that area. \n\n&amp;#x200B;\n\nThis involved wrangling a few API endpoints from various CRM and operational suppliers, doing ETL in pandas (inset that drooling pooh bear meme about doing ETL in pandas) to a SQLite database that we then query into our PowerBI reports. I am hoping that before the end of this year I can get enough organisational buy in to get this data hosted on BigQuery or something. \n\n&amp;#x200B;\n\nThis is easily the most enjoyable project I have done in my entire career as an analyst and made me think more about going down the data engineer path. I know there would still be alot to learn. How similar is this to what DE's do? I imagine you guys don't create SQLite databses at all but you build data pipelines (according to google anyway.) What does that entail?\n\n&amp;#x200B;\n\nFeel free to answer open endedly about what tools I should add to my stack next as I genuinely don't know, but I also have a few questions:\n\n&amp;#x200B;\n\nShould I try and get an AWS cert?\n\nWhy does every beginner data engineering project I see online require Docker? What even is Docker? is it used alot?\n\nWhere do I go to learn about Airflow, would that even be necessary?\n\nWhat kind of data sources do you guys work with/what kind of piplines do you build? I wanna know all about your processes?", "author_fullname": "t2_ftjmo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition from Analyst to Engineer? Where do I go from here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10axt5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673625090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I  have been a data analyst for the past five years and my tech stack currently looks like this:&lt;/p&gt;\n\n&lt;p&gt;SQL&lt;/p&gt;\n\n&lt;p&gt;Python (mostly pandas)&lt;/p&gt;\n\n&lt;p&gt;PowerBI&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Very recently, I had to undertake a project for a small area of the business that I work at, and for a number of reasons that I won&amp;#39;t get it into, I ended up having to build a SQLite database to get automate the PowerBI reporting we do for that area. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This involved wrangling a few API endpoints from various CRM and operational suppliers, doing ETL in pandas (inset that drooling pooh bear meme about doing ETL in pandas) to a SQLite database that we then query into our PowerBI reports. I am hoping that before the end of this year I can get enough organisational buy in to get this data hosted on BigQuery or something. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is easily the most enjoyable project I have done in my entire career as an analyst and made me think more about going down the data engineer path. I know there would still be alot to learn. How similar is this to what DE&amp;#39;s do? I imagine you guys don&amp;#39;t create SQLite databses at all but you build data pipelines (according to google anyway.) What does that entail?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Feel free to answer open endedly about what tools I should add to my stack next as I genuinely don&amp;#39;t know, but I also have a few questions:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Should I try and get an AWS cert?&lt;/p&gt;\n\n&lt;p&gt;Why does every beginner data engineering project I see online require Docker? What even is Docker? is it used alot?&lt;/p&gt;\n\n&lt;p&gt;Where do I go to learn about Airflow, would that even be necessary?&lt;/p&gt;\n\n&lt;p&gt;What kind of data sources do you guys work with/what kind of piplines do you build? I wanna know all about your processes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10axt5i", "is_robot_indexable": true, "report_reasons": null, "author": "punchoutlanddragons", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10axt5i/transition_from_analyst_to_engineer_where_do_i_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10axt5i/transition_from_analyst_to_engineer_where_do_i_go/", "subreddit_subscribers": 86209, "created_utc": 1673625090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially title. It feels like machine learning and AI tools are becoming more readily available, even to the point of utilizing them for forecasting in data warehouses. It also feels like a natural fit for analytics engineers to support ML models in the data warehouse on behalf of data scientists/the business.\n\nCan analytics engineers benefit from studying machine learning? Obviously not to the point to expect to be an MLE or researcher, but enough that they're proficient to utilize existing ML tools and models.", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can analytics engineers benefit from studying machine learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b56ph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673643118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially title. It feels like machine learning and AI tools are becoming more readily available, even to the point of utilizing them for forecasting in data warehouses. It also feels like a natural fit for analytics engineers to support ML models in the data warehouse on behalf of data scientists/the business.&lt;/p&gt;\n\n&lt;p&gt;Can analytics engineers benefit from studying machine learning? Obviously not to the point to expect to be an MLE or researcher, but enough that they&amp;#39;re proficient to utilize existing ML tools and models.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10b56ph", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b56ph/can_analytics_engineers_benefit_from_studying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b56ph/can_analytics_engineers_benefit_from_studying/", "subreddit_subscribers": 86209, "created_utc": 1673643118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm getting a regular flow of pings from recruiters on LinkedIn now. Like daily.\n\nI mean on the surface it's great but given the state of the market it's also a bit surprising. Seems fishy.\n\nAnyone else seeing this?\n\nIs DE just that hot? Are general SWEs seeing this too? Was it just the big FAANGs/Unicorns that over hired in 2021 maybe? And certain specific niches (eg crypto).\n\nI'm just wondering how real what I'm seeing is because I'm considering a move.. and of course if things aren't sustainable the noobs are always the first to get the axe!", "author_fullname": "t2_10kwn7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "jobs from LinkedIn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b5lat", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673644079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting a regular flow of pings from recruiters on LinkedIn now. Like daily.&lt;/p&gt;\n\n&lt;p&gt;I mean on the surface it&amp;#39;s great but given the state of the market it&amp;#39;s also a bit surprising. Seems fishy.&lt;/p&gt;\n\n&lt;p&gt;Anyone else seeing this?&lt;/p&gt;\n\n&lt;p&gt;Is DE just that hot? Are general SWEs seeing this too? Was it just the big FAANGs/Unicorns that over hired in 2021 maybe? And certain specific niches (eg crypto).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just wondering how real what I&amp;#39;m seeing is because I&amp;#39;m considering a move.. and of course if things aren&amp;#39;t sustainable the noobs are always the first to get the axe!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10b5lat", "is_robot_indexable": true, "report_reasons": null, "author": "bcsamsquanch", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b5lat/jobs_from_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b5lat/jobs_from_linkedin/", "subreddit_subscribers": 86209, "created_utc": 1673644079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone done TOGAF certification here in this sub ?\nI need some info", "author_fullname": "t2_8yd9vdzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TOGAF certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10arpka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673607437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone done TOGAF certification here in this sub ?\nI need some info&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10arpka", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Role_304", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10arpka/togaf_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10arpka/togaf_certification/", "subreddit_subscribers": 86209, "created_utc": 1673607437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rtceaie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ByteGraph: A Graph Database for TikTok", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": false, "name": "t3_10ao1op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/smvRHd5fWUN3Zti1zYpgxLNuyMcb2vXTr4LjC00jjwk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673593524.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mydistributed.systems", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mydistributed.systems/2023/01/bytegraph-graph-database-for-tiktok.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZkZT9luhKW-9HG1kaVXpS2LVlSWS4X2AXrIZgGq6VI0.jpg?auto=webp&amp;v=enabled&amp;s=a7d101a642247478b300db34f9b6dfea8b7f6b38", "width": 938, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ZkZT9luhKW-9HG1kaVXpS2LVlSWS4X2AXrIZgGq6VI0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64f3998fe15917f87f2f7c3c1f9632225c7abc08", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/ZkZT9luhKW-9HG1kaVXpS2LVlSWS4X2AXrIZgGq6VI0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c41656283dee7ceed698844b6f2cfeb49e40e831", "width": 216, "height": 145}, {"url": "https://external-preview.redd.it/ZkZT9luhKW-9HG1kaVXpS2LVlSWS4X2AXrIZgGq6VI0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4cba395718cb55ebbee9f6370d13ffdd336fe935", "width": 320, "height": 214}, {"url": "https://external-preview.redd.it/ZkZT9luhKW-9HG1kaVXpS2LVlSWS4X2AXrIZgGq6VI0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4110cb5f83cdbd5074a8537333b28f31cf02f951", "width": 640, "height": 429}], "variants": {}, "id": "Z1iA4TnuQy736Pmm89MlhrPimUAZErZJz0K2e1pIvIc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10ao1op", "is_robot_indexable": true, "report_reasons": null, "author": "roohitavaf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ao1op/bytegraph_a_graph_database_for_tiktok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mydistributed.systems/2023/01/bytegraph-graph-database-for-tiktok.html", "subreddit_subscribers": 86209, "created_utc": 1673593524.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have built a couple of web scrapers (following online tutorials) and have a decent understanding of how they work. A constant issue I see is having to do maintenance on the scripts due to changing HTML structures. \n\nAre there any solutions or best practices on how to deal with changing HTML structures?\n\n*For ex: I have a web scraper that scrapes Amazon for certain keywords which then creates a csv of the title, price, rating, and URL. This works fine and will continue to work until Amazon decides to change their page layout which could then break my web scraper.*", "author_fullname": "t2_5lpb7dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web Scraping: How to deal with changing HTML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b7wof", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673649716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a couple of web scrapers (following online tutorials) and have a decent understanding of how they work. A constant issue I see is having to do maintenance on the scripts due to changing HTML structures. &lt;/p&gt;\n\n&lt;p&gt;Are there any solutions or best practices on how to deal with changing HTML structures?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;For ex: I have a web scraper that scrapes Amazon for certain keywords which then creates a csv of the title, price, rating, and URL. This works fine and will continue to work until Amazon decides to change their page layout which could then break my web scraper.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10b7wof", "is_robot_indexable": true, "report_reasons": null, "author": "jtamayo97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b7wof/web_scraping_how_to_deal_with_changing_html/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b7wof/web_scraping_how_to_deal_with_changing_html/", "subreddit_subscribers": 86209, "created_utc": 1673649716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Data Engineer with 5yrs+ experience in that field and I'm currently reflecting on how to proceed in my career. So far I was never really struggling with getting job offers because I mainly just tried to adjust in what the market wanted int terms of skills and this always opened a lot of doors but I feel now how my interest in that field is slowly fading away.\n\nRecently I realised how I really hate infrastructure related topics, more so the troubleshooting part.  I often find myself not being able to finish work on time and hence work until late into the night because often I struggle to understand why a kubernetes pod isn't running the way it should or why terrarform isn't provisioning a service the way it should. I never wanted to be a Dev Ops guy but I feel like the most DE positions that I'm applying for sound and probably are 80% Dev Ops nowadays.\n\nMost of my tasks so far had been 10-20% coding, 80% setting up infrastructure environments. Creating pipelines always were the much easier part for me, but setting up/testing the infrastructure locally in kubernetes on docker desktop and then provisioning the pods in the cloud using terraform is where I often end up getting stuck. After having worked with these tools specifically since 1-2 years now, I feel that I should be much better at it but I feel that it rather just gets more frustating for me.\n\nI think I could improve by just studying these tools deeper obviously but the process of doing that feels incredible dry and boring so that my focus often shifts away during the process. I only see these tasks as something to get through asap because I rather like designing architecture and write code so I guess my lag of passion for dev ops is maybe the biggest obstacle.\n\nWhat's your motivation on becoming good at these things besides the paycheck or getting through it quickly?\n\nI've been recently interviewing but the vast majority of DE positions in my region seem to focus mainly on the Dev Ops part, e.g. not just guaranteeing data processes but data infrastructure as well to be running for stakeholders 24/7 and even being oncall here and there. Because of that I'm now only considering bigger departments that have Dev Ops Engineers as well, in the hope that the Data Engineer doesn't need to heavily focus on the infrastructure part.\n\nIn reality, I mainly enjoy things that are more closely related to analytical work, where I can optimize data availability (not infrastructure availability) for business processes and I like discussing the pros and cons of different architectures or processes since I rather have a very broad knowledge of data expertise to be frank. I feel that I've mediocre or 'good enough' experience in many DE tools but I don't have a real deep expertise in any of it, since I was mainly working in project related fields where every project required different tools.\n\nWhen I was recently interviewing, I saw that many DWH departments have Architects that had been Data Engineers for a lesser duration than me. I wonderd what their daily work would look like? I actually know Data Modelling since I studied them for the interview process but I never ended up modelling data since there were Data Architects for doing that. Not sure why they still expected me to have that knowledge then.\n\nDo you see Data Architect as just another Data position on the same level as a Data Engineer or do you see Data Architects as the next step in hierarchy for a Senior Data Engineer? Would it make sense to apply for this position instead or should I rather looking out for a company where I could transition to that inhouse? I just dream of a job where I can end my task on a normal schedule and not being up all night while trying to troubleshoot yaml files and cli commands to make things finally work the way they're supposed to so that I can present something during the next daily.\n\nWould be great if you could share your experience as a Data Architect and the daily work that comes with. Same goes for Data Engineer positions that don't require a lot of dev ops and where to found those.", "author_fullname": "t2_ucsqj51r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice: Boost intrinsic motivation or change the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aud2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673616269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673615974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Data Engineer with 5yrs+ experience in that field and I&amp;#39;m currently reflecting on how to proceed in my career. So far I was never really struggling with getting job offers because I mainly just tried to adjust in what the market wanted int terms of skills and this always opened a lot of doors but I feel now how my interest in that field is slowly fading away.&lt;/p&gt;\n\n&lt;p&gt;Recently I realised how I really hate infrastructure related topics, more so the troubleshooting part.  I often find myself not being able to finish work on time and hence work until late into the night because often I struggle to understand why a kubernetes pod isn&amp;#39;t running the way it should or why terrarform isn&amp;#39;t provisioning a service the way it should. I never wanted to be a Dev Ops guy but I feel like the most DE positions that I&amp;#39;m applying for sound and probably are 80% Dev Ops nowadays.&lt;/p&gt;\n\n&lt;p&gt;Most of my tasks so far had been 10-20% coding, 80% setting up infrastructure environments. Creating pipelines always were the much easier part for me, but setting up/testing the infrastructure locally in kubernetes on docker desktop and then provisioning the pods in the cloud using terraform is where I often end up getting stuck. After having worked with these tools specifically since 1-2 years now, I feel that I should be much better at it but I feel that it rather just gets more frustating for me.&lt;/p&gt;\n\n&lt;p&gt;I think I could improve by just studying these tools deeper obviously but the process of doing that feels incredible dry and boring so that my focus often shifts away during the process. I only see these tasks as something to get through asap because I rather like designing architecture and write code so I guess my lag of passion for dev ops is maybe the biggest obstacle.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your motivation on becoming good at these things besides the paycheck or getting through it quickly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been recently interviewing but the vast majority of DE positions in my region seem to focus mainly on the Dev Ops part, e.g. not just guaranteeing data processes but data infrastructure as well to be running for stakeholders 24/7 and even being oncall here and there. Because of that I&amp;#39;m now only considering bigger departments that have Dev Ops Engineers as well, in the hope that the Data Engineer doesn&amp;#39;t need to heavily focus on the infrastructure part.&lt;/p&gt;\n\n&lt;p&gt;In reality, I mainly enjoy things that are more closely related to analytical work, where I can optimize data availability (not infrastructure availability) for business processes and I like discussing the pros and cons of different architectures or processes since I rather have a very broad knowledge of data expertise to be frank. I feel that I&amp;#39;ve mediocre or &amp;#39;good enough&amp;#39; experience in many DE tools but I don&amp;#39;t have a real deep expertise in any of it, since I was mainly working in project related fields where every project required different tools.&lt;/p&gt;\n\n&lt;p&gt;When I was recently interviewing, I saw that many DWH departments have Architects that had been Data Engineers for a lesser duration than me. I wonderd what their daily work would look like? I actually know Data Modelling since I studied them for the interview process but I never ended up modelling data since there were Data Architects for doing that. Not sure why they still expected me to have that knowledge then.&lt;/p&gt;\n\n&lt;p&gt;Do you see Data Architect as just another Data position on the same level as a Data Engineer or do you see Data Architects as the next step in hierarchy for a Senior Data Engineer? Would it make sense to apply for this position instead or should I rather looking out for a company where I could transition to that inhouse? I just dream of a job where I can end my task on a normal schedule and not being up all night while trying to troubleshoot yaml files and cli commands to make things finally work the way they&amp;#39;re supposed to so that I can present something during the next daily.&lt;/p&gt;\n\n&lt;p&gt;Would be great if you could share your experience as a Data Architect and the daily work that comes with. Same goes for Data Engineer positions that don&amp;#39;t require a lot of dev ops and where to found those.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10aud2c", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Purpose-3452", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10aud2c/career_advice_boost_intrinsic_motivation_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10aud2c/career_advice_boost_intrinsic_motivation_or/", "subreddit_subscribers": 86209, "created_utc": 1673615974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious on how others handle this.\n\nWe have Kafka event data, Salesforce data that is snapshotted each day, Segment data etc.\n\nCustomer attributes in both Kafka customer event and Salesforce account table. Both sides get updates by the business, and so we end up with the equivalent of a Type2 SCD source for each, with valid to and from dates that overlap.\n\nWhen bringing the two together in the silver layer, would you try to blend the date ranges and keep a full change history across all source \u2018SCD2\u2019 tables that are used, or would you only me pulling forward the current version of the customer?\n\nFurther, if you would persist the history, and the Customer dataset came from 5 source tables across 2 source systems, each with changes at different times, is there a simple way to achieve that join?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medallion Architecture - persist history in Silver?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bbrsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673659849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious on how others handle this.&lt;/p&gt;\n\n&lt;p&gt;We have Kafka event data, Salesforce data that is snapshotted each day, Segment data etc.&lt;/p&gt;\n\n&lt;p&gt;Customer attributes in both Kafka customer event and Salesforce account table. Both sides get updates by the business, and so we end up with the equivalent of a Type2 SCD source for each, with valid to and from dates that overlap.&lt;/p&gt;\n\n&lt;p&gt;When bringing the two together in the silver layer, would you try to blend the date ranges and keep a full change history across all source \u2018SCD2\u2019 tables that are used, or would you only me pulling forward the current version of the customer?&lt;/p&gt;\n\n&lt;p&gt;Further, if you would persist the history, and the Customer dataset came from 5 source tables across 2 source systems, each with changes at different times, is there a simple way to achieve that join?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bbrsb", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bbrsb/medallion_architecture_persist_history_in_silver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bbrsb/medallion_architecture_persist_history_in_silver/", "subreddit_subscribers": 86209, "created_utc": 1673659849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to get a grip on the modeling techniques in a data lake environment\\*. Title captures it all, but to elaborate a bit more:\n\n1. Is the Gold layer always (or NEVER) independent of the Silver layer? (e.g. can you skip the Silver layer sometimes?  Is that good or bad practice?)\n2. How do you approach designing your aggregations in Gold layer? Is it always really obvious what needs to be aggregated, based on business requirements, or what? How should I think about this step?\n\nGreatly appreciate ANY advice... I've had these questions rolling around for a while, and need some practical perspective.\n\n&amp;#x200B;\n\n \n\n&amp;#x200B;\n\n*\\**Data Warehousing Modeling Techniques and Their Implementation on the Databricks Lakehouse Platform*:* [*https://www.databricks.com/blog/2022/06/24/data-warehousing-modeling-techniques-and-their-implementation-on-the-databricks-lakehouse-platform.html*](https://www.databricks.com/blog/2022/06/24/data-warehousing-modeling-techniques-and-their-implementation-on-the-databricks-lakehouse-platform.html)", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to get perspective on Silver/Gold layers: 1) Is Silver always needed, or can you go straight to Gold? 2) What is your strategy/approach for determining what fields to aggregate on in the Gold layer? How do you think about this when adding new data to the Gold layer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ayiup", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673626847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get a grip on the modeling techniques in a data lake environment*. Title captures it all, but to elaborate a bit more:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is the Gold layer always (or NEVER) independent of the Silver layer? (e.g. can you skip the Silver layer sometimes?  Is that good or bad practice?)&lt;/li&gt;\n&lt;li&gt;How do you approach designing your aggregations in Gold layer? Is it always really obvious what needs to be aggregated, based on business requirements, or what? How should I think about this step?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Greatly appreciate ANY advice... I&amp;#39;ve had these questions rolling around for a while, and need some practical perspective.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;\\&lt;/em&gt;&lt;em&gt;Data Warehousing Modeling Techniques and Their Implementation on the Databricks Lakehouse Platform&lt;/em&gt;:* &lt;a href=\"https://www.databricks.com/blog/2022/06/24/data-warehousing-modeling-techniques-and-their-implementation-on-the-databricks-lakehouse-platform.html\"&gt;&lt;em&gt;https://www.databricks.com/blog/2022/06/24/data-warehousing-modeling-techniques-and-their-implementation-on-the-databricks-lakehouse-platform.html&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?auto=webp&amp;v=enabled&amp;s=473b7825559ff11ab1a0f59acf461e69f5a17bcb", "width": 1200, "height": 890}, "resolutions": [{"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a1537ccceb767c5c85cb73b401c4dfbcc1f42c8", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=27654f666d77335d9b3ff8697bfb4e26187ca505", "width": 216, "height": 160}, {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=606fb0a4f80f7a2ecc752d0d3c15e446ce0e1f6b", "width": 320, "height": 237}, {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b26a9a0a53b2b463a47e245de43839988ba31c9f", "width": 640, "height": 474}, {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a1abd16ffa53dc8bf6af92f86fc2eb3d510fa57", "width": 960, "height": 712}, {"url": "https://external-preview.redd.it/GlkTXDUUc9QrvmRsibR_kVft_rUa1pbPzB0Yq3JrS_Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cc6a0d9519afe1f191e4ef3cec080ad70e67e59", "width": 1080, "height": 801}], "variants": {}, "id": "adIsbQLcfD21KE7SCcOwtRlJSRbLjjwMV4qs8jQujOc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ayiup", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ayiup/trying_to_get_perspective_on_silvergold_layers_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ayiup/trying_to_get_perspective_on_silvergold_layers_1/", "subreddit_subscribers": 86209, "created_utc": 1673626847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Designing a single source of truth for data coming from multiple sources. The scale of data is enormous more than PB and the solution needs to be deployed on premise, there could be multiple end goals [ Executive Reporting, ML/Al use case, etc]. What could be the to be state architecture? \n\nDo you think SSIS could be a fit? Or I should stick to medallion architecture? How to define the landing zone if cloud is not an option keeping in mind ease of scalability. What should be the target warehouse or Lakehouse...", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a single source of truth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10bbjt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673659223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Designing a single source of truth for data coming from multiple sources. The scale of data is enormous more than PB and the solution needs to be deployed on premise, there could be multiple end goals [ Executive Reporting, ML/Al use case, etc]. What could be the to be state architecture? &lt;/p&gt;\n\n&lt;p&gt;Do you think SSIS could be a fit? Or I should stick to medallion architecture? How to define the landing zone if cloud is not an option keeping in mind ease of scalability. What should be the target warehouse or Lakehouse...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10bbjt1", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10bbjt1/designing_a_single_source_of_truth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10bbjt1/designing_a_single_source_of_truth/", "subreddit_subscribers": 86209, "created_utc": 1673659223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I've been working for start-ups for the last 6 years. I started as an analyst in a tiny SaaS org on a team of DS, &amp; DE. Then moved to working with DEs on a BI team at a larger org. At my current very tiny start-up I manage the website tracking (Google Analytics, GTM, and Segment) which involves a bit of JS and I build some really super basic pipelines from web apps like Google Ads, Yahoo, Facebook, and stuff. \n\nMost of my projects are super eclectic and the skill-set seems to be random. I'm doing everything from writing JS to generate data, then creating Oauth scripts to connect to the app and ETL that data into our db, then mange the tables I've created. I also automate a lot of reporting that I find annoying. I generally prefer coding over UI stuff or analytics apps like Tableau. \n\nMy ad hoc analytic SQL and bd management SQL is really good and my python gets the jobs done. I can make a simple pipeline between an application and our db in a few days using SQL and python. \n\nWe recently contracted some 'real' DEs in a consulting firm and their ETAs on projects were weeks and months long (as opposed to days).  Since my job title is still 'Analyst' just wondering is that accurate or should I be asking for a DE title? I make about 90k + 10% and WFH.", "author_fullname": "t2_m1gs8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What title should I have and how should I rate my skill set?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b9mn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673654095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;ve been working for start-ups for the last 6 years. I started as an analyst in a tiny SaaS org on a team of DS, &amp;amp; DE. Then moved to working with DEs on a BI team at a larger org. At my current very tiny start-up I manage the website tracking (Google Analytics, GTM, and Segment) which involves a bit of JS and I build some really super basic pipelines from web apps like Google Ads, Yahoo, Facebook, and stuff. &lt;/p&gt;\n\n&lt;p&gt;Most of my projects are super eclectic and the skill-set seems to be random. I&amp;#39;m doing everything from writing JS to generate data, then creating Oauth scripts to connect to the app and ETL that data into our db, then mange the tables I&amp;#39;ve created. I also automate a lot of reporting that I find annoying. I generally prefer coding over UI stuff or analytics apps like Tableau. &lt;/p&gt;\n\n&lt;p&gt;My ad hoc analytic SQL and bd management SQL is really good and my python gets the jobs done. I can make a simple pipeline between an application and our db in a few days using SQL and python. &lt;/p&gt;\n\n&lt;p&gt;We recently contracted some &amp;#39;real&amp;#39; DEs in a consulting firm and their ETAs on projects were weeks and months long (as opposed to days).  Since my job title is still &amp;#39;Analyst&amp;#39; just wondering is that accurate or should I be asking for a DE title? I make about 90k + 10% and WFH.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10b9mn0", "is_robot_indexable": true, "report_reasons": null, "author": "SaraLR1221", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b9mn0/what_title_should_i_have_and_how_should_i_rate_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b9mn0/what_title_should_i_have_and_how_should_i_rate_my/", "subreddit_subscribers": 86209, "created_utc": 1673654095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to understand the type of approach you will follow in a scenario where you are consuming an unbounded streaming source and writing the data to an Iceberg table, let's say 30 in 30minutes. \n\nTechnically details:\n- data is being written in an append mode\n- events are deltas and not snapshots, meaning that some attributes can be null\n- events are partitioned in the table by an id and a date\n\nChallenge:\nUsing a query engine, such as Trino, how you build the query to retrieve the snapshots of the events by their id? Is it possible doing this and make sense or you will doing in a different way?\n\nExample:\nId | date | name | age\n1 | 2023 | John | null\n2 | 2022 | null | 20\n1 | 2023 | null | 25 \n\nOutput\n1|2023|25\n2|2022|20", "author_fullname": "t2_3b9qrlp9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Compute snapshot view from slowly changing dimension dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b8sg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673651941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to understand the type of approach you will follow in a scenario where you are consuming an unbounded streaming source and writing the data to an Iceberg table, let&amp;#39;s say 30 in 30minutes. &lt;/p&gt;\n\n&lt;p&gt;Technically details:\n- data is being written in an append mode\n- events are deltas and not snapshots, meaning that some attributes can be null\n- events are partitioned in the table by an id and a date&lt;/p&gt;\n\n&lt;p&gt;Challenge:\nUsing a query engine, such as Trino, how you build the query to retrieve the snapshots of the events by their id? Is it possible doing this and make sense or you will doing in a different way?&lt;/p&gt;\n\n&lt;p&gt;Example:\nId | date | name | age\n1 | 2023 | John | null\n2 | 2022 | null | 20\n1 | 2023 | null | 25 &lt;/p&gt;\n\n&lt;p&gt;Output\n1|2023|25\n2|2022|20&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10b8sg3", "is_robot_indexable": true, "report_reasons": null, "author": "cg3s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b8sg3/compute_snapshot_view_from_slowly_changing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b8sg3/compute_snapshot_view_from_slowly_changing/", "subreddit_subscribers": 86209, "created_utc": 1673651941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to EMR, I noticed that jobs are taking are taking 2-3 days for processing 2tb data.\nThe job is joining 2 tables of ~2tb(historical data partitioned on year and month) and ~300gb(partitioned on year). Data is updated and new data is inserted into the final dataset.\n\nUpon investigating, found out that the actual processing stage is completeled in few hours( still very slow ) but then it takes days to write to S3. \n\n__temoprary folder is created under which all the data writes and then to each partition.\n\nWhat can I do to reduce this time? This is causing a lot of trouble and I really want to solve this. The data comes quarterly and everyone forgets after the delivery\n\nSpark executor:5\nInstances:5\nExecutor memory:24g", "author_fullname": "t2_ivx2i554", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark on EMR writes to S3 extremely slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b86t1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673650430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to EMR, I noticed that jobs are taking are taking 2-3 days for processing 2tb data.\nThe job is joining 2 tables of ~2tb(historical data partitioned on year and month) and ~300gb(partitioned on year). Data is updated and new data is inserted into the final dataset.&lt;/p&gt;\n\n&lt;p&gt;Upon investigating, found out that the actual processing stage is completeled in few hours( still very slow ) but then it takes days to write to S3. &lt;/p&gt;\n\n&lt;p&gt;__temoprary folder is created under which all the data writes and then to each partition.&lt;/p&gt;\n\n&lt;p&gt;What can I do to reduce this time? This is causing a lot of trouble and I really want to solve this. The data comes quarterly and everyone forgets after the delivery&lt;/p&gt;\n\n&lt;p&gt;Spark executor:5\nInstances:5\nExecutor memory:24g&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10b86t1", "is_robot_indexable": true, "report_reasons": null, "author": "umermd", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b86t1/pyspark_on_emr_writes_to_s3_extremely_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b86t1/pyspark_on_emr_writes_to_s3_extremely_slow/", "subreddit_subscribers": 86209, "created_utc": 1673650430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am currently working as a DE in an MNC for the past 1 year. I know to code and was always fascinated by it.\n\nI am with only 1yr experience right now. I was placed to share the roles and responsibilities of an employee with 10+ years of experience in the SE + DE field. Now he's a manager in another team but still guides me on daily tasks.\n\nI mainly work on SQL - writing procedures/packages, user custom views, backend operations, ETL, Python scripting, python workers, KT documentations and technical issues solving for the PowerBI users for the database connections.\n\nI have been getting KT and work tickets simultaneously. I am the only database person for backend datahandling. (team manager tried hiring candidates but where not fit)\nI get a lot of workload and get exhausted.\nI have almost made sure the development cycle is not hampered by my role as a team with my contribution (1yr exp. compared to 10+yr exp. prev employee)\n\nQ1. How can I make sure to negotiate properly with HR on what I bring to the table and come to a good consensus on my compensation (not satisfied with my current in hand monthly \ud83d\ude42)?\nQ2. What in future i should hone my skills to be a good DE?", "author_fullname": "t2_5svl00at", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need an advice on this topic. Help! Advices to younger you if you were in my position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b7t7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673649483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am currently working as a DE in an MNC for the past 1 year. I know to code and was always fascinated by it.&lt;/p&gt;\n\n&lt;p&gt;I am with only 1yr experience right now. I was placed to share the roles and responsibilities of an employee with 10+ years of experience in the SE + DE field. Now he&amp;#39;s a manager in another team but still guides me on daily tasks.&lt;/p&gt;\n\n&lt;p&gt;I mainly work on SQL - writing procedures/packages, user custom views, backend operations, ETL, Python scripting, python workers, KT documentations and technical issues solving for the PowerBI users for the database connections.&lt;/p&gt;\n\n&lt;p&gt;I have been getting KT and work tickets simultaneously. I am the only database person for backend datahandling. (team manager tried hiring candidates but where not fit)\nI get a lot of workload and get exhausted.\nI have almost made sure the development cycle is not hampered by my role as a team with my contribution (1yr exp. compared to 10+yr exp. prev employee)&lt;/p&gt;\n\n&lt;p&gt;Q1. How can I make sure to negotiate properly with HR on what I bring to the table and come to a good consensus on my compensation (not satisfied with my current in hand monthly \ud83d\ude42)?\nQ2. What in future i should hone my skills to be a good DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10b7t7t", "is_robot_indexable": true, "report_reasons": null, "author": "Few_War_6750", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b7t7t/need_an_advice_on_this_topic_help_advices_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b7t7t/need_an_advice_on_this_topic_help_advices_to/", "subreddit_subscribers": 86209, "created_utc": 1673649483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lately in my learning, I have seen a lot of enterprise solutions, however I think that a lot of organizations especially small ones are seeking more affordable solutions that can scale. Yes all the major players in data management have solutions for this but at the cost of almost forcing people to pay ridiculous amounts of money when they're not ready for it. \n\nI kind of almost would love to see solutions based  on the number of employees or a budget. Of course you're going to be missing out on a lot of stuff but it would be helpful to see low tier low cost pipelines being published. One example would be something of using SharePoint, Access, Excel which I understand are not database solutions really but for a company with only five people it might be. \n\nI don't know if you guys have seen resources out there for something like this or that this is below the master data engineering race but something I think a lot of organizations would benefit from.", "author_fullname": "t2_8yface1u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different tier solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10b738d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673647707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lately in my learning, I have seen a lot of enterprise solutions, however I think that a lot of organizations especially small ones are seeking more affordable solutions that can scale. Yes all the major players in data management have solutions for this but at the cost of almost forcing people to pay ridiculous amounts of money when they&amp;#39;re not ready for it. &lt;/p&gt;\n\n&lt;p&gt;I kind of almost would love to see solutions based  on the number of employees or a budget. Of course you&amp;#39;re going to be missing out on a lot of stuff but it would be helpful to see low tier low cost pipelines being published. One example would be something of using SharePoint, Access, Excel which I understand are not database solutions really but for a company with only five people it might be. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if you guys have seen resources out there for something like this or that this is below the master data engineering race but something I think a lot of organizations would benefit from.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10b738d", "is_robot_indexable": true, "report_reasons": null, "author": "Benmagz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10b738d/different_tier_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10b738d/different_tier_solutions/", "subreddit_subscribers": 86209, "created_utc": 1673647707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/10aubiw)", "author_fullname": "t2_14i1sz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your data engineering team's remote policy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aubiw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673615842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10aubiw\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10aubiw", "is_robot_indexable": true, "report_reasons": null, "author": "pescennius", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1673875042871, "options": [{"text": "HQ office full time", "id": "20989894"}, {"text": "Satellite office full time", "id": "20989895"}, {"text": "Hybrid of remote and HQ office", "id": "20989896"}, {"text": "Hybrid of remote and satellite office", "id": "20989897"}, {"text": "Remote full time", "id": "20989898"}, {"text": "See Results", "id": "20989899"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 150, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10aubiw/what_is_your_data_engineering_teams_remote_policy/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10aubiw/what_is_your_data_engineering_teams_remote_policy/", "subreddit_subscribers": 86209, "created_utc": 1673615842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nIt becomes very important if you are working as a data scientist / data engineer or doing data analytics and have to write a lot of PySpark code mainly for data science, data engineering or analysis-based projects, such as data modeling, data processing, and data analytical algorithms, then it is your responsibility to improve the efficiency of PySpark code when you are doing anything within PySpark.\n\n[https://macxima.medium.com/pyspark-load-bigquery-table-into-pyspark-dataframe-e660fc9d9b0](https://macxima.medium.com/pyspark-load-bigquery-table-into-pyspark-dataframe-e660fc9d9b0)", "author_fullname": "t2_3aphf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark \u2014 Load BigQuery table into PySpark dataframe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ashfn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673610094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It becomes very important if you are working as a data scientist / data engineer or doing data analytics and have to write a lot of PySpark code mainly for data science, data engineering or analysis-based projects, such as data modeling, data processing, and data analytical algorithms, then it is your responsibility to improve the efficiency of PySpark code when you are doing anything within PySpark.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://macxima.medium.com/pyspark-load-bigquery-table-into-pyspark-dataframe-e660fc9d9b0\"&gt;https://macxima.medium.com/pyspark-load-bigquery-table-into-pyspark-dataframe-e660fc9d9b0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?auto=webp&amp;v=enabled&amp;s=508d51a60a9443309ebf715817a6e8fd4939a484", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a57a38fc987f37a4d749a1e34bdcc4e56314267", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84fb24083cd9dcaaff5af75797c29fa9f204396e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62792fd0f1f5c184b0d411ac6bf002bb693fd73a", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01914eef1ee6e89f479066f7526a3ab6e16fdd21", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6030894bc24b4e2c9657309e92820a58375f9114", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/XrmjxfYAvBaPAaMUhrIaWGgwkpXcUCCi90EHDHAQMQ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8eae307d0dd7692f41677bf47a75c2a930e2a4ca", "width": 1080, "height": 607}], "variants": {}, "id": "rmSox-_d5WJRV1HjTppQq9Ky7Viu4jBK7hRttzbVEsY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10ashfn", "is_robot_indexable": true, "report_reasons": null, "author": "macxima", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ashfn/pyspark_load_bigquery_table_into_pyspark_dataframe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ashfn/pyspark_load_bigquery_table_into_pyspark_dataframe/", "subreddit_subscribers": 86209, "created_utc": 1673610094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The second part of my conversation with Arjun and Frank from Materialize is out! We talk about the technical stuff this time. What timely dataflow is, how is different to MR and how building tech is different to building a product and co! Check it out.\n\n[https://datastackshow.com/podcast/materialize-origins-breaking-down-data-flow-layers-with-arjun-narayan-and-frank-mcsherry/](https://datastackshow.com/podcast/materialize-origins-breaking-down-data-flow-layers-with-arjun-narayan-and-frank-mcsherry/)", "author_fullname": "t2_fb1s1pke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part 2 of the discussion on Timely Dataflow and Materialize", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10akfm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673582142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The second part of my conversation with Arjun and Frank from Materialize is out! We talk about the technical stuff this time. What timely dataflow is, how is different to MR and how building tech is different to building a product and co! Check it out.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datastackshow.com/podcast/materialize-origins-breaking-down-data-flow-layers-with-arjun-narayan-and-frank-mcsherry/\"&gt;https://datastackshow.com/podcast/materialize-origins-breaking-down-data-flow-layers-with-arjun-narayan-and-frank-mcsherry/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?auto=webp&amp;v=enabled&amp;s=4576ca72be5e7c4105f1914c947ba7ee8866e16f", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fb8e47aa86c06829d3ab96d6765f45e1f9b010f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ac7750d9cb18f0770812fd3a602836b17137ae3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51a1f14248f4067fc9a2438906ef663daa344f49", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7f19d68a431b50565fe2d41c68b1c8d9420ac73", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6cc258be83e5b0ecfc09907e9300d70ff21a4636", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/FP5IxNSyM5ofKqnTCS2NtR_tOwY5I96h-J827fNdyxs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fe31123525df83336fdf6d7e0602e04c607c4ae", "width": 1080, "height": 607}], "variants": {}, "id": "sxhLbtHPBRlZSg4AJVbOpp6NR-C-tRmvcfEscQBDwBQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10akfm7", "is_robot_indexable": true, "report_reasons": null, "author": "cpardl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10akfm7/part_2_of_the_discussion_on_timely_dataflow_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10akfm7/part_2_of_the_discussion_on_timely_dataflow_and/", "subreddit_subscribers": 86209, "created_utc": 1673582142.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}