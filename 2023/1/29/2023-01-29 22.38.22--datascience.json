{"kind": "Listing", "data": {"after": "t3_10o49lr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Waittt What?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": false, "name": "t3_10nyhcl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 1178, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1178, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w9vi5By1rDrssAKaG_NyylSG68BUDbkr6m-Vd47ETDU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674965318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kbyv8h9u7yea1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?auto=webp&amp;v=enabled&amp;s=23c1005bb9046a0a296413e9bfe553c61ce8f9d7", "width": 864, "height": 751}, "resolutions": [{"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e7f87db54f90f5838b2918ced61ef24dbfcef35", "width": 108, "height": 93}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb32ae96bb90e17702fc3bca5e7cc2dfcd3815de", "width": 216, "height": 187}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92fb6dea8e15502cdec69edb551e8e769ac47e39", "width": 320, "height": 278}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f3b4b58c68ac8647735ac31be2b667c4b823436", "width": 640, "height": 556}], "variants": {}, "id": "XZNSxmVBRbsUVBChV_U7BLhRSc66dKoHdMrhKvEsz90"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nyhcl", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 256, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nyhcl/waittt_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kbyv8h9u7yea1.png", "subreddit_subscribers": 842562, "created_utc": 1674965318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve recently been laid off from my Data Science role in the UK. Currently looking for some ways to make ends meet whilst I look for another full-time role, and was wondering if anyone had some experience with contract or freelance data science work.\n\nI\u2019m most intrigued to know:\n\n1) What the best way to find these roles would be. Seems to be quite a few platforms, if I used one I\u2019d be unsure how to choose between them.\n2) If this would be appropriate for me. I\u2019ve only got 1.5 years of commercial DS experience post-uni, largely designing models and putting models into production.", "author_fullname": "t2_mh632", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions re: freelance DS work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10od4b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675013313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently been laid off from my Data Science role in the UK. Currently looking for some ways to make ends meet whilst I look for another full-time role, and was wondering if anyone had some experience with contract or freelance data science work.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m most intrigued to know:&lt;/p&gt;\n\n&lt;p&gt;1) What the best way to find these roles would be. Seems to be quite a few platforms, if I used one I\u2019d be unsure how to choose between them.\n2) If this would be appropriate for me. I\u2019ve only got 1.5 years of commercial DS experience post-uni, largely designing models and putting models into production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10od4b0", "is_robot_indexable": true, "report_reasons": null, "author": "JxLes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10od4b0/questions_re_freelance_ds_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10od4b0/questions_re_freelance_ds_work/", "subreddit_subscribers": 842562, "created_utc": 1675013313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "FYI I'm still a student so if there's sth I'm missing and/or misunderstanding, do enlightment me on this topic. Esp. from the perspective of practitioners in the real work setting.\n\nWhen it comes to hyperparams tuning, I've always been directed to using GridSearchCV or RandomSearchCV and that's the end of that. However, I've never really felt that those 2 are the best methods as the former seems to be rather arbitrary and the latter, well, simply random. After more research, I found out abt Bayesian optimization and based on my experience using it so far, it's always outperformed GridSearchCV and RandomSearchCV.\n\nIf u're a practitioner in the field, do u use Bayesian optimization for hyperparams tuning or not? Is there perhaps a more practical reason as to why/why not? (e.g. from a computing cost perspective, etc.)? Since GridSearchCV and RandomSearchCV are so prevalent, it appears that they're the go to method for hyperparams tuning altho they're suboptimal compared to Bayesian optimization - even some practitioners I've managed to ask abt the subject actually do know abt Bayesian optimization as a concept but don't rly use it in production.\n\nAppreciate \uff06 thanks for the insights in advance!", "author_fullname": "t2_lp3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hyperparams tuning w/ Bayesian optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oclb7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675020308.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675012052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;FYI I&amp;#39;m still a student so if there&amp;#39;s sth I&amp;#39;m missing and/or misunderstanding, do enlightment me on this topic. Esp. from the perspective of practitioners in the real work setting.&lt;/p&gt;\n\n&lt;p&gt;When it comes to hyperparams tuning, I&amp;#39;ve always been directed to using GridSearchCV or RandomSearchCV and that&amp;#39;s the end of that. However, I&amp;#39;ve never really felt that those 2 are the best methods as the former seems to be rather arbitrary and the latter, well, simply random. After more research, I found out abt Bayesian optimization and based on my experience using it so far, it&amp;#39;s always outperformed GridSearchCV and RandomSearchCV.&lt;/p&gt;\n\n&lt;p&gt;If u&amp;#39;re a practitioner in the field, do u use Bayesian optimization for hyperparams tuning or not? Is there perhaps a more practical reason as to why/why not? (e.g. from a computing cost perspective, etc.)? Since GridSearchCV and RandomSearchCV are so prevalent, it appears that they&amp;#39;re the go to method for hyperparams tuning altho they&amp;#39;re suboptimal compared to Bayesian optimization - even some practitioners I&amp;#39;ve managed to ask abt the subject actually do know abt Bayesian optimization as a concept but don&amp;#39;t rly use it in production.&lt;/p&gt;\n\n&lt;p&gt;Appreciate \uff06 thanks for the insights in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oclb7", "is_robot_indexable": true, "report_reasons": null, "author": "YsrYsl", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oclb7/hyperparams_tuning_w_bayesian_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oclb7/hyperparams_tuning_w_bayesian_optimization/", "subreddit_subscribers": 842562, "created_utc": 1675012052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say I\u2019m trying to increase the proportion of total female customers on my site. If I test 2 landing pages and my target metric is proportion of total purchases that are women, what test should I use? \n\nLet\u2019s say we have the following sample data:\n\nControl: 400 male customers, 600 female customers\n\nTreatment: 350 male customers, 600 female customers\n\nWhat test can I use to test whether the increase in female proportion is statistically significant?", "author_fullname": "t2_azc8nt5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What test to use to test differences in proportions of total?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o1978", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674974798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say I\u2019m trying to increase the proportion of total female customers on my site. If I test 2 landing pages and my target metric is proportion of total purchases that are women, what test should I use? &lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say we have the following sample data:&lt;/p&gt;\n\n&lt;p&gt;Control: 400 male customers, 600 female customers&lt;/p&gt;\n\n&lt;p&gt;Treatment: 350 male customers, 600 female customers&lt;/p&gt;\n\n&lt;p&gt;What test can I use to test whether the increase in female proportion is statistically significant?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o1978", "is_robot_indexable": true, "report_reasons": null, "author": "zsa23761", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o1978/what_test_to_use_to_test_differences_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o1978/what_test_to_use_to_test_differences_in/", "subreddit_subscribers": 842562, "created_utc": 1674974798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When working with large datasets or executing complex operations using pandas, you may experience Out of Memory (OOM) errors or long waiting periods for the results.\n\n[Xorbits](https://github.com/xprobe-inc/xorbits) can be an ideal solution for these issues. Xorbits is a scalable Python data science framework that aims to scale the Python data science stack while keeping the API compatibility. You can get an out-of-box performance gain by changing \\`import pandas as pd\\` to \\`import xorbits.pandas as pd\\`.\n\nCompared with other pandas-like solutions, Xorbits offers stronger performance, simpler deployment, and better API compatibility.\n\nWith TPC-H benchmarks at scale factor 100, Xorbits is 7x faster than Dask. For the benchmark results compared to other pandas-like systems, please visit: [https://xorbits.io/benchmark](https://xorbits.io/benchmark)\n\nhttps://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989\n\nIf you are interested in learning more about Xorbits, please visit our project's Github  for more information: [https://github.com/xprobe-inc/xorbits](https://github.com/xprobe-inc/xorbits)", "author_fullname": "t2_sjfelxlq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A new way to accelerate your data science workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uyavcs2irqea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c90a2aeb13de9bcd562106cfd0869bdde2efe6b8"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5dfcffa915bb9c88044a9990d8a2d6a91753793"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0332d904f1a8d783952949deb04e0d66ab20a848"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82013bf136cdab2a1a24492f7c80e95a705e2018"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9950ac39a34ab5b8d73d77adaef7396f8b6451a"}, {"y": 514, "x": 1080, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08df56cae3ef6206e5a7fb644d532938ccc3e10f"}], "s": {"y": 1120, "x": 2353, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989"}, "id": "uyavcs2irqea1"}}, "name": "t3_10o0djh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674971652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When working with large datasets or executing complex operations using pandas, you may experience Out of Memory (OOM) errors or long waiting periods for the results.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/xprobe-inc/xorbits\"&gt;Xorbits&lt;/a&gt; can be an ideal solution for these issues. Xorbits is a scalable Python data science framework that aims to scale the Python data science stack while keeping the API compatibility. You can get an out-of-box performance gain by changing `import pandas as pd` to `import xorbits.pandas as pd`.&lt;/p&gt;\n\n&lt;p&gt;Compared with other pandas-like solutions, Xorbits offers stronger performance, simpler deployment, and better API compatibility.&lt;/p&gt;\n\n&lt;p&gt;With TPC-H benchmarks at scale factor 100, Xorbits is 7x faster than Dask. For the benchmark results compared to other pandas-like systems, please visit: &lt;a href=\"https://xorbits.io/benchmark\"&gt;https://xorbits.io/benchmark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989\"&gt;https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in learning more about Xorbits, please visit our project&amp;#39;s Github  for more information: &lt;a href=\"https://github.com/xprobe-inc/xorbits\"&gt;https://github.com/xprobe-inc/xorbits&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?auto=webp&amp;v=enabled&amp;s=b4c437d9780f7deea38942e2f71874c4a5792ae0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8a20714e73d397807f6c3406afbc874486db459", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50984ace269a047c9250492e6ed13ddee7237ffb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a082fd5140f7529a4ae937e4136c0c7e0dfa8f01", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9514a20c7b740464677a7063d0823d7dbc6b97b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58e91db6a21bda66ff44ea8af3724eff5fd6b9ca", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f7973ace9a043c8b0c44ab67eb446f16600814", "width": 1080, "height": 540}], "variants": {}, "id": "zluzOfHdaTc_wTtSW5PBzgxataxeTpLBkbFxOxEzruo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o0djh", "is_robot_indexable": true, "report_reasons": null, "author": "CORNMONSTER_2022", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o0djh/a_new_way_to_accelerate_your_data_science_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o0djh/a_new_way_to_accelerate_your_data_science_workflow/", "subreddit_subscribers": 842562, "created_utc": 1674971652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the U.S. and I've enrolled in the WIOWA (Workforce Innovation and Opportunity Act) program since I'm a dislocated worker. I'm interested in getting a cert through UCLA's Extension course program. If you've gotten certs what was your experience?", "author_fullname": "t2_3nbsitw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone gotten a job with a data science certificate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nzuig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674969866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the U.S. and I&amp;#39;ve enrolled in the WIOWA (Workforce Innovation and Opportunity Act) program since I&amp;#39;m a dislocated worker. I&amp;#39;m interested in getting a cert through UCLA&amp;#39;s Extension course program. If you&amp;#39;ve gotten certs what was your experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nzuig", "is_robot_indexable": true, "report_reasons": null, "author": "madlove17", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nzuig/has_anyone_gotten_a_job_with_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nzuig/has_anyone_gotten_a_job_with_a_data_science/", "subreddit_subscribers": 842562, "created_utc": 1674969866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I notice a lot of my research at work ends up taking me to methods in information theory or signal processing. I was wondering what graduate college courses in mathematics would be most helpful to me as a data scientist. I have an undergrad in mathematics with calc, linear algebra, probability and statistics, ODE, analysis, etc. but no PDE, information theory, signal processing or graph theory. I also don\u2019t have any courses in advanced or specific statistics courses such as time series analysis, combinatorics, or Bayesian inference\u2014although I\u2019m familiar with the fundamentals from my undergrad probability courses.\n\nI\u2019m already pretty familiar with most of the models and methods in elements of statistical learning. It\u2019s more about being able to develop or understand novel methods and having a foundational base that prepares me for anything.", "author_fullname": "t2_o711uvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For mathematicians/statisticians: besides calc/stats/linalg, what are the most important (or additive) foundational math courses for data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nvsta", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674956956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I notice a lot of my research at work ends up taking me to methods in information theory or signal processing. I was wondering what graduate college courses in mathematics would be most helpful to me as a data scientist. I have an undergrad in mathematics with calc, linear algebra, probability and statistics, ODE, analysis, etc. but no PDE, information theory, signal processing or graph theory. I also don\u2019t have any courses in advanced or specific statistics courses such as time series analysis, combinatorics, or Bayesian inference\u2014although I\u2019m familiar with the fundamentals from my undergrad probability courses.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m already pretty familiar with most of the models and methods in elements of statistical learning. It\u2019s more about being able to develop or understand novel methods and having a foundational base that prepares me for anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nvsta", "is_robot_indexable": true, "report_reasons": null, "author": "CSCCguy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nvsta/for_mathematiciansstatisticians_besides/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nvsta/for_mathematiciansstatisticians_besides/", "subreddit_subscribers": 842562, "created_utc": 1674956956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Industrial Case Study of GNNs with PyTorch Geometric for Document Understanding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_10oj1id", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_6xfb1ruo", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "January Town Hall - Fetch Case Study", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "author_name": "PyTorch Geometric", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M1y3xzeqdsg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@pytorchgeometric"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10oj1id", "height": 200}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-JQm0v2trxmkKneKI-KiGRmgf5ZL6Rc_MolzNQvvxHA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "GeometricDeepLearning", "selftext": "", "author_fullname": "t2_6xfb1ruo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Industrial Case Study of GNNs with PyTorch Geometric for Document Understanding", "link_flair_richtext": [], "subreddit_name_prefixed": "r/GeometricDeepLearning", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10nqk3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "January Town Hall - Fetch Case Study", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "author_name": "PyTorch Geometric", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M1y3xzeqdsg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@pytorchgeometric"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10nqk3v", "height": 200}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-JQm0v2trxmkKneKI-KiGRmgf5ZL6Rc_MolzNQvvxHA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "created": 1674942560.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/M1y3xzeqdsg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?auto=webp&amp;v=enabled&amp;s=730af83b5a1c05700710ea8cf707c2310718d9ed", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cde16cffc45417e7145c00d558d2301a198a6f98", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f38bb6d1ae6b7c1e19968e59a6ecfe937d6ea98f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a70d1f5f11e00f40e484889f69bf1624193bcc4", "width": 320, "height": 240}], "variants": {}, "id": "ThGq7Wy0qfea4QAPAoMjKOV9zKw26juVTi1O81eqou8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_27mqix", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nqk3v", "is_robot_indexable": true, "report_reasons": null, "author": "how-it-is-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/GeometricDeepLearning/comments/10nqk3v/industrial_case_study_of_gnns_with_pytorch/", "parent_whitelist_status": null, "stickied": false, "url": "https://youtu.be/M1y3xzeqdsg", "subreddit_subscribers": 712, "created_utc": 1674942560.0, "num_crossposts": 4, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "January Town Hall - Fetch Case Study", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "author_name": "PyTorch Geometric", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M1y3xzeqdsg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@pytorchgeometric"}}, "is_video": false}], "created": 1675027368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/M1y3xzeqdsg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?auto=webp&amp;v=enabled&amp;s=730af83b5a1c05700710ea8cf707c2310718d9ed", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cde16cffc45417e7145c00d558d2301a198a6f98", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f38bb6d1ae6b7c1e19968e59a6ecfe937d6ea98f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/J-UXXzmHhTFtT4enSBi6kZFOMwunQL8R2HPH8EmbgXM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a70d1f5f11e00f40e484889f69bf1624193bcc4", "width": 320, "height": 240}], "variants": {}, "id": "ThGq7Wy0qfea4QAPAoMjKOV9zKw26juVTi1O81eqou8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oj1id", "is_robot_indexable": true, "report_reasons": null, "author": "how-it-is-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10nqk3v", "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oj1id/industrial_case_study_of_gnns_with_pytorch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/M1y3xzeqdsg", "subreddit_subscribers": 842562, "created_utc": 1675027368.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "January Town Hall - Fetch Case Study", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/M1y3xzeqdsg?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"January Town Hall - Fetch Case Study\"&gt;&lt;/iframe&gt;", "author_name": "PyTorch Geometric", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/M1y3xzeqdsg/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@pytorchgeometric"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a basic foundation in in subject and I have even developed my own code to generate some interactive 3D graph networks however I also recognize that I am no expert in the subject so I'm looking for some reccomendations on some good books for self study. \n\n&amp;#x200B;\n\nIdeally, the book would focus more on the math and logic as I can develop the code to implement this myself and realistically the applications at work call for something more powerful than networkX.", "author_fullname": "t2_4cx92o4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Recommendations for Network Graphs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ob7xw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675008596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a basic foundation in in subject and I have even developed my own code to generate some interactive 3D graph networks however I also recognize that I am no expert in the subject so I&amp;#39;m looking for some reccomendations on some good books for self study. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ideally, the book would focus more on the math and logic as I can develop the code to implement this myself and realistically the applications at work call for something more powerful than networkX.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ob7xw", "is_robot_indexable": true, "report_reasons": null, "author": "theRealDavidDavis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ob7xw/book_recommendations_for_network_graphs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ob7xw/book_recommendations_for_network_graphs/", "subreddit_subscribers": 842562, "created_utc": 1675008596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI am working on a project trying to analyze ride-sharing to and from airports.  I have emailed airports and ridesharing companies and searched Kaggle and other sites.  Now I'm looking for some more information/advice.\n\nDoes anyone have any suggestions on where I could find ridesharing data? Or where I could scrape it from? Or anyone that I could contact.  Or any other subreddits I should try?\n\nThanks!", "author_fullname": "t2_10sshp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airport ridesharing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o9k47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675004323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I am working on a project trying to analyze ride-sharing to and from airports.  I have emailed airports and ridesharing companies and searched Kaggle and other sites.  Now I&amp;#39;m looking for some more information/advice.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions on where I could find ridesharing data? Or where I could scrape it from? Or anyone that I could contact.  Or any other subreddits I should try?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o9k47", "is_robot_indexable": true, "report_reasons": null, "author": "frankOFWGKTA", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o9k47/airport_ridesharing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o9k47/airport_ridesharing_data/", "subreddit_subscribers": 842562, "created_utc": 1675004323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I saw a poll on r/cscareerquestionsEU which asked the number of weeks SWEs get as vacation in Switzerland. Most people replied 5 and 6 weeks. I guess there's a lot of declared holidays too (~30 days in a year). Unlimited sick leave is common across EU I guess. \n\nWhich countries have good pay and the highest possibility that I can take a 1 month long block leave (bring completely out of reach)? \n\nAnd which countries or organizations have the highest amount of leaves in general that people do end up taking?  I'm going to be doing an MS in AI/DS soon in the US. But can apply to some Unis in EU as well. I'm learning that US wouldn't let me take much leaves. \n\nAlso any other Careers that let you take 3 weeks to longer than 2 month leaves?\ud83d\ude2c", "author_fullname": "t2_2p7ddtjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which countries /orgz let you take more than 1 month long leaves?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o93j1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675003102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a poll on &lt;a href=\"/r/cscareerquestionsEU\"&gt;r/cscareerquestionsEU&lt;/a&gt; which asked the number of weeks SWEs get as vacation in Switzerland. Most people replied 5 and 6 weeks. I guess there&amp;#39;s a lot of declared holidays too (~30 days in a year). Unlimited sick leave is common across EU I guess. &lt;/p&gt;\n\n&lt;p&gt;Which countries have good pay and the highest possibility that I can take a 1 month long block leave (bring completely out of reach)? &lt;/p&gt;\n\n&lt;p&gt;And which countries or organizations have the highest amount of leaves in general that people do end up taking?  I&amp;#39;m going to be doing an MS in AI/DS soon in the US. But can apply to some Unis in EU as well. I&amp;#39;m learning that US wouldn&amp;#39;t let me take much leaves. &lt;/p&gt;\n\n&lt;p&gt;Also any other Careers that let you take 3 weeks to longer than 2 month leaves?\ud83d\ude2c&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o93j1", "is_robot_indexable": true, "report_reasons": null, "author": "anotheraccount97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o93j1/which_countries_orgz_let_you_take_more_than_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o93j1/which_countries_orgz_let_you_take_more_than_1/", "subreddit_subscribers": 842562, "created_utc": 1675003102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "SVMs were covered quite poorly in my Machine Learning course last semester, the teacher quickly glossed over the maths, only ever mentioning the key bits of it like \"Langrangian\" or \"Kuhn-Tucker conditions\". Most resources I referred just went \"the math is out of the scope of this textbook\"\n\nNow I still have no clue what or how SVMs find the Maximal Margin Hyperplane. I am looking for resources that help me understand. I have no problem sinking some time into learning the maths (I believe it's called optimization theory?) behind it either.\n\nThanks!", "author_fullname": "t2_1fe83wwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources for covering SVMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o8s1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675002217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SVMs were covered quite poorly in my Machine Learning course last semester, the teacher quickly glossed over the maths, only ever mentioning the key bits of it like &amp;quot;Langrangian&amp;quot; or &amp;quot;Kuhn-Tucker conditions&amp;quot;. Most resources I referred just went &amp;quot;the math is out of the scope of this textbook&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Now I still have no clue what or how SVMs find the Maximal Margin Hyperplane. I am looking for resources that help me understand. I have no problem sinking some time into learning the maths (I believe it&amp;#39;s called optimization theory?) behind it either.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o8s1t", "is_robot_indexable": true, "report_reasons": null, "author": "HyperKingK", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o8s1t/good_resources_for_covering_svms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o8s1t/good_resources_for_covering_svms/", "subreddit_subscribers": 842562, "created_utc": 1675002217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there, \n\nI have 2 semesters left to get graduated in economics and so far the subjects that I enjoyed the most have been econometrics and statistics. In fact, I just finished a DS minor this semester which was pretty enjoyable for me. \n\nThe thing is, I'm starting to look for bootcamps or self-taught so I could start developing my career in DS as soon as possible, but I'm not sure if this is the right choice. To make it clear, I would 100% finish the degree but maybe not as my first priority if I could get a DS job.\n\nWould you recommend finishing my degree and then focusing on DS or is it a good choice to prioritize learning DS and trying to get a job?\n\nThanks in advance,", "author_fullname": "t2_s3ah602a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I finish my economics degree asap or focus on learning DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o7npg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674998955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, &lt;/p&gt;\n\n&lt;p&gt;I have 2 semesters left to get graduated in economics and so far the subjects that I enjoyed the most have been econometrics and statistics. In fact, I just finished a DS minor this semester which was pretty enjoyable for me. &lt;/p&gt;\n\n&lt;p&gt;The thing is, I&amp;#39;m starting to look for bootcamps or self-taught so I could start developing my career in DS as soon as possible, but I&amp;#39;m not sure if this is the right choice. To make it clear, I would 100% finish the degree but maybe not as my first priority if I could get a DS job.&lt;/p&gt;\n\n&lt;p&gt;Would you recommend finishing my degree and then focusing on DS or is it a good choice to prioritize learning DS and trying to get a job?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o7npg", "is_robot_indexable": true, "report_reasons": null, "author": "Pitiful-Carpet8141", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o7npg/should_i_finish_my_economics_degree_asap_or_focus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o7npg/should_i_finish_my_economics_degree_asap_or_focus/", "subreddit_subscribers": 842562, "created_utc": 1674998955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks,   \n\n\n Currently working through the IBM DS and Google Analytics certificate. I am a complete rookie in DS.\n\nI am interested in where linguistics and  behavioral economics intersect with data science in terms of the types of jobs/research fields to target as it seems like 'Data Scientist' is somewhat of a catch all term for HR departments. \n\nIn terms of a following a learning pathway, employers (HR?) seem to all look for a degree, however online postgrad and BsS computer science course seem overpriced and, outside of data science specific programs, not as good as combining bootcamps, certificates and other online learning routes. Is this the case?   \n\n\nIn terms of building a portfolio of work, or a learning journal that can be linked to CV, does anyone have any recommendations?   \n\n\nMany thanks for any help!", "author_fullname": "t2_6d9ki34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Learning Pathway(s) and where personal interests intersect with DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nzin7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674968739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,   &lt;/p&gt;\n\n&lt;p&gt;Currently working through the IBM DS and Google Analytics certificate. I am a complete rookie in DS.&lt;/p&gt;\n\n&lt;p&gt;I am interested in where linguistics and  behavioral economics intersect with data science in terms of the types of jobs/research fields to target as it seems like &amp;#39;Data Scientist&amp;#39; is somewhat of a catch all term for HR departments. &lt;/p&gt;\n\n&lt;p&gt;In terms of a following a learning pathway, employers (HR?) seem to all look for a degree, however online postgrad and BsS computer science course seem overpriced and, outside of data science specific programs, not as good as combining bootcamps, certificates and other online learning routes. Is this the case?   &lt;/p&gt;\n\n&lt;p&gt;In terms of building a portfolio of work, or a learning journal that can be linked to CV, does anyone have any recommendations?   &lt;/p&gt;\n\n&lt;p&gt;Many thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nzin7", "is_robot_indexable": true, "report_reasons": null, "author": "SilentWitness13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nzin7/advice_on_learning_pathways_and_where_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nzin7/advice_on_learning_pathways_and_where_personal/", "subreddit_subscribers": 842562, "created_utc": 1674968739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Inspired by r/cscareerquestions.\n\nThat post seems to be getting a lot of attention and helpful answers. Just trying to do the same for the DS community.", "author_fullname": "t2_bv171ji2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most in demand skills of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ohsog", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675024459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Inspired by &lt;a href=\"/r/cscareerquestions\"&gt;r/cscareerquestions&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;That post seems to be getting a lot of attention and helpful answers. Just trying to do the same for the DS community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ohsog", "is_robot_indexable": true, "report_reasons": null, "author": "quite--average", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ohsog/what_are_the_most_in_demand_skills_of_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ohsog/what_are_the_most_in_demand_skills_of_2023/", "subreddit_subscribers": 842562, "created_utc": 1675024459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3uqo5boy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3 Smart Steps to Junior Data Analyst/Scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ocnmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1675012211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "becomingnerd.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://becomingnerd.com/blogs/data-analyst.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ocnmx", "is_robot_indexable": true, "report_reasons": null, "author": "P_01y", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ocnmx/3_smart_steps_to_junior_data_analystscientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://becomingnerd.com/blogs/data-analyst.html", "subreddit_subscribers": 842562, "created_utc": 1675012211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I encountered a question about Kernel SVM in a interview test to a internship, but I am not certain about the answer. Can anyone try to answer it?\n\nTo use a Gaussian kernel SVM, we usually normaliz the feature. Which one or few of following options is (are) True?\n\na. \uff08I don't quite remember this option. This one I pretty sure is True, but next two I am uncertain about. Can anyone help me remember it?)\nb. Sometimes some features cannot be normalized like categorical feature.\nc. Gaussian kernel SVM cannot be done without feature normalization.", "author_fullname": "t2_5aabbadw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions about kernel SVM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o86lw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675000543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I encountered a question about Kernel SVM in a interview test to a internship, but I am not certain about the answer. Can anyone try to answer it?&lt;/p&gt;\n\n&lt;p&gt;To use a Gaussian kernel SVM, we usually normaliz the feature. Which one or few of following options is (are) True?&lt;/p&gt;\n\n&lt;p&gt;a. \uff08I don&amp;#39;t quite remember this option. This one I pretty sure is True, but next two I am uncertain about. Can anyone help me remember it?)\nb. Sometimes some features cannot be normalized like categorical feature.\nc. Gaussian kernel SVM cannot be done without feature normalization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o86lw", "is_robot_indexable": true, "report_reasons": null, "author": "ArchibaldChain", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o86lw/interview_questions_about_kernel_svm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o86lw/interview_questions_about_kernel_svm/", "subreddit_subscribers": 842562, "created_utc": 1675000543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "HI folks\n\n&amp;#x200B;\n\nI am toying with the idea of a OMSCS vs MS DS in UT Austin or MS DS from Colorado, Boulder. I am a bit worried about being weak (have logn forgotten my programming skills) in Data Structures/Algorithms and so have some conerns on doing OMSCS. What would this group advise?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_6m1wqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OMSCS in GaTech vs MS DS in UT Austin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o60t6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674993326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI folks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am toying with the idea of a OMSCS vs MS DS in UT Austin or MS DS from Colorado, Boulder. I am a bit worried about being weak (have logn forgotten my programming skills) in Data Structures/Algorithms and so have some conerns on doing OMSCS. What would this group advise?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o60t6", "is_robot_indexable": true, "report_reasons": null, "author": "karraju", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o60t6/omscs_in_gatech_vs_ms_ds_in_ut_austin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o60t6/omscs_in_gatech_vs_ms_ds_in_ut_austin/", "subreddit_subscribers": 842562, "created_utc": 1674993326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! So I wasn\u2019t even intending to go for grad school right after my dual BS CS BS DS program, but I found out I would qualify for a full tuition and fee scholarship for UMSI\u2019s MSI program at Michigan. I\u2019d do the big data analytics curriculum full time and finish in the standard 2 years with a required internship in the summer between the first and second year.\n\nI\u2019m pretty much already fully invested as it\u2019s a free master of science at a top 5 public uni, so I thought I\u2019d ask what y\u2019all think of the situation, particularly the opportunity cost of delaying full professional entry into the field by 2 more years for an at worst tangentially-related graduate degree. Thanks!\n\nSome other notes: I\u2019d likely be able to fund living expenses comfortably the entire time, and I\u2019m a nontraditional student finishing undergrad in late 20s with some internships as a data analyst and \u201cmachine learning engineer\u201d (more like data engineering bleh)", "author_fullname": "t2_4fug1pf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going for the MSI at UMSI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ofdd7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675018711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! So I wasn\u2019t even intending to go for grad school right after my dual BS CS BS DS program, but I found out I would qualify for a full tuition and fee scholarship for UMSI\u2019s MSI program at Michigan. I\u2019d do the big data analytics curriculum full time and finish in the standard 2 years with a required internship in the summer between the first and second year.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m pretty much already fully invested as it\u2019s a free master of science at a top 5 public uni, so I thought I\u2019d ask what y\u2019all think of the situation, particularly the opportunity cost of delaying full professional entry into the field by 2 more years for an at worst tangentially-related graduate degree. Thanks!&lt;/p&gt;\n\n&lt;p&gt;Some other notes: I\u2019d likely be able to fund living expenses comfortably the entire time, and I\u2019m a nontraditional student finishing undergrad in late 20s with some internships as a data analyst and \u201cmachine learning engineer\u201d (more like data engineering bleh)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ofdd7", "is_robot_indexable": true, "report_reasons": null, "author": "baeristaboy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ofdd7/going_for_the_msi_at_umsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ofdd7/going_for_the_msi_at_umsi/", "subreddit_subscribers": 842562, "created_utc": 1675018711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, aroung where i live there's a university that offer this degree. I read a couple of question about CS vs DS degree, the main issue is that in my city no ones offer a degree in computer science so i have only one option.\n\nDo you think i could be in troubles for get a job if i graduated of DS?\n\nI'm currently work as software developer without degree and i want to transition to Data engineer and after graduate i will try to get a job as DS.", "author_fullname": "t2_354db2jm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on bachelor degree in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10odam1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675013727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, aroung where i live there&amp;#39;s a university that offer this degree. I read a couple of question about CS vs DS degree, the main issue is that in my city no ones offer a degree in computer science so i have only one option.&lt;/p&gt;\n\n&lt;p&gt;Do you think i could be in troubles for get a job if i graduated of DS?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently work as software developer without degree and i want to transition to Data engineer and after graduate i will try to get a job as DS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10odam1", "is_robot_indexable": true, "report_reasons": null, "author": "Snowi5", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10odam1/thoughts_on_bachelor_degree_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10odam1/thoughts_on_bachelor_degree_in_data_science/", "subreddit_subscribers": 842562, "created_utc": 1675013727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_nq03g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What if Patrick Bateman was a Data Scientist? An AI-Generated Video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10ntk65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b8m003GKqSwotrtcvTdv3eneh_0QT7UlU25gju0jPhY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674950455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@dreamferus/what-if-patrick-bateman-was-a-data-scientist-an-ai-generated-video-342003f60914?sk=e7426d5b5f46ab4a269d7014efa9e22c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?auto=webp&amp;v=enabled&amp;s=2f77d38323d6f16625e9b7d65953de579422a305", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5f0b778740348927c9184686544a4afc8ef9a72", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbe077c31f3e0a224165c9d0f095b6354febdd55", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=178d315a67dc67490a2627c1fef6b69e7acfbcbd", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d5b32cd7c6a2ea3b14a9bfb07f6720cca8fb6cb", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15abf2a44025a73cfa07a2860888218e6b51609f", "width": 960, "height": 960}], "variants": {}, "id": "sU_gduBY2tjcuvQH2lrSYWUOM-XygNpqWTHPKurlPPk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ntk65", "is_robot_indexable": true, "report_reasons": null, "author": "SupPandaHugger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ntk65/what_if_patrick_bateman_was_a_data_scientist_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@dreamferus/what-if-patrick-bateman-was-a-data-scientist-an-ai-generated-video-342003f60914?sk=e7426d5b5f46ab4a269d7014efa9e22c", "subreddit_subscribers": 842562, "created_utc": 1674950455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi people, I'm looking for a data scientist to partner with on a side project I'm working. I'd love if the person working on also part time like me. Building a free product for now so no money involve but open to paid consultation if you feel like you can help. An example on what I am trying to build: \n\n  \n[https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view](https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view)", "author_fullname": "t2_bep1zcu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking from DS background for a side project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oa3gg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675005680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people, I&amp;#39;m looking for a data scientist to partner with on a side project I&amp;#39;m working. I&amp;#39;d love if the person working on also part time like me. Building a free product for now so no money involve but open to paid consultation if you feel like you can help. An example on what I am trying to build: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view\"&gt;https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?auto=webp&amp;v=enabled&amp;s=a9cf0132935222d3d1d682e134698607dd6846ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2fc6749c30f7f0c93f9d546ea455294caeb6d3d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c474508f89660f93d33b47729236e4c4dd7cfbfb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f808c3e8e1d1bc362c97a4ac73bb3e2c77902603", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d377ab2f07764d40cd5a674ca9d8213be7a1281", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac1cf65fa85d69d2d92c7990894a52a423f4aaa6", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Pd04xeGYK1vzgwUu0BOzRYjBKooSnBPJjgOigHWNYHM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa5de8d2251af7d628786ae5b3dfb399fc2663cd", "width": 1080, "height": 567}], "variants": {}, "id": "BtWRoHllG4aTwWj0PmonnheNEdefQ4Hx8FO5GVpx4gs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oa3gg", "is_robot_indexable": true, "report_reasons": null, "author": "ChestAgitated5206", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oa3gg/looking_from_ds_background_for_a_side_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oa3gg/looking_from_ds_background_for_a_side_project/", "subreddit_subscribers": 842562, "created_utc": 1675005680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8cbs8tny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "hi guys require instagram dataset for building a hashtag generator for self learning. Please guide me from where I can get this. Thanks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oathb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675007581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oathb", "is_robot_indexable": true, "report_reasons": null, "author": "rsinda", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oathb/hi_guys_require_instagram_dataset_for_building_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oathb/hi_guys_require_instagram_dataset_for_building_a/", "subreddit_subscribers": 842562, "created_utc": 1675007581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an encoder model which was working fine with single channel 1024,1024 images, I'm trying to patch the original images (mega pixel images) to 256, 256, 64 images. I've changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I'm getting the following error with tape.gradient:\n\n    2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn('resource_tracker: There appear to be %d '                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n\nMy code is as below\n\n    class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n        super(encoder, self).__init__()     #encoder Module\n        self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n        self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding='same',activation='relu')\n        self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding='same',activation='relu')\n        self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding='same',activation='relu')\n        self.conv_5 = keras.layers.BatchNormalization()\n        self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding='same',activation='relu')\n        self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_9 = keras.layers.BatchNormalization()\n        self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')\n        \n        def call(self,inputs,training = True):\n            x = self.input_cnn(inputs)\n            x = self.conv_1(x)\n            x = self.conv_2(x)\n            x = self.conv_3(x)\n            x = self.conv_4(x)\n            if training == True:\n                x = self.conv_5(x,training = True)\n            else:\n                x = self.conv_5(x,training = False)\n            x = self.conv_6(x)\n            x = self.conv_7(x)\n            x = self.conv_8(x)\n            if training == True:\n                x = self.conv_9(x,training = True)\n            else:\n                x = self.conv_9(x,training = False)\n            x = self.conv_10(x)\n            return x\n\nsize 0 is 256 size 1 is 256 size 2 is 64\n\nTrain\\_step from main model:\n\n \n\n    def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n        super(BCDClassifier, self).__init__()         \n        self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n        self.encode = encoder(size)\n        self.flatten = keras.layers.Flatten()\n        self.concat = keras.layers.Concatenate(axis = 1)\n        self.classify = classifier(32)\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n        self.acc_tracker = metric\n        self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = 'micro')\n        self.sk_metric_acc = accuracy_score\n        self.sk_metric_f1 = f1_score\n        self.acc_history = []\n        self.loss_history = []\n        self.f1_history = []\n        \n        def call(self, cat_batch, view_batch, images_batch, training = True):\n            x1 = self.encode(images_batch,training)\n            x2 = self.input_cat(cat_batch)\n            x1 = self.flatten(x1)\n            x12 = self.concat([x1,x2])\n            x12 = self.classify(x12)\n            return x12\n    \n        def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n            with tf.GradientTape() as tape:\n                logits = self(cat_batch, views_batch, images_batch,training)\n                loss_value = self.loss_fn(target_batch, logits)\n    \n            grads = tape.gradient(loss_value, self.trainable_weights)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n            self.loss_tracker.update_state(loss_value)\n            pred = []\n            target = []\n            threshold = 0.5\n            for val in logits.numpy():\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                if v_2 &gt; threshold:\n                                    pred.append(1.0)\n                                else:\n                                    pred.append(0.0)\n                        else:\n                            if v_1 &gt; threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                else:\n                    if val &gt; threshold:\n                        pred.append(1.0)\n                    else:\n                        pred.append(0.0)\n            for val in target_batch:\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                target.append(v_2)\n                        else:\n                            target.append(v_1)\n                else:\n                    target.append(val)\n            acc = self.sk_metric_acc(target,pred)\n            f1 = self.sk_metric_f1(target,pred)\n            #self.f1_tracker.update_state(target_batch,logits)\n            return {\"Loss\": self.loss_tracker.result(), \"Accuracy\": acc, 'F1-score':f1}\n\nCan someone please help me figure out this error?", "author_fullname": "t2_9xa4pbdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can keeping channels more than '3' in images crash CNNs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o6gpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674994895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an encoder model which was working fine with single channel 1024,1024 images, I&amp;#39;m trying to patch the original images (mega pixel images) to 256, 256, 64 images. I&amp;#39;ve changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I&amp;#39;m getting the following error with tape.gradient:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn(&amp;#39;resource_tracker: There appear to be %d &amp;#39;                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, &amp;#39;The system cannot find the path specified&amp;#39;)                                    warnings.warn(&amp;#39;resource_tracker: %s: %r&amp;#39; % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, &amp;#39;The system cannot find the path specified&amp;#39;)                                    warnings.warn(&amp;#39;resource_tracker: %s: %r&amp;#39; % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My code is as below&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n    super(encoder, self).__init__()     #encoder Module\n    self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n    self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_5 = keras.layers.BatchNormalization()\n    self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_9 = keras.layers.BatchNormalization()\n    self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n\n    def call(self,inputs,training = True):\n        x = self.input_cnn(inputs)\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        x = self.conv_3(x)\n        x = self.conv_4(x)\n        if training == True:\n            x = self.conv_5(x,training = True)\n        else:\n            x = self.conv_5(x,training = False)\n        x = self.conv_6(x)\n        x = self.conv_7(x)\n        x = self.conv_8(x)\n        if training == True:\n            x = self.conv_9(x,training = True)\n        else:\n            x = self.conv_9(x,training = False)\n        x = self.conv_10(x)\n        return x\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;size 0 is 256 size 1 is 256 size 2 is 64&lt;/p&gt;\n\n&lt;p&gt;Train_step from main model:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n    super(BCDClassifier, self).__init__()         \n    self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n    self.encode = encoder(size)\n    self.flatten = keras.layers.Flatten()\n    self.concat = keras.layers.Concatenate(axis = 1)\n    self.classify = classifier(32)\n    self.optimizer = optimizer\n    self.loss_fn = loss_fn\n    self.loss_tracker = keras.metrics.Mean(name=&amp;quot;loss&amp;quot;)\n    self.acc_tracker = metric\n    self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = &amp;#39;micro&amp;#39;)\n    self.sk_metric_acc = accuracy_score\n    self.sk_metric_f1 = f1_score\n    self.acc_history = []\n    self.loss_history = []\n    self.f1_history = []\n\n    def call(self, cat_batch, view_batch, images_batch, training = True):\n        x1 = self.encode(images_batch,training)\n        x2 = self.input_cat(cat_batch)\n        x1 = self.flatten(x1)\n        x12 = self.concat([x1,x2])\n        x12 = self.classify(x12)\n        return x12\n\n    def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n        with tf.GradientTape() as tape:\n            logits = self(cat_batch, views_batch, images_batch,training)\n            loss_value = self.loss_fn(target_batch, logits)\n\n        grads = tape.gradient(loss_value, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.loss_tracker.update_state(loss_value)\n        pred = []\n        target = []\n        threshold = 0.5\n        for val in logits.numpy():\n            if isinstance(val,np.ndarray):\n                for v_1 in val:\n                    if isinstance(v_1,np.ndarray):\n                        for v_2 in v_1:\n                            if v_2 &amp;gt; threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                    else:\n                        if v_1 &amp;gt; threshold:\n                            pred.append(1.0)\n                        else:\n                            pred.append(0.0)\n            else:\n                if val &amp;gt; threshold:\n                    pred.append(1.0)\n                else:\n                    pred.append(0.0)\n        for val in target_batch:\n            if isinstance(val,np.ndarray):\n                for v_1 in val:\n                    if isinstance(v_1,np.ndarray):\n                        for v_2 in v_1:\n                            target.append(v_2)\n                    else:\n                        target.append(v_1)\n            else:\n                target.append(val)\n        acc = self.sk_metric_acc(target,pred)\n        f1 = self.sk_metric_f1(target,pred)\n        #self.f1_tracker.update_state(target_batch,logits)\n        return {&amp;quot;Loss&amp;quot;: self.loss_tracker.result(), &amp;quot;Accuracy&amp;quot;: acc, &amp;#39;F1-score&amp;#39;:f1}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Can someone please help me figure out this error?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6gpv", "is_robot_indexable": true, "report_reasons": null, "author": "jhanjeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o6gpv/can_keeping_channels_more_than_3_in_images_crash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o6gpv/can_keeping_channels_more_than_3_in_images_crash/", "subreddit_subscribers": 842562, "created_utc": 1674994895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1jg4zv3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to educate myself using online resources to get a job as a junior data scientist with no prior background in the field? If so, I would really appreciate any resource that can be shared. Thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o49lr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674986372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o49lr", "is_robot_indexable": true, "report_reasons": null, "author": "Keep_learning88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o49lr/is_it_possible_to_educate_myself_using_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o49lr/is_it_possible_to_educate_myself_using_online/", "subreddit_subscribers": 842562, "created_utc": 1674986372.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}