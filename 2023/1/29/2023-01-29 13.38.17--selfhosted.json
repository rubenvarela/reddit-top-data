{"kind": "Listing", "data": {"after": "t3_10o0lss", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Howdy all,\n\nThe Repo has the most up-to-date info @ https://github.com/McCloudS/subgen.  Sorry for the poor Reddit formatting, Github is a bit cleaner.\n\n\nThis is a project I've had running for a bit, then cleaned up for 'release' while the kids were sleeping.  It's more of a POC, piece of crap, or a proof of concept.  This was also my first ever Python usage.\n\n\n**What is this?**\n\nThis is a half-assed attempt of transcribing subtitles (.srt) from your personal media in a Plex server using a CPU.  It is currently reliant on Tautulli for webhooks from Plex.  Why? During my limited testing, Plex was VERY sporadically actually sending out their webhooks using their built-in functionality (https://support.plex.tv/articles/115002267687-webhooks).  Tautulli gave a little bit more functionality, and for my use case, didn't require doing a bunch of Plex API calls because their webhooks had all the functionality I needed.  This uses whisper.cpp which is an implementation of OpenAI's Whisper model to use CPUs (Do your own research!).  While CPUs obviously aren't super efficient at this, but my server sits idle 99% of the time, so this worked great for me.  \n\n**Why?**\n\nHonestly, I built this for me, but saw the utility in other people maybe using it.  This works well for my use case.  Since having children, I'm either deaf or wanting to have everything quiet.  We watch EVERYTHING with subtitles now, and I feel like I can't even understand the show without them.  I use Bazaar to auto-download subtitles, and gap fill with Plex's built-in capability.  This is for everything else.  Some shows just won't have subtitles available for some reason or another, or in some cases on my H265 media, they are wildly out of sync. \n\n**What can it do?**\n\n* Create .srt subtitles when a SINGLE media file is added or played via Plex which triggers off of Tautulli webhooks.  \n\n\n**How do I set it up?**\n\nYou'll need working knowledge of Docker-compose.  I also added very loose instructions to run without Docker.  Check the Github above.  \n\n\n**What are the limitations?**\n\n* If Plex adds multiple shows (like a season pack), it will fail to process subtitles.  It is reliant on a SINGLE file to accurately work now.\n* Long pauses/silence behave strangely.  It will likely show the previous or next words during long gaps of silence.  \n* I made it and know nothing about formal deployment for python coding.  \n* There is no 'wrapper' for python for whisper.cpp at this point, so I'm just using subprocess.call.  \n* Obviously, it won't be perfect, but we find the transcription goofs amusing.  \n\n\n**What's next?**\n\nI'm hoping someone that is much more skilled than I, to use this as a pushing off point to make this better.  In a perfect world, this would integrate with Plex, Sonarr, Radarr, or Bazaar.  Bazaar tracks failed subtitle downloads, I originally wanted to utilize its API, but decided on my current solution for simplicity.  \n\n\n**TLDR:  Someone else use this idea (not the code!) as a jumping off point.**. \n\n\n**Additional reading:**. \n\n\nhttps://github.com/ggerganov/whisper.cpp/issues/89 (Benchmarks)\n\nhttps://github.com/openai/whisper/discussions/454 (Whisper CPU implementation)\n\nhttps://github.com/openai/whisper (Original OpenAI project)\n\nhttps://en.wikipedia.org/wiki/List_of_ISO_639-1_codes (2 letter subtitle codes)\n\n**Credits:**   \n\n\nWhisper.cpp (https://github.com/ggerganov/whisper.cpp)\n\nWebhook_listener (https://pypi.org/project/Webhook-Listener)\n\nTautulli (https://tautulli.com)\n\nGoogle\n\nffmpeg", "author_fullname": "t2_43rhv", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Subgen - Autogen Plex Subtitles using Tautulli and Whisper OpenAI!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "release", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nlc4h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 206, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Release", "can_mod_post": false, "score": 206, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1674944490.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674929213.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy all,&lt;/p&gt;\n\n&lt;p&gt;The Repo has the most up-to-date info @ &lt;a href=\"https://github.com/McCloudS/subgen\"&gt;https://github.com/McCloudS/subgen&lt;/a&gt;.  Sorry for the poor Reddit formatting, Github is a bit cleaner.&lt;/p&gt;\n\n&lt;p&gt;This is a project I&amp;#39;ve had running for a bit, then cleaned up for &amp;#39;release&amp;#39; while the kids were sleeping.  It&amp;#39;s more of a POC, piece of crap, or a proof of concept.  This was also my first ever Python usage.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a half-assed attempt of transcribing subtitles (.srt) from your personal media in a Plex server using a CPU.  It is currently reliant on Tautulli for webhooks from Plex.  Why? During my limited testing, Plex was VERY sporadically actually sending out their webhooks using their built-in functionality (&lt;a href=\"https://support.plex.tv/articles/115002267687-webhooks\"&gt;https://support.plex.tv/articles/115002267687-webhooks&lt;/a&gt;).  Tautulli gave a little bit more functionality, and for my use case, didn&amp;#39;t require doing a bunch of Plex API calls because their webhooks had all the functionality I needed.  This uses whisper.cpp which is an implementation of OpenAI&amp;#39;s Whisper model to use CPUs (Do your own research!).  While CPUs obviously aren&amp;#39;t super efficient at this, but my server sits idle 99% of the time, so this worked great for me.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Honestly, I built this for me, but saw the utility in other people maybe using it.  This works well for my use case.  Since having children, I&amp;#39;m either deaf or wanting to have everything quiet.  We watch EVERYTHING with subtitles now, and I feel like I can&amp;#39;t even understand the show without them.  I use Bazaar to auto-download subtitles, and gap fill with Plex&amp;#39;s built-in capability.  This is for everything else.  Some shows just won&amp;#39;t have subtitles available for some reason or another, or in some cases on my H265 media, they are wildly out of sync. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What can it do?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create .srt subtitles when a SINGLE media file is added or played via Plex which triggers off of Tautulli webhooks.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;How do I set it up?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;ll need working knowledge of Docker-compose.  I also added very loose instructions to run without Docker.  Check the Github above.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What are the limitations?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If Plex adds multiple shows (like a season pack), it will fail to process subtitles.  It is reliant on a SINGLE file to accurately work now.&lt;/li&gt;\n&lt;li&gt;Long pauses/silence behave strangely.  It will likely show the previous or next words during long gaps of silence.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;I made it and know nothing about formal deployment for python coding.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;There is no &amp;#39;wrapper&amp;#39; for python for whisper.cpp at this point, so I&amp;#39;m just using subprocess.call.&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;Obviously, it won&amp;#39;t be perfect, but we find the transcription goofs amusing.&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s next?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping someone that is much more skilled than I, to use this as a pushing off point to make this better.  In a perfect world, this would integrate with Plex, Sonarr, Radarr, or Bazaar.  Bazaar tracks failed subtitle downloads, I originally wanted to utilize its API, but decided on my current solution for simplicity.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR:  Someone else use this idea (not the code!) as a jumping off point.&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Additional reading:&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ggerganov/whisper.cpp/issues/89\"&gt;https://github.com/ggerganov/whisper.cpp/issues/89&lt;/a&gt; (Benchmarks)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/openai/whisper/discussions/454\"&gt;https://github.com/openai/whisper/discussions/454&lt;/a&gt; (Whisper CPU implementation)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/openai/whisper\"&gt;https://github.com/openai/whisper&lt;/a&gt; (Original OpenAI project)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\"&gt;https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes&lt;/a&gt; (2 letter subtitle codes)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Credits:&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;Whisper.cpp (&lt;a href=\"https://github.com/ggerganov/whisper.cpp\"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Webhook_listener (&lt;a href=\"https://pypi.org/project/Webhook-Listener\"&gt;https://pypi.org/project/Webhook-Listener&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Tautulli (&lt;a href=\"https://tautulli.com\"&gt;https://tautulli.com&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Google&lt;/p&gt;\n\n&lt;p&gt;ffmpeg&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?auto=webp&amp;v=enabled&amp;s=16c4960779b2605705367b1aa060fe8d29303baa", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0ff0ce307893fa9511851c5f21eb9aafa585f1a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e24a2bdb1354f3c183c98104331813ab58617345", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1283d02a6dc76d7fcb6c92aec1f50a6d0557a2a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38f9473fa49587383e52fb7fe435c737c0474335", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c7dbf440cb1be984c277a38354b10dbafab5cf70", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/22x_O7Xizf00_jHGO18vliEe3_Ml13ie7S_QRIRDT1Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43d692a01abf573986c358e12c33760bb445f79a", "width": 1080, "height": 540}], "variants": {}, "id": "Q5NpszZXLZ20dc-qaQWe8itb33kryfCu2JTLxEA_234"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "7a2c90d0-4655-11ec-b067-9e334eed55f0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nlc4h", "is_robot_indexable": true, "report_reasons": null, "author": "McCloud", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nlc4h/subgen_autogen_plex_subtitles_using_tautulli_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nlc4h/subgen_autogen_plex_subtitles_using_tautulli_and/", "subreddit_subscribers": 226817, "created_utc": 1674929213.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "[https://neverinstall.com/](https://neverinstall.com/) allows you to log in to their website and get a very usable Linux desktop through your web browser. I've tried the freemium version and when it is available it is surprisingly usable.  This could be very useful for me when working in places where I can't install software and would prefer to be using Linux apps.\n\nWhat would be the best way to recreate this for myself?  I'm only talking about making this available for myself, not replicating the service for multiple users.  I know I could use something like RDP or VNC but I'd like to replicate the web browser access.\n\nAny pointers in the right direction to research would be appreciated.", "author_fullname": "t2_gvnjuoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self host something like Neverinstall?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "remote-access", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o3w20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Remote Access", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674984831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://neverinstall.com/\"&gt;https://neverinstall.com/&lt;/a&gt; allows you to log in to their website and get a very usable Linux desktop through your web browser. I&amp;#39;ve tried the freemium version and when it is available it is surprisingly usable.  This could be very useful for me when working in places where I can&amp;#39;t install software and would prefer to be using Linux apps.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way to recreate this for myself?  I&amp;#39;m only talking about making this available for myself, not replicating the service for multiple users.  I know I could use something like RDP or VNC but I&amp;#39;d like to replicate the web browser access.&lt;/p&gt;\n\n&lt;p&gt;Any pointers in the right direction to research would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?auto=webp&amp;v=enabled&amp;s=02e8ee73fbdf0eed7e72eca770dca4d57c63b951", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=360ea967c0dd9a5c486cdc91205006821f85162b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=27eba3174b56e614727d8eb796b4e6a88c3d7ab0", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47eed226f5babf301c0e42c15f8dae9800122231", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7af8fcca058742d483a30377030e3575ce1d5136", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2b1170d18a42affc1661b821374040505ac6a0e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/KJT88TwNIA07g7eEpA0U0D03zpSsHXTNVU8yyIiwuwI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=509337b90859391a4ffd624f184c5b00566e8b42", "width": 1080, "height": 567}], "variants": {}, "id": "ch0Elz32l0A4WNwmUh2DYgWNjdjBKlaZl_DJBOaOE2Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0a45032a-0de1-11ed-997f-0a924a5694f9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o3w20", "is_robot_indexable": true, "report_reasons": null, "author": "LoudStream", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o3w20/self_host_something_like_neverinstall/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o3w20/self_host_something_like_neverinstall/", "subreddit_subscribers": 226817, "created_utc": 1674984831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Are they more durable than external spinning disks, can I trust them for things like photo backups?\n\nI'm looking at the 1tb Sandisk ones specifically, any insight is appreciated.", "author_fullname": "t2_k2kz8iqm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long will SDCards Last?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nzbrn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674968119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are they more durable than external spinning disks, can I trust them for things like photo backups?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at the 1tb Sandisk ones specifically, any insight is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nzbrn", "is_robot_indexable": true, "report_reasons": null, "author": "kittywrastler", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nzbrn/how_long_will_sdcards_last/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nzbrn/how_long_will_sdcards_last/", "subreddit_subscribers": 226817, "created_utc": 1674968119.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey!\n\nI'm looking for recommendations on a RSS feed / new aggregator / feed reader.\n\nI've [got a list](https://github.com/awesome-selfhosted/awesome-selfhosted#feed-readers) of potential applications that all seem to have similar features, so I thought I'd reach out for recommendations and maybe save myself some headache.\n\nCheers :)", "author_fullname": "t2_4ttuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a good Feed Reader.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nxxkz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674963528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for recommendations on a RSS feed / new aggregator / feed reader.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve &lt;a href=\"https://github.com/awesome-selfhosted/awesome-selfhosted#feed-readers\"&gt;got a list&lt;/a&gt; of potential applications that all seem to have similar features, so I thought I&amp;#39;d reach out for recommendations and maybe save myself some headache.&lt;/p&gt;\n\n&lt;p&gt;Cheers :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?auto=webp&amp;v=enabled&amp;s=1adbd4c5689e6138ede5d40dbd4a8c23f5ee1125", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f758a07fdba5310a25aac9fe07e135b0c03c8a67", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b77b357648761cfcf1f5e7627df462cfe6905d6", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8eb5860c263ea317d0ec36f7e899f15eb343851", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bbce638231f8694e44b99b8e1f979e83809373f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c963a45352a8a9f28628b698a81a43a22ff56b6a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/me2IQJnoEfs-EXN3KQBBpeiAFZZ8yLHZSuILc0yd7SA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc01daf0d8b97f70599071c2df71142968705990", "width": 1080, "height": 540}], "variants": {}, "id": "B8gqMW8hIQJgEno6zWoGIgyDLri54EBhOEzJJlPeJbo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nxxkz", "is_robot_indexable": true, "report_reasons": null, "author": "Bradyns", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nxxkz/looking_for_a_good_feed_reader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nxxkz/looking_for_a_good_feed_reader/", "subreddit_subscribers": 226817, "created_utc": 1674963528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I setup Caddy for reverse proxy and HTTPS to forward mydomain.com (replaced with the actual domain I own) to my local IP using port 30000.  I can access the server by going to mydomain.com on my phone on data or on a computer outside my home network, but not from a computer on the same network.\n\n&amp;#x200B;\n\nIs there a way that I can access the server by typing [mydomain.com](https://mydomain.com) on a computer on the same network, or am I forced to use localIP:30000?\n\n&amp;#x200B;\n\nFor reference, the server is FoundryVTT running on a Debian 11 Lenovo Thinkcentre, and I am using an Xfinity modem/router.", "author_fullname": "t2_26sqq43u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Access Reverse Proxy from within the Same Network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nunf8", "quarantine": false, "link_flair_text_color": null, "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674953523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I setup Caddy for reverse proxy and HTTPS to forward mydomain.com (replaced with the actual domain I own) to my local IP using port 30000.  I can access the server by going to mydomain.com on my phone on data or on a computer outside my home network, but not from a computer on the same network.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there a way that I can access the server by typing &lt;a href=\"https://mydomain.com\"&gt;mydomain.com&lt;/a&gt; on a computer on the same network, or am I forced to use localIP:30000?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For reference, the server is FoundryVTT running on a Debian 11 Lenovo Thinkcentre, and I am using an Xfinity modem/router.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "10nunf8", "is_robot_indexable": true, "report_reasons": null, "author": "Zendrick42", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nunf8/access_reverse_proxy_from_within_the_same_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nunf8/access_reverse_proxy_from_within_the_same_network/", "subreddit_subscribers": 226817, "created_utc": 1674953523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I've been trying to get my own self hosted things setup for a while now and I usually only get part of it working. So I thought I would reach out and see what others install first. So, I'm spinning up a brand new Ubuntu server. Before when I did it I would have it install docker, nextcloud and a few other apps along with it. But that never seems to work. So I'm going to try and do the minimalist install instead. \n\nWhat would be the first thing/s to install on a new linux server? and then in what order would you go from there? Ideally I would like to get nextcloud, npm, photoprism, some sort of monitoring container, etc installed.", "author_fullname": "t2_7fcgj03a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to install first?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nny37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674935854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been trying to get my own self hosted things setup for a while now and I usually only get part of it working. So I thought I would reach out and see what others install first. So, I&amp;#39;m spinning up a brand new Ubuntu server. Before when I did it I would have it install docker, nextcloud and a few other apps along with it. But that never seems to work. So I&amp;#39;m going to try and do the minimalist install instead. &lt;/p&gt;\n\n&lt;p&gt;What would be the first thing/s to install on a new linux server? and then in what order would you go from there? Ideally I would like to get nextcloud, npm, photoprism, some sort of monitoring container, etc installed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nny37", "is_robot_indexable": true, "report_reasons": null, "author": "FaTheArmorShell", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nny37/what_to_install_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nny37/what_to_install_first/", "subreddit_subscribers": 226817, "created_utc": 1674935854.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am working on deploying the Gitea container via docker-compose and it works. However, if I bring the container down with `docker-compose down` and bring it up with `docker-compose up -d`, I could not login anymore. It seems like the admin user that was created in the beginning is a one time thing. The moment the container goes down, all the accounts goes away with it. When I checked the logs, it says \"user does not exist\".\n\nIs there away around this?\n\nThis is my docker compose file:\n\n    version: \"3\"\n    \n    networks:\n      gitea:\n        external: false\n    \n    services:\n      server:\n        env_file: .env\n        image: gitea/gitea\n        container_name: gitea\n        environment:\n          - USER_UID=${UUID}\n          - USER_GID=${GUID}\n          - GITEA__database__DB_TYPE=postgres\n          - GITEA__database__HOST=db:5432\n          - GITEA__database__NAME=${DB}\n          - GITEA__database__USER=${DBUSER}\n          - GITEA__database__PASSWD=${DBPASS}\n        restart: unless-stopped\n        networks:\n          - gitea\n        volumes:\n          - ${APPDATA}:/data\n          - /etc/timezone:/etc/timezone:ro\n          - /etc/localtime:/etc/localtime:ro\n        ports:\n          - \"${WEBPORT}:3000\"\n          - \"${SSHPORT}:22\"\n        depends_on:\n          - db\n     \n      db:\n        env_file: .env\n        image: postgres:13\n        restart: unless-stopped\n        environment:\n          - POSTGRES_USER=${DBUSER}\n          - POSTGRES_PASSWORD=${DBPASS}\n          - POSTGRES_DB=${DB}\n        networks:\n          - gitea\n        volumes:\n          - ${APPDATADB}:/var/lib/postgres/data\n    \n\n&amp;#x200B;", "author_fullname": "t2_4b61cig1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gitea issues. Admin account is missing after bring the container down.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "gittool", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nwvg0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "GIT Management", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674960733.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674960239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on deploying the Gitea container via docker-compose and it works. However, if I bring the container down with &lt;code&gt;docker-compose down&lt;/code&gt; and bring it up with &lt;code&gt;docker-compose up -d&lt;/code&gt;, I could not login anymore. It seems like the admin user that was created in the beginning is a one time thing. The moment the container goes down, all the accounts goes away with it. When I checked the logs, it says &amp;quot;user does not exist&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Is there away around this?&lt;/p&gt;\n\n&lt;p&gt;This is my docker compose file:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;version: &amp;quot;3&amp;quot;\n\nnetworks:\n  gitea:\n    external: false\n\nservices:\n  server:\n    env_file: .env\n    image: gitea/gitea\n    container_name: gitea\n    environment:\n      - USER_UID=${UUID}\n      - USER_GID=${GUID}\n      - GITEA__database__DB_TYPE=postgres\n      - GITEA__database__HOST=db:5432\n      - GITEA__database__NAME=${DB}\n      - GITEA__database__USER=${DBUSER}\n      - GITEA__database__PASSWD=${DBPASS}\n    restart: unless-stopped\n    networks:\n      - gitea\n    volumes:\n      - ${APPDATA}:/data\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n    ports:\n      - &amp;quot;${WEBPORT}:3000&amp;quot;\n      - &amp;quot;${SSHPORT}:22&amp;quot;\n    depends_on:\n      - db\n\n  db:\n    env_file: .env\n    image: postgres:13\n    restart: unless-stopped\n    environment:\n      - POSTGRES_USER=${DBUSER}\n      - POSTGRES_PASSWORD=${DBPASS}\n      - POSTGRES_DB=${DB}\n    networks:\n      - gitea\n    volumes:\n      - ${APPDATADB}:/var/lib/postgres/data\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d37b1912-7e67-11e9-93c2-0ec7a61a727c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nwvg0", "is_robot_indexable": true, "report_reasons": null, "author": "forwardslashroot", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nwvg0/gitea_issues_admin_account_is_missing_after_bring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nwvg0/gitea_issues_admin_account_is_missing_after_bring/", "subreddit_subscribers": 226817, "created_utc": 1674960239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi there,  \n\nI've been playing around with Pi-hole and my Traefik stack for a few hours now trying to achieve something that (I hope) should be fairly simple:  \n\nI have \"public\" services that I am already exposing through Traefik, with a domain name I own. That works just fine.  \n\nHowever, I have \"private\" services that I would like to access internally by typing \"[service.app](https://service.app)\" in my browser, where \"service\" is the name of the service, obviously.  \n\nNow, to that end, I set up Pi-hole and created a local DNS entry in there titled (for instance) \"[portainer.app](https://portainer.app)\". In my Portainer container, I added the necessary labels (check below for a configuration sample).  \n\nEverything seems to be working network-wise, but here's the deal: even though I disabled TLS and set the entrypoint to HTTP, my browser desperately wants to load it with HTTPS, which causes a security error and makes it impossible to access the service with this internal URL.  \n\nAny idea on what's failing? Maybe my Traefik configuration is wrong somewhere, but I'll admit I'm a bit lost since I also want to use TLS  for the exposed services.  \n\nHere's my Traefik configuration:\n\n    traefik:\n        container_name: traefik\n        image: traefik:2.2.1\n        restart: unless-stopped\n        command: # CLI arguments\n          - --global.checkNewVersion=true\n          - --global.sendAnonymousUsage=true\n          - --entryPoints.http.address=:80\n          - --entryPoints.https.address=:443\n          - --entrypoints.https.forwardedHeaders.trustedIPs=XXX.XXX.XXX.XXX(Cloudflare IPs here)\n          - --entryPoints.traefik.address=:8080\n          - --api=true\n          - --log=true\n          - --log.level=DEBUG\n          - --accessLog=true\n          - --accessLog.filePath=/traefik.log\n          - --accessLog.bufferingSize=100\n          - --accessLog.filters.statusCodes=400-499\n          - --providers.docker=true\n          - --providers.docker.endpoint=unix:///var/run/docker.sock\n          - --providers.docker.defaultrule=Host(`{{ index .Labels \"com.docker.compose.service\" }}.$DOMAINNAME_CLOUD_SERVER`)\n          - --providers.docker.exposedByDefault=false\n          - --providers.docker.network=t2_proxy\n          - --providers.docker.swarmMode=false\n          - --providers.file.directory=/rules\n          - --providers.file.watch=true\n          - --certificatesResolvers.dns-cloudflare.acme.email=$CLOUDFLARE_EMAIL\n          - --certificatesResolvers.dns-cloudflare.acme.storage=/acme.json\n          - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.provider=cloudflare\n          - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.disablePropagationCheck=true\n          - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.delayBeforeCheck=60\n        networks:\n          - t2_proxy\n        security_opt:\n          - no-new-privileges:true\n        ports:\n          - target: 80\n            published: 80\n            protocol: tcp\n            mode: host\n          - target: 443\n            published: 443\n            protocol: tcp\n            mode: host\n          - target: 8080\n            published: 8080\n            protocol: tcp\n            mode: host\n        volumes:\n          - $DOCKERDIR/traefik2/rules:/rules\n          - /var/run/docker.sock:/var/run/docker.sock:ro\n          - $DOCKERDIR/traefik2/acme/acme.json:/acme.json\n          - $DOCKERDIR/traefik2/traefik.log:/traefik.log\n          - $DOCKERDIR/shared:/shared\n        environment:\n          - CF_API_EMAIL=$CLOUDFLARE_EMAIL\n          - CF_API_KEY=$CLOUDFLARE_API_KEY\n        labels:\n          - \"traefik.enable=true\"\n          - \"traefik.http.routers.traefik-rtr.service=api@internal\"\n          # HTTP-to-HTTPS Redirect\n          - \"traefik.http.routers.http-catchall.entrypoints=http\"\n          - \"traefik.http.routers.http-catchall.rule=HostRegexp(`{host:.+}`)\"\n          - \"traefik.http.routers.http-catchall.middlewares=redirect-to-https\"\n          - \"traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https\"\n          # HTTP Routers\n          - \"traefik.http.routers.traefik-rtr.entrypoints=https\"\n          - \"traefik.http.routers.traefik-rtr.rule=Host(`traefik.$DOMAINNAME_CLOUD_SERVER`)\"\n          - \"traefik.http.routers.traefik-rtr.tls=true\"\n          - \"traefik.http.routers.traefik-rtr.tls.domains[0].main=$DOMAINNAME_CLOUD_SERVER\"\n          - \"traefik.http.routers.traefik-rtr.tls.domains[0].sans=*.$DOMAINNAME_CLOUD_SERVER\"\n          ## Middlewares\n          - \"traefik.http.routers.traefik-rtr.middlewares=chain-oauth@file\"\n\nAnd here's the Portainer configuration:  \n\n    portainer:\n        container_name: portainer\n        image: portainer/portainer:latest\n        restart: unless-stopped\n        command: -H unix:///var/run/docker.sock\n        networks:\n          - t2_proxy\n        security_opt:\n          - no-new-privileges:true\n        volumes:\n          - /var/run/docker.sock:/var/run/docker.sock:ro\n          - $DOCKERDIR/portainer/data:/data\n        environment:\n          - TZ=$TZ\n        labels:\n          - \"traefik.enable=true\"\n          ## HTTP Routers\n          - \"traefik.http.routers.portainer-rtr.entrypoints=http\"\n          - \"traefik.http.routers.portainer-rtr.rule=Host(`portainer.app`)\"\n          - \"traefik.http.routers.portainer-rtr.tls=false\"\n          ## HTTP Services\n          - \"traefik.http.routers.portainer-rtr.service=portainer-svc\"\n          - \"traefik.http.services.portainer-svc.loadbalancer.server.port=9000\"\n          ## Middlewares\n          - \"traefik.http.routers.portainer-rtr.middlewares=chain-internal@file\"\n\nFor reference, here are the middlewares that are contained in the chain-internal chain:\n\n    [http.middlewares.middlewares-rate-limit]\n      [http.middlewares.middlewares-rate-limit.rateLimit]\n        average = 100\n        burst = 50\n    \n    [http.middlewares.middlewares-ipwhitelist]\n      [http.middlewares.middlewares-ipwhitelist.ipWhiteList]\n        sourceRange = [\"127.0.0.1/32\", \"192.168.1.1/24\", \"172.19.0.1\"]", "author_fullname": "t2_10xcsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a local .app DNS entry to access an application behind Traefik", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "proxy", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ntn2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Proxy", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674950666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been playing around with Pi-hole and my Traefik stack for a few hours now trying to achieve something that (I hope) should be fairly simple:  &lt;/p&gt;\n\n&lt;p&gt;I have &amp;quot;public&amp;quot; services that I am already exposing through Traefik, with a domain name I own. That works just fine.  &lt;/p&gt;\n\n&lt;p&gt;However, I have &amp;quot;private&amp;quot; services that I would like to access internally by typing &amp;quot;&lt;a href=\"https://service.app\"&gt;service.app&lt;/a&gt;&amp;quot; in my browser, where &amp;quot;service&amp;quot; is the name of the service, obviously.  &lt;/p&gt;\n\n&lt;p&gt;Now, to that end, I set up Pi-hole and created a local DNS entry in there titled (for instance) &amp;quot;&lt;a href=\"https://portainer.app\"&gt;portainer.app&lt;/a&gt;&amp;quot;. In my Portainer container, I added the necessary labels (check below for a configuration sample).  &lt;/p&gt;\n\n&lt;p&gt;Everything seems to be working network-wise, but here&amp;#39;s the deal: even though I disabled TLS and set the entrypoint to HTTP, my browser desperately wants to load it with HTTPS, which causes a security error and makes it impossible to access the service with this internal URL.  &lt;/p&gt;\n\n&lt;p&gt;Any idea on what&amp;#39;s failing? Maybe my Traefik configuration is wrong somewhere, but I&amp;#39;ll admit I&amp;#39;m a bit lost since I also want to use TLS  for the exposed services.  &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my Traefik configuration:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;traefik:\n    container_name: traefik\n    image: traefik:2.2.1\n    restart: unless-stopped\n    command: # CLI arguments\n      - --global.checkNewVersion=true\n      - --global.sendAnonymousUsage=true\n      - --entryPoints.http.address=:80\n      - --entryPoints.https.address=:443\n      - --entrypoints.https.forwardedHeaders.trustedIPs=XXX.XXX.XXX.XXX(Cloudflare IPs here)\n      - --entryPoints.traefik.address=:8080\n      - --api=true\n      - --log=true\n      - --log.level=DEBUG\n      - --accessLog=true\n      - --accessLog.filePath=/traefik.log\n      - --accessLog.bufferingSize=100\n      - --accessLog.filters.statusCodes=400-499\n      - --providers.docker=true\n      - --providers.docker.endpoint=unix:///var/run/docker.sock\n      - --providers.docker.defaultrule=Host(`{{ index .Labels &amp;quot;com.docker.compose.service&amp;quot; }}.$DOMAINNAME_CLOUD_SERVER`)\n      - --providers.docker.exposedByDefault=false\n      - --providers.docker.network=t2_proxy\n      - --providers.docker.swarmMode=false\n      - --providers.file.directory=/rules\n      - --providers.file.watch=true\n      - --certificatesResolvers.dns-cloudflare.acme.email=$CLOUDFLARE_EMAIL\n      - --certificatesResolvers.dns-cloudflare.acme.storage=/acme.json\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.provider=cloudflare\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.disablePropagationCheck=true\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.delayBeforeCheck=60\n    networks:\n      - t2_proxy\n    security_opt:\n      - no-new-privileges:true\n    ports:\n      - target: 80\n        published: 80\n        protocol: tcp\n        mode: host\n      - target: 443\n        published: 443\n        protocol: tcp\n        mode: host\n      - target: 8080\n        published: 8080\n        protocol: tcp\n        mode: host\n    volumes:\n      - $DOCKERDIR/traefik2/rules:/rules\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - $DOCKERDIR/traefik2/acme/acme.json:/acme.json\n      - $DOCKERDIR/traefik2/traefik.log:/traefik.log\n      - $DOCKERDIR/shared:/shared\n    environment:\n      - CF_API_EMAIL=$CLOUDFLARE_EMAIL\n      - CF_API_KEY=$CLOUDFLARE_API_KEY\n    labels:\n      - &amp;quot;traefik.enable=true&amp;quot;\n      - &amp;quot;traefik.http.routers.traefik-rtr.service=api@internal&amp;quot;\n      # HTTP-to-HTTPS Redirect\n      - &amp;quot;traefik.http.routers.http-catchall.entrypoints=http&amp;quot;\n      - &amp;quot;traefik.http.routers.http-catchall.rule=HostRegexp(`{host:.+}`)&amp;quot;\n      - &amp;quot;traefik.http.routers.http-catchall.middlewares=redirect-to-https&amp;quot;\n      - &amp;quot;traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https&amp;quot;\n      # HTTP Routers\n      - &amp;quot;traefik.http.routers.traefik-rtr.entrypoints=https&amp;quot;\n      - &amp;quot;traefik.http.routers.traefik-rtr.rule=Host(`traefik.$DOMAINNAME_CLOUD_SERVER`)&amp;quot;\n      - &amp;quot;traefik.http.routers.traefik-rtr.tls=true&amp;quot;\n      - &amp;quot;traefik.http.routers.traefik-rtr.tls.domains[0].main=$DOMAINNAME_CLOUD_SERVER&amp;quot;\n      - &amp;quot;traefik.http.routers.traefik-rtr.tls.domains[0].sans=*.$DOMAINNAME_CLOUD_SERVER&amp;quot;\n      ## Middlewares\n      - &amp;quot;traefik.http.routers.traefik-rtr.middlewares=chain-oauth@file&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And here&amp;#39;s the Portainer configuration:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;portainer:\n    container_name: portainer\n    image: portainer/portainer:latest\n    restart: unless-stopped\n    command: -H unix:///var/run/docker.sock\n    networks:\n      - t2_proxy\n    security_opt:\n      - no-new-privileges:true\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - $DOCKERDIR/portainer/data:/data\n    environment:\n      - TZ=$TZ\n    labels:\n      - &amp;quot;traefik.enable=true&amp;quot;\n      ## HTTP Routers\n      - &amp;quot;traefik.http.routers.portainer-rtr.entrypoints=http&amp;quot;\n      - &amp;quot;traefik.http.routers.portainer-rtr.rule=Host(`portainer.app`)&amp;quot;\n      - &amp;quot;traefik.http.routers.portainer-rtr.tls=false&amp;quot;\n      ## HTTP Services\n      - &amp;quot;traefik.http.routers.portainer-rtr.service=portainer-svc&amp;quot;\n      - &amp;quot;traefik.http.services.portainer-svc.loadbalancer.server.port=9000&amp;quot;\n      ## Middlewares\n      - &amp;quot;traefik.http.routers.portainer-rtr.middlewares=chain-internal@file&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;For reference, here are the middlewares that are contained in the chain-internal chain:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[http.middlewares.middlewares-rate-limit]\n  [http.middlewares.middlewares-rate-limit.rateLimit]\n    average = 100\n    burst = 50\n\n[http.middlewares.middlewares-ipwhitelist]\n  [http.middlewares.middlewares-ipwhitelist.ipWhiteList]\n    sourceRange = [&amp;quot;127.0.0.1/32&amp;quot;, &amp;quot;192.168.1.1/24&amp;quot;, &amp;quot;172.19.0.1&amp;quot;]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5e46c26c-7e68-11e9-8d4e-0e3bbb559e74", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ntn2h", "is_robot_indexable": true, "report_reasons": null, "author": "paulchartres", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10ntn2h/using_a_local_app_dns_entry_to_access_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10ntn2h/using_a_local_app_dns_entry_to_access_an/", "subreddit_subscribers": 226817, "created_utc": 1674950666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Looking for something similar to Nextcloud mail, but a bit faster (preferably not written in php). And as already mentioned in the title it should have the option to add multiple mail accounts from different providers.", "author_fullname": "t2_buypr73y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern webmail client with multiaccount support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "emailmanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nm1c0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Email Management", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674930979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something similar to Nextcloud mail, but a bit faster (preferably not written in php). And as already mentioned in the title it should have the option to add multiple mail accounts from different providers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0690f484-7e68-11e9-80db-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nm1c0", "is_robot_indexable": true, "report_reasons": null, "author": "Im1Random", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nm1c0/modern_webmail_client_with_multiaccount_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nm1c0/modern_webmail_client_with_multiaccount_support/", "subreddit_subscribers": 226817, "created_utc": 1674930979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm looking at branding and hosting a few apps that are AGPL 3. The only modifications to the code being made are the branding side of things, Title, background, fonts... etc.   \n\n\nI'm very new to AGPL and following the  licensing for public facing tools- does a link to the creators GitHub satisfy the license ?  Are there examples of sites that are using AGPL 3 licensed code, that I could see as how it's addressed?\n\nAny and all advice is welcomed.", "author_fullname": "t2_i87b8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "APGL 3 Compliant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nz156", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674970824.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674967122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at branding and hosting a few apps that are AGPL 3. The only modifications to the code being made are the branding side of things, Title, background, fonts... etc.   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very new to AGPL and following the  licensing for public facing tools- does a link to the creators GitHub satisfy the license ?  Are there examples of sites that are using AGPL 3 licensed code, that I could see as how it&amp;#39;s addressed?&lt;/p&gt;\n\n&lt;p&gt;Any and all advice is welcomed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nz156", "is_robot_indexable": true, "report_reasons": null, "author": "WitesOfOdd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nz156/apgl_3_compliant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nz156/apgl_3_compliant/", "subreddit_subscribers": 226817, "created_utc": 1674967122.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello fellow curious people,\n\nI have a question about self-hosting and security concerns. I moved a website from my old hostinger to a new hostinger account. What I had to do was I had to delete the website in old account(after making a backup), then in new account- chose to migrate option and entered the website name(website name is not accepted if it is not deleted from the old account). It went thro smoothly and all I had to do was restore files and database- the website would work even with out restoring old files/database and can go for a fresh Wordpress install.\n\nMy question is if there is any unhosted website, looks like anyone can host it given that it has the same nameservers (where hostinger has one common nameserver and its not specific for any website).It appears having only a domain name and not hosted itself is not a safe option. Example, if someone buys the domain in hostinger and not hosted yet, someone else can host it if they know the domain name.\n\nIs this right? Am I missing something? I am new to this domain and hosting world and I don't know much. Just came across these questions when I was transferring my own websites. Please help me understand.\n\nThank you.", "author_fullname": "t2_48fo0dvv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qn about domain name which is not hosted", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nxufg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674963246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow curious people,&lt;/p&gt;\n\n&lt;p&gt;I have a question about self-hosting and security concerns. I moved a website from my old hostinger to a new hostinger account. What I had to do was I had to delete the website in old account(after making a backup), then in new account- chose to migrate option and entered the website name(website name is not accepted if it is not deleted from the old account). It went thro smoothly and all I had to do was restore files and database- the website would work even with out restoring old files/database and can go for a fresh Wordpress install.&lt;/p&gt;\n\n&lt;p&gt;My question is if there is any unhosted website, looks like anyone can host it given that it has the same nameservers (where hostinger has one common nameserver and its not specific for any website).It appears having only a domain name and not hosted itself is not a safe option. Example, if someone buys the domain in hostinger and not hosted yet, someone else can host it if they know the domain name.&lt;/p&gt;\n\n&lt;p&gt;Is this right? Am I missing something? I am new to this domain and hosting world and I don&amp;#39;t know much. Just came across these questions when I was transferring my own websites. Please help me understand.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nxufg", "is_robot_indexable": true, "report_reasons": null, "author": "S-u-g-i", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nxufg/qn_about_domain_name_which_is_not_hosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nxufg/qn_about_domain_name_which_is_not_hosted/", "subreddit_subscribers": 226817, "created_utc": 1674963246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webgui for docker updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nvck7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_64bjptqc", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "docker", "selftext": "# Webgui for [dockcheck](https://github.com/mag37/dockcheck) provided by [Mag37@github](https://github.com/mag37/dockcheck)\n\nA script checking updates for docker images\u00a0without the need of pulling\u00a0- then having the option to auto-update.\n\nI made a webgui for this amazing script that shows if there is a new image to pull.\n[Dockcheck-web](https://github.com/Palleri/dockcheck-web)\n\nStill in development.\nThis image use docker.sock, so use it with care and do not publish it on the internet.\n\n### Future ideas\n* Email notification on available images\n* Update and pull new image on selected container via webgui\n\n\nAll cred goes to [Mag37@github](https://github.com/mag37/dockcheck) for this base script that made this webgui possible.", "author_fullname": "t2_64bjptqc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webgui for docker updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/docker", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10m484z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674771397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.docker", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Webgui for &lt;a href=\"https://github.com/mag37/dockcheck\"&gt;dockcheck&lt;/a&gt; provided by &lt;a href=\"https://github.com/mag37/dockcheck\"&gt;Mag37@github&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;A script checking updates for docker images\u00a0without the need of pulling\u00a0- then having the option to auto-update.&lt;/p&gt;\n\n&lt;p&gt;I made a webgui for this amazing script that shows if there is a new image to pull.\n&lt;a href=\"https://github.com/Palleri/dockcheck-web\"&gt;Dockcheck-web&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Still in development.\nThis image use docker.sock, so use it with care and do not publish it on the internet.&lt;/p&gt;\n\n&lt;h3&gt;Future ideas&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Email notification on available images&lt;/li&gt;\n&lt;li&gt;Update and pull new image on selected container via webgui&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All cred goes to &lt;a href=\"https://github.com/mag37/dockcheck\"&gt;Mag37@github&lt;/a&gt; for this base script that made this webgui possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?auto=webp&amp;v=enabled&amp;s=54f36f8b7d312c5bf500ab62119d0cb7cc0ac3f6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47fcee01deb384c78340cd8855f5948429402479", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488317e033ec62b0f983b09013502379373837a8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22cbc5c296fed347ad8706c8355fcc2e2d185ade", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62ab0f3945d94db3a231f3c4fb3d472654e0487b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5ea2f69c0e95239ec0f930b647ed76536739e73", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f7619b2d7b10daf51f1da7c73b1398afd6073e0", "width": 1080, "height": 540}], "variants": {}, "id": "6hxX_4Uc7SmRHeOQtvQTgN1eDBKs0v9dwPe1jl71z80"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2y00f", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10m484z", "is_robot_indexable": true, "report_reasons": null, "author": "Palleri", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/docker/comments/10m484z/webgui_for_docker_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/docker/comments/10m484z/webgui_for_docker_updates/", "subreddit_subscribers": 166582, "created_utc": 1674771397.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1674955581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.docker", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/docker/comments/10m484z/webgui_for_docker_updates/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?auto=webp&amp;v=enabled&amp;s=54f36f8b7d312c5bf500ab62119d0cb7cc0ac3f6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47fcee01deb384c78340cd8855f5948429402479", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488317e033ec62b0f983b09013502379373837a8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22cbc5c296fed347ad8706c8355fcc2e2d185ade", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62ab0f3945d94db3a231f3c4fb3d472654e0487b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5ea2f69c0e95239ec0f930b647ed76536739e73", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/o9mwE0PK7_Bz5gcIPKCphqVEoo-eOcX6fs2isYBqSD4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f7619b2d7b10daf51f1da7c73b1398afd6073e0", "width": 1080, "height": 540}], "variants": {}, "id": "6hxX_4Uc7SmRHeOQtvQTgN1eDBKs0v9dwPe1jl71z80"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nvck7", "is_robot_indexable": true, "report_reasons": null, "author": "Palleri", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10m484z", "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nvck7/webgui_for_docker_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/docker/comments/10m484z/webgui_for_docker_updates/", "subreddit_subscribers": 226817, "created_utc": 1674955581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Not sure what\u2019s happened with formatting here but completed on browser and checked on phone and it\u2019s escaped all characters and some in weird places. I will fix markdown, but any quirks in the code is purely related to the escape chars. Think I caught all the \u2018/\u2018 and removed them all. Sigh. \n\nI have varying error messages depending on what I change and what I can find online. I will show current setup and at the end I will highlight things I have done and the different errors I have gotten.  \n\n\n_Nginx config for this subdomain_\n\n```bash\n\nserver {\n\nserver_name SUB-DOMAIN.MY-DOMAIN.uk\n\nlocation / {\n\nproxy_pass http://localhost:5500; #whatever port your app runs on\n\nproxy_http_version 1.1;\n\nproxy_set_header Upgrade $http_upgrade;\n\nproxy_set_header Connection 'upgrade';\n\nproxy_set_header Host $host;\n\nproxy_cache_bypass $http_upgrade;\n\n}\n\nlisten 443 ssl; # managed by Certbot\n\nssl_certificate /etc/letsencrypt/live/SUB_DOMAIN.MY_DOMAIN.uk/fullchain.pem; # managed by Certbot\n\nssl_certificate_key /etc/letsencrypt/live/SUB_DOMAIN.MY_DOMAIN.uk/privkey.pem; # managed by Certbot\n\ninclude /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n\nssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n\nserver {\n\nif ($host = SUB_DOMAIN.MY_DOMAIN.uk) {\n\nreturn 301 https://$host$request\\_uri;\n\n} # managed by Certbot\n\nserver_name SUB_DOMAIN.MY_DOMAIN.uk\n\nlisten 80;\n\nreturn 404; # managed by Certbot\n\n}\n\n```\n\nRequests will be coming to this API from SUB_DOMAIN.MY_DOMAIN.uk, but a different subdomain than the API itself. All other domains work find with HTTPS.\n\n_API_\n\n```js\n\nconst express = require('express');\n\nconst cors = require('cors');\n\nconst connectDB = require('./db/connections');\n\n\nconst routes = require('./routes');\n\nconst PORT = process.env.PORT || 5550;\n\nconnectDB();\n\n\nconst server = express();\n\nserver.use(express.json());\n\n\nconst whitelist = [\n\n\t'https://SUB.MY_DOMAIN.uk',\n\n\t'http://SUB.MY_DOMAIN.uk',\n\n];\n\n\nconst corsOptions = {\n\n\torigin: (origin, cb) =&gt; {\n\n\t\tif (whitelist.indexOf(origin) !== -1) {\n\n\t\t\tcb(null, true);\n\n\t\t} else {\n\n\t\t\tcb(new Error('Not allowed by CORS'));\n\n\t\t}\n\n\t},\n\n};\n\nserver.use(cors(corsOptions));\n\nserver.use('/api', routes);\n\nserver.get('/', (req, res) =&gt; {\n\n\tres.status(200).send({ message: 'Running' });\n\n});\n\n\nserver.all('*', (req, res) =&gt; {\n\n\tres.status(404).send({ message: 'Path not found' });\n\n});\n\nserver.listen(PORT, (err) =&gt; {\n\n\tconsole.log(`Server is running at http://localhost:${PORT}`);\n\n});\n\n```\n\nNow if I hit that endpoint in a browser for the API with only HTTP, it returns the resources from the DB. If I try with HTTPS then I get the error: `SSL_ERROR_RX_RECORD_TOO_LONG` which I tried to resolve with the Firefox recommendations but nothing.\n\nIf I try to hit the same endpoint from my front-end then I get the error that `Blocked loading mixed active content`, this is with the HTTP path and if I try with HTTPS then I get `Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at`\n\n\nI have tried to whitelist everything, I have added the headers it suggest for  `Access-Control-Allow-Origin\\`. I have removed the Nginx config and set up again, cleared firefox, tried other browsers and I can;t seem to get it set up correctly, just new and confusing errors each time.\n\nWhat I want is `https://SUB_ONE.MY_DOMAIN.UK` should be able to make requests to `https://SUB_TWO.MY_DOMAIN.UK`/api/something (the API). The API us running at localhost:5550/api/something\n\n\nAny guidance would be awesome as I am losing my sanity over this. Can provide any config I missed here.", "author_fullname": "t2_4rojq0jw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please for the love of Odin, can somebody help me resolve a CORS issue. I have tried so many things and now I am not sure if the errors are Firefox, bad setup or something else.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o6nwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674996561.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674995610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure what\u2019s happened with formatting here but completed on browser and checked on phone and it\u2019s escaped all characters and some in weird places. I will fix markdown, but any quirks in the code is purely related to the escape chars. Think I caught all the \u2018/\u2018 and removed them all. Sigh. &lt;/p&gt;\n\n&lt;p&gt;I have varying error messages depending on what I change and what I can find online. I will show current setup and at the end I will highlight things I have done and the different errors I have gotten.  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Nginx config for this subdomain&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;```bash&lt;/p&gt;\n\n&lt;p&gt;server {&lt;/p&gt;\n\n&lt;p&gt;server_name SUB-DOMAIN.MY-DOMAIN.uk&lt;/p&gt;\n\n&lt;p&gt;location / {&lt;/p&gt;\n\n&lt;p&gt;proxy_pass http://localhost:5500; #whatever port your app runs on&lt;/p&gt;\n\n&lt;p&gt;proxy_http_version 1.1;&lt;/p&gt;\n\n&lt;p&gt;proxy_set_header Upgrade $http_upgrade;&lt;/p&gt;\n\n&lt;p&gt;proxy_set_header Connection &amp;#39;upgrade&amp;#39;;&lt;/p&gt;\n\n&lt;p&gt;proxy_set_header Host $host;&lt;/p&gt;\n\n&lt;p&gt;proxy_cache_bypass $http_upgrade;&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;listen 443 ssl; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;ssl_certificate /etc/letsencrypt/live/SUB_DOMAIN.MY_DOMAIN.uk/fullchain.pem; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;ssl_certificate_key /etc/letsencrypt/live/SUB_DOMAIN.MY_DOMAIN.uk/privkey.pem; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;server {&lt;/p&gt;\n\n&lt;p&gt;if ($host = SUB_DOMAIN.MY_DOMAIN.uk) {&lt;/p&gt;\n\n&lt;p&gt;return 301 https://$host$request_uri;&lt;/p&gt;\n\n&lt;p&gt;} # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;server_name SUB_DOMAIN.MY_DOMAIN.uk&lt;/p&gt;\n\n&lt;p&gt;listen 80;&lt;/p&gt;\n\n&lt;p&gt;return 404; # managed by Certbot&lt;/p&gt;\n\n&lt;p&gt;}&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;Requests will be coming to this API from SUB_DOMAIN.MY_DOMAIN.uk, but a different subdomain than the API itself. All other domains work find with HTTPS.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;API&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;```js&lt;/p&gt;\n\n&lt;p&gt;const express = require(&amp;#39;express&amp;#39;);&lt;/p&gt;\n\n&lt;p&gt;const cors = require(&amp;#39;cors&amp;#39;);&lt;/p&gt;\n\n&lt;p&gt;const connectDB = require(&amp;#39;./db/connections&amp;#39;);&lt;/p&gt;\n\n&lt;p&gt;const routes = require(&amp;#39;./routes&amp;#39;);&lt;/p&gt;\n\n&lt;p&gt;const PORT = process.env.PORT || 5550;&lt;/p&gt;\n\n&lt;p&gt;connectDB();&lt;/p&gt;\n\n&lt;p&gt;const server = express();&lt;/p&gt;\n\n&lt;p&gt;server.use(express.json());&lt;/p&gt;\n\n&lt;p&gt;const whitelist = [&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;&amp;#39;https://SUB.MY_DOMAIN.uk&amp;#39;,\n\n&amp;#39;http://SUB.MY_DOMAIN.uk&amp;#39;,\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;];&lt;/p&gt;\n\n&lt;p&gt;const corsOptions = {&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;origin: (origin, cb) =&amp;gt; {\n\n    if (whitelist.indexOf(origin) !== -1) {\n\n        cb(null, true);\n\n    } else {\n\n        cb(new Error(&amp;#39;Not allowed by CORS&amp;#39;));\n\n    }\n\n},\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;};&lt;/p&gt;\n\n&lt;p&gt;server.use(cors(corsOptions));&lt;/p&gt;\n\n&lt;p&gt;server.use(&amp;#39;/api&amp;#39;, routes);&lt;/p&gt;\n\n&lt;p&gt;server.get(&amp;#39;/&amp;#39;, (req, res) =&amp;gt; {&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;res.status(200).send({ message: &amp;#39;Running&amp;#39; });\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;});&lt;/p&gt;\n\n&lt;p&gt;server.all(&amp;#39;*&amp;#39;, (req, res) =&amp;gt; {&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;res.status(404).send({ message: &amp;#39;Path not found&amp;#39; });\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;});&lt;/p&gt;\n\n&lt;p&gt;server.listen(PORT, (err) =&amp;gt; {&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;console.log(`Server is running at http://localhost:${PORT}`);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;});&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;Now if I hit that endpoint in a browser for the API with only HTTP, it returns the resources from the DB. If I try with HTTPS then I get the error: &lt;code&gt;SSL_ERROR_RX_RECORD_TOO_LONG&lt;/code&gt; which I tried to resolve with the Firefox recommendations but nothing.&lt;/p&gt;\n\n&lt;p&gt;If I try to hit the same endpoint from my front-end then I get the error that &lt;code&gt;Blocked loading mixed active content&lt;/code&gt;, this is with the HTTP path and if I try with HTTPS then I get &lt;code&gt;Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I have tried to whitelist everything, I have added the headers it suggest for  &lt;code&gt;Access-Control-Allow-Origin\\&lt;/code&gt;. I have removed the Nginx config and set up again, cleared firefox, tried other browsers and I can;t seem to get it set up correctly, just new and confusing errors each time.&lt;/p&gt;\n\n&lt;p&gt;What I want is &lt;code&gt;https://SUB_ONE.MY_DOMAIN.UK&lt;/code&gt; should be able to make requests to &lt;code&gt;https://SUB_TWO.MY_DOMAIN.UK&lt;/code&gt;/api/something (the API). The API us running at localhost:5550/api/something&lt;/p&gt;\n\n&lt;p&gt;Any guidance would be awesome as I am losing my sanity over this. Can provide any config I missed here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6nwj", "is_robot_indexable": true, "report_reasons": null, "author": "Fibonacci_11235813a", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o6nwj/please_for_the_love_of_odin_can_somebody_help_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o6nwj/please_for_the_love_of_odin_can_somebody_help_me/", "subreddit_subscribers": 226817, "created_utc": 1674995610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have gathered a long list of bookmarks of various web instructions and tutorials specific to my system setup and how to make my different software play nice with each other. Some links I visits often and other links only once or twice. \n\nI am looking for input, guidance, or suggestions on the best way to scrape the content/videos and host it all on my own local intranet/wiki-esk site. This is very new to me so i'm not sure where to begin.", "author_fullname": "t2_ltbzxq19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self hosted copies of instructions and tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nz7sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674967741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have gathered a long list of bookmarks of various web instructions and tutorials specific to my system setup and how to make my different software play nice with each other. Some links I visits often and other links only once or twice. &lt;/p&gt;\n\n&lt;p&gt;I am looking for input, guidance, or suggestions on the best way to scrape the content/videos and host it all on my own local intranet/wiki-esk site. This is very new to me so i&amp;#39;m not sure where to begin.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nz7sv", "is_robot_indexable": true, "report_reasons": null, "author": "29Top", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nz7sv/self_hosted_copies_of_instructions_and_tutorials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nz7sv/self_hosted_copies_of_instructions_and_tutorials/", "subreddit_subscribers": 226817, "created_utc": 1674967741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Planning to buy some used cheap hard disks for a NAS. What should I look out for when buying them.\n\nIs it possible to check the health of the hard disks? These are ones used in servers. Do the age or brand matter much?", "author_fullname": "t2_v2v272d6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buying used hard disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nyn4n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674965833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to buy some used cheap hard disks for a NAS. What should I look out for when buying them.&lt;/p&gt;\n\n&lt;p&gt;Is it possible to check the health of the hard disks? These are ones used in servers. Do the age or brand matter much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nyn4n", "is_robot_indexable": true, "report_reasons": null, "author": "hirzokitre", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nyn4n/buying_used_hard_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nyn4n/buying_used_hard_disks/", "subreddit_subscribers": 226817, "created_utc": 1674965833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Simplelogin self host\n\nSo I had a domain just hanging around, decided to give a try self hosting simplelogin. All went great, but had a question about maybe enabling a catch all on the default domain? Is the possible? My google powers are failing me and haven't found a possible answer besides adding another domain.  Anyone know how or if I would be able to do a catch all on just the default domain?", "author_fullname": "t2_ps1o1ka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple Login", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "emailmanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nw9mx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Email Management", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674958394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Simplelogin self host&lt;/p&gt;\n\n&lt;p&gt;So I had a domain just hanging around, decided to give a try self hosting simplelogin. All went great, but had a question about maybe enabling a catch all on the default domain? Is the possible? My google powers are failing me and haven&amp;#39;t found a possible answer besides adding another domain.  Anyone know how or if I would be able to do a catch all on just the default domain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0690f484-7e68-11e9-80db-0eb480af1d48", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nw9mx", "is_robot_indexable": true, "report_reasons": null, "author": "t2noob", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nw9mx/simple_login/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nw9mx/simple_login/", "subreddit_subscribers": 226817, "created_utc": 1674958394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Looking at setting up a file server to self-host a digital photo collection.  Currently leaning towards PiGallery2 to start with.  Based on some of the other apps mentioned in this sub, though, I may likely want to expand this to other apps down the road.  In the meantime, I've some basic getting started questions:\n\n(1) What sort of \"server\" hardware is needed?  A Raspberry Pi doesn't seem like it would be adequate.  But don't really see a need for a Threadripper or dual-Xeon setup for a home server.  Would a quad-core Ryzen 5 with 16gb be sufficient?  What about an older i3 dual core with only 4gb?\n\n(2) What about viruses?  All of this free and open software is being downloaded, but how does one know it doesn't have some backdoor built-in?\n\n(3) Docker seems to be heavily promoted in this sub.  The big selling point seems to be process isolation.  Does that help with security?", "author_fullname": "t2_snuvvnge", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self Hosting N00b Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nsire", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674947667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking at setting up a file server to self-host a digital photo collection.  Currently leaning towards PiGallery2 to start with.  Based on some of the other apps mentioned in this sub, though, I may likely want to expand this to other apps down the road.  In the meantime, I&amp;#39;ve some basic getting started questions:&lt;/p&gt;\n\n&lt;p&gt;(1) What sort of &amp;quot;server&amp;quot; hardware is needed?  A Raspberry Pi doesn&amp;#39;t seem like it would be adequate.  But don&amp;#39;t really see a need for a Threadripper or dual-Xeon setup for a home server.  Would a quad-core Ryzen 5 with 16gb be sufficient?  What about an older i3 dual core with only 4gb?&lt;/p&gt;\n\n&lt;p&gt;(2) What about viruses?  All of this free and open software is being downloaded, but how does one know it doesn&amp;#39;t have some backdoor built-in?&lt;/p&gt;\n\n&lt;p&gt;(3) Docker seems to be heavily promoted in this sub.  The big selling point seems to be process isolation.  Does that help with security?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nsire", "is_robot_indexable": true, "report_reasons": null, "author": "Muted-Act-6938", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10nsire/self_hosting_n00b_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10nsire/self_hosting_n00b_questions/", "subreddit_subscribers": 226817, "created_utc": 1674947667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm looking for an open-source, self-hosted solution to reset Android phones to factory and provision them with software and settings.\n\nAnsible doesn't seem to support Android.", "author_fullname": "t2_a2yeudcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Full reset and provisioning software for Android", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "phonesystem", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10njxep", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Phone System", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674925557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an open-source, self-hosted solution to reset Android phones to factory and provision them with software and settings.&lt;/p&gt;\n\n&lt;p&gt;Ansible doesn&amp;#39;t seem to support Android.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f5688f50-7e67-11e9-8fb9-0ee40327e406", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10njxep", "is_robot_indexable": true, "report_reasons": null, "author": "sugarplumpudding_", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10njxep/full_reset_and_provisioning_software_for_android/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10njxep/full_reset_and_provisioning_software_for_android/", "subreddit_subscribers": 226817, "created_utc": 1674925557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello guys,\n\nI am getting ready to switch my consumer garade Xiaomi router with a virtualized pfSense instance running on Proxmox server. The question is: will all my devices be assigned new IP addresses once I do that? (I haven't set the pfSense yet, so any advice on it would also be cool). I have a TrueNAS server and a Proxmox server (that the router would be installed on) on this network.\nIs there any common way of performing such operation?", "author_fullname": "t2_42a7ek5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob network question. Moving to new router.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ngjul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674916714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I am getting ready to switch my consumer garade Xiaomi router with a virtualized pfSense instance running on Proxmox server. The question is: will all my devices be assigned new IP addresses once I do that? (I haven&amp;#39;t set the pfSense yet, so any advice on it would also be cool). I have a TrueNAS server and a Proxmox server (that the router would be installed on) on this network.\nIs there any common way of performing such operation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ngjul", "is_robot_indexable": true, "report_reasons": null, "author": "D_1_G_Z_0_R", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10ngjul/noob_network_question_moving_to_new_router/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10ngjul/noob_network_question_moving_to_new_router/", "subreddit_subscribers": 226817, "created_utc": 1674916714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "As a preface; I do not understand much of the lingo on this subreddit and my question might be dumb but I want to learn. Feel free to be honest with me, I can take it.\n\nI have MS documents, pdfs, tax returns, contacts, receipts, photos, memes and some videos on a 1TB SSD in my gaming desktop(Windows 10) that I want to be able to access and edit from my laptop and my phone when I'm not at home but I do not want to host those things directly from that drive because I don't like leaving that computer on when I'm not using it. I want the contents of that drive to be backed up automatically onto a 1TB External SSD hooked up to an Intel Nuc(Ubuntu Gnome) I just put together and have the files hosted from there. The reason I set up Gnome on the Nuc is because I also want to be able to remote into it and do other stuff with it later. I also do not want the contents of the drive to be accessible to other people using my network.\n\nIs there a way to make it so that changes made to those drives automatically transfer over to the other drive even though they're on different computers and different operating systems? Would that interfere with the ability to host some of those files? I looked through the list of back-up software on github but I don't entirely understand which ones would be able to do this type of thing, or do it well. Also I figure maybe just nextcloud and another media server would do it for the hosting part, but would those be safe? Some of the documents I have contain sensitive information.\n\nHow would you recommend I do this?", "author_fullname": "t2_q7c07g3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob question: How should I mirror drives(on different PC's) and host their contents?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o6xx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674996629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a preface; I do not understand much of the lingo on this subreddit and my question might be dumb but I want to learn. Feel free to be honest with me, I can take it.&lt;/p&gt;\n\n&lt;p&gt;I have MS documents, pdfs, tax returns, contacts, receipts, photos, memes and some videos on a 1TB SSD in my gaming desktop(Windows 10) that I want to be able to access and edit from my laptop and my phone when I&amp;#39;m not at home but I do not want to host those things directly from that drive because I don&amp;#39;t like leaving that computer on when I&amp;#39;m not using it. I want the contents of that drive to be backed up automatically onto a 1TB External SSD hooked up to an Intel Nuc(Ubuntu Gnome) I just put together and have the files hosted from there. The reason I set up Gnome on the Nuc is because I also want to be able to remote into it and do other stuff with it later. I also do not want the contents of the drive to be accessible to other people using my network.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to make it so that changes made to those drives automatically transfer over to the other drive even though they&amp;#39;re on different computers and different operating systems? Would that interfere with the ability to host some of those files? I looked through the list of back-up software on github but I don&amp;#39;t entirely understand which ones would be able to do this type of thing, or do it well. Also I figure maybe just nextcloud and another media server would do it for the hosting part, but would those be safe? Some of the documents I have contain sensitive information.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend I do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6xx8", "is_robot_indexable": true, "report_reasons": null, "author": "ScriptedHorse", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o6xx8/noob_question_how_should_i_mirror_driveson/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o6xx8/noob_question_how_should_i_mirror_driveson/", "subreddit_subscribers": 226817, "created_utc": 1674996629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Basically, I have a docker setup on my NUC, with Traefik to handle LE certificates and reverse proxy for all my docker containers (home assistant, PiHole, bookstack, portainer and more ... ).\n\nNow, it happens that I will do some maintenance on my NUC, like upgrades or temporarily break things and therefor make all docker containers unavailable (including Pihole, which is even more problematic).\n\nSo in order to solve this issue, I was looking for ways to do some kind of Load Balancing or Failover to duplicated docker containers on another server so that when I try to reach [bookstack.mydomain.com](https://bookstack.mydomain.com), it would automatically point to the NUC server when it works, but to the other container on another server when the NUC is not available anymore.\n\nI was thinking of Docker Swarm, Kubernetes or things like that, but I am not familiar with those yet.\n\nWhat are the solutions you have put into place in order to avoid downtime for your selfhosted services ?", "author_fullname": "t2_4alk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Selfhosted docker &amp; Load balancing / Failover : how to do it ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o6h8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674995474.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674994947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, I have a docker setup on my NUC, with Traefik to handle LE certificates and reverse proxy for all my docker containers (home assistant, PiHole, bookstack, portainer and more ... ).&lt;/p&gt;\n\n&lt;p&gt;Now, it happens that I will do some maintenance on my NUC, like upgrades or temporarily break things and therefor make all docker containers unavailable (including Pihole, which is even more problematic).&lt;/p&gt;\n\n&lt;p&gt;So in order to solve this issue, I was looking for ways to do some kind of Load Balancing or Failover to duplicated docker containers on another server so that when I try to reach &lt;a href=\"https://bookstack.mydomain.com\"&gt;bookstack.mydomain.com&lt;/a&gt;, it would automatically point to the NUC server when it works, but to the other container on another server when the NUC is not available anymore.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of Docker Swarm, Kubernetes or things like that, but I am not familiar with those yet.&lt;/p&gt;\n\n&lt;p&gt;What are the solutions you have put into place in order to avoid downtime for your selfhosted services ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6h8s", "is_robot_indexable": true, "report_reasons": null, "author": "guigui42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o6h8s/selfhosted_docker_load_balancing_failover_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o6h8s/selfhosted_docker_load_balancing_failover_how_to/", "subreddit_subscribers": 226817, "created_utc": 1674994947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey Guys,\n\nI am searching a Backup Solution for my current docker containers. I also intend to start hosting Cloud Storage (most likely with nextcloud) and I am searching a backup solution for that aswell.\n\n*Current setup*: Debian Server with multiple docker containers (&lt;50Gb). I manually tar the docker data and copy them to another machine.\n\n*My Goal*: Cloud Storage with a 4-6TB Drive. Automatic backups of the cloud storage and my docker containers. Most likely three backup versions: last day, last week, last month (not too settled on this)\n\n*My Thoughts*: I have access to another server on another site. Thought about using borgmatic to store the backups on the other site. But my Internet speed is limited so I could only use incremental backups/sync. A full backup would take to much time. Thats why I thought to keep the backups on site and sync my main drive to the offsite server. I am also open to use a Cloud provider for an additional backup.\n\nAlso the Nextcloud downtime whilst backuping shouldnt be too long. Preferably under an hour. At most there will be 50GB of new Files/filechanges per day. Open to any recommendations you have. As my server is provisioned with ansible I am also open to migrate to proxmox or whatever might help.\n\n&amp;#x200B;\n\nI hope you can give me some recommendations/ point me in a specific direction. Thank you for your help", "author_fullname": "t2_pmefi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Searching Backup Solution for Docker containers and Cloudstorage(Nextcloud)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o6dt4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674994618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;/p&gt;\n\n&lt;p&gt;I am searching a Backup Solution for my current docker containers. I also intend to start hosting Cloud Storage (most likely with nextcloud) and I am searching a backup solution for that aswell.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Current setup&lt;/em&gt;: Debian Server with multiple docker containers (&amp;lt;50Gb). I manually tar the docker data and copy them to another machine.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;My Goal&lt;/em&gt;: Cloud Storage with a 4-6TB Drive. Automatic backups of the cloud storage and my docker containers. Most likely three backup versions: last day, last week, last month (not too settled on this)&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;My Thoughts&lt;/em&gt;: I have access to another server on another site. Thought about using borgmatic to store the backups on the other site. But my Internet speed is limited so I could only use incremental backups/sync. A full backup would take to much time. Thats why I thought to keep the backups on site and sync my main drive to the offsite server. I am also open to use a Cloud provider for an additional backup.&lt;/p&gt;\n\n&lt;p&gt;Also the Nextcloud downtime whilst backuping shouldnt be too long. Preferably under an hour. At most there will be 50GB of new Files/filechanges per day. Open to any recommendations you have. As my server is provisioned with ansible I am also open to migrate to proxmox or whatever might help.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I hope you can give me some recommendations/ point me in a specific direction. Thank you for your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6dt4", "is_robot_indexable": true, "report_reasons": null, "author": "Linusmann", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o6dt4/searching_backup_solution_for_docker_containers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o6dt4/searching_backup_solution_for_docker_containers/", "subreddit_subscribers": 226817, "created_utc": 1674994618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "", "author_fullname": "t2_vjtxw8lm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OneUptime: Open Source Self Hostable Status Page", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10o4uk1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/fdO17b4TlSuZPC4LYGSFoj0iK9I-FDF3glrEtY7zCy4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "created": 1674988648.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/oneuptime/oneuptime", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?auto=webp&amp;v=enabled&amp;s=6286897193c34ae581e5b38ddfc17ba4fbd0a505", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=803ae9958956a97efa8fecd013598d6e9e69832d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=130fa6cd575a06773403ba341233795c99f81509", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb51e9efa0ee06af3591e4f591fc609654e6419b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca621fd4ab83121ee931ad90dc04b0d5507ac2ad", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f194359208e130814cd4c39db45a775fa78813f2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rxKwnM3anBsX-SbbRCD2D1MoQ3VCwsEhK7ojwS1lUsU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d92b3deffa2c2fdb5c008b860a7e007336b2a545", "width": 1080, "height": 540}], "variants": {}, "id": "rqnTRO5Kto2zJCKVu7DalH96Fr8_RiEdJGc9xWHJ_3k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o4uk1", "is_robot_indexable": true, "report_reasons": null, "author": "simlarsen", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o4uk1/oneuptime_open_source_self_hostable_status_page/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/oneuptime/oneuptime", "subreddit_subscribers": 226817, "created_utc": 1674988648.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have a really weird situation that I don't quite understand. I've set up a VPS in the cloud to act as the entry point to my network. I put wireguard and nginx proxy manager on it to handle certain requests. I also needed to route non-http/https traffic into the wireguard network, so I used iptables to do that. This is what my iptables looks like:\n\n```\n*nat\n:PREROUTING ACCEPT [12:596]\n:INPUT ACCEPT [12:596]\n:OUTPUT ACCEPT [1:60]\n:POSTROUTING ACCEPT [1:60]\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 6000:7000 -j DNAT --to-destination 10.1.1.43\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 7159,7184,31300,22445 -j DNAT --to-destination 10.1.1.44\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 1300:1400 -j DNAT --to-destination 10.1.1.44\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 9000:9100 -j DNAT --to-destination 10.1.1.46\n-A POSTROUTING -o ens5 -j MASQUERADE\n-A POSTROUTING -d 10.1.1.44/32 -o wg1 -p tcp -m tcp -m multiport --dports 1300:1400 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.44/32 -o wg1 -p tcp -m tcp -m multiport --dports 7159,7184,31300,22445 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.43/32 -o wg1 -p tcp -m tcp -m multiport --dports 6000:7000 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.46/32 -o wg1 -p tcp -m tcp -m multiport --dports 9000:9100 -j SNAT --to-source 10.1.1.0\nCOMMIT\n# Completed on Sun Jan 29 06:09:25 2023\n# Generated by iptables-save v1.8.4 on Sun Jan 29 06:09:25 2023\n*filter\n:INPUT ACCEPT [11713:1340225]\n:FORWARD ACCEPT [189:14676]\n:OUTPUT ACCEPT [252816:65126525]\n-A FORWARD -i wg1 -j ACCEPT\nCOMMIT\n```\nSo my problem is, the nginx proxy manager only works if I have the same port forwarded in my iptables. This is a huge problem because I'll likely need tons of different entries in the reverse proxy.\n\nSo I'm trying to do `sub.domain.com -&gt; public IP -&gt; 10.1.1.46:9002`. This only works when have those last lines in the PRE/POST routing that forwards 9000:9100 to 10.1.1.46. (BTW 10.1.1.46:9002 is properly accessible internally). I tried to specify the interface to listen on for these routing tables, but that didn't work. Any solutions?\n\nEdit: Solved. So my iptables had overwritten the iptables that the npm docker container was creating, so I just flushed all the tables and restarted docker. I was able to then copy my custom routes into the updated table.", "author_fullname": "t2_7eret", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a problem with iptables interfering with my reverse proxy.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "solved", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o16k6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Solved", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674976192.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674974516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a really weird situation that I don&amp;#39;t quite understand. I&amp;#39;ve set up a VPS in the cloud to act as the entry point to my network. I put wireguard and nginx proxy manager on it to handle certain requests. I also needed to route non-http/https traffic into the wireguard network, so I used iptables to do that. This is what my iptables looks like:&lt;/p&gt;\n\n&lt;p&gt;```\n*nat\n:PREROUTING ACCEPT [12:596]\n:INPUT ACCEPT [12:596]\n:OUTPUT ACCEPT [1:60]\n:POSTROUTING ACCEPT [1:60]\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 6000:7000 -j DNAT --to-destination 10.1.1.43\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 7159,7184,31300,22445 -j DNAT --to-destination 10.1.1.44\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 1300:1400 -j DNAT --to-destination 10.1.1.44\n-A PREROUTING -i ens5 -p tcp -m tcp -m multiport --dports 9000:9100 -j DNAT --to-destination 10.1.1.46\n-A POSTROUTING -o ens5 -j MASQUERADE\n-A POSTROUTING -d 10.1.1.44/32 -o wg1 -p tcp -m tcp -m multiport --dports 1300:1400 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.44/32 -o wg1 -p tcp -m tcp -m multiport --dports 7159,7184,31300,22445 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.43/32 -o wg1 -p tcp -m tcp -m multiport --dports 6000:7000 -j SNAT --to-source 10.1.1.0\n-A POSTROUTING -d 10.1.1.46/32 -o wg1 -p tcp -m tcp -m multiport --dports 9000:9100 -j SNAT --to-source 10.1.1.0\nCOMMIT&lt;/p&gt;\n\n&lt;h1&gt;Completed on Sun Jan 29 06:09:25 2023&lt;/h1&gt;\n\n&lt;h1&gt;Generated by iptables-save v1.8.4 on Sun Jan 29 06:09:25 2023&lt;/h1&gt;\n\n&lt;p&gt;*filter\n:INPUT ACCEPT [11713:1340225]\n:FORWARD ACCEPT [189:14676]\n:OUTPUT ACCEPT [252816:65126525]\n-A FORWARD -i wg1 -j ACCEPT\nCOMMIT\n```\nSo my problem is, the nginx proxy manager only works if I have the same port forwarded in my iptables. This is a huge problem because I&amp;#39;ll likely need tons of different entries in the reverse proxy.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m trying to do &lt;code&gt;sub.domain.com -&amp;gt; public IP -&amp;gt; 10.1.1.46:9002&lt;/code&gt;. This only works when have those last lines in the PRE/POST routing that forwards 9000:9100 to 10.1.1.46. (BTW 10.1.1.46:9002 is properly accessible internally). I tried to specify the interface to listen on for these routing tables, but that didn&amp;#39;t work. Any solutions?&lt;/p&gt;\n\n&lt;p&gt;Edit: Solved. So my iptables had overwritten the iptables that the npm docker container was creating, so I just flushed all the tables and restarted docker. I was able to then copy my custom routes into the updated table.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7b9b9156-5ccb-11eb-9ab6-0e4839ba7cc3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o16k6", "is_robot_indexable": true, "report_reasons": null, "author": "Th3Appl3", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o16k6/i_have_a_problem_with_iptables_interfering_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o16k6/i_have_a_problem_with_iptables_interfering_with/", "subreddit_subscribers": 226817, "created_utc": 1674974516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Is there a way to have unlimited email domains and alias under one mail box?\n\nFor example:  \n[Person1@email.com](mailto:Person1@email.com) sends an email to [johndoe@mydomain.com](mailto:johndoe@mydomain.com), then sends a seperate email to [support@otherdomain.com](mailto:support@otherdomain.com). Can i see both those emails in one mailbox hub and when I go to reply to the email Person1 sent to [support@otherdomain.com](mailto:support@otherdomain.com) it will say it was sent from [support@otherdomain.com](mailto:support@otherdomain.com) and then I can go to the email sent to [johndoe@mydomain.com](mailto:johndoe@mydomain.com) and reply from that email. However if person1 sends an email to [admin@mydomain.com](mailto:admin@mydomain.com) and I don't have it set up then the email will not go through.\n\nAny possibility for a solution that accomplishes this?", "author_fullname": "t2_un4474ai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlimited Custom Domain Emails: Is it possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o0lss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674972438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to have unlimited email domains and alias under one mail box?&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;br/&gt;\n[&lt;a href=\"mailto:Person1@email.com\"&gt;Person1@email.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:Person1@email.com\"&gt;Person1@email.com&lt;/a&gt;) sends an email to [&lt;a href=\"mailto:johndoe@mydomain.com\"&gt;johndoe@mydomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:johndoe@mydomain.com\"&gt;johndoe@mydomain.com&lt;/a&gt;), then sends a seperate email to [&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;). Can i see both those emails in one mailbox hub and when I go to reply to the email Person1 sent to [&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;) it will say it was sent from [&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:support@otherdomain.com\"&gt;support@otherdomain.com&lt;/a&gt;) and then I can go to the email sent to [&lt;a href=\"mailto:johndoe@mydomain.com\"&gt;johndoe@mydomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:johndoe@mydomain.com\"&gt;johndoe@mydomain.com&lt;/a&gt;) and reply from that email. However if person1 sends an email to [&lt;a href=\"mailto:admin@mydomain.com\"&gt;admin@mydomain.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:admin@mydomain.com\"&gt;admin@mydomain.com&lt;/a&gt;) and I don&amp;#39;t have it set up then the email will not go through.&lt;/p&gt;\n\n&lt;p&gt;Any possibility for a solution that accomplishes this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o0lss", "is_robot_indexable": true, "report_reasons": null, "author": "simplyabloke", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/10o0lss/unlimited_custom_domain_emails_is_it_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/10o0lss/unlimited_custom_domain_emails_is_it_possible/", "subreddit_subscribers": 226817, "created_utc": 1674972438.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}