{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the last 4 hours, one error or the other keeps popping up. Never faced something like this in any other software.\n\nUpdate: I'm making do with Pyspark in my Jupyter Notebook. Had to configure some things but things working fine as of now.", "author_fullname": "t2_m8ebmzsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(RANT) I think I'll die trying to setup and run Spark with Python in my local environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10njfnd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674928815.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674924305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the last 4 hours, one error or the other keeps popping up. Never faced something like this in any other software.&lt;/p&gt;\n\n&lt;p&gt;Update: I&amp;#39;m making do with Pyspark in my Jupyter Notebook. Had to configure some things but things working fine as of now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10njfnd", "is_robot_indexable": true, "report_reasons": null, "author": "riderx65", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10njfnd/rant_i_think_ill_die_trying_to_setup_and_run/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10njfnd/rant_i_think_ill_die_trying_to_setup_and_run/", "subreddit_subscribers": 87817, "created_utc": 1674924305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A short context about my situation: I have two years of experience working as an in-house data analyst after graduating Bachelor\u2019s degree. I spent my first year in my southeast asian country, while the second year working in a multinational startup based in Eastern Europe. \n\nI want to switch to data engineering, and want to work in an analytics consulting firm to get wide experience across different industries and experience in planning and implementing end-to-end projects. I have several data engineering projects (GCP, AWS, DBT, Airflow, Kafka, etc) and have certifications of several bootcamp. However, I don\u2019t have the courage to directly apply to my dream job.\n\nMy initial plan was to move one step at a time, first switching to analytics engineer in my current company, and then switch to DE, and finally make the jump to join an analytics consulting firm. I also have plan to continue my study by taking a Master\u2019s degree, but also feel conflicted because it seems work experience is more valued than education for DE career.\n\nLast week I got an offer to switch to analytics engineer in my current comp. I think I was lowballed and get little salary bump, while the learning opportunity in that role is not so plenty. I also feel really afraid to waste another 6-12 months in this role before jumping to another role/company.\n\nTl;dr: what is your advice for a data analyst to switch to DE in consulting industry as efficient as possible? Thank you :D", "author_fullname": "t2_teveujl5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice needed: switching from in house data analyst to data engineer in consulting firm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ndkpy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674907565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A short context about my situation: I have two years of experience working as an in-house data analyst after graduating Bachelor\u2019s degree. I spent my first year in my southeast asian country, while the second year working in a multinational startup based in Eastern Europe. &lt;/p&gt;\n\n&lt;p&gt;I want to switch to data engineering, and want to work in an analytics consulting firm to get wide experience across different industries and experience in planning and implementing end-to-end projects. I have several data engineering projects (GCP, AWS, DBT, Airflow, Kafka, etc) and have certifications of several bootcamp. However, I don\u2019t have the courage to directly apply to my dream job.&lt;/p&gt;\n\n&lt;p&gt;My initial plan was to move one step at a time, first switching to analytics engineer in my current company, and then switch to DE, and finally make the jump to join an analytics consulting firm. I also have plan to continue my study by taking a Master\u2019s degree, but also feel conflicted because it seems work experience is more valued than education for DE career.&lt;/p&gt;\n\n&lt;p&gt;Last week I got an offer to switch to analytics engineer in my current comp. I think I was lowballed and get little salary bump, while the learning opportunity in that role is not so plenty. I also feel really afraid to waste another 6-12 months in this role before jumping to another role/company.&lt;/p&gt;\n\n&lt;p&gt;Tl;dr: what is your advice for a data analyst to switch to DE in consulting industry as efficient as possible? Thank you :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ndkpy", "is_robot_indexable": true, "report_reasons": null, "author": "ukmurmuk", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ndkpy/career_advice_needed_switching_from_in_house_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ndkpy/career_advice_needed_switching_from_in_house_data/", "subreddit_subscribers": 87817, "created_utc": 1674907565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wonder if knowing only Spark will help me get a job, or I need to be an expert on both?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does it make sense to learn Apache Spark without Apache Hadoop (for DE jobs/career)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nkjen", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674927181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wonder if knowing only Spark will help me get a job, or I need to be an expert on both?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10nkjen", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10nkjen/does_it_make_sense_to_learn_apache_spark_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10nkjen/does_it_make_sense_to_learn_apache_spark_without/", "subreddit_subscribers": 87817, "created_utc": 1674927181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to find ways to optimize pipelines. We currently have 10-12 large datasets that are used on a front end application and I\u2019m looking for ways to refactor the code base and improve performance. Is there any common design patterns you are aware of?\n\nSome of mine are very basic because I inherited a very poorly maintained project \n\n- MapReduce pattern \n- use reduce function call for multiple dataframes \n- repartitioning, coalescing \n- reducing rate of data updates (mine is biweekly at 5am before big reporting meeting for the front end users)\n- removing any for loops you can find\n- removing any array type columns to save on memory\n- Incremental updates to only update fresh data \n- Pruning old branches, deleting any test datasets \n- use as much AWS codeless architecture \n- Putting in a CI/CD pipeline via GitHub Actions Jenkins \n- Updating documentation on confluence", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most common patterns or efficiency enablers you encounter in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o3ytb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674985144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find ways to optimize pipelines. We currently have 10-12 large datasets that are used on a front end application and I\u2019m looking for ways to refactor the code base and improve performance. Is there any common design patterns you are aware of?&lt;/p&gt;\n\n&lt;p&gt;Some of mine are very basic because I inherited a very poorly maintained project &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MapReduce pattern &lt;/li&gt;\n&lt;li&gt;use reduce function call for multiple dataframes &lt;/li&gt;\n&lt;li&gt;repartitioning, coalescing &lt;/li&gt;\n&lt;li&gt;reducing rate of data updates (mine is biweekly at 5am before big reporting meeting for the front end users)&lt;/li&gt;\n&lt;li&gt;removing any for loops you can find&lt;/li&gt;\n&lt;li&gt;removing any array type columns to save on memory&lt;/li&gt;\n&lt;li&gt;Incremental updates to only update fresh data &lt;/li&gt;\n&lt;li&gt;Pruning old branches, deleting any test datasets &lt;/li&gt;\n&lt;li&gt;use as much AWS codeless architecture &lt;/li&gt;\n&lt;li&gt;Putting in a CI/CD pipeline via GitHub Actions Jenkins &lt;/li&gt;\n&lt;li&gt;Updating documentation on confluence&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o3ytb", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o3ytb/what_are_the_most_common_patterns_or_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10o3ytb/what_are_the_most_common_patterns_or_efficiency/", "subreddit_subscribers": 87817, "created_utc": 1674985144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im ingesting a data with the api calls and would like to use `widgets` to parameterize. In azure I have the following set up:\n\nhttps://preview.redd.it/v4qkge2tfuea1.png?width=945&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=18eb6675515ca19be2711da514657d124d39558b\n\nI have the list of `attribute_codes`, reading them with `lookup` activtiy and passing these parameters inside the databricks notebook code. Code inside the databricks:\n\n&amp;#x200B;\n\n    data, response = get_data_url(url=f\"https://p.cloud.com/api/rest/v1/attributes/{attribute_code}/options\",access_token=access_token)\n    #Removing the folder in Data Lake\n    dbutils.fs.rm(f'/mnt/bronze/attribute_code/{day}',True)\n    #Creating the folder in the Data Lake\n    dbutils.fs.mkdirs(f'/mnt/bronze/attribute_code/{day}')\n    \n    count = 0\n    #Putting the response inside of the Data Lake folder\n    dbutils.fs.put(f'/mnt/bronze/attribute_code/{day}/data_{count}.json', response.text)\n\nMy problem is that, since its in the `ForEach` loop, eveytime new parameter is passed, it deletes the entire folder with previosly, loaded data. Now someone can come and say to remove line where I drop and create the spacific daily folder but pipeline should run multiple times a day and I need to drop previously loaded data on that day and load new one.  \n\n&amp;#x200B;\n\nMy **goal** is to iterte over the entire list of the `attribute_code` and load them all in one folder with the name \"data\\_{count}.json.", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Data Factory - passing parameters to Azure Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 60, "top_awarded_type": null, "hide_score": false, "media_metadata": {"v4qkge2tfuea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 46, "x": 108, "u": "https://preview.redd.it/v4qkge2tfuea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feed411f6f3af64de9ef542436581ca3243ec0b5"}, {"y": 93, "x": 216, "u": "https://preview.redd.it/v4qkge2tfuea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e8d9741c2ad635e64258a6f0c5ba52fa6233df1"}, {"y": 137, "x": 320, "u": "https://preview.redd.it/v4qkge2tfuea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b737a6fccdf6ff3466360b7696344ed791f7c3a9"}, {"y": 275, "x": 640, "u": "https://preview.redd.it/v4qkge2tfuea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06dc271c4c3a9feec4ba77957b900a953ff0974b"}], "s": {"y": 407, "x": 945, "u": "https://preview.redd.it/v4qkge2tfuea1.png?width=945&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=18eb6675515ca19be2711da514657d124d39558b"}, "id": "v4qkge2tfuea1"}}, "name": "t3_10noo11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jiu-iAYlkd_BZScqa-DiPcOOGgdLLLb7QSaOG_wxqBI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674937715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im ingesting a data with the api calls and would like to use &lt;code&gt;widgets&lt;/code&gt; to parameterize. In azure I have the following set up:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v4qkge2tfuea1.png?width=945&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=18eb6675515ca19be2711da514657d124d39558b\"&gt;https://preview.redd.it/v4qkge2tfuea1.png?width=945&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=18eb6675515ca19be2711da514657d124d39558b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have the list of &lt;code&gt;attribute_codes&lt;/code&gt;, reading them with &lt;code&gt;lookup&lt;/code&gt; activtiy and passing these parameters inside the databricks notebook code. Code inside the databricks:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;data, response = get_data_url(url=f&amp;quot;https://p.cloud.com/api/rest/v1/attributes/{attribute_code}/options&amp;quot;,access_token=access_token)\n#Removing the folder in Data Lake\ndbutils.fs.rm(f&amp;#39;/mnt/bronze/attribute_code/{day}&amp;#39;,True)\n#Creating the folder in the Data Lake\ndbutils.fs.mkdirs(f&amp;#39;/mnt/bronze/attribute_code/{day}&amp;#39;)\n\ncount = 0\n#Putting the response inside of the Data Lake folder\ndbutils.fs.put(f&amp;#39;/mnt/bronze/attribute_code/{day}/data_{count}.json&amp;#39;, response.text)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My problem is that, since its in the &lt;code&gt;ForEach&lt;/code&gt; loop, eveytime new parameter is passed, it deletes the entire folder with previosly, loaded data. Now someone can come and say to remove line where I drop and create the spacific daily folder but pipeline should run multiple times a day and I need to drop previously loaded data on that day and load new one.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My &lt;strong&gt;goal&lt;/strong&gt; is to iterte over the entire list of the &lt;code&gt;attribute_code&lt;/code&gt; and load them all in one folder with the name &amp;quot;data_{count}.json.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10noo11", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10noo11/azure_data_factory_passing_parameters_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10noo11/azure_data_factory_passing_parameters_to_azure/", "subreddit_subscribers": 87817, "created_utc": 1674937715.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m using a Java application that\u2019s a Debezium Embedded Connector. Its input is PostgreSQL and sink is producing to Kafka. \n\nI am presently only running with one instance (Kubernetes replica desired=1). What is the recommended number of replicas for an Embedded Connector and why for production?", "author_fullname": "t2_j120t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Number of Replicas for Debezium Embedded Connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nfjtn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674913875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m using a Java application that\u2019s a Debezium Embedded Connector. Its input is PostgreSQL and sink is producing to Kafka. &lt;/p&gt;\n\n&lt;p&gt;I am presently only running with one instance (Kubernetes replica desired=1). What is the recommended number of replicas for an Embedded Connector and why for production?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10nfjtn", "is_robot_indexable": true, "report_reasons": null, "author": "kevin_meredith", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10nfjtn/number_of_replicas_for_debezium_embedded_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10nfjtn/number_of_replicas_for_debezium_embedded_connector/", "subreddit_subscribers": 87817, "created_utc": 1674913875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, has anyone enroled in this course by Udacity? I would like some opinions.\nI think the syllabus is quite interesting and I like that It focuses on AWS, but I don't know what quality of learning material it has.\nWould you recommend Datacamp or Coursera over this one?\n\nhttps://www.udacity.com/course/data-engineer-nanodegree--nd027", "author_fullname": "t2_69uxhxiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws Data Engineering Nanodegree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10o5gei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QyegggTQqfRdRoKyLvd0ruuUBGx7viZ3BqJw9MsuM6s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674991057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, has anyone enroled in this course by Udacity? I would like some opinions.\nI think the syllabus is quite interesting and I like that It focuses on AWS, but I don&amp;#39;t know what quality of learning material it has.\nWould you recommend Datacamp or Coursera over this one?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udacity.com/course/data-engineer-nanodegree--nd027\"&gt;https://www.udacity.com/course/data-engineer-nanodegree--nd027&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2atd4audc0fa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?auto=webp&amp;v=enabled&amp;s=15e0831fe1aa53901ce041365b3bc0dce736670b", "width": 1080, "height": 2340}, "resolutions": [{"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f2c4e6609efb5f2400150d2d126840ef6ee3cc5", "width": 108, "height": 216}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e54bc63757a8062954e12672d2422b590bdd7445", "width": 216, "height": 432}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63c0ea03180e4a7339c5802f7316d3936efd4db1", "width": 320, "height": 640}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0aff1d5c0e37a5f1496d197f22ea7f104cb615d0", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd3b93a8bc9b96085ca883b5649a2d09656df1d1", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f16ec28a27db48467239eef4c9ba69c5ef3c7ac", "width": 1080, "height": 2160}], "variants": {}, "id": "Rh33R0DDQS5mAIN3XEqoo-1Hj_6y_dKHDh3sQbQMMJQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o5gei", "is_robot_indexable": true, "report_reasons": null, "author": "rzgzLuis", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o5gei/aws_data_engineering_nanodegree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2atd4audc0fa1.jpg", "subreddit_subscribers": 87817, "created_utc": 1674991057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been speaking with my manager and we are thinking of having a data warehouse instance for each customer we have\n\nThey all use the same data except instead of RLS we segregate the data by giving them their own DB\n\nSeems overkill if we can have it all in one place and just use multi tenant approach?\n\nImagine having 100 Redshift instances for each customer! Has anyone done something like that?\n\nThe only benefit I can see is no data leaks between customers that\u2019s basically guaranteed", "author_fullname": "t2_htptc13q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reference architecture for serving many customers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10npejj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674939590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been speaking with my manager and we are thinking of having a data warehouse instance for each customer we have&lt;/p&gt;\n\n&lt;p&gt;They all use the same data except instead of RLS we segregate the data by giving them their own DB&lt;/p&gt;\n\n&lt;p&gt;Seems overkill if we can have it all in one place and just use multi tenant approach?&lt;/p&gt;\n\n&lt;p&gt;Imagine having 100 Redshift instances for each customer! Has anyone done something like that?&lt;/p&gt;\n\n&lt;p&gt;The only benefit I can see is no data leaks between customers that\u2019s basically guaranteed&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10npejj", "is_robot_indexable": true, "report_reasons": null, "author": "Main_Tap_1256", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10npejj/reference_architecture_for_serving_many_customers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10npejj/reference_architecture_for_serving_many_customers/", "subreddit_subscribers": 87817, "created_utc": 1674939590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll keep it brief. 21M, Spring or Fall 2024 Grad Compsci\n\n* Pursuing DE, longterm DS/ML\n* Comfortable with python and javascript\n* Learning how to use Docker and pipelines, currently taking the 2023 DE [bootcamp](https://www.reddit.com/r/dataengineering/comments/104xlft/free_data_engineering_bootcamp_data_engineering/), struggling but understanding slowly\n* Enjoy coding and learning, very beginner\n* Southern California located\n\nI was accepted into Galvanize's March full-time full-stack bootcamp program. Even after hours of research on Reddit, I'm still unsure about how I should follow my career path. I believe that improving my abilities and developing my personal portfolio/resume will increase my chances of obtaining a good job here. While focusing on my fundamental DE skills, my question is if I should study much fullstack or backend dev. Is this bootcamp even worth it at this point? Given that I won't graduate until next year. It's pricey, and I'm more interested in qualifying myself as soon as possible to enter this job market. I constantly hearing about how the job market is getting worse, and I completely understand. I just don't want to stay this end of the stick (unemployed). Courses in school are very basic and I'm learning way more off campus. I have more than enough time outside of class, as I am remote, and any advice for what I should do with my time going into this year would be GREATLY appreciated.", "author_fullname": "t2_pwk2f3iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I delay this bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o2ial", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674979443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll keep it brief. 21M, Spring or Fall 2024 Grad Compsci&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pursuing DE, longterm DS/ML&lt;/li&gt;\n&lt;li&gt;Comfortable with python and javascript&lt;/li&gt;\n&lt;li&gt;Learning how to use Docker and pipelines, currently taking the 2023 DE &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/104xlft/free_data_engineering_bootcamp_data_engineering/\"&gt;bootcamp&lt;/a&gt;, struggling but understanding slowly&lt;/li&gt;\n&lt;li&gt;Enjoy coding and learning, very beginner&lt;/li&gt;\n&lt;li&gt;Southern California located&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I was accepted into Galvanize&amp;#39;s March full-time full-stack bootcamp program. Even after hours of research on Reddit, I&amp;#39;m still unsure about how I should follow my career path. I believe that improving my abilities and developing my personal portfolio/resume will increase my chances of obtaining a good job here. While focusing on my fundamental DE skills, my question is if I should study much fullstack or backend dev. Is this bootcamp even worth it at this point? Given that I won&amp;#39;t graduate until next year. It&amp;#39;s pricey, and I&amp;#39;m more interested in qualifying myself as soon as possible to enter this job market. I constantly hearing about how the job market is getting worse, and I completely understand. I just don&amp;#39;t want to stay this end of the stick (unemployed). Courses in school are very basic and I&amp;#39;m learning way more off campus. I have more than enough time outside of class, as I am remote, and any advice for what I should do with my time going into this year would be GREATLY appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o2ial", "is_robot_indexable": true, "report_reasons": null, "author": "CowUnfair4318", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o2ial/should_i_delay_this_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10o2ial/should_i_delay_this_bootcamp/", "subreddit_subscribers": 87817, "created_utc": 1674979443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have a question about what's happening behind the scenes when I do a direct write / update in place. Say my ETL will do a batch load weekly to refresh my SCD1 dimension table. Each time, my ETL will compare the new data from the source with the current target table, and if my ETL sees that, for the same natural key, one field has a new value, my ETL will keep the old surrogate key of that row, but overwrite that one field with the new value. It's a SCD1 since my target table only keeps the latest value. But, one drawback of SCD1 is that you can't go back to the previous state if you want to abort the write. Since this seems quite risky, I'm wondering if certain databases could still keep track of history, even if my table seems to be a SCD1 table? \n\n&amp;#x200B;\n\nTo illustrate my descriptions above, here's an example: \n\nMy target table looks like below. Let's say this morning, my weekly ETL notices that for ID 12345, the \"City\" field gets a new value \"Toronto\". It will directly update that first row in place, and replace \"Ottawa\" with \"Toronto\". In this case, would the database still track that history of \"Ottawa\" behind the scenes?  Thanks everyone.\n\n|PK|ID#|Name |City|\n|:-|:-|:-|:-|\n|1|12345|Jenn|Ottawa|\n|2|23456|John|Toronto|", "author_fullname": "t2_szomhuik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question - Keep History for SCD1?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nuzdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674954479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have a question about what&amp;#39;s happening behind the scenes when I do a direct write / update in place. Say my ETL will do a batch load weekly to refresh my SCD1 dimension table. Each time, my ETL will compare the new data from the source with the current target table, and if my ETL sees that, for the same natural key, one field has a new value, my ETL will keep the old surrogate key of that row, but overwrite that one field with the new value. It&amp;#39;s a SCD1 since my target table only keeps the latest value. But, one drawback of SCD1 is that you can&amp;#39;t go back to the previous state if you want to abort the write. Since this seems quite risky, I&amp;#39;m wondering if certain databases could still keep track of history, even if my table seems to be a SCD1 table? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To illustrate my descriptions above, here&amp;#39;s an example: &lt;/p&gt;\n\n&lt;p&gt;My target table looks like below. Let&amp;#39;s say this morning, my weekly ETL notices that for ID 12345, the &amp;quot;City&amp;quot; field gets a new value &amp;quot;Toronto&amp;quot;. It will directly update that first row in place, and replace &amp;quot;Ottawa&amp;quot; with &amp;quot;Toronto&amp;quot;. In this case, would the database still track that history of &amp;quot;Ottawa&amp;quot; behind the scenes?  Thanks everyone.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;PK&lt;/th&gt;\n&lt;th align=\"left\"&gt;ID#&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;City&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;12345&lt;/td&gt;\n&lt;td align=\"left\"&gt;Jenn&lt;/td&gt;\n&lt;td align=\"left\"&gt;Ottawa&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;23456&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Toronto&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10nuzdr", "is_robot_indexable": true, "report_reasons": null, "author": "TendMyOwnGarden", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10nuzdr/question_keep_history_for_scd1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10nuzdr/question_keep_history_for_scd1/", "subreddit_subscribers": 87817, "created_utc": 1674954479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing Versatile Data Kit with Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10njrip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5malXLfq1z-s8s9PaOZkUssXtykGx7kzpxHChElGxEk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674925160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/versatile-data-kit/comparing-versatile-data-kit-with-apache-airflow-db3a082f588b", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?auto=webp&amp;v=enabled&amp;s=c89797abdbf431319d2d3f201dc709a8c87acaf6", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5906b97e47ed0ef65d5dd0a949e608037e6d8b17", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74a0c1a8f94f6f398bad005dd640ef495879ff7e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce47157137907e39ff5685996c87fad1c3334953", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1180d829ee1a2e81310d0b521a564f98b8258426", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a668c7985ccd9acde508c86ec48c336ea3c3367", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/FTm13xv80JZhQQW-IinZL567QkzzPzTizLCLBX2IDa8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d10e3fcd6ad63ddcf4c09c922d4385eef990bf7", "width": 1080, "height": 607}], "variants": {}, "id": "NX08ZniyqVj9q02bg2yv2BXiFBfgQSo424KeQo3AK-Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10njrip", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10njrip/comparing_versatile_data_kit_with_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/versatile-data-kit/comparing-versatile-data-kit-with-apache-airflow-db3a082f588b", "subreddit_subscribers": 87817, "created_utc": 1674925160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone,  are there any meetups for Data \nprofessionals in NJ area?", "author_fullname": "t2_gtqs4z53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meetups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ngrdv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674917297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,  are there any meetups for Data \nprofessionals in NJ area?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ngrdv", "is_robot_indexable": true, "report_reasons": null, "author": "10xbek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ngrdv/meetups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ngrdv/meetups/", "subreddit_subscribers": 87817, "created_utc": 1674917297.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}