{"kind": "Listing", "data": {"after": "t3_10nk804", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2xjdvpun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Waittt What?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": false, "name": "t3_10nyhcl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 695, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 695, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w9vi5By1rDrssAKaG_NyylSG68BUDbkr6m-Vd47ETDU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674965318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/kbyv8h9u7yea1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?auto=webp&amp;v=enabled&amp;s=23c1005bb9046a0a296413e9bfe553c61ce8f9d7", "width": 864, "height": 751}, "resolutions": [{"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e7f87db54f90f5838b2918ced61ef24dbfcef35", "width": 108, "height": 93}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb32ae96bb90e17702fc3bca5e7cc2dfcd3815de", "width": 216, "height": 187}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92fb6dea8e15502cdec69edb551e8e769ac47e39", "width": 320, "height": 278}, {"url": "https://preview.redd.it/kbyv8h9u7yea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f3b4b58c68ac8647735ac31be2b667c4b823436", "width": 640, "height": 556}], "variants": {}, "id": "XZNSxmVBRbsUVBChV_U7BLhRSc66dKoHdMrhKvEsz90"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nyhcl", "is_robot_indexable": true, "report_reasons": null, "author": "deepcontractor", "discussion_type": null, "num_comments": 165, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nyhcl/waittt_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/kbyv8h9u7yea1.png", "subreddit_subscribers": 842363, "created_utc": 1674965318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is this a reasonable interview coding question? ^ I was asked to code a perceptron from scratch with plain python, including backpropagation, calculate gradients and loss and update weights. I know it's a fun exercise to code a perceptron from scratch and almost all of us have done this at some point in our lives probably.\n\nI have over 2 years of work experience and wasn't expecting such interview question.\n\nI am glad I did fine though with a little bit of nudging given by the interviewer, but I am wondering if this was a reasonable interview question at all.\n\nEdit: I was interviewing for a deep learning engineer role", "author_fullname": "t2_9zl8m712", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is asking candidate (2 years experience) to code neural network from scratch on a live interview call a reasonable interview question?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nmite", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 245, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 245, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674980484.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674932246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is this a reasonable interview coding question? ^ I was asked to code a perceptron from scratch with plain python, including backpropagation, calculate gradients and loss and update weights. I know it&amp;#39;s a fun exercise to code a perceptron from scratch and almost all of us have done this at some point in our lives probably.&lt;/p&gt;\n\n&lt;p&gt;I have over 2 years of work experience and wasn&amp;#39;t expecting such interview question.&lt;/p&gt;\n\n&lt;p&gt;I am glad I did fine though with a little bit of nudging given by the interviewer, but I am wondering if this was a reasonable interview question at all.&lt;/p&gt;\n\n&lt;p&gt;Edit: I was interviewing for a deep learning engineer role&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10nmite", "is_robot_indexable": true, "report_reasons": null, "author": "OkAssociation8879", "discussion_type": null, "num_comments": 210, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nmite/is_asking_candidate_2_years_experience_to_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nmite/is_asking_candidate_2_years_experience_to_code/", "subreddit_subscribers": 842363, "created_utc": 1674932246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4w7rpbr7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any good, practical Data Science \"Cookbook\" style books/materials? Ie with step by step instructions, code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10njw8j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674925473.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10njw8j", "is_robot_indexable": true, "report_reasons": null, "author": "jarena009", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10njw8j/are_there_any_good_practical_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10njw8j/are_there_any_good_practical_data_science/", "subreddit_subscribers": 842363, "created_utc": 1674925473.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I'm creating a cheat sheet for beginners in machine learning that provides an overview of various unsupervised, supervised, and semi-supervised learning algorithms. The goal of this cheat sheet is to help beginners understand the different types of algorithms, their applications, and examples of how they are used. I would greatly appreciate any feedback on what else I can add to the cheat sheet to make it more useful for beginners. Please let me know your thoughts!\n\nMachine Learning Cheat Sheet: [https://medium.com/p/2992e295ee64](https://medium.com/p/2992e295ee64)", "author_fullname": "t2_vb57b4y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback: How to Improve My Cheat Sheet for Beginners in Machine Learning Algorithms - Types, Applications, and Examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nlpmy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674930156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m creating a cheat sheet for beginners in machine learning that provides an overview of various unsupervised, supervised, and semi-supervised learning algorithms. The goal of this cheat sheet is to help beginners understand the different types of algorithms, their applications, and examples of how they are used. I would greatly appreciate any feedback on what else I can add to the cheat sheet to make it more useful for beginners. Please let me know your thoughts!&lt;/p&gt;\n\n&lt;p&gt;Machine Learning Cheat Sheet: &lt;a href=\"https://medium.com/p/2992e295ee64\"&gt;https://medium.com/p/2992e295ee64&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?auto=webp&amp;v=enabled&amp;s=5f3596c045dbd8e1e0f8532ac2047b56fbf44b0d", "width": 1200, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c2bebe0bf059775fa30ffdc46b8585188bf73d3", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3457fa2e0751aa72a8bbe5e1f78400ab435b37a", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80d7786b978822b8c04cfa9477b24332750994d9", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46b47a1adabf58e50ce167f15f06a00fca29af0a", "width": 640, "height": 341}, {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0645e33699fbae6105d1a6a53b6b64e74e8ccc0e", "width": 960, "height": 512}, {"url": "https://external-preview.redd.it/t4WzYuiI8ySZh2TePkVk3LHZSr4q1qzYKzUPH-NkiSc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ab157ed2b19c19cfcbff7b28bb1a2d2f93e1e2f7", "width": 1080, "height": 576}], "variants": {}, "id": "wIAXaExyBH9ozPkJQS6Z8OvqcZAN6ZYv2hDA8cwMmBQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nlpmy", "is_robot_indexable": true, "report_reasons": null, "author": "Historical-Pen9653", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nlpmy/seeking_feedback_how_to_improve_my_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nlpmy/seeking_feedback_how_to_improve_my_cheat_sheet/", "subreddit_subscribers": 842363, "created_utc": 1674930156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on a data science project in an Indian ecommerce firm for the last one year. I have tried many different techniques and variations, however, I am yet to create a significant 'impact' according to my manager. Now as the days pass by, I am increasingly worried snd feel under a lot of pressure to get the project productionized. But I keep thinking this: what if it turns out to have no significant impact till the next few months?\n\nI talked to my manager about this, and even though he has assured me that I wont be laid off, that at the worst if the next few months the project does not yield any positive results and that I may be shifted to snother project, I am not sure of what should I do.\n\nShould I prepare for a possible layoff? Or should I plan to leave just in case this whole thing goes south? \n\nHave you faced a situation like this wiht yoir career? What happened then? How sre such situations usually resolved?\n\nI am looking for people in senior positions, ones who have seen the landscape of this industry for quite some years to provide me advice on this. I am a fresher with around 2 years of experience. And I also have a master's in data science from one of the top  government institutions in India. (Just giving out some details for context). Thanks", "author_fullname": "t2_2f84mqf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stuck in the same project without results for a year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nl7ah", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674928875.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a data science project in an Indian ecommerce firm for the last one year. I have tried many different techniques and variations, however, I am yet to create a significant &amp;#39;impact&amp;#39; according to my manager. Now as the days pass by, I am increasingly worried snd feel under a lot of pressure to get the project productionized. But I keep thinking this: what if it turns out to have no significant impact till the next few months?&lt;/p&gt;\n\n&lt;p&gt;I talked to my manager about this, and even though he has assured me that I wont be laid off, that at the worst if the next few months the project does not yield any positive results and that I may be shifted to snother project, I am not sure of what should I do.&lt;/p&gt;\n\n&lt;p&gt;Should I prepare for a possible layoff? Or should I plan to leave just in case this whole thing goes south? &lt;/p&gt;\n\n&lt;p&gt;Have you faced a situation like this wiht yoir career? What happened then? How sre such situations usually resolved?&lt;/p&gt;\n\n&lt;p&gt;I am looking for people in senior positions, ones who have seen the landscape of this industry for quite some years to provide me advice on this. I am a fresher with around 2 years of experience. And I also have a master&amp;#39;s in data science from one of the top  government institutions in India. (Just giving out some details for context). Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nl7ah", "is_robot_indexable": true, "report_reasons": null, "author": "egregious1527", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nl7ah/stuck_in_the_same_project_without_results_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nl7ah/stuck_in_the_same_project_without_results_for_a/", "subreddit_subscribers": 842363, "created_utc": 1674928875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the U.S. and I've enrolled in the WIOWA (Workforce Innovation and Opportunity Act) program since I'm a dislocated worker. I'm interested in getting a cert through UCLA's Extension course program. If you've gotten certs what was your experience?", "author_fullname": "t2_3nbsitw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone gotten a job with a data science certificate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nzuig", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674969866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the U.S. and I&amp;#39;ve enrolled in the WIOWA (Workforce Innovation and Opportunity Act) program since I&amp;#39;m a dislocated worker. I&amp;#39;m interested in getting a cert through UCLA&amp;#39;s Extension course program. If you&amp;#39;ve gotten certs what was your experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nzuig", "is_robot_indexable": true, "report_reasons": null, "author": "madlove17", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nzuig/has_anyone_gotten_a_job_with_a_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nzuig/has_anyone_gotten_a_job_with_a_data_science/", "subreddit_subscribers": 842363, "created_utc": 1674969866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been wondering how useful data analytics and data science is to the professionals' life outside of work. I know that SWE's will sometimes code up something they find useful for their everyday lives like automating tasks or making web apps for themselves that they find useful/fun, and I'm wondering if data professionals have something similar to that. \n\nLike have you ever been pondering a question to yourself and decided to pull in some data to answer it?", "author_fullname": "t2_wb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists and Data Analysts: Do you ever use your knowledge and experience in your profession outside of your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nkatr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674926538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wondering how useful data analytics and data science is to the professionals&amp;#39; life outside of work. I know that SWE&amp;#39;s will sometimes code up something they find useful for their everyday lives like automating tasks or making web apps for themselves that they find useful/fun, and I&amp;#39;m wondering if data professionals have something similar to that. &lt;/p&gt;\n\n&lt;p&gt;Like have you ever been pondering a question to yourself and decided to pull in some data to answer it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nkatr", "is_robot_indexable": true, "report_reasons": null, "author": "TinyStego", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nkatr/data_scientists_and_data_analysts_do_you_ever_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nkatr/data_scientists_and_data_analysts_do_you_ever_use/", "subreddit_subscribers": 842363, "created_utc": 1674926538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say I\u2019m trying to increase the proportion of total female customers on my site. If I test 2 landing pages and my target metric is proportion of total purchases that are women, what test should I use? \n\nLet\u2019s say we have the following sample data:\n\nControl: 400 male customers, 600 female customers\n\nTreatment: 350 male customers, 600 female customers\n\nWhat test can I use to test whether the increase in female proportion is statistically significant?", "author_fullname": "t2_azc8nt5r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What test to use to test differences in proportions of total?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o1978", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674974798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say I\u2019m trying to increase the proportion of total female customers on my site. If I test 2 landing pages and my target metric is proportion of total purchases that are women, what test should I use? &lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say we have the following sample data:&lt;/p&gt;\n\n&lt;p&gt;Control: 400 male customers, 600 female customers&lt;/p&gt;\n\n&lt;p&gt;Treatment: 350 male customers, 600 female customers&lt;/p&gt;\n\n&lt;p&gt;What test can I use to test whether the increase in female proportion is statistically significant?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o1978", "is_robot_indexable": true, "report_reasons": null, "author": "zsa23761", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o1978/what_test_to_use_to_test_differences_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o1978/what_test_to_use_to_test_differences_in/", "subreddit_subscribers": 842363, "created_utc": 1674974798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I notice a lot of my research at work ends up taking me to methods in information theory or signal processing. I was wondering what graduate college courses in mathematics would be most helpful to me as a data scientist. I have an undergrad in mathematics with calc, linear algebra, probability and statistics, ODE, analysis, etc. but no PDE, information theory, signal processing or graph theory. I also don\u2019t have any courses in advanced or specific statistics courses such as time series analysis, combinatorics, or Bayesian inference\u2014although I\u2019m familiar with the fundamentals from my undergrad probability courses.\n\nI\u2019m already pretty familiar with most of the models and methods in elements of statistical learning. It\u2019s more about being able to develop or understand novel methods and having a foundational base that prepares me for anything.", "author_fullname": "t2_o711uvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For mathematicians/statisticians: besides calc/stats/linalg, what are the most important (or additive) foundational math courses for data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nvsta", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674956956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I notice a lot of my research at work ends up taking me to methods in information theory or signal processing. I was wondering what graduate college courses in mathematics would be most helpful to me as a data scientist. I have an undergrad in mathematics with calc, linear algebra, probability and statistics, ODE, analysis, etc. but no PDE, information theory, signal processing or graph theory. I also don\u2019t have any courses in advanced or specific statistics courses such as time series analysis, combinatorics, or Bayesian inference\u2014although I\u2019m familiar with the fundamentals from my undergrad probability courses.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m already pretty familiar with most of the models and methods in elements of statistical learning. It\u2019s more about being able to develop or understand novel methods and having a foundational base that prepares me for anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nvsta", "is_robot_indexable": true, "report_reasons": null, "author": "CSCCguy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nvsta/for_mathematiciansstatisticians_besides/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nvsta/for_mathematiciansstatisticians_besides/", "subreddit_subscribers": 842363, "created_utc": 1674956956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When working with large datasets or executing complex operations using pandas, you may experience Out of Memory (OOM) errors or long waiting periods for the results.\n\n[Xorbits](https://github.com/xprobe-inc/xorbits) can be an ideal solution for these issues. Xorbits is a scalable Python data science framework that aims to scale the Python data science stack while keeping the API compatibility. You can get an out-of-box performance gain by changing \\`import pandas as pd\\` to \\`import xorbits.pandas as pd\\`.\n\nCompared with other pandas-like solutions, Xorbits offers stronger performance, simpler deployment, and better API compatibility.\n\nWith TPC-H benchmarks at scale factor 100, Xorbits is 7x faster than Dask. For the benchmark results compared to other pandas-like systems, please visit: [https://xorbits.io/benchmark](https://xorbits.io/benchmark)\n\nhttps://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989\n\nIf you are interested in learning more about Xorbits, please visit our project's Github  for more information: [https://github.com/xprobe-inc/xorbits](https://github.com/xprobe-inc/xorbits)", "author_fullname": "t2_sjfelxlq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A new way to accelerate your data science workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uyavcs2irqea1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c90a2aeb13de9bcd562106cfd0869bdde2efe6b8"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5dfcffa915bb9c88044a9990d8a2d6a91753793"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0332d904f1a8d783952949deb04e0d66ab20a848"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82013bf136cdab2a1a24492f7c80e95a705e2018"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9950ac39a34ab5b8d73d77adaef7396f8b6451a"}, {"y": 514, "x": 1080, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08df56cae3ef6206e5a7fb644d532938ccc3e10f"}], "s": {"y": 1120, "x": 2353, "u": "https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989"}, "id": "uyavcs2irqea1"}}, "name": "t3_10o0djh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674971652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When working with large datasets or executing complex operations using pandas, you may experience Out of Memory (OOM) errors or long waiting periods for the results.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/xprobe-inc/xorbits\"&gt;Xorbits&lt;/a&gt; can be an ideal solution for these issues. Xorbits is a scalable Python data science framework that aims to scale the Python data science stack while keeping the API compatibility. You can get an out-of-box performance gain by changing `import pandas as pd` to `import xorbits.pandas as pd`.&lt;/p&gt;\n\n&lt;p&gt;Compared with other pandas-like solutions, Xorbits offers stronger performance, simpler deployment, and better API compatibility.&lt;/p&gt;\n\n&lt;p&gt;With TPC-H benchmarks at scale factor 100, Xorbits is 7x faster than Dask. For the benchmark results compared to other pandas-like systems, please visit: &lt;a href=\"https://xorbits.io/benchmark\"&gt;https://xorbits.io/benchmark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989\"&gt;https://preview.redd.it/uyavcs2irqea1.png?width=2353&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=6488a5cc45c95879e651fb43ad8b28f25eb4e989&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you are interested in learning more about Xorbits, please visit our project&amp;#39;s Github  for more information: &lt;a href=\"https://github.com/xprobe-inc/xorbits\"&gt;https://github.com/xprobe-inc/xorbits&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?auto=webp&amp;v=enabled&amp;s=b4c437d9780f7deea38942e2f71874c4a5792ae0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8a20714e73d397807f6c3406afbc874486db459", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50984ace269a047c9250492e6ed13ddee7237ffb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a082fd5140f7529a4ae937e4136c0c7e0dfa8f01", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9514a20c7b740464677a7063d0823d7dbc6b97b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58e91db6a21bda66ff44ea8af3724eff5fd6b9ca", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/I_4n6wAjMo87v8gXwWLHgz8fpyi4zedQUKUfd02_-ZA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f7973ace9a043c8b0c44ab67eb446f16600814", "width": 1080, "height": 540}], "variants": {}, "id": "zluzOfHdaTc_wTtSW5PBzgxataxeTpLBkbFxOxEzruo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o0djh", "is_robot_indexable": true, "report_reasons": null, "author": "CORNMONSTER_2022", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o0djh/a_new_way_to_accelerate_your_data_science_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o0djh/a_new_way_to_accelerate_your_data_science_workflow/", "subreddit_subscribers": 842363, "created_utc": 1674971652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I spent like 40 hours building this project which is now useless due to title^. Is it still worth including it and it\u2019s code in my resume and portfolio? If so, what disclaimers should I include?", "author_fullname": "t2_3mnpqskk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A module my project depended on to retrieve data is obsolete. Still include project in portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nolvw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674937555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I spent like 40 hours building this project which is now useless due to title&lt;sup&gt;.&lt;/sup&gt; Is it still worth including it and it\u2019s code in my resume and portfolio? If so, what disclaimers should I include?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nolvw", "is_robot_indexable": true, "report_reasons": null, "author": "AbsoluteNeanderthall", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nolvw/a_module_my_project_depended_on_to_retrieve_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nolvw/a_module_my_project_depended_on_to_retrieve_data/", "subreddit_subscribers": 842363, "created_utc": 1674937555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All,\n\nI am working on a project trying to analyze ride-sharing to and from airports.  I have emailed airports and ridesharing companies and searched Kaggle and other sites.  Now I'm looking for some more information/advice.\n\nDoes anyone have any suggestions on where I could find ridesharing data? Or where I could scrape it from? Or anyone that I could contact.  Or any other subreddits I should try?\n\nThanks!", "author_fullname": "t2_10sshp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airport ridesharing data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o9k47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675004323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I am working on a project trying to analyze ride-sharing to and from airports.  I have emailed airports and ridesharing companies and searched Kaggle and other sites.  Now I&amp;#39;m looking for some more information/advice.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions on where I could find ridesharing data? Or where I could scrape it from? Or anyone that I could contact.  Or any other subreddits I should try?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o9k47", "is_robot_indexable": true, "report_reasons": null, "author": "frankOFWGKTA", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o9k47/airport_ridesharing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o9k47/airport_ridesharing_data/", "subreddit_subscribers": 842363, "created_utc": 1675004323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I saw a poll on r/cscareerquestionsEU which asked the number of weeks SWEs get as vacation in Switzerland. Most people replied 5 and 6 weeks. I guess there's a lot of declared holidays too (~30 days in a year). Unlimited sick leave is common across EU I guess. \n\nWhich countries have good pay and the highest possibility that I can take a 1 month long block leave (bring completely out of reach)? \n\nAnd which countries or organizations have the highest amount of leaves in general that people do end up taking?  I'm going to be doing an MS in AI/DS soon in the US. But can apply to some Unis in EU as well. I'm learning that US wouldn't let me take much leaves. \n\nAlso any other Careers that let you take 3 weeks to longer than 2 month leaves?\ud83d\ude2c", "author_fullname": "t2_2p7ddtjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which countries /orgz let you take more than 1 month long leaves?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o93j1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675003102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a poll on &lt;a href=\"/r/cscareerquestionsEU\"&gt;r/cscareerquestionsEU&lt;/a&gt; which asked the number of weeks SWEs get as vacation in Switzerland. Most people replied 5 and 6 weeks. I guess there&amp;#39;s a lot of declared holidays too (~30 days in a year). Unlimited sick leave is common across EU I guess. &lt;/p&gt;\n\n&lt;p&gt;Which countries have good pay and the highest possibility that I can take a 1 month long block leave (bring completely out of reach)? &lt;/p&gt;\n\n&lt;p&gt;And which countries or organizations have the highest amount of leaves in general that people do end up taking?  I&amp;#39;m going to be doing an MS in AI/DS soon in the US. But can apply to some Unis in EU as well. I&amp;#39;m learning that US wouldn&amp;#39;t let me take much leaves. &lt;/p&gt;\n\n&lt;p&gt;Also any other Careers that let you take 3 weeks to longer than 2 month leaves?\ud83d\ude2c&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o93j1", "is_robot_indexable": true, "report_reasons": null, "author": "anotheraccount97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o93j1/which_countries_orgz_let_you_take_more_than_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o93j1/which_countries_orgz_let_you_take_more_than_1/", "subreddit_subscribers": 842363, "created_utc": 1675003102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "SVMs were covered quite poorly in my Machine Learning course last semester, the teacher quickly glossed over the maths, only ever mentioning the key bits of it like \"Langrangian\" or \"Kuhn-Tucker conditions\". Most resources I referred just went \"the math is out of the scope of this textbook\"\n\nNow I still have no clue what or how SVMs find the Maximal Margin Hyperplane. I am looking for resources that help me understand. I have no problem sinking some time into learning the maths (I believe it's called optimization theory?) behind it either.\n\nThanks!", "author_fullname": "t2_1fe83wwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good resources for covering SVMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o8s1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675002217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SVMs were covered quite poorly in my Machine Learning course last semester, the teacher quickly glossed over the maths, only ever mentioning the key bits of it like &amp;quot;Langrangian&amp;quot; or &amp;quot;Kuhn-Tucker conditions&amp;quot;. Most resources I referred just went &amp;quot;the math is out of the scope of this textbook&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Now I still have no clue what or how SVMs find the Maximal Margin Hyperplane. I am looking for resources that help me understand. I have no problem sinking some time into learning the maths (I believe it&amp;#39;s called optimization theory?) behind it either.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o8s1t", "is_robot_indexable": true, "report_reasons": null, "author": "HyperKingK", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o8s1t/good_resources_for_covering_svms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o8s1t/good_resources_for_covering_svms/", "subreddit_subscribers": 842363, "created_utc": 1675002217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there, \n\nI have 2 semesters left to get graduated in economics and so far the subjects that I enjoyed the most have been econometrics and statistics. In fact, I just finished a DS minor this semester which was pretty enjoyable for me. \n\nThe thing is, I'm starting to look for bootcamps or self-taught so I could start developing my career in DS as soon as possible, but I'm not sure if this is the right choice. To make it clear, I would 100% finish the degree but maybe not as my first priority if I could get a DS job.\n\nWould you recommend finishing my degree and then focusing on DS or is it a good choice to prioritize learning DS and trying to get a job?\n\nThanks in advance,", "author_fullname": "t2_s3ah602a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I finish my economics degree asap or focus on learning DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o7npg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674998955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, &lt;/p&gt;\n\n&lt;p&gt;I have 2 semesters left to get graduated in economics and so far the subjects that I enjoyed the most have been econometrics and statistics. In fact, I just finished a DS minor this semester which was pretty enjoyable for me. &lt;/p&gt;\n\n&lt;p&gt;The thing is, I&amp;#39;m starting to look for bootcamps or self-taught so I could start developing my career in DS as soon as possible, but I&amp;#39;m not sure if this is the right choice. To make it clear, I would 100% finish the degree but maybe not as my first priority if I could get a DS job.&lt;/p&gt;\n\n&lt;p&gt;Would you recommend finishing my degree and then focusing on DS or is it a good choice to prioritize learning DS and trying to get a job?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o7npg", "is_robot_indexable": true, "report_reasons": null, "author": "Pitiful-Carpet8141", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o7npg/should_i_finish_my_economics_degree_asap_or_focus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o7npg/should_i_finish_my_economics_degree_asap_or_focus/", "subreddit_subscribers": 842363, "created_utc": 1674998955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks,   \n\n\n Currently working through the IBM DS and Google Analytics certificate. I am a complete rookie in DS.\n\nI am interested in where linguistics and  behavioral economics intersect with data science in terms of the types of jobs/research fields to target as it seems like 'Data Scientist' is somewhat of a catch all term for HR departments. \n\nIn terms of a following a learning pathway, employers (HR?) seem to all look for a degree, however online postgrad and BsS computer science course seem overpriced and, outside of data science specific programs, not as good as combining bootcamps, certificates and other online learning routes. Is this the case?   \n\n\nIn terms of building a portfolio of work, or a learning journal that can be linked to CV, does anyone have any recommendations?   \n\n\nMany thanks for any help!", "author_fullname": "t2_6d9ki34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Learning Pathway(s) and where personal interests intersect with DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nzin7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674968739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,   &lt;/p&gt;\n\n&lt;p&gt;Currently working through the IBM DS and Google Analytics certificate. I am a complete rookie in DS.&lt;/p&gt;\n\n&lt;p&gt;I am interested in where linguistics and  behavioral economics intersect with data science in terms of the types of jobs/research fields to target as it seems like &amp;#39;Data Scientist&amp;#39; is somewhat of a catch all term for HR departments. &lt;/p&gt;\n\n&lt;p&gt;In terms of a following a learning pathway, employers (HR?) seem to all look for a degree, however online postgrad and BsS computer science course seem overpriced and, outside of data science specific programs, not as good as combining bootcamps, certificates and other online learning routes. Is this the case?   &lt;/p&gt;\n\n&lt;p&gt;In terms of building a portfolio of work, or a learning journal that can be linked to CV, does anyone have any recommendations?   &lt;/p&gt;\n\n&lt;p&gt;Many thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nzin7", "is_robot_indexable": true, "report_reasons": null, "author": "SilentWitness13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nzin7/advice_on_learning_pathways_and_where_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nzin7/advice_on_learning_pathways_and_where_personal/", "subreddit_subscribers": 842363, "created_utc": 1674968739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_nq03g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What if Patrick Bateman was a Data Scientist? An AI-Generated Video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10ntk65", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b8m003GKqSwotrtcvTdv3eneh_0QT7UlU25gju0jPhY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674950455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@dreamferus/what-if-patrick-bateman-was-a-data-scientist-an-ai-generated-video-342003f60914?sk=e7426d5b5f46ab4a269d7014efa9e22c", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?auto=webp&amp;v=enabled&amp;s=2f77d38323d6f16625e9b7d65953de579422a305", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5f0b778740348927c9184686544a4afc8ef9a72", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbe077c31f3e0a224165c9d0f095b6354febdd55", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=178d315a67dc67490a2627c1fef6b69e7acfbcbd", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d5b32cd7c6a2ea3b14a9bfb07f6720cca8fb6cb", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/z7KNzrk8nHuQuVNJ6jRWYZds5J-7PmqjPzQ1AE-zDzQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15abf2a44025a73cfa07a2860888218e6b51609f", "width": 960, "height": 960}], "variants": {}, "id": "sU_gduBY2tjcuvQH2lrSYWUOM-XygNpqWTHPKurlPPk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ntk65", "is_robot_indexable": true, "report_reasons": null, "author": "SupPandaHugger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ntk65/what_if_patrick_bateman_was_a_data_scientist_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@dreamferus/what-if-patrick-bateman-was-a-data-scientist-an-ai-generated-video-342003f60914?sk=e7426d5b5f46ab4a269d7014efa9e22c", "subreddit_subscribers": 842363, "created_utc": 1674950455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was just watching Mindhunter and they were trying to create a profile for what a serial killer would look like based of of crimes. In such an analysis would missing actually be a potential indicator in one direction or another, like a particular characteristic never came up before.", "author_fullname": "t2_6keerz23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could missing data be considered an indicator for things within itself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10njh44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674924405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just watching Mindhunter and they were trying to create a profile for what a serial killer would look like based of of crimes. In such an analysis would missing actually be a potential indicator in one direction or another, like a particular characteristic never came up before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10njh44", "is_robot_indexable": true, "report_reasons": null, "author": "SurinamMix2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10njh44/could_missing_data_be_considered_an_indicator_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10njh44/could_missing_data_be_considered_an_indicator_for/", "subreddit_subscribers": 842363, "created_utc": 1674924405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I encountered a question about Kernel SVM in a interview test to a internship, but I am not certain about the answer. Can anyone try to answer it?\n\nTo use a Gaussian kernel SVM, we usually normaliz the feature. Which one or few of following options is (are) True?\n\na. \uff08I don't quite remember this option. This one I pretty sure is True, but next two I am uncertain about. Can anyone help me remember it?)\nb. Sometimes some features cannot be normalized like categorical feature.\nc. Gaussian kernel SVM cannot be done without feature normalization.", "author_fullname": "t2_5aabbadw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions about kernel SVM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10o86lw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675000543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I encountered a question about Kernel SVM in a interview test to a internship, but I am not certain about the answer. Can anyone try to answer it?&lt;/p&gt;\n\n&lt;p&gt;To use a Gaussian kernel SVM, we usually normaliz the feature. Which one or few of following options is (are) True?&lt;/p&gt;\n\n&lt;p&gt;a. \uff08I don&amp;#39;t quite remember this option. This one I pretty sure is True, but next two I am uncertain about. Can anyone help me remember it?)\nb. Sometimes some features cannot be normalized like categorical feature.\nc. Gaussian kernel SVM cannot be done without feature normalization.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o86lw", "is_robot_indexable": true, "report_reasons": null, "author": "ArchibaldChain", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o86lw/interview_questions_about_kernel_svm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o86lw/interview_questions_about_kernel_svm/", "subreddit_subscribers": 842363, "created_utc": 1675000543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "HI folks\n\n&amp;#x200B;\n\nI am toying with the idea of a OMSCS vs MS DS in UT Austin or MS DS from Colorado, Boulder. I am a bit worried about being weak (have logn forgotten my programming skills) in Data Structures/Algorithms and so have some conerns on doing OMSCS. What would this group advise?\n\n&amp;#x200B;\n\nThanks.", "author_fullname": "t2_6m1wqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OMSCS in GaTech vs MS DS in UT Austin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o60t6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674993326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HI folks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am toying with the idea of a OMSCS vs MS DS in UT Austin or MS DS from Colorado, Boulder. I am a bit worried about being weak (have logn forgotten my programming skills) in Data Structures/Algorithms and so have some conerns on doing OMSCS. What would this group advise?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o60t6", "is_robot_indexable": true, "report_reasons": null, "author": "karraju", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o60t6/omscs_in_gatech_vs_ms_ds_in_ut_austin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o60t6/omscs_in_gatech_vs_ms_ds_in_ut_austin/", "subreddit_subscribers": 842363, "created_utc": 1674993326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1jg4zv3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to educate myself using online resources to get a job as a junior data scientist with no prior background in the field? If so, I would really appreciate any resource that can be shared. Thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o49lr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674986372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o49lr", "is_robot_indexable": true, "report_reasons": null, "author": "Keep_learning88", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o49lr/is_it_possible_to_educate_myself_using_online/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o49lr/is_it_possible_to_educate_myself_using_online/", "subreddit_subscribers": 842363, "created_utc": 1674986372.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If you could also recommend where can I learn data preprocessing for ML extensively, would be a huge help.", "author_fullname": "t2_ngxvv0t4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there any companies or startups cleaning and pre-processing data for bigger companies that eventually use them for analytics or ML? Want to know their name?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nks8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674927823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you could also recommend where can I learn data preprocessing for ML extensively, would be a huge help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nks8h", "is_robot_indexable": true, "report_reasons": null, "author": "Federal_Ass_58", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nks8h/are_there_any_companies_or_startups_cleaning_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10nks8h/are_there_any_companies_or_startups_cleaning_and/", "subreddit_subscribers": 842363, "created_utc": 1674927823.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have an encoder model which was working fine with single channel 1024,1024 images, I'm trying to patch the original images (mega pixel images) to 256, 256, 64 images. I've changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I'm getting the following error with tape.gradient:\n\n    2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn('resource_tracker: There appear to be %d '                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n\nMy code is as below\n\n    class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n        super(encoder, self).__init__()     #encoder Module\n        self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n        self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding='same',activation='relu')\n        self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding='same',activation='relu')\n        self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding='same',activation='relu')\n        self.conv_5 = keras.layers.BatchNormalization()\n        self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding='same',activation='relu')\n        self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_9 = keras.layers.BatchNormalization()\n        self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')\n        \n        def call(self,inputs,training = True):\n            x = self.input_cnn(inputs)\n            x = self.conv_1(x)\n            x = self.conv_2(x)\n            x = self.conv_3(x)\n            x = self.conv_4(x)\n            if training == True:\n                x = self.conv_5(x,training = True)\n            else:\n                x = self.conv_5(x,training = False)\n            x = self.conv_6(x)\n            x = self.conv_7(x)\n            x = self.conv_8(x)\n            if training == True:\n                x = self.conv_9(x,training = True)\n            else:\n                x = self.conv_9(x,training = False)\n            x = self.conv_10(x)\n            return x\n\nsize 0 is 256 size 1 is 256 size 2 is 64\n\nTrain\\_step from main model:\n\n \n\n    def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n        super(BCDClassifier, self).__init__()         \n        self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n        self.encode = encoder(size)\n        self.flatten = keras.layers.Flatten()\n        self.concat = keras.layers.Concatenate(axis = 1)\n        self.classify = classifier(32)\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n        self.acc_tracker = metric\n        self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = 'micro')\n        self.sk_metric_acc = accuracy_score\n        self.sk_metric_f1 = f1_score\n        self.acc_history = []\n        self.loss_history = []\n        self.f1_history = []\n        \n        def call(self, cat_batch, view_batch, images_batch, training = True):\n            x1 = self.encode(images_batch,training)\n            x2 = self.input_cat(cat_batch)\n            x1 = self.flatten(x1)\n            x12 = self.concat([x1,x2])\n            x12 = self.classify(x12)\n            return x12\n    \n        def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n            with tf.GradientTape() as tape:\n                logits = self(cat_batch, views_batch, images_batch,training)\n                loss_value = self.loss_fn(target_batch, logits)\n    \n            grads = tape.gradient(loss_value, self.trainable_weights)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n            self.loss_tracker.update_state(loss_value)\n            pred = []\n            target = []\n            threshold = 0.5\n            for val in logits.numpy():\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                if v_2 &gt; threshold:\n                                    pred.append(1.0)\n                                else:\n                                    pred.append(0.0)\n                        else:\n                            if v_1 &gt; threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                else:\n                    if val &gt; threshold:\n                        pred.append(1.0)\n                    else:\n                        pred.append(0.0)\n            for val in target_batch:\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                target.append(v_2)\n                        else:\n                            target.append(v_1)\n                else:\n                    target.append(val)\n            acc = self.sk_metric_acc(target,pred)\n            f1 = self.sk_metric_f1(target,pred)\n            #self.f1_tracker.update_state(target_batch,logits)\n            return {\"Loss\": self.loss_tracker.result(), \"Accuracy\": acc, 'F1-score':f1}\n\nCan someone please help me figure out this error?", "author_fullname": "t2_9xa4pbdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can keeping channels more than '3' in images crash CNNs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o6gpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674994895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an encoder model which was working fine with single channel 1024,1024 images, I&amp;#39;m trying to patch the original images (mega pixel images) to 256, 256, 64 images. I&amp;#39;ve changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I&amp;#39;m getting the following error with tape.gradient:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn(&amp;#39;resource_tracker: There appear to be %d &amp;#39;                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, &amp;#39;The system cannot find the path specified&amp;#39;)                                    warnings.warn(&amp;#39;resource_tracker: %s: %r&amp;#39; % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, &amp;#39;The system cannot find the path specified&amp;#39;)                                    warnings.warn(&amp;#39;resource_tracker: %s: %r&amp;#39; % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My code is as below&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n    super(encoder, self).__init__()     #encoder Module\n    self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n    self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_5 = keras.layers.BatchNormalization()\n    self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n    self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n    self.conv_9 = keras.layers.BatchNormalization()\n    self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding=&amp;#39;same&amp;#39;,activation=&amp;#39;relu&amp;#39;)\n\n    def call(self,inputs,training = True):\n        x = self.input_cnn(inputs)\n        x = self.conv_1(x)\n        x = self.conv_2(x)\n        x = self.conv_3(x)\n        x = self.conv_4(x)\n        if training == True:\n            x = self.conv_5(x,training = True)\n        else:\n            x = self.conv_5(x,training = False)\n        x = self.conv_6(x)\n        x = self.conv_7(x)\n        x = self.conv_8(x)\n        if training == True:\n            x = self.conv_9(x,training = True)\n        else:\n            x = self.conv_9(x,training = False)\n        x = self.conv_10(x)\n        return x\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;size 0 is 256 size 1 is 256 size 2 is 64&lt;/p&gt;\n\n&lt;p&gt;Train_step from main model:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n    super(BCDClassifier, self).__init__()         \n    self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n    self.encode = encoder(size)\n    self.flatten = keras.layers.Flatten()\n    self.concat = keras.layers.Concatenate(axis = 1)\n    self.classify = classifier(32)\n    self.optimizer = optimizer\n    self.loss_fn = loss_fn\n    self.loss_tracker = keras.metrics.Mean(name=&amp;quot;loss&amp;quot;)\n    self.acc_tracker = metric\n    self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = &amp;#39;micro&amp;#39;)\n    self.sk_metric_acc = accuracy_score\n    self.sk_metric_f1 = f1_score\n    self.acc_history = []\n    self.loss_history = []\n    self.f1_history = []\n\n    def call(self, cat_batch, view_batch, images_batch, training = True):\n        x1 = self.encode(images_batch,training)\n        x2 = self.input_cat(cat_batch)\n        x1 = self.flatten(x1)\n        x12 = self.concat([x1,x2])\n        x12 = self.classify(x12)\n        return x12\n\n    def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n        with tf.GradientTape() as tape:\n            logits = self(cat_batch, views_batch, images_batch,training)\n            loss_value = self.loss_fn(target_batch, logits)\n\n        grads = tape.gradient(loss_value, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.loss_tracker.update_state(loss_value)\n        pred = []\n        target = []\n        threshold = 0.5\n        for val in logits.numpy():\n            if isinstance(val,np.ndarray):\n                for v_1 in val:\n                    if isinstance(v_1,np.ndarray):\n                        for v_2 in v_1:\n                            if v_2 &amp;gt; threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                    else:\n                        if v_1 &amp;gt; threshold:\n                            pred.append(1.0)\n                        else:\n                            pred.append(0.0)\n            else:\n                if val &amp;gt; threshold:\n                    pred.append(1.0)\n                else:\n                    pred.append(0.0)\n        for val in target_batch:\n            if isinstance(val,np.ndarray):\n                for v_1 in val:\n                    if isinstance(v_1,np.ndarray):\n                        for v_2 in v_1:\n                            target.append(v_2)\n                    else:\n                        target.append(v_1)\n            else:\n                target.append(val)\n        acc = self.sk_metric_acc(target,pred)\n        f1 = self.sk_metric_f1(target,pred)\n        #self.f1_tracker.update_state(target_batch,logits)\n        return {&amp;quot;Loss&amp;quot;: self.loss_tracker.result(), &amp;quot;Accuracy&amp;quot;: acc, &amp;#39;F1-score&amp;#39;:f1}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Can someone please help me figure out this error?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10o6gpv", "is_robot_indexable": true, "report_reasons": null, "author": "jhanjeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10o6gpv/can_keeping_channels_more_than_3_in_images_crash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10o6gpv/can_keeping_channels_more_than_3_in_images_crash/", "subreddit_subscribers": 842363, "created_utc": 1674994895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6bfsiya4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating Real-World AI Models by Newbies With ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nqco3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1674942026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "xrl1.sh", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://xrl1.sh/posts/coordinates-model-with-ChatGPT/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nqco3", "is_robot_indexable": true, "report_reasons": null, "author": "xrl9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nqco3/creating_realworld_ai_models_by_newbies_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://xrl1.sh/posts/coordinates-model-with-ChatGPT/", "subreddit_subscribers": 842363, "created_utc": 1674942026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ebrwg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Simple Things You Can Do to Improve Your Data Science Skills in 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_10nk804", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OJByFuuH9F8rwVNgTo2dA5EA4s-RToIL9hfHGJN1uUc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674926334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/10-simple-things-you-can-do-to-improve-your-data-science-skills-in-2023-af274dc513da", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zvcNRZvLqjOpxg7RZORtttjPY5dJRVjPuyPDWzpRoho.jpg?auto=webp&amp;v=enabled&amp;s=8a06f032d0f72cc53c3b05ad7828bce43b4d38b5", "width": 640, "height": 425}, "resolutions": [{"url": "https://external-preview.redd.it/zvcNRZvLqjOpxg7RZORtttjPY5dJRVjPuyPDWzpRoho.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c098073adc7d139a0d863779a9f1f19c8733482", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/zvcNRZvLqjOpxg7RZORtttjPY5dJRVjPuyPDWzpRoho.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e39ddc472af438727adc96dcb8759b77f4b7ca7d", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/zvcNRZvLqjOpxg7RZORtttjPY5dJRVjPuyPDWzpRoho.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c470471e19308282fe6b712dca97399a09350fc0", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/zvcNRZvLqjOpxg7RZORtttjPY5dJRVjPuyPDWzpRoho.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13c0936334a348155044c8e230d6286dc7bdfd8e", "width": 640, "height": 425}], "variants": {}, "id": "A_63-eZsY8_JM6Ze4zo_sV4AeTHQ6XYFmfY93eeUW0Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10nk804", "is_robot_indexable": true, "report_reasons": null, "author": "yourbasicgeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10nk804/10_simple_things_you_can_do_to_improve_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/10-simple-things-you-can-do-to-improve-your-data-science-skills-in-2023-af274dc513da", "subreddit_subscribers": 842363, "created_utc": 1674926334.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}