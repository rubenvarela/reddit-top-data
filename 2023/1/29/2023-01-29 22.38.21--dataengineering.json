{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to find ways to optimize pipelines. We currently have 10-12 large datasets that are used on a front end application and I\u2019m looking for ways to refactor the code base and improve performance. Is there any common design patterns you are aware of?\n\nSome of mine are very basic because I inherited a very poorly maintained project \n\n- MapReduce pattern \n- use reduce function call for multiple dataframes \n- repartitioning, coalescing \n- reducing rate of data updates (mine is biweekly at 5am before big reporting meeting for the front end users)\n- removing any for loops you can find\n- removing any array type columns to save on memory\n- Incremental updates to only update fresh data \n- Pruning old branches, deleting any test datasets \n- use as much AWS codeless architecture \n- Putting in a CI/CD pipeline via GitHub Actions Jenkins \n- Updating documentation on confluence", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most common patterns or efficiency enablers you encounter in your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o3ytb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674985144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find ways to optimize pipelines. We currently have 10-12 large datasets that are used on a front end application and I\u2019m looking for ways to refactor the code base and improve performance. Is there any common design patterns you are aware of?&lt;/p&gt;\n\n&lt;p&gt;Some of mine are very basic because I inherited a very poorly maintained project &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MapReduce pattern &lt;/li&gt;\n&lt;li&gt;use reduce function call for multiple dataframes &lt;/li&gt;\n&lt;li&gt;repartitioning, coalescing &lt;/li&gt;\n&lt;li&gt;reducing rate of data updates (mine is biweekly at 5am before big reporting meeting for the front end users)&lt;/li&gt;\n&lt;li&gt;removing any for loops you can find&lt;/li&gt;\n&lt;li&gt;removing any array type columns to save on memory&lt;/li&gt;\n&lt;li&gt;Incremental updates to only update fresh data &lt;/li&gt;\n&lt;li&gt;Pruning old branches, deleting any test datasets &lt;/li&gt;\n&lt;li&gt;use as much AWS codeless architecture &lt;/li&gt;\n&lt;li&gt;Putting in a CI/CD pipeline via GitHub Actions Jenkins &lt;/li&gt;\n&lt;li&gt;Updating documentation on confluence&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o3ytb", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o3ytb/what_are_the_most_common_patterns_or_efficiency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10o3ytb/what_are_the_most_common_patterns_or_efficiency/", "subreddit_subscribers": 87867, "created_utc": 1674985144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, after my master's Data Science I decided to pursue a data engineering traineeship at a large IT consultancy company. After a few months of earning certificates such as the DP-900 and DP-203, I now have my first data migration project. I love it so far. I get to write clever and clean SQL queries. I really enjoy working with SQL.\n\nBut my traineeship colleagues are not that lucky, they got assigned to projects in which they have the role of data engineer but they are barely programming or writing SQL queries. I asked a medior data engineer at my company whether this is normal and she responded that data engineering is nothing more than building some pipelines with ADF by clicking around in Azure. She could barely write code in Python or SQL herself. It turns out DE is a very low-code profession. \n\nI really don't like that. I aspired to become a data engineer because I wanted to pursue a hardcore programming job (in the context of data). So, now I aspire to become a SQL developer because I believe SQL developers spend more of their day coding.\n\nIs this a wise choice? What other hardcore coding jobs are there (in the context of data)? I don't necessarily want to become a software engineer because I prefer working with data rather than building applications. What should I do?", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose SQL developer or data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10od3v5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675017788.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675013284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, after my master&amp;#39;s Data Science I decided to pursue a data engineering traineeship at a large IT consultancy company. After a few months of earning certificates such as the DP-900 and DP-203, I now have my first data migration project. I love it so far. I get to write clever and clean SQL queries. I really enjoy working with SQL.&lt;/p&gt;\n\n&lt;p&gt;But my traineeship colleagues are not that lucky, they got assigned to projects in which they have the role of data engineer but they are barely programming or writing SQL queries. I asked a medior data engineer at my company whether this is normal and she responded that data engineering is nothing more than building some pipelines with ADF by clicking around in Azure. She could barely write code in Python or SQL herself. It turns out DE is a very low-code profession. &lt;/p&gt;\n\n&lt;p&gt;I really don&amp;#39;t like that. I aspired to become a data engineer because I wanted to pursue a hardcore programming job (in the context of data). So, now I aspire to become a SQL developer because I believe SQL developers spend more of their day coding.&lt;/p&gt;\n\n&lt;p&gt;Is this a wise choice? What other hardcore coding jobs are there (in the context of data)? I don&amp;#39;t necessarily want to become a software engineer because I prefer working with data rather than building applications. What should I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10od3v5", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10od3v5/should_i_choose_sql_developer_or_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10od3v5/should_i_choose_sql_developer_or_data_engineer/", "subreddit_subscribers": 87867, "created_utc": 1675013284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, has anyone enroled in this course by Udacity? I would like some opinions.\nI think the syllabus is quite interesting and I like that It focuses on AWS, but I don't know what quality of learning material it has.\nWould you recommend Datacamp or Coursera over this one?\n\nhttps://www.udacity.com/course/data-engineer-nanodegree--nd027", "author_fullname": "t2_69uxhxiu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aws Data Engineering Nanodegree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10o5gei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QyegggTQqfRdRoKyLvd0ruuUBGx7viZ3BqJw9MsuM6s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674991057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, has anyone enroled in this course by Udacity? I would like some opinions.\nI think the syllabus is quite interesting and I like that It focuses on AWS, but I don&amp;#39;t know what quality of learning material it has.\nWould you recommend Datacamp or Coursera over this one?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udacity.com/course/data-engineer-nanodegree--nd027\"&gt;https://www.udacity.com/course/data-engineer-nanodegree--nd027&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2atd4audc0fa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?auto=webp&amp;v=enabled&amp;s=15e0831fe1aa53901ce041365b3bc0dce736670b", "width": 1080, "height": 2340}, "resolutions": [{"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f2c4e6609efb5f2400150d2d126840ef6ee3cc5", "width": 108, "height": 216}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e54bc63757a8062954e12672d2422b590bdd7445", "width": 216, "height": 432}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63c0ea03180e4a7339c5802f7316d3936efd4db1", "width": 320, "height": 640}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0aff1d5c0e37a5f1496d197f22ea7f104cb615d0", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd3b93a8bc9b96085ca883b5649a2d09656df1d1", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/2atd4audc0fa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f16ec28a27db48467239eef4c9ba69c5ef3c7ac", "width": 1080, "height": 2160}], "variants": {}, "id": "Rh33R0DDQS5mAIN3XEqoo-1Hj_6y_dKHDh3sQbQMMJQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o5gei", "is_robot_indexable": true, "report_reasons": null, "author": "rzgzLuis", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o5gei/aws_data_engineering_nanodegree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2atd4audc0fa1.jpg", "subreddit_subscribers": 87867, "created_utc": 1674991057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, are there any resources about that? In general, I would like some resources about functional-style DE. Yes, I'm aware of that article from the founder of Airflow, but it's just... an article you know.", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources on how to structure ETL in a functional way", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10odjtg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675014341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, are there any resources about that? In general, I would like some resources about functional-style DE. Yes, I&amp;#39;m aware of that article from the founder of Airflow, but it&amp;#39;s just... an article you know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10odjtg", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10odjtg/resources_on_how_to_structure_etl_in_a_functional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10odjtg/resources_on_how_to_structure_etl_in_a_functional/", "subreddit_subscribers": 87867, "created_utc": 1675014341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im being asked to take and pass this exam and I was hoping I could get advice on how best to study from those who already passed the exam. Anything helps! Thank you!!", "author_fullname": "t2_151bcjhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who has passed the GCP Data Engineering Certification Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ofbt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675018608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im being asked to take and pass this exam and I was hoping I could get advice on how best to study from those who already passed the exam. Anything helps! Thank you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ofbt9", "is_robot_indexable": true, "report_reasons": null, "author": "BJJaddicy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ofbt9/who_has_passed_the_gcp_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ofbt9/who_has_passed_the_gcp_data_engineering/", "subreddit_subscribers": 87867, "created_utc": 1675018608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nDid anyone took the Databricks Certified Associate Developer for Apache Spark certification lately? \nIf so, I am\ncurious how did you prepare for the exams, what learning materials did you use? How was the exams? How are the questions? If there are any questions dump available which simulates the actual exam.\nThank you!", "author_fullname": "t2_6x5fs1hr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark Developer Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10odg0a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675014094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nDid anyone took the Databricks Certified Associate Developer for Apache Spark certification lately? \nIf so, I am\ncurious how did you prepare for the exams, what learning materials did you use? How was the exams? How are the questions? If there are any questions dump available which simulates the actual exam.\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10odg0a", "is_robot_indexable": true, "report_reasons": null, "author": "Glum-Violinist4911", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10odg0a/apache_spark_developer_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10odg0a/apache_spark_developer_certificate/", "subreddit_subscribers": 87867, "created_utc": 1675014094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll keep it brief. 21M, Spring or Fall 2024 Grad Compsci\n\n* Pursuing DE, longterm DS/ML\n* Comfortable with python and javascript\n* Learning how to use Docker and pipelines, currently taking the 2023 DE [bootcamp](https://www.reddit.com/r/dataengineering/comments/104xlft/free_data_engineering_bootcamp_data_engineering/), struggling but understanding slowly\n* Enjoy coding and learning, very beginner\n* Southern California located\n\nI was accepted into Galvanize's March full-time full-stack bootcamp program. Even after hours of research on Reddit, I'm still unsure about how I should follow my career path. I believe that improving my abilities and developing my personal portfolio/resume will increase my chances of obtaining a good job here. While focusing on my fundamental DE skills, my question is if I should study much fullstack or backend dev. Is this bootcamp even worth it at this point? Given that I won't graduate until next year. It's pricey, and I'm more interested in qualifying myself as soon as possible to enter this job market. I constantly hearing about how the job market is getting worse, and I completely understand. I just don't want to stay this end of the stick (unemployed). Courses in school are very basic and I'm learning way more off campus. I have more than enough time outside of class, as I am remote, and any advice for what I should do with my time going into this year would be GREATLY appreciated.", "author_fullname": "t2_pwk2f3iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I delay this bootcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o2ial", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674979443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll keep it brief. 21M, Spring or Fall 2024 Grad Compsci&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Pursuing DE, longterm DS/ML&lt;/li&gt;\n&lt;li&gt;Comfortable with python and javascript&lt;/li&gt;\n&lt;li&gt;Learning how to use Docker and pipelines, currently taking the 2023 DE &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/104xlft/free_data_engineering_bootcamp_data_engineering/\"&gt;bootcamp&lt;/a&gt;, struggling but understanding slowly&lt;/li&gt;\n&lt;li&gt;Enjoy coding and learning, very beginner&lt;/li&gt;\n&lt;li&gt;Southern California located&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I was accepted into Galvanize&amp;#39;s March full-time full-stack bootcamp program. Even after hours of research on Reddit, I&amp;#39;m still unsure about how I should follow my career path. I believe that improving my abilities and developing my personal portfolio/resume will increase my chances of obtaining a good job here. While focusing on my fundamental DE skills, my question is if I should study much fullstack or backend dev. Is this bootcamp even worth it at this point? Given that I won&amp;#39;t graduate until next year. It&amp;#39;s pricey, and I&amp;#39;m more interested in qualifying myself as soon as possible to enter this job market. I constantly hearing about how the job market is getting worse, and I completely understand. I just don&amp;#39;t want to stay this end of the stick (unemployed). Courses in school are very basic and I&amp;#39;m learning way more off campus. I have more than enough time outside of class, as I am remote, and any advice for what I should do with my time going into this year would be GREATLY appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10o2ial", "is_robot_indexable": true, "report_reasons": null, "author": "CowUnfair4318", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o2ial/should_i_delay_this_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10o2ial/should_i_delay_this_bootcamp/", "subreddit_subscribers": 87867, "created_utc": 1674979443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a DE focused youtube channel or tutorial which covers the following?\n\n1. Creation of small python etl pipeline that moves and transforms data from source to S3, and then load and transform into redshift .\n2. Build docker image for the python, save to ECR.\n3. Use of Lambda or AWS Batch/ECS to run the containers.\n4. Create a pipeline on Airflow running on EC2.\n5. Show how the CI/CD pipeline would work using Code commit, build, etc.\n6. Creation of this infrastructure using terraform or cloudformation.", "author_fullname": "t2_6lp7aig4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation of a YouTube channel/ tutorial?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10oi6o6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675025379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a DE focused youtube channel or tutorial which covers the following?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Creation of small python etl pipeline that moves and transforms data from source to S3, and then load and transform into redshift .&lt;/li&gt;\n&lt;li&gt;Build docker image for the python, save to ECR.&lt;/li&gt;\n&lt;li&gt;Use of Lambda or AWS Batch/ECS to run the containers.&lt;/li&gt;\n&lt;li&gt;Create a pipeline on Airflow running on EC2.&lt;/li&gt;\n&lt;li&gt;Show how the CI/CD pipeline would work using Code commit, build, etc.&lt;/li&gt;\n&lt;li&gt;Creation of this infrastructure using terraform or cloudformation.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10oi6o6", "is_robot_indexable": true, "report_reasons": null, "author": "ask_can", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10oi6o6/recommendation_of_a_youtube_channel_tutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10oi6o6/recommendation_of_a_youtube_channel_tutorial/", "subreddit_subscribers": 87867, "created_utc": 1675025379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have a question about what's happening behind the scenes when I do a direct write / update in place. Say my ETL will do a batch load weekly to refresh my SCD1 dimension table. Each time, my ETL will compare the new data from the source with the current target table, and if my ETL sees that, for the same natural key, one field has a new value, my ETL will keep the old surrogate key of that row, but overwrite that one field with the new value. It's a SCD1 since my target table only keeps the latest value. But, one drawback of SCD1 is that you can't go back to the previous state if you want to abort the write. Since this seems quite risky, I'm wondering if certain databases could still keep track of history, even if my table seems to be a SCD1 table? \n\n&amp;#x200B;\n\nTo illustrate my descriptions above, here's an example: \n\nMy target table looks like below. Let's say this morning, my weekly ETL notices that for ID 12345, the \"City\" field gets a new value \"Toronto\". It will directly update that first row in place, and replace \"Ottawa\" with \"Toronto\". In this case, would the database still track that history of \"Ottawa\" behind the scenes?  Thanks everyone.\n\n|PK|ID#|Name |City|\n|:-|:-|:-|:-|\n|1|12345|Jenn|Ottawa|\n|2|23456|John|Toronto|", "author_fullname": "t2_szomhuik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question - Keep History for SCD1?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10nuzdr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674954479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have a question about what&amp;#39;s happening behind the scenes when I do a direct write / update in place. Say my ETL will do a batch load weekly to refresh my SCD1 dimension table. Each time, my ETL will compare the new data from the source with the current target table, and if my ETL sees that, for the same natural key, one field has a new value, my ETL will keep the old surrogate key of that row, but overwrite that one field with the new value. It&amp;#39;s a SCD1 since my target table only keeps the latest value. But, one drawback of SCD1 is that you can&amp;#39;t go back to the previous state if you want to abort the write. Since this seems quite risky, I&amp;#39;m wondering if certain databases could still keep track of history, even if my table seems to be a SCD1 table? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To illustrate my descriptions above, here&amp;#39;s an example: &lt;/p&gt;\n\n&lt;p&gt;My target table looks like below. Let&amp;#39;s say this morning, my weekly ETL notices that for ID 12345, the &amp;quot;City&amp;quot; field gets a new value &amp;quot;Toronto&amp;quot;. It will directly update that first row in place, and replace &amp;quot;Ottawa&amp;quot; with &amp;quot;Toronto&amp;quot;. In this case, would the database still track that history of &amp;quot;Ottawa&amp;quot; behind the scenes?  Thanks everyone.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;PK&lt;/th&gt;\n&lt;th align=\"left\"&gt;ID#&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;City&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;12345&lt;/td&gt;\n&lt;td align=\"left\"&gt;Jenn&lt;/td&gt;\n&lt;td align=\"left\"&gt;Ottawa&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;23456&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Toronto&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10nuzdr", "is_robot_indexable": true, "report_reasons": null, "author": "TendMyOwnGarden", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10nuzdr/question_keep_history_for_scd1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10nuzdr/question_keep_history_for_scd1/", "subreddit_subscribers": 87867, "created_utc": 1674954479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,   \nin my company we have clear distinction between the reporting team and DWH team. I am looking into how to optimise the flow of requests between the two teams, mainly how should the guys from reporting form their request when requesting for a new data asset to be created on the DWH side. If you have any resources, templates or advices on this topic please share.   \nThanks!", "author_fullname": "t2_11jvjx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flow of requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10obh87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675009249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;br/&gt;\nin my company we have clear distinction between the reporting team and DWH team. I am looking into how to optimise the flow of requests between the two teams, mainly how should the guys from reporting form their request when requesting for a new data asset to be created on the DWH side. If you have any resources, templates or advices on this topic please share.&lt;br/&gt;\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10obh87", "is_robot_indexable": true, "report_reasons": null, "author": "isak000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10obh87/flow_of_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10obh87/flow_of_requests/", "subreddit_subscribers": 87867, "created_utc": 1675009249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a tool that has a functionality that I have not been able to find (in my limited googling).\n\n&amp;#x200B;\n\nI'm developing a pipeline that is pretty linear and written in pure python - nothing really run concurrently, each steps is executing after the previous, etc. It has many steps though, so editing and creating new steps in the pipeline takes a lot of time because I have to wait for the previous steps to execute before it gets to the latest step in the pipeline.\n\n&amp;#x200B;\n\nI'm looking for a way to save the state of the data after it completes a certain step, and then run the last step using the data in the modified form.\n\n&amp;#x200B;\n\nFor example: I have a pipeline with 4 steps - Extract JSON1, Extract JSON2, Create a DataFrame from both JSONs, Store it in a Database. If I have already developed steps 1-3, I don't want to have to keep rerunning the whole script to develop step 4. I would want to automatically save the output from the previous steps, and just work on step 4 with the data already collected/modified.\n\n&amp;#x200B;\n\nI know that I could simply save the data in it's own file and do it all manually, but I was wondering if a tool already existed where you could work with the data sequentially and essentially save the state of the data and just work with it that way. This would be a great time saver for me!\n\n&amp;#x200B;\n\nAny help is appreciated, thanks!", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this tool already exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ojtcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675029226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a tool that has a functionality that I have not been able to find (in my limited googling).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m developing a pipeline that is pretty linear and written in pure python - nothing really run concurrently, each steps is executing after the previous, etc. It has many steps though, so editing and creating new steps in the pipeline takes a lot of time because I have to wait for the previous steps to execute before it gets to the latest step in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a way to save the state of the data after it completes a certain step, and then run the last step using the data in the modified form.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example: I have a pipeline with 4 steps - Extract JSON1, Extract JSON2, Create a DataFrame from both JSONs, Store it in a Database. If I have already developed steps 1-3, I don&amp;#39;t want to have to keep rerunning the whole script to develop step 4. I would want to automatically save the output from the previous steps, and just work on step 4 with the data already collected/modified.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know that I could simply save the data in it&amp;#39;s own file and do it all manually, but I was wondering if a tool already existed where you could work with the data sequentially and essentially save the state of the data and just work with it that way. This would be a great time saver for me!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ojtcs", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ojtcs/does_this_tool_already_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ojtcs/does_this_tool_already_exist/", "subreddit_subscribers": 87867, "created_utc": 1675029226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have the following task at hand:\n\nI need to syncronize a list of products gathered from a SOAP API to a WooCommerce based webshop. I have written a Python script that does this seemingly well, but it is messy as f and I kinda feel that I am reinventing the wheel at certain points (the only external libraries that it uses are *zeep* (for SOAP requests), *lxml* and *woocommerce*).\n\nCurrently my Python script does the following:\n\n* extract all products from the SOAP API and store them as dictionaries\n* go through each of them and add each new category that is found onto a list\n* compare this list of categories to the list from the previous snapshot and sync the changes to woocommerce\n* compare the current list of products to the list from the previous snapshot\n  * if a product is not present in the previous snapshot upload it into woocommerce\n  * if an attribute of a product (stock status, price, etc.) has changed since the last snapshot update it in woocommerce\n  * if a product that was present in the previous snapshot is no longer present in the current list remove it from woocommerce\n* save the snapshot of the current state of woocommerce into a JSON file\n\n\n\nFrom what I was able to gather this task of mine is basically an ETL operation: I need to extract the data from the SOAP API, transform it into the format that is accepted by the woocommerce rest api and load it into woocommerce.\n\nAre there any data engineering libraries or technologies that you guys would recommend me to incorporate into this project. Could Apache Airflow or the Bonobo ETL library simplify this task? Should I invest time into learning those technologies? Right now my plan is to simply run this aforementioned python script once a day using a cronjob.", "author_fullname": "t2_3wultj0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing products from a SOAP API to Woocommerce via it's REST API. Any libraries or technologies that could simplify this task?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10o8dm6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675001112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the following task at hand:&lt;/p&gt;\n\n&lt;p&gt;I need to syncronize a list of products gathered from a SOAP API to a WooCommerce based webshop. I have written a Python script that does this seemingly well, but it is messy as f and I kinda feel that I am reinventing the wheel at certain points (the only external libraries that it uses are &lt;em&gt;zeep&lt;/em&gt; (for SOAP requests), &lt;em&gt;lxml&lt;/em&gt; and &lt;em&gt;woocommerce&lt;/em&gt;).&lt;/p&gt;\n\n&lt;p&gt;Currently my Python script does the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;extract all products from the SOAP API and store them as dictionaries&lt;/li&gt;\n&lt;li&gt;go through each of them and add each new category that is found onto a list&lt;/li&gt;\n&lt;li&gt;compare this list of categories to the list from the previous snapshot and sync the changes to woocommerce&lt;/li&gt;\n&lt;li&gt;compare the current list of products to the list from the previous snapshot\n\n&lt;ul&gt;\n&lt;li&gt;if a product is not present in the previous snapshot upload it into woocommerce&lt;/li&gt;\n&lt;li&gt;if an attribute of a product (stock status, price, etc.) has changed since the last snapshot update it in woocommerce&lt;/li&gt;\n&lt;li&gt;if a product that was present in the previous snapshot is no longer present in the current list remove it from woocommerce&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;save the snapshot of the current state of woocommerce into a JSON file&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;From what I was able to gather this task of mine is basically an ETL operation: I need to extract the data from the SOAP API, transform it into the format that is accepted by the woocommerce rest api and load it into woocommerce.&lt;/p&gt;\n\n&lt;p&gt;Are there any data engineering libraries or technologies that you guys would recommend me to incorporate into this project. Could Apache Airflow or the Bonobo ETL library simplify this task? Should I invest time into learning those technologies? Right now my plan is to simply run this aforementioned python script once a day using a cronjob.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10o8dm6", "is_robot_indexable": true, "report_reasons": null, "author": "Clock_Wise_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10o8dm6/syncing_products_from_a_soap_api_to_woocommerce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10o8dm6/syncing_products_from_a_soap_api_to_woocommerce/", "subreddit_subscribers": 87867, "created_utc": 1675001112.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}