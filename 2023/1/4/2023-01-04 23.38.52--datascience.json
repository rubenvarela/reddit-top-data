{"kind": "Listing", "data": {"after": "t3_1038kmh", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just a heads up to any other women that this could also work for. My name isn\u2019t typically associated with a more masculine sounding nickname so I had to get a bit creative. Happy to help anyone who needs it brainstorm a nickname.\n\nI\u2019m so tired.\n\n\nEDIT: This is an anecdotal experience I am sharing. Idk why some of y\u2019all think I am making some wild statistical claim. I don\u2019t do that for free in my time off. Relax.\n\nQuoting one of my earlier comments -\n\u201c168 applications, 39 of which I sent with the masculine named resume. Dude I\u2019m not trying to prove/debate gender discrimination in this post. Just let the fellow wistem homies know this is a possible help for them in tough times for everyone.\u201d \n\nOut of the latter 39 applications I got 3 interviews (in my desired industry), 2 offers and accepted 1. In the first 129 I only got 1 interview in my desired field. There were a handful of others interview calls for roles outside my industry. \n\nI would like to reiterate how tired I am.", "author_fullname": "t2_jdvaqz74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Changing my feminine first name to a masculine nickname on my resume gave me way more responses per application", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1032pgs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 576, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 576, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672857639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672835959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a heads up to any other women that this could also work for. My name isn\u2019t typically associated with a more masculine sounding nickname so I had to get a bit creative. Happy to help anyone who needs it brainstorm a nickname.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m so tired.&lt;/p&gt;\n\n&lt;p&gt;EDIT: This is an anecdotal experience I am sharing. Idk why some of y\u2019all think I am making some wild statistical claim. I don\u2019t do that for free in my time off. Relax.&lt;/p&gt;\n\n&lt;p&gt;Quoting one of my earlier comments -\n\u201c168 applications, 39 of which I sent with the masculine named resume. Dude I\u2019m not trying to prove/debate gender discrimination in this post. Just let the fellow wistem homies know this is a possible help for them in tough times for everyone.\u201d &lt;/p&gt;\n\n&lt;p&gt;Out of the latter 39 applications I got 3 interviews (in my desired industry), 2 offers and accepted 1. In the first 129 I only got 1 interview in my desired field. There were a handful of others interview calls for roles outside my industry. &lt;/p&gt;\n\n&lt;p&gt;I would like to reiterate how tired I am.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "award_fbe9527a-adb3-430e-af1a-5fd3489e641b", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=16&amp;height=16&amp;auto=webp&amp;s=36f008595706cfff9ef6d1fdd06ae5353474471b", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=32&amp;height=32&amp;auto=webp&amp;s=b1e37f10d35059cc2ac41356073420b41a429d75", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=48&amp;height=48&amp;auto=webp&amp;s=c0cc6ae54fbf3e94516aaacef918834fd12030b3", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=64&amp;height=64&amp;auto=webp&amp;s=ee6a20be9f41b0e203fff64eb47cb5674e22daa6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=128&amp;height=128&amp;auto=webp&amp;s=38ac24a33777a7fc3e77f68836c150daf7cb4aa4", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm genuinely flabbergasted.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Shocked", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=16&amp;height=16&amp;auto=webp&amp;s=36f008595706cfff9ef6d1fdd06ae5353474471b", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=32&amp;height=32&amp;auto=webp&amp;s=b1e37f10d35059cc2ac41356073420b41a429d75", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=48&amp;height=48&amp;auto=webp&amp;s=c0cc6ae54fbf3e94516aaacef918834fd12030b3", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=64&amp;height=64&amp;auto=webp&amp;s=ee6a20be9f41b0e203fff64eb47cb5674e22daa6", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png?width=128&amp;height=128&amp;auto=webp&amp;s=38ac24a33777a7fc3e77f68836c150daf7cb4aa4", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/fck3iedi2ug51_Shocked.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "1032pgs", "is_robot_indexable": true, "report_reasons": null, "author": "chartreuse_13", "discussion_type": null, "num_comments": 185, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1032pgs/changing_my_feminine_first_name_to_a_masculine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1032pgs/changing_my_feminine_first_name_to_a_masculine/", "subreddit_subscribers": 833779, "created_utc": 1672835959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It is a commonly held belief that achieving perfect language modeling is equivalent to achieving human-level intelligence. However, this belief has been challenged in recent years as language models have become more advanced and their capabilities have expanded. It is possible that, even with infinite compute power and no concerns about labor costs, a large language model alone may not be able to solve all problems or achieve true human-level intelligence. It is important to consider the limitations and capabilities of language models when evaluating their potential uses and applications.\n\nShortly, the main concerns about using LLMs are:\n\n1. Relating multiple texts to each other\n2. A notion of time\n3. Knowledge of Knowledge\n4. Numbers and math\n5. Rare events, high recall setups, high coverage setups\n6. Data hunger\n\n[Here is a twitter thread addressing these](https://twitter.com/artkulak/status/1610564387407892480)[ issues](https://twitter.com/artkulak/status/1610564387407892480)\n\n[Here is an original large post about this](https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9)\n\nDo you think these concerns will be gone with advancements in the field?", "author_fullname": "t2_9r0xbuve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Concerns and limitations of Large Language models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102z0kl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672823910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It is a commonly held belief that achieving perfect language modeling is equivalent to achieving human-level intelligence. However, this belief has been challenged in recent years as language models have become more advanced and their capabilities have expanded. It is possible that, even with infinite compute power and no concerns about labor costs, a large language model alone may not be able to solve all problems or achieve true human-level intelligence. It is important to consider the limitations and capabilities of language models when evaluating their potential uses and applications.&lt;/p&gt;\n\n&lt;p&gt;Shortly, the main concerns about using LLMs are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Relating multiple texts to each other&lt;/li&gt;\n&lt;li&gt;A notion of time&lt;/li&gt;\n&lt;li&gt;Knowledge of Knowledge&lt;/li&gt;\n&lt;li&gt;Numbers and math&lt;/li&gt;\n&lt;li&gt;Rare events, high recall setups, high coverage setups&lt;/li&gt;\n&lt;li&gt;Data hunger&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/artkulak/status/1610564387407892480\"&gt;Here is a twitter thread addressing these&lt;/a&gt;&lt;a href=\"https://twitter.com/artkulak/status/1610564387407892480\"&gt; issues&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9\"&gt;Here is an original large post about this&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do you think these concerns will be gone with advancements in the field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "102z0kl", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Doubt298", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/102z0kl/concerns_and_limitations_of_large_language_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/102z0kl/concerns_and_limitations_of_large_language_models/", "subreddit_subscribers": 833779, "created_utc": 1672823910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI\u2019ve been working as a junior data analyst for the last 8 months. \n\nThe onboarding phase was really disorganised, I\u2019d spend my time reading through documentation and getting familiar with whatever I could. \n\nI got my first project to work on around 6 weeks into the job. It was suppose to be just a dashboard but ended up being an automation piece so it was taken over by senior members in the team. \n\nMy second project came along a few months later, but the data engineer has been having ongoing issues with the data being sent over from an external provider, so that\u2019s been a blocker, but the data modelling and dashboard design is done. \n\nI was given a third project 2 months ago, a simple data model clean up and redesign of an existing dashboard, that didn\u2019t take long and the dashboard is live now.\n\nIt is the new year now and I truly have nothing to do. The last 8 months has been me looking for work to do, I\u2019ve asked to help out on other team member projects but they said they didn\u2019t need it. We have a daily stand up where we give updates and talk about what we\u2019ll be doing today. Today was the first day I couldn\u2019t bs my way through the meeting and said I didn\u2019t have an update. I feel really incompetent having nothing to do. It\u2019s isn\u2019t a fast paced company so there aren\u2019t millions of things going on, and our data team didn\u2019t exist just 4 years ago so the business doesn\u2019t rely on us too much. \n\nOnly 3 projects in the last 8 months, is this normal? If you currently work in data was your first job similar to my experience?? I\u2019m struggling to understand why they hired me in the first place, I don\u2019t think there\u2019s enough work for an extra person.\n\nShould I start looking for another job? I don\u2019t want to come up to the one year mark without much experience under my belt. I want to be a crucial member of a team.", "author_fullname": "t2_8jtoiqw9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Junior data analyst (23M) no responsibilities at work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1031bcs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672831657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working as a junior data analyst for the last 8 months. &lt;/p&gt;\n\n&lt;p&gt;The onboarding phase was really disorganised, I\u2019d spend my time reading through documentation and getting familiar with whatever I could. &lt;/p&gt;\n\n&lt;p&gt;I got my first project to work on around 6 weeks into the job. It was suppose to be just a dashboard but ended up being an automation piece so it was taken over by senior members in the team. &lt;/p&gt;\n\n&lt;p&gt;My second project came along a few months later, but the data engineer has been having ongoing issues with the data being sent over from an external provider, so that\u2019s been a blocker, but the data modelling and dashboard design is done. &lt;/p&gt;\n\n&lt;p&gt;I was given a third project 2 months ago, a simple data model clean up and redesign of an existing dashboard, that didn\u2019t take long and the dashboard is live now.&lt;/p&gt;\n\n&lt;p&gt;It is the new year now and I truly have nothing to do. The last 8 months has been me looking for work to do, I\u2019ve asked to help out on other team member projects but they said they didn\u2019t need it. We have a daily stand up where we give updates and talk about what we\u2019ll be doing today. Today was the first day I couldn\u2019t bs my way through the meeting and said I didn\u2019t have an update. I feel really incompetent having nothing to do. It\u2019s isn\u2019t a fast paced company so there aren\u2019t millions of things going on, and our data team didn\u2019t exist just 4 years ago so the business doesn\u2019t rely on us too much. &lt;/p&gt;\n\n&lt;p&gt;Only 3 projects in the last 8 months, is this normal? If you currently work in data was your first job similar to my experience?? I\u2019m struggling to understand why they hired me in the first place, I don\u2019t think there\u2019s enough work for an extra person.&lt;/p&gt;\n\n&lt;p&gt;Should I start looking for another job? I don\u2019t want to come up to the one year mark without much experience under my belt. I want to be a crucial member of a team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1031bcs", "is_robot_indexable": true, "report_reasons": null, "author": "Beneficial-Ice-6039", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1031bcs/junior_data_analyst_23m_no_responsibilities_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1031bcs/junior_data_analyst_23m_no_responsibilities_at/", "subreddit_subscribers": 833779, "created_utc": 1672831657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are your red flags for working at a company? \n\nMine are: \n1. Treating someone like family\n2. Not using any version control\n3. Not following any style guides or best practices.", "author_fullname": "t2_7r2a683l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Company Red Flags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1038aha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672850806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your red flags for working at a company? &lt;/p&gt;\n\n&lt;p&gt;Mine are: \n1. Treating someone like family\n2. Not using any version control\n3. Not following any style guides or best practices.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1038aha", "is_robot_indexable": true, "report_reasons": null, "author": "blacksnowboader", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1038aha/company_red_flags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1038aha/company_red_flags/", "subreddit_subscribers": 833779, "created_utc": 1672850806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am beginning my postdoctoral position. My Ph.D. was in bioinformatics, with half my chapters based on machine learning (regression and classification tasks). I have now been hired to collaborate on different projects, some of which require an upgrade on my data science skills (including using geopositioning and visual data). I have started reviewing my basic knowledge of Python in case R is too limited for complex analyses or applications. \n\nIs it worth it? If it is, which sources would you recommend? I am using Kaggle\u00b4s Python course so far.", "author_fullname": "t2_sl2udegu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Continue with R or get into Python? Postdoctoral job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1033eeo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672837990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am beginning my postdoctoral position. My Ph.D. was in bioinformatics, with half my chapters based on machine learning (regression and classification tasks). I have now been hired to collaborate on different projects, some of which require an upgrade on my data science skills (including using geopositioning and visual data). I have started reviewing my basic knowledge of Python in case R is too limited for complex analyses or applications. &lt;/p&gt;\n\n&lt;p&gt;Is it worth it? If it is, which sources would you recommend? I am using Kaggle\u00b4s Python course so far.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1033eeo", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Ladder922", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1033eeo/continue_with_r_or_get_into_python_postdoctoral/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1033eeo/continue_with_r_or_get_into_python_postdoctoral/", "subreddit_subscribers": 833779, "created_utc": 1672837990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ipbf10dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have no idea about Big Data and currently I am lost, does anybody know if this course will be of any help or not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_102yqf3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dMxvhzn3lQ-7U-Pl3GcMiBPOUpdRGH-3pmWz2IvVuqI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672822836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/efbkf8u4l0aa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?auto=webp&amp;s=5f151a59cbf10d7a903e5b5194df12ae54d626a0", "width": 1080, "height": 2408}, "resolutions": [{"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8c986de17c5b9e5f4350b4534816ad8caa71aa16", "width": 108, "height": 216}, {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6740245f9e5b12dae7289ec09a8f5e9e380a0a81", "width": 216, "height": 432}, {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=86d99a623e3239691ac63e8f2e0e0d9a14976a40", "width": 320, "height": 640}, {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa777e4f5e88b7f5a9ca13fe66d1b9b602668b1b", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=82f0919b9f42ba2dee6aeccfb7c420e4ee694933", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/efbkf8u4l0aa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=addced1af157c9afbe6179da796c8c8fdcc85414", "width": 1080, "height": 2160}], "variants": {}, "id": "7QgWNxVjOdSXKobGFYEcECxj3e_1bbQVVA9cE7iV0oc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "102yqf3", "is_robot_indexable": true, "report_reasons": null, "author": "Notalabel_4566", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/102yqf3/i_have_no_idea_about_big_data_and_currently_i_am/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/efbkf8u4l0aa1.jpg", "subreddit_subscribers": 833779, "created_utc": 1672822836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I just graduated in December and I'm about to start applying for jobs.\n\n[Here](https://imgur.com/a/e7USuvg) is my r\u00e9sum\u00e9 and I could really use some help with it. I'm really anxious about the next step so tips and tricks about interviews and whatnot are always welcome.\n\nI'm tryna break into Data Science/ ML / Data Engineering. Thanks (:", "author_fullname": "t2_jqznxjjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with resume! Newly grad (:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1035f8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672843755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I just graduated in December and I&amp;#39;m about to start applying for jobs.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/e7USuvg\"&gt;Here&lt;/a&gt; is my r\u00e9sum\u00e9 and I could really use some help with it. I&amp;#39;m really anxious about the next step so tips and tricks about interviews and whatnot are always welcome.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m tryna break into Data Science/ ML / Data Engineering. Thanks (:&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?auto=webp&amp;s=344f89c5f1e85a209ddd8d6cf6627e6efaf7de40", "width": 1125, "height": 1470}, "resolutions": [{"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=884db9caae32641e8cbf59e77b05093121a50ff2", "width": 108, "height": 141}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2383214aa6dc116f5c6e9e38cc0c866677e33480", "width": 216, "height": 282}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2a699a5b3b84c0222c3ec38e12db84677c26752", "width": 320, "height": 418}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f309a792b32d0665d9b204ddb812e25ada4a4b1", "width": 640, "height": 836}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ddb9f8df4bd8a750c19323494f2c636d758bde7", "width": 960, "height": 1254}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f23bb16e1e4c23405bb7256ebdf7a34d7caebf4", "width": 1080, "height": 1411}], "variants": {"obfuscated": {"source": {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?blur=40&amp;format=pjpg&amp;auto=webp&amp;s=0ccd833589f5fb112ad3ff1600e07f9c354b47d8", "width": 1125, "height": 1470}, "resolutions": [{"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=108&amp;crop=smart&amp;blur=10&amp;format=pjpg&amp;auto=webp&amp;s=54023b847dff3bd154fd4d3b03caee702d7bc8ca", "width": 108, "height": 141}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=216&amp;crop=smart&amp;blur=21&amp;format=pjpg&amp;auto=webp&amp;s=a1a377f3b5b7220f2cd1b5b73d6e15e0af9c6398", "width": 216, "height": 282}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=320&amp;crop=smart&amp;blur=32&amp;format=pjpg&amp;auto=webp&amp;s=415dadcad5f81d064ee80e36321e92dc40f4c510", "width": 320, "height": 418}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=640&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=04ace1bb4043010dd58e55173d0f3ad0c27e3af4", "width": 640, "height": 836}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=960&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=183e95997a7a6b30666587ec338183a78a25bb40", "width": 960, "height": 1254}, {"url": "https://external-preview.redd.it/0CYqug8S2SFERbSdE0qXUGvpb5gf9jv6W5GJ_DJw_Vk.jpg?width=1080&amp;crop=smart&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;s=51858752613d93576271371d000676173572a8ad", "width": 1080, "height": 1411}]}}, "id": "sRzB5-tQ-5amPa1d5LL_JvUjMCkl8sXVcx8LHpm8xVU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1035f8h", "is_robot_indexable": true, "report_reasons": null, "author": "D1N4D4N1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1035f8h/help_with_resume_newly_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1035f8h/help_with_resume_newly_grad/", "subreddit_subscribers": 833779, "created_utc": 1672843755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "^", "author_fullname": "t2_ptc2zg53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good is an applied math degree for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1032ql3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672836050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;^&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1032ql3", "is_robot_indexable": true, "report_reasons": null, "author": "Successful-Total1989", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1032ql3/how_good_is_an_applied_math_degree_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1032ql3/how_good_is_an_applied_math_degree_for_data/", "subreddit_subscribers": 833779, "created_utc": 1672836050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it normal to have 8 interviews for a senior position as a Data Scientist? I\u2019ve been scheduled for my 8th interview for next week and I\u2019m honestly feeling tired of pursuing this job opportunity. I have no clue if this will be the last one.", "author_fullname": "t2_9an79ua8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Number of interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103hy97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672873107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it normal to have 8 interviews for a senior position as a Data Scientist? I\u2019ve been scheduled for my 8th interview for next week and I\u2019m honestly feeling tired of pursuing this job opportunity. I have no clue if this will be the last one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103hy97", "is_robot_indexable": true, "report_reasons": null, "author": "AdEnvironmental4348", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103hy97/number_of_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103hy97/number_of_interviews/", "subreddit_subscribers": 833779, "created_utc": 1672873107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Did anyone experience a technical interview at Safran for a Data Scientist role? If yes, what type of questions are asked?", "author_fullname": "t2_dwijd9yj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist Technical Interview at Safran", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103d072", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672861657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did anyone experience a technical interview at Safran for a Data Scientist role? If yes, what type of questions are asked?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103d072", "is_robot_indexable": true, "report_reasons": null, "author": "No_Cardiologist_3158", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103d072/data_scientist_technical_interview_at_safran/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103d072/data_scientist_technical_interview_at_safran/", "subreddit_subscribers": 833779, "created_utc": 1672861657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, \n\nI'm new here and I just want to rant and rave a little! \n\nI studied statistics with a minor in programming in college. Afterward, started to work as an analytics campaign manager in a healthcare company. My job covered making sure the architecture was working correctly to using basic algorithms like K-means, and logistic regression to create campaigns to increase cx and sales. My job was very satisfactory in a way as I could see cancer patients struggling less or people would find they had cancer in the early stages and could get treatment before it was late. \n\n&amp;#x200B;\n\nDue to financial reasons, I decided to become a data scientist, did a master and found a job in Western Europe. I'm working at a consulting company where I just do the analytics and prepare presentations but all the interesting stuff like creating the solution, and presenting it to the client belongs to other people. I'm just doing my 'numbers magic' - whatever they asked me to do- and they do all the fun stuff. The worst part is whatever I do is just for companies to save money, it doesn't affect people in any way. \n\n&amp;#x200B;\n\nI can't go back to my old work because I have to stay in Europe to make the money and send it to my parents.  And my visa allows me just to do technical jobs, nothing like marketing, sales etc... \n\n&amp;#x200B;\n\nI feel stuck but don't know what to do. I'm not asking for advice or anything, I just wanted to share, to relax a little.", "author_fullname": "t2_tg4tyljh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hate my data science job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103c9al", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672859937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new here and I just want to rant and rave a little! &lt;/p&gt;\n\n&lt;p&gt;I studied statistics with a minor in programming in college. Afterward, started to work as an analytics campaign manager in a healthcare company. My job covered making sure the architecture was working correctly to using basic algorithms like K-means, and logistic regression to create campaigns to increase cx and sales. My job was very satisfactory in a way as I could see cancer patients struggling less or people would find they had cancer in the early stages and could get treatment before it was late. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Due to financial reasons, I decided to become a data scientist, did a master and found a job in Western Europe. I&amp;#39;m working at a consulting company where I just do the analytics and prepare presentations but all the interesting stuff like creating the solution, and presenting it to the client belongs to other people. I&amp;#39;m just doing my &amp;#39;numbers magic&amp;#39; - whatever they asked me to do- and they do all the fun stuff. The worst part is whatever I do is just for companies to save money, it doesn&amp;#39;t affect people in any way. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t go back to my old work because I have to stay in Europe to make the money and send it to my parents.  And my visa allows me just to do technical jobs, nothing like marketing, sales etc... &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I feel stuck but don&amp;#39;t know what to do. I&amp;#39;m not asking for advice or anything, I just wanted to share, to relax a little.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103c9al", "is_robot_indexable": true, "report_reasons": null, "author": "Good_Old_Days_92", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103c9al/hate_my_data_science_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103c9al/hate_my_data_science_job/", "subreddit_subscribers": 833779, "created_utc": 1672859937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi all, thanks in advance for your advice.\n\nI'm trying to determine whether certain product feature improvements increased the number of monthly active users (active is defined as whether the user made a purchase in the last 28 days). We have the ability to A/B test but I'm getting stuck because this MAU metric is a moving window metric. If we run the experiment for exactly 28 days then I think calculating the impact to MAU is easy. But most of the time our experiments run for more or less days than 28 days. Below are a few scenarios to illustrate my point.\n\nNote: All scenarios are A/B tests where we split our user base into equal treatment and control groups. So far, I've been calculating \"MAU Rate\", which is the proportion of users who placed an order in the last 28 days as of the last day of the experiment.\n\n* Scenario 1: Run experiment for exactly 28 days. At the end of 28 days, simply compare the proportion of users in each group that placed an order.\n* Scenario 2: Run experiment for less than 28 days, say 14 days. At the end of the experiment, compare the proportion of users in each group that placed an order in the last 28 days as of the last day of the experiment. The issue is that this will include days from before the experiment started. If I use only the days during the experiment, then I'm not really measuring MAU since MAU is 28 days and the experiment ran for only 14 days.\n* Scenario 3: Run experiment for more than 28 days, say 35 days. At the end of the experiment, compare the proportion of users in each group that placed an order in the last 28 days as of the last day of the experiment. The issue is that this will exclude data from the first 7 days of the experiment. If I use all the days during the experiment, then I'm not really measuring MAU since MAU is 28 days and the experiment ran for 35 days.\n\nDoes anyone have any advice on how to measure impact to MAU through experimentation? Thank you!", "author_fullname": "t2_4dj7jy40", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for measuring MAUs (Monthly Active Users) through A/B testing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103bqny", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672858773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, thanks in advance for your advice.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to determine whether certain product feature improvements increased the number of monthly active users (active is defined as whether the user made a purchase in the last 28 days). We have the ability to A/B test but I&amp;#39;m getting stuck because this MAU metric is a moving window metric. If we run the experiment for exactly 28 days then I think calculating the impact to MAU is easy. But most of the time our experiments run for more or less days than 28 days. Below are a few scenarios to illustrate my point.&lt;/p&gt;\n\n&lt;p&gt;Note: All scenarios are A/B tests where we split our user base into equal treatment and control groups. So far, I&amp;#39;ve been calculating &amp;quot;MAU Rate&amp;quot;, which is the proportion of users who placed an order in the last 28 days as of the last day of the experiment.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Scenario 1: Run experiment for exactly 28 days. At the end of 28 days, simply compare the proportion of users in each group that placed an order.&lt;/li&gt;\n&lt;li&gt;Scenario 2: Run experiment for less than 28 days, say 14 days. At the end of the experiment, compare the proportion of users in each group that placed an order in the last 28 days as of the last day of the experiment. The issue is that this will include days from before the experiment started. If I use only the days during the experiment, then I&amp;#39;m not really measuring MAU since MAU is 28 days and the experiment ran for only 14 days.&lt;/li&gt;\n&lt;li&gt;Scenario 3: Run experiment for more than 28 days, say 35 days. At the end of the experiment, compare the proportion of users in each group that placed an order in the last 28 days as of the last day of the experiment. The issue is that this will exclude data from the first 7 days of the experiment. If I use all the days during the experiment, then I&amp;#39;m not really measuring MAU since MAU is 28 days and the experiment ran for 35 days.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Does anyone have any advice on how to measure impact to MAU through experimentation? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103bqny", "is_robot_indexable": true, "report_reasons": null, "author": "productanalyst9", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103bqny/advice_for_measuring_maus_monthly_active_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103bqny/advice_for_measuring_maus_monthly_active_users/", "subreddit_subscribers": 833779, "created_utc": 1672858773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am currently pursuing bachelor's in Applied Statistics And Analytics. Should I enroll for online courses for better job opportunities, and if yes, which course should I opt for if I want to be a data scientist?", "author_fullname": "t2_ceeclsu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I enroll for online courses?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1032fqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672835152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am currently pursuing bachelor&amp;#39;s in Applied Statistics And Analytics. Should I enroll for online courses for better job opportunities, and if yes, which course should I opt for if I want to be a data scientist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1032fqa", "is_robot_indexable": true, "report_reasons": null, "author": "Personal-Month7033", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1032fqa/should_i_enroll_for_online_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1032fqa/should_i_enroll_for_online_courses/", "subreddit_subscribers": 833779, "created_utc": 1672835152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey there fellow data nerds!\nHaving just read 'story telling with data' by Cole and 'Accelerate' by Nicole I am looking for my next read.\n\nI stumbled upon the book 'designing data intensive applications' by Martin. Is the book still relevant today in 2023 as I can see the book is from 2017.\n\nThe reason I ask is that I felt like the book 'Accelerate' isn't really relevant anymore as it was more focused on the data about why DevOps is good - with data from 2013-2015. Today I don't believe there is much discussion and that a clear consensus exists that DevOps is great. \n\nHave anyone here read the book by Martin and can you recommend it in 2023?", "author_fullname": "t2_7z990bkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_102zjbs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672825804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there fellow data nerds!\nHaving just read &amp;#39;story telling with data&amp;#39; by Cole and &amp;#39;Accelerate&amp;#39; by Nicole I am looking for my next read.&lt;/p&gt;\n\n&lt;p&gt;I stumbled upon the book &amp;#39;designing data intensive applications&amp;#39; by Martin. Is the book still relevant today in 2023 as I can see the book is from 2017.&lt;/p&gt;\n\n&lt;p&gt;The reason I ask is that I felt like the book &amp;#39;Accelerate&amp;#39; isn&amp;#39;t really relevant anymore as it was more focused on the data about why DevOps is good - with data from 2013-2015. Today I don&amp;#39;t believe there is much discussion and that a clear consensus exists that DevOps is great. &lt;/p&gt;\n\n&lt;p&gt;Have anyone here read the book by Martin and can you recommend it in 2023?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "102zjbs", "is_robot_indexable": true, "report_reasons": null, "author": "ditlevrisdahl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/102zjbs/book_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/102zjbs/book_recommendation/", "subreddit_subscribers": 833779, "created_utc": 1672825804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm making some experiments on a dataset where I have a float value associated with a DateTime object - Like a dict.\n\nI'm trying to downsample this dataset to optimize the algorithm - I'm currently extracting some elements by the date (removing elements with less than 15 days intervals).\n\nBut now, with that sample that I extract, I don't know how to ensure the quality of the data. How can I make sure that I don't lose any important info in the removed elements?\n\n&amp;#x200B;\n\nTL;DR: How can I ensure the quality of info on downsampling compared with the original data?\n\n(I can't use correlation because of the different lengths of the original data and the filtered data.)\n\n(Language is not important, but I'm using Python)", "author_fullname": "t2_9s1yrp6d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ensure quality on data sampling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103hmu1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672872345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m making some experiments on a dataset where I have a float value associated with a DateTime object - Like a dict.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to downsample this dataset to optimize the algorithm - I&amp;#39;m currently extracting some elements by the date (removing elements with less than 15 days intervals).&lt;/p&gt;\n\n&lt;p&gt;But now, with that sample that I extract, I don&amp;#39;t know how to ensure the quality of the data. How can I make sure that I don&amp;#39;t lose any important info in the removed elements?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TL;DR: How can I ensure the quality of info on downsampling compared with the original data?&lt;/p&gt;\n\n&lt;p&gt;(I can&amp;#39;t use correlation because of the different lengths of the original data and the filtered data.)&lt;/p&gt;\n\n&lt;p&gt;(Language is not important, but I&amp;#39;m using Python)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103hmu1", "is_robot_indexable": true, "report_reasons": null, "author": "ddponwheels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103hmu1/ensure_quality_on_data_sampling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103hmu1/ensure_quality_on_data_sampling/", "subreddit_subscribers": 833779, "created_utc": 1672872345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A guide on How To Create an End-2-End Text Paraphrase App on. medium:\n\n[https://medium.com/towards-artificial-intelligence/how-to-create-an-end-2-end-text-paraphrase-app-db83a4e05918](https://medium.com/towards-artificial-intelligence/how-to-create-an-end-2-end-text-paraphrase-app-db83a4e05918)", "author_fullname": "t2_9u34jt5y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How To Create an End-2-End Text Paraphrase App", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103hdcu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672871715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A guide on How To Create an End-2-End Text Paraphrase App on. medium:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/towards-artificial-intelligence/how-to-create-an-end-2-end-text-paraphrase-app-db83a4e05918\"&gt;https://medium.com/towards-artificial-intelligence/how-to-create-an-end-2-end-text-paraphrase-app-db83a4e05918&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?auto=webp&amp;s=bb6389c4cd15b1abde36649ce97eaba42a213714", "width": 1200, "height": 1198}, "resolutions": [{"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dea9a59971b8cf41b1ccb3bcc1e087458e08241c", "width": 108, "height": 107}, {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=830bc4e25f32c0576a0f177fd6913b4f82c7630d", "width": 216, "height": 215}, {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=594c6c4907fa5659b09fb59e7fa9d2ef3a52f56b", "width": 320, "height": 319}, {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22efc5645824d6329150e4d57c79e4968917302c", "width": 640, "height": 638}, {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3dc6c2cb93f7054dc116b2fda2ca516c44ff18e2", "width": 960, "height": 958}, {"url": "https://external-preview.redd.it/h-TGeNNNx7Dq9GEju1221pxsLjOc7hj_mlWKjQyJSSI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1a0c1b607573de589482ac03e5d90ee831f0917", "width": 1080, "height": 1078}], "variants": {}, "id": "k2GmNr0rGXkRrwBC0TqHAGmo4_HKU4v_psIQLYdIAhI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103hdcu", "is_robot_indexable": true, "report_reasons": null, "author": "Nice-Tomorrow2926", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103hdcu/how_to_create_an_end2end_text_paraphrase_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103hdcu/how_to_create_an_end2end_text_paraphrase_app/", "subreddit_subscribers": 833779, "created_utc": 1672871715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a1u18i4p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great insights for first party data and buyer intent data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103hbmo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1672871609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "qualifi.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.qualifi.ai/en/resources/resource-center.html?utm_campaign=0123-RES-LB&amp;utm_source=outlook&amp;utm_medium=email", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103hbmo", "is_robot_indexable": true, "report_reasons": null, "author": "adguy1384", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103hbmo/great_insights_for_first_party_data_and_buyer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.qualifi.ai/en/resources/resource-center.html?utm_campaign=0123-RES-LB&amp;utm_source=outlook&amp;utm_medium=email", "subreddit_subscribers": 833779, "created_utc": 1672871609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My friend and I are working on a project that requires us to parse through public company investments and see what those companies invest in (for example what companies does Ford invest in). Where can I find forms that have this information? I\u2019ve been looking for days and can\u2019t find anything.", "author_fullname": "t2_1ejbhpsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there Public company investments data/data sheets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_103gonl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672870146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend and I are working on a project that requires us to parse through public company investments and see what those companies invest in (for example what companies does Ford invest in). Where can I find forms that have this information? I\u2019ve been looking for days and can\u2019t find anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103gonl", "is_robot_indexable": true, "report_reasons": null, "author": "ZavierTheSavior", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103gonl/are_there_public_company_investments_datadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103gonl/are_there_public_company_investments_datadata/", "subreddit_subscribers": 833779, "created_utc": 1672870146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I learned basic neural net and SVM but never needed to use them. What skills/tech/models are most useful?", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which DS skills/tech/models are most useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103fjzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672867564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I learned basic neural net and SVM but never needed to use them. What skills/tech/models are most useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103fjzz", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103fjzz/which_ds_skillstechmodels_are_most_useful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103fjzz/which_ds_skillstechmodels_are_most_useful/", "subreddit_subscribers": 833779, "created_utc": 1672867564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nI was having some thoughts lately, from my experiencem, that HPO in XGBoost does not all a lot. Does it make sense to anyone else?", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is HPO really, in XGBoost?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103c5jc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672859704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I was having some thoughts lately, from my experiencem, that HPO in XGBoost does not all a lot. Does it make sense to anyone else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103c5jc", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103c5jc/how_important_is_hpo_really_in_xgboost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103c5jc/how_important_is_hpo_really_in_xgboost/", "subreddit_subscribers": 833779, "created_utc": 1672859704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm modeling a Tweedie distribution on my dataset of counts in R.  When I run a Tweedie distribution model and check results in R, my dispersion/scale parameter is very high, about 200.  This is giving me very high p-values and an uncertain estimate.  (When I manually set the dispersion parameter to 1, I get the same results as Poisson and a highly significant p-value estimates).  How do I lower this dispersion for Tweedie without manually changing the dispersion parameter (cheating) to reduce p-values?   Do I just drop points/outliers until it goes down satisfactorily to get significant results?  Thanks!", "author_fullname": "t2_8avdky0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do to reduce scale parameter estimate in Tweedie distribution? [q]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103bzl9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672859324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m modeling a Tweedie distribution on my dataset of counts in R.  When I run a Tweedie distribution model and check results in R, my dispersion/scale parameter is very high, about 200.  This is giving me very high p-values and an uncertain estimate.  (When I manually set the dispersion parameter to 1, I get the same results as Poisson and a highly significant p-value estimates).  How do I lower this dispersion for Tweedie without manually changing the dispersion parameter (cheating) to reduce p-values?   Do I just drop points/outliers until it goes down satisfactorily to get significant results?  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103bzl9", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Work-204", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103bzl9/what_to_do_to_reduce_scale_parameter_estimate_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103bzl9/what_to_do_to_reduce_scale_parameter_estimate_in/", "subreddit_subscribers": 833779, "created_utc": 1672859324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_mlz5ca9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Year New Resume (SWE, DA, DS Internships)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_103bq0o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/P-aTaBtqKZDWakoLJgUAAalCoRwAzB41DphvILWDzCU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672858732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ezs3drvv74aa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?auto=webp&amp;s=3830f1c9e650674819c55aad8d466c2d6890dfcc", "width": 1170, "height": 1503}, "resolutions": [{"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3239d7f912bd8efb1b9265360a69529ad3af20d", "width": 108, "height": 138}, {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ae73563b137203450895752d3d0a5f8ff3d6eb2", "width": 216, "height": 277}, {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59bce1e1064ea104bac00144c44d411d0a27e650", "width": 320, "height": 411}, {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ef22980085e800988418cae0445f0bc91e7eb6d", "width": 640, "height": 822}, {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=68502804bc5ba43722f882638d26be2892c37265", "width": 960, "height": 1233}, {"url": "https://preview.redd.it/ezs3drvv74aa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95082f2655fae4ce522fc541b67e8a0597e1dcfd", "width": 1080, "height": 1387}], "variants": {}, "id": "doL-tL57hTSBkSuVdPv9QWzwI9qztv7KO4lIcMQz-WY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "103bq0o", "is_robot_indexable": true, "report_reasons": null, "author": "kingdemonfalconmusic", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103bq0o/new_year_new_resume_swe_da_ds_internships/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ezs3drvv74aa1.jpg", "subreddit_subscribers": 833779, "created_utc": 1672858732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello people! In the game of poker, spots for bluffing and bluff-catching can be defined using combinatorics and probability.\n\nFor instance, if on the river (last betting round) **player A** bets and **player B** thinks that **A** are bluffing, then **B** may call with a weak hand (5 card poker combination) given they have so-called blocker., i.e. a card **player B** holds which reduces the number of strong combinations **player A** may be betting with. Similarly, they may have an anti-blocker. It's the same idea mathematically but used in slightly different scenarios.\n\nCombinations are then linked to the probability of winning in a game (in poker it's called equity). If one player wants to bluff-catch given they have a blocker and suspect that another player is bluffing, then it can increase their equity if they decide to call. \n\nMy question is: how would you visualize this effect in a fancy way? I have computed a list of equities for the situations when player have and do not have blockers/anti-blockers, but before plotting a bar chart I thought to listen for suggestions, I would like to make it more professional.", "author_fullname": "t2_8o72hczf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualization of blocker effect in poker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_103aiee", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672855921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people! In the game of poker, spots for bluffing and bluff-catching can be defined using combinatorics and probability.&lt;/p&gt;\n\n&lt;p&gt;For instance, if on the river (last betting round) &lt;strong&gt;player A&lt;/strong&gt; bets and &lt;strong&gt;player B&lt;/strong&gt; thinks that &lt;strong&gt;A&lt;/strong&gt; are bluffing, then &lt;strong&gt;B&lt;/strong&gt; may call with a weak hand (5 card poker combination) given they have so-called blocker., i.e. a card &lt;strong&gt;player B&lt;/strong&gt; holds which reduces the number of strong combinations &lt;strong&gt;player A&lt;/strong&gt; may be betting with. Similarly, they may have an anti-blocker. It&amp;#39;s the same idea mathematically but used in slightly different scenarios.&lt;/p&gt;\n\n&lt;p&gt;Combinations are then linked to the probability of winning in a game (in poker it&amp;#39;s called equity). If one player wants to bluff-catch given they have a blocker and suspect that another player is bluffing, then it can increase their equity if they decide to call. &lt;/p&gt;\n\n&lt;p&gt;My question is: how would you visualize this effect in a fancy way? I have computed a list of equities for the situations when player have and do not have blockers/anti-blockers, but before plotting a bar chart I thought to listen for suggestions, I would like to make it more professional.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "103aiee", "is_robot_indexable": true, "report_reasons": null, "author": "International_Elk427", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/103aiee/visualization_of_blocker_effect_in_poker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/103aiee/visualization_of_blocker_effect_in_poker/", "subreddit_subscribers": 833779, "created_utc": 1672855921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I made a credit card fraud detector project but it only reads the one dataset from Kaagle. Everything work fine but I want to use ANY CSV exported by the users bank account, Is it possible to do it in a way it can read any CSV from any bank account that I export transactions to CSV?", "author_fullname": "t2_ay0frfzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Credit card fraud detection software with any CSV exported from bank?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1039pl3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672854110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a credit card fraud detector project but it only reads the one dataset from Kaagle. Everything work fine but I want to use ANY CSV exported by the users bank account, Is it possible to do it in a way it can read any CSV from any bank account that I export transactions to CSV?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1039pl3", "is_robot_indexable": true, "report_reasons": null, "author": "Canadagoose777", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1039pl3/credit_card_fraud_detection_software_with_any_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1039pl3/credit_card_fraud_detection_software_with_any_csv/", "subreddit_subscribers": 833779, "created_utc": 1672854110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a governmental organization. Recently there has been a massive reorganization where I work. My team is now situated within the \"Office of Data Science, Visualization Team\". The Vizualization team is responsible for producing various dashboards and other vizualizations (in the form of reports, ad hoc figures, etc) for the agency. \n\nMy specific unit within the Vizualisation Team is responsible for: extracting source data, cleaning and wrangling the data, summarising and performing descriptive statistics, then formatting the data so that it is in back-end CSV files that can then be used by another team, which produces dashboards in PowerBI and Tableau. \n\nThere is an adjacent unit with produces the dashboards in PowerBI and Tableau and governs the publication process (both public facing and internal dashboards). \n\nI need help coming up with a name for my new team (and the adjacent team). It must sound professional (I work in Gov).\n\nSome other relevent information:\n\nMy team primarily uses R for the above described tasks. We will sometimes also be writing code in R to produce Shiny dashboards, though this will be rare since we already have a unit that builds PowerBI and Tableau dashboards. \n\nAny ideas for us?!?!", "author_fullname": "t2_10waph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help coming up with a name for my data science team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1038kmh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672851493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a governmental organization. Recently there has been a massive reorganization where I work. My team is now situated within the &amp;quot;Office of Data Science, Visualization Team&amp;quot;. The Vizualization team is responsible for producing various dashboards and other vizualizations (in the form of reports, ad hoc figures, etc) for the agency. &lt;/p&gt;\n\n&lt;p&gt;My specific unit within the Vizualisation Team is responsible for: extracting source data, cleaning and wrangling the data, summarising and performing descriptive statistics, then formatting the data so that it is in back-end CSV files that can then be used by another team, which produces dashboards in PowerBI and Tableau. &lt;/p&gt;\n\n&lt;p&gt;There is an adjacent unit with produces the dashboards in PowerBI and Tableau and governs the publication process (both public facing and internal dashboards). &lt;/p&gt;\n\n&lt;p&gt;I need help coming up with a name for my new team (and the adjacent team). It must sound professional (I work in Gov).&lt;/p&gt;\n\n&lt;p&gt;Some other relevent information:&lt;/p&gt;\n\n&lt;p&gt;My team primarily uses R for the above described tasks. We will sometimes also be writing code in R to produce Shiny dashboards, though this will be rare since we already have a unit that builds PowerBI and Tableau dashboards. &lt;/p&gt;\n\n&lt;p&gt;Any ideas for us?!?!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1038kmh", "is_robot_indexable": true, "report_reasons": null, "author": "silverfoxrox", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1038kmh/help_coming_up_with_a_name_for_my_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1038kmh/help_coming_up_with_a_name_for_my_data_science/", "subreddit_subscribers": 833779, "created_utc": 1672851493.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}