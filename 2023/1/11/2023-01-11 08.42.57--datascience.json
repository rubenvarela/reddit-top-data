{"kind": "Listing", "data": {"after": "t3_108na3e", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My career started as an academic doing my PhD in cancer immunology research and extended through jobs at Harvard Medical School (Postdoc), Uber, Facebook, McKinsey &amp; Company.. and finally back to doing cancer research again.\n\nOver the years I've found that \"Data Scientist\" is a heterogenous term that primarily centres around anyone who can derive insight from data. And I've worked with both the traditional data scientist  CS/Stats background types all the way through to data scientists with bachelors in Art History. The bottom line is that each bring their own unique and very invaluable thinking styles to the field.\n\nThe art historian turned data scientist once proposed an extremely interesting way of organising plots way before sns.pairplot() was a thing, our client LOVED it. Another data scientist who had a background in sociology was able to pull some awesome insights around credit default rates given the average number of letterboxes in a neighbourhood.\n\nThe point is, some of the best DS people I've worked with came from eclectic backgrounds and it's usually those ones that I learn from the most. So if you're thinking about becoming a data scientist, don't be dissuaded by the coding aspect (which can be learned in months). The thinking style you've cultivated takes YEARS to develop.\n\n&amp;#x200B;\n\nEDIT: a bunch of people have been asking about DS entry programmes. Don't pay for tech skills you can learn for free on youtube. For example I teach DS on my channel - the fundamentals - totally free forever.\n\n[https://www.youtube.com/watch?v=ckw8D34c03U](https://www.youtube.com/watch?v=ckw8D34c03U) \\- Week 1\n\n[https://www.youtube.com/watch?v=1LCN\\_14OCc8&amp;t=2s](https://www.youtube.com/watch?v=1LCN_14OCc8&amp;t=2s) \\- Week 2\n\nIf guys need any help breaking into the industry shoot me a DM and I'll see if there's anyone I know that can refer you. \n\n&amp;#x200B;", "author_fullname": "t2_7h1mi6us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After having spent 10 years in Data Science - literally ANYONE could (and should) become a data scientist.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108boxq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 190, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 190, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673368674.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673362343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My career started as an academic doing my PhD in cancer immunology research and extended through jobs at Harvard Medical School (Postdoc), Uber, Facebook, McKinsey &amp;amp; Company.. and finally back to doing cancer research again.&lt;/p&gt;\n\n&lt;p&gt;Over the years I&amp;#39;ve found that &amp;quot;Data Scientist&amp;quot; is a heterogenous term that primarily centres around anyone who can derive insight from data. And I&amp;#39;ve worked with both the traditional data scientist  CS/Stats background types all the way through to data scientists with bachelors in Art History. The bottom line is that each bring their own unique and very invaluable thinking styles to the field.&lt;/p&gt;\n\n&lt;p&gt;The art historian turned data scientist once proposed an extremely interesting way of organising plots way before sns.pairplot() was a thing, our client LOVED it. Another data scientist who had a background in sociology was able to pull some awesome insights around credit default rates given the average number of letterboxes in a neighbourhood.&lt;/p&gt;\n\n&lt;p&gt;The point is, some of the best DS people I&amp;#39;ve worked with came from eclectic backgrounds and it&amp;#39;s usually those ones that I learn from the most. So if you&amp;#39;re thinking about becoming a data scientist, don&amp;#39;t be dissuaded by the coding aspect (which can be learned in months). The thinking style you&amp;#39;ve cultivated takes YEARS to develop.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: a bunch of people have been asking about DS entry programmes. Don&amp;#39;t pay for tech skills you can learn for free on youtube. For example I teach DS on my channel - the fundamentals - totally free forever.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=ckw8D34c03U\"&gt;https://www.youtube.com/watch?v=ckw8D34c03U&lt;/a&gt; - Week 1&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=1LCN_14OCc8&amp;amp;t=2s\"&gt;https://www.youtube.com/watch?v=1LCN_14OCc8&amp;amp;t=2s&lt;/a&gt; - Week 2&lt;/p&gt;\n\n&lt;p&gt;If guys need any help breaking into the industry shoot me a DM and I&amp;#39;ll see if there&amp;#39;s anyone I know that can refer you. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?auto=webp&amp;v=enabled&amp;s=c38eb7b95ce56a3a5647efa18b59d6d44a921cbc", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d5fb6ac0fc019d8dfbbdc09ca0f51e003f5bf6a", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c88b289386a91f1175d81ece87389a07160b4519", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=86c4fbe502a59fb4553dc2cee13428f3167c413e", "width": 320, "height": 240}], "variants": {}, "id": "kbV3ao1DWT7nSe-FDzynjLiV3nCKwCf-0CO6khmjc_8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108boxq", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPaintings5866", "discussion_type": null, "num_comments": 143, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108boxq/after_having_spent_10_years_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108boxq/after_having_spent_10_years_in_data_science/", "subreddit_subscribers": 835971, "created_utc": 1673362343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pzr91bdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nerf Technology with Stable Diffusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_108fq2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/jajny30c59ba1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 960, "scrubber_media_url": "https://v.redd.it/jajny30c59ba1/DASH_96.mp4", "dash_url": "https://v.redd.it/jajny30c59ba1/DASHPlaylist.mpd?a=1676018576%2CYWNlZWUyMmMxZjliZWQ5N2Q1NjM4Yjc5NGIyYTlhMGZhZTFkZjE3NTY2ODhjMDg5ZDRlYzQ0YmFjZmI5YWM3OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/jajny30c59ba1/HLSPlaylist.m3u8?a=1676018576%2CMTA5ZDUzZTBlNWE1ZmE3YmQ2M2ViY2JlMWExODM2NDdmNjAwMjdiMjNjMmI1ZTM1ODVmZTdkNTUyNjg4YmRlNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZehTDjLOeUbXNkoKXlKZV2HRFfBu3y0PEkCnRkFoMrE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673372277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/jajny30c59ba1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0aceceaf9131ab532c3d502d47ab2a1c6e2d9d0b", "width": 1920, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=cc41263e8403cf286f5534259d8e82ba00d1eeee", "width": 108, "height": 121}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=13373209aced2d8930c7a3456089875bdbb182dc", "width": 216, "height": 243}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b0d8939818fa1e6ffab98d1a241d0f0300139ff2", "width": 320, "height": 360}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=154fd30445e575c309a06b124163748596888caf", "width": 640, "height": 720}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c2b93739c4813f1616796761aa02ffcfc3232d66", "width": 960, "height": 1080}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=027c0bd33f32398a74a42638c78ab8c10e8b441c", "width": 1080, "height": 1215}], "variants": {}, "id": "gAhTBMwZ_Y_NLNG99bK_fsoASmG9gTWMFL8RBqyAMwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108fq2y", "is_robot_indexable": true, "report_reasons": null, "author": "oridnary_artist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108fq2y/nerf_technology_with_stable_diffusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/jajny30c59ba1", "subreddit_subscribers": 835971, "created_utc": 1673372277.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/jajny30c59ba1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 960, "scrubber_media_url": "https://v.redd.it/jajny30c59ba1/DASH_96.mp4", "dash_url": "https://v.redd.it/jajny30c59ba1/DASHPlaylist.mpd?a=1676018576%2CYWNlZWUyMmMxZjliZWQ5N2Q1NjM4Yjc5NGIyYTlhMGZhZTFkZjE3NTY2ODhjMDg5ZDRlYzQ0YmFjZmI5YWM3OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/jajny30c59ba1/HLSPlaylist.m3u8?a=1676018576%2CMTA5ZDUzZTBlNWE1ZmE3YmQ2M2ViY2JlMWExODM2NDdmNjAwMjdiMjNjMmI1ZTM1ODVmZTdkNTUyNjg4YmRlNQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My employer has been on and off about his growth plans so I started to look to upgrade my job and have been applying to different jobs for several weeks now.\n\nI just use a basic excel spreadsheet and 95% precut cover letter and I am at 151 jobs applied to since Thanksgiving and I got two callbacks this week. Marketing Analytics and Data Science Analyst position both sent me links to www.codility.com\n\nThe first is likely 100% remote and recruiter has been very prompt and forwarded me to a tech screen. I just got off the phone with the \u201cit\u2019s pretty standard but you should have no problem if you know what you\u2019re doing\u201d\n\n\u2026famous last words.\n\nThese recruiters each need me to do a two hour \u201ccodility\u201d test, which I\u2019ve never heard of but who has tips about the format or what to expect?\n\nObviously I\u2019m not asking for any answers or links to data dumps, I just have never heard of and don\u2019t know what to expect for www.codility.com. Any reccomendations that I can prepare or brush up on my SQL code or maybe they\u2019re more situational questions I don\u2019t know?\n\nI\u2019ve signed up for the developer account and waiting for their verification email to start to practice but advice is welcome.", "author_fullname": "t2_a1wq8rgz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recruiter for a big reputable firm I\u2019d love to work for sent me an \u201ctech assessment\u201d (I think) via codility, who has used these?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108nvnx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673391414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My employer has been on and off about his growth plans so I started to look to upgrade my job and have been applying to different jobs for several weeks now.&lt;/p&gt;\n\n&lt;p&gt;I just use a basic excel spreadsheet and 95% precut cover letter and I am at 151 jobs applied to since Thanksgiving and I got two callbacks this week. Marketing Analytics and Data Science Analyst position both sent me links to &lt;a href=\"http://www.codility.com\"&gt;www.codility.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The first is likely 100% remote and recruiter has been very prompt and forwarded me to a tech screen. I just got off the phone with the \u201cit\u2019s pretty standard but you should have no problem if you know what you\u2019re doing\u201d&lt;/p&gt;\n\n&lt;p&gt;\u2026famous last words.&lt;/p&gt;\n\n&lt;p&gt;These recruiters each need me to do a two hour \u201ccodility\u201d test, which I\u2019ve never heard of but who has tips about the format or what to expect?&lt;/p&gt;\n\n&lt;p&gt;Obviously I\u2019m not asking for any answers or links to data dumps, I just have never heard of and don\u2019t know what to expect for &lt;a href=\"http://www.codility.com\"&gt;www.codility.com&lt;/a&gt;. Any reccomendations that I can prepare or brush up on my SQL code or maybe they\u2019re more situational questions I don\u2019t know?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve signed up for the developer account and waiting for their verification email to start to practice but advice is welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?auto=webp&amp;v=enabled&amp;s=152c43142e9891d38481b8073ecda5b9e42a59fe", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=194ccaf05b4bfe7cb7673a2151e789dd5dc4178d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bbffe6d27dcbca61883a51f4e98099f37e2dfdd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1af45973cb5a971c792832e405ffd9eb3afff017", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33aa1952e614077c07c6556c120d56c1530b228b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3256ef4d050fa80a42ba7980fa58439d51fc25a3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a79f8b5c2f7db94b94d4ffe5d4bf855c07db8ee", "width": 1080, "height": 567}], "variants": {}, "id": "d8eWOwyigfUJobzo9He56f9jD0Gj1VyVpcob5LcVzBg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "108nvnx", "is_robot_indexable": true, "report_reasons": null, "author": "FourTerrabytesLost", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108nvnx/recruiter_for_a_big_reputable_firm_id_love_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108nvnx/recruiter_for_a_big_reputable_firm_id_love_to/", "subreddit_subscribers": 835971, "created_utc": 1673391414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started using the statsmodels python package and I'm having trouble figuring out how we should fit and evaluate a time series model.\n\nMy way of thinking was: you split data into train and test, you train a model with the train data (say ARIMA for example) and you evaluate it on the test set, but I've seen people do different things.\n\nI saw a lot of people feed the ARIMA model the whole dataset, fit it and then evaluate on the last couple of data points. This would be training and evaluating on the same dataset and I'm sure that is wrong.\n\nI've also seen people train the model with the train data and then forecast X time steps into the future and compare those results with the test set (RMSE, R\\^2, etc...), but this has the disadvantage that the forecasted values will tend towards the mean, so it's not really a good way to evaluate the model, right?\n\nWhy isn't there a more straight forward way to do this with statsmodels? At least from what I've seen you can't feed an already trained model test data to evaluate it, right?\n\nI thought it should be done like it is done in this [notebook](https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary) but I never seem him give the model the test data, so how can it work?", "author_fullname": "t2_h916gqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to evaluate ARIMA model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108jzf1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673382440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started using the statsmodels python package and I&amp;#39;m having trouble figuring out how we should fit and evaluate a time series model.&lt;/p&gt;\n\n&lt;p&gt;My way of thinking was: you split data into train and test, you train a model with the train data (say ARIMA for example) and you evaluate it on the test set, but I&amp;#39;ve seen people do different things.&lt;/p&gt;\n\n&lt;p&gt;I saw a lot of people feed the ARIMA model the whole dataset, fit it and then evaluate on the last couple of data points. This would be training and evaluating on the same dataset and I&amp;#39;m sure that is wrong.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen people train the model with the train data and then forecast X time steps into the future and compare those results with the test set (RMSE, R^2, etc...), but this has the disadvantage that the forecasted values will tend towards the mean, so it&amp;#39;s not really a good way to evaluate the model, right?&lt;/p&gt;\n\n&lt;p&gt;Why isn&amp;#39;t there a more straight forward way to do this with statsmodels? At least from what I&amp;#39;ve seen you can&amp;#39;t feed an already trained model test data to evaluate it, right?&lt;/p&gt;\n\n&lt;p&gt;I thought it should be done like it is done in this &lt;a href=\"https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary\"&gt;notebook&lt;/a&gt; but I never seem him give the model the test data, so how can it work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&amp;v=enabled&amp;s=631c5ffb5e73b7cba00d3037f93f6b0e3a572cc1", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6233a4c291e5fa397dc009e7b51e5b4f0956e81", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a4c66acaa5a7fb54e888c77ab524a597a037c26", "width": 216, "height": 216}], "variants": {}, "id": "63C1GbYQbI4tHZMkw99e-qlyoYaGnG58yfnmnFUJ34s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108jzf1", "is_robot_indexable": true, "report_reasons": null, "author": "AdministrativeRub484", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108jzf1/how_to_evaluate_arima_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108jzf1/how_to_evaluate_arima_model/", "subreddit_subscribers": 835971, "created_utc": 1673382440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nOur retail customers sell products through our platform, they are free to enter the product name as they see fit, this causes a problem as we would have different strings referring to the same product.\n\n&amp;#x200B;\n\n|product entered by user|actual product in reference table|\n|:-|:-|\n|tothbrush red 100|toothbrush red 100|\n|toothb r 100|toothbrush red 100|\n|X shampooooo! 100ml|X shampoo 100ml|\n\nI would like to build a model that given a text entered by the user it will find it's closest match from a reference list containing all the product names. However, I have three major concerns:\n\n1. Thousands of products are sold each day, comparing thousands of products with the reference list that is approximately 10,000 (and keeps growing) would yield tens of millions of iterations. How would I tackle this computational complexity.\n2. I am thinking of using sentence transformers, where the incoming product embedding is compared to the embeddings of the products the reference list, returning the one with the max similarity, or using a siamese network where each pair of products is fed to the network and return the first match found.\n3. The goal of this exercise is to diminish the manual work involved in linking the products, but how do I define a similarity threshold, such that if the similarity is not sufficient, it has to be reviewed manually by humans.\n\nNote: I can utilize an additional feature such as the price of the product to reduce the number of products am iterating over as well.\n\nyour thoughts veterans would be highly appreciated.", "author_fullname": "t2_8jmib0lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Discussion] NLP for products matching", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108a5sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673358243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Our retail customers sell products through our platform, they are free to enter the product name as they see fit, this causes a problem as we would have different strings referring to the same product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;product entered by user&lt;/th&gt;\n&lt;th align=\"left\"&gt;actual product in reference table&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;tothbrush red 100&lt;/td&gt;\n&lt;td align=\"left\"&gt;toothbrush red 100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;toothb r 100&lt;/td&gt;\n&lt;td align=\"left\"&gt;toothbrush red 100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;X shampooooo! 100ml&lt;/td&gt;\n&lt;td align=\"left\"&gt;X shampoo 100ml&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I would like to build a model that given a text entered by the user it will find it&amp;#39;s closest match from a reference list containing all the product names. However, I have three major concerns:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Thousands of products are sold each day, comparing thousands of products with the reference list that is approximately 10,000 (and keeps growing) would yield tens of millions of iterations. How would I tackle this computational complexity.&lt;/li&gt;\n&lt;li&gt;I am thinking of using sentence transformers, where the incoming product embedding is compared to the embeddings of the products the reference list, returning the one with the max similarity, or using a siamese network where each pair of products is fed to the network and return the first match found.&lt;/li&gt;\n&lt;li&gt;The goal of this exercise is to diminish the manual work involved in linking the products, but how do I define a similarity threshold, such that if the similarity is not sufficient, it has to be reviewed manually by humans.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Note: I can utilize an additional feature such as the price of the product to reduce the number of products am iterating over as well.&lt;/p&gt;\n\n&lt;p&gt;your thoughts veterans would be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108a5sj", "is_robot_indexable": true, "report_reasons": null, "author": "Riolite55", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108a5sj/discussion_nlp_for_products_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108a5sj/discussion_nlp_for_products_matching/", "subreddit_subscribers": 835971, "created_utc": 1673358243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vi17yd7i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Review? Looking for Data Analytics/Science and Business Intelligence internships. Bay area based!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_108wmc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b8ozaEFRJIiwEgHg4xhVpc4Sghfe2sHDECC-nCPtr38.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673414934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/713eo9cr5eba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?auto=webp&amp;v=enabled&amp;s=a3f77cae7f75b0c62a7ff2d7c6fab30e67272c27", "width": 2550, "height": 3300}, "resolutions": [{"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b7191fa5a9c485d5a13ed5e5a8b6a91eccb5b2", "width": 108, "height": 139}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca035fe219e7e3c59279be1382377b8ce224a101", "width": 216, "height": 279}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b0a259314426511da576d32507ffcaf5d293bfd", "width": 320, "height": 414}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=306e53449c3643ce2f9ed0a9d280dc1c5621208e", "width": 640, "height": 828}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80553ba6ba809600c5634c3640cb4da501a8b822", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14cd709293a7bdee14dbd3fe38de9f69463ac5cb", "width": 1080, "height": 1397}], "variants": {}, "id": "xG2bpFPC4VqOAvG42JzmKXfATcoOqNwXGBpon2vuYUM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "108wmc9", "is_robot_indexable": true, "report_reasons": null, "author": "i-am-nobody156", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108wmc9/resume_review_looking_for_data_analyticsscience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/713eo9cr5eba1.jpg", "subreddit_subscribers": 835971, "created_utc": 1673414934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am so far only familar with basic CNN architecture (peeps an image, makes a classification). However, if an image has 2 objects (for example, my problem has two letters in a grid and i must identify them), I believe that basic CNN and softmax activation would fail. Is there a relatively simple way to build this type of model?", "author_fullname": "t2_66zyb9or", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CNN with multiple letters in an image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108rwi0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673401433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am so far only familar with basic CNN architecture (peeps an image, makes a classification). However, if an image has 2 objects (for example, my problem has two letters in a grid and i must identify them), I believe that basic CNN and softmax activation would fail. Is there a relatively simple way to build this type of model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108rwi0", "is_robot_indexable": true, "report_reasons": null, "author": "DChoiBobaboi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108rwi0/cnn_with_multiple_letters_in_an_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108rwi0/cnn_with_multiple_letters_in_an_image/", "subreddit_subscribers": 835971, "created_utc": 1673401433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am trying to fit a model using EconML to get treatment effects and optimal pricing strategies for different products in my dataset. I am trying to fit the model at a county level (to get more observations), but the treatment effects need to be at a state level. Is it possible to extract treatment effects at a state level even though the model is fit at a county level?", "author_fullname": "t2_9ynwnzxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you get treatment effects at higher level of granularity than the level of granularity the model was built for using the EconML package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108f61z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673370947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to fit a model using EconML to get treatment effects and optimal pricing strategies for different products in my dataset. I am trying to fit the model at a county level (to get more observations), but the treatment effects need to be at a state level. Is it possible to extract treatment effects at a state level even though the model is fit at a county level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108f61z", "is_robot_indexable": true, "report_reasons": null, "author": "Ordinary_Zombie_2345", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108f61z/can_you_get_treatment_effects_at_higher_level_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108f61z/can_you_get_treatment_effects_at_higher_level_of/", "subreddit_subscribers": 835971, "created_utc": 1673370947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I test next week to get my CompTIA Data+ certification. I don\u2019t have a background in data science or data analytics but I\u2019m in college for data science. I\u2019m also learning as much as I can through datacamp. For those of you who are seasoned do you find CompTIA Data+ and other certs valuable?", "author_fullname": "t2_sy7sjvbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CompTIA Data+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108n0ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673389462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I test next week to get my CompTIA Data+ certification. I don\u2019t have a background in data science or data analytics but I\u2019m in college for data science. I\u2019m also learning as much as I can through datacamp. For those of you who are seasoned do you find CompTIA Data+ and other certs valuable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108n0ho", "is_robot_indexable": true, "report_reasons": null, "author": "M3TAV3RSE", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108n0ho/comptia_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108n0ho/comptia_data/", "subreddit_subscribers": 835971, "created_utc": 1673389462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tl;dr \u2013 Trying to choose a masters\u2019 program to do research in data science, in a biomedical/clinical context. Options are health informatics, biostatistics, and computer science.\n\n&amp;#x200B;\n\nHey everyone! I graduated from my bachelor\u2019s in Biomedical Sciences this past spring, and have been exploring career options since then, including working at a clinical job, a research job, and self-learning programming/advanced math. \n\nI\u2019ve come to realize I enjoy specific aspects from each experience:\n\n* Data visualization: I enjoy analyzing and communicating research visually, pulling from background courses in biostatistics and graphic design. \n* Research methodology: I noticed that the subject matter didn\u2019t matter (ranging from cell biology to public health), but rather I take interest in how research is structured and designed, and how other computational methods could be applied (e.g. drawing from my science background to see how predictive machine learning can be used in biomedical imaging, epidemiology, etc.)\n* Clinical component: I\u2019d still like to have a clinical/healthcare approach to things, e.g. not closing doors on the (pipedream of an) idea of being a clinician-scientist of sorts\n\n&amp;#x200B;\n\nThat being said, an ideal career of mine would consist of collaborating with various physicians and research groups. This includes working on designing research projects, applying statistical and computational methods for data analysis, and ultimately visually illustrating and communicating the results of the research (e.g. for the public and/or to other researchers).\n\nDoes such a career exist? I\u2019m looking into Masters\u2019 programs to explore the subject matter further, but it seems to be an intersect between computer science, biostatistics, and health informatics. What seems most appropriate from my experience/interests, alongside finding a job afterward?\n\n&amp;#x200B;\n\nSome side thoughts/notes:\n\n* Health informatics was the first thing I came across. Programs I\u2019m looking at are 2 years with internships included. However, they seem more focused solely on management and policy of electronic health records (versus software development or data science), and I\u2019m not too sure how this would translate out to other data science industries in the case I\u2019m needing to pivot fields? Plus, a fair amount of the job descriptions also consider candidates in statistics and CS, but not the other way around\n* Biostatistics programs are 1-2 years long and some also have internships. They focus more on statistical theory alongside other public health concepts. However, I\u2019ve also read that pure statistics might be more theory than I actually need, versus the software skills which data science employers look for?\n* Computer science programs are 2 years long, but I\u2019d be finding internships on my own. Computer science is the least familiar of the fields to me, so I don't know how relevant the skills are in this program to my interests.", "author_fullname": "t2_81epo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Computer Science, Biostatistics, Health Informatics \u2013 best for biomedical data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108lp08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673386422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr \u2013 Trying to choose a masters\u2019 program to do research in data science, in a biomedical/clinical context. Options are health informatics, biostatistics, and computer science.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone! I graduated from my bachelor\u2019s in Biomedical Sciences this past spring, and have been exploring career options since then, including working at a clinical job, a research job, and self-learning programming/advanced math. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve come to realize I enjoy specific aspects from each experience:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data visualization: I enjoy analyzing and communicating research visually, pulling from background courses in biostatistics and graphic design. &lt;/li&gt;\n&lt;li&gt;Research methodology: I noticed that the subject matter didn\u2019t matter (ranging from cell biology to public health), but rather I take interest in how research is structured and designed, and how other computational methods could be applied (e.g. drawing from my science background to see how predictive machine learning can be used in biomedical imaging, epidemiology, etc.)&lt;/li&gt;\n&lt;li&gt;Clinical component: I\u2019d still like to have a clinical/healthcare approach to things, e.g. not closing doors on the (pipedream of an) idea of being a clinician-scientist of sorts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;That being said, an ideal career of mine would consist of collaborating with various physicians and research groups. This includes working on designing research projects, applying statistical and computational methods for data analysis, and ultimately visually illustrating and communicating the results of the research (e.g. for the public and/or to other researchers).&lt;/p&gt;\n\n&lt;p&gt;Does such a career exist? I\u2019m looking into Masters\u2019 programs to explore the subject matter further, but it seems to be an intersect between computer science, biostatistics, and health informatics. What seems most appropriate from my experience/interests, alongside finding a job afterward?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Some side thoughts/notes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Health informatics was the first thing I came across. Programs I\u2019m looking at are 2 years with internships included. However, they seem more focused solely on management and policy of electronic health records (versus software development or data science), and I\u2019m not too sure how this would translate out to other data science industries in the case I\u2019m needing to pivot fields? Plus, a fair amount of the job descriptions also consider candidates in statistics and CS, but not the other way around&lt;/li&gt;\n&lt;li&gt;Biostatistics programs are 1-2 years long and some also have internships. They focus more on statistical theory alongside other public health concepts. However, I\u2019ve also read that pure statistics might be more theory than I actually need, versus the software skills which data science employers look for?&lt;/li&gt;\n&lt;li&gt;Computer science programs are 2 years long, but I\u2019d be finding internships on my own. Computer science is the least familiar of the fields to me, so I don&amp;#39;t know how relevant the skills are in this program to my interests.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108lp08", "is_robot_indexable": true, "report_reasons": null, "author": "itsmarq", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108lp08/computer_science_biostatistics_health_informatics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108lp08/computer_science_biostatistics_health_informatics/", "subreddit_subscribers": 835971, "created_utc": 1673386422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7obzgfpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Data Reday for Analysis - Top Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_108yypn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1673422838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/dataengineering/comments/1086c9u/get_your_data_ready_for_analysis_top_tools_for/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108yypn", "is_robot_indexable": true, "report_reasons": null, "author": "Ill-Psychology-2407", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108yypn/get_data_reday_for_analysis_top_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/dataengineering/comments/1086c9u/get_your_data_ready_for_analysis_top_tools_for/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "subreddit_subscribers": 835971, "created_utc": 1673422838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks!\n\nI am searching for good solution to sync data from several postgres databases located in separate servers into one clickhouse server and multiple clickhouse databases.\n\nFor example:\n\n    postgres-server-1 -&gt; clickhouse-server.database1\npostgres-server-2 -&gt; clickhouse-server.database2\n...\n\nI found airbyte, but they currently do no support JSON fields (I have JSON data in columns) and each sync lasts about 10 minutes.\n\nIs there something more lightweight or should I implement something on myself?\n\nI am really curious about your ideas!", "author_fullname": "t2_efe06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing data from postgres to clickhouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_108yvv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673422531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks!&lt;/p&gt;\n\n&lt;p&gt;I am searching for good solution to sync data from several postgres databases located in separate servers into one clickhouse server and multiple clickhouse databases.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;postgres-server-1 -&amp;gt; clickhouse-server.database1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;postgres-server-2 -&amp;gt; clickhouse-server.database2\n...&lt;/p&gt;\n\n&lt;p&gt;I found airbyte, but they currently do no support JSON fields (I have JSON data in columns) and each sync lasts about 10 minutes.&lt;/p&gt;\n\n&lt;p&gt;Is there something more lightweight or should I implement something on myself?&lt;/p&gt;\n\n&lt;p&gt;I am really curious about your ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108yvv0", "is_robot_indexable": true, "report_reasons": null, "author": "bykof", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108yvv0/syncing_data_from_postgres_to_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108yvv0/syncing_data_from_postgres_to_clickhouse/", "subreddit_subscribers": 835971, "created_utc": 1673422531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Science and Robotics are the cross-disciplines of similar fields of study \u2013 science, statistics, computer technology, and engineering.\n\nLearn more: [https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics](https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics)", "author_fullname": "t2_vfnsdpj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact of Data Science in Robotics | USDSI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108xged", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673417608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Science and Robotics are the cross-disciplines of similar fields of study \u2013 science, statistics, computer technology, and engineering.&lt;/p&gt;\n\n&lt;p&gt;Learn more: &lt;a href=\"https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics\"&gt;https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108xged", "is_robot_indexable": true, "report_reasons": null, "author": "Nikita-Techblogger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108xged/impact_of_data_science_in_robotics_usdsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108xged/impact_of_data_science_in_robotics_usdsi/", "subreddit_subscribers": 835971, "created_utc": 1673417608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In ML how do you guys think about tackling model drift? \n\nFew questions I have are \n\nIs there a way to simulate model in production by backtesting a fitted model with drift triggers? Is this be a practice?\n\nDoes data drift alone work or is it necessary to have error analysis dashboards set up to monitor where the model can mess up through time.\n\nWhat about features importance, wouldn\u2019t feature value loss/gain importance with time? Is it better to stick to what makes sense then select features later? (Even when using more robust methods such as SHAP these features can lose value eventually)\n\nI would like to learn more and take insight if possible?", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model error analysis, and data/feature drift.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108oz6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673393993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In ML how do you guys think about tackling model drift? &lt;/p&gt;\n\n&lt;p&gt;Few questions I have are &lt;/p&gt;\n\n&lt;p&gt;Is there a way to simulate model in production by backtesting a fitted model with drift triggers? Is this be a practice?&lt;/p&gt;\n\n&lt;p&gt;Does data drift alone work or is it necessary to have error analysis dashboards set up to monitor where the model can mess up through time.&lt;/p&gt;\n\n&lt;p&gt;What about features importance, wouldn\u2019t feature value loss/gain importance with time? Is it better to stick to what makes sense then select features later? (Even when using more robust methods such as SHAP these features can lose value eventually)&lt;/p&gt;\n\n&lt;p&gt;I would like to learn more and take insight if possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108oz6w", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108oz6w/model_error_analysis_and_datafeature_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108oz6w/model_error_analysis_and_datafeature_drift/", "subreddit_subscribers": 835971, "created_utc": 1673393993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear datascience sub.\n\nMy team is asking some advices on some A/B testing regarding a model I did not design and I also now need your help !\n\nLet's say we created a ML tool that returns me a list of clients that are considered as \"high value\". The first time after being detected that they enter one of our shop, we greet them in a special manner. \nSome of those detected are NOT \"activated\" in order to be our control group.\n\nNow, stakeholders want to know if the model works, meaning if there is a difference between the clients we contacted and the ones in the control group : we shall look at expense, number of visit, etc.\n\nHow would you compare the two groups, knowing that within the group of people who are activated, all of them are at a different date (and I don't want any time effect to pollute the analysis...)\n\nAny ideas ?\nThanks !", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help Testing \"lagged\" effect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108osc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673393535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear datascience sub.&lt;/p&gt;\n\n&lt;p&gt;My team is asking some advices on some A/B testing regarding a model I did not design and I also now need your help !&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we created a ML tool that returns me a list of clients that are considered as &amp;quot;high value&amp;quot;. The first time after being detected that they enter one of our shop, we greet them in a special manner. \nSome of those detected are NOT &amp;quot;activated&amp;quot; in order to be our control group.&lt;/p&gt;\n\n&lt;p&gt;Now, stakeholders want to know if the model works, meaning if there is a difference between the clients we contacted and the ones in the control group : we shall look at expense, number of visit, etc.&lt;/p&gt;\n\n&lt;p&gt;How would you compare the two groups, knowing that within the group of people who are activated, all of them are at a different date (and I don&amp;#39;t want any time effect to pollute the analysis...)&lt;/p&gt;\n\n&lt;p&gt;Any ideas ?\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108osc9", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108osc9/help_testing_lagged_effect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108osc9/help_testing_lagged_effect/", "subreddit_subscribers": 835971, "created_utc": 1673393535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been seeing around these beautifully drawn flowcharts around and been wondering what's the tool used here to draw the following?\n\nhttps://preview.redd.it/jahiqosim9ba1.png?width=642&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c8879a3c8a674f5c94847f8555e9f524118abcc2", "author_fullname": "t2_btnb6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the software used to draw this flowchart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jahiqosim9ba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 115, "x": 108, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c38a962a0c4a9d6413d82ddf68d9a809bb6d57f6"}, {"y": 231, "x": 216, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=641baa7fabe085336bc64d3b74624ee16d802c31"}, {"y": 343, "x": 320, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e14ad8aad1f233f1c4fbfd2561e7c19b9c8270c9"}, {"y": 686, "x": 640, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1befd05b08b28540fa1639038fe2245498de39ce"}], "s": {"y": 689, "x": 642, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c8879a3c8a674f5c94847f8555e9f524118abcc2"}, "id": "jahiqosim9ba1"}}, "name": "t3_108i57v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ywNBa3I6o3-NwWmPvFlH9g6AIiCayRIWsAB6oIxlzq0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673378097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been seeing around these beautifully drawn flowcharts around and been wondering what&amp;#39;s the tool used here to draw the following?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c8879a3c8a674f5c94847f8555e9f524118abcc2\"&gt;https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c8879a3c8a674f5c94847f8555e9f524118abcc2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108i57v", "is_robot_indexable": true, "report_reasons": null, "author": "smoothtwist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108i57v/what_is_the_software_used_to_draw_this_flowchart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108i57v/what_is_the_software_used_to_draw_this_flowchart/", "subreddit_subscribers": 835971, "created_utc": 1673378097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_usk7jj3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[New Feature] Discover and Extract Text Patterns with RATH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_108b680", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zTWsIEjqhCDqYOS-Qb5gDybSvD2qver7RxRCyDXU-Bo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673360974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/95o38brk68ba1.gif", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?format=png8&amp;v=enabled&amp;s=7d1194c3607e13aa1181663edcac0095a7e46d9b", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=628650ce4f824a3a2ac892894839ad30ac1178e6", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=1716767b8c4caa4a07e91249958bfd0405d1c592", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=a7e33b2fcb3285051fad3b519fd9552ae2fc03ce", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=f22e27bc2826cbf854bd859c503144e0f244a151", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;crop=smart&amp;format=png8&amp;v=enabled&amp;s=3840692b336cea0925475596f7f0ef1745670742", "width": 960, "height": 433}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?s=7168c620b27dda45663967fe2bdee370bd22f9e6", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;crop=smart&amp;v=enabled&amp;s=b88bf75bae722f1434ba915e2da1f52ff1b97ce6", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;crop=smart&amp;v=enabled&amp;s=a6ac7437e3a7038eeeb0bd370d787e0014b29b82", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;crop=smart&amp;v=enabled&amp;s=1f0d6968de1ee9f418cea72b9e999851e167cf24", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;crop=smart&amp;v=enabled&amp;s=ec87124c2a5f0abb2b7b995cd13597da6bdd601c", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;crop=smart&amp;v=enabled&amp;s=c27d8811b555165c1c213a735f2ffc0e58392606", "width": 960, "height": 433}]}, "mp4": {"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?format=mp4&amp;v=enabled&amp;s=c1fd365d9810e1e5edcb75edcf8de553134d9b18", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;format=mp4&amp;v=enabled&amp;s=1af240bd8aba20032e6422f6d4c59d14708edd73", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;format=mp4&amp;v=enabled&amp;s=dd0fcc249c80b978169c6d3414db41b98266c790", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;format=mp4&amp;v=enabled&amp;s=f440228117e59e956befe2d2d556fcafc23eb50e", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;format=mp4&amp;v=enabled&amp;s=6d9a52f0e16e5974d2913b711f00602f4b546f68", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;format=mp4&amp;v=enabled&amp;s=09a3a175bf5df61be9a00e13c0eaad200c03ec75", "width": 960, "height": 433}]}}, "id": "A8a3PkdpOgSEpSIsb6pGmNSNoVF6viIYusCT-NSlR-8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108b680", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Round-4366", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108b680/new_feature_discover_and_extract_text_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/95o38brk68ba1.gif", "subreddit_subscribers": 835971, "created_utc": 1673360974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to know how it compares to working in a company. Are the projects harder or easier? What are the pros and cons? I know I can google this but I wanted to hear some real life experiences - looking to eventually do this but I\u2019m scared it\u2019ll be too hard until I\u2019m an expert! Thanks \ud83d\ude0a", "author_fullname": "t2_m1eyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Freelance data scientists: how did you get into it and what has your journey and experience been so far?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108az26", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673360422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to know how it compares to working in a company. Are the projects harder or easier? What are the pros and cons? I know I can google this but I wanted to hear some real life experiences - looking to eventually do this but I\u2019m scared it\u2019ll be too hard until I\u2019m an expert! Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108az26", "is_robot_indexable": true, "report_reasons": null, "author": "33spoonman", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108az26/freelance_data_scientists_how_did_you_get_into_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108az26/freelance_data_scientists_how_did_you_get_into_it/", "subreddit_subscribers": 835971, "created_utc": 1673360422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[OC] Analyzing Transfer Spend in the top 5 European Leagues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_108prop", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_4qcoujx1", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lLAYnVZXo7CU4b8tqZsTdY3gaGUoTqyDds5AM8_-gHs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_yubBruv", "selftext": "", "author_fullname": "t2_4qcoujx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "[OC] Analyzing Transfer Spend in the top 5 European Leagues", "link_flair_richtext": [], "subreddit_name_prefixed": "u/yubBruv", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u77flz083bba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/u77flz083bba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45db6afa578a2441731d40dbb37bbbcb90cc1031"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/u77flz083bba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=421111548acff2e78786774561e7da6a8514976d"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/u77flz083bba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9476a047cbb941edb38d96ed99105097f2428c64"}, {"y": 395, "x": 640, "u": "https://preview.redd.it/u77flz083bba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc5c682ef8406fe60f8fe8e7965cb2c5881ee4c2"}], "s": {"y": 395, "x": 640, "u": "https://preview.redd.it/u77flz083bba1.png?width=640&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e2834b43852af51c538310a1e3ddb4494f515179"}, "id": "u77flz083bba1"}, "5y6sodga3bba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=365e4ccd249e78be4426f3f3fd84ef2254b134c1"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=989f9ad7daf9877f641eff355d6cb06e635f430c"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44df377b39476535b9e428a6e3eafb698c9f0ff1"}, {"y": 395, "x": 640, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acc9c823802d3b6bfe0e29f2d10fcd0932ed806d"}, {"y": 593, "x": 960, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db60e66350359dd344f03aebcd66efa488736af8"}, {"y": 667, "x": 1080, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9da75ebe199f17ca1377d307a6ce11c0abb6a5e8"}], "s": {"y": 865, "x": 1400, "u": "https://preview.redd.it/5y6sodga3bba1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=74f919ffcccea5f8f984944f5b5c42dbce5ce4f1"}, "id": "5y6sodga3bba1"}, "h9biymt93bba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/h9biymt93bba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f220f627736aa5a15aa697d90fdafcec5fc4c851"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/h9biymt93bba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05c526ad765f456f9716e659be9c58f5976fc999"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/h9biymt93bba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08b28e6060e498d497596cbb8282a49bb2c82b43"}, {"y": 395, "x": 640, "u": "https://preview.redd.it/h9biymt93bba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faf77bd5409da943db42d8b5c53b51828a0f92a0"}, {"y": 593, "x": 960, "u": "https://preview.redd.it/h9biymt93bba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd3a0abe4d258bbac8a1e26dccd4ed3544ba29c1"}, {"y": 667, "x": 1080, "u": "https://preview.redd.it/h9biymt93bba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcefda934beaaa86ed389860a2f99f194ba0264a"}], "s": {"y": 865, "x": 1400, "u": "https://preview.redd.it/h9biymt93bba1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=81502fadc1b804d414e14849564d136748962122"}, "id": "h9biymt93bba1"}}, "name": "t3_108pqny", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "u77flz083bba1", "id": 228466450}, {"media_id": "h9biymt93bba1", "id": 228466451}, {"media_id": "5y6sodga3bba1", "id": 228466452}]}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lLAYnVZXo7CU4b8tqZsTdY3gaGUoTqyDds5AM8_-gHs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "user", "created": 1673395809.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "qa", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/108pqny", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2613p0", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108pqny", "is_robot_indexable": true, "report_reasons": null, "author": "yubBruv", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_yubBruv/comments/108pqny/oc_analyzing_transfer_spend_in_the_top_5_european/", "parent_whitelist_status": null, "stickied": false, "url": "https://www.reddit.com/gallery/108pqny", "subreddit_subscribers": 0, "created_utc": 1673395809.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1673395876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/108pqny", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108prop", "is_robot_indexable": true, "report_reasons": null, "author": "yubBruv", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_108pqny", "author_flair_text_color": null, "permalink": "/r/datascience/comments/108prop/oc_analyzing_transfer_spend_in_the_top_5_european/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/108pqny", "subreddit_subscribers": 835971, "created_utc": 1673395876.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hello,\n\nI am working on a data science task for my university. The goal is simple: Two datasets have the same \"meaning\", but the data record content is written differently. The task is to create a machine-learning model which predicts whether the data record is the same or not. My problem is: what is the best way to convert both data records so they can be used for an ml model (I am currently using sklearn.linear\\_model =&gt; LogisticRegression as a machine learning model). I already tried doc2vec, but my results were poor, and I am now trying to use TfidfVectorizer. But there, my problem is that my feature vectors have different lengths. Do you have any tips on how to solve this?", "author_fullname": "t2_t0eztqp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for help in a data science task.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108nbhd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673390147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am working on a data science task for my university. The goal is simple: Two datasets have the same &amp;quot;meaning&amp;quot;, but the data record content is written differently. The task is to create a machine-learning model which predicts whether the data record is the same or not. My problem is: what is the best way to convert both data records so they can be used for an ml model (I am currently using sklearn.linear_model =&amp;gt; LogisticRegression as a machine learning model). I already tried doc2vec, but my results were poor, and I am now trying to use TfidfVectorizer. But there, my problem is that my feature vectors have different lengths. Do you have any tips on how to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108nbhd", "is_robot_indexable": true, "report_reasons": null, "author": "lollo4ever", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108nbhd/looking_for_help_in_a_data_science_task/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108nbhd/looking_for_help_in_a_data_science_task/", "subreddit_subscribers": 835971, "created_utc": 1673390147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In this moment, I am close to losing my job as an investigator at a university where I have been working with machine learning models for almost 2 years. Because of this, I am thinking of starting as a freelancer as a data analyst and then as a data scientist. However, I am aware that the business environment is very different from the academic environment. So, I want to ask, what should I know (or study) before starting so that this transition is not so difficult and I can perform better as a professional?\n\nCurrently, I am working on a portfolio using Kaggle's competitions and reading \"Storytelling with Data\" by Cole Nussbaumer Knaflic.\n\nI am very grateful for any input that can help me in what seems to be a new phase.", "author_fullname": "t2_t9v1d21r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know when I am ready to start freelancing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108ivkf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673379856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this moment, I am close to losing my job as an investigator at a university where I have been working with machine learning models for almost 2 years. Because of this, I am thinking of starting as a freelancer as a data analyst and then as a data scientist. However, I am aware that the business environment is very different from the academic environment. So, I want to ask, what should I know (or study) before starting so that this transition is not so difficult and I can perform better as a professional?&lt;/p&gt;\n\n&lt;p&gt;Currently, I am working on a portfolio using Kaggle&amp;#39;s competitions and reading &amp;quot;Storytelling with Data&amp;quot; by Cole Nussbaumer Knaflic.&lt;/p&gt;\n\n&lt;p&gt;I am very grateful for any input that can help me in what seems to be a new phase.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108ivkf", "is_robot_indexable": true, "report_reasons": null, "author": "axdertui", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108ivkf/how_do_i_know_when_i_am_ready_to_start_freelancing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108ivkf/how_do_i_know_when_i_am_ready_to_start_freelancing/", "subreddit_subscribers": 835971, "created_utc": 1673379856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jqb5kt26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Here's an Infographic that shows what makes data \"F.A.I.R\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_108dzqn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CpewAucT2Z25fSbK_aB1FD38u0HCjfCFstkTciTUTHo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673368124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/h1sdzl8zs8ba1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/h1sdzl8zs8ba1.png?auto=webp&amp;v=enabled&amp;s=462cdde57e7fecbd75740b94d1a7fa27411bc001", "width": 800, "height": 2000}, "resolutions": [{"url": "https://preview.redd.it/h1sdzl8zs8ba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c18b0dff28138eb907ef377a5293ff8fbb59aff4", "width": 108, "height": 216}, {"url": "https://preview.redd.it/h1sdzl8zs8ba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c78cc445262e369c3f71011b253d7b90f2188f50", "width": 216, "height": 432}, {"url": "https://preview.redd.it/h1sdzl8zs8ba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5994c28f206b35a3e119d468aacf95ac30c48bc", "width": 320, "height": 640}, {"url": "https://preview.redd.it/h1sdzl8zs8ba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a333dde1dcce67cb2c0e1beebf413c353f101c9", "width": 640, "height": 1280}], "variants": {}, "id": "rX0h6FG_PWxu03ssxZPYBOu1NzyB6baVoNlC1I0Noow"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108dzqn", "is_robot_indexable": true, "report_reasons": null, "author": "SnthesisInc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108dzqn/heres_an_infographic_that_shows_what_makes_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/h1sdzl8zs8ba1.png", "subreddit_subscribers": 835971, "created_utc": 1673368124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Simple 5-Step Process for Creating a Winning Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1089c1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7ZNRKnEPC4nWYg_9U8OS__J9yI4iWy1P1yPaLEU4rMI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673355841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/the-simple-5-step-process-for-creating-a-winning-data-pipeline", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UfSt8PiC0a6sLBoi0tZAs3HZahkF9DWaL8FOf9VoA-c.jpg?auto=webp&amp;v=enabled&amp;s=3070d4a4b0ae0909441f1027a1ba994dd9284b70", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/UfSt8PiC0a6sLBoi0tZAs3HZahkF9DWaL8FOf9VoA-c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e1d34f89cf07bc40e74fb597a4ebac716e2ba58", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/UfSt8PiC0a6sLBoi0tZAs3HZahkF9DWaL8FOf9VoA-c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0006ff4fe3cac97fdccb28e19da28b47142dafb4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/UfSt8PiC0a6sLBoi0tZAs3HZahkF9DWaL8FOf9VoA-c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0885ef488dd0688d256b0261c4020871be5a71a0", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/UfSt8PiC0a6sLBoi0tZAs3HZahkF9DWaL8FOf9VoA-c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e662b2c70c6bb73966ddd4d07e19d33c44d6aba3", "width": 640, "height": 336}], "variants": {}, "id": "4kZyY6Ay9_IQsKpdw4mPVgXxrQGPFjJ6dcbfxfGXsWE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1089c1o", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1089c1o/the_simple_5step_process_for_creating_a_winning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/the-simple-5-step-process-for-creating-a-winning-data-pipeline", "subreddit_subscribers": 835971, "created_utc": 1673355841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI created a data analytics portfolio consisting of SQL projects on Github. I had my friend review it who works as a data analyst, and he liked these projects.\n\nHowever, he pointed out that my SQL projects consist of files that have bunch of queries in them. But their outputs are not visible in these files, since there would be at times too many rows visible.\n\nNow, is there a simple way to display query outputs for these projects on my portfolio in Github. I am currently thinking of creating xlsx files for each project showcasing the query outputs. \n\nThanks in advance for your help!", "author_fullname": "t2_cw8f2loo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Displaying SQL query outputs on portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1085w9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673343955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I created a data analytics portfolio consisting of SQL projects on Github. I had my friend review it who works as a data analyst, and he liked these projects.&lt;/p&gt;\n\n&lt;p&gt;However, he pointed out that my SQL projects consist of files that have bunch of queries in them. But their outputs are not visible in these files, since there would be at times too many rows visible.&lt;/p&gt;\n\n&lt;p&gt;Now, is there a simple way to display query outputs for these projects on my portfolio in Github. I am currently thinking of creating xlsx files for each project showcasing the query outputs. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1085w9o", "is_robot_indexable": true, "report_reasons": null, "author": "Present-Ground-9925", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1085w9o/displaying_sql_query_outputs_on_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1085w9o/displaying_sql_query_outputs_on_portfolio/", "subreddit_subscribers": 835971, "created_utc": 1673343955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Curious to hear your thoughts and experiences, I know every company is different.", "author_fullname": "t2_sfnxkfax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did you all find that you needed to have a PhD in order to be a good data scientist and land the positions you wanted at certain companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108na3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673390062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to hear your thoughts and experiences, I know every company is different.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108na3e", "is_robot_indexable": true, "report_reasons": null, "author": "Agile_Committee3405", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108na3e/did_you_all_find_that_you_needed_to_have_a_phd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108na3e/did_you_all_find_that_you_needed_to_have_a_phd_in/", "subreddit_subscribers": 835971, "created_utc": 1673390062.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}