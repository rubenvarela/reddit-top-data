{"kind": "Listing", "data": {"after": "t3_108az26", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My career started as an academic doing my PhD in cancer immunology research and extended through jobs at Harvard Medical School (Postdoc), Uber, Facebook, McKinsey &amp; Company.. and finally back to doing cancer research again.\n\nOver the years I've found that \"Data Scientist\" is a heterogenous term that primarily centres around anyone who can derive insight from data. And I've worked with both the traditional data scientist  CS/Stats background types all the way through to data scientists with bachelors in Art History. The bottom line is that each bring their own unique and very invaluable thinking styles to the field.\n\nThe art historian turned data scientist once proposed an extremely interesting way of organising plots way before sns.pairplot() was a thing, our client LOVED it. Another data scientist who had a background in sociology was able to pull some awesome insights around credit default rates given the average number of letterboxes in a neighbourhood.\n\nThe point is, some of the best DS people I've worked with came from eclectic backgrounds and it's usually those ones that I learn from the most. So if you're thinking about becoming a data scientist, don't be dissuaded by the coding aspect (which can be learned in months). The thinking style you've cultivated takes YEARS to develop.\n\n&amp;#x200B;\n\nEDIT: a bunch of people have been asking about DS entry programmes. Don't pay for tech skills you can learn for free on youtube. For example I teach DS on my channel - the fundamentals - totally free forever.\n\n[https://www.youtube.com/watch?v=ckw8D34c03U](https://www.youtube.com/watch?v=ckw8D34c03U) \\- Week 1\n\n[https://www.youtube.com/watch?v=1LCN\\_14OCc8&amp;t=2s](https://www.youtube.com/watch?v=1LCN_14OCc8&amp;t=2s) \\- Week 2\n\nIf guys need any help breaking into the industry shoot me a DM and I'll see if there's anyone I know that can refer you. \n\n&amp;#x200B;", "author_fullname": "t2_7h1mi6us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After having spent 10 years in Data Science - literally ANYONE could (and should) become a data scientist.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108boxq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 202, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 202, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673368674.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673362343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My career started as an academic doing my PhD in cancer immunology research and extended through jobs at Harvard Medical School (Postdoc), Uber, Facebook, McKinsey &amp;amp; Company.. and finally back to doing cancer research again.&lt;/p&gt;\n\n&lt;p&gt;Over the years I&amp;#39;ve found that &amp;quot;Data Scientist&amp;quot; is a heterogenous term that primarily centres around anyone who can derive insight from data. And I&amp;#39;ve worked with both the traditional data scientist  CS/Stats background types all the way through to data scientists with bachelors in Art History. The bottom line is that each bring their own unique and very invaluable thinking styles to the field.&lt;/p&gt;\n\n&lt;p&gt;The art historian turned data scientist once proposed an extremely interesting way of organising plots way before sns.pairplot() was a thing, our client LOVED it. Another data scientist who had a background in sociology was able to pull some awesome insights around credit default rates given the average number of letterboxes in a neighbourhood.&lt;/p&gt;\n\n&lt;p&gt;The point is, some of the best DS people I&amp;#39;ve worked with came from eclectic backgrounds and it&amp;#39;s usually those ones that I learn from the most. So if you&amp;#39;re thinking about becoming a data scientist, don&amp;#39;t be dissuaded by the coding aspect (which can be learned in months). The thinking style you&amp;#39;ve cultivated takes YEARS to develop.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: a bunch of people have been asking about DS entry programmes. Don&amp;#39;t pay for tech skills you can learn for free on youtube. For example I teach DS on my channel - the fundamentals - totally free forever.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=ckw8D34c03U\"&gt;https://www.youtube.com/watch?v=ckw8D34c03U&lt;/a&gt; - Week 1&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=1LCN_14OCc8&amp;amp;t=2s\"&gt;https://www.youtube.com/watch?v=1LCN_14OCc8&amp;amp;t=2s&lt;/a&gt; - Week 2&lt;/p&gt;\n\n&lt;p&gt;If guys need any help breaking into the industry shoot me a DM and I&amp;#39;ll see if there&amp;#39;s anyone I know that can refer you. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?auto=webp&amp;s=519255e1af8c1a7303ac25373302278192d66dd3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd433f14c2a2ab23165330427718f37a5a0efc91", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7db2101ea9d195f8250a06805687a2ec7cc5de54", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/PEw0x9ivAlrn1JwgL7hoIgqp2hOZVQFgBCZyBy0iJOg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b3355e532487bcce4d7b84d3bc683390b5595a4", "width": 320, "height": 240}], "variants": {}, "id": "kbV3ao1DWT7nSe-FDzynjLiV3nCKwCf-0CO6khmjc_8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108boxq", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPaintings5866", "discussion_type": null, "num_comments": 151, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108boxq/after_having_spent_10_years_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108boxq/after_having_spent_10_years_in_data_science/", "subreddit_subscribers": 835978, "created_utc": 1673362343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pzr91bdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nerf Technology with Stable Diffusion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_108fq2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/jajny30c59ba1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 960, "scrubber_media_url": "https://v.redd.it/jajny30c59ba1/DASH_96.mp4", "dash_url": "https://v.redd.it/jajny30c59ba1/DASHPlaylist.mpd?a=1676025784%2COTUzYzQ0ZDZjMGIxZWEwMWYyM2MyOTljZGJmOGVmZTY0Yjk3NjM3ODk5ZDE2ZGJkMDFkMmM0MzBmNjBlNTA5OA%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/jajny30c59ba1/HLSPlaylist.m3u8?a=1676025784%2COGFiNWVlMWI0M2Y3NzIzYjFjN2FkNWQ2MWNjMmNmYjBkOWEwNTBhY2QwZGRhMzU1YzkxNzExYTMxNzE2N2U0OQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZehTDjLOeUbXNkoKXlKZV2HRFfBu3y0PEkCnRkFoMrE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673372277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/jajny30c59ba1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?format=pjpg&amp;auto=webp&amp;s=fa5da8fc3136e3bb52686ecf59315b3a14ac1090", "width": 1920, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9fe7553d55561721938834c95addb1235f5a7a71", "width": 108, "height": 121}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4233ea4f106e403921b2ff9d5485f24739b7e515", "width": 216, "height": 243}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c84310b107ff39f547847581f5705990c5a5d469", "width": 320, "height": 360}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=01b3721b0ced2dfd9194f84fab46dad1b502ecca", "width": 640, "height": 720}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0001006c5427042e6457e20f722f06020c87a5cc", "width": 960, "height": 1080}, {"url": "https://external-preview.redd.it/ytVm1OkhCmLXGBCdfZp-Pa-r_ika-z9bUmu9II3KCn0.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e114781a5adaaba2aa4aec5f87738692d5c55279", "width": 1080, "height": 1215}], "variants": {}, "id": "gAhTBMwZ_Y_NLNG99bK_fsoASmG9gTWMFL8RBqyAMwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108fq2y", "is_robot_indexable": true, "report_reasons": null, "author": "oridnary_artist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108fq2y/nerf_technology_with_stable_diffusion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/jajny30c59ba1", "subreddit_subscribers": 835978, "created_utc": 1673372277.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/jajny30c59ba1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 960, "scrubber_media_url": "https://v.redd.it/jajny30c59ba1/DASH_96.mp4", "dash_url": "https://v.redd.it/jajny30c59ba1/DASHPlaylist.mpd?a=1676025784%2COTUzYzQ0ZDZjMGIxZWEwMWYyM2MyOTljZGJmOGVmZTY0Yjk3NjM3ODk5ZDE2ZGJkMDFkMmM0MzBmNjBlNTA5OA%3D%3D&amp;v=1&amp;f=sd", "duration": 12, "hls_url": "https://v.redd.it/jajny30c59ba1/HLSPlaylist.m3u8?a=1676025784%2COGFiNWVlMWI0M2Y3NzIzYjFjN2FkNWQ2MWNjMmNmYjBkOWEwNTBhY2QwZGRhMzU1YzkxNzExYTMxNzE2N2U0OQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": true, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My employer has been on and off about his growth plans so I started to look to upgrade my job and have been applying to different jobs for several weeks now.\n\nI just use a basic excel spreadsheet and 95% precut cover letter and I am at 151 jobs applied to since Thanksgiving and I got two callbacks this week. Marketing Analytics and Data Science Analyst position both sent me links to www.codility.com\n\nThe first is likely 100% remote and recruiter has been very prompt and forwarded me to a tech screen. I just got off the phone with the \u201cit\u2019s pretty standard but you should have no problem if you know what you\u2019re doing\u201d\n\n\u2026famous last words.\n\nThese recruiters each need me to do a two hour \u201ccodility\u201d test, which I\u2019ve never heard of but who has tips about the format or what to expect?\n\nObviously I\u2019m not asking for any answers or links to data dumps, I just have never heard of and don\u2019t know what to expect for www.codility.com. Any reccomendations that I can prepare or brush up on my SQL code or maybe they\u2019re more situational questions I don\u2019t know?\n\nI\u2019ve signed up for the developer account and waiting for their verification email to start to practice but advice is welcome.", "author_fullname": "t2_a1wq8rgz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recruiter for a big reputable firm I\u2019d love to work for sent me an \u201ctech assessment\u201d (I think) via codility, who has used these?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108nvnx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673391414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My employer has been on and off about his growth plans so I started to look to upgrade my job and have been applying to different jobs for several weeks now.&lt;/p&gt;\n\n&lt;p&gt;I just use a basic excel spreadsheet and 95% precut cover letter and I am at 151 jobs applied to since Thanksgiving and I got two callbacks this week. Marketing Analytics and Data Science Analyst position both sent me links to &lt;a href=\"http://www.codility.com\"&gt;www.codility.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The first is likely 100% remote and recruiter has been very prompt and forwarded me to a tech screen. I just got off the phone with the \u201cit\u2019s pretty standard but you should have no problem if you know what you\u2019re doing\u201d&lt;/p&gt;\n\n&lt;p&gt;\u2026famous last words.&lt;/p&gt;\n\n&lt;p&gt;These recruiters each need me to do a two hour \u201ccodility\u201d test, which I\u2019ve never heard of but who has tips about the format or what to expect?&lt;/p&gt;\n\n&lt;p&gt;Obviously I\u2019m not asking for any answers or links to data dumps, I just have never heard of and don\u2019t know what to expect for &lt;a href=\"http://www.codility.com\"&gt;www.codility.com&lt;/a&gt;. Any reccomendations that I can prepare or brush up on my SQL code or maybe they\u2019re more situational questions I don\u2019t know?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve signed up for the developer account and waiting for their verification email to start to practice but advice is welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?auto=webp&amp;s=2199d403c4073a9afb3aebcff9ae845aa65e2190", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=29dc1f8eb5a8ed431793de3534b108df5d23ea36", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=860ab95e9874d511a06f1bcf0b297d08cd653a93", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=76ca95c47d4e38085397d67590545d3c6891a13e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ed572791e1e190a4b2f8786e230dd79c1f4282e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4fbd5f212bc3c1d3ff5b72d0146dc1c345a14837", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/WknbVrNgr4t9sENS8LwDtM5wFTDUemdpSxPWUMjqWBU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56438c82173ee2bb715a118abbc11a7d73724c59", "width": 1080, "height": 567}], "variants": {}, "id": "d8eWOwyigfUJobzo9He56f9jD0Gj1VyVpcob5LcVzBg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "108nvnx", "is_robot_indexable": true, "report_reasons": null, "author": "FourTerrabytesLost", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108nvnx/recruiter_for_a_big_reputable_firm_id_love_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108nvnx/recruiter_for_a_big_reputable_firm_id_love_to/", "subreddit_subscribers": 835978, "created_utc": 1673391414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vi17yd7i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Review? Looking for Data Analytics/Science and Business Intelligence internships. Bay area based!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_108wmc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b8ozaEFRJIiwEgHg4xhVpc4Sghfe2sHDECC-nCPtr38.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673414934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/713eo9cr5eba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?auto=webp&amp;s=634c5339131a2f890709f2b071c39340aaa0efbe", "width": 2550, "height": 3300}, "resolutions": [{"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01fbf65cc2cd6da18996a50110523974a60429bf", "width": 108, "height": 139}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2094c8e6ad75996063ca1418737c96bbd5495fdc", "width": 216, "height": 279}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c155223f9c31ddbc2769e8b40314f80eb27fe377", "width": 320, "height": 414}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5c8c214d74bbb8af4331def1216ded99745148d2", "width": 640, "height": 828}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e7a9afa70f4fec70ddf68486f3daf3a4aaf53ad", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/713eo9cr5eba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b3bb2b4a9cffd606b052bfbf5060386d4d119a2", "width": 1080, "height": 1397}], "variants": {}, "id": "xG2bpFPC4VqOAvG42JzmKXfATcoOqNwXGBpon2vuYUM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "108wmc9", "is_robot_indexable": true, "report_reasons": null, "author": "i-am-nobody156", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108wmc9/resume_review_looking_for_data_analyticsscience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/713eo9cr5eba1.jpg", "subreddit_subscribers": 835978, "created_utc": 1673414934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started using the statsmodels python package and I'm having trouble figuring out how we should fit and evaluate a time series model.\n\nMy way of thinking was: you split data into train and test, you train a model with the train data (say ARIMA for example) and you evaluate it on the test set, but I've seen people do different things.\n\nI saw a lot of people feed the ARIMA model the whole dataset, fit it and then evaluate on the last couple of data points. This would be training and evaluating on the same dataset and I'm sure that is wrong.\n\nI've also seen people train the model with the train data and then forecast X time steps into the future and compare those results with the test set (RMSE, R\\^2, etc...), but this has the disadvantage that the forecasted values will tend towards the mean, so it's not really a good way to evaluate the model, right?\n\nWhy isn't there a more straight forward way to do this with statsmodels? At least from what I've seen you can't feed an already trained model test data to evaluate it, right?\n\nI thought it should be done like it is done in this [notebook](https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary) but I never seem him give the model the test data, so how can it work?", "author_fullname": "t2_h916gqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to evaluate ARIMA model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108jzf1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673382440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started using the statsmodels python package and I&amp;#39;m having trouble figuring out how we should fit and evaluate a time series model.&lt;/p&gt;\n\n&lt;p&gt;My way of thinking was: you split data into train and test, you train a model with the train data (say ARIMA for example) and you evaluate it on the test set, but I&amp;#39;ve seen people do different things.&lt;/p&gt;\n\n&lt;p&gt;I saw a lot of people feed the ARIMA model the whole dataset, fit it and then evaluate on the last couple of data points. This would be training and evaluating on the same dataset and I&amp;#39;m sure that is wrong.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen people train the model with the train data and then forecast X time steps into the future and compare those results with the test set (RMSE, R^2, etc...), but this has the disadvantage that the forecasted values will tend towards the mean, so it&amp;#39;s not really a good way to evaluate the model, right?&lt;/p&gt;\n\n&lt;p&gt;Why isn&amp;#39;t there a more straight forward way to do this with statsmodels? At least from what I&amp;#39;ve seen you can&amp;#39;t feed an already trained model test data to evaluate it, right?&lt;/p&gt;\n\n&lt;p&gt;I thought it should be done like it is done in this &lt;a href=\"https://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary\"&gt;notebook&lt;/a&gt; but I never seem him give the model the test data, so how can it work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?auto=webp&amp;s=e25be8cb5cf2448d39a7e5ffc877e4d466b776d3", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9645cb9b1f6437724f04c3b63b841cf7766f27d6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/GK4J2jdDCd68cmAzq4b5v8wOyVmJzcMn471wSxWrwMY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc7ee570d3611e1ef9314d658423c42908808820", "width": 216, "height": 216}], "variants": {}, "id": "63C1GbYQbI4tHZMkw99e-qlyoYaGnG58yfnmnFUJ34s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108jzf1", "is_robot_indexable": true, "report_reasons": null, "author": "AdministrativeRub484", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108jzf1/how_to_evaluate_arima_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108jzf1/how_to_evaluate_arima_model/", "subreddit_subscribers": 835978, "created_utc": 1673382440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nOur retail customers sell products through our platform, they are free to enter the product name as they see fit, this causes a problem as we would have different strings referring to the same product.\n\n&amp;#x200B;\n\n|product entered by user|actual product in reference table|\n|:-|:-|\n|tothbrush red 100|toothbrush red 100|\n|toothb r 100|toothbrush red 100|\n|X shampooooo! 100ml|X shampoo 100ml|\n\nI would like to build a model that given a text entered by the user it will find it's closest match from a reference list containing all the product names. However, I have three major concerns:\n\n1. Thousands of products are sold each day, comparing thousands of products with the reference list that is approximately 10,000 (and keeps growing) would yield tens of millions of iterations. How would I tackle this computational complexity.\n2. I am thinking of using sentence transformers, where the incoming product embedding is compared to the embeddings of the products the reference list, returning the one with the max similarity, or using a siamese network where each pair of products is fed to the network and return the first match found.\n3. The goal of this exercise is to diminish the manual work involved in linking the products, but how do I define a similarity threshold, such that if the similarity is not sufficient, it has to be reviewed manually by humans.\n\nNote: I can utilize an additional feature such as the price of the product to reduce the number of products am iterating over as well.\n\nyour thoughts veterans would be highly appreciated.", "author_fullname": "t2_8jmib0lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Discussion] NLP for products matching", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108a5sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673358243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Our retail customers sell products through our platform, they are free to enter the product name as they see fit, this causes a problem as we would have different strings referring to the same product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;product entered by user&lt;/th&gt;\n&lt;th align=\"left\"&gt;actual product in reference table&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;tothbrush red 100&lt;/td&gt;\n&lt;td align=\"left\"&gt;toothbrush red 100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;toothb r 100&lt;/td&gt;\n&lt;td align=\"left\"&gt;toothbrush red 100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;X shampooooo! 100ml&lt;/td&gt;\n&lt;td align=\"left\"&gt;X shampoo 100ml&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I would like to build a model that given a text entered by the user it will find it&amp;#39;s closest match from a reference list containing all the product names. However, I have three major concerns:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Thousands of products are sold each day, comparing thousands of products with the reference list that is approximately 10,000 (and keeps growing) would yield tens of millions of iterations. How would I tackle this computational complexity.&lt;/li&gt;\n&lt;li&gt;I am thinking of using sentence transformers, where the incoming product embedding is compared to the embeddings of the products the reference list, returning the one with the max similarity, or using a siamese network where each pair of products is fed to the network and return the first match found.&lt;/li&gt;\n&lt;li&gt;The goal of this exercise is to diminish the manual work involved in linking the products, but how do I define a similarity threshold, such that if the similarity is not sufficient, it has to be reviewed manually by humans.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Note: I can utilize an additional feature such as the price of the product to reduce the number of products am iterating over as well.&lt;/p&gt;\n\n&lt;p&gt;your thoughts veterans would be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108a5sj", "is_robot_indexable": true, "report_reasons": null, "author": "Riolite55", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108a5sj/discussion_nlp_for_products_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108a5sj/discussion_nlp_for_products_matching/", "subreddit_subscribers": 835978, "created_utc": 1673358243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am so far only familar with basic CNN architecture (peeps an image, makes a classification). However, if an image has 2 objects (for example, my problem has two letters in a grid and i must identify them), I believe that basic CNN and softmax activation would fail. Is there a relatively simple way to build this type of model?", "author_fullname": "t2_66zyb9or", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CNN with multiple letters in an image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108rwi0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673401433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am so far only familar with basic CNN architecture (peeps an image, makes a classification). However, if an image has 2 objects (for example, my problem has two letters in a grid and i must identify them), I believe that basic CNN and softmax activation would fail. Is there a relatively simple way to build this type of model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108rwi0", "is_robot_indexable": true, "report_reasons": null, "author": "DChoiBobaboi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108rwi0/cnn_with_multiple_letters_in_an_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108rwi0/cnn_with_multiple_letters_in_an_image/", "subreddit_subscribers": 835978, "created_utc": 1673401433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am trying to fit a model using EconML to get treatment effects and optimal pricing strategies for different products in my dataset. I am trying to fit the model at a county level (to get more observations), but the treatment effects need to be at a state level. Is it possible to extract treatment effects at a state level even though the model is fit at a county level?", "author_fullname": "t2_9ynwnzxs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you get treatment effects at higher level of granularity than the level of granularity the model was built for using the EconML package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108f61z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673370947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am trying to fit a model using EconML to get treatment effects and optimal pricing strategies for different products in my dataset. I am trying to fit the model at a county level (to get more observations), but the treatment effects need to be at a state level. Is it possible to extract treatment effects at a state level even though the model is fit at a county level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108f61z", "is_robot_indexable": true, "report_reasons": null, "author": "Ordinary_Zombie_2345", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108f61z/can_you_get_treatment_effects_at_higher_level_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108f61z/can_you_get_treatment_effects_at_higher_level_of/", "subreddit_subscribers": 835978, "created_utc": 1673370947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_t5hi6lze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10913h1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/PFwiotg_lxHOmu5VnaKyyKcP7_JV9lhRKZG4flGr4wk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673431234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/96xkzprn0eba1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/96xkzprn0eba1.jpg?auto=webp&amp;s=06eda4fe8b4a630fb87ff4a97dff31018046af5a", "width": 800, "height": 2000}, "resolutions": [{"url": "https://preview.redd.it/96xkzprn0eba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a958a9ded7d9844ef03fdb530efd00c48ff3d7d", "width": 108, "height": 216}, {"url": "https://preview.redd.it/96xkzprn0eba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd241032db47c2d48f9a496eac0745716ae785ef", "width": 216, "height": 432}, {"url": "https://preview.redd.it/96xkzprn0eba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c256bf9cf3c0fbe014a4ddec1fabb8b9db1b1a55", "width": 320, "height": 640}, {"url": "https://preview.redd.it/96xkzprn0eba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8eca1c3fdccd009faeca129fdd5375eda3bc8e72", "width": 640, "height": 1280}], "variants": {}, "id": "3pleYUqaHSsSr5-DS545DRmiVGrxB5z-1UShxNcSBI8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10913h1", "is_robot_indexable": true, "report_reasons": null, "author": "praveen-skillslash", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10913h1/python_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/96xkzprn0eba1.jpg", "subreddit_subscribers": 835978, "created_utc": 1673431234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_t5hi6lze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist skillset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10912wp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MSLGfyhQIMJFR9INpB_KRQ50nsNklIPa28IYSTxJGsY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673431200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8fq4qvjj0eba1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8fq4qvjj0eba1.jpg?auto=webp&amp;s=6043622769925fa2c129c842fb538f22e017f459", "width": 800, "height": 2000}, "resolutions": [{"url": "https://preview.redd.it/8fq4qvjj0eba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3ec5f2c2fc939d8eacc63ea25a20f3486c3c291d", "width": 108, "height": 216}, {"url": "https://preview.redd.it/8fq4qvjj0eba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=28942eb2a346c890e33795144a79a32f4ada7bad", "width": 216, "height": 432}, {"url": "https://preview.redd.it/8fq4qvjj0eba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b29b8d60c841b8f0a18869acdfdb131c78d16976", "width": 320, "height": 640}, {"url": "https://preview.redd.it/8fq4qvjj0eba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=422b11e9970cbebaaf92a6187cddf56b20996c6b", "width": 640, "height": 1280}], "variants": {}, "id": "uzWmEF-istoNWARynhvHyQbdvI3OAW-vXF5_6Ui9HvQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10912wp", "is_robot_indexable": true, "report_reasons": null, "author": "praveen-skillslash", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10912wp/data_scientist_skillset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8fq4qvjj0eba1.jpg", "subreddit_subscribers": 835978, "created_utc": 1673431200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \n\nI'm currently looking for a good way to share data analytical reports to clients. But would want these dashboards to be interactive and hosted by us. So more like a micro service. \n\nAre there any good platforms for this specific use case? \n\nThanks for a great community!", "author_fullname": "t2_884psjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best platform to build dashboards for clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1090tf7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673430122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking for a good way to share data analytical reports to clients. But would want these dashboards to be interactive and hosted by us. So more like a micro service. &lt;/p&gt;\n\n&lt;p&gt;Are there any good platforms for this specific use case? &lt;/p&gt;\n\n&lt;p&gt;Thanks for a great community!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1090tf7", "is_robot_indexable": true, "report_reasons": null, "author": "jakekubb", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090tf7/best_platform_to_build_dashboards_for_clients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090tf7/best_platform_to_build_dashboards_for_clients/", "subreddit_subscribers": 835978, "created_utc": 1673430122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I test next week to get my CompTIA Data+ certification. I don\u2019t have a background in data science or data analytics but I\u2019m in college for data science. I\u2019m also learning as much as I can through datacamp. For those of you who are seasoned do you find CompTIA Data+ and other certs valuable?", "author_fullname": "t2_sy7sjvbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CompTIA Data+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108n0ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673389462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I test next week to get my CompTIA Data+ certification. I don\u2019t have a background in data science or data analytics but I\u2019m in college for data science. I\u2019m also learning as much as I can through datacamp. For those of you who are seasoned do you find CompTIA Data+ and other certs valuable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108n0ho", "is_robot_indexable": true, "report_reasons": null, "author": "M3TAV3RSE", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108n0ho/comptia_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108n0ho/comptia_data/", "subreddit_subscribers": 835978, "created_utc": 1673389462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "tl;dr \u2013 Trying to choose a masters\u2019 program to do research in data science, in a biomedical/clinical context. Options are health informatics, biostatistics, and computer science.\n\n&amp;#x200B;\n\nHey everyone! I graduated from my bachelor\u2019s in Biomedical Sciences this past spring, and have been exploring career options since then, including working at a clinical job, a research job, and self-learning programming/advanced math. \n\nI\u2019ve come to realize I enjoy specific aspects from each experience:\n\n* Data visualization: I enjoy analyzing and communicating research visually, pulling from background courses in biostatistics and graphic design. \n* Research methodology: I noticed that the subject matter didn\u2019t matter (ranging from cell biology to public health), but rather I take interest in how research is structured and designed, and how other computational methods could be applied (e.g. drawing from my science background to see how predictive machine learning can be used in biomedical imaging, epidemiology, etc.)\n* Clinical component: I\u2019d still like to have a clinical/healthcare approach to things, e.g. not closing doors on the (pipedream of an) idea of being a clinician-scientist of sorts\n\n&amp;#x200B;\n\nThat being said, an ideal career of mine would consist of collaborating with various physicians and research groups. This includes working on designing research projects, applying statistical and computational methods for data analysis, and ultimately visually illustrating and communicating the results of the research (e.g. for the public and/or to other researchers).\n\nDoes such a career exist? I\u2019m looking into Masters\u2019 programs to explore the subject matter further, but it seems to be an intersect between computer science, biostatistics, and health informatics. What seems most appropriate from my experience/interests, alongside finding a job afterward?\n\n&amp;#x200B;\n\nSome side thoughts/notes:\n\n* Health informatics was the first thing I came across. Programs I\u2019m looking at are 2 years with internships included. However, they seem more focused solely on management and policy of electronic health records (versus software development or data science), and I\u2019m not too sure how this would translate out to other data science industries in the case I\u2019m needing to pivot fields? Plus, a fair amount of the job descriptions also consider candidates in statistics and CS, but not the other way around\n* Biostatistics programs are 1-2 years long and some also have internships. They focus more on statistical theory alongside other public health concepts. However, I\u2019ve also read that pure statistics might be more theory than I actually need, versus the software skills which data science employers look for?\n* Computer science programs are 2 years long, but I\u2019d be finding internships on my own. Computer science is the least familiar of the fields to me, so I don't know how relevant the skills are in this program to my interests.", "author_fullname": "t2_81epo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Computer Science, Biostatistics, Health Informatics \u2013 best for biomedical data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108lp08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673386422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;tl;dr \u2013 Trying to choose a masters\u2019 program to do research in data science, in a biomedical/clinical context. Options are health informatics, biostatistics, and computer science.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone! I graduated from my bachelor\u2019s in Biomedical Sciences this past spring, and have been exploring career options since then, including working at a clinical job, a research job, and self-learning programming/advanced math. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve come to realize I enjoy specific aspects from each experience:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data visualization: I enjoy analyzing and communicating research visually, pulling from background courses in biostatistics and graphic design. &lt;/li&gt;\n&lt;li&gt;Research methodology: I noticed that the subject matter didn\u2019t matter (ranging from cell biology to public health), but rather I take interest in how research is structured and designed, and how other computational methods could be applied (e.g. drawing from my science background to see how predictive machine learning can be used in biomedical imaging, epidemiology, etc.)&lt;/li&gt;\n&lt;li&gt;Clinical component: I\u2019d still like to have a clinical/healthcare approach to things, e.g. not closing doors on the (pipedream of an) idea of being a clinician-scientist of sorts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;That being said, an ideal career of mine would consist of collaborating with various physicians and research groups. This includes working on designing research projects, applying statistical and computational methods for data analysis, and ultimately visually illustrating and communicating the results of the research (e.g. for the public and/or to other researchers).&lt;/p&gt;\n\n&lt;p&gt;Does such a career exist? I\u2019m looking into Masters\u2019 programs to explore the subject matter further, but it seems to be an intersect between computer science, biostatistics, and health informatics. What seems most appropriate from my experience/interests, alongside finding a job afterward?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Some side thoughts/notes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Health informatics was the first thing I came across. Programs I\u2019m looking at are 2 years with internships included. However, they seem more focused solely on management and policy of electronic health records (versus software development or data science), and I\u2019m not too sure how this would translate out to other data science industries in the case I\u2019m needing to pivot fields? Plus, a fair amount of the job descriptions also consider candidates in statistics and CS, but not the other way around&lt;/li&gt;\n&lt;li&gt;Biostatistics programs are 1-2 years long and some also have internships. They focus more on statistical theory alongside other public health concepts. However, I\u2019ve also read that pure statistics might be more theory than I actually need, versus the software skills which data science employers look for?&lt;/li&gt;\n&lt;li&gt;Computer science programs are 2 years long, but I\u2019d be finding internships on my own. Computer science is the least familiar of the fields to me, so I don&amp;#39;t know how relevant the skills are in this program to my interests.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108lp08", "is_robot_indexable": true, "report_reasons": null, "author": "itsmarq", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108lp08/computer_science_biostatistics_health_informatics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108lp08/computer_science_biostatistics_health_informatics/", "subreddit_subscribers": 835978, "created_utc": 1673386422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If i were to produce 2 models (e.g. logistic regression and xgboost) and would like to generate a confidence interval and p value to compare the auc of roc curve of both models, how should i go about doing it? \n\nA scientific article that i read mentioned that they've done it using a paired t-test.\nFor reference, this is the article im referring to https://www.sciencedirect.com/science/article/pii/S2667100X21000323", "author_fullname": "t2_qe43i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "statistical comparison of two roc curves", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1091504", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673431392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If i were to produce 2 models (e.g. logistic regression and xgboost) and would like to generate a confidence interval and p value to compare the auc of roc curve of both models, how should i go about doing it? &lt;/p&gt;\n\n&lt;p&gt;A scientific article that i read mentioned that they&amp;#39;ve done it using a paired t-test.\nFor reference, this is the article im referring to &lt;a href=\"https://www.sciencedirect.com/science/article/pii/S2667100X21000323\"&gt;https://www.sciencedirect.com/science/article/pii/S2667100X21000323&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1091504", "is_robot_indexable": true, "report_reasons": null, "author": "GoodboyBuddy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1091504/statistical_comparison_of_two_roc_curves/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1091504/statistical_comparison_of_two_roc_curves/", "subreddit_subscribers": 835978, "created_utc": 1673431392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hoping it is allowed to ask some questions here about analysis help\n\nI have panel data analysis, i have run a fixed effects model but want to do a robustness check however what I'm finding is that there aren't really any for fixed effects models as they already incorporate it in the main analysis? Can I just run a reverse regression as a sort of robustness check? In such case, if the outcome is significant does that mean there is reverse causality?\n\nI have to do some sort of robustness check for my thesis requirements", "author_fullname": "t2_5rqavi4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "panel data robustness check?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1090dhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673428308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping it is allowed to ask some questions here about analysis help&lt;/p&gt;\n\n&lt;p&gt;I have panel data analysis, i have run a fixed effects model but want to do a robustness check however what I&amp;#39;m finding is that there aren&amp;#39;t really any for fixed effects models as they already incorporate it in the main analysis? Can I just run a reverse regression as a sort of robustness check? In such case, if the outcome is significant does that mean there is reverse causality?&lt;/p&gt;\n\n&lt;p&gt;I have to do some sort of robustness check for my thesis requirements&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1090dhv", "is_robot_indexable": true, "report_reasons": null, "author": "gottschegobble", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090dhv/panel_data_robustness_check/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090dhv/panel_data_robustness_check/", "subreddit_subscribers": 835978, "created_utc": 1673428308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n`import sklearn.neighbors._base`  \n`import sys`  \n`sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base`  \n`import missingpy`\n\nError message:\n\n **---------------------------------------------------------------------------** **ImportError**                               Traceback (most recent call last) **c:\\\\Users\\\\Godfred King\\\\Desktop\\\\Tableau\\\\COVID-19\\\\try.ipynb Cell 1** in &lt;cell line: 5&gt;**()**  3 import sys  4 sys.modules\\['sklearn.neighbors.base'\\] = sklearn.neighbors.\\_base \n\n**----&gt; 5** import missingpy  File **c:\\\\Users\\\\Godfred King\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\missingpy\\\\\\_\\_init\\_\\_.py:1**, in &lt;module&gt; \n\n**----&gt; 1** from .knnimpute import KNNImputer      \n\n 2 from .missforest import MissForest       4 \\_\\_all\\_\\_ = \\['KNNImputer', 'MissForest'\\]  File **c:\\\\Users\\\\Godfred King\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\missingpy\\\\knnimpute.py:13**, in &lt;module&gt;  \n\n11 from sklearn.utils.validation import check\\_is\\_fitted      12 from sklearn.utils.validation import FLOAT\\_DTYPES \n\n**--&gt; 13** from sklearn.neighbors.base import \\_check\\_weights      14 from sklearn.neighbors.base import \\_get\\_weights      16 from .pairwise\\_external import pairwise\\_distances  \n\n**ImportError**: cannot import name '\\_check\\_weights' from 'sklearn.neighbors.\\_base' (c:\\\\Users\\\\Godfred King\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\sklearn\\\\neighbors\\\\\\_base.py) \n\nThis is the code block I am trying to run and I get thrown the same error. Does anyone know how I can fix this error?", "author_fullname": "t2_a5ncsf7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to import and use missingpy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1090bdk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673428076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;import sklearn.neighbors._base&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;import sys&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;sys.modules[&amp;#39;sklearn.neighbors.base&amp;#39;] = sklearn.neighbors._base&lt;/code&gt;&lt;br/&gt;\n&lt;code&gt;import missingpy&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Error message:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;---------------------------------------------------------------------------&lt;/strong&gt; &lt;strong&gt;ImportError&lt;/strong&gt;                               Traceback (most recent call last) &lt;strong&gt;c:\\Users\\Godfred King\\Desktop\\Tableau\\COVID-19\\try.ipynb Cell 1&lt;/strong&gt; in &amp;lt;cell line: 5&amp;gt;&lt;strong&gt;()&lt;/strong&gt;  3 import sys  4 sys.modules[&amp;#39;sklearn.neighbors.base&amp;#39;] = sklearn.neighbors._base &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;----&amp;gt; 5&lt;/strong&gt; import missingpy  File &lt;strong&gt;c:\\Users\\Godfred King\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\missingpy\\__init__.py:1&lt;/strong&gt;, in &amp;lt;module&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;----&amp;gt; 1&lt;/strong&gt; from .knnimpute import KNNImputer      &lt;/p&gt;\n\n&lt;p&gt;2 from .missforest import MissForest       4 __all__ = [&amp;#39;KNNImputer&amp;#39;, &amp;#39;MissForest&amp;#39;]  File &lt;strong&gt;c:\\Users\\Godfred King\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\missingpy\\knnimpute.py:13&lt;/strong&gt;, in &amp;lt;module&amp;gt;  &lt;/p&gt;\n\n&lt;p&gt;11 from sklearn.utils.validation import check_is_fitted      12 from sklearn.utils.validation import FLOAT_DTYPES &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;--&amp;gt; 13&lt;/strong&gt; from sklearn.neighbors.base import _check_weights      14 from sklearn.neighbors.base import _get_weights      16 from .pairwise_external import pairwise_distances  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ImportError&lt;/strong&gt;: cannot import name &amp;#39;_check_weights&amp;#39; from &amp;#39;sklearn.neighbors._base&amp;#39; (c:\\Users\\Godfred King\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_base.py) &lt;/p&gt;\n\n&lt;p&gt;This is the code block I am trying to run and I get thrown the same error. Does anyone know how I can fix this error?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1090bdk", "is_robot_indexable": true, "report_reasons": null, "author": "KinGodfredd", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090bdk/how_to_import_and_use_missingpy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090bdk/how_to_import_and_use_missingpy/", "subreddit_subscribers": 835978, "created_utc": 1673428076.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_fx5w3fux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any information related to freelance data science jobs which need 0years of experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1090417", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673427276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "1090417", "is_robot_indexable": true, "report_reasons": null, "author": "RegularTechGuy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090417/any_information_related_to_freelance_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090417/any_information_related_to_freelance_data_science/", "subreddit_subscribers": 835978, "created_utc": 1673427276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just finished introductory python Machine Learning course. I find it very interesting and I want to advance my skill maybe to point of getting  a job with it. \nI studied Mathematics in University (west Africa) which make the algorithm and models quite understandable.\nI need help with advanced machine and data course material that I can to up my skill.\nI actually can\u2019t afford to buy courses right now. I will be glad to have your help", "author_fullname": "t2_bmzdtay8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Learning Materials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108zg1b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673424638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just finished introductory python Machine Learning course. I find it very interesting and I want to advance my skill maybe to point of getting  a job with it. \nI studied Mathematics in University (west Africa) which make the algorithm and models quite understandable.\nI need help with advanced machine and data course material that I can to up my skill.\nI actually can\u2019t afford to buy courses right now. I will be glad to have your help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108zg1b", "is_robot_indexable": true, "report_reasons": null, "author": "arakunrin_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108zg1b/seeking_learning_materials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108zg1b/seeking_learning_materials/", "subreddit_subscribers": 835978, "created_utc": 1673424638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks!\n\nI am searching for good solution to sync data from several postgres databases located in separate servers into one clickhouse server and multiple clickhouse databases.\n\nFor example:\n\n    postgres-server-1 -&gt; clickhouse-server.database1\npostgres-server-2 -&gt; clickhouse-server.database2\n...\n\nI found airbyte, but they currently do no support JSON fields (I have JSON data in columns) and each sync lasts about 10 minutes.\n\nIs there something more lightweight or should I implement something on myself?\n\nI am really curious about your ideas!", "author_fullname": "t2_efe06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing data from postgres to clickhouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108yvv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673422531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks!&lt;/p&gt;\n\n&lt;p&gt;I am searching for good solution to sync data from several postgres databases located in separate servers into one clickhouse server and multiple clickhouse databases.&lt;/p&gt;\n\n&lt;p&gt;For example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;postgres-server-1 -&amp;gt; clickhouse-server.database1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;postgres-server-2 -&amp;gt; clickhouse-server.database2\n...&lt;/p&gt;\n\n&lt;p&gt;I found airbyte, but they currently do no support JSON fields (I have JSON data in columns) and each sync lasts about 10 minutes.&lt;/p&gt;\n\n&lt;p&gt;Is there something more lightweight or should I implement something on myself?&lt;/p&gt;\n\n&lt;p&gt;I am really curious about your ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108yvv0", "is_robot_indexable": true, "report_reasons": null, "author": "bykof", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108yvv0/syncing_data_from_postgres_to_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108yvv0/syncing_data_from_postgres_to_clickhouse/", "subreddit_subscribers": 835978, "created_utc": 1673422531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Science and Robotics are the cross-disciplines of similar fields of study \u2013 science, statistics, computer technology, and engineering.\n\nLearn more: [https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics](https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics)", "author_fullname": "t2_vfnsdpj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impact of Data Science in Robotics | USDSI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108xged", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673417608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Science and Robotics are the cross-disciplines of similar fields of study \u2013 science, statistics, computer technology, and engineering.&lt;/p&gt;\n\n&lt;p&gt;Learn more: &lt;a href=\"https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics\"&gt;https://www.usdsi.org/data-science-insights/impact-of-data-science-in-robotics&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108xged", "is_robot_indexable": true, "report_reasons": null, "author": "Nikita-Techblogger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108xged/impact_of_data_science_in_robotics_usdsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108xged/impact_of_data_science_in_robotics_usdsi/", "subreddit_subscribers": 835978, "created_utc": 1673417608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In ML how do you guys think about tackling model drift? \n\nFew questions I have are \n\nIs there a way to simulate model in production by backtesting a fitted model with drift triggers? Is this be a practice?\n\nDoes data drift alone work or is it necessary to have error analysis dashboards set up to monitor where the model can mess up through time.\n\nWhat about features importance, wouldn\u2019t feature value loss/gain importance with time? Is it better to stick to what makes sense then select features later? (Even when using more robust methods such as SHAP these features can lose value eventually)\n\nI would like to learn more and take insight if possible?", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model error analysis, and data/feature drift.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108oz6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673393993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In ML how do you guys think about tackling model drift? &lt;/p&gt;\n\n&lt;p&gt;Few questions I have are &lt;/p&gt;\n\n&lt;p&gt;Is there a way to simulate model in production by backtesting a fitted model with drift triggers? Is this be a practice?&lt;/p&gt;\n\n&lt;p&gt;Does data drift alone work or is it necessary to have error analysis dashboards set up to monitor where the model can mess up through time.&lt;/p&gt;\n\n&lt;p&gt;What about features importance, wouldn\u2019t feature value loss/gain importance with time? Is it better to stick to what makes sense then select features later? (Even when using more robust methods such as SHAP these features can lose value eventually)&lt;/p&gt;\n\n&lt;p&gt;I would like to learn more and take insight if possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108oz6w", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108oz6w/model_error_analysis_and_datafeature_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108oz6w/model_error_analysis_and_datafeature_drift/", "subreddit_subscribers": 835978, "created_utc": 1673393993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear datascience sub.\n\nMy team is asking some advices on some A/B testing regarding a model I did not design and I also now need your help !\n\nLet's say we created a ML tool that returns me a list of clients that are considered as \"high value\". The first time after being detected that they enter one of our shop, we greet them in a special manner. \nSome of those detected are NOT \"activated\" in order to be our control group.\n\nNow, stakeholders want to know if the model works, meaning if there is a difference between the clients we contacted and the ones in the control group : we shall look at expense, number of visit, etc.\n\nHow would you compare the two groups, knowing that within the group of people who are activated, all of them are at a different date (and I don't want any time effect to pollute the analysis...)\n\nAny ideas ?\nThanks !", "author_fullname": "t2_bl8dhx5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help Testing \"lagged\" effect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108osc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673393535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear datascience sub.&lt;/p&gt;\n\n&lt;p&gt;My team is asking some advices on some A/B testing regarding a model I did not design and I also now need your help !&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say we created a ML tool that returns me a list of clients that are considered as &amp;quot;high value&amp;quot;. The first time after being detected that they enter one of our shop, we greet them in a special manner. \nSome of those detected are NOT &amp;quot;activated&amp;quot; in order to be our control group.&lt;/p&gt;\n\n&lt;p&gt;Now, stakeholders want to know if the model works, meaning if there is a difference between the clients we contacted and the ones in the control group : we shall look at expense, number of visit, etc.&lt;/p&gt;\n\n&lt;p&gt;How would you compare the two groups, knowing that within the group of people who are activated, all of them are at a different date (and I don&amp;#39;t want any time effect to pollute the analysis...)&lt;/p&gt;\n\n&lt;p&gt;Any ideas ?\nThanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108osc9", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-Yak5547", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108osc9/help_testing_lagged_effect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108osc9/help_testing_lagged_effect/", "subreddit_subscribers": 835978, "created_utc": 1673393535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been seeing around these beautifully drawn flowcharts around and been wondering what's the tool used here to draw the following?\n\nhttps://preview.redd.it/jahiqosim9ba1.png?width=642&amp;format=png&amp;auto=webp&amp;s=32f4cd80c17c2157c963c373b875f0ca1d5a796e", "author_fullname": "t2_btnb6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the software used to draw this flowchart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jahiqosim9ba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 115, "x": 108, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee2675e36616e2bf73ba8c6c46306897137c6299"}, {"y": 231, "x": 216, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=052a9b5b5b3d73dee3d899abf6ec7c3892c67bc7"}, {"y": 343, "x": 320, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=88ba31e30c1a5d422b38f452a6bab53890c4603d"}, {"y": 686, "x": 640, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=90ea6539fd7136a0a2f40c201f7351fbb463b17a"}], "s": {"y": 689, "x": 642, "u": "https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;format=png&amp;auto=webp&amp;s=32f4cd80c17c2157c963c373b875f0ca1d5a796e"}, "id": "jahiqosim9ba1"}}, "name": "t3_108i57v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ywNBa3I6o3-NwWmPvFlH9g6AIiCayRIWsAB6oIxlzq0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673378097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been seeing around these beautifully drawn flowcharts around and been wondering what&amp;#39;s the tool used here to draw the following?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32f4cd80c17c2157c963c373b875f0ca1d5a796e\"&gt;https://preview.redd.it/jahiqosim9ba1.png?width=642&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32f4cd80c17c2157c963c373b875f0ca1d5a796e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108i57v", "is_robot_indexable": true, "report_reasons": null, "author": "smoothtwist", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108i57v/what_is_the_software_used_to_draw_this_flowchart/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108i57v/what_is_the_software_used_to_draw_this_flowchart/", "subreddit_subscribers": 835978, "created_utc": 1673378097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_usk7jj3j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[New Feature] Discover and Extract Text Patterns with RATH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "name": "t3_108b680", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zTWsIEjqhCDqYOS-Qb5gDybSvD2qver7RxRCyDXU-Bo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673360974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/95o38brk68ba1.gif", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?format=png8&amp;s=19273eceb175b9b92b622280e1ab22689606678a", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=31f1e48071431de0a9ff369ced1b5befaff5917a", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=0e48232df2a7b47732f0ac6dab8a39fb6c48f63c", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=63615c12d9a127a4381ace4851ef606a131a62c1", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=04b2f822ba216fd76ff11976b35736d50eff6e87", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=fcfa7f089ebaa299122aff2c917d0ced8527cee3", "width": 960, "height": 433}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?s=7168c620b27dda45663967fe2bdee370bd22f9e6", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;crop=smart&amp;s=782fb373479f2f808a176f97d8fd3c4745c1ca32", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;crop=smart&amp;s=49cdf6ce75f44a648882a6d1575160f16a1ebab1", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;crop=smart&amp;s=3ecddf4cfb0a3d1f6ac74e2520cad6143da4f4ec", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;crop=smart&amp;s=61f3ca610d0cbc7951532a72e045379b9dccf963", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;crop=smart&amp;s=c141aa6ae3b1eed058c4d289cc4970c185cb4e93", "width": 960, "height": 433}]}, "mp4": {"source": {"url": "https://preview.redd.it/95o38brk68ba1.gif?format=mp4&amp;s=84e874e9024a93256707f1151a6df102e97f34f1", "width": 1000, "height": 452}, "resolutions": [{"url": "https://preview.redd.it/95o38brk68ba1.gif?width=108&amp;format=mp4&amp;s=0e826bb0071bd6d19114a39b33325c9d3e1cfe8c", "width": 108, "height": 48}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=216&amp;format=mp4&amp;s=026285d41c52ed45763eca9429d7a9f481a19eb0", "width": 216, "height": 97}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=320&amp;format=mp4&amp;s=84dd5443f3b18db039a0e4f187e90af84cc81e77", "width": 320, "height": 144}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=640&amp;format=mp4&amp;s=9b65c84fa92999f4f9a34fd09f3b8f7f3655020d", "width": 640, "height": 289}, {"url": "https://preview.redd.it/95o38brk68ba1.gif?width=960&amp;format=mp4&amp;s=a39ad53a0cc636d09d5b8c70d66399ef3cc02db5", "width": 960, "height": 433}]}}, "id": "A8a3PkdpOgSEpSIsb6pGmNSNoVF6viIYusCT-NSlR-8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "108b680", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Round-4366", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108b680/new_feature_discover_and_extract_text_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/95o38brk68ba1.gif", "subreddit_subscribers": 835978, "created_utc": 1673360974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to know how it compares to working in a company. Are the projects harder or easier? What are the pros and cons? I know I can google this but I wanted to hear some real life experiences - looking to eventually do this but I\u2019m scared it\u2019ll be too hard until I\u2019m an expert! Thanks \ud83d\ude0a", "author_fullname": "t2_m1eyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Freelance data scientists: how did you get into it and what has your journey and experience been so far?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108az26", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673360422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to know how it compares to working in a company. Are the projects harder or easier? What are the pros and cons? I know I can google this but I wanted to hear some real life experiences - looking to eventually do this but I\u2019m scared it\u2019ll be too hard until I\u2019m an expert! Thanks \ud83d\ude0a&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "108az26", "is_robot_indexable": true, "report_reasons": null, "author": "33spoonman", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/108az26/freelance_data_scientists_how_did_you_get_into_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/108az26/freelance_data_scientists_how_did_you_get_into_it/", "subreddit_subscribers": 835978, "created_utc": 1673360422.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}