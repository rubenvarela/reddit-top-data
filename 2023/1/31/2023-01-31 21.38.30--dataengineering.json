{"kind": "Listing", "data": {"after": "t3_10q49z4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my second data project. Creating an Extract Transform Load pipeline using python and automating with airflow.\n\n# Problem Statement:\n\nWe need to use Spotify\u2019s API to read the data and perform some basic transformations and Data Quality checks finally will load the retrieved data to PostgreSQL DB and then automate the entire process through airflow. **Est.Time:**\\[4\u20137 Hours\\]\n\n# Tech Stack / Skill used:\n\n1. Python\n2. API\u2019s\n3. Docker\n4. Airflow\n5. PostgreSQL\n\n# Learning Outcomes:\n\n1. Understand how to interact with API to retrieve data\n2. Handling Dataframe in pandas\n3. Setting up Airflow and PostgreSQL through Docker-Compose.\n4. Learning to Create DAGs in Airflow\n\nHere is the [GitHub repo](https://github.com/sidharth1805/Spotify_etl).\n\nHere is a blog where I have documented my project [Blog](https://medium.com/p/432dd8e4ffa3)\n\n[Design Diagram](https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef)\n\n&amp;#x200B;\n\n[Tree View of Airflow DAG](https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=02d5b357c50c80801f9b5131a042988870ee21ec)", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekend Data Engineering Project-Building Spotify pipeline using Python and Airflow. Est.Time:[4\u20137 Hours]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7gqn7up8pbfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccf217d1cbeabe7fa98b54afa04fc6acd096bdf7"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbca526fa4987a747670b35104f949cff3f03245"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47cf32337b3b9cb2ff8773ebc675ed19612c36c2"}], "s": {"y": 213, "x": 635, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=02d5b357c50c80801f9b5131a042988870ee21ec"}, "id": "7gqn7up8pbfa1"}, "a6kh9au6nbfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa8ab55f6aec6eab0c802c8bef7e65cf249f3698"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25629e845ca0317c63c72e79c7e612519398a3a2"}, {"y": 186, "x": 320, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1597e2954b5165241d2de8f220c7862d4bb0e54c"}, {"y": 373, "x": 640, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b23007973e1096d3695f50cd59d0acf70ca2be8"}, {"y": 560, "x": 960, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bce285750a2d3706c51493936f5a3e221f8b8442"}, {"y": 630, "x": 1080, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af3a89566d07560692d6c465f79e765bf02b4bf6"}], "s": {"y": 1332, "x": 2283, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef"}, "id": "a6kh9au6nbfa1"}}, "name": "t3_10pqspk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "transparent", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VxmI86MsFsJ7Q2igGddKbdyJNb9dokMDikebUBRapKM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1675146406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my second data project. Creating an Extract Transform Load pipeline using python and automating with airflow.&lt;/p&gt;\n\n&lt;h1&gt;Problem Statement:&lt;/h1&gt;\n\n&lt;p&gt;We need to use Spotify\u2019s API to read the data and perform some basic transformations and Data Quality checks finally will load the retrieved data to PostgreSQL DB and then automate the entire process through airflow. &lt;strong&gt;Est.Time:&lt;/strong&gt;[4\u20137 Hours]&lt;/p&gt;\n\n&lt;h1&gt;Tech Stack / Skill used:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;API\u2019s&lt;/li&gt;\n&lt;li&gt;Docker&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;PostgreSQL&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Learning Outcomes:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Understand how to interact with API to retrieve data&lt;/li&gt;\n&lt;li&gt;Handling Dataframe in pandas&lt;/li&gt;\n&lt;li&gt;Setting up Airflow and PostgreSQL through Docker-Compose.&lt;/li&gt;\n&lt;li&gt;Learning to Create DAGs in Airflow&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/sidharth1805/Spotify_etl\"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is a blog where I have documented my project &lt;a href=\"https://medium.com/p/432dd8e4ffa3\"&gt;Blog&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef\"&gt;Design Diagram&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=02d5b357c50c80801f9b5131a042988870ee21ec\"&gt;Tree View of Airflow DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?auto=webp&amp;v=enabled&amp;s=e336fd843f5783ca5cfbb9c5dc232f8cb1c6b4b2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e1f2a75d54de15a628ab56bfb234c9ce7cf638b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57d58d4288d7dd1c07c271f50d96770a1adfbdd2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63f310fb6864de7bd744aebbc202bec6fcc597c9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7d3a00191306057f6dba6db6b400cfd215b5a6a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=729e3e9648986c5d575283a4ba741b79f9d69540", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=006dd09a81cf5747871d0419dc0e3a1026d4f2e6", "width": 1080, "height": 540}], "variants": {}, "id": "T31bODdgOZMYN-TPAk0oYZ_YSgsbZ9pNCQo_R6CXdWU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10pqspk", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pqspk/weekend_data_engineering_projectbuilding_spotify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pqspk/weekend_data_engineering_projectbuilding_spotify/", "subreddit_subscribers": 88059, "created_utc": 1675146406.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey over the past year and a half I have gotten my team using git, CICD, and pull requests to help with code quality. All pull requests do have to be reviewed and checked with a checklist for basic things to check. \nThe next thing I want to try and start implementing is code reviews. \n\nHow do code reviews worth within your team? Are you doing actual meetings for each pull request? Is it just once a week for 30 mins reviewing changes for that week?\n\nThank you!", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code Reviews - Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ph6fr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675120185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey over the past year and a half I have gotten my team using git, CICD, and pull requests to help with code quality. All pull requests do have to be reviewed and checked with a checklist for basic things to check. \nThe next thing I want to try and start implementing is code reviews. &lt;/p&gt;\n\n&lt;p&gt;How do code reviews worth within your team? Are you doing actual meetings for each pull request? Is it just once a week for 30 mins reviewing changes for that week?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ph6fr", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ph6fr/code_reviews_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ph6fr/code_reviews_best_practices/", "subreddit_subscribers": 88059, "created_utc": 1675120185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I'm pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.\n\n\n\n\n\nIf I were to look for another company, I don't think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should experienced data engineers be doing until the economy improves?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pxqcl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675167962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I&amp;#39;m pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.&lt;/p&gt;\n\n&lt;p&gt;If I were to look for another company, I don&amp;#39;t think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pxqcl", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "subreddit_subscribers": 88059, "created_utc": 1675167962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello data engineering community!\n\nI would like to learn more about Kafka since I'm supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don't use streaming at all.\n\nI understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.\n\nThus, please don't mention any Kafka basics course since those should be a waste of time.\n\nThank you in advance for your input!", "author_fullname": "t2_ce7do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka course recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4jux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675185166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data engineering community!&lt;/p&gt;\n\n&lt;p&gt;I would like to learn more about Kafka since I&amp;#39;m supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don&amp;#39;t use streaming at all.&lt;/p&gt;\n\n&lt;p&gt;I understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.&lt;/p&gt;\n\n&lt;p&gt;Thus, please don&amp;#39;t mention any Kafka basics course since those should be a waste of time.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4jux", "is_robot_indexable": true, "report_reasons": null, "author": "ulysses_black", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "subreddit_subscribers": 88059, "created_utc": 1675185166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, \n\nI have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. \n\nI have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. \n\nHow to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. \n\nAny help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE best practices when working with ML (MLops?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pz27i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675171771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. &lt;/p&gt;\n\n&lt;p&gt;I have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. &lt;/p&gt;\n\n&lt;p&gt;How to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. &lt;/p&gt;\n\n&lt;p&gt;Any help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pz27i", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "subreddit_subscribers": 88059, "created_utc": 1675171771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow", "author_fullname": "t2_ldunk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What size is your airflow cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q0teh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675176287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q0teh", "is_robot_indexable": true, "report_reasons": null, "author": "wytesmurf", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "subreddit_subscribers": 88059, "created_utc": 1675176287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The raise in popularity of ChatGPT/GPT3 and LLMs in general got me wondering.  \nDid these tools make it into the hands of the data community already?  \nAre you using such a tool for your daily work?\n\nPlease share your stories on the topic.\n\n&amp;#x200B;\n\nAdded an example from ChatGPT usage:\n\n&amp;#x200B;\n\n[ChatGPT creates DDL from natural language request](https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b)\n\n[View Poll](https://www.reddit.com/poll/10puzjt)", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Usage of generative AI for SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 123, "top_awarded_type": null, "hide_score": false, "media_metadata": {"afg46q8pncfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b11400a12393d67551dbfb1c2afde422d1faad95"}, {"y": 189, "x": 216, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7212b9f51d5d68c4db4c9582c0dc9b7c5a5dd9d1"}, {"y": 281, "x": 320, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8da9a58d6bcff85eb7038a6fc9705e9a13007807"}, {"y": 562, "x": 640, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f43f49dcc2002aa246f9bd939b653c94ce96225"}], "s": {"y": 631, "x": 718, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b"}, "id": "afg46q8pncfa1"}}, "name": "t3_10puzjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XXXj7AhFbzIb6u2z6sbL4WgAmrthuGMRjAbxy6yS0OM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675158380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The raise in popularity of ChatGPT/GPT3 and LLMs in general got me wondering.&lt;br/&gt;\nDid these tools make it into the hands of the data community already?&lt;br/&gt;\nAre you using such a tool for your daily work?&lt;/p&gt;\n\n&lt;p&gt;Please share your stories on the topic.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Added an example from ChatGPT usage:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b\"&gt;ChatGPT creates DDL from natural language request&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10puzjt\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10puzjt", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675244780952, "options": [{"text": "I'm not sure how to implement it in my day-to-day work", "id": "21341009"}, {"text": "I use it all the time! ChatGPT FTW", "id": "21341010"}, {"text": "I use GitHub co-pilot in vscode", "id": "21341011"}, {"text": "I think this is over hyped buzz with no significant value", "id": "21341012"}, {"text": "I think it has a lot of potential but not intuitive to use", "id": "21341013"}, {"text": "I just want to see the results", "id": "21341014"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 130, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10puzjt/usage_of_generative_ai_for_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10puzjt/usage_of_generative_ai_for_sql/", "subreddit_subscribers": 88059, "created_utc": 1675158380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are people liking for data quality control / profiling? Great Expectations, custom python scripts? Another product?", "author_fullname": "t2_iety6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data QC? Great Expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pj5gi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675125237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are people liking for data quality control / profiling? Great Expectations, custom python scripts? Another product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pj5gi", "is_robot_indexable": true, "report_reasons": null, "author": "chocotaco1981", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pj5gi/data_qc_great_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pj5gi/data_qc_great_expectations/", "subreddit_subscribers": 88059, "created_utc": 1675125237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if it's something I should invest in, pretty sure the people in charge of the DMBOK offer one.", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance certifications: how useful are they in this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if it&amp;#39;s something I should invest in, pretty sure the people in charge of the DMBOK offer one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q5xke", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "subreddit_subscribers": 88059, "created_utc": 1675188370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here read it? Do you think I should do that, would you recommend it to a DE?", "author_fullname": "t2_1xbf9q7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "thinking of reading sicp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10peniq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675114205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here read it? Do you think I should do that, would you recommend it to a DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10peniq", "is_robot_indexable": true, "report_reasons": null, "author": "aerdna69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10peniq/thinking_of_reading_sicp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10peniq/thinking_of_reading_sicp/", "subreddit_subscribers": 88059, "created_utc": 1675114205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever used Databricks with an on premise source control system? If so, can you provide what's steps you did for code development and CICD.", "author_fullname": "t2_4anjpw7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and On Premise Source Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever used Databricks with an on premise source control system? If so, can you provide what&amp;#39;s steps you did for code development and CICD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q5xek", "is_robot_indexable": true, "report_reasons": null, "author": "B1WR2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "subreddit_subscribers": 88059, "created_utc": 1675188361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I always had this doubt as in for movies/Entertainment and all we have various websites that keep sending out gossips or news on the fly to keep us posted\n\nWhat resources do we have to stay updated in the technology front? I was going through this channel and I found there is something called DuckDB. Now I am also curious how do people stay updated I\u2019m particularly interested in Data Engineering front but DS should also be fine.\n\nI would love to have some resources like Websites YouTube channels or anything that helps us stay in touch with what\u2019s happening around us", "author_fullname": "t2_vltlyjpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stay updated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5e8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675187123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I always had this doubt as in for movies/Entertainment and all we have various websites that keep sending out gossips or news on the fly to keep us posted&lt;/p&gt;\n\n&lt;p&gt;What resources do we have to stay updated in the technology front? I was going through this channel and I found there is something called DuckDB. Now I am also curious how do people stay updated I\u2019m particularly interested in Data Engineering front but DS should also be fine.&lt;/p&gt;\n\n&lt;p&gt;I would love to have some resources like Websites YouTube channels or anything that helps us stay in touch with what\u2019s happening around us&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q5e8o", "is_robot_indexable": true, "report_reasons": null, "author": "RandomDEguy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5e8o/stay_updated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5e8o/stay_updated/", "subreddit_subscribers": 88059, "created_utc": 1675187123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_meq7wkla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 Signs Analytics Engineering Might Be the Right Career For You", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10q3rv7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qcwX46deOGDBhCvJWjVAtW5bTKXHIdLnKujoYYFu078.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675183368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/analytics-engineering-career", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?auto=webp&amp;v=enabled&amp;s=f56325dae27cdfcfe687b86f6a7511e1b31b143e", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15cd1de2f3a15b31224853e13151a180ffb386eb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65af7da16e343e34f83e994fb5f140a77aef4d82", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04842315ff1fb307376fbfb2e64fb02b3c2a68a8", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9b451dabfffa46677a86a2a18e8bad3eadd372e", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=56726614c9911aa21deab22b2b6fe0bea4147fba", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Xv1nBJRHQP4TkdzqiR4Gh4AajQ5p24-y_G3qcaFiwNo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5240301924a7fa575c8eb0e5a595e5c872baf695", "width": 1080, "height": 565}], "variants": {}, "id": "ke0xxaeu5iOhpHcjh-yk1OixZpXliLETPwLXaizQRaU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10q3rv7", "is_robot_indexable": true, "report_reasons": null, "author": "thabarrera", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q3rv7/5_signs_analytics_engineering_might_be_the_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/analytics-engineering-career", "subreddit_subscribers": 88059, "created_utc": 1675183368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.\n\nIs this linked data a viable option or is it just a niche?", "author_fullname": "t2_mv3d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDF/triply for building dataplatform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q2ejq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675180122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.&lt;/p&gt;\n\n&lt;p&gt;Is this linked data a viable option or is it just a niche?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q2ejq", "is_robot_indexable": true, "report_reasons": null, "author": "artopaper", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "subreddit_subscribers": 88059, "created_utc": 1675180122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. \n\nSo a company I recently started at have previously attempted to implement a medallion architecture using Databricks and ADLS.\n\nIn the silver stage, data is being written out as Delta Lakes (only overwrite mode, never upserts) however a new directory is being created for each run, for example:\n\n    DatasetName\n    \u251c\u2500 Jan\n    \u2502  \u251c\u2500 15\n    \u2502  \u2502  \u251c\u2500 _delta_log\n    \u2502  \u2502  \u251c\u2500 part000...parquet\n    \u2502  \u251c\u2500 31\n    \u2502  \u2502  \u251c\u2500 _delta_log\n    \u2502  \u2502  \u251c\u2500 part000...parquet\n    \u251c\u2500 Feb\n    \n    etc...\n\nFrom my understanding, this completely misses the point of using delta to begin with? I think there should just be a single Delta Lake for a given dataset and this should just be overwritten every time like this:\n\n    DatasetName\n    \u251c\u2500 _delta_log\n    \u251c\u2500 part000...parquet\n    \u251c\u2500 part001...parquet\n    \u251c\u2500 part002...parquet\n    \n    etc...\n\nTheir argument is that these Delta Lakes will need to be kept for upwards of 10/20 years, and that they were told it would be more cost efficient to save out each version to a separate directory, rather than overwriting an existing Delta Lake and using time travel when required for audits etc. \n\nThis doesn't really make much sense to me as it over complicates the pipelines, and from my understanding of how the delta log works time travelling shouldn't really have much of a computational/cost overhead if they wanted to go back years when compared to loading data from different data/month/day directories?\n\nWould anybody be able to clarify which approach is correct here, and if so then why?\n\nThanks!", "author_fullname": "t2_152cpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of delta lake time travel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pw3na", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675162443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. &lt;/p&gt;\n\n&lt;p&gt;So a company I recently started at have previously attempted to implement a medallion architecture using Databricks and ADLS.&lt;/p&gt;\n\n&lt;p&gt;In the silver stage, data is being written out as Delta Lakes (only overwrite mode, never upserts) however a new directory is being created for each run, for example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DatasetName\n\u251c\u2500 Jan\n\u2502  \u251c\u2500 15\n\u2502  \u2502  \u251c\u2500 _delta_log\n\u2502  \u2502  \u251c\u2500 part000...parquet\n\u2502  \u251c\u2500 31\n\u2502  \u2502  \u251c\u2500 _delta_log\n\u2502  \u2502  \u251c\u2500 part000...parquet\n\u251c\u2500 Feb\n\netc...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From my understanding, this completely misses the point of using delta to begin with? I think there should just be a single Delta Lake for a given dataset and this should just be overwritten every time like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DatasetName\n\u251c\u2500 _delta_log\n\u251c\u2500 part000...parquet\n\u251c\u2500 part001...parquet\n\u251c\u2500 part002...parquet\n\netc...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Their argument is that these Delta Lakes will need to be kept for upwards of 10/20 years, and that they were told it would be more cost efficient to save out each version to a separate directory, rather than overwriting an existing Delta Lake and using time travel when required for audits etc. &lt;/p&gt;\n\n&lt;p&gt;This doesn&amp;#39;t really make much sense to me as it over complicates the pipelines, and from my understanding of how the delta log works time travelling shouldn&amp;#39;t really have much of a computational/cost overhead if they wanted to go back years when compared to loading data from different data/month/day directories?&lt;/p&gt;\n\n&lt;p&gt;Would anybody be able to clarify which approach is correct here, and if so then why?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10pw3na", "is_robot_indexable": true, "report_reasons": null, "author": "Battery_Powered_Box", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pw3na/cost_of_delta_lake_time_travel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pw3na/cost_of_delta_lake_time_travel/", "subreddit_subscribers": 88059, "created_utc": 1675162443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From HackerNews: Heroku deleted my database with no warning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10qadtn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1675198937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=34598563", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qadtn", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qadtn/from_hackernews_heroku_deleted_my_database_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=34598563", "subreddit_subscribers": 88059, "created_utc": 1675198937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any particular patterns, native libraries or other?\n\n(We know data sciencists have pandas, numpy etc..)", "author_fullname": "t2_2pxsf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which aspects of the python programming language help you be a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10qa5zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675198446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any particular patterns, native libraries or other?&lt;/p&gt;\n\n&lt;p&gt;(We know data sciencists have pandas, numpy etc..)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qa5zk", "is_robot_indexable": true, "report_reasons": null, "author": "blue_trains_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "subreddit_subscribers": 88059, "created_utc": 1675198446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys! So I'm an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere's the deal:\n\n-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.\n\n-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it's like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.\n\nWhat do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo\n\n\n\n\n\nIs this worth it? I mean, it would be", "author_fullname": "t2_171ccp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "22% difference salary worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10q9uvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! So I&amp;#39;m an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere&amp;#39;s the deal:&lt;/p&gt;\n\n&lt;p&gt;-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.&lt;/p&gt;\n\n&lt;p&gt;-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it&amp;#39;s like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo&lt;/p&gt;\n\n&lt;p&gt;Is this worth it? I mean, it would be&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q9uvv", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Nicotine", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "subreddit_subscribers": 88059, "created_utc": 1675197735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to hear about other experiences here.\n\nThe kind of DE I've done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.\n\nI'm currently doing DE Zoomcamp and it's been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I've never encountered anything I wanted to do but couldn't do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to \"see\" the data so well if you are using python to manipulate data?\n\nIs the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don't have direct access to the DB?\n\nI feel I am missing some key part of the picture regarding \"why everyone uses python\", or the kinds of tools they are using that depend on python rather than SQL.", "author_fullname": "t2_5n8mvd7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different types of DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10q9s2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to hear about other experiences here.&lt;/p&gt;\n\n&lt;p&gt;The kind of DE I&amp;#39;ve done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently doing DE Zoomcamp and it&amp;#39;s been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I&amp;#39;ve never encountered anything I wanted to do but couldn&amp;#39;t do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to &amp;quot;see&amp;quot; the data so well if you are using python to manipulate data?&lt;/p&gt;\n\n&lt;p&gt;Is the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don&amp;#39;t have direct access to the DB?&lt;/p&gt;\n\n&lt;p&gt;I feel I am missing some key part of the picture regarding &amp;quot;why everyone uses python&amp;quot;, or the kinds of tools they are using that depend on python rather than SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q9s2t", "is_robot_indexable": true, "report_reasons": null, "author": "kaiso_gunkan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9s2t/different_types_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9s2t/different_types_of_de/", "subreddit_subscribers": 88059, "created_utc": 1675197553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?", "author_fullname": "t2_81izlu1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering in the US Army", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10q97ag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675196166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q97ag", "is_robot_indexable": true, "report_reasons": null, "author": "Bane_of_Titan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "subreddit_subscribers": 88059, "created_utc": 1675196166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a creating a cloud formation stack where I am creating a Secrets Manager resource with Secret String value. \n\nIn the same Cloud Formation template, I have a Lambda Function that has a secrets manager client defined that expects Secrets Name and the Secrets ARN. How can I refer to the Secrets resource information in the Lambda function resource that is being created in the same cloud formation stack.", "author_fullname": "t2_mspamalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Secrets Manager, Lambda Function in the same Cloud Formation template.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q7ukh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675192863.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a creating a cloud formation stack where I am creating a Secrets Manager resource with Secret String value. &lt;/p&gt;\n\n&lt;p&gt;In the same Cloud Formation template, I have a Lambda Function that has a secrets manager client defined that expects Secrets Name and the Secrets ARN. How can I refer to the Secrets resource information in the Lambda function resource that is being created in the same cloud formation stack.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q7ukh", "is_robot_indexable": true, "report_reasons": null, "author": "Awsmason", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q7ukh/aws_secrets_manager_lambda_function_in_the_same/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q7ukh/aws_secrets_manager_lambda_function_in_the_same/", "subreddit_subscribers": 88059, "created_utc": 1675192863.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone tried to connect openmetadata to catalog Raw/txt files? We were thinking about building a connector to the fileshare, but wanted to see if anyone else had a better solution.", "author_fullname": "t2_799vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Openmetadata connection to Fileshare?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5lak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675187584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried to connect openmetadata to catalog Raw/txt files? We were thinking about building a connector to the fileshare, but wanted to see if anyone else had a better solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10q5lak", "is_robot_indexable": true, "report_reasons": null, "author": "fozzie33", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5lak/openmetadata_connection_to_fileshare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5lak/openmetadata_connection_to_fileshare/", "subreddit_subscribers": 88059, "created_utc": 1675187584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is investigating how to insure that we are alerted when data delivery SLAs are missed. Rather than include this in our Airflow system we would prefer an independent system (I've been burned too many times when a problem causes the Airflow SLA monitoring task to fail at the same time as the data are not making it to the final expected location). Does anyone have any tools that they are happily using for this use case?", "author_fullname": "t2_ycsml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Tooling to Alert on Missing Data Delivery SLAs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4vqo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675185928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is investigating how to insure that we are alerted when data delivery SLAs are missed. Rather than include this in our Airflow system we would prefer an independent system (I&amp;#39;ve been burned too many times when a problem causes the Airflow SLA monitoring task to fail at the same time as the data are not making it to the final expected location). Does anyone have any tools that they are happily using for this use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q4vqo", "is_robot_indexable": true, "report_reasons": null, "author": "kevinpostlewaite", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q4vqo/open_source_tooling_to_alert_on_missing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4vqo/open_source_tooling_to_alert_on_missing_data/", "subreddit_subscribers": 88059, "created_utc": 1675185928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title is self-explanatory.", "author_fullname": "t2_vf6l0ngg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've made a MySQL Workbench file with all tables and values inserted, but now I need to access it with Microsoft Access. How do I do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4dgm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675184760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title is self-explanatory.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4dgm", "is_robot_indexable": true, "report_reasons": null, "author": "NeverendingZ", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q4dgm/ive_made_a_mysql_workbench_file_with_all_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4dgm/ive_made_a_mysql_workbench_file_with_all_tables/", "subreddit_subscribers": 88059, "created_utc": 1675184760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I tried several things, but it was unsuccessful.", "author_fullname": "t2_vf6l0ngg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've made a MySQL Workbench file with all tables and values inserted, but now I need to access it with Microsoft Access. How do I do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q49z4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675184531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried several things, but it was unsuccessful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q49z4", "is_robot_indexable": true, "report_reasons": null, "author": "NeverendingZ", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q49z4/ive_made_a_mysql_workbench_file_with_all_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q49z4/ive_made_a_mysql_workbench_file_with_all_tables/", "subreddit_subscribers": 88059, "created_utc": 1675184531.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}