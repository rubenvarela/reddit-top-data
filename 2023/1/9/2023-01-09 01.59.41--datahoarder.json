{"kind": "Listing", "data": {"after": "t3_106xtyp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Constructive feedback very much appreciated.\n\nHere is the guide:\n\nhttps://medium.com/@goughgough/the-best-way-for-microsoft-teams-users-without-administrator-rights-to-save-export-print-copy-8212aa9e5f11\n\n__TL;DR:__\nTo export Teams chat messages without Microsoft Teams admin rights, download Gildas Lormeau's (GL) browser extension at https://github.com/gildas-lormeau/single-file-export-chat.\n\nBy the way, this extension is based on their excellent Singlefile browser extension.\n\n__Assumptions:__\nYou are not very tech-savvy.\n\nYou can log into Microsoft Teams in a browser at https://teams.microsoft.com/\n\nIn Teams, you do not have admin rights for a group chat. Nevertheless, you still need to export the messages from that specific group chat.\n\nYou want to use noncommercial software and do the exporting for free.\n\nYou want to export messages from the Chat section (in Microsoft Teams left column). NOT the Team section (in Microsoft Teams left column).\n\nYou wish to export Teams messages in their entirety, including any body text that contains clickable links.\n\nYou want to export Teams messages to a searchable final output rather than an image file.\n\nYou do not want to waste time manually copying and pasting individual Teams messages, which is one of the techniques in quite a few of the online guides. This manual copying and pasting makes sense if you only have a few Teams messages to export.\n\nYou do not want to use the GoFullPage browser extension. Even though it is not as effective as GL\u2019s solutions, it does let you export Teams messages as images (e.g., a non-searchable PDF file). Before I came across GL\u2019s methods, the GoFullPage browser extension was the best method I tried. Unfortunately, the final product is not searchable due to its image format.", "author_fullname": "t2_ipdh111g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just published my guide for Microsoft Teams users (without administrator rights) to save, export, print, copy, archive, back up, or migrate Teams conversation threads, messages, chat history. Hope you like it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106fwt4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 176, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 176, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673217375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673173191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Constructive feedback very much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Here is the guide:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@goughgough/the-best-way-for-microsoft-teams-users-without-administrator-rights-to-save-export-print-copy-8212aa9e5f11\"&gt;https://medium.com/@goughgough/the-best-way-for-microsoft-teams-users-without-administrator-rights-to-save-export-print-copy-8212aa9e5f11&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt;\nTo export Teams chat messages without Microsoft Teams admin rights, download Gildas Lormeau&amp;#39;s (GL) browser extension at &lt;a href=\"https://github.com/gildas-lormeau/single-file-export-chat\"&gt;https://github.com/gildas-lormeau/single-file-export-chat&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;By the way, this extension is based on their excellent Singlefile browser extension.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Assumptions:&lt;/strong&gt;\nYou are not very tech-savvy.&lt;/p&gt;\n\n&lt;p&gt;You can log into Microsoft Teams in a browser at &lt;a href=\"https://teams.microsoft.com/\"&gt;https://teams.microsoft.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In Teams, you do not have admin rights for a group chat. Nevertheless, you still need to export the messages from that specific group chat.&lt;/p&gt;\n\n&lt;p&gt;You want to use noncommercial software and do the exporting for free.&lt;/p&gt;\n\n&lt;p&gt;You want to export messages from the Chat section (in Microsoft Teams left column). NOT the Team section (in Microsoft Teams left column).&lt;/p&gt;\n\n&lt;p&gt;You wish to export Teams messages in their entirety, including any body text that contains clickable links.&lt;/p&gt;\n\n&lt;p&gt;You want to export Teams messages to a searchable final output rather than an image file.&lt;/p&gt;\n\n&lt;p&gt;You do not want to waste time manually copying and pasting individual Teams messages, which is one of the techniques in quite a few of the online guides. This manual copying and pasting makes sense if you only have a few Teams messages to export.&lt;/p&gt;\n\n&lt;p&gt;You do not want to use the GoFullPage browser extension. Even though it is not as effective as GL\u2019s solutions, it does let you export Teams messages as images (e.g., a non-searchable PDF file). Before I came across GL\u2019s methods, the GoFullPage browser extension was the best method I tried. Unfortunately, the final product is not searchable due to its image format.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 150, "id": "award_f44611f1-b89e-46dc-97fe-892280b13b82", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Thank you stranger. Shows the award.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Helpful", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106fwt4", "is_robot_indexable": true, "report_reasons": null, "author": "cashpayer", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106fwt4/just_published_my_guide_for_microsoft_teams_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106fwt4/just_published_my_guide_for_microsoft_teams_users/", "subreddit_subscribers": 664826, "created_utc": 1673173191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a a 1TB SanDisk 520s and I am looking for a solution to expand my storage capacity. Obviously I could just get another 1TB, but then I would then have multiple drives I need to eject when I move my MacBook about.\n\nLooking at YouTube videos it does look like it has an M2 NVME drive installed, so this got me thinking. For the same price of another 1TB sandisk I can get a 2tb M2 drive.\n\nIs there some enclose preferably unpowered (or type c) that can hold multiple M2s? I suppose two drives would be ok, but would prefer four. I have looked on Amazon and they either seem to be exposed, too big and also need power.\n\nRaid capability isn't necessary. Portability is fairly important though.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/j2bssghsbvaa1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=41d07a33f39622a5df81dac42d95e4fed58059a9", "author_fullname": "t2_1gm1x1ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a solution for a multi M2 drive storage with a single cable. Have a 1TB SanDisk and want to expand.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 136, "top_awarded_type": null, "hide_score": false, "media_metadata": {"j2bssghsbvaa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 105, "x": 108, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77213af351033a331e12698f8fd978e66d31f5b6"}, {"y": 210, "x": 216, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8883baee2817b6e67db79fedb328247d0b8d9bab"}, {"y": 312, "x": 320, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ff67dcc4cc07c268e4297d71b4100401dce0ac5"}, {"y": 624, "x": 640, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ed99c8890df4ea17367f49af5feac416f0526e7"}, {"y": 936, "x": 960, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a24605ba408fd541bb62c311a5b6cbe1669d182"}, {"y": 1053, "x": 1080, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8580e7afd77f36be18428e754b33d33b762f5f2d"}], "s": {"y": 1463, "x": 1500, "u": "https://preview.redd.it/j2bssghsbvaa1.jpg?width=1500&amp;format=pjpg&amp;auto=webp&amp;s=41d07a33f39622a5df81dac42d95e4fed58059a9"}, "id": "j2bssghsbvaa1"}}, "name": "t3_106fh0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/38krtbUG4CznLJGNjfsGTJkU05UacwwdYt4J-2n4Rss.jpg", "edited": 1673204933.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673171633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a a 1TB SanDisk 520s and I am looking for a solution to expand my storage capacity. Obviously I could just get another 1TB, but then I would then have multiple drives I need to eject when I move my MacBook about.&lt;/p&gt;\n\n&lt;p&gt;Looking at YouTube videos it does look like it has an M2 NVME drive installed, so this got me thinking. For the same price of another 1TB sandisk I can get a 2tb M2 drive.&lt;/p&gt;\n\n&lt;p&gt;Is there some enclose preferably unpowered (or type c) that can hold multiple M2s? I suppose two drives would be ok, but would prefer four. I have looked on Amazon and they either seem to be exposed, too big and also need power.&lt;/p&gt;\n\n&lt;p&gt;Raid capability isn&amp;#39;t necessary. Portability is fairly important though.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/j2bssghsbvaa1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=41d07a33f39622a5df81dac42d95e4fed58059a9\"&gt;https://preview.redd.it/j2bssghsbvaa1.jpg?width=1500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=41d07a33f39622a5df81dac42d95e4fed58059a9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106fh0r", "is_robot_indexable": true, "report_reasons": null, "author": "matmah", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106fh0r/looking_for_a_solution_for_a_multi_m2_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106fh0r/looking_for_a_solution_for_a_multi_m2_drive/", "subreddit_subscribers": 664826, "created_utc": 1673171633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need help finding duplicates of my JAV collection, the problem is that some files have their titles in different format like:\n\na) GVG-001.mp4\n\nb) GVG001.mp4\n\nc) GVG001 - additional movie title\n\nWhat software would you recommend to find dupes? Duplicate files might have different lengths so CRC search will not work. I need some way to analyze the first few letters of a filename keeping in mind that there may or may not be \"-\" sing in there. Can you help me out?\n\nI have total commander but I'm not sure if its search function is as powerful.", "author_fullname": "t2_tmiw5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software for finding duplicate files based on a similar filename.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106g20g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673173717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need help finding duplicates of my JAV collection, the problem is that some files have their titles in different format like:&lt;/p&gt;\n\n&lt;p&gt;a) GVG-001.mp4&lt;/p&gt;\n\n&lt;p&gt;b) GVG001.mp4&lt;/p&gt;\n\n&lt;p&gt;c) GVG001 - additional movie title&lt;/p&gt;\n\n&lt;p&gt;What software would you recommend to find dupes? Duplicate files might have different lengths so CRC search will not work. I need some way to analyze the first few letters of a filename keeping in mind that there may or may not be &amp;quot;-&amp;quot; sing in there. Can you help me out?&lt;/p&gt;\n\n&lt;p&gt;I have total commander but I&amp;#39;m not sure if its search function is as powerful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106g20g", "is_robot_indexable": true, "report_reasons": null, "author": "wooshaq", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106g20g/software_for_finding_duplicate_files_based_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106g20g/software_for_finding_duplicate_files_based_on_a/", "subreddit_subscribers": 664826, "created_utc": 1673173717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have quite a collection of MP3 audio books that I have collected over the decades.  Some are divided by chapter.  Some are even divided by chapter in different CD folders.  I am looking for a good Windows app that will take a folder of MP3s (with even subfolders) and convert them into a single M4B.  OpenAudible lets me import the MP3s, but I can't figure out how to combine and convert them using that, so I'm looking for suggestions.", "author_fullname": "t2_6qsou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Windows app for combining multiple MP3s into single M4B", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106m2yz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673192233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have quite a collection of MP3 audio books that I have collected over the decades.  Some are divided by chapter.  Some are even divided by chapter in different CD folders.  I am looking for a good Windows app that will take a folder of MP3s (with even subfolders) and convert them into a single M4B.  OpenAudible lets me import the MP3s, but I can&amp;#39;t figure out how to combine and convert them using that, so I&amp;#39;m looking for suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106m2yz", "is_robot_indexable": true, "report_reasons": null, "author": "djeaton", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106m2yz/best_windows_app_for_combining_multiple_mp3s_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106m2yz/best_windows_app_for_combining_multiple_mp3s_into/", "subreddit_subscribers": 664826, "created_utc": 1673192233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nThe HDDs will be part of my self built NAS, which is housed in an old Fractal Design Define R6 - a case that comes with some amount of soundproofing. Unfortunately, in my apartment I don't have any space where noise absolutely does not matter. For now, it will be in the working room, where I and the gf spend significant amounts of time trying to be productive. Because of this, I want to buy HDDs that are the most likely to not annoy us too much. Read/Write performance is a secondary concern, so long as they make full use of my gigabit ethernet connection.\n\nI've done a bunch of research on this; both in this sub and beyond, and unfortunately there is no drive for which I don't find three different people making five contradicting claims about their noise levels.\n\nFor instance, I've heard a bunch of good things about the Ultrastar DC HC550 drives; but other sources say they produce a thudding noise every five seconds or so, which may or may not be quite annoying.\n\nI also recently got a good deal on two Toshiba MG08ACA16TE drives which are sitting here unused so far, as I'm considering returning them. I've heard people claim they're rather quiet or really loud.\n\nIt would be helpful to hear from people who have tried different HDDs from different companies and thus can give some sort of comparison. I am also totally open to other models or to shucking, if that's still a thing.\n\nOS Wise I am likely going with True NAS Core for the NAS, if this has any bearing on the question.", "author_fullname": "t2_pvd4p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quiet HDDs for NAS in working room?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106tcb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673209736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;The HDDs will be part of my self built NAS, which is housed in an old Fractal Design Define R6 - a case that comes with some amount of soundproofing. Unfortunately, in my apartment I don&amp;#39;t have any space where noise absolutely does not matter. For now, it will be in the working room, where I and the gf spend significant amounts of time trying to be productive. Because of this, I want to buy HDDs that are the most likely to not annoy us too much. Read/Write performance is a secondary concern, so long as they make full use of my gigabit ethernet connection.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a bunch of research on this; both in this sub and beyond, and unfortunately there is no drive for which I don&amp;#39;t find three different people making five contradicting claims about their noise levels.&lt;/p&gt;\n\n&lt;p&gt;For instance, I&amp;#39;ve heard a bunch of good things about the Ultrastar DC HC550 drives; but other sources say they produce a thudding noise every five seconds or so, which may or may not be quite annoying.&lt;/p&gt;\n\n&lt;p&gt;I also recently got a good deal on two Toshiba MG08ACA16TE drives which are sitting here unused so far, as I&amp;#39;m considering returning them. I&amp;#39;ve heard people claim they&amp;#39;re rather quiet or really loud.&lt;/p&gt;\n\n&lt;p&gt;It would be helpful to hear from people who have tried different HDDs from different companies and thus can give some sort of comparison. I am also totally open to other models or to shucking, if that&amp;#39;s still a thing.&lt;/p&gt;\n\n&lt;p&gt;OS Wise I am likely going with True NAS Core for the NAS, if this has any bearing on the question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106tcb2", "is_robot_indexable": true, "report_reasons": null, "author": "SWHH", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106tcb2/quiet_hdds_for_nas_in_working_room/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106tcb2/quiet_hdds_for_nas_in_working_room/", "subreddit_subscribers": 664826, "created_utc": 1673209736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Entire question fit in the title of this post.", "author_fullname": "t2_8hlee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In a 2-drive raid 1 array, is it a viable backup strategy to pull one drive for cold storage and then replace it (rebuilding the array)? Could one then just rotate the third drive through periodically in this manner when a new backup is desired?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1067x0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673146956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Entire question fit in the title of this post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1067x0r", "is_robot_indexable": true, "report_reasons": null, "author": "nouvie", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1067x0r/in_a_2drive_raid_1_array_is_it_a_viable_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1067x0r/in_a_2drive_raid_1_array_is_it_a_viable_backup/", "subreddit_subscribers": 664826, "created_utc": 1673146956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I seem to have Rclone setup properly, but Im a bit confused on how I would clone an entire folder of my external drive(connected to my mac) into a specific folder in my Google drive account. My Rclone account name will be NAME for the purpose of this post\n\nThe folder that I'm looking to copy is in this chain \"4tb&gt;offloaded footage&gt;categorized&gt;DJI&gt;2021\n\nand I'm looking to copy this to my google drive \"My Drive&gt;Categorized footage&gt;DJI&gt;2021\n\nHere is the terminal command that I'm using\n\n    rclone -v sync /Volumes/4TB\\ Offloaded\\ Footage/Categorized/DJI/2021 NAME:\n\nThen what do I put after this to get the contents copied into \n\n&gt;My Drive&gt;Categorized footage&gt;DJI&gt;2021", "author_fullname": "t2_y7xmw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using RClone to copy folder to folder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106m302", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673192235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I seem to have Rclone setup properly, but Im a bit confused on how I would clone an entire folder of my external drive(connected to my mac) into a specific folder in my Google drive account. My Rclone account name will be NAME for the purpose of this post&lt;/p&gt;\n\n&lt;p&gt;The folder that I&amp;#39;m looking to copy is in this chain &amp;quot;4tb&amp;gt;offloaded footage&amp;gt;categorized&amp;gt;DJI&amp;gt;2021&lt;/p&gt;\n\n&lt;p&gt;and I&amp;#39;m looking to copy this to my google drive &amp;quot;My Drive&amp;gt;Categorized footage&amp;gt;DJI&amp;gt;2021&lt;/p&gt;\n\n&lt;p&gt;Here is the terminal command that I&amp;#39;m using&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;rclone -v sync /Volumes/4TB\\ Offloaded\\ Footage/Categorized/DJI/2021 NAME:\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then what do I put after this to get the contents copied into &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My Drive&amp;gt;Categorized footage&amp;gt;DJI&amp;gt;2021&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106m302", "is_robot_indexable": true, "report_reasons": null, "author": "AllAboutGadgets", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106m302/using_rclone_to_copy_folder_to_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106m302/using_rclone_to_copy_folder_to_folder/", "subreddit_subscribers": 664826, "created_utc": 1673192235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks,\n\nNot sure if this is the right place to post this question, but here goes.\n\nI have boxes and boxes of photography slides that I'd like to digitise. Currently, my solution is to buy something like [https://www.amazon.co.uk/dp/B0074H6NTO](https://www.amazon.co.uk/dp/B0074H6NTO?tag=georiot-trd-21&amp;th=1&amp;ascsubtag=dcw-gb-8778368215956837000-21&amp;geniuslink=true), but that involves me having to fill the trays with 4 slides at a time. Obviously not totally feasible with thousands of slides.\n\nDoes anyone have any experience with a project like this? Or ideas on how to proceed?\n\nCheers.", "author_fullname": "t2_3ued9syv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitising thousands of 35mm photo slides", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106j8ia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673184407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;Not sure if this is the right place to post this question, but here goes.&lt;/p&gt;\n\n&lt;p&gt;I have boxes and boxes of photography slides that I&amp;#39;d like to digitise. Currently, my solution is to buy something like &lt;a href=\"https://www.amazon.co.uk/dp/B0074H6NTO?tag=georiot-trd-21&amp;amp;th=1&amp;amp;ascsubtag=dcw-gb-8778368215956837000-21&amp;amp;geniuslink=true\"&gt;https://www.amazon.co.uk/dp/B0074H6NTO&lt;/a&gt;, but that involves me having to fill the trays with 4 slides at a time. Obviously not totally feasible with thousands of slides.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience with a project like this? Or ideas on how to proceed?&lt;/p&gt;\n\n&lt;p&gt;Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106j8ia", "is_robot_indexable": true, "report_reasons": null, "author": "thisismyfirsttime123", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106j8ia/digitising_thousands_of_35mm_photo_slides/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106j8ia/digitising_thousands_of_35mm_photo_slides/", "subreddit_subscribers": 664826, "created_utc": 1673184407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just had an external hard drive become corrupted and unreadable. I thought this would be a good opportunity to upgrade my setup, but I have some questions.\n\n&amp;#x200B;\n\n1. I was thinking of getting regular hard drives and a hard drive toaster rather than external drives. Is there a consensus as to which setup is better?\n\n&amp;#x200B;\n\n2. I need to transfer data between linux and windows computers. I was using the ExFat file system for this. Is this a good idea or is there a better file system?\n\n&amp;#x200B;\n\n3. I was told recently that drives larger than 2TB are far more susceptible to corruption. Is this true? \n\n&amp;#x200B;\n\n4. What programs would you recommend for data recovery on a hard drive?\n\n&amp;#x200B;\n\nThank you", "author_fullname": "t2_x9tme", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me upgrade my storage setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106ojil", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673198293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just had an external hard drive become corrupted and unreadable. I thought this would be a good opportunity to upgrade my setup, but I have some questions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I was thinking of getting regular hard drives and a hard drive toaster rather than external drives. Is there a consensus as to which setup is better?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I need to transfer data between linux and windows computers. I was using the ExFat file system for this. Is this a good idea or is there a better file system?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I was told recently that drives larger than 2TB are far more susceptible to corruption. Is this true? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What programs would you recommend for data recovery on a hard drive?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106ojil", "is_robot_indexable": true, "report_reasons": null, "author": "archmage24601", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106ojil/help_me_upgrade_my_storage_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106ojil/help_me_upgrade_my_storage_setup/", "subreddit_subscribers": 664826, "created_utc": 1673198293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't run raid or NAS, at least not yet, just a simple DAS(?) setup with two drives (19tb) and a single backup drive (13tb). In the future I plan to get more drives and may top out at a total of 5-6 drives.\n\nWhat's the ideal solution for this? Get a large PC case like the Meshify 2 or a smaller case and get like a 5-8 bay enclosure?", "author_fullname": "t2_hrdo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large PC case vs SFF with external HDD enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1067u94", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673146768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t run raid or NAS, at least not yet, just a simple DAS(?) setup with two drives (19tb) and a single backup drive (13tb). In the future I plan to get more drives and may top out at a total of 5-6 drives.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the ideal solution for this? Get a large PC case like the Meshify 2 or a smaller case and get like a 5-8 bay enclosure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1067u94", "is_robot_indexable": true, "report_reasons": null, "author": "c9898", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1067u94/large_pc_case_vs_sff_with_external_hdd_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1067u94/large_pc_case_vs_sff_with_external_hdd_enclosure/", "subreddit_subscribers": 664826, "created_utc": 1673146768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm interested in setting up a CCTV system, 1 security camera only.\n\nWhere I'm at in the middle of nowhere (Australia) there isn't fixed line, and there is barely any data signal with most carriers.\n\nWhat I'd like is to have the security camera recording to a local system, let's say a simple computer setup with some HDDs that constantly records with a set retention.\n\nBut I'd also want to be able to remotely view what's happening when I am not at the location, and being limited with internet options (cellular plans only) the cost of 24/7 streaming online would not be viable. So, I thought about a system that: records locally, then every 1 hour (more or less) uploads 1 photo to a cloud service, let's say back blaze (from a portable wifi router connected via SIM). That way, I can look to check to see if there is anything gone occasionally without having to livestream which would use a huge amount of data, and if something did happen, I can go check the local storage and see what exactly happened.\n\nIdeally, the only monthly costs would be:\n\nSIM data plan\n\nBackblaze\n\nIf anyone has some knowledge on what cameras are the best option or how I could achieve this, if i'm on the right track etc please feel free to share!", "author_fullname": "t2_vgleq1ng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Outback CCTV system with limited internet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106elia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673168431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in setting up a CCTV system, 1 security camera only.&lt;/p&gt;\n\n&lt;p&gt;Where I&amp;#39;m at in the middle of nowhere (Australia) there isn&amp;#39;t fixed line, and there is barely any data signal with most carriers.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d like is to have the security camera recording to a local system, let&amp;#39;s say a simple computer setup with some HDDs that constantly records with a set retention.&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;d also want to be able to remotely view what&amp;#39;s happening when I am not at the location, and being limited with internet options (cellular plans only) the cost of 24/7 streaming online would not be viable. So, I thought about a system that: records locally, then every 1 hour (more or less) uploads 1 photo to a cloud service, let&amp;#39;s say back blaze (from a portable wifi router connected via SIM). That way, I can look to check to see if there is anything gone occasionally without having to livestream which would use a huge amount of data, and if something did happen, I can go check the local storage and see what exactly happened.&lt;/p&gt;\n\n&lt;p&gt;Ideally, the only monthly costs would be:&lt;/p&gt;\n\n&lt;p&gt;SIM data plan&lt;/p&gt;\n\n&lt;p&gt;Backblaze&lt;/p&gt;\n\n&lt;p&gt;If anyone has some knowledge on what cameras are the best option or how I could achieve this, if i&amp;#39;m on the right track etc please feel free to share!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106elia", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Wing9364", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106elia/outback_cctv_system_with_limited_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106elia/outback_cctv_system_with_limited_internet/", "subreddit_subscribers": 664826, "created_utc": 1673168431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for an image host (like imagur) that does not compress the image I upload. 100% lossless. I don't really care about features other than I would need to be able to see it from anywhere so would other people. Thanks.", "author_fullname": "t2_usun3qeu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lossless Image Hosting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106d1dr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673162829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for an image host (like imagur) that does not compress the image I upload. 100% lossless. I don&amp;#39;t really care about features other than I would need to be able to see it from anywhere so would other people. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106d1dr", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedTennis23", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106d1dr/lossless_image_hosting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106d1dr/lossless_image_hosting/", "subreddit_subscribers": 664826, "created_utc": 1673162829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm wondering if I'm weird or not... but I enjoy watching my downloads go and mental place bets on which download will finish first. Does anyone else do this, or am I just... weird?", "author_fullname": "t2_8zyu4htp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else watch their downloads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10701td", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673225968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if I&amp;#39;m weird or not... but I enjoy watching my downloads go and mental place bets on which download will finish first. Does anyone else do this, or am I just... weird?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "70TB usable, 48TB backup, 70TB cloud backup", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10701td", "is_robot_indexable": true, "report_reasons": null, "author": "ComputingElephant", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10701td/does_anyone_else_watch_their_downloads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10701td/does_anyone_else_watch_their_downloads/", "subreddit_subscribers": 664826, "created_utc": 1673225968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What I want is a copy program that runs overnight / in a certain time frame, so I can copy a NAS to a backup when the network is not in use.  It runs from 11pm to 6am &amp; at 6am it stops transferring until that night.  So it doesn't have to be restarted, but pickups up where it left off?\n\nI know I could use robocopy for starters, then schedule a task to kill it in the morning?\n\nAnything fanicier?  This would be using a Windows host with the NAS shares mapped on the Win box.\n\nIs there something I could use on UnRAID that would run on the server?", "author_fullname": "t2_d1ic8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time frame copier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106tvqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673211209.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673211024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What I want is a copy program that runs overnight / in a certain time frame, so I can copy a NAS to a backup when the network is not in use.  It runs from 11pm to 6am &amp;amp; at 6am it stops transferring until that night.  So it doesn&amp;#39;t have to be restarted, but pickups up where it left off?&lt;/p&gt;\n\n&lt;p&gt;I know I could use robocopy for starters, then schedule a task to kill it in the morning?&lt;/p&gt;\n\n&lt;p&gt;Anything fanicier?  This would be using a Windows host with the NAS shares mapped on the Win box.&lt;/p&gt;\n\n&lt;p&gt;Is there something I could use on UnRAID that would run on the server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "128TB UnRAID &amp; 72TB Synology", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106tvqy", "is_robot_indexable": true, "report_reasons": null, "author": "hacnstein", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/106tvqy/time_frame_copier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106tvqy/time_frame_copier/", "subreddit_subscribers": 664826, "created_utc": 1673211024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI am having issues with my freshly built NAS using TRUENAS Scale. I had an Intel core i7 12700K cpu from a previous build, so I chose to build around that. The other key components are as follows:\n\n1. MSI MAG B660M MORTAR WIFI DDR4\n2. Corsair Vengeance LPX 32GB (2 X 16GB) DDR4 3600\n\nI successfully installed the iso using a usb stick. I\u2019m at the stage where I should be able to access the web GUI. However, the link/ip address is not there and instead reads \u201c**The web interface could not be accessed. Please check network configuration**\u201d.\n\nHere are the other options:\n1. Configure network interface\n2. Configure network settings\n3. Configure static routes\n4. Change local administrator password\n5. Reset configuration to defaults\n6. Open TRUENAS CLI Shell\n7. Open Linux Shell\n8. Reboot\n9. Shutdown\n\nFrankly, I am not very technologically inclined and feel I\u2019ve made a mistake. I\u2019m not sure what I can do. I\u2019ve attempted looking up solutions and they tend to say it\u2019s a problem with the built in Wi-Fi (2.5G LAN and Intel Wi-Fi 6E Solution). I\u2019m in around 5 hours of research and all I\u2019m seeing is possibly getting a Intel NIC. That would be fine, but my home does not have Ethernet. \n\nThe only thing I can really think of is:\n\nA) Update the motherboard bios (not sure how to do this given it\u2019s on a NAS os)\n\nB) Buy a extremely expensive server board with w680 chipset. This would mean spending about 2x the amount of money I already have.\n\nC) Scrap it and just buy a synology which is still a net negative but at least I know it\u2019ll work. \n\nI wanted to be able to mess around with Linux and it\u2019s capabilities but this is beyond frustrating and frankly a bit demoralizing being my first experience with it.", "author_fullname": "t2_rwbgmvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TRUENAS scale error: The web interface could not be accessed. New to NAS and could use some advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106t4gb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673209207.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I am having issues with my freshly built NAS using TRUENAS Scale. I had an Intel core i7 12700K cpu from a previous build, so I chose to build around that. The other key components are as follows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;MSI MAG B660M MORTAR WIFI DDR4&lt;/li&gt;\n&lt;li&gt;Corsair Vengeance LPX 32GB (2 X 16GB) DDR4 3600&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I successfully installed the iso using a usb stick. I\u2019m at the stage where I should be able to access the web GUI. However, the link/ip address is not there and instead reads \u201c&lt;strong&gt;The web interface could not be accessed. Please check network configuration&lt;/strong&gt;\u201d.&lt;/p&gt;\n\n&lt;p&gt;Here are the other options:\n1. Configure network interface\n2. Configure network settings\n3. Configure static routes\n4. Change local administrator password\n5. Reset configuration to defaults\n6. Open TRUENAS CLI Shell\n7. Open Linux Shell\n8. Reboot\n9. Shutdown&lt;/p&gt;\n\n&lt;p&gt;Frankly, I am not very technologically inclined and feel I\u2019ve made a mistake. I\u2019m not sure what I can do. I\u2019ve attempted looking up solutions and they tend to say it\u2019s a problem with the built in Wi-Fi (2.5G LAN and Intel Wi-Fi 6E Solution). I\u2019m in around 5 hours of research and all I\u2019m seeing is possibly getting a Intel NIC. That would be fine, but my home does not have Ethernet. &lt;/p&gt;\n\n&lt;p&gt;The only thing I can really think of is:&lt;/p&gt;\n\n&lt;p&gt;A) Update the motherboard bios (not sure how to do this given it\u2019s on a NAS os)&lt;/p&gt;\n\n&lt;p&gt;B) Buy a extremely expensive server board with w680 chipset. This would mean spending about 2x the amount of money I already have.&lt;/p&gt;\n\n&lt;p&gt;C) Scrap it and just buy a synology which is still a net negative but at least I know it\u2019ll work. &lt;/p&gt;\n\n&lt;p&gt;I wanted to be able to mess around with Linux and it\u2019s capabilities but this is beyond frustrating and frankly a bit demoralizing being my first experience with it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106t4gb", "is_robot_indexable": true, "report_reasons": null, "author": "Karizmology", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106t4gb/truenas_scale_error_the_web_interface_could_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106t4gb/truenas_scale_error_the_web_interface_could_not/", "subreddit_subscribers": 664826, "created_utc": 1673209207.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried recovering a lost video using the Wayback Machine, but I get the error \"Attempts to archive this video failed.\".  Somehow, I'm still able to see slides if I hover over the bar that shows how much of the video has passed. What can I do?\n\nThis is the video:\n\n[https://web.archive.org/web/20200618135626/https://www.youtube.com/watch?v=LMlFwHpqEpU](https://web.archive.org/web/20200618135626/https://www.youtube.com/watch?v=LMlFwHpqEpU)", "author_fullname": "t2_mxw50928", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wayback Machine Error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106oxb7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673199208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried recovering a lost video using the Wayback Machine, but I get the error &amp;quot;Attempts to archive this video failed.&amp;quot;.  Somehow, I&amp;#39;m still able to see slides if I hover over the bar that shows how much of the video has passed. What can I do?&lt;/p&gt;\n\n&lt;p&gt;This is the video:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.archive.org/web/20200618135626/https://www.youtube.com/watch?v=LMlFwHpqEpU\"&gt;https://web.archive.org/web/20200618135626/https://www.youtube.com/watch?v=LMlFwHpqEpU&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106oxb7", "is_robot_indexable": true, "report_reasons": null, "author": "Adriana_Istrate", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106oxb7/wayback_machine_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106oxb7/wayback_machine_error/", "subreddit_subscribers": 664826, "created_utc": 1673199208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an external hard drive with a LOT of folders and subfolders and would like to be able to collectively and simultaneously view all of the files and folders in one of the main folders (for the purposes of sorting by date). Is that possible?", "author_fullname": "t2_i1z51n31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about viewing files in folder/subfolder tree all at once", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106ovpx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673199106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an external hard drive with a LOT of folders and subfolders and would like to be able to collectively and simultaneously view all of the files and folders in one of the main folders (for the purposes of sorting by date). Is that possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106ovpx", "is_robot_indexable": true, "report_reasons": null, "author": "tucson_throwaway1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106ovpx/question_about_viewing_files_in_foldersubfolder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106ovpx/question_about_viewing_files_in_foldersubfolder/", "subreddit_subscribers": 664826, "created_utc": 1673199106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently at a point in my journey where I'm looking to start planning out my storage config for my first homelab. This isn't a post asking EXACTLY what I should do but moreso trying to get a feel for what first timers don't really think about. What are common regrets you've heard or experienced when setting up the storage for homelab for the first time? I'm still deciding how much extra storage I plan on having(I know I need more than 10TB). Still deciding on a file system(I'm definitely leaning towards ZFS). Deciding whether I want to virtualize my NAS or not. For context, I plan on using this lab as part \"production\"(things like Plex, pihole, Home Assistant and a steam cache) and part testing to get more familiar with all kinds of things, from setting up a Windows domain controller to familiarizing myself with kubernetes.", "author_fullname": "t2_7sqku996", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for insight from those who've been there.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106exgz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673169614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently at a point in my journey where I&amp;#39;m looking to start planning out my storage config for my first homelab. This isn&amp;#39;t a post asking EXACTLY what I should do but moreso trying to get a feel for what first timers don&amp;#39;t really think about. What are common regrets you&amp;#39;ve heard or experienced when setting up the storage for homelab for the first time? I&amp;#39;m still deciding how much extra storage I plan on having(I know I need more than 10TB). Still deciding on a file system(I&amp;#39;m definitely leaning towards ZFS). Deciding whether I want to virtualize my NAS or not. For context, I plan on using this lab as part &amp;quot;production&amp;quot;(things like Plex, pihole, Home Assistant and a steam cache) and part testing to get more familiar with all kinds of things, from setting up a Windows domain controller to familiarizing myself with kubernetes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106exgz", "is_robot_indexable": true, "report_reasons": null, "author": "RiggedyWreckt", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106exgz/looking_for_insight_from_those_whove_been_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106exgz/looking_for_insight_from_those_whove_been_there/", "subreddit_subscribers": 664826, "created_utc": 1673169614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not really sure why hardware raid is so common, I'm under the assumption that their only benefits are speed and compatibility with any system as it gets detected as a single drive. But is that it. Why should I use Software RAID. For example, Windows has software RAID but I'm not sure if its RAID or mirroring. I feel that risking a corrupted RAID controller makes hardware raid a worse choice.", "author_fullname": "t2_8lrao3fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware RAID vs Software RAID.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106b9jh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673156917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not really sure why hardware raid is so common, I&amp;#39;m under the assumption that their only benefits are speed and compatibility with any system as it gets detected as a single drive. But is that it. Why should I use Software RAID. For example, Windows has software RAID but I&amp;#39;m not sure if its RAID or mirroring. I feel that risking a corrupted RAID controller makes hardware raid a worse choice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106b9jh", "is_robot_indexable": true, "report_reasons": null, "author": "imtotallyjustadude", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106b9jh/hardware_raid_vs_software_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106b9jh/hardware_raid_vs_software_raid/", "subreddit_subscribers": 664826, "created_utc": 1673156917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had thought this would be easier since it's an Android device, but my Windows 10 PC does not seem to recognize the phone. I have installed USB drivers from the LG website, and have enabled USB debugging on the phone, but no dice. Are there any utilities that might work or alternative ways to get the files off the phone?", "author_fullname": "t2_108wws", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up all data (ideally root folder) from old Android phone (LG P500H)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_106zino", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673224564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had thought this would be easier since it&amp;#39;s an Android device, but my Windows 10 PC does not seem to recognize the phone. I have installed USB drivers from the LG website, and have enabled USB debugging on the phone, but no dice. Are there any utilities that might work or alternative ways to get the files off the phone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106zino", "is_robot_indexable": true, "report_reasons": null, "author": "jehube", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106zino/backing_up_all_data_ideally_root_folder_from_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106zino/backing_up_all_data_ideally_root_folder_from_old/", "subreddit_subscribers": 664826, "created_utc": 1673224564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm hoarding some audiofiles with looping audio and I want to only save a single loop to save space. Are there any preferrably automated tools to detect loops and clip files?", "author_fullname": "t2_vguwdx4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there tools for detecting and clipping looping audio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106uvno", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673213359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hoarding some audiofiles with looping audio and I want to only save a single loop to save space. Are there any preferrably automated tools to detect loops and clip files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106uvno", "is_robot_indexable": true, "report_reasons": null, "author": "Stock-Wolverine-4309", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106uvno/are_there_tools_for_detecting_and_clipping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106uvno/are_there_tools_for_detecting_and_clipping/", "subreddit_subscribers": 664826, "created_utc": 1673213359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basically looking to sort and tag 1000s of porn links, wish to input a URL, and to get a scraped image/thumbnail, so i dont have to do it manually. I dont think pornOrganizer, Stash and similar can do this.", "author_fullname": "t2_8porvch7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any software or website for scraping or categorizing online links for videos and thumbnails", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106rt8q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673206077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically looking to sort and tag 1000s of porn links, wish to input a URL, and to get a scraped image/thumbnail, so i dont have to do it manually. I dont think pornOrganizer, Stash and similar can do this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106rt8q", "is_robot_indexable": true, "report_reasons": null, "author": "PORNforORC", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106rt8q/is_there_any_software_or_website_for_scraping_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106rt8q/is_there_any_software_or_website_for_scraping_or/", "subreddit_subscribers": 664826, "created_utc": 1673206077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, I wanted to buy a new HDD to replace my WD Elements 4TB that lately gives me some problems. I am undecided whether to buy the same model or an alternative model in which case I would not know which one. Would someone be able to advise me on valid alternatives :)", "author_fullname": "t2_2ee66xxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on which HDD to buy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106rn2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673205667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I wanted to buy a new HDD to replace my WD Elements 4TB that lately gives me some problems. I am undecided whether to buy the same model or an alternative model in which case I would not know which one. Would someone be able to advise me on valid alternatives :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106rn2p", "is_robot_indexable": true, "report_reasons": null, "author": "xXx_F3D3_xXx", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106rn2p/advice_on_which_hdd_to_buy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106rn2p/advice_on_which_hdd_to_buy/", "subreddit_subscribers": 664826, "created_utc": 1673205667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like most of you, I've got tons of hard drives floating around. I've got a good 20+ drives sitting in a bin that I need test and determine if I want to keep or not (most are 4tb-8tb), including some which are shucked drives. For both these and future drives, I've been looking at picking a handy USB dock that I can hook up to my main workstation, and stick drives in from to time to slow clear out the back log.  \n\n\nSomething like this: [https://www.amazon.com/gp/product/B00CE65C4W?th=1](https://www.amazon.com/gp/product/B00CE65C4W?th=1)  , or possibly the two drive version of it. \n\nTask-wise, I'm looking at testing the drive, basic power on and SMART tests, pulling data off the drive (not a common occurrence), and securely wiping the drive. Performance is not a real concern at all.  \n\n\nTwo possible issues with a setup like this, whether I can access the raw SMART diagnostics of the drive and if I'll have any issues with the PWDIS/3.3V pin. I haven't used many USB/SATA bridges over the years, so not sure of the SMART data is a problem or not.   \n\n\nRegarding the 3.3V pin, handling it in  server/PC/whatever is easy enough. I generally just make sure the power for that pin is disconnected/cut up stream of the drive. Would rather not have to deal with figuring out which drives it will be an issue with and putting tape over the pins. Do USB docks even have power on that pin and/or proper support for it?   \n\n\nWhat are people's experiences with this stuff? Do I need to worry about either thing, any recommendations for or against a given dock/brand would also be appreciated.\n\n(Searching for info on r/DataHoarder and the rest of reddit didn't provide much solid information on the 3.3V pin with USB dock issue)", "author_fullname": "t2_4ct09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SATA USB Dock with support/easy solution for 3.3V Pin (PWDIS) and SMART tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106np9e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": "", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673196296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like most of you, I&amp;#39;ve got tons of hard drives floating around. I&amp;#39;ve got a good 20+ drives sitting in a bin that I need test and determine if I want to keep or not (most are 4tb-8tb), including some which are shucked drives. For both these and future drives, I&amp;#39;ve been looking at picking a handy USB dock that I can hook up to my main workstation, and stick drives in from to time to slow clear out the back log.  &lt;/p&gt;\n\n&lt;p&gt;Something like this: &lt;a href=\"https://www.amazon.com/gp/product/B00CE65C4W?th=1\"&gt;https://www.amazon.com/gp/product/B00CE65C4W?th=1&lt;/a&gt;  , or possibly the two drive version of it. &lt;/p&gt;\n\n&lt;p&gt;Task-wise, I&amp;#39;m looking at testing the drive, basic power on and SMART tests, pulling data off the drive (not a common occurrence), and securely wiping the drive. Performance is not a real concern at all.  &lt;/p&gt;\n\n&lt;p&gt;Two possible issues with a setup like this, whether I can access the raw SMART diagnostics of the drive and if I&amp;#39;ll have any issues with the PWDIS/3.3V pin. I haven&amp;#39;t used many USB/SATA bridges over the years, so not sure of the SMART data is a problem or not.   &lt;/p&gt;\n\n&lt;p&gt;Regarding the 3.3V pin, handling it in  server/PC/whatever is easy enough. I generally just make sure the power for that pin is disconnected/cut up stream of the drive. Would rather not have to deal with figuring out which drives it will be an issue with and putting tape over the pins. Do USB docks even have power on that pin and/or proper support for it?   &lt;/p&gt;\n\n&lt;p&gt;What are people&amp;#39;s experiences with this stuff? Do I need to worry about either thing, any recommendations for or against a given dock/brand would also be appreciated.&lt;/p&gt;\n\n&lt;p&gt;(Searching for info on &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; and the rest of reddit didn&amp;#39;t provide much solid information on the 3.3V pin with USB dock issue)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80+TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106np9e", "is_robot_indexable": true, "report_reasons": null, "author": "dnabre", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/106np9e/sata_usb_dock_with_supporteasy_solution_for_33v/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106np9e/sata_usb_dock_with_supporteasy_solution_for_33v/", "subreddit_subscribers": 664826, "created_utc": 1673196296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, I'm going to post this to r/datarecovery but I thought that I'd try my luck here first.\n\nI think that I've messed up my backups and need help. I've been dumb enough to make copies of my backups of my files from the first backup that I ever did, and not from the original source. \n\nI have now noticed that the original drive the backup I have been using to create the other backups with has a C5, current pending sector count of 56. Since it is a lot of images I have been storing, I have never really checked so they haven't been damaged after each copy made, untill now.\n\nMany image files have their original name and metadata, but both the preview and the image itself are completley black ([image](https://imgur.com/a/M65IWU1)).\n\nI will admit it, I'm really new to this and have never before thougt about checking my drives health. I have several copies, but they are all made from the broken drive, as said. I can't neither access the files on their original source. Is there anything that I can do?", "author_fullname": "t2_r76xkp0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current pending sector count seems to has messed with my backups and some of the photos are black, can they be saved?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_106xtyp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673220307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, I&amp;#39;m going to post this to &lt;a href=\"/r/datarecovery\"&gt;r/datarecovery&lt;/a&gt; but I thought that I&amp;#39;d try my luck here first.&lt;/p&gt;\n\n&lt;p&gt;I think that I&amp;#39;ve messed up my backups and need help. I&amp;#39;ve been dumb enough to make copies of my backups of my files from the first backup that I ever did, and not from the original source. &lt;/p&gt;\n\n&lt;p&gt;I have now noticed that the original drive the backup I have been using to create the other backups with has a C5, current pending sector count of 56. Since it is a lot of images I have been storing, I have never really checked so they haven&amp;#39;t been damaged after each copy made, untill now.&lt;/p&gt;\n\n&lt;p&gt;Many image files have their original name and metadata, but both the preview and the image itself are completley black (&lt;a href=\"https://imgur.com/a/M65IWU1\"&gt;image&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;I will admit it, I&amp;#39;m really new to this and have never before thougt about checking my drives health. I have several copies, but they are all made from the broken drive, as said. I can&amp;#39;t neither access the files on their original source. Is there anything that I can do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?auto=webp&amp;s=d49125f484592c54741315b15ddc3b975ca366ee", "width": 1382, "height": 708}, "resolutions": [{"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f639609edfc22bc00e350f88d2916803cc5c4363", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a82c47069802c6cb48167b683cb4d9356f37fc97", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=af3b74a41c678a26e5e101b33659ae565d1af8af", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c85492d04d74d0d454319db3613ac11d9b51870", "width": 640, "height": 327}, {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99ae4f9d17c247f592318019d78b5532e905865c", "width": 960, "height": 491}, {"url": "https://external-preview.redd.it/Ij9Kw7xeT5YII1WIuEW4_2Ge-hriYbPfRkYi7oTx_R8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da0e15d683998aa8507c249aa77aa78896daf477", "width": 1080, "height": 553}], "variants": {}, "id": "yh6oAHANowP4WvH7dAIuEk402LcWS_upftgQE9iJEYA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "106xtyp", "is_robot_indexable": true, "report_reasons": null, "author": "mediamystery", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/106xtyp/current_pending_sector_count_seems_to_has_messed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/106xtyp/current_pending_sector_count_seems_to_has_messed/", "subreddit_subscribers": 664826, "created_utc": 1673220307.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}