{"kind": "Listing", "data": {"after": "t3_10h5m8n", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "That's it. I was an sql dev and a data analyst before that. The closest thing I have to version control was renaming each new file with a date. I am feeling like a lamb in fire. My new coworkers are nice about but I do not want to keep asking them for help.\n\nEdit: thank you all so much", "author_fullname": "t2_89syl1dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I started a new DE job in Dec and I suck at git.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h56jr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674253244.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674241331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s it. I was an sql dev and a data analyst before that. The closest thing I have to version control was renaming each new file with a date. I am feeling like a lamb in fire. My new coworkers are nice about but I do not want to keep asking them for help.&lt;/p&gt;\n\n&lt;p&gt;Edit: thank you all so much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10h56jr", "is_robot_indexable": true, "report_reasons": null, "author": "WhyDoIHaveAnAccount9", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h56jr/i_started_a_new_de_job_in_dec_and_i_suck_at_git/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h56jr/i_started_a_new_de_job_in_dec_and_i_suck_at_git/", "subreddit_subscribers": 86916, "created_utc": 1674241331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is me multiple times a day:\n\nhttps://preview.redd.it/aajtxc8p44da1.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=fee1002c06dde822acbca49cca9f2ce85be125a5\n\nIf this is also you, you should check out this experts panel I moderated with Shirshanka Das &amp; Chad Sanderson to nail down the what, the why, and the how behind Data Contracts\n\n[https://youtu.be/jBMvb039RFU](https://youtu.be/jBMvb039RFU)\n\nWhat questions did I miss? What's still unclear when it comes to data contracts? ", "author_fullname": "t2_g7cej1g1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm once again asking: WTF is a Data Contract?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"aajtxc8p44da1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/aajtxc8p44da1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1bb91630cb16e9915dbf19438982e80dfef34a71"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/aajtxc8p44da1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4192462824bf843aff0baff302bb9ee9cb71cfcc"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/aajtxc8p44da1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a030839c3202aeadb64db0d57684cccb82d01518"}], "s": {"y": 500, "x": 500, "u": "https://preview.redd.it/aajtxc8p44da1.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=fee1002c06dde822acbca49cca9f2ce85be125a5"}, "id": "aajtxc8p44da1"}}, "name": "t3_10glhpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 23, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jBMvb039RFU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Contracts Experts Panel &amp;amp; AMA\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Contracts Experts Panel &amp; AMA", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jBMvb039RFU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Contracts Experts Panel &amp;amp; AMA\"&gt;&lt;/iframe&gt;", "author_name": "DataHub", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jBMvb039RFU/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataHubProject"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jBMvb039RFU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Contracts Experts Panel &amp;amp; AMA\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10glhpm", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UziC05KLYIAO4vNGNJMdD5UNztio0FyB6smsiyt9Rsg.jpg", "edited": 1674183785.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674183528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is me multiple times a day:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aajtxc8p44da1.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fee1002c06dde822acbca49cca9f2ce85be125a5\"&gt;https://preview.redd.it/aajtxc8p44da1.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fee1002c06dde822acbca49cca9f2ce85be125a5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If this is also you, you should check out this experts panel I moderated with Shirshanka Das &amp;amp; Chad Sanderson to nail down the what, the why, and the how behind Data Contracts&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/jBMvb039RFU\"&gt;https://youtu.be/jBMvb039RFU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What questions did I miss? What&amp;#39;s still unclear when it comes to data contracts? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rLNDsz2lGsNrU0u8ofa0QDpCQhzq0_twnDJgh0wDaFI.jpg?auto=webp&amp;v=enabled&amp;s=197d5b5d6224b216daefc252040cbd38222a0e03", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/rLNDsz2lGsNrU0u8ofa0QDpCQhzq0_twnDJgh0wDaFI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c85a2ad438df963b88581022bf16ca9ff41ffb9", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/rLNDsz2lGsNrU0u8ofa0QDpCQhzq0_twnDJgh0wDaFI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c0faf3a7ddce93de615849827ebd1ac84ad4034", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/rLNDsz2lGsNrU0u8ofa0QDpCQhzq0_twnDJgh0wDaFI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fb9b7383b116483c5c21f231d0511ce5086c5e4", "width": 320, "height": 240}], "variants": {}, "id": "68LvsX5bMLbwnnSC9RI90jGgXkWzG4t6OxEjnflKKwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10glhpm", "is_robot_indexable": true, "report_reasons": null, "author": "Brief_Actuator_8731", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10glhpm/im_once_again_asking_wtf_is_a_data_contract/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10glhpm/im_once_again_asking_wtf_is_a_data_contract/", "subreddit_subscribers": 86916, "created_utc": 1674183528.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Contracts Experts Panel &amp; AMA", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jBMvb039RFU?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Contracts Experts Panel &amp;amp; AMA\"&gt;&lt;/iframe&gt;", "author_name": "DataHub", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jBMvb039RFU/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataHubProject"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assuming the following:\n\nProgramming, DS&amp;A, discrete math, databases, networking, OS? What other subjects would -add value- to the DE?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What CS subjects are most important and/or relevant to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gxasx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674222226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming the following:&lt;/p&gt;\n\n&lt;p&gt;Programming, DS&amp;amp;A, discrete math, databases, networking, OS? What other subjects would -add value- to the DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10gxasx", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gxasx/what_cs_subjects_are_most_important_andor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gxasx/what_cs_subjects_are_most_important_andor/", "subreddit_subscribers": 86916, "created_utc": 1674222226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently at my organization, we use an on premises data warehouse. Cloud solutions have been discussed but not implemented. I have a web crawling script that downloads two XLS files, reads them, verifies their data, and then pushes it into our data warehouse. I do this task weekly and there is further comparison down the road. Our data engineer is not fond of putting this script in our VDI, okay fine. But I want to explore the concept of putting this script on a cloud VM. There is no API yet to obtain this data.\n\nI'm currently taking the DataTalks Data Engineering Zoom so I am getting introduced to the idea of a VM specifically with Google Clouse Platform. Imagine the solution is in Azure environment though because we currently use SQL Server\n\n1. How do I tie in the process of running the pipeline in the cloud and then sending it to our on prem warehouse?\n2. The pipeline develops a table of 28k records, so not too big, how much would this cost to implement on a weekly basis? Running the code and then sending the output to our data warehouse\n3. There are events when the source website is down. How would handle this error if the code is in the cloud? I want to be notified when it did not run successfully. I currently have that inside my script to tell me. \n\nI just need some guidance on this process. Thank you.", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proof of Concept: How do I transfer this pipeline to a virtual machine in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h1bkf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674232270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently at my organization, we use an on premises data warehouse. Cloud solutions have been discussed but not implemented. I have a web crawling script that downloads two XLS files, reads them, verifies their data, and then pushes it into our data warehouse. I do this task weekly and there is further comparison down the road. Our data engineer is not fond of putting this script in our VDI, okay fine. But I want to explore the concept of putting this script on a cloud VM. There is no API yet to obtain this data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently taking the DataTalks Data Engineering Zoom so I am getting introduced to the idea of a VM specifically with Google Clouse Platform. Imagine the solution is in Azure environment though because we currently use SQL Server&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do I tie in the process of running the pipeline in the cloud and then sending it to our on prem warehouse?&lt;/li&gt;\n&lt;li&gt;The pipeline develops a table of 28k records, so not too big, how much would this cost to implement on a weekly basis? Running the code and then sending the output to our data warehouse&lt;/li&gt;\n&lt;li&gt;There are events when the source website is down. How would handle this error if the code is in the cloud? I want to be notified when it did not run successfully. I currently have that inside my script to tell me. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I just need some guidance on this process. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10h1bkf", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h1bkf/proof_of_concept_how_do_i_transfer_this_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h1bkf/proof_of_concept_how_do_i_transfer_this_pipeline/", "subreddit_subscribers": 86916, "created_utc": 1674232270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering if you guys have deprecation timelines for pipelines.\n\nI was thinking a system where after a year (or some other predetermined amount of time), pipelines get evaluated and deprecated if unnecessary.\n\n I suggested this as an idea, but there were concerns about implementing such a system:\n\n1. It doesn't add business value, so if we spend too much time doing this, it will be counterproductive.\n2. There are pipelines feeding datasets that are used very infrequently, it is still important to keep old data.\n3. Ideally, all pipelines we create are used forever, so it doesn't make sense to plan on deprecating them.\n\nThe reason I feel a need for some way to systematically decrease the number of pipelines are:\n\n1. Having many pipelines makes onboarding more difficult.\n2. Costs of running pipelines and holding data unnecessarily.\n3. Increasing complexity of responsibilities and maintenance \n\nDo you guys have any thoughts on this matter? I agree with many of the counterpoints, but have no doubts we are maintaining some unnecessary pipelines.", "author_fullname": "t2_wuozf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pipeline Deprecation Timelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gntsu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674190368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if you guys have deprecation timelines for pipelines.&lt;/p&gt;\n\n&lt;p&gt;I was thinking a system where after a year (or some other predetermined amount of time), pipelines get evaluated and deprecated if unnecessary.&lt;/p&gt;\n\n&lt;p&gt;I suggested this as an idea, but there were concerns about implementing such a system:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;It doesn&amp;#39;t add business value, so if we spend too much time doing this, it will be counterproductive.&lt;/li&gt;\n&lt;li&gt;There are pipelines feeding datasets that are used very infrequently, it is still important to keep old data.&lt;/li&gt;\n&lt;li&gt;Ideally, all pipelines we create are used forever, so it doesn&amp;#39;t make sense to plan on deprecating them.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The reason I feel a need for some way to systematically decrease the number of pipelines are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Having many pipelines makes onboarding more difficult.&lt;/li&gt;\n&lt;li&gt;Costs of running pipelines and holding data unnecessarily.&lt;/li&gt;\n&lt;li&gt;Increasing complexity of responsibilities and maintenance &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you guys have any thoughts on this matter? I agree with many of the counterpoints, but have no doubts we are maintaining some unnecessary pipelines.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10gntsu", "is_robot_indexable": true, "report_reasons": null, "author": "KdyLoL", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gntsu/pipeline_deprecation_timelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gntsu/pipeline_deprecation_timelines/", "subreddit_subscribers": 86916, "created_utc": 1674190368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi,\n\nWe've provisioned an Azure Data Lake Gen2 storage account to store our blobs, and we're currently looking at different security options.\n\nWe're migrating from an Azure SQL environment but we have noticed that a lot of the security features (such as Point-in-time restore) are not available for Gen2 storage accounts. We've provisioned soft-delete for blobs, containers &amp; files, along with RA-GRS redundancy but how do we backup the storage account itself? Azure backup is not compatible so i'm interested in how you are all doing that? Is it necessary?\n\nA couple of options i've explored:\n\n1. Use Azure Data Factory to copy the blobs into a new storage account. This seems expensive &amp; you need to define too many requirements for this to be an optimal approach.\n2. Use AzCopy - seems overly complex\n\nAre you using any of the above options or something else?\n\nThanks,", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backup Azure Gen2 Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gtvny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674211639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve provisioned an Azure Data Lake Gen2 storage account to store our blobs, and we&amp;#39;re currently looking at different security options.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re migrating from an Azure SQL environment but we have noticed that a lot of the security features (such as Point-in-time restore) are not available for Gen2 storage accounts. We&amp;#39;ve provisioned soft-delete for blobs, containers &amp;amp; files, along with RA-GRS redundancy but how do we backup the storage account itself? Azure backup is not compatible so i&amp;#39;m interested in how you are all doing that? Is it necessary?&lt;/p&gt;\n\n&lt;p&gt;A couple of options i&amp;#39;ve explored:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use Azure Data Factory to copy the blobs into a new storage account. This seems expensive &amp;amp; you need to define too many requirements for this to be an optimal approach.&lt;/li&gt;\n&lt;li&gt;Use AzCopy - seems overly complex&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Are you using any of the above options or something else?&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10gtvny", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gtvny/how_to_backup_azure_gen2_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gtvny/how_to_backup_azure_gen2_data_lake/", "subreddit_subscribers": 86916, "created_utc": 1674211639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nMy friend talked me through a side project of his and I\u2019m trying to tamest its viability as well as how best we\u2019d build it. I\u2019m testing the idea elsewhere so my question here is only about execution.\n\nOne key feature of this script would be to move  highly sensitive files (formats csv, pdf, doc) from a partner\u2019s internal systems (no idea yet how they store these files) to ours in an automated fashion with a quarterly cadence. I\u2019m more on the analytics side so limited in my knowledge of options and my first thought was an s3 bucket that we set up for them and that we then retrieve the files from. Maybe some sort of sftp drive is also an option but we\u2019d need to use the best option possible in terms of security.\n\nPosting here because you\u2019re DEs. Any insight/suggestions are appreciated!", "author_fullname": "t2_h9bp3xei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automated SFTP for Highly Sensitive Files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gxbsy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674222305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;My friend talked me through a side project of his and I\u2019m trying to tamest its viability as well as how best we\u2019d build it. I\u2019m testing the idea elsewhere so my question here is only about execution.&lt;/p&gt;\n\n&lt;p&gt;One key feature of this script would be to move  highly sensitive files (formats csv, pdf, doc) from a partner\u2019s internal systems (no idea yet how they store these files) to ours in an automated fashion with a quarterly cadence. I\u2019m more on the analytics side so limited in my knowledge of options and my first thought was an s3 bucket that we set up for them and that we then retrieve the files from. Maybe some sort of sftp drive is also an option but we\u2019d need to use the best option possible in terms of security.&lt;/p&gt;\n\n&lt;p&gt;Posting here because you\u2019re DEs. Any insight/suggestions are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10gxbsy", "is_robot_indexable": true, "report_reasons": null, "author": "yrmidon", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gxbsy/automated_sftp_for_highly_sensitive_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gxbsy/automated_sftp_for_highly_sensitive_files/", "subreddit_subscribers": 86916, "created_utc": 1674222305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have a Kafka topic containing different event types and these events may have significantly different schemas.\n\nI am reading from the topic with a spark structured streaming job, values are in avro format.\n\nIn snowflake, this is perfectly fine because these values are stored as variant type, which allows completely different data structures and schema is enforced only when data is read.\n\nIs there anything similar in Spark? It is true that I can keep the values as byte arrays, but then I need to connect to the schema registry everytime I want to deserialize data. Moreover, if I wanted to consume this data in Athena, I am not sure how to provide the proper schema from the registry (or keep it up to date).\n\nIt is perfectly fine if the soluton won't let me read one or more event types at once, I would like to partition by event_type and read each type individually.", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark equivalent of Snowflake's variant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gqt0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674204756.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674200211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have a Kafka topic containing different event types and these events may have significantly different schemas.&lt;/p&gt;\n\n&lt;p&gt;I am reading from the topic with a spark structured streaming job, values are in avro format.&lt;/p&gt;\n\n&lt;p&gt;In snowflake, this is perfectly fine because these values are stored as variant type, which allows completely different data structures and schema is enforced only when data is read.&lt;/p&gt;\n\n&lt;p&gt;Is there anything similar in Spark? It is true that I can keep the values as byte arrays, but then I need to connect to the schema registry everytime I want to deserialize data. Moreover, if I wanted to consume this data in Athena, I am not sure how to provide the proper schema from the registry (or keep it up to date).&lt;/p&gt;\n\n&lt;p&gt;It is perfectly fine if the soluton won&amp;#39;t let me read one or more event types at once, I would like to partition by event_type and read each type individually.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10gqt0f", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10gqt0f/spark_equivalent_of_snowflakes_variant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gqt0f/spark_equivalent_of_snowflakes_variant/", "subreddit_subscribers": 86916, "created_utc": 1674200211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Earlier this week, we started seeing an issue where a DBT build seems to clog up Redshift. The build starts and runs for a bit, then it freezes (in terminal). Inside Redshift, the CPU load spikes to 100% for a few minutes, then comes back down. After 5 min or so the load is back to baseline around 6%, but if I check `svv_transactions` there are 423 entries. \n\nThis just started after running without issue for a couple months. We've been adding more models of course, but nothing crazy has changed. I have a few ideas like turning down the number of threads, but I'm not sure what the root cause is, so I'm afraid this will just come back again in the future.   \n\n\nHas anyone seen anything like this?", "author_fullname": "t2_4mt61lqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Crushing / Locking Up Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gmkn3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674186606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Earlier this week, we started seeing an issue where a DBT build seems to clog up Redshift. The build starts and runs for a bit, then it freezes (in terminal). Inside Redshift, the CPU load spikes to 100% for a few minutes, then comes back down. After 5 min or so the load is back to baseline around 6%, but if I check &lt;code&gt;svv_transactions&lt;/code&gt; there are 423 entries. &lt;/p&gt;\n\n&lt;p&gt;This just started after running without issue for a couple months. We&amp;#39;ve been adding more models of course, but nothing crazy has changed. I have a few ideas like turning down the number of threads, but I&amp;#39;m not sure what the root cause is, so I&amp;#39;m afraid this will just come back again in the future.   &lt;/p&gt;\n\n&lt;p&gt;Has anyone seen anything like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10gmkn3", "is_robot_indexable": true, "report_reasons": null, "author": "cbc-bear", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gmkn3/dbt_crushing_locking_up_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gmkn3/dbt_crushing_locking_up_redshift/", "subreddit_subscribers": 86916, "created_utc": 1674186606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anybody recommend any DE conferences coming up this year? I work with snowflake mainly and would love to attend the summit in Vegas in June but it is close to $2000- not to mention hotel/travel fees. Is this standard for conferences? Or way too much? \n\nAlso, has anyone had any success in getting discounts to conferences based on being existing partners vs potential new clients?", "author_fullname": "t2_28pdy33m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Conferences ($nowflake)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h5uyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674242964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody recommend any DE conferences coming up this year? I work with snowflake mainly and would love to attend the summit in Vegas in June but it is close to $2000- not to mention hotel/travel fees. Is this standard for conferences? Or way too much? &lt;/p&gt;\n\n&lt;p&gt;Also, has anyone had any success in getting discounts to conferences based on being existing partners vs potential new clients?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10h5uyj", "is_robot_indexable": true, "report_reasons": null, "author": "seandog107", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h5uyj/de_conferences_nowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h5uyj/de_conferences_nowflake/", "subreddit_subscribers": 86916, "created_utc": 1674242964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interested to hear the kinds of internal tooling people have created. Is there a tool you have made that had a significant impact on your team or organisation?", "author_fullname": "t2_ij7c2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internal tooling ideas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gsykp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674208338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested to hear the kinds of internal tooling people have created. Is there a tool you have made that had a significant impact on your team or organisation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10gsykp", "is_robot_indexable": true, "report_reasons": null, "author": "TehMightyDuk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gsykp/internal_tooling_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gsykp/internal_tooling_ideas/", "subreddit_subscribers": 86916, "created_utc": 1674208338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I appreciate any advice anyone might have for this seemingly simple scenario.\n\n&amp;#x200B;\n\nI have two lambda functions in AWS populating two separate tables in an RDS instance on a batch cycle. The tables look like:\n\n|uuid\\_table1 | name | Biographic\\_details |  \nand   \n|uuid\\_table2 |  uuid\\_table1 | Important\\_info |  \n\n\nI want to create a foreign key relation between the two tables, but if I try to insert a record into table 2 before a corresponding record in table 1 I get an error that the uuid\\_1 does not exist yet. Due to the race condition of the two lambdas in parallel (and other upstream things) I can't guarantee table 1 will be populated before table 2. Is there a way I can *easily* still create this key relationship without adding a bunch of infrastructure to enforce the order of events. \n\n&amp;#x200B;\n\nThanks in advance.", "author_fullname": "t2_9sx698nr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to solve this simple problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h775x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674246336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I appreciate any advice anyone might have for this seemingly simple scenario.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have two lambda functions in AWS populating two separate tables in an RDS instance on a batch cycle. The tables look like:&lt;/p&gt;\n\n&lt;p&gt;|uuid_table1 | name | Biographic_details |&lt;br/&gt;\nand&lt;br/&gt;\n|uuid_table2 |  uuid_table1 | Important_info |  &lt;/p&gt;\n\n&lt;p&gt;I want to create a foreign key relation between the two tables, but if I try to insert a record into table 2 before a corresponding record in table 1 I get an error that the uuid_1 does not exist yet. Due to the race condition of the two lambdas in parallel (and other upstream things) I can&amp;#39;t guarantee table 1 will be populated before table 2. Is there a way I can &lt;em&gt;easily&lt;/em&gt; still create this key relationship without adding a bunch of infrastructure to enforce the order of events. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10h775x", "is_robot_indexable": true, "report_reasons": null, "author": "goldenBoardPhD", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h775x/how_to_solve_this_simple_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h775x/how_to_solve_this_simple_problem/", "subreddit_subscribers": 86916, "created_utc": 1674246336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_74uu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interested in learning more about data pipelines? PostgreSQL is a great place to start, being 100% open source with an active community for over 35 years. Check out this course for a high-level intro to ETL/ELT data pipelines using Postgres!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "name": "t3_10h3u7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 70, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9VuDnM22UvMMZh9-87raMLFb6rgq4aG0R99bPZPQo9k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674238175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "linkedin.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.linkedin.com/learning-login/share?forceAccount=false&amp;redirect=https%3A%2F%2Fwww.linkedin.com%2Flearning%2Fetl-and-elt-in-postgresql%3Ftrk%3Dshare_ent_url%26shareId%3DY%252BfFsU%252FuRAaij7RT%252BnkCiQ%253D%253D", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NAYG6uJDJ1uhjy7DeXZVvRmPhV4Fck65Z17klZ-hWgs.jpg?auto=webp&amp;v=enabled&amp;s=12bc24318a35c976064a0de3b78caedc67e62205", "width": 100, "height": 60}, "resolutions": [], "variants": {}, "id": "-J6Tl5ZHiNQdf-i2UP4--Cgt2ryDo2EtQI3DX8Wih1w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10h3u7i", "is_robot_indexable": true, "report_reasons": null, "author": "aelwydevenstar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h3u7i/interested_in_learning_more_about_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.linkedin.com/learning-login/share?forceAccount=false&amp;redirect=https%3A%2F%2Fwww.linkedin.com%2Flearning%2Fetl-and-elt-in-postgresql%3Ftrk%3Dshare_ent_url%26shareId%3DY%252BfFsU%252FuRAaij7RT%252BnkCiQ%253D%253D", "subreddit_subscribers": 86916, "created_utc": 1674238175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I would like to know the simple existing methods for an incremental data refresh. The data source I have comes from many files located in a folder, on each file there are many lines so the refresh has become very slow. So far I\u2019ve been using Power Query on Excel to do it (I filter what I need), but now I have months of information and it takes more than 30 minutes to finish. I tried doing it with Power BI service using the Incremental Refresh tool, but the first refresh on the server takes so long it never finishes (I waited 24 hours and it didn\u2019t finish), so I am looking for other methods to do it.\n\nI cannot use any cloud service since the company is small and has limited resources, if anyone knows a method to solve this problem I will be very grateful \ud83d\ude4c\ud83c\udffd", "author_fullname": "t2_ngtjo999", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple Methods for Incremental Data Refresh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h13z0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674231759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I would like to know the simple existing methods for an incremental data refresh. The data source I have comes from many files located in a folder, on each file there are many lines so the refresh has become very slow. So far I\u2019ve been using Power Query on Excel to do it (I filter what I need), but now I have months of information and it takes more than 30 minutes to finish. I tried doing it with Power BI service using the Incremental Refresh tool, but the first refresh on the server takes so long it never finishes (I waited 24 hours and it didn\u2019t finish), so I am looking for other methods to do it.&lt;/p&gt;\n\n&lt;p&gt;I cannot use any cloud service since the company is small and has limited resources, if anyone knows a method to solve this problem I will be very grateful \ud83d\ude4c\ud83c\udffd&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10h13z0", "is_robot_indexable": true, "report_reasons": null, "author": "sergionicolas28", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h13z0/simple_methods_for_incremental_data_refresh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h13z0/simple_methods_for_incremental_data_refresh/", "subreddit_subscribers": 86916, "created_utc": 1674231759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Airbnb data engineer discourses about low-code tools [https://medium.com/@eczachly/should-data-engineers-fear-low-code-tools-619c4c6cb612](https://medium.com/@eczachly/should-data-engineers-fear-low-code-tools-619c4c6cb612). What are your thoughts on the topic?", "author_fullname": "t2_d834g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data engineers fear low-code tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gsa49", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674205716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Airbnb data engineer discourses about low-code tools &lt;a href=\"https://medium.com/@eczachly/should-data-engineers-fear-low-code-tools-619c4c6cb612\"&gt;https://medium.com/@eczachly/should-data-engineers-fear-low-code-tools-619c4c6cb612&lt;/a&gt;. What are your thoughts on the topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10gsa49", "is_robot_indexable": true, "report_reasons": null, "author": "an_tonova", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gsa49/should_data_engineers_fear_lowcode_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gsa49/should_data_engineers_fear_lowcode_tools/", "subreddit_subscribers": 86916, "created_utc": 1674205716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does one attach a dollar value to data engineering projects that concern tightening of security \u2013 improving access control for Snowflake data, improved methods of authentication into AWS from within GitHub, Jenkins, etc. I\u2019m pushing for initiatives like these but need to justify it to the business using monetary benefits.", "author_fullname": "t2_4y7rb87m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assigning dollar value benefits to projects concerning security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gpnj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674196145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does one attach a dollar value to data engineering projects that concern tightening of security \u2013 improving access control for Snowflake data, improved methods of authentication into AWS from within GitHub, Jenkins, etc. I\u2019m pushing for initiatives like these but need to justify it to the business using monetary benefits.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10gpnj4", "is_robot_indexable": true, "report_reasons": null, "author": "ElectricalFilm2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gpnj4/assigning_dollar_value_benefits_to_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gpnj4/assigning_dollar_value_benefits_to_projects/", "subreddit_subscribers": 86916, "created_utc": 1674196145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI've been lurking on this subreddit for awhile and have been learning a lot based on all the great posts here. Recently I completed an end to end project after also working through the DataTalksClub zoomcamp based on their 2022 youtube videos. I'm in a semi technical role now although it's similar to an SAP-FI specialist so I don't really use python or SQL as part of my job.\n\nI've been spending a lot of time practicing both my SQL/python skills and learning data warehousing fundamentals (normalization/denormalization, fact/dimension/star/snowflake, OLAP/OLTP, etc.) and am hopefully at a point where I can start applying to junior DE jobs. I'm also half way through the computational track of the Georgia Tech Analytics masters so I have been getting a lot of practice through that program as well.\n\nIf anyone has any feedback on either my project or my resume it would be much appreciated. Also, on the off chance anyone knows of a job opportunity that might be a good fit feel free to DM me.\n\n[End to End Data Pipeline Project](https://medium.com/@tgrady101/building-an-end-to-end-data-engineering-project-f8f34b334648)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/vz6kkpjwq7da1.jpg?width=2550&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3b014c7e8d75832bec0d9d694e64fa6fa8f543c4", "author_fullname": "t2_re0fe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another Aspiring Data Engineer: Project/Resume Feedback Request", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vz6kkpjwq7da1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc7f0a59a20dbe6d4eb57e91abcaacf82aeb5458"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43b8b86ef5981d1d0d5902914af0eee954d39c56"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0edc9b181be94c7ce532418117c1e4e672c5487"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b514295541b19ce57aed46f95bc770ca2274ccf"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6660a51ed2c00471551ac361a2813f5225bbe595"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f64a38d9d8105de69c5dad65f0cd93db33cf294b"}], "s": {"y": 3300, "x": 2550, "u": "https://preview.redd.it/vz6kkpjwq7da1.jpg?width=2550&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3b014c7e8d75832bec0d9d694e64fa6fa8f543c4"}, "id": "vz6kkpjwq7da1"}}, "name": "t3_10gmrri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8_OpWY3hRkZ0kownCpKBEtGG3l1l1DJTz_-nHbPQ3G8.jpg", "edited": 1674226994.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674187212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been lurking on this subreddit for awhile and have been learning a lot based on all the great posts here. Recently I completed an end to end project after also working through the DataTalksClub zoomcamp based on their 2022 youtube videos. I&amp;#39;m in a semi technical role now although it&amp;#39;s similar to an SAP-FI specialist so I don&amp;#39;t really use python or SQL as part of my job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been spending a lot of time practicing both my SQL/python skills and learning data warehousing fundamentals (normalization/denormalization, fact/dimension/star/snowflake, OLAP/OLTP, etc.) and am hopefully at a point where I can start applying to junior DE jobs. I&amp;#39;m also half way through the computational track of the Georgia Tech Analytics masters so I have been getting a lot of practice through that program as well.&lt;/p&gt;\n\n&lt;p&gt;If anyone has any feedback on either my project or my resume it would be much appreciated. Also, on the off chance anyone knows of a job opportunity that might be a good fit feel free to DM me.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@tgrady101/building-an-end-to-end-data-engineering-project-f8f34b334648\"&gt;End to End Data Pipeline Project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vz6kkpjwq7da1.jpg?width=2550&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3b014c7e8d75832bec0d9d694e64fa6fa8f543c4\"&gt;https://preview.redd.it/vz6kkpjwq7da1.jpg?width=2550&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3b014c7e8d75832bec0d9d694e64fa6fa8f543c4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10gmrri", "is_robot_indexable": true, "report_reasons": null, "author": "Jovius10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gmrri/another_aspiring_data_engineer_projectresume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gmrri/another_aspiring_data_engineer_projectresume/", "subreddit_subscribers": 86916, "created_utc": 1674187212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Little background, I'm 28, dropped out of my community college a while ago because I needed to focus on work to pay some bills. Since then I worked at Fry's doing tech support for 4 years, then have been doing Helpdesk for the past 3 years. Really want to get out of the Helpdesk and do something higher up.\n\nI've been struggling with figuring out what I want to actually do as a career in the long term. So far I've narrowed it down to backend development, data engineering, or data analytics. \n\nI know that not having any degree is a huge detriment to me and I won't be able to land any data engineering role with just projects and Helpdesk experience.\n\nSo what I was hoping to do was keep my current Helpdesk job and use most if not all of my free time to study backend development and create projects in order to land a development job ASAP. Then once I have a role where I can work on the backend, I will use my free time to study and work on projects more focused on data engineering. \n\nSo I guess what I really want to ask is, how realistic is it land a data engineering job with a few years of backend development experience and no degree?\n\nI'd love to go back to school and get my Bachelor's in CS, but I just cannot afford to do that, at least in the next few years.", "author_fullname": "t2_wb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a good roadmap for someone with no experience or college degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h5c00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674241692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Little background, I&amp;#39;m 28, dropped out of my community college a while ago because I needed to focus on work to pay some bills. Since then I worked at Fry&amp;#39;s doing tech support for 4 years, then have been doing Helpdesk for the past 3 years. Really want to get out of the Helpdesk and do something higher up.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been struggling with figuring out what I want to actually do as a career in the long term. So far I&amp;#39;ve narrowed it down to backend development, data engineering, or data analytics. &lt;/p&gt;\n\n&lt;p&gt;I know that not having any degree is a huge detriment to me and I won&amp;#39;t be able to land any data engineering role with just projects and Helpdesk experience.&lt;/p&gt;\n\n&lt;p&gt;So what I was hoping to do was keep my current Helpdesk job and use most if not all of my free time to study backend development and create projects in order to land a development job ASAP. Then once I have a role where I can work on the backend, I will use my free time to study and work on projects more focused on data engineering. &lt;/p&gt;\n\n&lt;p&gt;So I guess what I really want to ask is, how realistic is it land a data engineering job with a few years of backend development experience and no degree?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to go back to school and get my Bachelor&amp;#39;s in CS, but I just cannot afford to do that, at least in the next few years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10h5c00", "is_robot_indexable": true, "report_reasons": null, "author": "TinyStego", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h5c00/is_this_a_good_roadmap_for_someone_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h5c00/is_this_a_good_roadmap_for_someone_with_no/", "subreddit_subscribers": 86916, "created_utc": 1674241692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello  I need help with a job title/brand question. \n\nPeople will post they are moving into data platform and I've seen data operations also mentioned.  How do these roles differ?\n\nAbout me. My title is SRE and what I do aligns with the Google definition.  My day job is provisioning and maintaining a on-premise Hadoop platform that mainly ingests from Kafka.  I'm able to write simple beam jobs and I attend office hours to help customers with tuning/fixing their pipelines.  Does this mean I work in data platform or am I more data operations?\n\nI checked the wiki section on data engineer vs X but these aren't listed. I would be happy to submit a PR based on this discussion. \n\nThanks", "author_fullname": "t2_lms647f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Operations vs Data Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h4u9d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674240547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello  I need help with a job title/brand question. &lt;/p&gt;\n\n&lt;p&gt;People will post they are moving into data platform and I&amp;#39;ve seen data operations also mentioned.  How do these roles differ?&lt;/p&gt;\n\n&lt;p&gt;About me. My title is SRE and what I do aligns with the Google definition.  My day job is provisioning and maintaining a on-premise Hadoop platform that mainly ingests from Kafka.  I&amp;#39;m able to write simple beam jobs and I attend office hours to help customers with tuning/fixing their pipelines.  Does this mean I work in data platform or am I more data operations?&lt;/p&gt;\n\n&lt;p&gt;I checked the wiki section on data engineer vs X but these aren&amp;#39;t listed. I would be happy to submit a PR based on this discussion. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10h4u9d", "is_robot_indexable": true, "report_reasons": null, "author": "toakao", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h4u9d/data_operations_vs_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h4u9d/data_operations_vs_data_platform/", "subreddit_subscribers": 86916, "created_utc": 1674240547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey! So I\u2019m a data analyst. I really enjoy my role, particularly when I\u2019m writing SQL. My ideal day is probably writing and testing code. I care less about visualisation and analysis. \n\nIn my personal time I learn and write Python (do this a little in my job). My favourite projects are ones in which I build stuff to deliver data to people, like Twitter bots.\n\nI feel like a lot of analysts I know want to jump into data science but machine learning, AI and all that jazz doesn\u2019t really appeal to me if I\u2019m being honest.\n\nDo you think data engineering is a career I\u2019d be interested in?", "author_fullname": "t2_a7uw8rfx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoping to get your advice on whether data engineering would be suited to me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10gy58s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674224463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! So I\u2019m a data analyst. I really enjoy my role, particularly when I\u2019m writing SQL. My ideal day is probably writing and testing code. I care less about visualisation and analysis. &lt;/p&gt;\n\n&lt;p&gt;In my personal time I learn and write Python (do this a little in my job). My favourite projects are ones in which I build stuff to deliver data to people, like Twitter bots.&lt;/p&gt;\n\n&lt;p&gt;I feel like a lot of analysts I know want to jump into data science but machine learning, AI and all that jazz doesn\u2019t really appeal to me if I\u2019m being honest.&lt;/p&gt;\n\n&lt;p&gt;Do you think data engineering is a career I\u2019d be interested in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10gy58s", "is_robot_indexable": true, "report_reasons": null, "author": "ruthlesscattle", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10gy58s/hoping_to_get_your_advice_on_whether_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10gy58s/hoping_to_get_your_advice_on_whether_data/", "subreddit_subscribers": 86916, "created_utc": 1674224463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you ever designed a lakehouse/datawarehouse - Top Down ( KPI-&gt; Use Case-&gt;Architecture -&gt; ETL) or Bottom Up ( Architecture -&gt; ETL -&gt; Use Case -&gt; KPI ) ? What were the lessons learned ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trade off - Top Down vs Bottom up Approach of Data Estate Set Up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10grc86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674202189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you ever designed a lakehouse/datawarehouse - Top Down ( KPI-&amp;gt; Use Case-&amp;gt;Architecture -&amp;gt; ETL) or Bottom Up ( Architecture -&amp;gt; ETL -&amp;gt; Use Case -&amp;gt; KPI ) ? What were the lessons learned ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10grc86", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10grc86/trade_off_top_down_vs_bottom_up_approach_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10grc86/trade_off_top_down_vs_bottom_up_approach_of_data/", "subreddit_subscribers": 86916, "created_utc": 1674202189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a new graduate looking for any tips on my resume for applying to data engineering roles. If you have any advice regarding DE projects I should do to become a more qualified candidate that would be especially helpful.\n\n[Resume](https://preview.redd.it/o24ryiwyxada1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9ed825dcb644005efbfab9f20931aaf0b321189c)", "author_fullname": "t2_gnme5lnf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume advice for an aspiring data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"o24ryiwyxada1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ba0967d047394a36cd0c63878c3dc992e6a5a32a"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61188993d2d7d21d10c3a3e1179be4502c332849"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eab1abd31558b0cb1ed9c6b54366a719c4da551c"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04b8d2cd61297d7bbab81de9846ca91a3ba698a6"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a506e65e13b01d02d73ce4c06a747faa2927dd14"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c309b003ba7eb0af5dd3d886caeb361c836152d"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/o24ryiwyxada1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9ed825dcb644005efbfab9f20931aaf0b321189c"}, "id": "o24ryiwyxada1"}}, "name": "t3_10hfljp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wiuQDhyEquVf2Ay-5Of1m0NzmrlopmdEKCNM4X8X_qo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674265733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a new graduate looking for any tips on my resume for applying to data engineering roles. If you have any advice regarding DE projects I should do to become a more qualified candidate that would be especially helpful.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/o24ryiwyxada1.jpg?width=1700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9ed825dcb644005efbfab9f20931aaf0b321189c\"&gt;Resume&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10hfljp", "is_robot_indexable": true, "report_reasons": null, "author": "d_Milt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10hfljp/resume_advice_for_an_aspiring_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10hfljp/resume_advice_for_an_aspiring_data_engineer/", "subreddit_subscribers": 86916, "created_utc": 1674265733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_71x5v4dp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rip me apart doods! Thank you so much!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10heg22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/O7IE83xgNoIEnbByFcpczlg_2A36aXDgEXtPmw04CO0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674262336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bgms03ti5cda1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bgms03ti5cda1.jpg?auto=webp&amp;v=enabled&amp;s=af8b1a0c695d0f4e259b8b68a0a24c796e8f8185", "width": 750, "height": 888}, "resolutions": [{"url": "https://preview.redd.it/bgms03ti5cda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c779b43264a4564a64b1dd915f67768fdf70a88", "width": 108, "height": 127}, {"url": "https://preview.redd.it/bgms03ti5cda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a80713b986a87110be8fb207ded04f6b26d83e7", "width": 216, "height": 255}, {"url": "https://preview.redd.it/bgms03ti5cda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8db78561de6d3cf919137a7a75b34bef91ca11b", "width": 320, "height": 378}, {"url": "https://preview.redd.it/bgms03ti5cda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f7d67691ca233f7fe2db72882afcd06a386bc6b", "width": 640, "height": 757}], "variants": {}, "id": "ljLfLvhRF4wAuEaTOmW3iVOcElHzqrzdA2IHBQSonXk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10heg22", "is_robot_indexable": true, "report_reasons": null, "author": "Emosk8rboi42969", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10heg22/rip_me_apart_doods_thank_you_so_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bgms03ti5cda1.jpg", "subreddit_subscribers": 86916, "created_utc": 1674262336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see the feature and at times my eyes just glaze over the information so first is to understand what to look at and why as well how to action value off it. \n\nalso , is it buggy ?\n\nEx:\n\nTrying to profile what is more efficient:\n\nQ1:\nSelect * from table where column not like \u2018t%\u2019\n\nQ2:\n\nSelect * from table where column not like \u2018%t%\u2019", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use snowflake profile feature..effectively?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h6zr9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674245799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see the feature and at times my eyes just glaze over the information so first is to understand what to look at and why as well how to action value off it. &lt;/p&gt;\n\n&lt;p&gt;also , is it buggy ?&lt;/p&gt;\n\n&lt;p&gt;Ex:&lt;/p&gt;\n\n&lt;p&gt;Trying to profile what is more efficient:&lt;/p&gt;\n\n&lt;p&gt;Q1:\nSelect * from table where column not like \u2018t%\u2019&lt;/p&gt;\n\n&lt;p&gt;Q2:&lt;/p&gt;\n\n&lt;p&gt;Select * from table where column not like \u2018%t%\u2019&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10h6zr9", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h6zr9/how_to_use_snowflake_profile_featureeffectively/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h6zr9/how_to_use_snowflake_profile_featureeffectively/", "subreddit_subscribers": 86916, "created_utc": 1674245799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I have a Knime workflow, which downloads multiple CSV files and processes them (simple transformations, filtering, etc) and writes them to MySQL DB. This is rather manual process as I have to manually execute workflow. \n\nI want to automate it. Due to the price, I can't do it in Knime, so I need to choose another ETL tool. I have a private Linux server. \n\nCan someone advise what would be alternatives to try. Main purpose as described: connection to online csv files, data processing joining, cleansing etc. Or I rather focus cron jobs and mysql procedures?", "author_fullname": "t2_15yv6m9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on open source ETL alternatives to be used on Linux server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10h5m8n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674242375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have a Knime workflow, which downloads multiple CSV files and processes them (simple transformations, filtering, etc) and writes them to MySQL DB. This is rather manual process as I have to manually execute workflow. &lt;/p&gt;\n\n&lt;p&gt;I want to automate it. Due to the price, I can&amp;#39;t do it in Knime, so I need to choose another ETL tool. I have a private Linux server. &lt;/p&gt;\n\n&lt;p&gt;Can someone advise what would be alternatives to try. Main purpose as described: connection to online csv files, data processing joining, cleansing etc. Or I rather focus cron jobs and mysql procedures?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10h5m8n", "is_robot_indexable": true, "report_reasons": null, "author": "mrscript_lt", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10h5m8n/advice_on_open_source_etl_alternatives_to_be_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10h5m8n/advice_on_open_source_etl_alternatives_to_be_used/", "subreddit_subscribers": 86916, "created_utc": 1674242375.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}