{"kind": "Listing", "data": {"after": "t3_10emkmw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_m6gnxiuj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DW toolkit book by Ralph Kimball", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "name": "t3_10esybb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5ioEG9GaIPjg4DO8YEHXNaQLLEZ29VHNOBtRF9u2KaY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674002443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yc0bxaypoqca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?auto=webp&amp;v=enabled&amp;s=579f4c43ca548b1e0742912ba9dfea97c392c86f", "width": 2819, "height": 1953}, "resolutions": [{"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7d6aca1f1b6519a452a7852feed37a02fb924c0", "width": 108, "height": 74}, {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae5930e940d0713f43e6184c6c0df951e5af2353", "width": 216, "height": 149}, {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=954c43e1c94f190557f4541106f2dc24f4a5f1ea", "width": 320, "height": 221}, {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=726092b906848d30d07c31f9715bfbbd62fb79cd", "width": 640, "height": 443}, {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e790040401ee5a93fc61d0098c4843d73d6efb1", "width": 960, "height": 665}, {"url": "https://preview.redd.it/yc0bxaypoqca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7d765bedccbfc6d37bf7201318cec16c16e4926", "width": 1080, "height": 748}], "variants": {}, "id": "gKCsuiInCaKY56pQ3Kk6u9IsUHba7ufeNr9UMkEUlRw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10esybb", "is_robot_indexable": true, "report_reasons": null, "author": "rajekum512", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10esybb/dw_toolkit_book_by_ralph_kimball/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yc0bxaypoqca1.jpg", "subreddit_subscribers": 86661, "created_utc": 1674002443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I've been working with TB-scale data for several years. I realize this could sound like a DA/DS question, but almost all of the visualization products I have seen do not work well (at at all) at this scale or require significant pre-processing and customization, so I think this is appropriately a DE question. \n\nLet's say I have some data I want to visualize that is updated at an offline cadence, e.g. once a day. Parquet/Iceberg etc. New data is appended to daily partitions at a rate of \\~100GB/day. I have about a dozen dimensions and filters I would like to aggregate across or filter on, but the metrics themselves are somewhat basic (sums, counts, ratios, etc). Are there any visualization solutions that can handle interactive querying against data of this scale (interactive meaning the end user self-filter and update the visualization within a second or two)? What are the benefits/tradeoffs to current systems for this? Is this a use case to bring in a specialized OLAP cube product?", "author_fullname": "t2_7pxby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who is doing large-scale visualization and dashboarding well?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eov35", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 51, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 51, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673992650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I&amp;#39;ve been working with TB-scale data for several years. I realize this could sound like a DA/DS question, but almost all of the visualization products I have seen do not work well (at at all) at this scale or require significant pre-processing and customization, so I think this is appropriately a DE question. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I have some data I want to visualize that is updated at an offline cadence, e.g. once a day. Parquet/Iceberg etc. New data is appended to daily partitions at a rate of ~100GB/day. I have about a dozen dimensions and filters I would like to aggregate across or filter on, but the metrics themselves are somewhat basic (sums, counts, ratios, etc). Are there any visualization solutions that can handle interactive querying against data of this scale (interactive meaning the end user self-filter and update the visualization within a second or two)? What are the benefits/tradeoffs to current systems for this? Is this a use case to bring in a specialized OLAP cube product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10eov35", "is_robot_indexable": true, "report_reasons": null, "author": "ColdPorridge", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eov35/who_is_doing_largescale_visualization_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10eov35/who_is_doing_largescale_visualization_and/", "subreddit_subscribers": 86661, "created_utc": 1673992650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets say ***a small company currently handles all data by sharing excel files over emails and has never heard the concept of a database***. \n\n***How do you transition this into a data warehouse?***\n\nDoes this mean now I have to write a lot of code to process a bunch of random csv files to turn them into a star schema?\n\nLet's say I managed to turn their csv files into a consistent set of tables... How do they access it? Do they need to hire a bunch of sql analysts to get the information? or Do you build some sort of dashboard out of it?  \n\n\nI know someone has suffered from this before.  \n\n\nHow would you approach it?  \nIs there a guide or a book for this?", "author_fullname": "t2_zs1xp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering for small companies.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10eurjm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674007202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say &lt;strong&gt;&lt;em&gt;a small company currently handles all data by sharing excel files over emails and has never heard the concept of a database&lt;/em&gt;&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;How do you transition this into a data warehouse?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Does this mean now I have to write a lot of code to process a bunch of random csv files to turn them into a star schema?&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I managed to turn their csv files into a consistent set of tables... How do they access it? Do they need to hire a bunch of sql analysts to get the information? or Do you build some sort of dashboard out of it?  &lt;/p&gt;\n\n&lt;p&gt;I know someone has suffered from this before.  &lt;/p&gt;\n\n&lt;p&gt;How would you approach it?&lt;br/&gt;\nIs there a guide or a book for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10eurjm", "is_robot_indexable": true, "report_reasons": null, "author": "lFuckRedditl", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10eurjm/data_engineering_for_small_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10eurjm/data_engineering_for_small_companies/", "subreddit_subscribers": 86661, "created_utc": 1674007202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We can leverage platforms like Coursera Plus and Udemy.", "author_fullname": "t2_5p0gzgth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your favourite DBT training/learning resources in 2023? Moving part of our stack to DBT Cloud and opening up access to more data analysts. Gotta get these newbies trained up!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f8yo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674052844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We can leverage platforms like Coursera Plus and Udemy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10f8yo6", "is_robot_indexable": true, "report_reasons": null, "author": "the-strange-ninja", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f8yo6/what_are_your_favourite_dbt_traininglearning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f8yo6/what_are_your_favourite_dbt_traininglearning/", "subreddit_subscribers": 86661, "created_utc": 1674052844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, is there a good implementation for Delta Sharing usable for on-prem deployments?\n\nThe reference implementation provided doesn't support adding new shares without modifying the configuration file and restarting the server, also there's no user management there.", "author_fullname": "t2_4clu4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Sharing on premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ezch7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674020331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, is there a good implementation for Delta Sharing usable for on-prem deployments?&lt;/p&gt;\n\n&lt;p&gt;The reference implementation provided doesn&amp;#39;t support adding new shares without modifying the configuration file and restarting the server, also there&amp;#39;s no user management there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ezch7", "is_robot_indexable": true, "report_reasons": null, "author": "inteloid", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ezch7/delta_sharing_on_premise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ezch7/delta_sharing_on_premise/", "subreddit_subscribers": 86661, "created_utc": 1674020331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working as a data engineer/data integration for 8+ years from traditional ETL to build data warehouses to cloud (mainly GCP) in large Biotech and start-up Fintech. \n\nI wanna use these skillets to work at a non-profit for animal welfare or organization rather than working for corporations. I wanna contribute my skill to something more meaningful. \n\nI've been searching but it's a bit tricky to find these organizations or they even have job postings. \n\nWhat do you recommend? Or site I should look at? Beside LinkedIn, indeed, zip recruiter, etc...", "author_fullname": "t2_16lpc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to search for job posting at animal non profit organizations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f7xf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674050016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a data engineer/data integration for 8+ years from traditional ETL to build data warehouses to cloud (mainly GCP) in large Biotech and start-up Fintech. &lt;/p&gt;\n\n&lt;p&gt;I wanna use these skillets to work at a non-profit for animal welfare or organization rather than working for corporations. I wanna contribute my skill to something more meaningful. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching but it&amp;#39;s a bit tricky to find these organizations or they even have job postings. &lt;/p&gt;\n\n&lt;p&gt;What do you recommend? Or site I should look at? Beside LinkedIn, indeed, zip recruiter, etc...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10f7xf7", "is_robot_indexable": true, "report_reasons": null, "author": "Totoro328", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f7xf7/how_to_search_for_job_posting_at_animal_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f7xf7/how_to_search_for_job_posting_at_animal_non/", "subreddit_subscribers": 86661, "created_utc": 1674050016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you document data products? I mean e.g. we use mainly Python for ETL jobs and our documentation consists of README in the git repo and sometimes (depending on the transformation complexity) also a Google Document describing the app, calculations, input and outputs etc. \n\nDo you have any better approach? I would really like to have some \u201cdocumentation framework\u201d that would have all data products described and explorable in one place. It would be nice to see products dependencies/lineage similar way you see in Airflow. I am thinking of some custom data catalog maybe, but firstly I would like to know what others do/have out there.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you document data products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ekhrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673982550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you document data products? I mean e.g. we use mainly Python for ETL jobs and our documentation consists of README in the git repo and sometimes (depending on the transformation complexity) also a Google Document describing the app, calculations, input and outputs etc. &lt;/p&gt;\n\n&lt;p&gt;Do you have any better approach? I would really like to have some \u201cdocumentation framework\u201d that would have all data products described and explorable in one place. It would be nice to see products dependencies/lineage similar way you see in Airflow. I am thinking of some custom data catalog maybe, but firstly I would like to know what others do/have out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ekhrq", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ekhrq/how_do_you_document_data_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ekhrq/how_do_you_document_data_products/", "subreddit_subscribers": 86661, "created_utc": 1673982550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When you do a merge in SQL, is it doing a full table scan of the target? If so, isn\u2019t that something we want to avoid?", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MERGE statement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10exb2o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674014249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When you do a merge in SQL, is it doing a full table scan of the target? If so, isn\u2019t that something we want to avoid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10exb2o", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10exb2o/merge_statement/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10exb2o/merge_statement/", "subreddit_subscribers": 86661, "created_utc": 1674014249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_502r5jht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to make a change, resume feedback / advice appreciated for junior DE role.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10f2eow", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Sy52Ie6JvJWizUvuv5xo1U7nvqu7OXkc1LzxFEdNZMA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674031173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zbpozed52tca1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zbpozed52tca1.jpg?auto=webp&amp;v=enabled&amp;s=24840a9556acbb5748715338b28ad0e4a48a2087", "width": 1203, "height": 1723}, "resolutions": [{"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=538cffe182f66e8f7d78190dc8c2928e9437cb73", "width": 108, "height": 154}, {"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3786ab72038cbe2a4d83014c4d792028820cde4f", "width": 216, "height": 309}, {"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1718595b0b5c4e07764565ec79ed3e4fa6e79462", "width": 320, "height": 458}, {"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b223390d8ac0a08a2cf930a9914404460722901", "width": 640, "height": 916}, {"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d5d0f9c3f577c1340f4229ba95fcbb4ff2bda9d", "width": 960, "height": 1374}, {"url": "https://preview.redd.it/zbpozed52tca1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2a40325e0f0927f7547c023f0dfe71f6a0c89ea", "width": 1080, "height": 1546}], "variants": {}, "id": "2QiMbQXoSVTA6udrYgV4EfBnJyQkKItlm1SrK4_k-Bs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10f2eow", "is_robot_indexable": true, "report_reasons": null, "author": "toem033", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f2eow/looking_to_make_a_change_resume_feedback_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zbpozed52tca1.jpg", "subreddit_subscribers": 86661, "created_utc": 1674031173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to flatten the JSON file\n\nstructure of the file looks like this \n\n    root\n     |-- items: array (nullable = true)\n     |    |-- element: struct (containsNull = true)\n     |    |    |-- _links: struct (nullable = true)\n     |    |    |    |-- self: struct (nullable = true)\n     |    |    |    |    |-- href: string (nullable = true)\n     |    |    |-- code: string (nullable = true)\n     |    |    |-- labels: struct (nullable = true)\n     |    |    |    |-- bg_BG: string (nullable = true)\n     |    |    |    |-- cs_CZ: string (nullable = true)\n     |    |    |    |-- da_DK: string (nullable = true)\n     |    |    |    |-- de_AT: string (nullable = true)\n     |    |    |    |-- de_BE: string (nullable = true)\n     |    |    |    |-- de_CH: string (nullable = true)\n     |    |    |    |-- de_DE: string (nullable = true)\n     |    |    |    |-- el_GR: string (nullable = true)\n     |    |    |    |-- en_AU: string (nullable = true)\n     |    |    |    |-- en_CA: string (nullable = true)\n     |    |    |    |-- en_CH: string (nullable = true)\n     |    |    |    |-- en_GB: string (nullable = true)\n     |    |    |    |-- en_IE: string (nullable = true)\n     |    |    |    |-- en_IN: string (nullable = true)\n     |    |    |    |-- en_MY: string (nullable = true)\n     |    |    |    |-- en_NZ: string (nullable = true)\n     |    |    |    |-- en_PH: string (nullable = true)\n     |    |    |    |-- en_SG: string (nullable = true)\n     |    |    |    |-- en_US: string (nullable = true)\n     |    |    |    |-- en_US_America: string (nullable = true)\n     |    |    |    |-- es_ES: string (nullable = true)\n     |    |    |    |-- et_EE: string (nullable = true)\n     |    |    |    |-- fi_FI: string (nullable = true)\n     |    |    |    |-- fr_BE: string (nullable = true)\n     |    |    |    |-- fr_CH: string (nullable = true)\n     |    |    |    |-- fr_FR: string (nullable = true)\n     |    |    |    |-- hr_HR: string (nullable = true)\n     |    |    |    |-- hu_HU: string (nullable = true)\n     |    |    |    |-- id_ID: string (nullable = true)\n     |    |    |    |-- is_IS: string (nullable = true)\n     |    |    |    |-- it_CH: string (nullable = true)\n     |    |    |    |-- it_IT: string (nullable = true)\n     |    |    |    |-- ja_JP: string (nullable = true)\n     |    |    |    |-- ko_KR: string (nullable = true)\n     |    |    |    |-- lt_LT: string (nullable = true)\n     |    |    |    |-- lv_LV: string (nullable = true)\n     |    |    |    |-- ms_MY: string (nullable = true)\n     |    |    |    |-- nb_NO: string (nullable = true)\n     |    |    |    |-- nl_BE: string (nullable = true)\n     |    |    |    |-- nl_NL: string (nullable = true)\n     |    |    |    |-- nn_NO: string (nullable = true)\n     |    |    |    |-- pl_PL: string (nullable = true)\n     |    |    |    |-- pt_PT: string (nullable = true)\n     |    |    |    |-- ro_RO: string (nullable = true)\n     |    |    |    |-- ru_RU: string (nullable = true)\n     |    |    |    |-- sk_SK: string (nullable = true)\n     |    |    |    |-- sl_SI: string (nullable = true)\n     |    |    |    |-- sr_Cyrl_RS: string (nullable = true)\n     |    |    |    |-- sv_SE: string (nullable = true)\n     |    |    |    |-- th_TH: string (nullable = true)\n     |    |    |    |-- tr_TR: string (nullable = true)\n     |    |    |    |-- uk_UA: string (nullable = true)\n     |    |    |    |-- vi_VN: string (nullable = true)\n     |    |    |    |-- zh_CN: string (nullable = true)\n     |    |    |    |-- zh_TW: string (nullable = true)\n     |    |    |-- parent: string (nullable = true)\n     |    |    |-- updated: string (nullable = true)\n\nMy function is this \n\n    def flatten_df(nested_df):\n        flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'string']\n        nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == 'struct']\n    \n        flat_df = nested_df.select(flat_cols +\n                                   [col(nc+'.'+c).alias(nc+'_'+c)\n                                    for nc in nested_cols\n                                    for c in nested_df.select(nc+'.*').columns])\n        return flat_df\n    \n    # Top level hierarchy\n    df = df.select('_embedded.*')\n    #Reaching the lower level called \"items\"\n    df1 = df.select(explode(df.items).alias('required'))\n    # Creating dataframe which will be passed to flatten_df to flatten entire data under \"items\" hierarchy\n    df2 = df1.select('required.*')\n    final = flatten_df(df2)\n    display(final)\n\nthis function takes the `lables`   column keys and puts them as seperate columns ( please see the image [https://imgur.com/a/xa5VmCu](https://imgur.com/a/xa5VmCu) )\n\n&amp;#x200B;\n\nwhat I want is that function should give only two columns from `lables` column named Lable\\_key Lable\\_value  as shown in the image  [https://imgur.com/a/sTW9sSx](https://imgur.com/a/sTW9sSx)", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "flatten nested JSON file pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f1kh1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674027896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to flatten the JSON file&lt;/p&gt;\n\n&lt;p&gt;structure of the file looks like this &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- _links: struct (nullable = true)\n |    |    |    |-- self: struct (nullable = true)\n |    |    |    |    |-- href: string (nullable = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- labels: struct (nullable = true)\n |    |    |    |-- bg_BG: string (nullable = true)\n |    |    |    |-- cs_CZ: string (nullable = true)\n |    |    |    |-- da_DK: string (nullable = true)\n |    |    |    |-- de_AT: string (nullable = true)\n |    |    |    |-- de_BE: string (nullable = true)\n |    |    |    |-- de_CH: string (nullable = true)\n |    |    |    |-- de_DE: string (nullable = true)\n |    |    |    |-- el_GR: string (nullable = true)\n |    |    |    |-- en_AU: string (nullable = true)\n |    |    |    |-- en_CA: string (nullable = true)\n |    |    |    |-- en_CH: string (nullable = true)\n |    |    |    |-- en_GB: string (nullable = true)\n |    |    |    |-- en_IE: string (nullable = true)\n |    |    |    |-- en_IN: string (nullable = true)\n |    |    |    |-- en_MY: string (nullable = true)\n |    |    |    |-- en_NZ: string (nullable = true)\n |    |    |    |-- en_PH: string (nullable = true)\n |    |    |    |-- en_SG: string (nullable = true)\n |    |    |    |-- en_US: string (nullable = true)\n |    |    |    |-- en_US_America: string (nullable = true)\n |    |    |    |-- es_ES: string (nullable = true)\n |    |    |    |-- et_EE: string (nullable = true)\n |    |    |    |-- fi_FI: string (nullable = true)\n |    |    |    |-- fr_BE: string (nullable = true)\n |    |    |    |-- fr_CH: string (nullable = true)\n |    |    |    |-- fr_FR: string (nullable = true)\n |    |    |    |-- hr_HR: string (nullable = true)\n |    |    |    |-- hu_HU: string (nullable = true)\n |    |    |    |-- id_ID: string (nullable = true)\n |    |    |    |-- is_IS: string (nullable = true)\n |    |    |    |-- it_CH: string (nullable = true)\n |    |    |    |-- it_IT: string (nullable = true)\n |    |    |    |-- ja_JP: string (nullable = true)\n |    |    |    |-- ko_KR: string (nullable = true)\n |    |    |    |-- lt_LT: string (nullable = true)\n |    |    |    |-- lv_LV: string (nullable = true)\n |    |    |    |-- ms_MY: string (nullable = true)\n |    |    |    |-- nb_NO: string (nullable = true)\n |    |    |    |-- nl_BE: string (nullable = true)\n |    |    |    |-- nl_NL: string (nullable = true)\n |    |    |    |-- nn_NO: string (nullable = true)\n |    |    |    |-- pl_PL: string (nullable = true)\n |    |    |    |-- pt_PT: string (nullable = true)\n |    |    |    |-- ro_RO: string (nullable = true)\n |    |    |    |-- ru_RU: string (nullable = true)\n |    |    |    |-- sk_SK: string (nullable = true)\n |    |    |    |-- sl_SI: string (nullable = true)\n |    |    |    |-- sr_Cyrl_RS: string (nullable = true)\n |    |    |    |-- sv_SE: string (nullable = true)\n |    |    |    |-- th_TH: string (nullable = true)\n |    |    |    |-- tr_TR: string (nullable = true)\n |    |    |    |-- uk_UA: string (nullable = true)\n |    |    |    |-- vi_VN: string (nullable = true)\n |    |    |    |-- zh_CN: string (nullable = true)\n |    |    |    |-- zh_TW: string (nullable = true)\n |    |    |-- parent: string (nullable = true)\n |    |    |-- updated: string (nullable = true)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My function is this &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def flatten_df(nested_df):\n    flat_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == &amp;#39;string&amp;#39;]\n    nested_cols = [c[0] for c in nested_df.dtypes if c[1][:6] == &amp;#39;struct&amp;#39;]\n\n    flat_df = nested_df.select(flat_cols +\n                               [col(nc+&amp;#39;.&amp;#39;+c).alias(nc+&amp;#39;_&amp;#39;+c)\n                                for nc in nested_cols\n                                for c in nested_df.select(nc+&amp;#39;.*&amp;#39;).columns])\n    return flat_df\n\n# Top level hierarchy\ndf = df.select(&amp;#39;_embedded.*&amp;#39;)\n#Reaching the lower level called &amp;quot;items&amp;quot;\ndf1 = df.select(explode(df.items).alias(&amp;#39;required&amp;#39;))\n# Creating dataframe which will be passed to flatten_df to flatten entire data under &amp;quot;items&amp;quot; hierarchy\ndf2 = df1.select(&amp;#39;required.*&amp;#39;)\nfinal = flatten_df(df2)\ndisplay(final)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;this function takes the &lt;code&gt;lables&lt;/code&gt;   column keys and puts them as seperate columns ( please see the image &lt;a href=\"https://imgur.com/a/xa5VmCu\"&gt;https://imgur.com/a/xa5VmCu&lt;/a&gt; )&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what I want is that function should give only two columns from &lt;code&gt;lables&lt;/code&gt; column named Lable_key Lable_value  as shown in the image  &lt;a href=\"https://imgur.com/a/sTW9sSx\"&gt;https://imgur.com/a/sTW9sSx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?auto=webp&amp;v=enabled&amp;s=7a58cc0ee2d095f64688402d8012d36b9b6a66d2", "width": 1317, "height": 184}, "resolutions": [{"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f66ce948572caabe1038462bad873d97fc1a6f00", "width": 108, "height": 15}, {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19b8cfa11924aba9692b30f9f090ba1b2bdc5cf6", "width": 216, "height": 30}, {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d770f580c8e9f5a3b75d918f355a185747d363e", "width": 320, "height": 44}, {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e91a890cf3c85f5d7f35fc36efa574576ea686b6", "width": 640, "height": 89}, {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca2e0618fd945164bb0ee5d1f453f615f3370c12", "width": 960, "height": 134}, {"url": "https://external-preview.redd.it/tm3pGXLMNkap3E02C1aTihqrxwC3Dux36kk5J2fUaxo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d83982ce3a8ecd415011b397cfd95a71b1a3ba4", "width": 1080, "height": 150}], "variants": {}, "id": "-PIFhkx_4ZX0v6qeVW9b0POiuvOW5532KuWALDCw1dU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10f1kh1", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f1kh1/flatten_nested_json_file_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f1kh1/flatten_nested_json_file_pyspark/", "subreddit_subscribers": 86661, "created_utc": 1674027896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can somebody help? In over my head trying to run a product assessment for Databricks with almost no guidance for the use case. Would be helpful to hear what folks really like about the product + what questions people wish they had asked or better understood before becoming a customer", "author_fullname": "t2_tye5ydmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks evaluation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10euyrz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674007714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody help? In over my head trying to run a product assessment for Databricks with almost no guidance for the use case. Would be helpful to hear what folks really like about the product + what questions people wish they had asked or better understood before becoming a customer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10euyrz", "is_robot_indexable": true, "report_reasons": null, "author": "LuckyChopsSOS", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10euyrz/databricks_evaluation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10euyrz/databricks_evaluation/", "subreddit_subscribers": 86661, "created_utc": 1674007714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_alka6pjc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Review request - BA to DE Pivot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10ezuz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9KYzoafqeDnG-_PpUWLOByjbMlz1QfJEuPzJVCCVOxo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674021917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lrfnoo02tqca1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lrfnoo02tqca1.png?auto=webp&amp;v=enabled&amp;s=91b8620f075e5ce896f4b5e14c0d567427cf6f54", "width": 422, "height": 516}, "resolutions": [{"url": "https://preview.redd.it/lrfnoo02tqca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85d093ca93176a394919ff46e28fecee90627c97", "width": 108, "height": 132}, {"url": "https://preview.redd.it/lrfnoo02tqca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51bfb89f9e5b6abaed0c5f1291aaf34be7a05594", "width": 216, "height": 264}, {"url": "https://preview.redd.it/lrfnoo02tqca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dbe508bd3270e09688cf52b82f2c1631f491b38", "width": 320, "height": 391}], "variants": {}, "id": "NKWY7CXzH_LGoyIUo72kU-hbkmDTtkN7Hugu4VkV8Wg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10ezuz9", "is_robot_indexable": true, "report_reasons": null, "author": "depressedbutsassy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ezuz9/resume_review_request_ba_to_de_pivot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lrfnoo02tqca1.png", "subreddit_subscribers": 86661, "created_utc": 1674021917.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some time series data coming from different sources that have different levels of granularity/frequency\n\nSome data comes in monthly, some daily, some hourly \n\nIs it possible to store all this in one time series database? We like the querying benefits a time series db provides for time series but I wasn\u2019t sure if all the data has to be the same level of granularity", "author_fullname": "t2_7nbpziqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series databases with different granularity or multiple time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10elmce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673985168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some time series data coming from different sources that have different levels of granularity/frequency&lt;/p&gt;\n\n&lt;p&gt;Some data comes in monthly, some daily, some hourly &lt;/p&gt;\n\n&lt;p&gt;Is it possible to store all this in one time series database? We like the querying benefits a time series db provides for time series but I wasn\u2019t sure if all the data has to be the same level of granularity&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10elmce", "is_robot_indexable": true, "report_reasons": null, "author": "Affectionate_Shine55", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10elmce/time_series_databases_with_different_granularity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10elmce/time_series_databases_with_different_granularity/", "subreddit_subscribers": 86661, "created_utc": 1673985168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Come join the first [Seattle Spark Meetup](https://www.meetup.com/Seattle-Spark-Meetup/events/290865855/?response=3&amp;action=rsvp&amp;utm_medium=email&amp;utm_source=braze_canvas&amp;utm_campaign=mmrk_alleng_event_announcement_prod_v7_en&amp;utm_term=promo&amp;utm_content=lp_meetup) of 2023 on Jan 31!\n\nhttps://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4", "author_fullname": "t2_5dvfu5m2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seattle Spark Meetup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "media_metadata": {"p065ppb4inca1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd9eb36775709b68eaee28f59ef7034a2892dba3"}, {"y": 130, "x": 216, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92f406cec1da38d5a0a4a69addb38148a1b27cc9"}, {"y": 192, "x": 320, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ecdb676d3374bcac03cad41c5a995896b60d556"}], "s": {"y": 369, "x": 612, "u": "https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4"}, "id": "p065ppb4inca1"}}, "name": "t3_10ek8ut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5XJvvvK19Bd24JizxyEjIfnJoXEDbapKMQAvQ-ji-ck.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673981977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Come join the first &lt;a href=\"https://www.meetup.com/Seattle-Spark-Meetup/events/290865855/?response=3&amp;amp;action=rsvp&amp;amp;utm_medium=email&amp;amp;utm_source=braze_canvas&amp;amp;utm_campaign=mmrk_alleng_event_announcement_prod_v7_en&amp;amp;utm_term=promo&amp;amp;utm_content=lp_meetup\"&gt;Seattle Spark Meetup&lt;/a&gt; of 2023 on Jan 31!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4\"&gt;https://preview.redd.it/p065ppb4inca1.jpg?width=612&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=21dbb8c3c9fca9f59257ce30f3d53bcec85076d4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10ek8ut", "is_robot_indexable": true, "report_reasons": null, "author": "bp_ryan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10ek8ut/seattle_spark_meetup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ek8ut/seattle_spark_meetup/", "subreddit_subscribers": 86661, "created_utc": 1673981977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Talks Club talks to Versatile Data Kit contributor @ Open-Source Spotlight", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10fbx3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/beLo1BGcRpI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/beLo1BGcRpI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev\"&gt;&lt;/iframe&gt;", "author_name": "DataTalksClub \u2b1b", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/beLo1BGcRpI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataTalksClub"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/beLo1BGcRpI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10fbx3v", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/04WtPwQrJJva4ART6tgg_zjwQ9AdsZlgCMZVOO1DkwA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674060054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/beLo1BGcRpI", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ql3y-kwq-QIWaWxu2JB6NPnQX0FfNh0rAnukmfXqgcY.jpg?auto=webp&amp;v=enabled&amp;s=9f38f3f80e5a0b9f11ce2bd9dff06ec4800b195c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/ql3y-kwq-QIWaWxu2JB6NPnQX0FfNh0rAnukmfXqgcY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c7cd44986e26434dd87405d6302e27957f19a2f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/ql3y-kwq-QIWaWxu2JB6NPnQX0FfNh0rAnukmfXqgcY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4c77ec271bdeccd46e55835e9ecd64cc8f42c98", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/ql3y-kwq-QIWaWxu2JB6NPnQX0FfNh0rAnukmfXqgcY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5b3b9184c6eb23b05cc89193630a3bfbfdbb2f3", "width": 320, "height": 240}], "variants": {}, "id": "AdhBuGH_vpxQo7W8hcgEr28X3Zq-l0IrTj9yZcy-1oI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10fbx3v", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10fbx3v/data_talks_club_talks_to_versatile_data_kit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/beLo1BGcRpI", "subreddit_subscribers": 86661, "created_utc": 1674060054.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/beLo1BGcRpI?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Open-Source Spotlight - Versatile Data Kit - Gabriel Georgiev\"&gt;&lt;/iframe&gt;", "author_name": "DataTalksClub \u2b1b", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/beLo1BGcRpI/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataTalksClub"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_anyz9dbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Live now State of Data Conference 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10fbwjq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/j-gruNSEd80?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"State Of Data Conference By Seattle Data Guy - 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "State Of Data Conference By Seattle Data Guy - 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/j-gruNSEd80?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"State Of Data Conference By Seattle Data Guy - 2023\"&gt;&lt;/iframe&gt;", "author_name": "Seattle Data Guy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/j-gruNSEd80/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SeattleDataGuy"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/j-gruNSEd80?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"State Of Data Conference By Seattle Data Guy - 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10fbwjq", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/HdQdLb6trEdre_KIXcpyWZtfhPse4CcrrtnbqCUbar8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674060017.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/j-gruNSEd80", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aUue3f8wBtEGfIW6_E3R-GFsE3DbRa6JSavtVNHdWK4.jpg?auto=webp&amp;v=enabled&amp;s=0a1679c918956366f5129d6808ef34c4b0322832", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/aUue3f8wBtEGfIW6_E3R-GFsE3DbRa6JSavtVNHdWK4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69ebdf278cf6523aca9522700778140400580519", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/aUue3f8wBtEGfIW6_E3R-GFsE3DbRa6JSavtVNHdWK4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ca6364a0780a74293a25cdcaf8ad7ad7c9a4c885", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/aUue3f8wBtEGfIW6_E3R-GFsE3DbRa6JSavtVNHdWK4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0abfbfdbbd65a963536f529d76f9ce4ac15cd9a3", "width": 320, "height": 240}], "variants": {}, "id": "yiyO67P4YiblW4RXOfFRYBM7Z6eHgTy5O3zKEqKicVI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10fbwjq", "is_robot_indexable": true, "report_reasons": null, "author": "tchungry", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10fbwjq/live_now_state_of_data_conference_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/j-gruNSEd80", "subreddit_subscribers": 86661, "created_utc": 1674060017.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "State Of Data Conference By Seattle Data Guy - 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/j-gruNSEd80?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"State Of Data Conference By Seattle Data Guy - 2023\"&gt;&lt;/iframe&gt;", "author_name": "Seattle Data Guy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/j-gruNSEd80/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@SeattleDataGuy"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Oracle has a free tier which I want to use for a general cloud computing instance on multiple projects; its specs are more or less .48 Gbps for network bandwidth, 1GB RAM, and 20GB storage.\n\nOne of the things I plan on using it for is for a data engineering project which itself would deal with pulls from some API for data and transporting the data into a BiqQuery instance on GCP. I figured I'd deal with the complete scheduling through Airflow.\n\nThus the crux of the problem: Airflow normally installable through pip, and I normally use pip under miniconda just to deal with environments and whatnot more easily. Afaik, conda is too beefy for this thing and there are some open bugs on issues with such low memory. I can install pip and poetry or whatever to deal with it, but I don't have any experience with poetry and have heard its learning curve is up there. I'm not opposed to learning it if that's the recommended way.\n\nI'm also considering just getting a docker image up there, but then I wouldn't be sure of whether I should dockerize everything else that would be involved in this project and how much that would affect the puny VM.\n\n&amp;#x200B;\n\nThoughts?", "author_fullname": "t2_svn12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to deal with my environments/projects on a minimal VM?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fb2lx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674058049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Oracle has a free tier which I want to use for a general cloud computing instance on multiple projects; its specs are more or less .48 Gbps for network bandwidth, 1GB RAM, and 20GB storage.&lt;/p&gt;\n\n&lt;p&gt;One of the things I plan on using it for is for a data engineering project which itself would deal with pulls from some API for data and transporting the data into a BiqQuery instance on GCP. I figured I&amp;#39;d deal with the complete scheduling through Airflow.&lt;/p&gt;\n\n&lt;p&gt;Thus the crux of the problem: Airflow normally installable through pip, and I normally use pip under miniconda just to deal with environments and whatnot more easily. Afaik, conda is too beefy for this thing and there are some open bugs on issues with such low memory. I can install pip and poetry or whatever to deal with it, but I don&amp;#39;t have any experience with poetry and have heard its learning curve is up there. I&amp;#39;m not opposed to learning it if that&amp;#39;s the recommended way.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also considering just getting a docker image up there, but then I wouldn&amp;#39;t be sure of whether I should dockerize everything else that would be involved in this project and how much that would affect the puny VM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10fb2lx", "is_robot_indexable": true, "report_reasons": null, "author": "paxmlank", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10fb2lx/whats_the_best_way_to_deal_with_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10fb2lx/whats_the_best_way_to_deal_with_my/", "subreddit_subscribers": 86661, "created_utc": 1674058049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI produce the #TrueDataOps Podcast with host, Kent Graziano. [https://www.youtube.com/playlist?list=PLgdSafWhtnBhTbzhT2o9XbQ-O6En1gs3Q](https://www.youtube.com/playlist?list=PLgdSafWhtnBhTbzhT2o9XbQ-O6En1gs3Q)\n\nWe discuss all things DataOps with the people leading the field and bringing dataops to maturity. A few past guests we had on are Wayne Eckerson and Joe Reis.   \n\n\nMy question is, What are your thoughts? What are ways we can improve? Thank you in advance!", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "#TrueDataOps Podcast - Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f94yw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674053311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I produce the #TrueDataOps Podcast with host, Kent Graziano. &lt;a href=\"https://www.youtube.com/playlist?list=PLgdSafWhtnBhTbzhT2o9XbQ-O6En1gs3Q\"&gt;https://www.youtube.com/playlist?list=PLgdSafWhtnBhTbzhT2o9XbQ-O6En1gs3Q&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We discuss all things DataOps with the people leading the field and bringing dataops to maturity. A few past guests we had on are Wayne Eckerson and Joe Reis.   &lt;/p&gt;\n\n&lt;p&gt;My question is, What are your thoughts? What are ways we can improve? Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BcKe7vAvwB9RQLSftH9A0yYdRiBTYP_QqpLVKh8VrN4.jpg?auto=webp&amp;v=enabled&amp;s=f69215e4e8e2708116989bd8a467e5a73eaf9d2e", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/BcKe7vAvwB9RQLSftH9A0yYdRiBTYP_QqpLVKh8VrN4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98deb0994b26eec0cc4e539fd4ec95262b080f25", "width": 108, "height": 60}], "variants": {}, "id": "ON1UkDE3vdDvk5Ry9ELGDqD9y1-GqL74aUzQrFKbBhM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10f94yw", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f94yw/truedataops_podcast_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f94yw/truedataops_podcast_feedback/", "subreddit_subscribers": 86661, "created_utc": 1674053311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v3fb8jv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I'm having around 2 YoE. Thought of making a switch within a year. Looking to get into top product companies. Any advice to optimise my resume would be appreciated. Thanks in advance. Also I'm confused about which resume to use. Single column or Two columns.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"e6le1l2qatca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 163, "x": 108, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a539c6c6627ece027d4b7ce14a54e8b1ad56107"}, {"y": 327, "x": 216, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9948abdcf4e4928259900fe9474e811ae9c96b11"}, {"y": 485, "x": 320, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08171eb17c29bebd1b9cce7af911d203152b5b98"}, {"y": 970, "x": 640, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c81d9bba3335b643d611c8a90e20efa55eb1ded0"}, {"y": 1455, "x": 960, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c09185f4537352a80a249e45ab15cbe3b283719"}, {"y": 1637, "x": 1080, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bd1a8c4bfe1cff24d13522a6e37149a66e7d9d8"}], "s": {"y": 1637, "x": 1080, "u": "https://preview.redd.it/e6le1l2qatca1.png?width=1080&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2f28740ad619acbd33d01293f2ed1368c6ab5ecc"}, "id": "e6le1l2qatca1"}, "hp6f6jcqatca1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 152, "x": 108, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cb3d40d10f42bb10a1adedd87fea87928471074"}, {"y": 304, "x": 216, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7ffd64dd7d092de072f0f3d72e17b226cf4ab63"}, {"y": 451, "x": 320, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb21e351447d2d9ab74f60933ec03724f4be099c"}, {"y": 903, "x": 640, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8267624046544a7f2789348ec19847b9cec8d003"}, {"y": 1354, "x": 960, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb984ca8c0c9da03a8921e6c5e726fa5411f25ad"}, {"y": 1524, "x": 1080, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19f5477a79f7ec2125c81f24655752735932791b"}], "s": {"y": 1524, "x": 1080, "u": "https://preview.redd.it/hp6f6jcqatca1.png?width=1080&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ea4ef3342c33ae40be64db9dfab4d9ad21d5a978"}, "id": "hp6f6jcqatca1"}}, "name": "t3_10f8o4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "e6le1l2qatca1", "id": 231063009}, {"media_id": "hp6f6jcqatca1", "id": 231063010}]}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-iBH-vqT0TqJrO6XIU0cyYKPlxuQ87K_fTXGmotX6Ko.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674052059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10f8o4k", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10f8o4k", "is_robot_indexable": true, "report_reasons": null, "author": "CheesecakeFrosty20", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f8o4k/im_having_around_2_yoe_thought_of_making_a_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10f8o4k", "subreddit_subscribers": 86661, "created_utc": 1674052059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# [Jailer Database Tools.](https://wisser.github.io/Jailer/)\n\nJailer is a tool for database subsetting and relational data browsing.\n\nIt creates small slices from your database and lets you navigate through your database following the relationships.Ideal for creating small samples of test data or for local problem analysis with relevant production data.\n\nThe Subsetter creates small slices from your database (consistent and reverentially intact) as SQL (topologically sorted), DbUnit records or XML. Ideal for creating small samples of test data or for local problem analysis with relevant production data.\n\nThe Data Browser lets you navigate through your database following the relationships (foreign key-based or user-defined) between tables.\n\n# Features\n\nExports consistent and reverentially intact row-sets from your productive database and imports the data into your development and test environment.\n\nImproves database performance by removing and archiving obsolete data without violating integrity.\n\nGenerates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.\n\nData Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.\n\nSQL Console with code completion, syntax highlighting and database metadata visualization.\n\nA demo database is included with which you can get a first impression without any configuration effort.", "author_fullname": "t2_5sa5b0ia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New release of Jailer database tools publicized", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f3lpo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674035839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;&lt;a href=\"https://wisser.github.io/Jailer/\"&gt;Jailer Database Tools.&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;Jailer is a tool for database subsetting and relational data browsing.&lt;/p&gt;\n\n&lt;p&gt;It creates small slices from your database and lets you navigate through your database following the relationships.Ideal for creating small samples of test data or for local problem analysis with relevant production data.&lt;/p&gt;\n\n&lt;p&gt;The Subsetter creates small slices from your database (consistent and reverentially intact) as SQL (topologically sorted), DbUnit records or XML. Ideal for creating small samples of test data or for local problem analysis with relevant production data.&lt;/p&gt;\n\n&lt;p&gt;The Data Browser lets you navigate through your database following the relationships (foreign key-based or user-defined) between tables.&lt;/p&gt;\n\n&lt;h1&gt;Features&lt;/h1&gt;\n\n&lt;p&gt;Exports consistent and reverentially intact row-sets from your productive database and imports the data into your development and test environment.&lt;/p&gt;\n\n&lt;p&gt;Improves database performance by removing and archiving obsolete data without violating integrity.&lt;/p&gt;\n\n&lt;p&gt;Generates topologically sorted SQL-DML, hierarchically structured XML and DbUnit datasets.&lt;/p&gt;\n\n&lt;p&gt;Data Browsing. Navigate bidirectionally through the database by following foreign-key-based or user-defined relationships.&lt;/p&gt;\n\n&lt;p&gt;SQL Console with code completion, syntax highlighting and database metadata visualization.&lt;/p&gt;\n\n&lt;p&gt;A demo database is included with which you can get a first impression without any configuration effort.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10f3lpo", "is_robot_indexable": true, "report_reasons": null, "author": "Plane-Discussion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f3lpo/new_release_of_jailer_database_tools_publicized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f3lpo/new_release_of_jailer_database_tools_publicized/", "subreddit_subscribers": 86661, "created_utc": 1674035839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm at a new position and currently understanding their architecture. Since it is my first time learning data engineering solutions, I wanted to ask for your help/input.\n\nCurrently there are different machines with different sensors that collect data, I think you can think of IoT and telemetry data, for instance. The HW/SW onboard sends a JSON file to the Azure Blob Storage Cloud. The JSON is formed with semi-structured data cointaining the composite key to identify the machine, the composite key to identify the sensor, the value of the data and its timestamp (and other things not important). At the moment a scheduled ELT routine take these JSON and rewrite CSV files to the Blob Storage, one .csv for one machine: the rows are measurements and the columns the sensors of the machine. The problem is that this structure is very sparse due to the different sampling frequency of the sensor, many columns are very sparse. Also later analytics have to download every machines files in the desired data range to check if a desired measure is collected or not.\n\nMy idea is first to use binary data files, for instance .parquet, then maybe make one file for each (machine x sensor) product, so that the \"tables\" are not sparse anymore. I don't know how to evaluate the overhead of this solutions taking into considerations that Azure Blob Storage already has a tree directory path where the trees are hourly files, e.g. maximum 3600 rows for each machine x sensor since our max frequency is 1s and slowest 5m.\n\nMy idea was to use the Blob Storage with a logical division, the JSON raw data as semi-structured and the output of the ELT routine as a \"Data Warehouse\" where I could easily query the interested binary data and index them by the desired rows (the desired datetime range, using the timestamp information as index).\n\nAm I missing something? Any input is appreciated", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure blob storage and design of its files (database)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10f2ijv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674031604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a new position and currently understanding their architecture. Since it is my first time learning data engineering solutions, I wanted to ask for your help/input.&lt;/p&gt;\n\n&lt;p&gt;Currently there are different machines with different sensors that collect data, I think you can think of IoT and telemetry data, for instance. The HW/SW onboard sends a JSON file to the Azure Blob Storage Cloud. The JSON is formed with semi-structured data cointaining the composite key to identify the machine, the composite key to identify the sensor, the value of the data and its timestamp (and other things not important). At the moment a scheduled ELT routine take these JSON and rewrite CSV files to the Blob Storage, one .csv for one machine: the rows are measurements and the columns the sensors of the machine. The problem is that this structure is very sparse due to the different sampling frequency of the sensor, many columns are very sparse. Also later analytics have to download every machines files in the desired data range to check if a desired measure is collected or not.&lt;/p&gt;\n\n&lt;p&gt;My idea is first to use binary data files, for instance .parquet, then maybe make one file for each (machine x sensor) product, so that the &amp;quot;tables&amp;quot; are not sparse anymore. I don&amp;#39;t know how to evaluate the overhead of this solutions taking into considerations that Azure Blob Storage already has a tree directory path where the trees are hourly files, e.g. maximum 3600 rows for each machine x sensor since our max frequency is 1s and slowest 5m.&lt;/p&gt;\n\n&lt;p&gt;My idea was to use the Blob Storage with a logical division, the JSON raw data as semi-structured and the output of the ELT routine as a &amp;quot;Data Warehouse&amp;quot; where I could easily query the interested binary data and index them by the desired rows (the desired datetime range, using the timestamp information as index).&lt;/p&gt;\n\n&lt;p&gt;Am I missing something? Any input is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10f2ijv", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10f2ijv/azure_blob_storage_and_design_of_its_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10f2ijv/azure_blob_storage_and_design_of_its_files/", "subreddit_subscribers": 86661, "created_utc": 1674031604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone out there have experience with these tools?  If so, how do they compare in your opinion?", "author_fullname": "t2_5lfqidpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alation vs. Atlan vs. Collibra", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10esiz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674001376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone out there have experience with these tools?  If so, how do they compare in your opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10esiz9", "is_robot_indexable": true, "report_reasons": null, "author": "imani_TqiynAZU", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10esiz9/alation_vs_atlan_vs_collibra/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10esiz9/alation_vs_atlan_vs_collibra/", "subreddit_subscribers": 86661, "created_utc": 1674001376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nTL;DR\n\nSole Data Engineer in the company is to propose a new architecture to gradually connect 30 ERP systems. There is a failed Data Vault project because it was designed as a Source System Data Vault and there are also errors in the technical implementation.\n\nThe existing technologies are Snowflake and Wherescape.\n\nThe question is whether another Data Vault project should be set up or whether the new DWH should be set up differently.\n\n&amp;#x200B;\n\nI am new in a company, the only one who has anything to do with data engineering/BI. The previous developer left, leaving behind a failed Data Vault project. I am Data Vault 2.0 certified, but have never had to implement it in practice. I say failed Data Vault project because it is 1:1 to the source system and the historisation does not work. So there is a source data vault (Anti Pattern) that does not even historise the data.\n\nThis was implemented with Wherescape as the automation tool and Snowflake as the database. No upstream data lake or anything similar.\n\n&amp;#x200B;\n\nI have been using Informatica PowerCenter and have strong SQL skills and know dimensional modelling, but I am no longer interested in no code tools like PowerCenter, Talent, SSIS etc. and would be happy to leave them behind.\n\n&amp;#x200B;\n\nThe company is based in the manufacturing sector and has a total of over 30 more or less small sites, the largest of which run their own ERP systems.\n\nThe goal is (and was) to first integrate the ERP systems of the two largest sites into one DWH and then connect other sites. The larger locations each use the same ERP system (MS Dynamics NAV on-prem) and the smaller locations, for example, MS Dynamics 365 Business Central (Cloud). The departments only need daily updated data, which is good because CDC mechanisms are not active in the ERP databases and the DB responsibles have not had anything to do with it yet.\n\nAs far as I can see, only Azure AD and VMs are used in Azure.\n\n&amp;#x200B;\n\nThe question for me now is how to proceed, as my supervisor has asked me to suggest which architecture and data model we want to use.\n\nHow would you approach the issue?\n\nI see the possibility of creating the DV model again with the help of external support and implementing it using Wherescape.\n\nAlternatively, it would be conceivable to load the data into Snowflake and build a persistent staging area (PSA) there and transform the whole thing using dbt. I would find dbt interesting because it is essentially SQL. But then it would have to be decided which tools would be used for extraction and orchestration.", "author_fullname": "t2_uyjws4s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH architecture for the integration of 30 sites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ejp50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673980681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;TL;DR&lt;/p&gt;\n\n&lt;p&gt;Sole Data Engineer in the company is to propose a new architecture to gradually connect 30 ERP systems. There is a failed Data Vault project because it was designed as a Source System Data Vault and there are also errors in the technical implementation.&lt;/p&gt;\n\n&lt;p&gt;The existing technologies are Snowflake and Wherescape.&lt;/p&gt;\n\n&lt;p&gt;The question is whether another Data Vault project should be set up or whether the new DWH should be set up differently.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am new in a company, the only one who has anything to do with data engineering/BI. The previous developer left, leaving behind a failed Data Vault project. I am Data Vault 2.0 certified, but have never had to implement it in practice. I say failed Data Vault project because it is 1:1 to the source system and the historisation does not work. So there is a source data vault (Anti Pattern) that does not even historise the data.&lt;/p&gt;\n\n&lt;p&gt;This was implemented with Wherescape as the automation tool and Snowflake as the database. No upstream data lake or anything similar.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been using Informatica PowerCenter and have strong SQL skills and know dimensional modelling, but I am no longer interested in no code tools like PowerCenter, Talent, SSIS etc. and would be happy to leave them behind.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The company is based in the manufacturing sector and has a total of over 30 more or less small sites, the largest of which run their own ERP systems.&lt;/p&gt;\n\n&lt;p&gt;The goal is (and was) to first integrate the ERP systems of the two largest sites into one DWH and then connect other sites. The larger locations each use the same ERP system (MS Dynamics NAV on-prem) and the smaller locations, for example, MS Dynamics 365 Business Central (Cloud). The departments only need daily updated data, which is good because CDC mechanisms are not active in the ERP databases and the DB responsibles have not had anything to do with it yet.&lt;/p&gt;\n\n&lt;p&gt;As far as I can see, only Azure AD and VMs are used in Azure.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The question for me now is how to proceed, as my supervisor has asked me to suggest which architecture and data model we want to use.&lt;/p&gt;\n\n&lt;p&gt;How would you approach the issue?&lt;/p&gt;\n\n&lt;p&gt;I see the possibility of creating the DV model again with the help of external support and implementing it using Wherescape.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, it would be conceivable to load the data into Snowflake and build a persistent staging area (PSA) there and transform the whole thing using dbt. I would find dbt interesting because it is essentially SQL. But then it would have to be decided which tools would be used for extraction and orchestration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ejp50", "is_robot_indexable": true, "report_reasons": null, "author": "Individual-Detail286", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ejp50/dwh_architecture_for_the_integration_of_30_sites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ejp50/dwh_architecture_for_the_integration_of_30_sites/", "subreddit_subscribers": 86661, "created_utc": 1673980681.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a free course to be a data engineer? I'm one of the people who is struggling picking a career path and I just thought to give data engineering a shot.", "author_fullname": "t2_v1c1ivpg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to be a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10fah7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674056649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a free course to be a data engineer? I&amp;#39;m one of the people who is struggling picking a career path and I just thought to give data engineering a shot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10fah7i", "is_robot_indexable": true, "report_reasons": null, "author": "AdamAdamantite", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10fah7i/how_to_be_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10fah7i/how_to_be_a_data_engineer/", "subreddit_subscribers": 86661, "created_utc": 1674056649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a company that does geographic data processing for the country. We have a project that uses a library, previously made by the company, that contains several processing modules, where each module does the prediction or analysis of different types of geographic events for small regions of the country. For each region that we are going to monitor, we create a new virtual machine and do a workflow with airflow, and choose the module that will be applied to that region. The problem is that this is obviously getting too bad to manage or scale. We would also like to integrate the part of creating new monitoring flows with our portal, allowing the end user to create them, rather than it being an internal process.\n\n\n\nI was thinking of changing this architecture to something like:\n\n- Create a table in the database to manage the stream control, where each row would have the information of the stream type, periodicity, region, module and if it is being processed by any machines. Ex:\n\n\n\nTable Worflows:\n\nID | Module | Region | Period | Status\n---|---|----|----|----\n0 | RainPrediction | 55AX | 1 hour | Processing\n1 | RainPrediction | 45TB | 1 hour | Free\n2 | TornadoPrediction | 55AX | 1 hour | Processing\n\n\nTable Workflow_Logs\n\nID | Worflow_ID | Started_DT | Finished_DT | Logs \n---|---|----|----|----    \n0 | 1 | 13:00 | 13:17 | Lorem Ipsum...\n\n\n\n- Instead of creating a machine to run each region of each module, I am thinking of adapting the lib to have a main entrypoint that receives parameters and can run the X algorithm for the Y region. Then this machine would scan the flow control table looking for the tasks that are not being processed in order to process them.\n\n\n\n- Adapt the frontend so that the user can insert a new row into this flow control table.\n\n\n\nThen when we need to scale up our algorithm we would just need to create a new container and this container would start reading and fetching unprocessed tasks. I think I am trying to reinvent the wheel by doing this and would like some suggestions that do not increase the complexity of the project too much. I have been reading about kafka but it seems to add a lot of complexity to the project.", "author_fullname": "t2_9ca451os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions on how to improve the architecture that I am working on", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10emkmw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673987372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a company that does geographic data processing for the country. We have a project that uses a library, previously made by the company, that contains several processing modules, where each module does the prediction or analysis of different types of geographic events for small regions of the country. For each region that we are going to monitor, we create a new virtual machine and do a workflow with airflow, and choose the module that will be applied to that region. The problem is that this is obviously getting too bad to manage or scale. We would also like to integrate the part of creating new monitoring flows with our portal, allowing the end user to create them, rather than it being an internal process.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of changing this architecture to something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create a table in the database to manage the stream control, where each row would have the information of the stream type, periodicity, region, module and if it is being processed by any machines. Ex:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Table Worflows:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;ID&lt;/th&gt;\n&lt;th&gt;Module&lt;/th&gt;\n&lt;th&gt;Region&lt;/th&gt;\n&lt;th&gt;Period&lt;/th&gt;\n&lt;th&gt;Status&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;RainPrediction&lt;/td&gt;\n&lt;td&gt;55AX&lt;/td&gt;\n&lt;td&gt;1 hour&lt;/td&gt;\n&lt;td&gt;Processing&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;RainPrediction&lt;/td&gt;\n&lt;td&gt;45TB&lt;/td&gt;\n&lt;td&gt;1 hour&lt;/td&gt;\n&lt;td&gt;Free&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;TornadoPrediction&lt;/td&gt;\n&lt;td&gt;55AX&lt;/td&gt;\n&lt;td&gt;1 hour&lt;/td&gt;\n&lt;td&gt;Processing&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Table Workflow_Logs&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;ID&lt;/th&gt;\n&lt;th&gt;Worflow_ID&lt;/th&gt;\n&lt;th&gt;Started_DT&lt;/th&gt;\n&lt;th&gt;Finished_DT&lt;/th&gt;\n&lt;th&gt;Logs&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;13:00&lt;/td&gt;\n&lt;td&gt;13:17&lt;/td&gt;\n&lt;td&gt;Lorem Ipsum...&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Instead of creating a machine to run each region of each module, I am thinking of adapting the lib to have a main entrypoint that receives parameters and can run the X algorithm for the Y region. Then this machine would scan the flow control table looking for the tasks that are not being processed in order to process them.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Adapt the frontend so that the user can insert a new row into this flow control table.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then when we need to scale up our algorithm we would just need to create a new container and this container would start reading and fetching unprocessed tasks. I think I am trying to reinvent the wheel by doing this and would like some suggestions that do not increase the complexity of the project too much. I have been reading about kafka but it seems to add a lot of complexity to the project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10emkmw", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableAstronaut77", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10emkmw/suggestions_on_how_to_improve_the_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10emkmw/suggestions_on_how_to_improve_the_architecture/", "subreddit_subscribers": 86661, "created_utc": 1673987372.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}