{"kind": "Listing", "data": {"after": "t3_10a5hno", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just recently, I wrote up a guide on how to use [ChatGPT to build a website with Replit](https://buildspace.so/notes/chatgpt-replit-website?utm_source=r).\n\nGot some pretty good responses, so I decided to write + document more of the applications I'm discovering.\n\n**I'm actually really excited about this one, since I was in a graduate program for statistics.**\n\n[Here's the guide](https://buildspace.so/notes/chatgpt-data-science?utm_source=r) for doing data sci with ChatGPT\n\nThe tl;dr is that I show you some of the crazy data sci stuff ChatGPT can do:\n\n\\- Read and analyze raw CSV data. I just had to copy and paste.\n\n\\- It could tell what kind of data you're feeding it judging by the header columns!\n\n\\- It will give you the python/r code on how to run specific analysis.\n\n\\- It even knew how to use scikit-learn to run regression models \ud83e\udd2f (I mean, this makes sense since it's an AI tool lol).\n\nHonestly, this is just crazy to me.\n\n**Before I dropped out of graduate school for statistics, I often consulted non-technical researchers in the social sciences. It was always a pain for them to run datasets by themselves just to get some answers to their questions.**\n\nAlthough ChatGPT isn't perfect (and does make mistakes), it's crazy where the tool is going.\n\nI think this is really good news for a lot of people who are interested in doing research, but might feel too intimidated by needing to do stats. Obvi...some bad stuff could come from it. We'll see!\n\nhttps://preview.redd.it/ggd96gyhnnba1.png?width=619&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=336d66a381cceb0befe1614d221694d7a831ab31", "author_fullname": "t2_rp0am0gy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote up a guide showing how to do Data Science with ChatGPT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ggd96gyhnnba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 142, "x": 108, "u": "https://preview.redd.it/ggd96gyhnnba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5779bbd697a6c99463bb440c6215ad916a691f83"}, {"y": 285, "x": 216, "u": "https://preview.redd.it/ggd96gyhnnba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a482afc006aedd53f5e6eafc6e44eb95caf1282"}, {"y": 423, "x": 320, "u": "https://preview.redd.it/ggd96gyhnnba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=877afb8c364964484b19f5acfba0464008535d21"}], "s": {"y": 819, "x": 619, "u": "https://preview.redd.it/ggd96gyhnnba1.png?width=619&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=336d66a381cceb0befe1614d221694d7a831ab31"}, "id": "ggd96gyhnnba1"}}, "name": "t3_10a7kq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 172, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 172, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NwGBiFzvMKnAVlPoLgKzu6aUKtRriWzQ7RZ_Nv6Q2Fw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1673550084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just recently, I wrote up a guide on how to use &lt;a href=\"https://buildspace.so/notes/chatgpt-replit-website?utm_source=r\"&gt;ChatGPT to build a website with Replit&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Got some pretty good responses, so I decided to write + document more of the applications I&amp;#39;m discovering.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m actually really excited about this one, since I was in a graduate program for statistics.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://buildspace.so/notes/chatgpt-data-science?utm_source=r\"&gt;Here&amp;#39;s the guide&lt;/a&gt; for doing data sci with ChatGPT&lt;/p&gt;\n\n&lt;p&gt;The tl;dr is that I show you some of the crazy data sci stuff ChatGPT can do:&lt;/p&gt;\n\n&lt;p&gt;- Read and analyze raw CSV data. I just had to copy and paste.&lt;/p&gt;\n\n&lt;p&gt;- It could tell what kind of data you&amp;#39;re feeding it judging by the header columns!&lt;/p&gt;\n\n&lt;p&gt;- It will give you the python/r code on how to run specific analysis.&lt;/p&gt;\n\n&lt;p&gt;- It even knew how to use scikit-learn to run regression models \ud83e\udd2f (I mean, this makes sense since it&amp;#39;s an AI tool lol).&lt;/p&gt;\n\n&lt;p&gt;Honestly, this is just crazy to me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Before I dropped out of graduate school for statistics, I often consulted non-technical researchers in the social sciences. It was always a pain for them to run datasets by themselves just to get some answers to their questions.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Although ChatGPT isn&amp;#39;t perfect (and does make mistakes), it&amp;#39;s crazy where the tool is going.&lt;/p&gt;\n\n&lt;p&gt;I think this is really good news for a lot of people who are interested in doing research, but might feel too intimidated by needing to do stats. Obvi...some bad stuff could come from it. We&amp;#39;ll see!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ggd96gyhnnba1.png?width=619&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=336d66a381cceb0befe1614d221694d7a831ab31\"&gt;https://preview.redd.it/ggd96gyhnnba1.png?width=619&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=336d66a381cceb0befe1614d221694d7a831ab31&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?auto=webp&amp;v=enabled&amp;s=8ec4b54e7f1288e29fcab0cfe66782742f6f96a1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0690be4f8d9aefcca0fdfcf5f070835826b39112", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d566c1d3b4ead76c66dbf4f0484c5d0a6122db8c", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=548576729a71e074d0bc3f5fb8010d06f912b0dd", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0f539d22c093992d6cadaa5f696305a1f21683a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7267705d81cb9ecbefb47a767bcc8b7beaddb9f9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/bMmYVU5qbeHyacqdcjNNX_6ifH0w5YFDI-tqDoWS5H0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1cc369d3bf529f1ad4a03bab1d4dc5348716f0b", "width": 1080, "height": 567}], "variants": {}, "id": "37JQnsF20Ok1m7gNTdPyXwo10tviNPSdLDxDrQ5FXbs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a7kq4", "is_robot_indexable": true, "report_reasons": null, "author": "Own-Anteater4164", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a7kq4/i_wrote_up_a_guide_showing_how_to_do_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a7kq4/i_wrote_up_a_guide_showing_how_to_do_data_science/", "subreddit_subscribers": 836656, "created_utc": 1673550084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&amp;s=08).\n\n2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.\n\nEmergent Abilities in LLMs\n\nIn a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs will allow them, among other things, to:\n\n* Become better at math\n* Understand even more subtleties of human language\n* Stop hallucinating and answer truthfully\n* ...\n\n(See the plot on break-out performance below for a full list)\n\n**Some Context:**\n\nIf you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.\n\n**Why does this happen?**\n\nLLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.\n\nHence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).\n\nLet's look at the following sentence.\n\n\"The sum of two plus two is ...\"\n\nThe model figures out that the most likely missing word is \"four\".\n\nThe fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).\n\nThere are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example are words that change their meaning with context. When the model encounters the word \"bed\", it needs to figure out from the context, if the text is talking about a \"river bed\" or a \"bed\" to sleep in.\n\n**What they discovered:**\n\nFor smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (proxy for model size) is reached.\n\nThe figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.\n\n&amp;#x200B;\n\n[Break-Out Performance At Critical Scale](https://preview.redd.it/w7xffqjimmba1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c573f6199db7b5ccebfa73ce8e58313e5ae27822)\n\nThey observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.\n\nLooking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.\n\n(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.\n\nThere is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.\n\n**So what does this mean exactly?**\n\nThis beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.\n\nHowever, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.\n\nSuch exciting times to be alive!\n\nIf you got down here, thank you! It was a privilege to make this for you.  \nAt **TheDecoding** \u2b55, I send out a thoughtful newsletter about ML research and the data economy once a week.  \nNo Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)", "author_fullname": "t2_az3v2qdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Research From Google Shines Light On The Future Of Language Models \u2b55", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w7xffqjimmba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/w7xffqjimmba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=064271844381b5d30e9e64768dca602c28e79ca0"}, {"y": 142, "x": 216, "u": "https://preview.redd.it/w7xffqjimmba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1134d5c14f8b0c4bf0844668ea108b606c26037c"}, {"y": 211, "x": 320, "u": "https://preview.redd.it/w7xffqjimmba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e48a5a0a0b5a51ee2dbcfd6b97ce6a352252c0e3"}, {"y": 422, "x": 640, "u": "https://preview.redd.it/w7xffqjimmba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3c6d9e818e81b07e4aa3f6c5eb9a7eefd103691"}], "s": {"y": 528, "x": 800, "u": "https://preview.redd.it/w7xffqjimmba1.png?width=800&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c573f6199db7b5ccebfa73ce8e58313e5ae27822"}, "id": "w7xffqjimmba1"}}, "name": "t3_10a1mik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HHMyocjc1mprY1KVeTd2oCjTsPTwuNrN1QlSqTydiEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673535544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create &lt;a href=\"https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:%7E:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company\"&gt;billion-dollar companies&lt;/a&gt;, and most notably they helped us recognize the &lt;a href=\"https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&amp;amp;s=08\"&gt;divine nature of ducks&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.&lt;/p&gt;\n\n&lt;p&gt;Emergent Abilities in LLMs&lt;/p&gt;\n\n&lt;p&gt;In a recent &lt;a href=\"https://arxiv.org/pdf/2206.07682.pdf\"&gt;paper from Google Brain&lt;/a&gt;, Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs will allow them, among other things, to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Become better at math&lt;/li&gt;\n&lt;li&gt;Understand even more subtleties of human language&lt;/li&gt;\n&lt;li&gt;Stop hallucinating and answer truthfully&lt;/li&gt;\n&lt;li&gt;...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(See the plot on break-out performance below for a full list)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Some Context:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does this happen?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;LLMs are commonly trained by &lt;a href=\"https://www.cs.ubc.ca/%7Eamuham01/LING530/papers/radford2018improving.pdf\"&gt;maximizing the likelihood&lt;/a&gt; over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.&lt;/p&gt;\n\n&lt;p&gt;Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s look at the following sentence.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The sum of two plus two is ...&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The model figures out that the most likely missing word is &amp;quot;four&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated &lt;a href=\"https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&amp;amp;ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F\"&gt;LLMs begin to struggle&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example are words that change their meaning with context. When the model encounters the word &amp;quot;bed&amp;quot;, it needs to figure out from the context, if the text is talking about a &amp;quot;river bed&amp;quot; or a &amp;quot;bed&amp;quot; to sleep in.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What they discovered:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (proxy for model size) is reached.&lt;/p&gt;\n\n&lt;p&gt;The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w7xffqjimmba1.png?width=800&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c573f6199db7b5ccebfa73ce8e58313e5ae27822\"&gt;Break-Out Performance At Critical Scale&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei&amp;#39;s personal blog. There he &lt;a href=\"https://www.jasonwei.net/blog/emergence\"&gt;listed a total of 137&lt;/a&gt; emergent abilities observable in LLMs.&lt;/p&gt;\n\n&lt;p&gt;Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.&lt;/p&gt;\n\n&lt;p&gt;(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.&lt;/p&gt;\n\n&lt;p&gt;There is &lt;a href=\"https://arxiv.org/abs/2203.15556\"&gt;other research&lt;/a&gt; suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So what does this mean exactly?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.&lt;/p&gt;\n\n&lt;p&gt;However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.&lt;/p&gt;\n\n&lt;p&gt;Such exciting times to be alive!&lt;/p&gt;\n\n&lt;p&gt;If you got down here, thank you! It was a privilege to make this for you.&lt;br/&gt;\nAt &lt;strong&gt;TheDecoding&lt;/strong&gt; \u2b55, I send out a thoughtful newsletter about ML research and the data economy once a week.&lt;br/&gt;\nNo Spam. No Nonsense. &lt;a href=\"https://thedecoding.net/\"&gt;Click here to sign up!&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a1mik", "is_robot_indexable": true, "report_reasons": null, "author": "LesleyFair", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a1mik/new_research_from_google_shines_light_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a1mik/new_research_from_google_shines_light_on_the/", "subreddit_subscribers": 836656, "created_utc": 1673535544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I created this website to help data professionals to find jobs across the globe. I hope it helps someone [https://bestdatajobs.com/](https://bestdatajobs.com/).", "author_fullname": "t2_10i9ox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job board focused on data-related positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a4upc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673543476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I created this website to help data professionals to find jobs across the globe. I hope it helps someone &lt;a href=\"https://bestdatajobs.com/\"&gt;https://bestdatajobs.com/&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?auto=webp&amp;v=enabled&amp;s=7d33e0d0617204d2c5b7f6c085324f96ce32961c", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcad11b0baf1f4ebbb41ef423772d6051c03904d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=715edf043dcaff30a192dffd7c964b48b3ed0864", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06a2d915073801529b5259a67cd1d4ded3ed53b1", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ffed8109990b53c78aa066de24fae92c86aa8133", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9a7c8666996e93741be03d88ea20de29de04a0e", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/E6f4YaDXyqldIIBAv3yB-4VsZWypEBIljQeS4xvd92A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3eee43ede5929242c1e1e8a44b0e1120ef0fec88", "width": 1080, "height": 564}], "variants": {}, "id": "jbPfVNFmntGIzd22YlFuLy3hAAqKfIlgxxRvgMUZINU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a4upc", "is_robot_indexable": true, "report_reasons": null, "author": "campostqe", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a4upc/job_board_focused_on_datarelated_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a4upc/job_board_focused_on_datarelated_positions/", "subreddit_subscribers": 836656, "created_utc": 1673543476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4zowqhsx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "5 Growing Libraries in Python for Causality Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 112, "top_awarded_type": null, "hide_score": false, "name": "t3_10ab0wb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/hjXvSl4PH8TOQxQZLbqPgaLopbMm03zsMi8J4zaZcf4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673558314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/towards-artificial-intelligence/5-growing-libraries-in-python-for-causality-analysis-39266d19edea", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?auto=webp&amp;v=enabled&amp;s=df9ae78c81dc0aa91d131c6ec84974e8917269f4", "width": 1024, "height": 825}, "resolutions": [{"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c79fa0793ec0ccfc2c1f3cc72a9710ba07df1a8c", "width": 108, "height": 87}, {"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9237efb6cf7c218816cb8d596fffe2838e26c67", "width": 216, "height": 174}, {"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c165519ce90a847c28320f9eb79a2ef56eba7ce5", "width": 320, "height": 257}, {"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38052e10bea3b6900d5a137f2d6d7727a89bc584", "width": 640, "height": 515}, {"url": "https://external-preview.redd.it/mpqy5Y2Coak1-Tom3AMghl-3QgMjEY7dl29cQpSHpIg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8400e0c67a2f5ae6a8661b1a5a91c301890f703", "width": 960, "height": 773}], "variants": {}, "id": "3ZAGUGvOSR4FtMN0dzBFJ61edjRoB01SCgtobvad2NQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ab0wb", "is_robot_indexable": true, "report_reasons": null, "author": "giorgiodidio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ab0wb/5_growing_libraries_in_python_for_causality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/towards-artificial-intelligence/5-growing-libraries-in-python-for-causality-analysis-39266d19edea", "subreddit_subscribers": 836656, "created_utc": 1673558314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For years I told myself I didn't want to be a manager. Too many meetings, people management, and I was afraid my technical skills would degrade or only develop superficially. But of course management is a natural and admirable next step in the corporate ladder. \n\nFor those who have experienced it, do you mind sharing your experience? Your overall opinion?", "author_fullname": "t2_n88sl8wf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists that became managers, how did that experience go for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10adkz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673564229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For years I told myself I didn&amp;#39;t want to be a manager. Too many meetings, people management, and I was afraid my technical skills would degrade or only develop superficially. But of course management is a natural and admirable next step in the corporate ladder. &lt;/p&gt;\n\n&lt;p&gt;For those who have experienced it, do you mind sharing your experience? Your overall opinion?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10adkz7", "is_robot_indexable": true, "report_reasons": null, "author": "bathroomworld", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10adkz7/data_scientists_that_became_managers_how_did_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10adkz7/data_scientists_that_became_managers_how_did_that/", "subreddit_subscribers": 836656, "created_utc": 1673564229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just 2 simple questions :\n\n1) Is data cleaning the most annoying part of the process?\n\n2) What alternative method do you use to clean your data other than pandas and Excel formulae ?", "author_fullname": "t2_4yke0pyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi data dudes! Lemme know what you think...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a24yx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673536832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just 2 simple questions :&lt;/p&gt;\n\n&lt;p&gt;1) Is data cleaning the most annoying part of the process?&lt;/p&gt;\n\n&lt;p&gt;2) What alternative method do you use to clean your data other than pandas and Excel formulae ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a24yx", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-You4014", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a24yx/hi_data_dudes_lemme_know_what_you_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a24yx/hi_data_dudes_lemme_know_what_you_think/", "subreddit_subscribers": 836656, "created_utc": 1673536832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have done due diligence and cleaned and removed outliers in my dataset. \n\n*This was not the study I actually did but trying to get an answer conceptually. \n\nIn my data set, I am trying to see if there is a correlation between course certifications and income. \n\nSay I have two sources of \u201ccourse certifications\u201d. For example 1 comes from someone\u2019s linked in and the other their resume\u2019 (not practical I know).\n\nThere is a moderately low positive correlation when looking at both groups of certifications and income. However, the p values for the resume\u2019 certifications are statistically significant while the p values for the linked in certifications are not. \n\nWould this indicate that while not strongly correlated, the resume\u2019 certifications are more reliable than the linked in source?", "author_fullname": "t2_4k7lwxqc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correlation Question (Beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a0k7n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673532641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have done due diligence and cleaned and removed outliers in my dataset. &lt;/p&gt;\n\n&lt;p&gt;*This was not the study I actually did but trying to get an answer conceptually. &lt;/p&gt;\n\n&lt;p&gt;In my data set, I am trying to see if there is a correlation between course certifications and income. &lt;/p&gt;\n\n&lt;p&gt;Say I have two sources of \u201ccourse certifications\u201d. For example 1 comes from someone\u2019s linked in and the other their resume\u2019 (not practical I know).&lt;/p&gt;\n\n&lt;p&gt;There is a moderately low positive correlation when looking at both groups of certifications and income. However, the p values for the resume\u2019 certifications are statistically significant while the p values for the linked in certifications are not. &lt;/p&gt;\n\n&lt;p&gt;Would this indicate that while not strongly correlated, the resume\u2019 certifications are more reliable than the linked in source?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a0k7n", "is_robot_indexable": true, "report_reasons": null, "author": "Data_rulez", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a0k7n/correlation_question_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a0k7n/correlation_question_beginner/", "subreddit_subscribers": 836656, "created_utc": 1673532641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Are there any data scientists here that came from a software engineering background? I have a 30 minute call next week with a software engineer (will most likely collaborate with him) for a SaaS company, and I'm wondering what would he/she ask - from a SE perspective. Thank you!", "author_fullname": "t2_xqw0k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Final round with a software engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aka9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673581707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any data scientists here that came from a software engineering background? I have a 30 minute call next week with a software engineer (will most likely collaborate with him) for a SaaS company, and I&amp;#39;m wondering what would he/she ask - from a SE perspective. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10aka9n", "is_robot_indexable": true, "report_reasons": null, "author": "surprise--me", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10aka9n/final_round_with_a_software_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10aka9n/final_round_with_a_software_engineer/", "subreddit_subscribers": 836656, "created_utc": 1673581707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm in the last leg of my PhD and was hoping for some thoughts and opinions as I transition into industry. My PhD is in agricultural science and the main focus of it involves running ML models on agricultural and geospatial datasets and then interpreting the results for agricultural decision making. I've been applying to DS positions in AgTech and would ideally get a position where I use ML with big ag/geospatial datasets to develop new tools, similar to my current work.\n\n&amp;#x200B;\n\nI'm very happy with what I've learned during my degree, especially with my soft skills and domain knowledge. The being said, I have a few months before I graduate and have been spending about an hour a day trying to beef up my technical skills. I'm good at learning new things and have been productive so far, but there's so just many ways that I could be spending my time here. I'd hugely appreciate some advice on how I should spend it.\n\n&amp;#x200B;\n\nHere's where I'm at:\n\n* My Python is just decent overall. I'm fairly strong with general DS work in Python (NumPy, pandas, matplot, etc.) and with working with sklearn models, and am a little weaker with general programming. I can easily do DS work when it's using datasets that I'm comfortable with, and can hold my own on out-of-domain practice datasets from Kaggle, although there's room for improvement. For more general programming, I'd say I can only do about half of the 'easy' ranked Leetcode problems.\n* I have basic GIS/Geo-Python skills.\n* I have basic MySQL programming skills from self-teaching, but have never actually used them in academia.\n* My statistics knowledge is moderately strong, particularly in my domain (biostats). Similarly, I have decently strong fundamental ML knowledge. I wouldn't say I'm an 'expert' in either of these categories.\n\n&amp;#x200B;\n\nHow would someone in my position prioritize their time? Grind DS on Kaggle? Focus on Leetcode-style programming? Get better at SQL? Improve my conceptual fundamentals in stats/ML/math? What about spending time learning more ancillary programs like AWS, Azure, Git, or Flask? Maybe learn something like TensorFlow or PyTorch? Something entirely different? One uncertainty I have is whether I would get more out of improving my existing skills or spending time adding new skills to my CV. \n\n&amp;#x200B;\n\nHope it's alright that I rambled a bit here. Overall, I feel fortunate that I have time to improve my skills but am a little unsure of what skills to prioritize. Discussion is open to anyone in a similar situation as well. Thanks in advance for any advice.", "author_fullname": "t2_c3p7wy9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What skills should I prioritize improving as I finish my PhD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aiexg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673576786.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673576467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m in the last leg of my PhD and was hoping for some thoughts and opinions as I transition into industry. My PhD is in agricultural science and the main focus of it involves running ML models on agricultural and geospatial datasets and then interpreting the results for agricultural decision making. I&amp;#39;ve been applying to DS positions in AgTech and would ideally get a position where I use ML with big ag/geospatial datasets to develop new tools, similar to my current work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m very happy with what I&amp;#39;ve learned during my degree, especially with my soft skills and domain knowledge. The being said, I have a few months before I graduate and have been spending about an hour a day trying to beef up my technical skills. I&amp;#39;m good at learning new things and have been productive so far, but there&amp;#39;s so just many ways that I could be spending my time here. I&amp;#39;d hugely appreciate some advice on how I should spend it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s where I&amp;#39;m at:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;My Python is just decent overall. I&amp;#39;m fairly strong with general DS work in Python (NumPy, pandas, matplot, etc.) and with working with sklearn models, and am a little weaker with general programming. I can easily do DS work when it&amp;#39;s using datasets that I&amp;#39;m comfortable with, and can hold my own on out-of-domain practice datasets from Kaggle, although there&amp;#39;s room for improvement. For more general programming, I&amp;#39;d say I can only do about half of the &amp;#39;easy&amp;#39; ranked Leetcode problems.&lt;/li&gt;\n&lt;li&gt;I have basic GIS/Geo-Python skills.&lt;/li&gt;\n&lt;li&gt;I have basic MySQL programming skills from self-teaching, but have never actually used them in academia.&lt;/li&gt;\n&lt;li&gt;My statistics knowledge is moderately strong, particularly in my domain (biostats). Similarly, I have decently strong fundamental ML knowledge. I wouldn&amp;#39;t say I&amp;#39;m an &amp;#39;expert&amp;#39; in either of these categories.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How would someone in my position prioritize their time? Grind DS on Kaggle? Focus on Leetcode-style programming? Get better at SQL? Improve my conceptual fundamentals in stats/ML/math? What about spending time learning more ancillary programs like AWS, Azure, Git, or Flask? Maybe learn something like TensorFlow or PyTorch? Something entirely different? One uncertainty I have is whether I would get more out of improving my existing skills or spending time adding new skills to my CV. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hope it&amp;#39;s alright that I rambled a bit here. Overall, I feel fortunate that I have time to improve my skills but am a little unsure of what skills to prioritize. Discussion is open to anyone in a similar situation as well. Thanks in advance for any advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10aiexg", "is_robot_indexable": true, "report_reasons": null, "author": "HelpWithMusicPC", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10aiexg/what_skills_should_i_prioritize_improving_as_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10aiexg/what_skills_should_i_prioritize_improving_as_i/", "subreddit_subscribers": 836656, "created_utc": 1673576467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Asking in terms of number of jobs available, competition and working conditions.\nTy", "author_fullname": "t2_128av8yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it still worth it going for a master degreee in data science in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aqiaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673602889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Asking in terms of number of jobs available, competition and working conditions.\nTy&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10aqiaw", "is_robot_indexable": true, "report_reasons": null, "author": "checaralho", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10aqiaw/is_it_still_worth_it_going_for_a_master_degreee/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10aqiaw/is_it_still_worth_it_going_for_a_master_degreee/", "subreddit_subscribers": 836656, "created_utc": 1673602889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Wanted to ask if anyone has gone through the hiring steps for a data analyst at CVS. Of the places Ive records call backs from its the most vague in terms of prior information available so any nods towards what they tend to cover is appreciated.", "author_fullname": "t2_7fu0lvtc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CVS Data Scientist Interview Process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ae7rl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673565703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to ask if anyone has gone through the hiring steps for a data analyst at CVS. Of the places Ive records call backs from its the most vague in terms of prior information available so any nods towards what they tend to cover is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10ae7rl", "is_robot_indexable": true, "report_reasons": null, "author": "Philo-Sophism", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ae7rl/cvs_data_scientist_interview_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ae7rl/cvs_data_scientist_interview_process/", "subreddit_subscribers": 836656, "created_utc": 1673565703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to find a package that is capable of creating simple 3D plots of data held in pandas dataframes with the same ease of use as seaborn. I am trying to teach my coworkers how to do data analysis in python (they only know excel) and i do not want to overwhelm them with the need for coding knowhow so something plug-and-play like seaborn would be ideal. I have been searching high and low but i cannot find anything suitable. Vispy seems to be the best candidate so far but it's a little too powerful for what we need. I am almost considering adapting seaborn scatterplot function for our needs with mplot3d but that's gonna be debug hell so i would like to avoid it if possible.", "author_fullname": "t2_9x6sdtq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anybody know an easy high-level plotting package in python similar to seaborn that is capable of making 3d scatterplots?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a2lwa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673538034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to find a package that is capable of creating simple 3D plots of data held in pandas dataframes with the same ease of use as seaborn. I am trying to teach my coworkers how to do data analysis in python (they only know excel) and i do not want to overwhelm them with the need for coding knowhow so something plug-and-play like seaborn would be ideal. I have been searching high and low but i cannot find anything suitable. Vispy seems to be the best candidate so far but it&amp;#39;s a little too powerful for what we need. I am almost considering adapting seaborn scatterplot function for our needs with mplot3d but that&amp;#39;s gonna be debug hell so i would like to avoid it if possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a2lwa", "is_robot_indexable": true, "report_reasons": null, "author": "vp_port", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a2lwa/does_anybody_know_an_easy_highlevel_plotting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a2lwa/does_anybody_know_an_easy_highlevel_plotting/", "subreddit_subscribers": 836656, "created_utc": 1673538034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently in high school and thinking of applying to Data science programs. I do not know much about Data Science except that it\u2019s a growing field. Would you recommend for someone to major in it? If so why? Thank you in advance.", "author_fullname": "t2_3nvrupsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Majoring in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10amrzw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673589311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently in high school and thinking of applying to Data science programs. I do not know much about Data Science except that it\u2019s a growing field. Would you recommend for someone to major in it? If so why? Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10amrzw", "is_robot_indexable": true, "report_reasons": null, "author": "milk0606", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10amrzw/majoring_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10amrzw/majoring_in_data_science/", "subreddit_subscribers": 836656, "created_utc": 1673589311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am tasked with completing the creation/analysis of a database from a dataset I can find online. This is for my masters in data science. I want to use this project as a way to showcase my skills for hiring managers. Does anyone have any opinions on what data set analysis would impress them as a hiring manager? Or a topic idea?", "author_fullname": "t2_dz6ua8ns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Project Ideas that would impress you as a hiring manager:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109ztfa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673530562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am tasked with completing the creation/analysis of a database from a dataset I can find online. This is for my masters in data science. I want to use this project as a way to showcase my skills for hiring managers. Does anyone have any opinions on what data set analysis would impress them as a hiring manager? Or a topic idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109ztfa", "is_robot_indexable": true, "report_reasons": null, "author": "Effective-Guava8142", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109ztfa/database_project_ideas_that_would_impress_you_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109ztfa/database_project_ideas_that_would_impress_you_as/", "subreddit_subscribers": 836656, "created_utc": 1673530562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ve46jrfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quantum Machine Learning: A Beginner\u2019s Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10anhmi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qjNXA0UU9bvdSkeUhwh7x9LcfxhTuf8lk0j7b7in_Eg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673591616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/7c7f1d349693", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?auto=webp&amp;v=enabled&amp;s=8382a0bc73a9c1dd91be4ab9c08233e66df0651a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4adf4d86a35d686aed615dd4b53f52651131d291", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70cbcc70e7838116e97501f30436951299872dd2", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a670593615719559dece598284aa00ba073a0e0", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75514a2ce02a0b1cc4525fc5b44eb9faa51c176a", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baca5b72f65bab7ac42da33f4689b4bc8c7326d9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/yVAS2p9SZfFbFRwCg9veczzx1WQQFaOquGAxSwJiviU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b02773112cbc1e742683cf96f6acb701ed97499d", "width": 1080, "height": 720}], "variants": {}, "id": "4CBkgrXSs0T_nIM4Kb6jGJ3Vg6MImM0UzYVkZXm86EE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10anhmi", "is_robot_indexable": true, "report_reasons": null, "author": "Distinct-Moose-8532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10anhmi/quantum_machine_learning_a_beginners_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/7c7f1d349693", "subreddit_subscribers": 836656, "created_utc": 1673591616.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newbie here. I was wondering how can we estimate/quantify data veracity, given that it is somewhat abstract without any specific method (from what I know so far). What statistical/mathematical approaches maybe helpful for this purpose? Furthermore, how do we link data veracity to the value?", "author_fullname": "t2_vim9c74n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to estimate/quantify data veracity and value?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aix1i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673577868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newbie here. I was wondering how can we estimate/quantify data veracity, given that it is somewhat abstract without any specific method (from what I know so far). What statistical/mathematical approaches maybe helpful for this purpose? Furthermore, how do we link data veracity to the value?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10aix1i", "is_robot_indexable": true, "report_reasons": null, "author": "KH327", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10aix1i/how_to_estimatequantify_data_veracity_and_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10aix1i/how_to_estimatequantify_data_veracity_and_value/", "subreddit_subscribers": 836656, "created_utc": 1673577868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Best analytics or data science societies or groups to join that are either non-regional or east coast? Want to join and to projects / competitions with friends from grad school but we are all dispersed across the country now. \n\nIk Kaggle but other than that. Something more of a society or group. (: thanks!", "author_fullname": "t2_5njlw0ic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science / analytics societies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a0ram", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673533171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Best analytics or data science societies or groups to join that are either non-regional or east coast? Want to join and to projects / competitions with friends from grad school but we are all dispersed across the country now. &lt;/p&gt;\n\n&lt;p&gt;Ik Kaggle but other than that. Something more of a society or group. (: thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a0ram", "is_robot_indexable": true, "report_reasons": null, "author": "sunflowerworms", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a0ram/data_science_analytics_societies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a0ram/data_science_analytics_societies/", "subreddit_subscribers": 836656, "created_utc": 1673533171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a0oh9j1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analytics Trends You Need To Know (2023) - more aimed at data analytics, but there are some useful insight for data scientists too!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_109zsr6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Fv0dlGGIKTQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Analytics Trends You Need To Know (2023)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Analytics Trends You Need To Know (2023)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Fv0dlGGIKTQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Analytics Trends You Need To Know (2023)\"&gt;&lt;/iframe&gt;", "author_name": "CareerFoundry", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Fv0dlGGIKTQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@careerfoundry"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Fv0dlGGIKTQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Analytics Trends You Need To Know (2023)\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/109zsr6", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ggCFh5hgsjGjJmHjERm-YN0ggPiAlIzlDF-54LIglT4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673530508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/Fv0dlGGIKTQ", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JQIa9M7bNHKvqNmdML3EKFA5QWvdZ4xAinB8hiFmy5c.jpg?auto=webp&amp;v=enabled&amp;s=8c7f5c22206296758c15e8197ce680f6d8607f5e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/JQIa9M7bNHKvqNmdML3EKFA5QWvdZ4xAinB8hiFmy5c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d26a17cf53f6ac0e7b9d1ff47c1faee5e523548", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/JQIa9M7bNHKvqNmdML3EKFA5QWvdZ4xAinB8hiFmy5c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4dbadb482580ec1c57f3fcd49ababdac6d19f138", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/JQIa9M7bNHKvqNmdML3EKFA5QWvdZ4xAinB8hiFmy5c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79fae16cc3acc39c9fa312bfdf1b5d5cea01fc96", "width": 320, "height": 240}], "variants": {}, "id": "c9MNbTtFpBZLoOhDahSwjo7TsPHiLTySu0VZTFMw2Lo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "109zsr6", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Narwhal15", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109zsr6/data_analytics_trends_you_need_to_know_2023_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/Fv0dlGGIKTQ", "subreddit_subscribers": 836656, "created_utc": 1673530508.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Data Analytics Trends You Need To Know (2023)", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Fv0dlGGIKTQ?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Data Analytics Trends You Need To Know (2023)\"&gt;&lt;/iframe&gt;", "author_name": "CareerFoundry", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Fv0dlGGIKTQ/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@careerfoundry"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm about to finish my BA in economics and politics and want to get into data science (probably first data analysis) after that. I have been applying a bunch but haven't really heard back. I am applying to German companies if this is important.\n\nI am not sure if my degree is the issue, since it is quite far from the field of data science, or if I am simply making obvious mistakes on my resume. I taught myself R, Python and basic SQL and Tableau and took the Google Data Analytics course as well as one on machine learning using R. I am not sure how to present those outside of my projects. Do I just mention them somewhere?\n\nAlso my Tableau Viz that I have linked is very basic, do you think I should just leave it out?\n\nThank you for any advice in advance!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/or86pq65osba1.png?width=1654&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f9ee13d8be16f99ad3efe7c1b3c74d70f92d3763", "author_fullname": "t2_9odflfnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would love some advice on my resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"or86pq65osba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 152, "x": 108, "u": "https://preview.redd.it/or86pq65osba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46c1b55361a7ba9ca5707c4c74b9bf2ad531905b"}, {"y": 305, "x": 216, "u": "https://preview.redd.it/or86pq65osba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7c47f2c25d20598d6fe22a35589247f71c7a939"}, {"y": 452, "x": 320, "u": "https://preview.redd.it/or86pq65osba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9f9f7a74301febd7937e7db1bf638022ba45434"}, {"y": 905, "x": 640, "u": "https://preview.redd.it/or86pq65osba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19e725820abc1992b0b7f0c50d9c4156669cc795"}, {"y": 1357, "x": 960, "u": "https://preview.redd.it/or86pq65osba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5be1ca971bf9997f1edd16802efd30003fc31ef2"}, {"y": 1527, "x": 1080, "u": "https://preview.redd.it/or86pq65osba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8944679fbde3793247deaef4a95bf2ccc5e793d"}], "s": {"y": 2339, "x": 1654, "u": "https://preview.redd.it/or86pq65osba1.png?width=1654&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f9ee13d8be16f99ad3efe7c1b3c74d70f92d3763"}, "id": "or86pq65osba1"}}, "name": "t3_10as42v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p13HYOfrIIkBkGFvfY-sHsNXH0suAt_4-71bcwOFMPw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673608817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to finish my BA in economics and politics and want to get into data science (probably first data analysis) after that. I have been applying a bunch but haven&amp;#39;t really heard back. I am applying to German companies if this is important.&lt;/p&gt;\n\n&lt;p&gt;I am not sure if my degree is the issue, since it is quite far from the field of data science, or if I am simply making obvious mistakes on my resume. I taught myself R, Python and basic SQL and Tableau and took the Google Data Analytics course as well as one on machine learning using R. I am not sure how to present those outside of my projects. Do I just mention them somewhere?&lt;/p&gt;\n\n&lt;p&gt;Also my Tableau Viz that I have linked is very basic, do you think I should just leave it out?&lt;/p&gt;\n\n&lt;p&gt;Thank you for any advice in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/or86pq65osba1.png?width=1654&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f9ee13d8be16f99ad3efe7c1b3c74d70f92d3763\"&gt;https://preview.redd.it/or86pq65osba1.png?width=1654&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f9ee13d8be16f99ad3efe7c1b3c74d70f92d3763&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10as42v", "is_robot_indexable": true, "report_reasons": null, "author": "Mori-Spumae", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10as42v/would_love_some_advice_on_my_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10as42v/would_love_some_advice_on_my_resume/", "subreddit_subscribers": 836656, "created_utc": 1673608817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear all,\n\nI've been building a codon optimizer (translating amino acids to DNA codons) using the transformer model 'Attention is all you need'. I've been training it on 1,5 million tokens. As the image shows the loss is stuck and very stable at 1.05, even after 4000 epochs (see figure A). When I use the model for interference I see that it does a lot right, how ever it seems not possible for it to find the &lt;EOS&gt; token. Figure B shows my inference with the bold tokens showing the desired length. It goes all the way untill it reaches the max\\_len constraint. The average length of the translated sequence is 300 tokens and a maximum of 1000 tokens. My questions: How can I stimulate the model to find the &lt;EOS&gt;? Since the length of the source is always the same length as the target can I hard code the EOS, would this help? Do I have enough tokens to train on or should i get more? If you need more information I can provide it :)\n\nThank you for helping me out,\n\nGreetings from the Netherlands,\n\nDaan\n\n&amp;#x200B;\n\nhttps://preview.redd.it/r40zme9a7sba1.png?width=1868&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1b54ef9d7014f9ec3b41e23a0a68a263ff1652f4", "author_fullname": "t2_6x50hbyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transformer not converging because it cannot find EOS token", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "media_metadata": {"r40zme9a7sba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8de49d99a00f039af9a7b0dfe739ea9a3cdaf101"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80d3acf734e08f53891b829455af13e192dfffba"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afa1619d87686d705e03e63b420a408e4f8d2036"}, {"y": 361, "x": 640, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b812f5d908398e90771beac2333ec6ff33524da7"}, {"y": 542, "x": 960, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2202d75f1498e82e8e0f9ff50026bbb2770cd260"}, {"y": 609, "x": 1080, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a199abe24660883ec378c63e830543d49e4489a3"}], "s": {"y": 1055, "x": 1868, "u": "https://preview.redd.it/r40zme9a7sba1.png?width=1868&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1b54ef9d7014f9ec3b41e23a0a68a263ff1652f4"}, "id": "r40zme9a7sba1"}}, "name": "t3_10aqj7f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tER3qDmViWu17SbeGKXUxEuCMy7A8uzYi3Ho7VNGveA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673602987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been building a codon optimizer (translating amino acids to DNA codons) using the transformer model &amp;#39;Attention is all you need&amp;#39;. I&amp;#39;ve been training it on 1,5 million tokens. As the image shows the loss is stuck and very stable at 1.05, even after 4000 epochs (see figure A). When I use the model for interference I see that it does a lot right, how ever it seems not possible for it to find the &amp;lt;EOS&amp;gt; token. Figure B shows my inference with the bold tokens showing the desired length. It goes all the way untill it reaches the max_len constraint. The average length of the translated sequence is 300 tokens and a maximum of 1000 tokens. My questions: How can I stimulate the model to find the &amp;lt;EOS&amp;gt;? Since the length of the source is always the same length as the target can I hard code the EOS, would this help? Do I have enough tokens to train on or should i get more? If you need more information I can provide it :)&lt;/p&gt;\n\n&lt;p&gt;Thank you for helping me out,&lt;/p&gt;\n\n&lt;p&gt;Greetings from the Netherlands,&lt;/p&gt;\n\n&lt;p&gt;Daan&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r40zme9a7sba1.png?width=1868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1b54ef9d7014f9ec3b41e23a0a68a263ff1652f4\"&gt;https://preview.redd.it/r40zme9a7sba1.png?width=1868&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=1b54ef9d7014f9ec3b41e23a0a68a263ff1652f4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10aqj7f", "is_robot_indexable": true, "report_reasons": null, "author": "Defiant-Nobody642", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10aqj7f/transformer_not_converging_because_it_cannot_find/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10aqj7f/transformer_not_converging_because_it_cannot_find/", "subreddit_subscribers": 836656, "created_utc": 1673602987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_s06e5vkl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get the domain expertise as a beginner to become a data scientis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10amngv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673588901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10amngv", "is_robot_indexable": true, "report_reasons": null, "author": "master_crazy69", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10amngv/how_to_get_the_domain_expertise_as_a_beginner_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10amngv/how_to_get_the_domain_expertise_as_a_beginner_to/", "subreddit_subscribers": 836656, "created_utc": 1673588901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m torn on what programming language I want to teach/use in my course.\n\nAcademia tells me R.\n\nIndustry tells me Python.\n\nJokingly (kinda) I want to program in Julia.\n\nWhen I was getting my masters it was in R, then I went to industry and Python was just awesome! The wrappers for PySpark, ML packages all made sense to me. Then I wanted to challenge myself and I learned Julia\u2026which I absolutely love. \n\nI\u2019m teaching an undergraduate level course. What should I choose for my course?\n\nEdits: wow hella grammar mistake. Embarrassing for a teacher.", "author_fullname": "t2_4hpiqt08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programming Language for Class", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10agryb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673576505.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673572139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m torn on what programming language I want to teach/use in my course.&lt;/p&gt;\n\n&lt;p&gt;Academia tells me R.&lt;/p&gt;\n\n&lt;p&gt;Industry tells me Python.&lt;/p&gt;\n\n&lt;p&gt;Jokingly (kinda) I want to program in Julia.&lt;/p&gt;\n\n&lt;p&gt;When I was getting my masters it was in R, then I went to industry and Python was just awesome! The wrappers for PySpark, ML packages all made sense to me. Then I wanted to challenge myself and I learned Julia\u2026which I absolutely love. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m teaching an undergraduate level course. What should I choose for my course?&lt;/p&gt;\n\n&lt;p&gt;Edits: wow hella grammar mistake. Embarrassing for a teacher.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10agryb", "is_robot_indexable": true, "report_reasons": null, "author": "CmdrAstroNaughty", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10agryb/programming_language_for_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10agryb/programming_language_for_class/", "subreddit_subscribers": 836656, "created_utc": 1673572139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4cx0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Made a meme for an onsite assignment presentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10abefa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/x8GBHhw0aaWCK1zwyKmHkHvbMNGpIqz7Rcyxu_gy6Ko.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673559167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cy32gg2vkoba1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cy32gg2vkoba1.png?auto=webp&amp;v=enabled&amp;s=94147b39844a2fbbeb504a51188af22020765332", "width": 1770, "height": 994}, "resolutions": [{"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6255f181f83125465488bcfe42de3b889f03c9d3", "width": 108, "height": 60}, {"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5d62570ab328c01eef2dc7d765a53b065918cf9", "width": 216, "height": 121}, {"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f76fe7f52279eb12b830436be90047e9d33868d", "width": 320, "height": 179}, {"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f1a241e257d73579da566a253015c3207e64ced", "width": 640, "height": 359}, {"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2aba33b6ca56ebd61f2d23732699967aea2adf98", "width": 960, "height": 539}, {"url": "https://preview.redd.it/cy32gg2vkoba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be0acacab3de3793a24670949c7ac0a3da0a88ed", "width": 1080, "height": 606}], "variants": {}, "id": "5peBui1d_9CPknNxRfZ980dtTOoY_NPZC2Bd2CEMqrI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10abefa", "is_robot_indexable": true, "report_reasons": null, "author": "Bagelthief", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10abefa/made_a_meme_for_an_onsite_assignment_presentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cy32gg2vkoba1.png", "subreddit_subscribers": 836656, "created_utc": 1673559167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently solving a transportation problem in CPLEX, need to implement a constraint that warehouse one can no longer serve customers 1-5.\n\nAny suggestions?", "author_fullname": "t2_e287cydl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transport problem constraint", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a9ynx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673555806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently solving a transportation problem in CPLEX, need to implement a constraint that warehouse one can no longer serve customers 1-5.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a9ynx", "is_robot_indexable": true, "report_reasons": null, "author": "Applesoranges124", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a9ynx/transport_problem_constraint/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a9ynx/transport_problem_constraint/", "subreddit_subscribers": 836656, "created_utc": 1673555806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "To the people who have earned cloud certifications such as azure DS and GCP ml engineer. Has it paid off during your job?\n\nMy situation is org is transitioning to GCP and not many have that skill. So up-skilling can be a serious asset. I have 1 year experience of coops and internships + masters but no full time permanent experience. \n\nCan you share your stories?", "author_fullname": "t2_2sm7vahg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud certifications and promotions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a5hno", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673545050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To the people who have earned cloud certifications such as azure DS and GCP ml engineer. Has it paid off during your job?&lt;/p&gt;\n\n&lt;p&gt;My situation is org is transitioning to GCP and not many have that skill. So up-skilling can be a serious asset. I have 1 year experience of coops and internships + masters but no full time permanent experience. &lt;/p&gt;\n\n&lt;p&gt;Can you share your stories?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10a5hno", "is_robot_indexable": true, "report_reasons": null, "author": "Tarneks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10a5hno/cloud_certifications_and_promotions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10a5hno/cloud_certifications_and_promotions/", "subreddit_subscribers": 836656, "created_utc": 1673545050.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}