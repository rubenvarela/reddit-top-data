{"kind": "Listing", "data": {"after": "t3_109yn4c", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5z5rj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "YouTubers said they destroyed over 100 VHS tapes of an obscure 1987 movie to increase the value of their final copy. They sold it on eBay for $80,600.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10a50y4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 938, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 938, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Qv6VDMJ9RIpS_qPBQ49h4TZuGnbi7vn-81cpkqngm2Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673543913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "insider.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.insider.com/youtubers-destroy-nukie-vhs-tape-collectable-ebay-sale-redlettermedia-2023-1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?auto=webp&amp;v=enabled&amp;s=eeec15dd0fc4a21f4b70116ef9efdaab0d529fca", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c58fe37eba227f4d81b2839e2086d8bf3e388eb5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=22769873551441f606718b7c7af2fc76eaeba25b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4187a265dcbbb07b8e58d84e8bd6a093e2e80ee", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b27a59c96af5d6556352631ef545aaa0eb11992b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d7b3a5c0168f9b727303ef54e8c063e24841299", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/kSRLcifnH85uyd5JGm4cflV_eZCwGKODHE5RUbddi5M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be08317c9a35c9da4e5399b1c5ba6898750ecbd4", "width": 1080, "height": 540}], "variants": {}, "id": "xRZTtLBIe0INmo3ybLtCCz7LqQtFpG1yBU1egx6NDfk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a50y4", "is_robot_indexable": true, "report_reasons": null, "author": "ET2-SW", "discussion_type": null, "num_comments": 258, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a50y4/youtubers_said_they_destroyed_over_100_vhs_tapes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.insider.com/youtubers-destroy-nukie-vhs-tape-collectable-ebay-sale-redlettermedia-2023-1", "subreddit_subscribers": 665611, "created_utc": 1673543913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Micron Unveils 9400 SSD: 30 TB Capacities With Best-In-Class Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "name": "t3_10a4nvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/AC0ueZqYqdOMzCdm3ntxWB65qmLoxW0SUkHoeuH1Bds.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673543009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "wccftech.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://wccftech.com/micron-unveils-9400-ssd-30-tb-capacities-with-best-in-class-performance/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?auto=webp&amp;v=enabled&amp;s=c5683a71bf7f47729b0ff2c5cc693e5e54236a37", "width": 980, "height": 620}, "resolutions": [{"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f096790349c2231fec800a7e162ac38ff971e054", "width": 108, "height": 68}, {"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c6c9f335d72366983fe496f7108b7ba824b5f74", "width": 216, "height": 136}, {"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6be074be75dbd483261d4e50615feebc1a996a10", "width": 320, "height": 202}, {"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=14a9c87bb2670e5df83de7748e5ddaa8c8813a88", "width": 640, "height": 404}, {"url": "https://external-preview.redd.it/ytVstvPnKHj54pM1Qo75ZoZa4XzbvbMCkazABs59QHs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5652b2fb0ca0e91c36cb053db1abddf73351f32", "width": 960, "height": 607}], "variants": {}, "id": "Z0sSJbkM797eMfo6AVw0nJG4sVsDUTAEeTjiWS9-Vlc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a4nvv", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10a4nvv/micron_unveils_9400_ssd_30_tb_capacities_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://wccftech.com/micron-unveils-9400-ssd-30-tb-capacities-with-best-in-class-performance/", "subreddit_subscribers": 665611, "created_utc": 1673543009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've located and reuploaded a long lost UnleashX skin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_109vz32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2b9r7ngd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jnjs0qw2eBd5aTzRu8i0sLwfd-qlwww-SgI8E2Y9eSE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "originalxbox", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2072dcd672302c1afa94268bcd3f1514386135f7\n\nI archived an UnleashX skin that was deleted off the internet suddenly. It was posted to Twitter by its creator Retro Game Rarities in 2020 and his account suddenly got deleted. I was able to find a link to it via google cache and I've since reuploaded it to [archive.org](https://archive.org)\n\n[https://archive.org/details/UnleashX-EmeraldX-skin](https://archive.org/details/UnleashX-EmeraldX-skin)\n\nIt's easily the coolest looking UnleashX skin I've ever seen. It was disappointing to discover it was so hastily deleted and purged off the internet.\n\n&amp;#x200B;\n\nThe creator's original video is here\n\nhttps://reddit.com/link/109ri3e/video/icgsgx97ujba1/player", "author_fullname": "t2_77nrtq1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've located and reuploaded a long lost UnleashX skin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/originalxbox", "hidden": false, "pwls": 6, "link_flair_css_class": "tools", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "media_metadata": {"20rcv4cgtjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efe2643dd2b8fbcee893090d86edbc036005feda"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c285fb7495f33678c3b1ed7089e7269b1a5d74b"}, {"y": 177, "x": 320, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76a2a4d9e3b0066cf79801458a08be4ba34f33a4"}, {"y": 355, "x": 640, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f108e3c16a23e91941d839c7142df34078624251"}], "s": {"y": 383, "x": 689, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2072dcd672302c1afa94268bcd3f1514386135f7"}, "id": "20rcv4cgtjba1"}, "icgsgx97ujba1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/109ri3e/asset/icgsgx97ujba1/DASHPlaylist.mpd?a=1676176951%2CMGI1YWZhOTJiN2E3MmEwZTUyYmQwMDgxNTVkODM0MmU5YjgzOGI2YmUxZWRiYTZlYzcxY2I1MGU5M2IzYjYxMg%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 720, "hlsUrl": "https://v.redd.it/link/109ri3e/asset/icgsgx97ujba1/HLSPlaylist.m3u8?a=1676176951%2CZWIyZmQyNGM1NTU4ZDJhYjgzZTMwM2UxOWFkN2Q3MWY2ZWY1MDJlMzJiMzUxOWU2OGY2YmViN2Y4NmQxOWQxNQ%3D%3D&amp;v=1&amp;f=sd", "id": "icgsgx97ujba1", "isGif": false}}, "name": "t3_109ri3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Software &amp; Tools", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jnjs0qw2eBd5aTzRu8i0sLwfd-qlwww-SgI8E2Y9eSE.jpg", "edited": 1673516612.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673501638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.originalxbox", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2072dcd672302c1afa94268bcd3f1514386135f7\"&gt;https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2072dcd672302c1afa94268bcd3f1514386135f7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I archived an UnleashX skin that was deleted off the internet suddenly. It was posted to Twitter by its creator Retro Game Rarities in 2020 and his account suddenly got deleted. I was able to find a link to it via google cache and I&amp;#39;ve since reuploaded it to &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://archive.org/details/UnleashX-EmeraldX-skin\"&gt;https://archive.org/details/UnleashX-EmeraldX-skin&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s easily the coolest looking UnleashX skin I&amp;#39;ve ever seen. It was disappointing to discover it was so hastily deleted and purged off the internet.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The creator&amp;#39;s original video is here&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/109ri3e/video/icgsgx97ujba1/player\"&gt;https://reddit.com/link/109ri3e/video/icgsgx97ujba1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "65253322-f811-11ec-aadc-4685b9374796", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rww7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109ri3e", "is_robot_indexable": true, "report_reasons": null, "author": "Archer_Jr", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "subreddit_subscribers": 50906, "created_utc": 1673501638.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1673517607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.originalxbox", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109vz32", "is_robot_indexable": true, "report_reasons": null, "author": "RustedBlade7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_109ri3e", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109vz32/ive_located_and_reuploaded_a_long_lost_unleashx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "subreddit_subscribers": 665611, "created_utc": 1673517607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got about 300,000 emails going back to 1993.  I love having the whole thing indexed and searchable for practical and nostalgic purposes, but the ratio of \"good\" to \"bad\" is ridiculous.  Even with gmail doing a lot of the heavy spam filtering, it's got a lot of garbage.\n\nDoes anyone have any pointers on how to efficiently spam filter large quantities of email spread across about 30 unix mbox files?  \n\nIf I had to, I'd be OK resorting to something somewhat iterative and convoluted (somehow feed all the mbox files to a mail server running on one of my linux boxes?) but it would be nice if there were tools out there to make this as easy as possible.", "author_fullname": "t2_tthrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "30 years of saved email - spam filtering options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a02eo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673531289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got about 300,000 emails going back to 1993.  I love having the whole thing indexed and searchable for practical and nostalgic purposes, but the ratio of &amp;quot;good&amp;quot; to &amp;quot;bad&amp;quot; is ridiculous.  Even with gmail doing a lot of the heavy spam filtering, it&amp;#39;s got a lot of garbage.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any pointers on how to efficiently spam filter large quantities of email spread across about 30 unix mbox files?  &lt;/p&gt;\n\n&lt;p&gt;If I had to, I&amp;#39;d be OK resorting to something somewhat iterative and convoluted (somehow feed all the mbox files to a mail server running on one of my linux boxes?) but it would be nice if there were tools out there to make this as easy as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a02eo", "is_robot_indexable": true, "report_reasons": null, "author": "lectures", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a02eo/30_years_of_saved_email_spam_filtering_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a02eo/30_years_of_saved_email_spam_filtering_options/", "subreddit_subscribers": 665611, "created_utc": 1673531289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI download a lot of content for archival purposes. These contents are typically downloaded as ZIP or RAR archives which then have to be extracted. I am wondering if there is any way I can automatically add read-only attributes to all files as they are being extracted (eg. as an option inside WinRAR or 7-Zip) instead of having to manually select the folder afterwards, then right-clicking and selecting the read-only checkbox (which sometimes I forget to do)\n\nThanks in advance!", "author_fullname": "t2_fcjv96r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Windows] Is there any way to automatically add read-only attributes to all files extracted by WinRAR or 7-Zip?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a3vd9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673541140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I download a lot of content for archival purposes. These contents are typically downloaded as ZIP or RAR archives which then have to be extracted. I am wondering if there is any way I can automatically add read-only attributes to all files as they are being extracted (eg. as an option inside WinRAR or 7-Zip) instead of having to manually select the folder afterwards, then right-clicking and selecting the read-only checkbox (which sometimes I forget to do)&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a3vd9", "is_robot_indexable": true, "report_reasons": null, "author": "P650SE", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a3vd9/windows_is_there_any_way_to_automatically_add/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a3vd9/windows_is_there_any_way_to_automatically_add/", "subreddit_subscribers": 665611, "created_utc": 1673541140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to grab a VKontakte group's media hoard- specifically the photos. I'm not up to no good (much), it's just a public fanpage for a celeb but it goes back too many years to save everything individually. We're talking nearly 4500 pics, and I may want the video too, idk yet.\n\nI turn to the DH brains trust here to advise me- what is the best way to do this? Are there any dedicated bulk VK rippers? I have had a google and JDownloader is an option I've investigated, but it's not grabbing everything (I have a tech support Q pending on the JD sub, but I think im going to be S.O.O.L). I need *everything. E.v.e.r.y. t. h. i. n. g.*\n\nHelp a fangirl out, how do I do this?\n\nI can *maybe* deal with a program in Russian if I have to. I can't code, I'm looking for an off the shelf solution.\n\nETA- Internet Download Manager and DownAll from the sub wiki didn't get anywhere.", "author_fullname": "t2_5l13q7a9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to hoard a VK profile/group?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109voht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673521458.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673516482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to grab a VKontakte group&amp;#39;s media hoard- specifically the photos. I&amp;#39;m not up to no good (much), it&amp;#39;s just a public fanpage for a celeb but it goes back too many years to save everything individually. We&amp;#39;re talking nearly 4500 pics, and I may want the video too, idk yet.&lt;/p&gt;\n\n&lt;p&gt;I turn to the DH brains trust here to advise me- what is the best way to do this? Are there any dedicated bulk VK rippers? I have had a google and JDownloader is an option I&amp;#39;ve investigated, but it&amp;#39;s not grabbing everything (I have a tech support Q pending on the JD sub, but I think im going to be S.O.O.L). I need &lt;em&gt;everything. E.v.e.r.y. t. h. i. n. g.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Help a fangirl out, how do I do this?&lt;/p&gt;\n\n&lt;p&gt;I can &lt;em&gt;maybe&lt;/em&gt; deal with a program in Russian if I have to. I can&amp;#39;t code, I&amp;#39;m looking for an off the shelf solution.&lt;/p&gt;\n\n&lt;p&gt;ETA- Internet Download Manager and DownAll from the sub wiki didn&amp;#39;t get anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109voht", "is_robot_indexable": true, "report_reasons": null, "author": "nectarine_pie", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109voht/best_way_to_hoard_a_vk_profilegroup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109voht/best_way_to_hoard_a_vk_profilegroup/", "subreddit_subscribers": 665611, "created_utc": 1673516482.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got the HDDs of almost every computer I've ever owned sitting in a box. I recently built myself a NAS and would like to save the contents of the disks to the NAS. I want to keep a full copy of the disk and not just common locations such as \"My Documents\" etc.\n\nI originally tried the na\u00efve approach of copying the entire contents of the drive into a folder. This doesn't work too well for Windows boot drives, as there are millions of tiny files all over the place. Even my 128GB SSD took over 24 hours to transfer.\n\nWhat I'm looking for is:\n\n* Ideally filesystem agnostic - while most of my drives are NTFS I have several from machines running Linux and macOS. Windows-only is better than nothing though.\n* Something that creates a single file that can be opened/mounted to view files.\n* Only the size of used space - I believe this rules out most types of disk image. I don't want to store an 8TB file for a drive that only has 100GB saved on it.\n* Free and preferably open source tools available for creation and viewing.\n\nI'm not sure if there's anything that exists that meets all my requirements but I'd be interested to know of anything that comes close. I'd also be interested to know what other people do to archive their old hard drives.\n\nThanks!", "author_fullname": "t2_rf5b8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to archive contents of old HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10agls0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673571698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got the HDDs of almost every computer I&amp;#39;ve ever owned sitting in a box. I recently built myself a NAS and would like to save the contents of the disks to the NAS. I want to keep a full copy of the disk and not just common locations such as &amp;quot;My Documents&amp;quot; etc.&lt;/p&gt;\n\n&lt;p&gt;I originally tried the na\u00efve approach of copying the entire contents of the drive into a folder. This doesn&amp;#39;t work too well for Windows boot drives, as there are millions of tiny files all over the place. Even my 128GB SSD took over 24 hours to transfer.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ideally filesystem agnostic - while most of my drives are NTFS I have several from machines running Linux and macOS. Windows-only is better than nothing though.&lt;/li&gt;\n&lt;li&gt;Something that creates a single file that can be opened/mounted to view files.&lt;/li&gt;\n&lt;li&gt;Only the size of used space - I believe this rules out most types of disk image. I don&amp;#39;t want to store an 8TB file for a drive that only has 100GB saved on it.&lt;/li&gt;\n&lt;li&gt;Free and preferably open source tools available for creation and viewing.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if there&amp;#39;s anything that exists that meets all my requirements but I&amp;#39;d be interested to know of anything that comes close. I&amp;#39;d also be interested to know what other people do to archive their old hard drives.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10agls0", "is_robot_indexable": true, "report_reasons": null, "author": "Nogtail", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10agls0/best_way_to_archive_contents_of_old_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10agls0/best_way_to_archive_contents_of_old_hdds/", "subreddit_subscribers": 665611, "created_utc": 1673571698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7l2p5s3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2010-Present: At ten years old, I started collecting the music I was listening to after finding an ipod nano next to a drunk guy sleeping on my front lawn. 11 GB isn't a lot, but I'm still proud of hauling these tracks around for 12 years straight.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10abzbp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Audio Data", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/M-t7fnovqe2WstYdUHEZWYUyII_PtebRC--jIOobsr0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673560512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/5q6309u4aoba1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/5q6309u4aoba1.png?auto=webp&amp;v=enabled&amp;s=c345d10e74ba82f3d114f97725d2229e0b7b13bc", "width": 303, "height": 313}, "resolutions": [{"url": "https://preview.redd.it/5q6309u4aoba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d95b3105e04660a6b7e3340da5f57b32f074ab59", "width": 108, "height": 111}, {"url": "https://preview.redd.it/5q6309u4aoba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce58d3ded722b1eb2c8754f251a3afef62b16628", "width": 216, "height": 223}], "variants": {}, "id": "_PXHrjLaqDIiAWLyr_Xmd27OGgLdjJA4oqHgm7Z9Vf0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10abzbp", "is_robot_indexable": true, "report_reasons": null, "author": "shinnith", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10abzbp/2010present_at_ten_years_old_i_started_collecting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/5q6309u4aoba1.png", "subreddit_subscribers": 665611, "created_utc": 1673560512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nI am not that much of a hoarder rather a storage/compute/backup specialist.\n\nLast couple of months I found that torrent trackers don't have movies in my native language. So for me the tube is best source of movies and even 4k nature videos. Can you share with me what proof to be best way for you to download YT videos/playlist both 720p and 4k?\n\nPS\n\nHere is a snip from session that will time out:\n\nuser@host:\\~$ ls -lh\n\ntotal 235M\n\n\\-rw-rw-r-- 1 user 235M Jan  4 21:02 '\u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm.part'\n\nuser@host:\\~$ rm '\u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm.part'\n\nuser@host:\\~$ youtube-dl -f 315 [https://www.youtube.com/watch?v=LCDDzLK-sys](https://www.youtube.com/watch?v=LCDDzLK-sys)\n\n\\[youtube\\] LCDDzLK-sys: Downloading webpage\n\n\\[download\\] Destination: \u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm\n\n\\[download\\]   0.9% of 2.76GiB at 70.46KiB/s ETA 11:17:32", "author_fullname": "t2_db0rv0yp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you like to dump 4k Youtube videos ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aa20l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673556026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am not that much of a hoarder rather a storage/compute/backup specialist.&lt;/p&gt;\n\n&lt;p&gt;Last couple of months I found that torrent trackers don&amp;#39;t have movies in my native language. So for me the tube is best source of movies and even 4k nature videos. Can you share with me what proof to be best way for you to download YT videos/playlist both 720p and 4k?&lt;/p&gt;\n\n&lt;p&gt;PS&lt;/p&gt;\n\n&lt;p&gt;Here is a snip from session that will time out:&lt;/p&gt;\n\n&lt;p&gt;user@host:~$ ls -lh&lt;/p&gt;\n\n&lt;p&gt;total 235M&lt;/p&gt;\n\n&lt;p&gt;-rw-rw-r-- 1 user 235M Jan  4 21:02 &amp;#39;\u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm.part&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;user@host:~$ rm &amp;#39;\u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm.part&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;user@host:~$ youtube-dl -f 315 &lt;a href=\"https://www.youtube.com/watch?v=LCDDzLK-sys\"&gt;https://www.youtube.com/watch?v=LCDDzLK-sys&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;[youtube] LCDDzLK-sys: Downloading webpage&lt;/p&gt;\n\n&lt;p&gt;[download] Destination: \u0422\u0435\u0437\u0438 \u0433\u043b\u0435\u0434\u043a\u0438 \u0449\u0435 \u041d\u0410\u0421\u042a\u041b\u0417\u042f\u0422 \u043e\u0447\u0438\u0442\u0435 \u0432\u0438!-LCDDzLK-sys.webm&lt;/p&gt;\n\n&lt;p&gt;[download]   0.9% of 2.76GiB at 70.46KiB/s ETA 11:17:32&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B_95ltT36M0Z_42W0ff5ZhRSP8_V3dIr00yEl4_xSyg.jpg?auto=webp&amp;v=enabled&amp;s=0750adbce2c293bab5e98c3db1fc417259085eff", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/B_95ltT36M0Z_42W0ff5ZhRSP8_V3dIr00yEl4_xSyg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a42c015f4b6d258225a8ce691de9bbef630ed1ca", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/B_95ltT36M0Z_42W0ff5ZhRSP8_V3dIr00yEl4_xSyg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9cd0fe9388dd7504c6be08fa00f019a728d63f3c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/B_95ltT36M0Z_42W0ff5ZhRSP8_V3dIr00yEl4_xSyg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a55a3af333fb19a2e81021b7da43de8dd7ea89b", "width": 320, "height": 240}], "variants": {}, "id": "UW-6yU-dqtHKKqWFY9jvmOw8xW-z6xI7jzKq6jBnulw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "9TB TerraMaster", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10aa20l", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Eye1673", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10aa20l/how_do_you_like_to_dump_4k_youtube_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10aa20l/how_do_you_like_to_dump_4k_youtube_videos/", "subreddit_subscribers": 665611, "created_utc": 1673556026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anybody know a service that offers large amounts of storage for very short periods of time and how much would this cost? cheers", "author_fullname": "t2_h36vzasl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to buy 2tb cloud hosted storage for a very short period of time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a7x3c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673550889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anybody know a service that offers large amounts of storage for very short periods of time and how much would this cost? cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a7x3c", "is_robot_indexable": true, "report_reasons": null, "author": "JustYourJoe_", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a7x3c/looking_to_buy_2tb_cloud_hosted_storage_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a7x3c/looking_to_buy_2tb_cloud_hosted_storage_for_a/", "subreddit_subscribers": 665611, "created_utc": 1673550889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't actually have the hardware yet, I'm doing some research before purchase (always advisable lol). I'm interested in buying a used 3.2TB Micron 7300 MAX, but I want to bump that up to 3.84TB for more capacity since I won't be using anywhere near the listed 3DWPD spec. Hell, assuming that makes it equal to the \"Pro\" version of the drive, 1DWPD is still waaaay overkill.\n\nIt seems like Micron calls it \"Flex Capacity\" and it seems to be a part of \"Storage Executive Software\". Is this where I change the capacity? Can I even increase the capacity? I've heard of people reducing capacity to increase endurance, but I've never heard of someone doing the reverse.", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I change the capacity / overprovisioning on a Micron 7300 MAX?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109z0cp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673528186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t actually have the hardware yet, I&amp;#39;m doing some research before purchase (always advisable lol). I&amp;#39;m interested in buying a used 3.2TB Micron 7300 MAX, but I want to bump that up to 3.84TB for more capacity since I won&amp;#39;t be using anywhere near the listed 3DWPD spec. Hell, assuming that makes it equal to the &amp;quot;Pro&amp;quot; version of the drive, 1DWPD is still waaaay overkill.&lt;/p&gt;\n\n&lt;p&gt;It seems like Micron calls it &amp;quot;Flex Capacity&amp;quot; and it seems to be a part of &amp;quot;Storage Executive Software&amp;quot;. Is this where I change the capacity? Can I even increase the capacity? I&amp;#39;ve heard of people reducing capacity to increase endurance, but I&amp;#39;ve never heard of someone doing the reverse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109z0cp", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109z0cp/how_do_i_change_the_capacity_overprovisioning_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109z0cp/how_do_i_change_the_capacity_overprovisioning_on/", "subreddit_subscribers": 665611, "created_utc": 1673528186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't know if it's on point with the subreddit but I don't where else I could find opinions.\nI have some games and anime series backed up in HDDs but I also wanted a second backup on a storage of a different type. Bluray is too pricey for me so I went for DVD-r and DVD-dl. \n\nThe other option would have been a chain of USB but I wanted to keep a better aesthetic /s\n\nAnyway, I am now undecided on which package to use to keep the DVDs. Considering also their shelf position. \nMy library is not directly exposed to sunlight but \"diagonally\" there is some light. Normally summer is not really harsh. Maybe there is a bit of humidity problem in some months.\n\n[Plastic case] But I recently read/heard about problems coming from black pvc cases, since they would stick to the disk and may have come chemical reaction that can ruin the disk. Is it true that hot/humidity+enclosed pvc case really makes a mess?\n\n[Transparent jewel case] So I looked for the smaller cases, the ones with the flimsy hinge that always breaks. Majority of them seems to be made of PP and other non toxic materials.\n\nJewel seems the best choice, but I want opinions on the truth of the pvc/pp/other materials debate. I don't think there are many more type of rigid cases. I don't need the folder/booklet one with 4 discs, single pockets of paper/plastic are too \"nude\".\n\nAlso, for proper temperature, is it a good idea to put the cases in a second line, behind books/other stuff?\n\n\nThen there is the external HDD placement. I know that I should plug them in sometimes to check if files are corrupted/spin the disk inside.\nSo, is it a good idea to put my HDD on a shelf, plugged to a multi-port USB that routinely I connect to an external battery? So I can power them up with minimal hassle. They should have no problem with data \"safely remove hardware\" when unplugged since they only transfer energy with the battery, I suppose. \nThe hdd shelf is also easier to manage rather than dump them in a box or pile over a desk, and it's better covered from sunlight", "author_fullname": "t2_3n8go9g5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DVD and HDD:how and where to shelf/store/encase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10adzyc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673565201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s on point with the subreddit but I don&amp;#39;t where else I could find opinions.\nI have some games and anime series backed up in HDDs but I also wanted a second backup on a storage of a different type. Bluray is too pricey for me so I went for DVD-r and DVD-dl. &lt;/p&gt;\n\n&lt;p&gt;The other option would have been a chain of USB but I wanted to keep a better aesthetic /s&lt;/p&gt;\n\n&lt;p&gt;Anyway, I am now undecided on which package to use to keep the DVDs. Considering also their shelf position. \nMy library is not directly exposed to sunlight but &amp;quot;diagonally&amp;quot; there is some light. Normally summer is not really harsh. Maybe there is a bit of humidity problem in some months.&lt;/p&gt;\n\n&lt;p&gt;[Plastic case] But I recently read/heard about problems coming from black pvc cases, since they would stick to the disk and may have come chemical reaction that can ruin the disk. Is it true that hot/humidity+enclosed pvc case really makes a mess?&lt;/p&gt;\n\n&lt;p&gt;[Transparent jewel case] So I looked for the smaller cases, the ones with the flimsy hinge that always breaks. Majority of them seems to be made of PP and other non toxic materials.&lt;/p&gt;\n\n&lt;p&gt;Jewel seems the best choice, but I want opinions on the truth of the pvc/pp/other materials debate. I don&amp;#39;t think there are many more type of rigid cases. I don&amp;#39;t need the folder/booklet one with 4 discs, single pockets of paper/plastic are too &amp;quot;nude&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Also, for proper temperature, is it a good idea to put the cases in a second line, behind books/other stuff?&lt;/p&gt;\n\n&lt;p&gt;Then there is the external HDD placement. I know that I should plug them in sometimes to check if files are corrupted/spin the disk inside.\nSo, is it a good idea to put my HDD on a shelf, plugged to a multi-port USB that routinely I connect to an external battery? So I can power them up with minimal hassle. They should have no problem with data &amp;quot;safely remove hardware&amp;quot; when unplugged since they only transfer energy with the battery, I suppose. \nThe hdd shelf is also easier to manage rather than dump them in a box or pile over a desk, and it&amp;#39;s better covered from sunlight&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10adzyc", "is_robot_indexable": true, "report_reasons": null, "author": "CourierLordProcione2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10adzyc/dvd_and_hddhow_and_where_to_shelfstoreencase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10adzyc/dvd_and_hddhow_and_where_to_shelfstoreencase/", "subreddit_subscribers": 665611, "created_utc": 1673565201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I\u2019ve been somewhat of a DataHoarder for a bit. AKA, I download a crap ton of files and feel apart of me die inside whenever I run out of room and have to delete stuff. I\u2019ve also had my PC growing up crash 3 times and lose *everything*, including projects that I had made and never backed up anywhere. 13 year old me was devastated.\n\nI\u2019m all ready to jump head first in, but the hard part is I really don\u2019t understand any of this technical jargon. I understand the basics, as I\u2019m currently learning how to do front end work on websites, but I\u2019ve never hosted my own server or even built my own computer before.\n\nI currently have a shitty laptop with 1TB of storage, and have only ever bought an SSD for my PS4.\n\nI do have a basic understanding of how the internet *actually* works, and can grasp the ideas behind internet protocols and how servers work.\n\nCurrently, I mainly wanna hoarde music files, (I have visited the music hoarding subreddit for tips on that) and a *l o t* of niche content / files. Mainly USTs, VSQs, SVPs, some midis, etc. If you don\u2019t know what those are, they\u2019re file types that are used by some vocal synths, like VOCALOID. Think Hatsune Miku.\n\nI do want to expand to having my own media collection in general, but that\u2019s something further down the line once I am more knowledgeable and can get a server running.\n\nShould I first build my own setup? If I stick to my laptop for the time being, is cloud storage + an external backup (like USBs or something) my best bet? Should I even bother with getting an external hard drive and just wait until I can build my own setup?\n\nAre USBs even comparable to having your data on HDDs and SSDs?\n\nOr, do any of you have any good resources for absolute newbies like me?\n\nGoogle keeps sending me to unhelpful websites, and honestly? Getting some tips from people who love data hoarding seems much more reliable then whatever google will show me.\n\nEither way, I am eternally thankful for this subreddit making me realize I should embrace my hoarding.", "author_fullname": "t2_47z0zk6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Absolute Newbie DataHoarder with limited technical experience, any tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ad410", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673563083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I\u2019ve been somewhat of a DataHoarder for a bit. AKA, I download a crap ton of files and feel apart of me die inside whenever I run out of room and have to delete stuff. I\u2019ve also had my PC growing up crash 3 times and lose &lt;em&gt;everything&lt;/em&gt;, including projects that I had made and never backed up anywhere. 13 year old me was devastated.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m all ready to jump head first in, but the hard part is I really don\u2019t understand any of this technical jargon. I understand the basics, as I\u2019m currently learning how to do front end work on websites, but I\u2019ve never hosted my own server or even built my own computer before.&lt;/p&gt;\n\n&lt;p&gt;I currently have a shitty laptop with 1TB of storage, and have only ever bought an SSD for my PS4.&lt;/p&gt;\n\n&lt;p&gt;I do have a basic understanding of how the internet &lt;em&gt;actually&lt;/em&gt; works, and can grasp the ideas behind internet protocols and how servers work.&lt;/p&gt;\n\n&lt;p&gt;Currently, I mainly wanna hoarde music files, (I have visited the music hoarding subreddit for tips on that) and a &lt;em&gt;l o t&lt;/em&gt; of niche content / files. Mainly USTs, VSQs, SVPs, some midis, etc. If you don\u2019t know what those are, they\u2019re file types that are used by some vocal synths, like VOCALOID. Think Hatsune Miku.&lt;/p&gt;\n\n&lt;p&gt;I do want to expand to having my own media collection in general, but that\u2019s something further down the line once I am more knowledgeable and can get a server running.&lt;/p&gt;\n\n&lt;p&gt;Should I first build my own setup? If I stick to my laptop for the time being, is cloud storage + an external backup (like USBs or something) my best bet? Should I even bother with getting an external hard drive and just wait until I can build my own setup?&lt;/p&gt;\n\n&lt;p&gt;Are USBs even comparable to having your data on HDDs and SSDs?&lt;/p&gt;\n\n&lt;p&gt;Or, do any of you have any good resources for absolute newbies like me?&lt;/p&gt;\n\n&lt;p&gt;Google keeps sending me to unhelpful websites, and honestly? Getting some tips from people who love data hoarding seems much more reliable then whatever google will show me.&lt;/p&gt;\n\n&lt;p&gt;Either way, I am eternally thankful for this subreddit making me realize I should embrace my hoarding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ad410", "is_robot_indexable": true, "report_reasons": null, "author": "Ellestyx", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ad410/absolute_newbie_datahoarder_with_limited/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ad410/absolute_newbie_datahoarder_with_limited/", "subreddit_subscribers": 665611, "created_utc": 1673563083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "ive got a WD 12tb in desktop rig. When I try to open two particular folders on it [throws me this message](https://i.imgur.com/SQ08o7a.png). **note** I stole that image from somebody else in another forum with the same problem. my message looks identical to that just obviously with a different folder path. \n\ni loaded partedmagic usb boot and while inside the boot environment one of those folders is completely accessible and i can view and use the contents of it. so i changed the name of the folder and rebooted windows and the folder is fine now. but the other folder? it doesnt show up in partedmagic at all. its like it doesnt exist. but then i reboot back into windows and there it is again, but i cant access it without it giving me that error message. so weird and frustrating.\n\nnot sure if my OS was corrupted so i tried putting the hard drive in a different desktop and even loaded it on a mac via an external enclosure but no luck. folder still either doesnt exist or cant be accessed. \n\nim moving everything i can get off the drive via teracopy so i can full format it. i can live without the contents of that folder but still id like to save the the folder if anybody knows how before i give up.\n\nthanks for anybody that can help me.", "author_fullname": "t2_uhn37jxx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(Windows 10) some folders on one of my drives are \"unavailable\" while others are fine. SMART tests come up fine... Anybody encountered this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aajcd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673559209.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673557195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ive got a WD 12tb in desktop rig. When I try to open two particular folders on it &lt;a href=\"https://i.imgur.com/SQ08o7a.png\"&gt;throws me this message&lt;/a&gt;. &lt;strong&gt;note&lt;/strong&gt; I stole that image from somebody else in another forum with the same problem. my message looks identical to that just obviously with a different folder path. &lt;/p&gt;\n\n&lt;p&gt;i loaded partedmagic usb boot and while inside the boot environment one of those folders is completely accessible and i can view and use the contents of it. so i changed the name of the folder and rebooted windows and the folder is fine now. but the other folder? it doesnt show up in partedmagic at all. its like it doesnt exist. but then i reboot back into windows and there it is again, but i cant access it without it giving me that error message. so weird and frustrating.&lt;/p&gt;\n\n&lt;p&gt;not sure if my OS was corrupted so i tried putting the hard drive in a different desktop and even loaded it on a mac via an external enclosure but no luck. folder still either doesnt exist or cant be accessed. &lt;/p&gt;\n\n&lt;p&gt;im moving everything i can get off the drive via teracopy so i can full format it. i can live without the contents of that folder but still id like to save the the folder if anybody knows how before i give up.&lt;/p&gt;\n\n&lt;p&gt;thanks for anybody that can help me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FEsLF3NsYPIGH6T6AgTmwYvbuE9XQ68-N6_BbhNd_nY.png?auto=webp&amp;v=enabled&amp;s=2be013fea68f20dbe6f4163b6e486eed4bd8df0d", "width": 715, "height": 194}, "resolutions": [{"url": "https://external-preview.redd.it/FEsLF3NsYPIGH6T6AgTmwYvbuE9XQ68-N6_BbhNd_nY.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc33d509f9f9005831db8dcd25ed6110bb73a4b5", "width": 108, "height": 29}, {"url": "https://external-preview.redd.it/FEsLF3NsYPIGH6T6AgTmwYvbuE9XQ68-N6_BbhNd_nY.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c50962b225720f25193fb4cba68cc03ab3749eb5", "width": 216, "height": 58}, {"url": "https://external-preview.redd.it/FEsLF3NsYPIGH6T6AgTmwYvbuE9XQ68-N6_BbhNd_nY.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1fe57502d21d7ae69637b7b3c663fddbdbd8e56", "width": 320, "height": 86}, {"url": "https://external-preview.redd.it/FEsLF3NsYPIGH6T6AgTmwYvbuE9XQ68-N6_BbhNd_nY.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8866099ecbf3cc08035035400d73378f04bb42fc", "width": 640, "height": 173}], "variants": {}, "id": "ekN92S2jlLjd1FPlBiPJOHCIJyBrfKL9VTc3LeAvKJA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10aajcd", "is_robot_indexable": true, "report_reasons": null, "author": "woodpilecake", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10aajcd/windows_10_some_folders_on_one_of_my_drives_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10aajcd/windows_10_some_folders_on_one_of_my_drives_are/", "subreddit_subscribers": 665611, "created_utc": 1673557195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Wonder if YouTube-DL would work, however this site isn\u2019t mainstream \n\nAny ideas? \n\nThanks", "author_fullname": "t2_jp6vscfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download from a \u201cstreaming only\u201d site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a8exh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673552079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wonder if YouTube-DL would work, however this site isn\u2019t mainstream &lt;/p&gt;\n\n&lt;p&gt;Any ideas? &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a8exh", "is_robot_indexable": true, "report_reasons": null, "author": "StoryThrowAway916", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a8exh/download_from_a_streaming_only_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a8exh/download_from_a_streaming_only_site/", "subreddit_subscribers": 665611, "created_utc": 1673552079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone found a software they like for managing a library of *arbitrary* files? I have Plex for Video, Kavita for ebooks, Paperless-ng for personal documents, etc.\n\nIs there anything like these tools but for any and all file types? Basically I'd want a tool that could read metadata, potentially file contexts for text, and also allow any file to be tagged \u00e0 la Gmail labels, making searching easy. If it's something common like HTML/PDF/mp4 it could just view the file in browser, but otherwise provide a file location reference or download link.\n\nAnyone aware of anything in this vein existing?", "author_fullname": "t2_32pyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Library Management Software for Arbitrary Files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a5ttt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673545888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone found a software they like for managing a library of &lt;em&gt;arbitrary&lt;/em&gt; files? I have Plex for Video, Kavita for ebooks, Paperless-ng for personal documents, etc.&lt;/p&gt;\n\n&lt;p&gt;Is there anything like these tools but for any and all file types? Basically I&amp;#39;d want a tool that could read metadata, potentially file contexts for text, and also allow any file to be tagged \u00e0 la Gmail labels, making searching easy. If it&amp;#39;s something common like HTML/PDF/mp4 it could just view the file in browser, but otherwise provide a file location reference or download link.&lt;/p&gt;\n\n&lt;p&gt;Anyone aware of anything in this vein existing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a5ttt", "is_robot_indexable": true, "report_reasons": null, "author": "eldridgea", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10a5ttt/library_management_software_for_arbitrary_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a5ttt/library_management_software_for_arbitrary_files/", "subreddit_subscribers": 665611, "created_utc": 1673545888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title says it all , been trying many github scripts but nothing works", "author_fullname": "t2_aj30rvtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any way to download photo album from weibo ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109x642", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673521913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title says it all , been trying many github scripts but nothing works&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109x642", "is_robot_indexable": true, "report_reasons": null, "author": "Digital-Nuke", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109x642/any_way_to_download_photo_album_from_weibo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109x642/any_way_to_download_photo_album_from_weibo/", "subreddit_subscribers": 665611, "created_utc": 1673521913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Been wondering about this for ages.\n\nThere use to be some way to get Finder to show thumbnails in Finder for WebM files, as I recall, using a 3rd party thing that integrated with Finder. Apple shut it down with Catalina, circa 2019, according to this old post: [https://www.reddit.com/r/applehelp/comments/dxc7l5/how\\_can\\_i\\_get\\_finder\\_to\\_show\\_thumbnails\\_for\\_webm/](https://www.reddit.com/r/applehelp/comments/dxc7l5/how_can_i_get_finder_to_show_thumbnails_for_webm/)\n\nWondering how all the DataHoarders are managing this.  Do you just deal with never having thumbnails for this file type?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thumbnails for WebM files (MacOS): what are my options in 2023? MacOS Finder does not natively support thumbnails, should I convert them to something compatible? Is there some media management software I should be using instead of Finder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ahwbn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673575117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been wondering about this for ages.&lt;/p&gt;\n\n&lt;p&gt;There use to be some way to get Finder to show thumbnails in Finder for WebM files, as I recall, using a 3rd party thing that integrated with Finder. Apple shut it down with Catalina, circa 2019, according to this old post: &lt;a href=\"https://www.reddit.com/r/applehelp/comments/dxc7l5/how_can_i_get_finder_to_show_thumbnails_for_webm/\"&gt;https://www.reddit.com/r/applehelp/comments/dxc7l5/how_can_i_get_finder_to_show_thumbnails_for_webm/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Wondering how all the DataHoarders are managing this.  Do you just deal with never having thumbnails for this file type?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ahwbn", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ahwbn/thumbnails_for_webm_files_macos_what_are_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ahwbn/thumbnails_for_webm_files_macos_what_are_my/", "subreddit_subscribers": 665611, "created_utc": 1673575117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for some help in finding ways to better saturate my 10Gb network. I'm currently maxing out at ~5Gbps using a 10GB zip file but I know the storage is capable of far more (internal transfers and tar'd mbuffered external transfers are far faster) and the network is fine (iperf registers 9.8Gbps both ways). Tests are done between the pools on the server and a storage NVMe on my entirely overspec'd workstation. Any help is appreciated.\n\nServer Hardware:\n\n- Box: Dell T620\n- RAM: 220GB DDR3 ECC\n- CPU: 2x E5-2643v2 - 12C/24T@3.5GHz\n- HBA: LSI 9305-16i in IT mode\n- NIC: MCX354A-FCCT in ethernet mode, using a QSFP to SFP+ adapter\n- OS: Proxmox 7.3-4\n- File server: Samba directly on Proxmox, shares through ZFS pool settings\n\nServer Storage: \n\n- ssdpool: 8x 8TB Samsung 870QVO drives in ZFS RAID0, typically tops out at 3-4Gbps.\n- hddpool: 12x 16TB Seagate Exos HDDs in ZFS RAID0 + 2x 960GB Intel Optane 905P as a mirrored special vdev, typically tops out at 3-4Gbps.\n- cache: 1x 1.92TB Samsung DCT983 NVMe on ZFS, tops out at 5Gbps.\n\n---\n\nBefore anyone asks: I'm not concerned about the large RAID0 arrays, I have backups and am looking for lots of speed and scratch space. The 870QVO pool is read-only to the services that access it. Writes are infrequent and manual (download to cache, categorize and clean, transfer to pool). The shares are based on Proxmox because every attempt at setting up a file share container results in a ~2Gbps bottleneck. Jumbo frames are on for every device in the network. Network connections are all SFP+ DACs.", "author_fullname": "t2_u4u6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me squeeze some more speed out of my file shares", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10aezg0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673567591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for some help in finding ways to better saturate my 10Gb network. I&amp;#39;m currently maxing out at ~5Gbps using a 10GB zip file but I know the storage is capable of far more (internal transfers and tar&amp;#39;d mbuffered external transfers are far faster) and the network is fine (iperf registers 9.8Gbps both ways). Tests are done between the pools on the server and a storage NVMe on my entirely overspec&amp;#39;d workstation. Any help is appreciated.&lt;/p&gt;\n\n&lt;p&gt;Server Hardware:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Box: Dell T620&lt;/li&gt;\n&lt;li&gt;RAM: 220GB DDR3 ECC&lt;/li&gt;\n&lt;li&gt;CPU: 2x E5-2643v2 - 12C/&lt;a href=\"mailto:24T@3.5GHz\"&gt;24T@3.5GHz&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;HBA: LSI 9305-16i in IT mode&lt;/li&gt;\n&lt;li&gt;NIC: MCX354A-FCCT in ethernet mode, using a QSFP to SFP+ adapter&lt;/li&gt;\n&lt;li&gt;OS: Proxmox 7.3-4&lt;/li&gt;\n&lt;li&gt;File server: Samba directly on Proxmox, shares through ZFS pool settings&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Server Storage: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ssdpool: 8x 8TB Samsung 870QVO drives in ZFS RAID0, typically tops out at 3-4Gbps.&lt;/li&gt;\n&lt;li&gt;hddpool: 12x 16TB Seagate Exos HDDs in ZFS RAID0 + 2x 960GB Intel Optane 905P as a mirrored special vdev, typically tops out at 3-4Gbps.&lt;/li&gt;\n&lt;li&gt;cache: 1x 1.92TB Samsung DCT983 NVMe on ZFS, tops out at 5Gbps.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Before anyone asks: I&amp;#39;m not concerned about the large RAID0 arrays, I have backups and am looking for lots of speed and scratch space. The 870QVO pool is read-only to the services that access it. Writes are infrequent and manual (download to cache, categorize and clean, transfer to pool). The shares are based on Proxmox because every attempt at setting up a file share container results in a ~2Gbps bottleneck. Jumbo frames are on for every device in the network. Network connections are all SFP+ DACs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10aezg0", "is_robot_indexable": true, "report_reasons": null, "author": "certifiedintelligent", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10aezg0/help_me_squeeze_some_more_speed_out_of_my_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10aezg0/help_me_squeeze_some_more_speed_out_of_my_file/", "subreddit_subscribers": 665611, "created_utc": 1673567591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time data hoarder (though I usually refer to myself as digital hoarder), but new to the group and not a NAS/RAID/Server expert, though with decent computer knowledge.\n\nI currently have 2 EOL Lenovo NAS (PX4-400D with 4x4TB and IX4-300D with 4x3TB) but would like to \"consolidate\" with truly large drives. According to this list below, the biggest drive they list is 6TB\n\n[https://download.lenovo.com/lenovoemc/eu/en/app/answers/detail/a\\_id/33754.html](https://download.lenovo.com/lenovoemc/eu/en/app/answers/detail/a_id/33754.html)\n\nI know the NAS systems are old and EOL, but they are just local storage of downloads and videos without installed apps or services that reach outside. Usually 1 user accessing the drive, sometimes 2. The data is not \"super precious\" and while a loss would hurt, it wouldn't ruin me. I am hoping to just make one the \"mother of all data\" throwing 4x12TB or something like that at the NAS in RAID-5.\n\nQ1: Is 6TB really the limit, or is this just what was available at the time the list was release (2015). Does anyone run either of them with bigger drives than that?\n\nQ2: Can I buy new drives in stages? For example get 2x12TB running RAID-1 (I know it will only have 12TB usable), then add another 12TB and convert the RAID-1 to RAID-5 to have 24TB usable. Then add another 12TB after that to get to 36TB? This is mainly because of my available funds, because they currently run at about $200 a piece. I understand that generally you can convert RAID-1 to RAID-5 but wondering about these older systems.\n\nQ3: They currently use dedicated NAS drives (WD Red), could I use Enterprise or Surveillance disks like EXOS if they are cheaper or is this risky? I understand I can generally run whatever I want but even after googling, I am not sure if the difference between the drives should worry me for this setup\n\nQ4: Seagate Ironwolf or WD Red?", "author_fullname": "t2_5ai3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lenovo EMC questions about max drive size", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a9cyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673554366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time data hoarder (though I usually refer to myself as digital hoarder), but new to the group and not a NAS/RAID/Server expert, though with decent computer knowledge.&lt;/p&gt;\n\n&lt;p&gt;I currently have 2 EOL Lenovo NAS (PX4-400D with 4x4TB and IX4-300D with 4x3TB) but would like to &amp;quot;consolidate&amp;quot; with truly large drives. According to this list below, the biggest drive they list is 6TB&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://download.lenovo.com/lenovoemc/eu/en/app/answers/detail/a_id/33754.html\"&gt;https://download.lenovo.com/lenovoemc/eu/en/app/answers/detail/a_id/33754.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I know the NAS systems are old and EOL, but they are just local storage of downloads and videos without installed apps or services that reach outside. Usually 1 user accessing the drive, sometimes 2. The data is not &amp;quot;super precious&amp;quot; and while a loss would hurt, it wouldn&amp;#39;t ruin me. I am hoping to just make one the &amp;quot;mother of all data&amp;quot; throwing 4x12TB or something like that at the NAS in RAID-5.&lt;/p&gt;\n\n&lt;p&gt;Q1: Is 6TB really the limit, or is this just what was available at the time the list was release (2015). Does anyone run either of them with bigger drives than that?&lt;/p&gt;\n\n&lt;p&gt;Q2: Can I buy new drives in stages? For example get 2x12TB running RAID-1 (I know it will only have 12TB usable), then add another 12TB and convert the RAID-1 to RAID-5 to have 24TB usable. Then add another 12TB after that to get to 36TB? This is mainly because of my available funds, because they currently run at about $200 a piece. I understand that generally you can convert RAID-1 to RAID-5 but wondering about these older systems.&lt;/p&gt;\n\n&lt;p&gt;Q3: They currently use dedicated NAS drives (WD Red), could I use Enterprise or Surveillance disks like EXOS if they are cheaper or is this risky? I understand I can generally run whatever I want but even after googling, I am not sure if the difference between the drives should worry me for this setup&lt;/p&gt;\n\n&lt;p&gt;Q4: Seagate Ironwolf or WD Red?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a9cyw", "is_robot_indexable": true, "report_reasons": null, "author": "saldridge", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a9cyw/lenovo_emc_questions_about_max_drive_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a9cyw/lenovo_emc_questions_about_max_drive_size/", "subreddit_subscribers": 665611, "created_utc": 1673554366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, posted this in the QNAP sub but thought it would be worth trying here as well\n\nHave a 4 bay QNAP 453BT3 connected to my Mac via thunderbolt 3. Have just upgraded it to 4 x 16tb ironwolfs and want to set it up a little differently to my previous config as I wasnt happy with the speeds I was getting previously with RAID 5, thick volume (310 write, 580 read).\n\nI was hoping Id see a bump in speed by going RAID 10, static volume, but its about the same as before (280 write, 530 read).\n\nWould be very open to any other tips as to how to get a better speed, been hoping for something closer to 600 on the write. Raid 0 is out of the question because Id like some form of protection against a drive failure and don\u2019t mind sacrificing the storage to go with RAID 10 if it ended up being a fast option.\n\nCan try and find a 10Gbe dock to give that a go, but the thunderbolt 3 connection is managing 550 on the write so it\u2019s clearly capable of that speed.\n\nFinally Im also down to try some SSD QTier or Caching but from what I\u2019ve read it doesn\u2019t sound like that\u2019s going to give me a big enough bump in speed over what I\u2019m seeing currently.\n\nAny help or hot tips about what I could be doing wrong would be very very appreciated\nThanks!", "author_fullname": "t2_248eq7zg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Poor RAID speeds Thunderbolt 3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a8zsk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673556335.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673553536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, posted this in the QNAP sub but thought it would be worth trying here as well&lt;/p&gt;\n\n&lt;p&gt;Have a 4 bay QNAP 453BT3 connected to my Mac via thunderbolt 3. Have just upgraded it to 4 x 16tb ironwolfs and want to set it up a little differently to my previous config as I wasnt happy with the speeds I was getting previously with RAID 5, thick volume (310 write, 580 read).&lt;/p&gt;\n\n&lt;p&gt;I was hoping Id see a bump in speed by going RAID 10, static volume, but its about the same as before (280 write, 530 read).&lt;/p&gt;\n\n&lt;p&gt;Would be very open to any other tips as to how to get a better speed, been hoping for something closer to 600 on the write. Raid 0 is out of the question because Id like some form of protection against a drive failure and don\u2019t mind sacrificing the storage to go with RAID 10 if it ended up being a fast option.&lt;/p&gt;\n\n&lt;p&gt;Can try and find a 10Gbe dock to give that a go, but the thunderbolt 3 connection is managing 550 on the write so it\u2019s clearly capable of that speed.&lt;/p&gt;\n\n&lt;p&gt;Finally Im also down to try some SSD QTier or Caching but from what I\u2019ve read it doesn\u2019t sound like that\u2019s going to give me a big enough bump in speed over what I\u2019m seeing currently.&lt;/p&gt;\n\n&lt;p&gt;Any help or hot tips about what I could be doing wrong would be very very appreciated\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a8zsk", "is_robot_indexable": true, "report_reasons": null, "author": "doco32", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a8zsk/poor_raid_speeds_thunderbolt_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a8zsk/poor_raid_speeds_thunderbolt_3/", "subreddit_subscribers": 665611, "created_utc": 1673553536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there, I am looking into building my first NAS and am looking for advice on the kind of disk setup to go with. At this point I plan to reuse an older PC with TrueNAS and just need to get the drives. I might *possibly* end up moving to a prebuilt NAS device like from Synology in the future, depending on how I get on with my home build.\n \n \n \nMy use case is going to be primarily archive storage and a media server, used by only a couple of users at once. An external drive would be used to backup files from the NAS. \n \n \n \nMy concern now is whether I should go with 2x 6TB disks in RAID 1 (6TB usable), or 4x 2TB disks in RAID 5 / RAIDZ1 (also 6TB usable). Rookie numbers I know, but I can't justify spending 1000s on bigger drives at this point. \n\nThere is a difference of literally a couple of dollars between the two options above.\n \n \n \nResearching the different RAIDs, the cons are each one are:\n\n*RAID1:*\n\n* cost - half the potential storage is \"wasted\". -- This is the big one, essentially buying 2 things but only getting to use 1. Future upgrades are more expensive too, needing to buy pairs of larger dsks.\n\n* In the case of a failed drive, the system needs to be shut down to repair. -- This downtime is not a concern for me.\n\n*Raid 5:*\n\n* Rebuilding after a failure is a long process (days for large drives) and leaves the data vulnerable to further loss. This sounds pretty annoying. I'm not conerned with having the data accessable 24/7, so prefer the RAID1 in this respect.\n \n \n \nMaybe anoher option is no RAID at all? As I mentioned, my most important files (and likely a good chunk of whatever else) would be backed up elsewhere, so while downloading/copying stuff all over again would be a huge pain, it's not the end of the world. This would of course be half the cost, or I could get even more storage for just a bit more, but without any redundancy. Decisions decisions... I need a push in the right direction I think.", "author_fullname": "t2_3ycsbgx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Disk / RAID Choice for First Build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a2g8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673538700.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673537625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there, I am looking into building my first NAS and am looking for advice on the kind of disk setup to go with. At this point I plan to reuse an older PC with TrueNAS and just need to get the drives. I might &lt;em&gt;possibly&lt;/em&gt; end up moving to a prebuilt NAS device like from Synology in the future, depending on how I get on with my home build.&lt;/p&gt;\n\n&lt;p&gt;My use case is going to be primarily archive storage and a media server, used by only a couple of users at once. An external drive would be used to backup files from the NAS. &lt;/p&gt;\n\n&lt;p&gt;My concern now is whether I should go with 2x 6TB disks in RAID 1 (6TB usable), or 4x 2TB disks in RAID 5 / RAIDZ1 (also 6TB usable). Rookie numbers I know, but I can&amp;#39;t justify spending 1000s on bigger drives at this point. &lt;/p&gt;\n\n&lt;p&gt;There is a difference of literally a couple of dollars between the two options above.&lt;/p&gt;\n\n&lt;p&gt;Researching the different RAIDs, the cons are each one are:&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;RAID1:&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;cost - half the potential storage is &amp;quot;wasted&amp;quot;. -- This is the big one, essentially buying 2 things but only getting to use 1. Future upgrades are more expensive too, needing to buy pairs of larger dsks.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In the case of a failed drive, the system needs to be shut down to repair. -- This downtime is not a concern for me.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;em&gt;Raid 5:&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Rebuilding after a failure is a long process (days for large drives) and leaves the data vulnerable to further loss. This sounds pretty annoying. I&amp;#39;m not conerned with having the data accessable 24/7, so prefer the RAID1 in this respect.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Maybe anoher option is no RAID at all? As I mentioned, my most important files (and likely a good chunk of whatever else) would be backed up elsewhere, so while downloading/copying stuff all over again would be a huge pain, it&amp;#39;s not the end of the world. This would of course be half the cost, or I could get even more storage for just a bit more, but without any redundancy. Decisions decisions... I need a push in the right direction I think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a2g8s", "is_robot_indexable": true, "report_reasons": null, "author": "RogerTheBannister", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a2g8s/disk_raid_choice_for_first_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a2g8s/disk_raid_choice_for_first_build/", "subreddit_subscribers": 665611, "created_utc": 1673537625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a diy nas running windows server 2016 and a storage pool with 2 6TB WD Red drives set up as mirrored.  Yes I know this isn't the best or cleanest nas setup but for all my windows shares it's the easiest for me so I want to continue using storage spaces.\n\nMy question is, what happens when I add new drives to the existing pool that has 2 mirrored drives already.  I have on hand and want to add 2 12TB drives to the pool. Eventually I want to remove one by one the 6TB drives from the pool and replace them with larger newer drives.  Will storage spaces mirror the 2 12TB drives together? Will it copy the data from the 6TB drives to the 12TB drives or will it act like a 2x2 mirrored striped setup when the data is split between the 2 sets of drives?\n\nI would prefer more redundancy than total storage space.", "author_fullname": "t2_511438q9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage Spaces adding drives to existing mirrored pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a26dk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673536931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a diy nas running windows server 2016 and a storage pool with 2 6TB WD Red drives set up as mirrored.  Yes I know this isn&amp;#39;t the best or cleanest nas setup but for all my windows shares it&amp;#39;s the easiest for me so I want to continue using storage spaces.&lt;/p&gt;\n\n&lt;p&gt;My question is, what happens when I add new drives to the existing pool that has 2 mirrored drives already.  I have on hand and want to add 2 12TB drives to the pool. Eventually I want to remove one by one the 6TB drives from the pool and replace them with larger newer drives.  Will storage spaces mirror the 2 12TB drives together? Will it copy the data from the 6TB drives to the 12TB drives or will it act like a 2x2 mirrored striped setup when the data is split between the 2 sets of drives?&lt;/p&gt;\n\n&lt;p&gt;I would prefer more redundancy than total storage space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a26dk", "is_robot_indexable": true, "report_reasons": null, "author": "Historical_Wheel1090", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a26dk/storage_spaces_adding_drives_to_existing_mirrored/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a26dk/storage_spaces_adding_drives_to_existing_mirrored/", "subreddit_subscribers": 665611, "created_utc": 1673536931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like the title states, we're going to be moving (quite far) and I'm looking for recommendations for the best way to move the NAS and hard drives. I'm running a 920+ with 4 HDDs, can I bubblewrap the NAS, box it up and move with the drives installed or would it be advisable to remove the drives and individually bubblewrap and box them?\n\nFor what it matters, we're moving a long ways away, renting a uHaul pull behind trailer and will be traveling over bumpy / dirt roads for a not negligible portion of the drive. I'm leaning towards taking the hard drives out and individually wrapping them for transport.", "author_fullname": "t2_ckfoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transport Synology / Drives during a move", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a10ye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673533916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like the title states, we&amp;#39;re going to be moving (quite far) and I&amp;#39;m looking for recommendations for the best way to move the NAS and hard drives. I&amp;#39;m running a 920+ with 4 HDDs, can I bubblewrap the NAS, box it up and move with the drives installed or would it be advisable to remove the drives and individually bubblewrap and box them?&lt;/p&gt;\n\n&lt;p&gt;For what it matters, we&amp;#39;re moving a long ways away, renting a uHaul pull behind trailer and will be traveling over bumpy / dirt roads for a not negligible portion of the drive. I&amp;#39;m leaning towards taking the hard drives out and individually wrapping them for transport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a10ye", "is_robot_indexable": true, "report_reasons": null, "author": "offthewallness", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a10ye/how_to_transport_synology_drives_during_a_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a10ye/how_to_transport_synology_drives_during_a_move/", "subreddit_subscribers": 665611, "created_utc": 1673533916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are some search engines out there that provide direct links to images (duck duck go, metager, brave that I know of) though they are still somewhat hidden (you have to click on the image to then see the direct link, and you have to scroll down to see more results) by java i guess it is? Anyway, its quite convenient to be able to specify what you want to see and then hover up the results :)\n\nAnyway know of a way to get past this?", "author_fullname": "t2_f5t3js0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scraping image search results?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109yn4c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673527007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are some search engines out there that provide direct links to images (duck duck go, metager, brave that I know of) though they are still somewhat hidden (you have to click on the image to then see the direct link, and you have to scroll down to see more results) by java i guess it is? Anyway, its quite convenient to be able to specify what you want to see and then hover up the results :)&lt;/p&gt;\n\n&lt;p&gt;Anyway know of a way to get past this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109yn4c", "is_robot_indexable": true, "report_reasons": null, "author": "AlfieMcLuvin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109yn4c/scraping_image_search_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109yn4c/scraping_image_search_results/", "subreddit_subscribers": 665611, "created_utc": 1673527007.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}