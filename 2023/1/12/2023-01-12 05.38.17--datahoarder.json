{"kind": "Listing", "data": {"after": "t3_109jicb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3t9lh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pulled this from a Synology NAS. Over 8 years old\u2026how much more life could be reasonably expected? Haven\u2019t even powered it on to check overall health yet, just going by the disk &amp; date. Non-critical files, just trying to gauge how much I trust this disk at this age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10973ac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 310, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 310, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VzkJCwoWMKfDR_G-XAlanJ4iHTqgi8GaAqVhg_uVeO8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673450072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m1uxflo82hba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?auto=webp&amp;v=enabled&amp;s=38962ad10b9ff8fc6389fecc51d6621254e638b3", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90a638729bc797b1e3d9f03e2c3b2ccd53fbee25", "width": 108, "height": 144}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20d57e9a1925ab0d3773149171223d601cd9a630", "width": 216, "height": 288}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0636517a50df9f57ff06aec405213e19c6f838c5", "width": 320, "height": 426}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea53916348a61b9094d18e1f8d8420481185323b", "width": 640, "height": 853}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b52e3920e3fc735bcc974bc2c649a5c9e94c91a9", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a76e21e3a3a2f421ba4f4b50bc3010dc0d0520d0", "width": 1080, "height": 1440}], "variants": {}, "id": "rsQ04fVBKdmZ1EcVFpnc84qMLNK428HYo4GpVsYeml0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10973ac", "is_robot_indexable": true, "report_reasons": null, "author": "andytagonist", "discussion_type": null, "num_comments": 182, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10973ac/pulled_this_from_a_synology_nas_over_8_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m1uxflo82hba1.jpg", "subreddit_subscribers": 665468, "created_utc": 1673450072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I'm located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I'm aware, but it all seemed like a good idea at the time).\n\nThe process is deceptively simple if you've never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.\n\nThe first thing you'll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.\n\nThen you'll discover that there's absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word \"asynchronous\" and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don't even see your checkboxes get checked until the requests complete.\n\nBut let's say you've checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn't you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I've seen (something like 20-30 minutes) and no \"Remember me\" button. This is a bit more of a big deal, or - as you might find out later - a very big deal.\n\nSo you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I've had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven't had that happen often with large ones, but a bunch of times with small ones.\n\nYou've finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you've had first hand experience with the downloader. (Spoilers, I know). Let's say you listen and download the downloader - pointlessly, as it turns out, since it's already there along with your Backblaze installation.\n\nYou give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.\n\nAnd then you realize the downloader has the same problem as the UI with the \"async\" concept, except Windows really, *really* doesn't like apps hogging the UI thread. So 90 percent of the time the window is \"not responding\", the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I've had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you've made a mistake of restoring to your C:\\ drive this is going to be even worse since that's also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them \"threads\"; that's not quite telling the whole story as they're entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it's hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.\n\nBut let's say you've downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there's no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there's no indication which restores you have or have not already downloaded.\n\nAnd while you've been marveling at that the unzip process has thrown a CRC error - which I really, *really* hope is just an issue with the zipping/downloading process and the actual data that's being stored on the servers is okay. If you've had the downloader hang on you there's a pretty much 100% chance you'll get that, if you've stopped and restarted the download you'll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you're lucky it's just going to be one or two files and you can restore them separately, if you're not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.\n\nSo you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the \"acceleration\" part, which for some reason works only up to some size - maybe that's some issue on my side, but I've tried multiple ones and I haven't gotten the big restores to download in parallel, only smaller ones.\n\nAnd even if you've gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they've finished a chunk, said connections are now getting redirected to the login page. I've tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don't care for the acceleration, I hope you didn't spend too much time setting up a queue of downloads (or go to bed afterwards), because that won't work either for the same reason.\n\nIronically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don't ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can't just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.\n\nNow does it mean Backblaze is a bad service? I guess not - for the price it's still a steal, and there are other options to restore. If you're in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I'm likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don't want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might've heard of the restore process being a bit iffy but it can't be that bad, right?\n\nWell, it's exactly as bad as above, no more, no less - whether that's a dealbreaker is in the eye of the beholder, but it's better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I'm hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it's really a bit disappointing that the current process is so miserable.", "author_fullname": "t2_epug6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Backblaze large restore experience (is miserable)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109kd3j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673481815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I&amp;#39;m located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I&amp;#39;m aware, but it all seemed like a good idea at the time).&lt;/p&gt;\n\n&lt;p&gt;The process is deceptively simple if you&amp;#39;ve never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.&lt;/p&gt;\n\n&lt;p&gt;The first thing you&amp;#39;ll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.&lt;/p&gt;\n\n&lt;p&gt;Then you&amp;#39;ll discover that there&amp;#39;s absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word &amp;quot;asynchronous&amp;quot; and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don&amp;#39;t even see your checkboxes get checked until the requests complete.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn&amp;#39;t you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I&amp;#39;ve seen (something like 20-30 minutes) and no &amp;quot;Remember me&amp;quot; button. This is a bit more of a big deal, or - as you might find out later - a very big deal.&lt;/p&gt;\n\n&lt;p&gt;So you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I&amp;#39;ve had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven&amp;#39;t had that happen often with large ones, but a bunch of times with small ones.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;ve finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you&amp;#39;ve had first hand experience with the downloader. (Spoilers, I know). Let&amp;#39;s say you listen and download the downloader - pointlessly, as it turns out, since it&amp;#39;s already there along with your Backblaze installation.&lt;/p&gt;\n\n&lt;p&gt;You give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.&lt;/p&gt;\n\n&lt;p&gt;And then you realize the downloader has the same problem as the UI with the &amp;quot;async&amp;quot; concept, except Windows really, &lt;em&gt;really&lt;/em&gt; doesn&amp;#39;t like apps hogging the UI thread. So 90 percent of the time the window is &amp;quot;not responding&amp;quot;, the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I&amp;#39;ve had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you&amp;#39;ve made a mistake of restoring to your C:\\ drive this is going to be even worse since that&amp;#39;s also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them &amp;quot;threads&amp;quot;; that&amp;#39;s not quite telling the whole story as they&amp;#39;re entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it&amp;#39;s hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there&amp;#39;s no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there&amp;#39;s no indication which restores you have or have not already downloaded.&lt;/p&gt;\n\n&lt;p&gt;And while you&amp;#39;ve been marveling at that the unzip process has thrown a CRC error - which I really, &lt;em&gt;really&lt;/em&gt; hope is just an issue with the zipping/downloading process and the actual data that&amp;#39;s being stored on the servers is okay. If you&amp;#39;ve had the downloader hang on you there&amp;#39;s a pretty much 100% chance you&amp;#39;ll get that, if you&amp;#39;ve stopped and restarted the download you&amp;#39;ll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you&amp;#39;re lucky it&amp;#39;s just going to be one or two files and you can restore them separately, if you&amp;#39;re not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.&lt;/p&gt;\n\n&lt;p&gt;So you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the &amp;quot;acceleration&amp;quot; part, which for some reason works only up to some size - maybe that&amp;#39;s some issue on my side, but I&amp;#39;ve tried multiple ones and I haven&amp;#39;t gotten the big restores to download in parallel, only smaller ones.&lt;/p&gt;\n\n&lt;p&gt;And even if you&amp;#39;ve gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they&amp;#39;ve finished a chunk, said connections are now getting redirected to the login page. I&amp;#39;ve tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don&amp;#39;t care for the acceleration, I hope you didn&amp;#39;t spend too much time setting up a queue of downloads (or go to bed afterwards), because that won&amp;#39;t work either for the same reason.&lt;/p&gt;\n\n&lt;p&gt;Ironically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don&amp;#39;t ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can&amp;#39;t just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.&lt;/p&gt;\n\n&lt;p&gt;Now does it mean Backblaze is a bad service? I guess not - for the price it&amp;#39;s still a steal, and there are other options to restore. If you&amp;#39;re in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I&amp;#39;m likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don&amp;#39;t want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might&amp;#39;ve heard of the restore process being a bit iffy but it can&amp;#39;t be that bad, right?&lt;/p&gt;\n\n&lt;p&gt;Well, it&amp;#39;s exactly as bad as above, no more, no less - whether that&amp;#39;s a dealbreaker is in the eye of the beholder, but it&amp;#39;s better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I&amp;#39;m hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it&amp;#39;s really a bit disappointing that the current process is so miserable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109kd3j", "is_robot_indexable": true, "report_reasons": null, "author": "Mivexil", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "subreddit_subscribers": 665468, "created_utc": 1673481815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). \n\nI grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn't *need* to do it so I wasn't looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. \n\nI have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. \n\nLuckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.", "author_fullname": "t2_hz5u5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bought used QNAP TS431+.. Previous owner left hsi whole company on the drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h0eu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). &lt;/p&gt;\n\n&lt;p&gt;I grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn&amp;#39;t &lt;em&gt;need&lt;/em&gt; to do it so I wasn&amp;#39;t looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. &lt;/p&gt;\n\n&lt;p&gt;I have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. &lt;/p&gt;\n\n&lt;p&gt;Luckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109h0eu", "is_robot_indexable": true, "report_reasons": null, "author": "DeffNotTom", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "subreddit_subscribers": 665468, "created_utc": 1673473617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uyo43rx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building my first server ordered 4 ironwolf nas I got 2 and 2 with different labels all manufactured within 2 months of each other. Is there any difference in these models or is it it just the same drive with different sku that was sent ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_109bu22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c2jbX7b3UhyQurMFUhttmpCFURt2u611mr54l2OI89M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673461467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/3LFi29T.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?auto=webp&amp;v=enabled&amp;s=6710305a9cd53d5664e90e5591beab4d5edacd63", "width": 1500, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64050a9f5bc430f26fb1aedac51def6817a41cfd", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c3cfd278a50b090624057c885b6ae0f1aca5bb1", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30f98641b32882419cd8e5707e08babbff8c0ccc", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=647e785ef4717773d796e26063513786711ad06e", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49798d4dd8bf4d9770b9de0b2b668ad041f47f93", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=737def69e6194720c6a6b36d19b5d8575a583312", "width": 1080, "height": 1440}], "variants": {}, "id": "dGFmEl7G6uLJ9TlJnP-3Orf4-A5rCRB9aAQ2vW9aKBo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109bu22", "is_robot_indexable": true, "report_reasons": null, "author": "Yung_Gleesh_", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109bu22/building_my_first_server_ordered_4_ironwolf_nas_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/3LFi29T.jpg", "subreddit_subscribers": 665468, "created_utc": 1673461467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.\n\nstarted filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, \"smr, working as intended\"\n\nonce downloads completed I figured I'd give chkdsk another pass just to be sure. 10 bad clusters found this time.\n\nI'm dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn't trust it with important data, but considering I'm stuck with it, is there anything I can do? maybe zero fill?\n\nEDIT\n\nfull chkdsk log: https://i.imgur.com/Waab8Hb.png", "author_fullname": "t2_18grx8tx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 bad clusters on recently acquired WD external", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1099y9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673459963.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673457091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.&lt;/p&gt;\n\n&lt;p&gt;started filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, &amp;quot;smr, working as intended&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;once downloads completed I figured I&amp;#39;d give chkdsk another pass just to be sure. 10 bad clusters found this time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn&amp;#39;t trust it with important data, but considering I&amp;#39;m stuck with it, is there anything I can do? maybe zero fill?&lt;/p&gt;\n\n&lt;p&gt;EDIT&lt;/p&gt;\n\n&lt;p&gt;full chkdsk log: &lt;a href=\"https://i.imgur.com/Waab8Hb.png\"&gt;https://i.imgur.com/Waab8Hb.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?auto=webp&amp;v=enabled&amp;s=fa22f783b4db4bed916c680781e0f71926150b29", "width": 1324, "height": 916}, "resolutions": [{"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=365328e4f0f15ae1640e0794ffeeb0506be978ce", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02df3d9cd0ffded9da82365fd3e75535b7254778", "width": 216, "height": 149}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7f5c08ca3023ea82e4cfcd3fd24e087bbc69ca4", "width": 320, "height": 221}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0691378505539a6abecb7007d2b64691ccd6bd29", "width": 640, "height": 442}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd404e36265ed7b36c9faa1a8b82675c1510d172", "width": 960, "height": 664}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1948ff24faecef9cda2940048d6d093a970c24", "width": 1080, "height": 747}], "variants": {}, "id": "WRxgf3zs3hd4T5edmv4gY-a8OnqkOammTTB4c1y_Lgc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1099y9o", "is_robot_indexable": true, "report_reasons": null, "author": "h-t-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "subreddit_subscribers": 665468, "created_utc": 1673457091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? \n\nI love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. \n\nThanks!", "author_fullname": "t2_jijjmnms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you BUY your ebooks from?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1096x85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673449643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? &lt;/p&gt;\n\n&lt;p&gt;I love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1096x85", "is_robot_indexable": true, "report_reasons": null, "author": "clickbg", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "subreddit_subscribers": 665468, "created_utc": 1673449643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not the type of person for this sub. All of my data is under a TB.... but I started playing around with 3d scanning and that's changing fast. 20gb scans. 150gb project files. \n\nI'm not wanting to spend too much or get too involved for now so this is the setup I'm thinking. \n\npurchase 3 HDD in the 4-6tb range. 2 go into an old computer running raid 1. map network drive and drag the projects over when I'm done with them. The third is kept somewhere else and brought over once a month to get updated\n\nto me it sounds like a good idea with more than 1 layer of defense. any opinions?", "author_fullname": "t2_v3z3kryc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to get a sanity check for archive/backup idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109n680", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673489125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not the type of person for this sub. All of my data is under a TB.... but I started playing around with 3d scanning and that&amp;#39;s changing fast. 20gb scans. 150gb project files. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not wanting to spend too much or get too involved for now so this is the setup I&amp;#39;m thinking. &lt;/p&gt;\n\n&lt;p&gt;purchase 3 HDD in the 4-6tb range. 2 go into an old computer running raid 1. map network drive and drag the projects over when I&amp;#39;m done with them. The third is kept somewhere else and brought over once a month to get updated&lt;/p&gt;\n\n&lt;p&gt;to me it sounds like a good idea with more than 1 layer of defense. any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109n680", "is_robot_indexable": true, "report_reasons": null, "author": "Optimal-Growth-5741", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109n680/wanting_to_get_a_sanity_check_for_archivebackup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109n680/wanting_to_get_a_sanity_check_for_archivebackup/", "subreddit_subscribers": 665468, "created_utc": 1673489125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm struggling to understand the guides on GitHub and have some questions.\n\n1. I have a failing drive I want to \"vacate\" and found a Github thread that mentions setting the drive as read only while copying out the drive.  How can I do this via ssh commands that will override the /etc/fstab?\n\n Related: At the moment I'm having an issue where running \"sudo mount -a\" fails on some drives. Something about \"wrong fs type, bad option, bad superblock or other error\".  I don't think it's caused by MergerFS but does make using the \"sudo mount -a\" not an option, at least for now.\n\n2. The thread mentions creating a temporary pool excluding the dying drive.  My drives are all mounted to the same path and arranged as \"disk1\" and \"disk2\" etc.  I currently use \"disk*\" to mount them all.  Is there a way to mount \"disk*\" and specifically exclude \"disk5\" for example, again via ssh command?", "author_fullname": "t2_9zarh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MergerFS questions from a new user", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108x81e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673416858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to understand the guides on GitHub and have some questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I have a failing drive I want to &amp;quot;vacate&amp;quot; and found a Github thread that mentions setting the drive as read only while copying out the drive.  How can I do this via ssh commands that will override the /etc/fstab?&lt;/p&gt;\n\n&lt;p&gt;Related: At the moment I&amp;#39;m having an issue where running &amp;quot;sudo mount -a&amp;quot; fails on some drives. Something about &amp;quot;wrong fs type, bad option, bad superblock or other error&amp;quot;.  I don&amp;#39;t think it&amp;#39;s caused by MergerFS but does make using the &amp;quot;sudo mount -a&amp;quot; not an option, at least for now.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The thread mentions creating a temporary pool excluding the dying drive.  My drives are all mounted to the same path and arranged as &amp;quot;disk1&amp;quot; and &amp;quot;disk2&amp;quot; etc.  I currently use &amp;quot;disk&lt;em&gt;&amp;quot; to mount them all.  Is there a way to mount &amp;quot;disk&lt;/em&gt;&amp;quot; and specifically exclude &amp;quot;disk5&amp;quot; for example, again via ssh command?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108x81e", "is_robot_indexable": true, "report_reasons": null, "author": "silentdragon14", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108x81e/mergerfs_questions_from_a_new_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108x81e/mergerfs_questions_from_a_new_user/", "subreddit_subscribers": 665468, "created_utc": 1673416858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photo sorter recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109l5sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673483820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109l5sr", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "subreddit_subscribers": 665468, "created_utc": 1673483820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.\n\nLooking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.\n\nTIA!", "author_fullname": "t2_9jlhrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions: Data migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h2xs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109h2xs", "is_robot_indexable": true, "report_reasons": null, "author": "PerpetuallyPerplxed", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "subreddit_subscribers": 665468, "created_utc": 1673473789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.\n\nAs an example, here is what I\u2019ve tried so far:\n\n    youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\nBut this returns an Unsupported URL error.\n\nImportantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.\n\nAny way to do this?", "author_fullname": "t2_151mwt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[youtube-dl] How to download all the videos belonging to a Vimeo user archived on Wayback Machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097ut9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.&lt;/p&gt;\n\n&lt;p&gt;As an example, here is what I\u2019ve tried so far:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But this returns an Unsupported URL error.&lt;/p&gt;\n\n&lt;p&gt;Importantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.&lt;/p&gt;\n\n&lt;p&gt;Any way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097ut9", "is_robot_indexable": true, "report_reasons": null, "author": "AsleepInTheStalks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "subreddit_subscribers": 665468, "created_utc": 1673452007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Here someone says NAS is not a back up \n\nhttps://www.reddit.com/r/synology/comments/ga58cj/is_it_safe_to_use_a_nas_as_a_backup_instead_of_a/foxljta?utm_medium=android_app&amp;utm_source=share&amp;context=3\n\nHere a guy says to get a NAS \n\nhttps://www.reddit.com/r/torrents/comments/m6c2pk/where_do_you_store_your_larger_files/gr5067o?utm_medium=android_app&amp;utm_source=share&amp;context=3\n\nWould the better be to get 2 NAS'S or is that to expensive", "author_fullname": "t2_wk3o3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I don't know whether to have 3 external hard drives or a NAS I'm looking for the cheapest option", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109pfx6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673495402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here someone says NAS is not a back up &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/synology/comments/ga58cj/is_it_safe_to_use_a_nas_as_a_backup_instead_of_a/foxljta?utm_medium=android_app&amp;amp;utm_source=share&amp;amp;context=3\"&gt;https://www.reddit.com/r/synology/comments/ga58cj/is_it_safe_to_use_a_nas_as_a_backup_instead_of_a/foxljta?utm_medium=android_app&amp;amp;utm_source=share&amp;amp;context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here a guy says to get a NAS &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/torrents/comments/m6c2pk/where_do_you_store_your_larger_files/gr5067o?utm_medium=android_app&amp;amp;utm_source=share&amp;amp;context=3\"&gt;https://www.reddit.com/r/torrents/comments/m6c2pk/where_do_you_store_your_larger_files/gr5067o?utm_medium=android_app&amp;amp;utm_source=share&amp;amp;context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would the better be to get 2 NAS&amp;#39;S or is that to expensive&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109pfx6", "is_robot_indexable": true, "report_reasons": null, "author": "CONFUS3D_DOTCOM", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109pfx6/i_dont_know_whether_to_have_3_external_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109pfx6/i_dont_know_whether_to_have_3_external_hard/", "subreddit_subscribers": 665468, "created_utc": 1673495402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "ArchiveBox only seems to allow a person to save *all* of one's bookmarks and I couldn't even do that because I got the following error:\n\nError while loading link! \\[1673463122.097194\\] \\[path to my browser's bookmarks file\\] \"None\"\n\n&amp;#x200B;\n\nThis error was shown after I used the following command:\n\narchivebox add --depth=1 \\[path to my browser's bookmarks file\\]\n\n&amp;#x200B;\n\nCan somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as 'HTML Only.' It wouldn't take me long to do it manually, but I figured I would finally try to do it automatically.", "author_fullname": "t2_emji9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically save all pages in a bookmarks subfolder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109d68v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673464571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ArchiveBox only seems to allow a person to save &lt;em&gt;all&lt;/em&gt; of one&amp;#39;s bookmarks and I couldn&amp;#39;t even do that because I got the following error:&lt;/p&gt;\n\n&lt;p&gt;Error while loading link! [1673463122.097194] [path to my browser&amp;#39;s bookmarks file] &amp;quot;None&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This error was shown after I used the following command:&lt;/p&gt;\n\n&lt;p&gt;archivebox add --depth=1 [path to my browser&amp;#39;s bookmarks file]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as &amp;#39;HTML Only.&amp;#39; It wouldn&amp;#39;t take me long to do it manually, but I figured I would finally try to do it automatically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109d68v", "is_robot_indexable": true, "report_reasons": null, "author": "PA99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "subreddit_subscribers": 665468, "created_utc": 1673464571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, \n\nI am building myself a NAS to digitize my parents' DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives\n\nI'm planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I'm worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5\" HDD, and I would hope for some more HDD Bays for future expansion.\n\nI am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn't seem to be too difficult, but I wanna make sure I haven't overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!", "author_fullname": "t2_bzoyakj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "needing a little help/reassurance with my first server build!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097xi4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, &lt;/p&gt;\n\n&lt;p&gt;I am building myself a NAS to digitize my parents&amp;#39; DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I&amp;#39;m worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5&amp;quot; HDD, and I would hope for some more HDD Bays for future expansion.&lt;/p&gt;\n\n&lt;p&gt;I am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn&amp;#39;t seem to be too difficult, but I wanna make sure I haven&amp;#39;t overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097xi4", "is_robot_indexable": true, "report_reasons": null, "author": "justinc0617", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "subreddit_subscribers": 665468, "created_utc": 1673452196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can folks help back up the various articles and posts about this incident before Vietnamese State influenced media and accounts take them down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109qow8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_4suircub", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "helpme", "selftext": "I don\u2019t know how to start this, I honestly just want to spread this to somewhere out there, please be our voice, please help us.\nThe title said it all, I will cut to the chase. Here in Vietnam college students will have to participate in a military course for a few weeks, the two girls were on their way home but then were pulled away by the guys RIGHT IN THE SCHOOL, hurt and traumatized, they both jumped down from the highest floor, one sadly passed away and the other one was paralyzed. I am writing this here because I know the police won\u2019t do shit, things like this had happened so many time and because these kinds of incidents will \u201caffect the school reputation\u201d they will silently clean up the crime scene in the middle of the night and no one can speak about this, even the victim\u2019s families. I am shaking writing this so pardon the writing, I\u2019m only 16 and will go to college soon and I don\u2019t want this to happen to me or anyone again. The girls\u2019s school name is HUFLIT, and the guy\u2019s is Military School Region 7, both located in Ho Chi Minh city, Vietnam and both are covering this incident up as \u201ctwo girls having an argument and lead to this tragedy\u201d \nI don\u2019t want to grow up in this kind of society, please be our voice or else some people will be able to let this pass in silence \nI have two clips here, one is one of the girls screaming for help, the other one is people taking her lifeless body away in the middle of the night, no ambulance lights, no siren, no nothing.\nPlease help us by spreading awareness, the posts about this incident is being deleted one by one as I\u2019m writing this and the students there are forbidden from saying a word about this, they even go as far as taking all of their phones and checking them\n\n[the incident](https://drive.google.com/drive/folders/1GMuRmOxzQ7uyYlnjvbPVlblakrrielkj)", "author_fullname": "t2_vggmor4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2 college girls committed unalive after being gangr8 by 12 guys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/helpme", "hidden": false, "pwls": 0, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1098qxx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 81, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673454206.0, "link_flair_type": "text", "wls": 0, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.helpme", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t know how to start this, I honestly just want to spread this to somewhere out there, please be our voice, please help us.\nThe title said it all, I will cut to the chase. Here in Vietnam college students will have to participate in a military course for a few weeks, the two girls were on their way home but then were pulled away by the guys RIGHT IN THE SCHOOL, hurt and traumatized, they both jumped down from the highest floor, one sadly passed away and the other one was paralyzed. I am writing this here because I know the police won\u2019t do shit, things like this had happened so many time and because these kinds of incidents will \u201caffect the school reputation\u201d they will silently clean up the crime scene in the middle of the night and no one can speak about this, even the victim\u2019s families. I am shaking writing this so pardon the writing, I\u2019m only 16 and will go to college soon and I don\u2019t want this to happen to me or anyone again. The girls\u2019s school name is HUFLIT, and the guy\u2019s is Military School Region 7, both located in Ho Chi Minh city, Vietnam and both are covering this incident up as \u201ctwo girls having an argument and lead to this tragedy\u201d \nI don\u2019t want to grow up in this kind of society, please be our voice or else some people will be able to let this pass in silence \nI have two clips here, one is one of the girls screaming for help, the other one is people taking her lifeless body away in the middle of the night, no ambulance lights, no siren, no nothing.\nPlease help us by spreading awareness, the posts about this incident is being deleted one by one as I\u2019m writing this and the students there are forbidden from saying a word about this, they even go as far as taking all of their phones and checking them&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://drive.google.com/drive/folders/1GMuRmOxzQ7uyYlnjvbPVlblakrrielkj\"&gt;the incident&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 50, "id": "award_02d9ab2c-162e-4c01-8438-317a016ed3d9", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://i.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=32add54efce28cc8ce035c5e2bc89a27286a815e", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dfb00ece05340570177df7cfa1af6d2737c0910b", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=e8b0b87b868f6cd6313e2c90975dac636e4a0412", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=2a3ad7ec2ccc57b6c65b17e2b57647a81f335039", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/p4yzxkaed5f61_oldtakemyenergy.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=d4a8ca64b391e8b057408067d77f503752c29b7e", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "I'm in this with you.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "Take My Energy", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=4efb20a46b5cee58042da74830ee914d1547236c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=83e8bea70baef2140842017e967f163a9f530a9d", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=14fb29ce140b35a21a7cc7ee1c4d212ce0b1179d", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=533b05085677b48f15004bd7f9ff19ec5b29099f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=6f767b3c289e5cb2a733b24da5f4c46d9c079bc7", "width": 128, "height": 128}], "icon_format": "PNG", "icon_height": 2048, "penny_price": 0, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/jtw7x06j68361_TakeMyEnergyElf.png"}], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qpmh", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1098qxx", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable_Ladder_64", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "no_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/helpme/comments/1098qxx/2_college_girls_committed_unalive_after_being/", "parent_whitelist_status": "no_ads", "stickied": false, "url": "https://old.reddit.com/r/helpme/comments/1098qxx/2_college_girls_committed_unalive_after_being/", "subreddit_subscribers": 52955, "created_utc": 1673454206.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1673499113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.helpme", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/helpme/comments/1098qxx/2_college_girls_committed_unalive_after_being/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109qow8", "is_robot_indexable": true, "report_reasons": null, "author": "messyredemptions", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1098qxx", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109qow8/can_folks_help_back_up_the_various_articles_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/helpme/comments/1098qxx/2_college_girls_committed_unalive_after_being/", "subreddit_subscribers": 665468, "created_utc": 1673499113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi folks,\n\nI had a single 8TB drive failure out of my array, which I then switched out for a new 16TB drive. Problems started when I switched SATA channels on the 8TB drive, and it came back online. I then readded it to the storage spaces pool. (Stupid, I know, but I'm a greedy simpleton. Please take pity.)\n\nSince then, the pool has been stuck on \"Storage pool-Rebalance\". Output from PS \\`Get-StorageJob\\`:\n\n    Name | IsBackgroundTask | ElapsedTime | JobState | PercentComplete | BytesProcessed | BytesTotal\n    ----\n    Storage pool-Rebalance | True | 5012.09:03:37 | Shutting Down | 0 | 0 B | 8 GB\n    Nonresilient space-Repair | True | 1.01:14:57 | Suspended | 0 | 0 B | 256 GB\n\nFurther, the GUI shows something similar: [https://imgur.com/a/wcjcdla](https://imgur.com/a/wcjcdla), and \\`Stop-StorageJob -Name \"Storage pool-Rebalance\"\\` gives me:\n\n    Stop-StorageJob : Unspecified error\n    At line:1 char:1\n    + Stop-StorageJob -Name \"Storage pool-Rebalance\"\n    + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n        + CategoryInfo          : NotSpecified: (MSFT_StorageJob...Windows/Sto...):ROOT/Microsoft/...MSFT_StorageJob) [Sto\n       p-StorageJob], CimException\n        + FullyQualifiedErrorId : HRESULT 0x80004005,Stop-StorageJob\n\nGoing into the Event Viewer, I have the same event over and over: [https://pastebin.com/GH44S4km](https://pastebin.com/GH44S4km) (but with RepairPhases increasing by 1 each time).\n\nMy sense is that if I can remove the drive for good, or alternatively reset the 'job queue' of the storage spaces, it will be able to recover from there. Any ideas?", "author_fullname": "t2_ph67y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage Spaces - stuck on Jobstate: Shutting Down", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109qatw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673497936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I had a single 8TB drive failure out of my array, which I then switched out for a new 16TB drive. Problems started when I switched SATA channels on the 8TB drive, and it came back online. I then readded it to the storage spaces pool. (Stupid, I know, but I&amp;#39;m a greedy simpleton. Please take pity.)&lt;/p&gt;\n\n&lt;p&gt;Since then, the pool has been stuck on &amp;quot;Storage pool-Rebalance&amp;quot;. Output from PS `Get-StorageJob`:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Name | IsBackgroundTask | ElapsedTime | JobState | PercentComplete | BytesProcessed | BytesTotal\n----\nStorage pool-Rebalance | True | 5012.09:03:37 | Shutting Down | 0 | 0 B | 8 GB\nNonresilient space-Repair | True | 1.01:14:57 | Suspended | 0 | 0 B | 256 GB\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Further, the GUI shows something similar: &lt;a href=\"https://imgur.com/a/wcjcdla\"&gt;https://imgur.com/a/wcjcdla&lt;/a&gt;, and `Stop-StorageJob -Name &amp;quot;Storage pool-Rebalance&amp;quot;` gives me:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Stop-StorageJob : Unspecified error\nAt line:1 char:1\n+ Stop-StorageJob -Name &amp;quot;Storage pool-Rebalance&amp;quot;\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    + CategoryInfo          : NotSpecified: (MSFT_StorageJob...Windows/Sto...):ROOT/Microsoft/...MSFT_StorageJob) [Sto\n   p-StorageJob], CimException\n    + FullyQualifiedErrorId : HRESULT 0x80004005,Stop-StorageJob\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Going into the Event Viewer, I have the same event over and over: &lt;a href=\"https://pastebin.com/GH44S4km\"&gt;https://pastebin.com/GH44S4km&lt;/a&gt; (but with RepairPhases increasing by 1 each time).&lt;/p&gt;\n\n&lt;p&gt;My sense is that if I can remove the drive for good, or alternatively reset the &amp;#39;job queue&amp;#39; of the storage spaces, it will be able to recover from there. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?auto=webp&amp;v=enabled&amp;s=29a9a63637ba4d7d7351133779f5fa07adb1d870", "width": 1803, "height": 1924}, "resolutions": [{"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2276873138d3e501787d9a79f3b15a5942741712", "width": 108, "height": 115}, {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=690183b4ac50dfee46b470f920c3d5120a499763", "width": 216, "height": 230}, {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d51ac3f5cb42667c31310b06bdc7054a1282549", "width": 320, "height": 341}, {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a3ae6c98d333d0485c622397379b8e788fab6a6", "width": 640, "height": 682}, {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=651f3888ff9af03bec825464ff23945959a00f6d", "width": 960, "height": 1024}, {"url": "https://external-preview.redd.it/YVFsfYRKZZeiIjNne5tFPDiIHN09K02P9y2gC7J1E2U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd9e9543a43ec482fa3feef62c78f643cd0333a6", "width": 1080, "height": 1152}], "variants": {}, "id": "QC9JE9G8hCpktX-YPJ4kEV8IJxPAON37FrYeq91Jsfc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109qatw", "is_robot_indexable": true, "report_reasons": null, "author": "cuss_sayer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109qatw/storage_spaces_stuck_on_jobstate_shutting_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109qatw/storage_spaces_stuck_on_jobstate_shutting_down/", "subreddit_subscribers": 665468, "created_utc": 1673497936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI've been lurking around here for quite a while and I'm hoping someone could maybe help me in acquiring my first NAS.\n\nFirstly, here's what I would like to do. I'd like to have 4 bays for a start of 20TB with IronWolf drives that I already have. There will be Mac's and PC's connecting to this, and I'd like to be able to transfer files over the internet with something like SSH or Nextcloud. I will be storing mostly video and photo content on here. In the future I'd like to add Plex to it aswell, and it would be cool to have Dropbox support too. I don't need it to have any special power for transcoding; its hardware just needs to transfer files as fast as my network can (gigabit).\n\nMy old solution was a couple of large IronWolf's in my PC, but I've switched away to a MacBook and now use a couple of drive enclosures to connect to the drives here and there. (don't worry, the drives have been in great care.) This has been a temporary solution for a year now, and I now have the budget to get a proper NAS.\n\nI'd like everything to be pretty seamless and would not like to spend extra time troubleshooting issues in the future. I've worked with a QNAP before at my friend's place and kind of liked that, but I've never touched a Synology before. The consensus I've seen is that Synology is the better choice of an all-in-one since it has good software. So I think I'm in the right direction for an all-in-one, but I've been turned on a little bit to building my own, too. Plus, offerings like the DS920+ seems to be out of stock.\n\nI always thought that building a NAS from PC parts can yield more troubleshooting from something breaking (I think about issues I used to have building my PC's). But after seeing this subreddit and videos like those from Linus, it might be way more simple than I thought. Can someone with actual experience weigh into if this is true (and what you use)? I've seen TrueNAS and unRAID, and would be willing to lean into learning curves **if** **I don't have to troubleshoot so much in the future.** Maybe I'm wishing too much, but hey, I don't know. I would appreciate input from someone who knows more about this than me. Thanks.\n\nLuke", "author_fullname": "t2_ol7v3ls", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to buy or possibly build a new NAS for video and beyond", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109pzyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673497909.0, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673497029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been lurking around here for quite a while and I&amp;#39;m hoping someone could maybe help me in acquiring my first NAS.&lt;/p&gt;\n\n&lt;p&gt;Firstly, here&amp;#39;s what I would like to do. I&amp;#39;d like to have 4 bays for a start of 20TB with IronWolf drives that I already have. There will be Mac&amp;#39;s and PC&amp;#39;s connecting to this, and I&amp;#39;d like to be able to transfer files over the internet with something like SSH or Nextcloud. I will be storing mostly video and photo content on here. In the future I&amp;#39;d like to add Plex to it aswell, and it would be cool to have Dropbox support too. I don&amp;#39;t need it to have any special power for transcoding; its hardware just needs to transfer files as fast as my network can (gigabit).&lt;/p&gt;\n\n&lt;p&gt;My old solution was a couple of large IronWolf&amp;#39;s in my PC, but I&amp;#39;ve switched away to a MacBook and now use a couple of drive enclosures to connect to the drives here and there. (don&amp;#39;t worry, the drives have been in great care.) This has been a temporary solution for a year now, and I now have the budget to get a proper NAS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like everything to be pretty seamless and would not like to spend extra time troubleshooting issues in the future. I&amp;#39;ve worked with a QNAP before at my friend&amp;#39;s place and kind of liked that, but I&amp;#39;ve never touched a Synology before. The consensus I&amp;#39;ve seen is that Synology is the better choice of an all-in-one since it has good software. So I think I&amp;#39;m in the right direction for an all-in-one, but I&amp;#39;ve been turned on a little bit to building my own, too. Plus, offerings like the DS920+ seems to be out of stock.&lt;/p&gt;\n\n&lt;p&gt;I always thought that building a NAS from PC parts can yield more troubleshooting from something breaking (I think about issues I used to have building my PC&amp;#39;s). But after seeing this subreddit and videos like those from Linus, it might be way more simple than I thought. Can someone with actual experience weigh into if this is true (and what you use)? I&amp;#39;ve seen TrueNAS and unRAID, and would be willing to lean into learning curves &lt;strong&gt;if&lt;/strong&gt; &lt;strong&gt;I don&amp;#39;t have to troubleshoot so much in the future.&lt;/strong&gt; Maybe I&amp;#39;m wishing too much, but hey, I don&amp;#39;t know. I would appreciate input from someone who knows more about this than me. Thanks.&lt;/p&gt;\n\n&lt;p&gt;Luke&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109pzyf", "is_robot_indexable": true, "report_reasons": null, "author": "montana500", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/109pzyf/looking_to_buy_or_possibly_build_a_new_nas_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109pzyf/looking_to_buy_or_possibly_build_a_new_nas_for/", "subreddit_subscribers": 665468, "created_utc": 1673497029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My setup is fairly simple.  I have two Win10 work PCs:  A sw development workstation, and a DAW (music workstation).\n\nBoth of these computers operate from a 1TB system drive, although the music workstation has an additional 2TB drive for sample libraries (that doesn't need to be backed up).  So the requirement is simple, I want network backups of both computers that can be restored in case of failure. \n\n[What I've *been* doing is manually saving projects to a 2tb usb drive.  Online software repositories also contain my software work so that is mostly backed up to the cloud.]\n\nThere is an old PC (4790k) that I intend to use as plex server and as NAS.   It has four drives: 250gb ssd, 2x 1tb hdd, 1x 2tb hdd.  I would like to \"mirror\" the working drives of my two PCs onto the 1TB hdds.\n\nBut the question, is it really worth the hassle of setting up a seprate NAS and coordinating network backups?  I could install one of each 1TB drive into the two computers, and the backups could be performed locally.   Availability isn't that important so I'm not really looking at a raid, just some sort of automated script that backs up the system.  I don't know what software is available to do this.\n\nHere is what I'm thinking:\n\n1) Can I set up a Windows \"storage space\" on the 3rd PC, using the 1tb drives as mirrors for each of the work PCs?\n\n2) How can it be automated in a completely reliable fashion to perform nightly backups without having the server powered up 24/7 (it only needs to be on when performing a backup)?  \n\n2b) I said \"nightly\" in previous question, is there a way to network mirror a drive to that it is updated in relatively real time without hurting performance?\n\n3) I am assuming the mirrors are written with the same sequence of changes that were made to the primary drive, so that it doesn't have to bottom up copy the whole drive every night.  How do I synchronize these backups with online cloud storage so that I don't have to upload the entire disk image(s)?\n\n4) Will this result in an image that can be 100% reliably restored to a drive should it fail and need replacement?\n\nAny help or push in right direction appreciated.  It is my opinion that people/myself tend to over complicate things.  The reason I don't want local raids is that if one of the computers(notebook) is lost or stolen, I will have a backup in a separate box at home, and online.\n\nI know I could install TrueNas Core on the third computer, but the benefit of this hasn't been made apparent over a Win10 server.  Also plan to use it as Plex server, so would like to keep it windows.", "author_fullname": "t2_sfgikkx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategy: In your experience, what is the simplest/best/cheapest way to create automated backups for multiple PCs in my setup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109nptn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673490573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My setup is fairly simple.  I have two Win10 work PCs:  A sw development workstation, and a DAW (music workstation).&lt;/p&gt;\n\n&lt;p&gt;Both of these computers operate from a 1TB system drive, although the music workstation has an additional 2TB drive for sample libraries (that doesn&amp;#39;t need to be backed up).  So the requirement is simple, I want network backups of both computers that can be restored in case of failure. &lt;/p&gt;\n\n&lt;p&gt;[What I&amp;#39;ve &lt;em&gt;been&lt;/em&gt; doing is manually saving projects to a 2tb usb drive.  Online software repositories also contain my software work so that is mostly backed up to the cloud.]&lt;/p&gt;\n\n&lt;p&gt;There is an old PC (4790k) that I intend to use as plex server and as NAS.   It has four drives: 250gb ssd, 2x 1tb hdd, 1x 2tb hdd.  I would like to &amp;quot;mirror&amp;quot; the working drives of my two PCs onto the 1TB hdds.&lt;/p&gt;\n\n&lt;p&gt;But the question, is it really worth the hassle of setting up a seprate NAS and coordinating network backups?  I could install one of each 1TB drive into the two computers, and the backups could be performed locally.   Availability isn&amp;#39;t that important so I&amp;#39;m not really looking at a raid, just some sort of automated script that backs up the system.  I don&amp;#39;t know what software is available to do this.&lt;/p&gt;\n\n&lt;p&gt;Here is what I&amp;#39;m thinking:&lt;/p&gt;\n\n&lt;p&gt;1) Can I set up a Windows &amp;quot;storage space&amp;quot; on the 3rd PC, using the 1tb drives as mirrors for each of the work PCs?&lt;/p&gt;\n\n&lt;p&gt;2) How can it be automated in a completely reliable fashion to perform nightly backups without having the server powered up 24/7 (it only needs to be on when performing a backup)?  &lt;/p&gt;\n\n&lt;p&gt;2b) I said &amp;quot;nightly&amp;quot; in previous question, is there a way to network mirror a drive to that it is updated in relatively real time without hurting performance?&lt;/p&gt;\n\n&lt;p&gt;3) I am assuming the mirrors are written with the same sequence of changes that were made to the primary drive, so that it doesn&amp;#39;t have to bottom up copy the whole drive every night.  How do I synchronize these backups with online cloud storage so that I don&amp;#39;t have to upload the entire disk image(s)?&lt;/p&gt;\n\n&lt;p&gt;4) Will this result in an image that can be 100% reliably restored to a drive should it fail and need replacement?&lt;/p&gt;\n\n&lt;p&gt;Any help or push in right direction appreciated.  It is my opinion that people/myself tend to over complicate things.  The reason I don&amp;#39;t want local raids is that if one of the computers(notebook) is lost or stolen, I will have a backup in a separate box at home, and online.&lt;/p&gt;\n\n&lt;p&gt;I know I could install TrueNas Core on the third computer, but the benefit of this hasn&amp;#39;t been made apparent over a Win10 server.  Also plan to use it as Plex server, so would like to keep it windows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109nptn", "is_robot_indexable": true, "report_reasons": null, "author": "ahoypolloi69", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109nptn/strategy_in_your_experience_what_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109nptn/strategy_in_your_experience_what_is_the/", "subreddit_subscribers": 665468, "created_utc": 1673490573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking for a webui tool to manage my music folder.\n\nMy idea is something like that:\n\n\\- I tell the program where I will add new songs (like the rip folder)\n\n\\- It automatically detect new songs, search for tags and the move the song to the correct folder\n\n\\- from the webui I set the rules and edit metadata if needed.\n\n&amp;#x200B;\n\nDo you know anything that can do that?", "author_fullname": "t2_24u5cpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manage music folder from webui?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109jdnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673479355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a webui tool to manage my music folder.&lt;/p&gt;\n\n&lt;p&gt;My idea is something like that:&lt;/p&gt;\n\n&lt;p&gt;- I tell the program where I will add new songs (like the rip folder)&lt;/p&gt;\n\n&lt;p&gt;- It automatically detect new songs, search for tags and the move the song to the correct folder&lt;/p&gt;\n\n&lt;p&gt;- from the webui I set the rules and edit metadata if needed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you know anything that can do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109jdnd", "is_robot_indexable": true, "report_reasons": null, "author": "TopdeckIsSkill", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "subreddit_subscribers": 665468, "created_utc": 1673479355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there fellow hoarders! Right now I'm using a couple external WD HDDs to store my media and want to upgrade to a true media server. I was given a very nice server tower for free and plan to use this for my build. It holds 17 HDDS though I'm not positive I'm going to fill it completely to begin with. I'm curious if any of you have worked out what the best size to cost ratio is for buying drives? Any help would be appreciated", "author_fullname": "t2_5tr1nl7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost to Size sweetspot for HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109eic3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673467710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there fellow hoarders! Right now I&amp;#39;m using a couple external WD HDDs to store my media and want to upgrade to a true media server. I was given a very nice server tower for free and plan to use this for my build. It holds 17 HDDS though I&amp;#39;m not positive I&amp;#39;m going to fill it completely to begin with. I&amp;#39;m curious if any of you have worked out what the best size to cost ratio is for buying drives? Any help would be appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109eic3", "is_robot_indexable": true, "report_reasons": null, "author": "ThornOvCamor", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109eic3/cost_to_size_sweetspot_for_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109eic3/cost_to_size_sweetspot_for_hdds/", "subreddit_subscribers": 665468, "created_utc": 1673467710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've heard that NAS HDDs are not made for that on/off and laying around. So I am curious which drives I should buy.\n\nI am planning to buy two external cases and two 4TB drives and keeping them in sync manually with freefilesync.", "author_fullname": "t2_87bhn57g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I buy NAS or normal HDDs for an external case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1092z9q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673438319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve heard that NAS HDDs are not made for that on/off and laying around. So I am curious which drives I should buy.&lt;/p&gt;\n\n&lt;p&gt;I am planning to buy two external cases and two 4TB drives and keeping them in sync manually with freefilesync.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1092z9q", "is_robot_indexable": true, "report_reasons": null, "author": "pocox3", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1092z9q/should_i_buy_nas_or_normal_hdds_for_an_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1092z9q/should_i_buy_nas_or_normal_hdds_for_an_external/", "subreddit_subscribers": 665468, "created_utc": 1673438319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI would like to hear your advice about a reliable backup solution. today I use Crashplan to backup about 1tb of data, with addition of payment to google for phone camera backup (although every 3 months or so i move my phone photos to my computer)\n\n&amp;#x200B;\n\ni would like to find a backup service (hopefully free, with a GUI, but not a must) to backup all my (or my important folders)  to google drive or onedrive . i searched and saw programs like Rsync/ duplicity  but i know Reddit probably has a more solid opinion on this, which i would love to hear. it must has a possibility to Restore in case of a disaster (like PC is stolen / broken)\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_aibn51my", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup solution with onedrive/gdrive as storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108zx5u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673426477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I would like to hear your advice about a reliable backup solution. today I use Crashplan to backup about 1tb of data, with addition of payment to google for phone camera backup (although every 3 months or so i move my phone photos to my computer)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i would like to find a backup service (hopefully free, with a GUI, but not a must) to backup all my (or my important folders)  to google drive or onedrive . i searched and saw programs like Rsync/ duplicity  but i know Reddit probably has a more solid opinion on this, which i would love to hear. it must has a possibility to Restore in case of a disaster (like PC is stolen / broken)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108zx5u", "is_robot_indexable": true, "report_reasons": null, "author": "ellevy12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108zx5u/backup_solution_with_onedrivegdrive_as_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108zx5u/backup_solution_with_onedrivegdrive_as_storage/", "subreddit_subscribers": 665468, "created_utc": 1673426477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I keep my old [Time Machine](https://en.wikipedia.org/wiki/Time_Machine_(macOS)) backups all the way from 2013. I keep them on my NAS as read-only DMGs which I made from the Time Machine disk. For searching I am planning to use [NeoFinder](https://www.cdfinder.de/).\n\nWhat do people think: Does this make sense?  And what do others do? How do they store their old Time machine backups? And how do they search/access them?", "author_fullname": "t2_850k4phh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does it make sense to hoard Apple time machine backups? Who keeps them? And in which format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109qfj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673498324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep my old &lt;a href=\"https://en.wikipedia.org/wiki/Time_Machine_(macOS\"&gt;Time Machine&lt;/a&gt;) backups all the way from 2013. I keep them on my NAS as read-only DMGs which I made from the Time Machine disk. For searching I am planning to use &lt;a href=\"https://www.cdfinder.de/\"&gt;NeoFinder&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;What do people think: Does this make sense?  And what do others do? How do they store their old Time machine backups? And how do they search/access them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109qfj2", "is_robot_indexable": true, "report_reasons": null, "author": "jan_aloleo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109qfj2/does_it_make_sense_to_hoard_apple_time_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109qfj2/does_it_make_sense_to_hoard_apple_time_machine/", "subreddit_subscribers": 665468, "created_utc": 1673498324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When I export a WhatsApp chat using the built in export feature in WhatsApp on iPhone, it\u2019s a txt file but emojis are still visible when opening the exported file on iPhone txt viewer. However, on windows notepad obviously it doesn\u2019t display the emojis. What text reader is on the iPhone and is there anything similar for windows to allow viewing the WhatsApp chat with emojis like they show in the iPhone text viewer?", "author_fullname": "t2_e6drpuch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WhatsApp export and formatting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109maot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673486796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I export a WhatsApp chat using the built in export feature in WhatsApp on iPhone, it\u2019s a txt file but emojis are still visible when opening the exported file on iPhone txt viewer. However, on windows notepad obviously it doesn\u2019t display the emojis. What text reader is on the iPhone and is there anything similar for windows to allow viewing the WhatsApp chat with emojis like they show in the iPhone text viewer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109maot", "is_robot_indexable": true, "report_reasons": null, "author": "aviator_L1011", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109maot/whatsapp_export_and_formatting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109maot/whatsapp_export_and_formatting/", "subreddit_subscribers": 665468, "created_utc": 1673486796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_582xz2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing Pin Tweet to IPFS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_109jicb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jvM5ok8cCSZytyXa1yzGsEM4eZjXVlVIduvnMHlJMSc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673479680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.ipfs.tech", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.ipfs.tech/announcing-pin-tweet-to-ipfs/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?auto=webp&amp;v=enabled&amp;s=8781dbda893c73eea5a534ce394fd27749f1c0a0", "width": 2000, "height": 1124}, "resolutions": [{"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4e9602a01e6c41794c27be0975dda67fefc3313", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efa89b156712e3446be2d89f6f4ce09bd5cc6b63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83a355a7b627c64c8e0602924f379e213b635a28", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6c5f69397b1c5b4e176a882b875c569bbbdfe1", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=544b3c4580083afe09e25ce473da552239e23a90", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0cc95f3e9bce8798f400e5954aec4f2ce0738b3", "width": 1080, "height": 606}], "variants": {}, "id": "B2uk6TAJvETommfm85rwk4tuEHxycKfZo3h36xyAGes"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109jicb", "is_robot_indexable": true, "report_reasons": null, "author": "Spirited-Pause", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109jicb/announcing_pin_tweet_to_ipfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.ipfs.tech/announcing-pin-tweet-to-ipfs/", "subreddit_subscribers": 665468, "created_utc": 1673479680.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}