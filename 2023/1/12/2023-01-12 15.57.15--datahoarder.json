{"kind": "Listing", "data": {"after": "t3_109voht", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3t9lh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pulled this from a Synology NAS. Over 8 years old\u2026how much more life could be reasonably expected? Haven\u2019t even powered it on to check overall health yet, just going by the disk &amp; date. Non-critical files, just trying to gauge how much I trust this disk at this age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10973ac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 377, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 377, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VzkJCwoWMKfDR_G-XAlanJ4iHTqgi8GaAqVhg_uVeO8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673450072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m1uxflo82hba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?auto=webp&amp;v=enabled&amp;s=38962ad10b9ff8fc6389fecc51d6621254e638b3", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90a638729bc797b1e3d9f03e2c3b2ccd53fbee25", "width": 108, "height": 144}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20d57e9a1925ab0d3773149171223d601cd9a630", "width": 216, "height": 288}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0636517a50df9f57ff06aec405213e19c6f838c5", "width": 320, "height": 426}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea53916348a61b9094d18e1f8d8420481185323b", "width": 640, "height": 853}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b52e3920e3fc735bcc974bc2c649a5c9e94c91a9", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a76e21e3a3a2f421ba4f4b50bc3010dc0d0520d0", "width": 1080, "height": 1440}], "variants": {}, "id": "rsQ04fVBKdmZ1EcVFpnc84qMLNK428HYo4GpVsYeml0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10973ac", "is_robot_indexable": true, "report_reasons": null, "author": "andytagonist", "discussion_type": null, "num_comments": 209, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10973ac/pulled_this_from_a_synology_nas_over_8_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m1uxflo82hba1.jpg", "subreddit_subscribers": 665513, "created_utc": 1673450072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I'm located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I'm aware, but it all seemed like a good idea at the time).\n\nThe process is deceptively simple if you've never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.\n\nThe first thing you'll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.\n\nThen you'll discover that there's absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word \"asynchronous\" and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don't even see your checkboxes get checked until the requests complete.\n\nBut let's say you've checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn't you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I've seen (something like 20-30 minutes) and no \"Remember me\" button. This is a bit more of a big deal, or - as you might find out later - a very big deal.\n\nSo you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I've had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven't had that happen often with large ones, but a bunch of times with small ones.\n\nYou've finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you've had first hand experience with the downloader. (Spoilers, I know). Let's say you listen and download the downloader - pointlessly, as it turns out, since it's already there along with your Backblaze installation.\n\nYou give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.\n\nAnd then you realize the downloader has the same problem as the UI with the \"async\" concept, except Windows really, *really* doesn't like apps hogging the UI thread. So 90 percent of the time the window is \"not responding\", the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I've had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you've made a mistake of restoring to your C:\\ drive this is going to be even worse since that's also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them \"threads\"; that's not quite telling the whole story as they're entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it's hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.\n\nBut let's say you've downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there's no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there's no indication which restores you have or have not already downloaded.\n\nAnd while you've been marveling at that the unzip process has thrown a CRC error - which I really, *really* hope is just an issue with the zipping/downloading process and the actual data that's being stored on the servers is okay. If you've had the downloader hang on you there's a pretty much 100% chance you'll get that, if you've stopped and restarted the download you'll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you're lucky it's just going to be one or two files and you can restore them separately, if you're not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.\n\nSo you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the \"acceleration\" part, which for some reason works only up to some size - maybe that's some issue on my side, but I've tried multiple ones and I haven't gotten the big restores to download in parallel, only smaller ones.\n\nAnd even if you've gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they've finished a chunk, said connections are now getting redirected to the login page. I've tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don't care for the acceleration, I hope you didn't spend too much time setting up a queue of downloads (or go to bed afterwards), because that won't work either for the same reason.\n\nIronically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don't ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can't just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.\n\nNow does it mean Backblaze is a bad service? I guess not - for the price it's still a steal, and there are other options to restore. If you're in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I'm likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don't want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might've heard of the restore process being a bit iffy but it can't be that bad, right?\n\nWell, it's exactly as bad as above, no more, no less - whether that's a dealbreaker is in the eye of the beholder, but it's better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I'm hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it's really a bit disappointing that the current process is so miserable.", "author_fullname": "t2_epug6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Backblaze large restore experience (is miserable)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109kd3j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 296, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 296, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673481815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I&amp;#39;m located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I&amp;#39;m aware, but it all seemed like a good idea at the time).&lt;/p&gt;\n\n&lt;p&gt;The process is deceptively simple if you&amp;#39;ve never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.&lt;/p&gt;\n\n&lt;p&gt;The first thing you&amp;#39;ll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.&lt;/p&gt;\n\n&lt;p&gt;Then you&amp;#39;ll discover that there&amp;#39;s absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word &amp;quot;asynchronous&amp;quot; and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don&amp;#39;t even see your checkboxes get checked until the requests complete.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn&amp;#39;t you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I&amp;#39;ve seen (something like 20-30 minutes) and no &amp;quot;Remember me&amp;quot; button. This is a bit more of a big deal, or - as you might find out later - a very big deal.&lt;/p&gt;\n\n&lt;p&gt;So you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I&amp;#39;ve had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven&amp;#39;t had that happen often with large ones, but a bunch of times with small ones.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;ve finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you&amp;#39;ve had first hand experience with the downloader. (Spoilers, I know). Let&amp;#39;s say you listen and download the downloader - pointlessly, as it turns out, since it&amp;#39;s already there along with your Backblaze installation.&lt;/p&gt;\n\n&lt;p&gt;You give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.&lt;/p&gt;\n\n&lt;p&gt;And then you realize the downloader has the same problem as the UI with the &amp;quot;async&amp;quot; concept, except Windows really, &lt;em&gt;really&lt;/em&gt; doesn&amp;#39;t like apps hogging the UI thread. So 90 percent of the time the window is &amp;quot;not responding&amp;quot;, the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I&amp;#39;ve had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you&amp;#39;ve made a mistake of restoring to your C:\\ drive this is going to be even worse since that&amp;#39;s also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them &amp;quot;threads&amp;quot;; that&amp;#39;s not quite telling the whole story as they&amp;#39;re entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it&amp;#39;s hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there&amp;#39;s no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there&amp;#39;s no indication which restores you have or have not already downloaded.&lt;/p&gt;\n\n&lt;p&gt;And while you&amp;#39;ve been marveling at that the unzip process has thrown a CRC error - which I really, &lt;em&gt;really&lt;/em&gt; hope is just an issue with the zipping/downloading process and the actual data that&amp;#39;s being stored on the servers is okay. If you&amp;#39;ve had the downloader hang on you there&amp;#39;s a pretty much 100% chance you&amp;#39;ll get that, if you&amp;#39;ve stopped and restarted the download you&amp;#39;ll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you&amp;#39;re lucky it&amp;#39;s just going to be one or two files and you can restore them separately, if you&amp;#39;re not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.&lt;/p&gt;\n\n&lt;p&gt;So you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the &amp;quot;acceleration&amp;quot; part, which for some reason works only up to some size - maybe that&amp;#39;s some issue on my side, but I&amp;#39;ve tried multiple ones and I haven&amp;#39;t gotten the big restores to download in parallel, only smaller ones.&lt;/p&gt;\n\n&lt;p&gt;And even if you&amp;#39;ve gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they&amp;#39;ve finished a chunk, said connections are now getting redirected to the login page. I&amp;#39;ve tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don&amp;#39;t care for the acceleration, I hope you didn&amp;#39;t spend too much time setting up a queue of downloads (or go to bed afterwards), because that won&amp;#39;t work either for the same reason.&lt;/p&gt;\n\n&lt;p&gt;Ironically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don&amp;#39;t ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can&amp;#39;t just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.&lt;/p&gt;\n\n&lt;p&gt;Now does it mean Backblaze is a bad service? I guess not - for the price it&amp;#39;s still a steal, and there are other options to restore. If you&amp;#39;re in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I&amp;#39;m likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don&amp;#39;t want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might&amp;#39;ve heard of the restore process being a bit iffy but it can&amp;#39;t be that bad, right?&lt;/p&gt;\n\n&lt;p&gt;Well, it&amp;#39;s exactly as bad as above, no more, no less - whether that&amp;#39;s a dealbreaker is in the eye of the beholder, but it&amp;#39;s better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I&amp;#39;m hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it&amp;#39;s really a bit disappointing that the current process is so miserable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109kd3j", "is_robot_indexable": true, "report_reasons": null, "author": "Mivexil", "discussion_type": null, "num_comments": 142, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "subreddit_subscribers": 665513, "created_utc": 1673481815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). \n\nI grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn't *need* to do it so I wasn't looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. \n\nI have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. \n\nLuckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.", "author_fullname": "t2_hz5u5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bought used QNAP TS431+.. Previous owner left hsi whole company on the drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h0eu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). &lt;/p&gt;\n\n&lt;p&gt;I grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn&amp;#39;t &lt;em&gt;need&lt;/em&gt; to do it so I wasn&amp;#39;t looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. &lt;/p&gt;\n\n&lt;p&gt;I have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. &lt;/p&gt;\n\n&lt;p&gt;Luckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109h0eu", "is_robot_indexable": true, "report_reasons": null, "author": "DeffNotTom", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "subreddit_subscribers": 665513, "created_utc": 1673473617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uyo43rx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building my first server ordered 4 ironwolf nas I got 2 and 2 with different labels all manufactured within 2 months of each other. Is there any difference in these models or is it it just the same drive with different sku that was sent ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_109bu22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c2jbX7b3UhyQurMFUhttmpCFURt2u611mr54l2OI89M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673461467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/3LFi29T.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?auto=webp&amp;v=enabled&amp;s=6710305a9cd53d5664e90e5591beab4d5edacd63", "width": 1500, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64050a9f5bc430f26fb1aedac51def6817a41cfd", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c3cfd278a50b090624057c885b6ae0f1aca5bb1", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30f98641b32882419cd8e5707e08babbff8c0ccc", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=647e785ef4717773d796e26063513786711ad06e", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49798d4dd8bf4d9770b9de0b2b668ad041f47f93", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=737def69e6194720c6a6b36d19b5d8575a583312", "width": 1080, "height": 1440}], "variants": {}, "id": "dGFmEl7G6uLJ9TlJnP-3Orf4-A5rCRB9aAQ2vW9aKBo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109bu22", "is_robot_indexable": true, "report_reasons": null, "author": "Yung_Gleesh_", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109bu22/building_my_first_server_ordered_4_ironwolf_nas_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/3LFi29T.jpg", "subreddit_subscribers": 665513, "created_utc": 1673461467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.\n\nstarted filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, \"smr, working as intended\"\n\nonce downloads completed I figured I'd give chkdsk another pass just to be sure. 10 bad clusters found this time.\n\nI'm dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn't trust it with important data, but considering I'm stuck with it, is there anything I can do? maybe zero fill?\n\nEDIT\n\nfull chkdsk log: https://i.imgur.com/Waab8Hb.png", "author_fullname": "t2_18grx8tx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 bad clusters on recently acquired WD external", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1099y9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673459963.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673457091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.&lt;/p&gt;\n\n&lt;p&gt;started filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, &amp;quot;smr, working as intended&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;once downloads completed I figured I&amp;#39;d give chkdsk another pass just to be sure. 10 bad clusters found this time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn&amp;#39;t trust it with important data, but considering I&amp;#39;m stuck with it, is there anything I can do? maybe zero fill?&lt;/p&gt;\n\n&lt;p&gt;EDIT&lt;/p&gt;\n\n&lt;p&gt;full chkdsk log: &lt;a href=\"https://i.imgur.com/Waab8Hb.png\"&gt;https://i.imgur.com/Waab8Hb.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?auto=webp&amp;v=enabled&amp;s=fa22f783b4db4bed916c680781e0f71926150b29", "width": 1324, "height": 916}, "resolutions": [{"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=365328e4f0f15ae1640e0794ffeeb0506be978ce", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02df3d9cd0ffded9da82365fd3e75535b7254778", "width": 216, "height": 149}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7f5c08ca3023ea82e4cfcd3fd24e087bbc69ca4", "width": 320, "height": 221}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0691378505539a6abecb7007d2b64691ccd6bd29", "width": 640, "height": 442}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd404e36265ed7b36c9faa1a8b82675c1510d172", "width": 960, "height": 664}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1948ff24faecef9cda2940048d6d093a970c24", "width": 1080, "height": 747}], "variants": {}, "id": "WRxgf3zs3hd4T5edmv4gY-a8OnqkOammTTB4c1y_Lgc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1099y9o", "is_robot_indexable": true, "report_reasons": null, "author": "h-t-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "subreddit_subscribers": 665513, "created_utc": 1673457091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? \n\nI love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. \n\nThanks!", "author_fullname": "t2_jijjmnms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you BUY your ebooks from?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1096x85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673449643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? &lt;/p&gt;\n\n&lt;p&gt;I love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1096x85", "is_robot_indexable": true, "report_reasons": null, "author": "clickbg", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "subreddit_subscribers": 665513, "created_utc": 1673449643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not the type of person for this sub. All of my data is under a TB.... but I started playing around with 3d scanning and that's changing fast. 20gb scans. 150gb project files. \n\nI'm not wanting to spend too much or get too involved for now so this is the setup I'm thinking. \n\npurchase 3 HDD in the 4-6tb range. 2 go into an old computer running raid 1. map network drive and drag the projects over when I'm done with them. The third is kept somewhere else and brought over once a month to get updated\n\nto me it sounds like a good idea with more than 1 layer of defense. any opinions?", "author_fullname": "t2_v3z3kryc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to get a sanity check for archive/backup idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109n680", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673489125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not the type of person for this sub. All of my data is under a TB.... but I started playing around with 3d scanning and that&amp;#39;s changing fast. 20gb scans. 150gb project files. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not wanting to spend too much or get too involved for now so this is the setup I&amp;#39;m thinking. &lt;/p&gt;\n\n&lt;p&gt;purchase 3 HDD in the 4-6tb range. 2 go into an old computer running raid 1. map network drive and drag the projects over when I&amp;#39;m done with them. The third is kept somewhere else and brought over once a month to get updated&lt;/p&gt;\n\n&lt;p&gt;to me it sounds like a good idea with more than 1 layer of defense. any opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109n680", "is_robot_indexable": true, "report_reasons": null, "author": "Optimal-Growth-5741", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109n680/wanting_to_get_a_sanity_check_for_archivebackup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109n680/wanting_to_get_a_sanity_check_for_archivebackup/", "subreddit_subscribers": 665513, "created_utc": 1673489125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photo sorter recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109l5sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673483820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109l5sr", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "subreddit_subscribers": 665513, "created_utc": 1673483820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.\n\nAs an example, here is what I\u2019ve tried so far:\n\n    youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\nBut this returns an Unsupported URL error.\n\nImportantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.\n\nAny way to do this?", "author_fullname": "t2_151mwt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[youtube-dl] How to download all the videos belonging to a Vimeo user archived on Wayback Machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097ut9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.&lt;/p&gt;\n\n&lt;p&gt;As an example, here is what I\u2019ve tried so far:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But this returns an Unsupported URL error.&lt;/p&gt;\n\n&lt;p&gt;Importantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.&lt;/p&gt;\n\n&lt;p&gt;Any way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097ut9", "is_robot_indexable": true, "report_reasons": null, "author": "AsleepInTheStalks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "subreddit_subscribers": 665513, "created_utc": 1673452007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.\n\nLooking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.\n\nTIA!", "author_fullname": "t2_9jlhrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions: Data migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h2xs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109h2xs", "is_robot_indexable": true, "report_reasons": null, "author": "PerpetuallyPerplxed", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "subreddit_subscribers": 665513, "created_utc": 1673473789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've got about 300,000 emails going back to 1993.  I love having the whole thing indexed and searchable for practical and nostalgic purposes, but the ratio of \"good\" to \"bad\" is ridiculous.  Even with gmail doing a lot of the heavy spam filtering, it's got a lot of garbage.\n\nDoes anyone have any pointers on how to efficiently spam filter large quantities of email spread across about 30 unix mbox files?  \n\nIf I had to, I'd be OK resorting to something somewhat iterative and convoluted (somehow feed all the mbox files to a mail server running on one of my linux boxes?) but it would be nice if there were tools out there to make this as easy as possible.", "author_fullname": "t2_tthrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "30 years of saved email - spam filtering options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10a02eo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673531289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got about 300,000 emails going back to 1993.  I love having the whole thing indexed and searchable for practical and nostalgic purposes, but the ratio of &amp;quot;good&amp;quot; to &amp;quot;bad&amp;quot; is ridiculous.  Even with gmail doing a lot of the heavy spam filtering, it&amp;#39;s got a lot of garbage.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any pointers on how to efficiently spam filter large quantities of email spread across about 30 unix mbox files?  &lt;/p&gt;\n\n&lt;p&gt;If I had to, I&amp;#39;d be OK resorting to something somewhat iterative and convoluted (somehow feed all the mbox files to a mail server running on one of my linux boxes?) but it would be nice if there were tools out there to make this as easy as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a02eo", "is_robot_indexable": true, "report_reasons": null, "author": "lectures", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a02eo/30_years_of_saved_email_spam_filtering_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a02eo/30_years_of_saved_email_spam_filtering_options/", "subreddit_subscribers": 665513, "created_utc": 1673531289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't actually have the hardware yet, I'm doing some research before purchase (always advisable lol). I'm interested in buying a used 3.2TB Micron 7300 MAX, but I want to bump that up to 3.84TB for more capacity since I won't be using anywhere near the listed 3DWPD spec. Hell, assuming that makes it equal to the \"Pro\" version of the drive, 1DWPD is still waaaay overkill.\n\nIt seems like Micron calls it \"Flex Capacity\" and it seems to be a part of \"Storage Executive Software\". Is this where I change the capacity? Can I even increase the capacity? I've heard of people reducing capacity to increase endurance, but I've never heard of someone doing the reverse.", "author_fullname": "t2_upalof7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I change the capacity / overprovisioning on a Micron 7300 MAX?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109z0cp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673528186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t actually have the hardware yet, I&amp;#39;m doing some research before purchase (always advisable lol). I&amp;#39;m interested in buying a used 3.2TB Micron 7300 MAX, but I want to bump that up to 3.84TB for more capacity since I won&amp;#39;t be using anywhere near the listed 3DWPD spec. Hell, assuming that makes it equal to the &amp;quot;Pro&amp;quot; version of the drive, 1DWPD is still waaaay overkill.&lt;/p&gt;\n\n&lt;p&gt;It seems like Micron calls it &amp;quot;Flex Capacity&amp;quot; and it seems to be a part of &amp;quot;Storage Executive Software&amp;quot;. Is this where I change the capacity? Can I even increase the capacity? I&amp;#39;ve heard of people reducing capacity to increase endurance, but I&amp;#39;ve never heard of someone doing the reverse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109z0cp", "is_robot_indexable": true, "report_reasons": null, "author": "Party_9001", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109z0cp/how_do_i_change_the_capacity_overprovisioning_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109z0cp/how_do_i_change_the_capacity_overprovisioning_on/", "subreddit_subscribers": 665513, "created_utc": 1673528186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've located and reuploaded a long lost UnleashX skin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_109vz32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2b9r7ngd", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jnjs0qw2eBd5aTzRu8i0sLwfd-qlwww-SgI8E2Y9eSE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "originalxbox", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2072dcd672302c1afa94268bcd3f1514386135f7\n\nI archived an UnleashX skin that was deleted off the internet suddenly. It was posted to Twitter by its creator Retro Game Rarities in 2020 and his account suddenly got deleted. I was able to find a link to it via google cache and I've since reuploaded it to [archive.org](https://archive.org)\n\n[https://archive.org/details/UnleashX-EmeraldX-skin](https://archive.org/details/UnleashX-EmeraldX-skin)\n\nIt's easily the coolest looking UnleashX skin I've ever seen. It was disappointing to discover it was so hastily deleted and purged off the internet.\n\n&amp;#x200B;\n\nThe creator's original video is here\n\nhttps://reddit.com/link/109ri3e/video/icgsgx97ujba1/player", "author_fullname": "t2_77nrtq1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've located and reuploaded a long lost UnleashX skin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/originalxbox", "hidden": false, "pwls": 6, "link_flair_css_class": "tools", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "media_metadata": {"20rcv4cgtjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efe2643dd2b8fbcee893090d86edbc036005feda"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c285fb7495f33678c3b1ed7089e7269b1a5d74b"}, {"y": 177, "x": 320, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=76a2a4d9e3b0066cf79801458a08be4ba34f33a4"}, {"y": 355, "x": 640, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f108e3c16a23e91941d839c7142df34078624251"}], "s": {"y": 383, "x": 689, "u": "https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2072dcd672302c1afa94268bcd3f1514386135f7"}, "id": "20rcv4cgtjba1"}, "icgsgx97ujba1": {"status": "valid", "e": "RedditVideo", "dashUrl": "https://v.redd.it/link/109ri3e/asset/icgsgx97ujba1/DASHPlaylist.mpd?a=1676131035%2CM2ExYjhmYjkxZjVlODk4OTc4NGRhOTdiOGE3YjlmODlhOGM5MjYzYmY5NzgyNmFiYjQwM2I4ZWFlMjQwM2MzNQ%3D%3D&amp;v=1&amp;f=sd", "x": 1280, "y": 720, "hlsUrl": "https://v.redd.it/link/109ri3e/asset/icgsgx97ujba1/HLSPlaylist.m3u8?a=1676131035%2COTliY2E3YzE3YzIxOTQzZjc3YzhmMmFkMDk4N2VhNTczNjE1ZDQ2YmQ5NjBhOGRhZTA3MWE3YmRkZDY5MzE5OQ%3D%3D&amp;v=1&amp;f=sd", "id": "icgsgx97ujba1", "isGif": false}}, "name": "t3_109ri3e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Software &amp; Tools", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Jnjs0qw2eBd5aTzRu8i0sLwfd-qlwww-SgI8E2Y9eSE.jpg", "edited": 1673516612.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673501638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.originalxbox", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2072dcd672302c1afa94268bcd3f1514386135f7\"&gt;https://preview.redd.it/20rcv4cgtjba1.png?width=689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2072dcd672302c1afa94268bcd3f1514386135f7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I archived an UnleashX skin that was deleted off the internet suddenly. It was posted to Twitter by its creator Retro Game Rarities in 2020 and his account suddenly got deleted. I was able to find a link to it via google cache and I&amp;#39;ve since reuploaded it to &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://archive.org/details/UnleashX-EmeraldX-skin\"&gt;https://archive.org/details/UnleashX-EmeraldX-skin&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s easily the coolest looking UnleashX skin I&amp;#39;ve ever seen. It was disappointing to discover it was so hastily deleted and purged off the internet.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The creator&amp;#39;s original video is here&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/109ri3e/video/icgsgx97ujba1/player\"&gt;https://reddit.com/link/109ri3e/video/icgsgx97ujba1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "65253322-f811-11ec-aadc-4685b9374796", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rww7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109ri3e", "is_robot_indexable": true, "report_reasons": null, "author": "Archer_Jr", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "subreddit_subscribers": 50891, "created_utc": 1673501638.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1673517607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.originalxbox", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109vz32", "is_robot_indexable": true, "report_reasons": null, "author": "RustedBlade7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_109ri3e", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109vz32/ive_located_and_reuploaded_a_long_lost_unleashx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/originalxbox/comments/109ri3e/ive_located_and_reuploaded_a_long_lost_unleashx/", "subreddit_subscribers": 665513, "created_utc": 1673517607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking for a webui tool to manage my music folder.\n\nMy idea is something like that:\n\n\\- I tell the program where I will add new songs (like the rip folder)\n\n\\- It automatically detect new songs, search for tags and the move the song to the correct folder\n\n\\- from the webui I set the rules and edit metadata if needed.\n\n&amp;#x200B;\n\nDo you know anything that can do that?", "author_fullname": "t2_24u5cpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manage music folder from webui?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109jdnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673479355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a webui tool to manage my music folder.&lt;/p&gt;\n\n&lt;p&gt;My idea is something like that:&lt;/p&gt;\n\n&lt;p&gt;- I tell the program where I will add new songs (like the rip folder)&lt;/p&gt;\n\n&lt;p&gt;- It automatically detect new songs, search for tags and the move the song to the correct folder&lt;/p&gt;\n\n&lt;p&gt;- from the webui I set the rules and edit metadata if needed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you know anything that can do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109jdnd", "is_robot_indexable": true, "report_reasons": null, "author": "TopdeckIsSkill", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "subreddit_subscribers": 665513, "created_utc": 1673479355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "ArchiveBox only seems to allow a person to save *all* of one's bookmarks and I couldn't even do that because I got the following error:\n\nError while loading link! \\[1673463122.097194\\] \\[path to my browser's bookmarks file\\] \"None\"\n\n&amp;#x200B;\n\nThis error was shown after I used the following command:\n\narchivebox add --depth=1 \\[path to my browser's bookmarks file\\]\n\n&amp;#x200B;\n\nCan somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as 'HTML Only.' It wouldn't take me long to do it manually, but I figured I would finally try to do it automatically.", "author_fullname": "t2_emji9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically save all pages in a bookmarks subfolder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109d68v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673464571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ArchiveBox only seems to allow a person to save &lt;em&gt;all&lt;/em&gt; of one&amp;#39;s bookmarks and I couldn&amp;#39;t even do that because I got the following error:&lt;/p&gt;\n\n&lt;p&gt;Error while loading link! [1673463122.097194] [path to my browser&amp;#39;s bookmarks file] &amp;quot;None&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This error was shown after I used the following command:&lt;/p&gt;\n\n&lt;p&gt;archivebox add --depth=1 [path to my browser&amp;#39;s bookmarks file]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as &amp;#39;HTML Only.&amp;#39; It wouldn&amp;#39;t take me long to do it manually, but I figured I would finally try to do it automatically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109d68v", "is_robot_indexable": true, "report_reasons": null, "author": "PA99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "subreddit_subscribers": 665513, "created_utc": 1673464571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, \n\nI am building myself a NAS to digitize my parents' DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives\n\nI'm planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I'm worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5\" HDD, and I would hope for some more HDD Bays for future expansion.\n\nI am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn't seem to be too difficult, but I wanna make sure I haven't overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!", "author_fullname": "t2_bzoyakj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "needing a little help/reassurance with my first server build!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097xi4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, &lt;/p&gt;\n\n&lt;p&gt;I am building myself a NAS to digitize my parents&amp;#39; DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I&amp;#39;m worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5&amp;quot; HDD, and I would hope for some more HDD Bays for future expansion.&lt;/p&gt;\n\n&lt;p&gt;I am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn&amp;#39;t seem to be too difficult, but I wanna make sure I haven&amp;#39;t overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097xi4", "is_robot_indexable": true, "report_reasons": null, "author": "justinc0617", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "subreddit_subscribers": 665513, "created_utc": 1673452196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Greetings all. I've been in an adventure trying to archive Reddit. I mostly want to download saved posts/singular posts (includes deleted posts as well) and not an entire sub-reddit. I have searched the web but I haven't found anything very helpful.\n\nI have tried BFDR and Export-Archive-Reddit-Saved but those don't deliver the results I want.\n\nI am currently using HTTraQt/HTTrack and its pretty good for other sites but when it comes to Reddit it doesn't quite work (I am probably not configuring it correctly). It can't get video files and when I open the HTMLs the page doesn't load correctly (it shows contents but it quickly goes to a white background). I'm good with using it, but I'll need a bit of help in order to configure it. However, if there are options out there that are better and **potentially** find deleted posts with maybe their content [images/videos] (because I got plenty of those) I'll also be very happy with that.\n\nThanks for the help. (Unsure of the flair a bit, mods are free to fix it if there's something wrong.)", "author_fullname": "t2_4jvz448c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need tips or in general a bit of help trying to locally save Reddit posts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10a1ktz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673535416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings all. I&amp;#39;ve been in an adventure trying to archive Reddit. I mostly want to download saved posts/singular posts (includes deleted posts as well) and not an entire sub-reddit. I have searched the web but I haven&amp;#39;t found anything very helpful.&lt;/p&gt;\n\n&lt;p&gt;I have tried BFDR and Export-Archive-Reddit-Saved but those don&amp;#39;t deliver the results I want.&lt;/p&gt;\n\n&lt;p&gt;I am currently using HTTraQt/HTTrack and its pretty good for other sites but when it comes to Reddit it doesn&amp;#39;t quite work (I am probably not configuring it correctly). It can&amp;#39;t get video files and when I open the HTMLs the page doesn&amp;#39;t load correctly (it shows contents but it quickly goes to a white background). I&amp;#39;m good with using it, but I&amp;#39;ll need a bit of help in order to configure it. However, if there are options out there that are better and &lt;strong&gt;potentially&lt;/strong&gt; find deleted posts with maybe their content [images/videos] (because I got plenty of those) I&amp;#39;ll also be very happy with that.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help. (Unsure of the flair a bit, mods are free to fix it if there&amp;#39;s something wrong.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a1ktz", "is_robot_indexable": true, "report_reasons": null, "author": "NoExplorer_Gr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a1ktz/need_tips_or_in_general_a_bit_of_help_trying_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a1ktz/need_tips_or_in_general_a_bit_of_help_trying_to/", "subreddit_subscribers": 665513, "created_utc": 1673535416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Like the title states, we're going to be moving (quite far) and I'm looking for recommendations for the best way to move the NAS and hard drives. I'm running a 920+ with 4 HDDs, can I bubblewrap the NAS, box it up and move with the drives installed or would it be advisable to remove the drives and individually bubblewrap and box them?\n\nFor what it matters, we're moving a long ways away, renting a uHaul pull behind trailer and will be traveling over bumpy / dirt roads for a not negligible portion of the drive. I'm leaning towards taking the hard drives out and individually wrapping them for transport.", "author_fullname": "t2_ckfoz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transport Synology / Drives during a move", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10a10ye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673533916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like the title states, we&amp;#39;re going to be moving (quite far) and I&amp;#39;m looking for recommendations for the best way to move the NAS and hard drives. I&amp;#39;m running a 920+ with 4 HDDs, can I bubblewrap the NAS, box it up and move with the drives installed or would it be advisable to remove the drives and individually bubblewrap and box them?&lt;/p&gt;\n\n&lt;p&gt;For what it matters, we&amp;#39;re moving a long ways away, renting a uHaul pull behind trailer and will be traveling over bumpy / dirt roads for a not negligible portion of the drive. I&amp;#39;m leaning towards taking the hard drives out and individually wrapping them for transport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10a10ye", "is_robot_indexable": true, "report_reasons": null, "author": "offthewallness", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10a10ye/how_to_transport_synology_drives_during_a_move/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10a10ye/how_to_transport_synology_drives_during_a_move/", "subreddit_subscribers": 665513, "created_utc": 1673533916.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\"Dear ASRockRack team,\n\nI have been looking for your X570D4I-2T server boards for quite some time and have not found any in stock anywhere. \n\nThis is quite unfortunate as this board is as far as I know the only mini ITX motherboard that supports 8x SATA on an AMD platform. \n\nHave you ended production on this model or is the unavailability due to the global chip shortage?\n\nAre you planning to offer a similar solution on AM5?\n\nI would be very grateful for a response,\n\nMichael H.\"\n\nWrote this email months ago and no reply yet. Do you think it's worth waiting for the X570D4I-2T to come back into stock or something happening on the AM5 side of things?\n\nI'm planning to build a Node 304 TrueNas Scale server with a tiny Gtx 1660 for transcoding and all 6 bays populated. \n\nAny help greatly appreciated!", "author_fullname": "t2_om20w2iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "X570D4I-2T", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109zyu8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673530998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Dear ASRockRack team,&lt;/p&gt;\n\n&lt;p&gt;I have been looking for your X570D4I-2T server boards for quite some time and have not found any in stock anywhere. &lt;/p&gt;\n\n&lt;p&gt;This is quite unfortunate as this board is as far as I know the only mini ITX motherboard that supports 8x SATA on an AMD platform. &lt;/p&gt;\n\n&lt;p&gt;Have you ended production on this model or is the unavailability due to the global chip shortage?&lt;/p&gt;\n\n&lt;p&gt;Are you planning to offer a similar solution on AM5?&lt;/p&gt;\n\n&lt;p&gt;I would be very grateful for a response,&lt;/p&gt;\n\n&lt;p&gt;Michael H.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Wrote this email months ago and no reply yet. Do you think it&amp;#39;s worth waiting for the X570D4I-2T to come back into stock or something happening on the AM5 side of things?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to build a Node 304 TrueNas Scale server with a tiny Gtx 1660 for transcoding and all 6 bays populated. &lt;/p&gt;\n\n&lt;p&gt;Any help greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109zyu8", "is_robot_indexable": true, "report_reasons": null, "author": "Stay_Curious_Bro", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109zyu8/x570d4i2t/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109zyu8/x570d4i2t/", "subreddit_subscribers": 665513, "created_utc": 1673530998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are some search engines out there that provide direct links to images (duck duck go, metager, brave that I know of) though they are still somewhat hidden (you have to click on the image to then see the direct link, and you have to scroll down to see more results) by java i guess it is? Anyway, its quite convenient to be able to specify what you want to see and then hover up the results :)\n\nAnyway know of a way to get past this?", "author_fullname": "t2_f5t3js0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scraping image search results?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109yn4c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673527007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are some search engines out there that provide direct links to images (duck duck go, metager, brave that I know of) though they are still somewhat hidden (you have to click on the image to then see the direct link, and you have to scroll down to see more results) by java i guess it is? Anyway, its quite convenient to be able to specify what you want to see and then hover up the results :)&lt;/p&gt;\n\n&lt;p&gt;Anyway know of a way to get past this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109yn4c", "is_robot_indexable": true, "report_reasons": null, "author": "AlfieMcLuvin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109yn4c/scraping_image_search_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109yn4c/scraping_image_search_results/", "subreddit_subscribers": 665513, "created_utc": 1673527007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I plan to install a small CEPH cluster at home with refurbished computer laying around, with little regard to bandwidth, but with regard to storage capacity.\n\nI looked at https://diskprices.com/?locale=us : good price, starting at 7USD/To and many options under 10USD/To. Then, I checked the french version (thid also apply to deutch and spain versions): Price starting at 15\u20ac/To. Knowing the change rate is 1\u20ac for 0.94USD (so buying in \u20ac will add... not too much) and the 20 percents of taxes, it still get far from the price of the 5th option of each, france being 90% costlier than the US one.\n\nI\u2019m looking for internal HDD as these are exempted from another \u201cremuneration\u201d for private copy (which is insanly costly in France \u2014 and so, it surprise me that the few first place are external HDD, with this tax adding for example 12\u20ac/To for USB HDD between 5 and 10 To).\n\nAlso, where could I find cheap HDD per storage in France, by extension.", "author_fullname": "t2_129y37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are HDD significantly costlier in France than in US.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109xoli", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673524277.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673523817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan to install a small CEPH cluster at home with refurbished computer laying around, with little regard to bandwidth, but with regard to storage capacity.&lt;/p&gt;\n\n&lt;p&gt;I looked at &lt;a href=\"https://diskprices.com/?locale=us\"&gt;https://diskprices.com/?locale=us&lt;/a&gt; : good price, starting at 7USD/To and many options under 10USD/To. Then, I checked the french version (thid also apply to deutch and spain versions): Price starting at 15\u20ac/To. Knowing the change rate is 1\u20ac for 0.94USD (so buying in \u20ac will add... not too much) and the 20 percents of taxes, it still get far from the price of the 5th option of each, france being 90% costlier than the US one.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for internal HDD as these are exempted from another \u201cremuneration\u201d for private copy (which is insanly costly in France \u2014 and so, it surprise me that the few first place are external HDD, with this tax adding for example 12\u20ac/To for USB HDD between 5 and 10 To).&lt;/p&gt;\n\n&lt;p&gt;Also, where could I find cheap HDD per storage in France, by extension.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109xoli", "is_robot_indexable": true, "report_reasons": null, "author": "marius851000", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109xoli/why_are_hdd_significantly_costlier_in_france_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109xoli/why_are_hdd_significantly_costlier_in_france_than/", "subreddit_subscribers": 665513, "created_utc": 1673523817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title says it all , been trying many github scripts but nothing works", "author_fullname": "t2_aj30rvtl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any way to download photo album from weibo ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109x642", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673521913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title says it all , been trying many github scripts but nothing works&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109x642", "is_robot_indexable": true, "report_reasons": null, "author": "Digital-Nuke", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109x642/any_way_to_download_photo_album_from_weibo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109x642/any_way_to_download_photo_album_from_weibo/", "subreddit_subscribers": 665513, "created_utc": 1673521913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I\u2019m currently trying to recover a fan- animated video of Jack Stauber\u2019s \u201cBaby Hotline\u201d that I last saw around July 2022. Within the past few months, YouTube took it down and I didn\u2019t notice until I went to revisit it. It was well animated and what ultimately led me to liking this song, but it\u2019s impossible to search for the creator or title of the video and have some way of preserving its existence. \n\nI was only able to find an untitled link digging through my Google watch history but internet archives and google/international search bars, the usual avenues, have brought nothing. \n\nthe URL: https://youtube.com/watch?v=RDdsbNwTW0k\n\nIf anyone knows another way of sourcing video titles/information from dead links, I\u2019d be grateful.", "author_fullname": "t2_11778y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to recover an animated music video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109w9qz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673518662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019m currently trying to recover a fan- animated video of Jack Stauber\u2019s \u201cBaby Hotline\u201d that I last saw around July 2022. Within the past few months, YouTube took it down and I didn\u2019t notice until I went to revisit it. It was well animated and what ultimately led me to liking this song, but it\u2019s impossible to search for the creator or title of the video and have some way of preserving its existence. &lt;/p&gt;\n\n&lt;p&gt;I was only able to find an untitled link digging through my Google watch history but internet archives and google/international search bars, the usual avenues, have brought nothing. &lt;/p&gt;\n\n&lt;p&gt;the URL: &lt;a href=\"https://youtube.com/watch?v=RDdsbNwTW0k\"&gt;https://youtube.com/watch?v=RDdsbNwTW0k&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If anyone knows another way of sourcing video titles/information from dead links, I\u2019d be grateful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109w9qz", "is_robot_indexable": true, "report_reasons": null, "author": "nyansensei888", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109w9qz/trying_to_recover_an_animated_music_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109w9qz/trying_to_recover_an_animated_music_video/", "subreddit_subscribers": 665513, "created_utc": 1673518662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My 2tb harddrive is at the moment being used as a backup time machine for my mac. The problem is: it is suddenly disconnecting. Is that an issue with failing harddrives, with the enclosure or something else? Tested on different machines, all of them macs (I don\u2019t have a windows machine at disposal) should I remove all my backup from that drive? I have everything there.", "author_fullname": "t2_3knbe326", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got a 2 TB HDD 7200RPM (the big ones). But it has an issue and im not sure what is the cause:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109w34j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673517992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My 2tb harddrive is at the moment being used as a backup time machine for my mac. The problem is: it is suddenly disconnecting. Is that an issue with failing harddrives, with the enclosure or something else? Tested on different machines, all of them macs (I don\u2019t have a windows machine at disposal) should I remove all my backup from that drive? I have everything there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109w34j", "is_robot_indexable": true, "report_reasons": null, "author": "Clipthecliph", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109w34j/got_a_2_tb_hdd_7200rpm_the_big_ones_but_it_has_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109w34j/got_a_2_tb_hdd_7200rpm_the_big_ones_but_it_has_an/", "subreddit_subscribers": 665513, "created_utc": 1673517992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to grab a VKontakte group's media hoard- specifically the photos. I'm not up to no good (much), it's just a public fanpage for a celeb but it goes back too many years to save everything individually. We're talking nearly 4500 pics, and I may want the video too, idk yet.\n\nI turn to the DH brains trust here to advise me- what is the best way to do this? Are there any dedicated bulk VK rippers? I have had a google and JDownloader is an option I've investigated, but it's not grabbing everything (I have a tech support Q pending on the JD sub, but I think im going to be S.O.O.L). I need *everything. E.v.e.r.y. t. h. i. n. g.*\n\nHelp a fangirl out, how do I do this?\n\nI can *maybe* deal with a program in Russian if I have to. I can't code, I'm looking for an off the shelf solution.\n\nETA- Internet Download Manager and DownAll from the sub wiki didn't get anywhere.", "author_fullname": "t2_5l13q7a9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to hoard a VK profile/group?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109voht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673521458.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673516482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to grab a VKontakte group&amp;#39;s media hoard- specifically the photos. I&amp;#39;m not up to no good (much), it&amp;#39;s just a public fanpage for a celeb but it goes back too many years to save everything individually. We&amp;#39;re talking nearly 4500 pics, and I may want the video too, idk yet.&lt;/p&gt;\n\n&lt;p&gt;I turn to the DH brains trust here to advise me- what is the best way to do this? Are there any dedicated bulk VK rippers? I have had a google and JDownloader is an option I&amp;#39;ve investigated, but it&amp;#39;s not grabbing everything (I have a tech support Q pending on the JD sub, but I think im going to be S.O.O.L). I need &lt;em&gt;everything. E.v.e.r.y. t. h. i. n. g.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Help a fangirl out, how do I do this?&lt;/p&gt;\n\n&lt;p&gt;I can &lt;em&gt;maybe&lt;/em&gt; deal with a program in Russian if I have to. I can&amp;#39;t code, I&amp;#39;m looking for an off the shelf solution.&lt;/p&gt;\n\n&lt;p&gt;ETA- Internet Download Manager and DownAll from the sub wiki didn&amp;#39;t get anywhere.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109voht", "is_robot_indexable": true, "report_reasons": null, "author": "nectarine_pie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109voht/best_way_to_hoard_a_vk_profilegroup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109voht/best_way_to_hoard_a_vk_profilegroup/", "subreddit_subscribers": 665513, "created_utc": 1673516482.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}