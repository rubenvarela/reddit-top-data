{"kind": "Listing", "data": {"after": "t3_109hp0r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, \n\nI'm currently looking for a good way to share data analytical reports to clients. But would want these dashboards to be interactive and hosted by us. So more like a micro service. \n\nAre there any good platforms for this specific use case? \n\nThanks for a great community!", "author_fullname": "t2_884psjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best platform to build dashboards for clients", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1090tf7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673430122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking for a good way to share data analytical reports to clients. But would want these dashboards to be interactive and hosted by us. So more like a micro service. &lt;/p&gt;\n\n&lt;p&gt;Are there any good platforms for this specific use case? &lt;/p&gt;\n\n&lt;p&gt;Thanks for a great community!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1090tf7", "is_robot_indexable": true, "report_reasons": null, "author": "jakekubb", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090tf7/best_platform_to_build_dashboards_for_clients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090tf7/best_platform_to_build_dashboards_for_clients/", "subreddit_subscribers": 836276, "created_utc": 1673430122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lots of organizations can benefit from ML but often struggle to find impactful projects. We wanted to share a simple but effective method for finding valuable applications that keep delivering value for our business: look for software rules that are already in production, but are suboptimal, and upgrade them with a ML solution.\n\nThis approach guarantees that you will work on something needed for the business as the rules are already in use. It will also guarantee that you will create value with ML as you are focusing on going from a working solution to optimized solution. Delivering a ML solution that creates value is a great way to prove that ML is relevant to your business and that further investments should be made into it. We believe ML still has lots of potential to improve businesses and consumer experiences across industries.\n\nWe wrote an article sharing a detailed example of this strategy that helped us to save thousands of orders from cancellation and make all sides of our marketplace happy. You can read about it [here](https://doordash.engineering/2023/01/10/how-doordash-upgraded-a-heuristic-with-ml-to-save-thousands-of-canceled-orders/). Please leave comments below if you find this useful.", "author_fullname": "t2_fm5qvxh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A useful pattern we found for getting business impact with ML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1098x1u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673454624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lots of organizations can benefit from ML but often struggle to find impactful projects. We wanted to share a simple but effective method for finding valuable applications that keep delivering value for our business: look for software rules that are already in production, but are suboptimal, and upgrade them with a ML solution.&lt;/p&gt;\n\n&lt;p&gt;This approach guarantees that you will work on something needed for the business as the rules are already in use. It will also guarantee that you will create value with ML as you are focusing on going from a working solution to optimized solution. Delivering a ML solution that creates value is a great way to prove that ML is relevant to your business and that further investments should be made into it. We believe ML still has lots of potential to improve businesses and consumer experiences across industries.&lt;/p&gt;\n\n&lt;p&gt;We wrote an article sharing a detailed example of this strategy that helped us to save thousands of orders from cancellation and make all sides of our marketplace happy. You can read about it &lt;a href=\"https://doordash.engineering/2023/01/10/how-doordash-upgraded-a-heuristic-with-ml-to-save-thousands-of-canceled-orders/\"&gt;here&lt;/a&gt;. Please leave comments below if you find this useful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1098x1u", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal-One8213", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1098x1u/a_useful_pattern_we_found_for_getting_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1098x1u/a_useful_pattern_we_found_for_getting_business/", "subreddit_subscribers": 836276, "created_utc": 1673454624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I maintain a numeric model with unit and integration \"spot tests\".  When I add a new feature that changes the model some of these tests will predictably fail.  I usually manually go through and update each affected test, ensure the \"failed\" value looks correct, and then use it for the new expected value.  Is there any more automated way to accomplish this, or other approaches to the problem?  Thanks!\n\nFor background I am using Python with Pytest.", "author_fullname": "t2_172zngvk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to update many unit tests when a numeric model changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109n88c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673489594.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673489276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I maintain a numeric model with unit and integration &amp;quot;spot tests&amp;quot;.  When I add a new feature that changes the model some of these tests will predictably fail.  I usually manually go through and update each affected test, ensure the &amp;quot;failed&amp;quot; value looks correct, and then use it for the new expected value.  Is there any more automated way to accomplish this, or other approaches to the problem?  Thanks!&lt;/p&gt;\n\n&lt;p&gt;For background I am using Python with Pytest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109n88c", "is_robot_indexable": true, "report_reasons": null, "author": "Bertie_Woo", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109n88c/how_to_update_many_unit_tests_when_a_numeric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109n88c/how_to_update_many_unit_tests_when_a_numeric/", "subreddit_subscribers": 836276, "created_utc": 1673489276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI am currently a political science major about to graduate and I don't really like it. I've been getting into data science/data analysis recently by doing some courses on Coursera and EDX, and I'm loving it. I've always been an analytical thinker, and I'm great at finding patterns and connections, and I have great logical thinking skills.\n\nI am yet to learn Python, SQL, R, etc. more in-depth, but I have learned over 17 languages. Even if it doesn't seem like programming languages and natural languages have anything in common, I'd like to differ, since both of them require learning a different code, structure, and usage, so I'm used to organizing my ideas using different patterns.\n\nI have heard many stories of people in similar situations who came from fields completely unrelated to data science that managed to thrive upon doing some courses on the internet and maybe getting some certificates elsewhere. I am afraid that it's too late for me to even attempt to join the field and I'd like to know if there's anyone with an unconventional trajectory through data science.\n\nI know this is something I enjoy, and I would like to put to use my analytical/mathematical/logical thinking skills which in political science would be useless. I don't know, however, if this is within my realm of possibilities.\n\nI know most of you are math or engineering graduates, so I'd like to know if many of you are not.", "author_fullname": "t2_7usea7do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you study at uni? (if anything at all)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109adcm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673458097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently a political science major about to graduate and I don&amp;#39;t really like it. I&amp;#39;ve been getting into data science/data analysis recently by doing some courses on Coursera and EDX, and I&amp;#39;m loving it. I&amp;#39;ve always been an analytical thinker, and I&amp;#39;m great at finding patterns and connections, and I have great logical thinking skills.&lt;/p&gt;\n\n&lt;p&gt;I am yet to learn Python, SQL, R, etc. more in-depth, but I have learned over 17 languages. Even if it doesn&amp;#39;t seem like programming languages and natural languages have anything in common, I&amp;#39;d like to differ, since both of them require learning a different code, structure, and usage, so I&amp;#39;m used to organizing my ideas using different patterns.&lt;/p&gt;\n\n&lt;p&gt;I have heard many stories of people in similar situations who came from fields completely unrelated to data science that managed to thrive upon doing some courses on the internet and maybe getting some certificates elsewhere. I am afraid that it&amp;#39;s too late for me to even attempt to join the field and I&amp;#39;d like to know if there&amp;#39;s anyone with an unconventional trajectory through data science.&lt;/p&gt;\n\n&lt;p&gt;I know this is something I enjoy, and I would like to put to use my analytical/mathematical/logical thinking skills which in political science would be useless. I don&amp;#39;t know, however, if this is within my realm of possibilities.&lt;/p&gt;\n\n&lt;p&gt;I know most of you are math or engineering graduates, so I&amp;#39;d like to know if many of you are not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109adcm", "is_robot_indexable": true, "report_reasons": null, "author": "frootloop2000", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109adcm/what_did_you_study_at_uni_if_anything_at_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109adcm/what_did_you_study_at_uni_if_anything_at_all/", "subreddit_subscribers": 836276, "created_utc": 1673458097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a PhD in Engineering and have very good knowledge of Python, SQL, and machine learning.\n\nCurrently, work as a data scientist in an insurance company (less than 1 year of job experience), but my plan is to get into Amazon or Meta as a data scientist as the next step. \n\nMy current data scientist position is mainly about data cleaning, building, and improving ML models using Python.\n\nI do not have that much experience in Cloud and Big Data frameworks such as Spark, and my current employer does not provide such possibilities either.\n\nMy plan is to learn cloud (AWS or GCP) and focus on Leet Code for this. I consider 12 months for improving my resume and boosting the required skills. Considering my knowledge in SQL, Python, and ML, do you think improving my knowledge/experience in Cloud and Leet Code is a good package for a job change to Amazon or Meta? Do you recommend any other skillset such as Spark, etc?\n\nThank you so much!", "author_fullname": "t2_h2udjs11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Skills required for DS position at Meta/AMAZON", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109hp8q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673475500.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673475277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a PhD in Engineering and have very good knowledge of Python, SQL, and machine learning.&lt;/p&gt;\n\n&lt;p&gt;Currently, work as a data scientist in an insurance company (less than 1 year of job experience), but my plan is to get into Amazon or Meta as a data scientist as the next step. &lt;/p&gt;\n\n&lt;p&gt;My current data scientist position is mainly about data cleaning, building, and improving ML models using Python.&lt;/p&gt;\n\n&lt;p&gt;I do not have that much experience in Cloud and Big Data frameworks such as Spark, and my current employer does not provide such possibilities either.&lt;/p&gt;\n\n&lt;p&gt;My plan is to learn cloud (AWS or GCP) and focus on Leet Code for this. I consider 12 months for improving my resume and boosting the required skills. Considering my knowledge in SQL, Python, and ML, do you think improving my knowledge/experience in Cloud and Leet Code is a good package for a job change to Amazon or Meta? Do you recommend any other skillset such as Spark, etc?&lt;/p&gt;\n\n&lt;p&gt;Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109hp8q", "is_robot_indexable": true, "report_reasons": null, "author": "Last-Revenue-660", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109hp8q/skills_required_for_ds_position_at_metaamazon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109hp8q/skills_required_for_ds_position_at_metaamazon/", "subreddit_subscribers": 836276, "created_utc": 1673475277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[The masters in question.](https://www.ntu.edu.sg/education/graduate-programme/master-of-science-in-analytics) \n\nI have a background in biology and a little organic chemistry (final semester in my bachelors) but realised I also appreciate math and programming during my internship and final year project. (I went through almost half of the chapters in linear algebra and its applications by David C. Lay, completing 80% of its associated problems and felt like it was as fun as playing Monster Hunter World or Guild Wars 2.)\n\nHowever, I am unable to find any placement statistics for the masters, is this considered a red flag?  Additionally, MH6211 Analytics Software I and MH6212 Analytics Software II cover SPS which according to some, is not really used in industry? I was also unable to find any reviews. I googled the degree on linkedin and found that some alumni who had the degree are still data analysts 4 years after the degree while others are data scientists. Are data analysts considered entry level positions compared to data scientists? Can someone point out anything that stands out in the curriculum?\n\nAm I better off with Georgia Tech\u2019s Online Master of Science in Analytics (OMS Analytics)? I do have some basic knowledge of linear algebra, programming with python and introductory classical physics and do prefer learning on my own. Then there is also the [masters in data science by the same university](https://www.ntu.edu.sg/education/graduate-programme/master-of-science-in-data-science-(msds)) but that seems to be too competitive for a non-CS major to get into. Or is the data science field too saturated right now for non-CS majors?\n\nThanks for reading this far and any advice or insight would be greatly appreciated!", "author_fullname": "t2_cnbql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some thoughts on NTU's master's in analytics program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1099er5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673455847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.ntu.edu.sg/education/graduate-programme/master-of-science-in-analytics\"&gt;The masters in question.&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I have a background in biology and a little organic chemistry (final semester in my bachelors) but realised I also appreciate math and programming during my internship and final year project. (I went through almost half of the chapters in linear algebra and its applications by David C. Lay, completing 80% of its associated problems and felt like it was as fun as playing Monster Hunter World or Guild Wars 2.)&lt;/p&gt;\n\n&lt;p&gt;However, I am unable to find any placement statistics for the masters, is this considered a red flag?  Additionally, MH6211 Analytics Software I and MH6212 Analytics Software II cover SPS which according to some, is not really used in industry? I was also unable to find any reviews. I googled the degree on linkedin and found that some alumni who had the degree are still data analysts 4 years after the degree while others are data scientists. Are data analysts considered entry level positions compared to data scientists? Can someone point out anything that stands out in the curriculum?&lt;/p&gt;\n\n&lt;p&gt;Am I better off with Georgia Tech\u2019s Online Master of Science in Analytics (OMS Analytics)? I do have some basic knowledge of linear algebra, programming with python and introductory classical physics and do prefer learning on my own. Then there is also the &lt;a href=\"https://www.ntu.edu.sg/education/graduate-programme/master-of-science-in-data-science-(msds\"&gt;masters in data science by the same university&lt;/a&gt;) but that seems to be too competitive for a non-CS major to get into. Or is the data science field too saturated right now for non-CS majors?&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading this far and any advice or insight would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H2HOY1ddpbU7MPDlXd8uo_tov-3KE8a0jdwScMP-ohs.jpg?auto=webp&amp;v=enabled&amp;s=caaaa88965fa30fea504732213d4552afb7ae478", "width": 775, "height": 465}, "resolutions": [{"url": "https://external-preview.redd.it/H2HOY1ddpbU7MPDlXd8uo_tov-3KE8a0jdwScMP-ohs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61c1eb84db31b551e84c05dcf517bb3ad9ec00bb", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/H2HOY1ddpbU7MPDlXd8uo_tov-3KE8a0jdwScMP-ohs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90cb9b48703cccebc712bccd508d038f3f9e0de6", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/H2HOY1ddpbU7MPDlXd8uo_tov-3KE8a0jdwScMP-ohs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=438d577db514b5bd9e1ae96c1458a62ade87b6a8", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/H2HOY1ddpbU7MPDlXd8uo_tov-3KE8a0jdwScMP-ohs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f396488f2ffdd1870aee237dcd10b8896333311", "width": 640, "height": 384}], "variants": {}, "id": "Lei49j-xSbvhd-Dmd_ZniNF_o5oF4aV0VAaS39JSH6M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1099er5", "is_robot_indexable": true, "report_reasons": null, "author": "TheBHSP", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1099er5/need_some_thoughts_on_ntus_masters_in_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1099er5/need_some_thoughts_on_ntus_masters_in_analytics/", "subreddit_subscribers": 836276, "created_utc": 1673455847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone.  Can you recommend what is the best SQL course on udemy for a beginner?\n\nThank you.", "author_fullname": "t2_d3p6qdhv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best SQL course on Udemy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1092zq9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673438366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone.  Can you recommend what is the best SQL course on udemy for a beginner?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1092zq9", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious-Ad-2519", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1092zq9/best_sql_course_on_udemy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1092zq9/best_sql_course_on_udemy/", "subreddit_subscribers": 836276, "created_utc": 1673438366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How do I write out my regression equation? Am using fixed effects model but I really don't know how to write out the equation", "author_fullname": "t2_5rqavi4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fixed effects model with interaction/moderating variables equation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1092lmb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673436944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I write out my regression equation? Am using fixed effects model but I really don&amp;#39;t know how to write out the equation&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1092lmb", "is_robot_indexable": true, "report_reasons": null, "author": "gottschegobble", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1092lmb/fixed_effects_model_with_interactionmoderating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1092lmb/fixed_effects_model_with_interactionmoderating/", "subreddit_subscribers": 836276, "created_utc": 1673436944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a graduating senior at a university in the US (US citizen). I have always been interested in studying abroad, but due to covid and the nature of my major I was unable to find opportunities. I am now looking for jobs abroad, but the process has been complicated and uneventful. I go to a school that qualifies me for the UK High Potential Individual visa, but every job I've applied to in the UK has rejected me. I've also looked at jobs in Switzerland and France, but their immigration laws are incredibly strict. My question follows: As an American, have you ever worked abroad as a data scientist in another country, and if so, when in your career and how?", "author_fullname": "t2_3im2k46f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you (as an American) ever worked in another country?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109akwy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673458586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a graduating senior at a university in the US (US citizen). I have always been interested in studying abroad, but due to covid and the nature of my major I was unable to find opportunities. I am now looking for jobs abroad, but the process has been complicated and uneventful. I go to a school that qualifies me for the UK High Potential Individual visa, but every job I&amp;#39;ve applied to in the UK has rejected me. I&amp;#39;ve also looked at jobs in Switzerland and France, but their immigration laws are incredibly strict. My question follows: As an American, have you ever worked abroad as a data scientist in another country, and if so, when in your career and how?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "109akwy", "is_robot_indexable": true, "report_reasons": null, "author": "bc_951", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109akwy/have_you_as_an_american_ever_worked_in_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109akwy/have_you_as_an_american_ever_worked_in_another/", "subreddit_subscribers": 836276, "created_utc": 1673458586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there, I found an exciting Scikit-Learn cheat sheet covering everything from basic steps to implementing machine learning algorithms successfully. This is great for beginners! You can download it from here - https://linktr.ee/codehub.ninja", "author_fullname": "t2_2buje7as", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have found a complete Scikit-Learn Cheat Sheet for Beginners.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10991pv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673454931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I found an exciting Scikit-Learn cheat sheet covering everything from basic steps to implementing machine learning algorithms successfully. This is great for beginners! You can download it from here - &lt;a href=\"https://linktr.ee/codehub.ninja\"&gt;https://linktr.ee/codehub.ninja&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3Jq8puCcZTWyqYf78ava6cep849k7FbQ9-d9ZkJZF9k.jpg?auto=webp&amp;v=enabled&amp;s=061a8c1f59d2990d00c2a50007165ec250440495", "width": 180, "height": 180}, "resolutions": [{"url": "https://external-preview.redd.it/3Jq8puCcZTWyqYf78ava6cep849k7FbQ9-d9ZkJZF9k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c05cb03193f912e439101bb660e915fd92b9486a", "width": 108, "height": 108}], "variants": {}, "id": "bJzW2lZfHWph5R43dHg2rX-ZhGurVLEqwaXR7qY02Nk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10991pv", "is_robot_indexable": true, "report_reasons": null, "author": "ParticularBack", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10991pv/i_have_found_a_complete_scikitlearn_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10991pv/i_have_found_a_complete_scikitlearn_cheat_sheet/", "subreddit_subscribers": 836276, "created_utc": 1673454931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on identifying customer behaviors that are correlated to with retention. For instance, I've read that in its early days, Netflix found that if a user rented out at least 3 DVDs, they were highly likely to continue with the service. Similarly with Uber, if a rider completed at least 2 rides, they were hooked. I'm trying to understand if there are any stats / ML techniques that can help me arrive at a similar answer for my company. We've taken an EDA approach, looking at the behavior of loyal customers in the first 30 days. But I'm hoping to understand if there are better ways to approach the problem", "author_fullname": "t2_7ff392o2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding indicators of customer stickiness for a subscription business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10915jg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673431453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on identifying customer behaviors that are correlated to with retention. For instance, I&amp;#39;ve read that in its early days, Netflix found that if a user rented out at least 3 DVDs, they were highly likely to continue with the service. Similarly with Uber, if a rider completed at least 2 rides, they were hooked. I&amp;#39;m trying to understand if there are any stats / ML techniques that can help me arrive at a similar answer for my company. We&amp;#39;ve taken an EDA approach, looking at the behavior of loyal customers in the first 30 days. But I&amp;#39;m hoping to understand if there are better ways to approach the problem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10915jg", "is_robot_indexable": true, "report_reasons": null, "author": "Powerful_Tiger1254", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10915jg/finding_indicators_of_customer_stickiness_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10915jg/finding_indicators_of_customer_stickiness_for_a/", "subreddit_subscribers": 836276, "created_utc": 1673431453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If i were to produce 2 models (e.g. logistic regression and xgboost) and would like to generate a confidence interval and p value to compare the auc of roc curve of both models, how should i go about doing it? \n\nA scientific article that i read mentioned that they've done it using a paired t-test.\nFor reference, this is the article im referring to https://www.sciencedirect.com/science/article/pii/S2667100X21000323", "author_fullname": "t2_qe43i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "statistical comparison of two roc curves", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1091504", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673431392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If i were to produce 2 models (e.g. logistic regression and xgboost) and would like to generate a confidence interval and p value to compare the auc of roc curve of both models, how should i go about doing it? &lt;/p&gt;\n\n&lt;p&gt;A scientific article that i read mentioned that they&amp;#39;ve done it using a paired t-test.\nFor reference, this is the article im referring to &lt;a href=\"https://www.sciencedirect.com/science/article/pii/S2667100X21000323\"&gt;https://www.sciencedirect.com/science/article/pii/S2667100X21000323&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1091504", "is_robot_indexable": true, "report_reasons": null, "author": "GoodboyBuddy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1091504/statistical_comparison_of_two_roc_curves/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1091504/statistical_comparison_of_two_roc_curves/", "subreddit_subscribers": 836276, "created_utc": 1673431392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi. I work as a junior data analyst and started my job recently. I have been asked to do a predictive model for a automobile insurance company.  This is the project :\n\nInsurance pricing policies at XYZ automobile company would like to be reviewed. In order to adjust current pricing policies, the company would like to have models for predicting both frequency and severity of claims. \n\nSolution expected :\n\nPredictive models that can be used for predicting future frequency and severity of claims.  \n\n\nI have past data with me. Can anyone help me how to approach this?", "author_fullname": "t2_t03wuws1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you approach this problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109rbom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673501067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I work as a junior data analyst and started my job recently. I have been asked to do a predictive model for a automobile insurance company.  This is the project :&lt;/p&gt;\n\n&lt;p&gt;Insurance pricing policies at XYZ automobile company would like to be reviewed. In order to adjust current pricing policies, the company would like to have models for predicting both frequency and severity of claims. &lt;/p&gt;\n\n&lt;p&gt;Solution expected :&lt;/p&gt;\n\n&lt;p&gt;Predictive models that can be used for predicting future frequency and severity of claims.  &lt;/p&gt;\n\n&lt;p&gt;I have past data with me. Can anyone help me how to approach this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109rbom", "is_robot_indexable": true, "report_reasons": null, "author": "decisiondengindi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109rbom/how_would_you_approach_this_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109rbom/how_would_you_approach_this_problem/", "subreddit_subscribers": 836276, "created_utc": 1673501067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What's the best approach to explain how ChatGPT **works** to high level executives who are not aware of machine learning? Do you talk about how it is essentially doing next word prediction etc? Do you talk about how it was trained? Are there any good resources I can refer to?", "author_fullname": "t2_218q3luo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to explain ChatGPT to laypeople / executives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109r7lq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673500711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the best approach to explain how ChatGPT &lt;strong&gt;works&lt;/strong&gt; to high level executives who are not aware of machine learning? Do you talk about how it is essentially doing next word prediction etc? Do you talk about how it was trained? Are there any good resources I can refer to?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109r7lq", "is_robot_indexable": true, "report_reasons": null, "author": "prawmlhandson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109r7lq/how_to_explain_chatgpt_to_laypeople_executives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109r7lq/how_to_explain_chatgpt_to_laypeople_executives/", "subreddit_subscribers": 836276, "created_utc": 1673500711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want it all, the eternal power of both worlds. I want great notebooks with latex, ml, data...\n\nBut nothing i tried gave me the complete feeling.\n\nVs code =&gt; Unfinished. Cannot export R to pdf, R is just a hassle to work with, no good variable explorer, kernel browser is just bad. Cannot see R variables, Too much options and so little documentation.\n\nJupyter =&gt; No documented code completion.\n\nRstudio =&gt; No documented code completion for python.\n\nJetbrains... F jetbucks.\n\nWhat do i do?", "author_fullname": "t2_4qvdgg7g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Im trying to have both R &amp; Python in one editor for notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109hv6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673476446.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673475661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want it all, the eternal power of both worlds. I want great notebooks with latex, ml, data...&lt;/p&gt;\n\n&lt;p&gt;But nothing i tried gave me the complete feeling.&lt;/p&gt;\n\n&lt;p&gt;Vs code =&amp;gt; Unfinished. Cannot export R to pdf, R is just a hassle to work with, no good variable explorer, kernel browser is just bad. Cannot see R variables, Too much options and so little documentation.&lt;/p&gt;\n\n&lt;p&gt;Jupyter =&amp;gt; No documented code completion.&lt;/p&gt;\n\n&lt;p&gt;Rstudio =&amp;gt; No documented code completion for python.&lt;/p&gt;\n\n&lt;p&gt;Jetbrains... F jetbucks.&lt;/p&gt;\n\n&lt;p&gt;What do i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109hv6c", "is_robot_indexable": true, "report_reasons": null, "author": "Rootsyl", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109hv6c/im_trying_to_have_both_r_python_in_one_editor_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109hv6c/im_trying_to_have_both_r_python_in_one_editor_for/", "subreddit_subscribers": 836276, "created_utc": 1673475661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all! Are you a data enthusiast looking for opportunities to highlight your work and win cash prizes? Interested in researching how access to green space impacts public health? If the answer is yes, then the Green Space Data Challenge hosted by the Massive Data Institute at Georgetown\u2019s McCourt School of Public Policy is for you! \n\nUndergraduate students, graduate students, and early-career professionals are invited to participate in the data challenge during the entire month of February 2023 to create or improve indicators involving green space to better understand and measure community impact. \n\nParticipants will access various data sources on our Redivis platform in individual or team notebooks to transform green space data into community indicators. They will conduct their analyses and submit a short project narrative that describes the research question, analytic approach, and key findings. All submissions will be evaluated by judges based on the relevance, completeness, and quality of the submission. \n\nThere will be separate prize categories for submissions examining the effects of green space on the following subject areas: community health, community safety, specific populations, and physical environment. Winners can receive $5,000 for first place prizes, $2,000 for second place prizes, and $1,000 for third place prizes. Winners will also be invited to present their project at a webinar hosted by the Association of Public Data Users (APDU) and at APDU\u2019s annual conference in July 2023. \n\n[**Click here to learn more about the data challenge and to register.**](https://mdi.georgetown.edu/pbi/greenspace/)\n\nPlease help us spread the word and invite anyone eligible in your networks!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rn0wdqrxagba1.png?width=1600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9fb427c8637d463775a890b650350944b8b25c65", "author_fullname": "t2_vi8w67ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Green Space Data Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rn0wdqrxagba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff7104992aee187a7dafe7ba1e171e63b6849c52"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5384406bfa4f7de4a4649189f1cc7c2d580a33d2"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=477a38731b64a3f2ffd98a057f27e8691d4f081c"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37329f855bde1499e14295074b612a3753000f7f"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa66a7671eb8da709f98d693ad45abd57d64623e"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f4a001281fbcafa624c41f94540534904c01e93"}], "s": {"y": 900, "x": 1600, "u": "https://preview.redd.it/rn0wdqrxagba1.png?width=1600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9fb427c8637d463775a890b650350944b8b25c65"}, "id": "rn0wdqrxagba1"}}, "name": "t3_109asiq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7xVk10fDnvzwtPQ4UpraSRHFywOPm68Txuo_92T9Ubg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673459084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! Are you a data enthusiast looking for opportunities to highlight your work and win cash prizes? Interested in researching how access to green space impacts public health? If the answer is yes, then the Green Space Data Challenge hosted by the Massive Data Institute at Georgetown\u2019s McCourt School of Public Policy is for you! &lt;/p&gt;\n\n&lt;p&gt;Undergraduate students, graduate students, and early-career professionals are invited to participate in the data challenge during the entire month of February 2023 to create or improve indicators involving green space to better understand and measure community impact. &lt;/p&gt;\n\n&lt;p&gt;Participants will access various data sources on our Redivis platform in individual or team notebooks to transform green space data into community indicators. They will conduct their analyses and submit a short project narrative that describes the research question, analytic approach, and key findings. All submissions will be evaluated by judges based on the relevance, completeness, and quality of the submission. &lt;/p&gt;\n\n&lt;p&gt;There will be separate prize categories for submissions examining the effects of green space on the following subject areas: community health, community safety, specific populations, and physical environment. Winners can receive $5,000 for first place prizes, $2,000 for second place prizes, and $1,000 for third place prizes. Winners will also be invited to present their project at a webinar hosted by the Association of Public Data Users (APDU) and at APDU\u2019s annual conference in July 2023. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://mdi.georgetown.edu/pbi/greenspace/\"&gt;&lt;strong&gt;Click here to learn more about the data challenge and to register.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Please help us spread the word and invite anyone eligible in your networks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rn0wdqrxagba1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9fb427c8637d463775a890b650350944b8b25c65\"&gt;https://preview.redd.it/rn0wdqrxagba1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9fb427c8637d463775a890b650350944b8b25c65&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109asiq", "is_robot_indexable": true, "report_reasons": null, "author": "georgetownpbi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109asiq/green_space_data_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109asiq/green_space_data_challenge/", "subreddit_subscribers": 836276, "created_utc": 1673459084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\nI am a junior data scientist, I worked on only one Data Science project. My objective is to learn the theoretical concepts and at the same time acquire programming knowledge. Can you suggest me some Kaggle competitions or datasets to start with. I want challenging ones to learn the subject the hard way.", "author_fullname": "t2_dwijd9yj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kaggle datasets to suggest ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109aers", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673458195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,\nI am a junior data scientist, I worked on only one Data Science project. My objective is to learn the theoretical concepts and at the same time acquire programming knowledge. Can you suggest me some Kaggle competitions or datasets to start with. I want challenging ones to learn the subject the hard way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109aers", "is_robot_indexable": true, "report_reasons": null, "author": "No_Cardiologist_3158", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109aers/kaggle_datasets_to_suggest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109aers/kaggle_datasets_to_suggest/", "subreddit_subscribers": 836276, "created_utc": 1673458195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello everybody,My major is electronic engineer. i just wondered big4 work culture so i got a job from big4 as a data analyst. It focuses on SQL and Excel  however now i am feeling bored during big4 time.I try get a data scientist job from finance company or others, took some course like introduction to computing and data science from uni and also i am learning from datacamp and doing project on kaggle. Can Certificatioans and kaggle projects persuade company ? If not, what is your suggestion ?", "author_fullname": "t2_l30zjdkp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "from big4 to data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1092jin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673436726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello everybody,My major is electronic engineer. i just wondered big4 work culture so i got a job from big4 as a data analyst. It focuses on SQL and Excel  however now i am feeling bored during big4 time.I try get a data scientist job from finance company or others, took some course like introduction to computing and data science from uni and also i am learning from datacamp and doing project on kaggle. Can Certificatioans and kaggle projects persuade company ? If not, what is your suggestion ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1092jin", "is_robot_indexable": true, "report_reasons": null, "author": "mayyam13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1092jin/from_big4_to_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1092jin/from_big4_to_data_scientist/", "subreddit_subscribers": 836276, "created_utc": 1673436726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hoping it is allowed to ask some questions here about analysis help\n\nI have panel data analysis, i have run a fixed effects model but want to do a robustness check however what I'm finding is that there aren't really any for fixed effects models as they already incorporate it in the main analysis? Can I just run a reverse regression as a sort of robustness check? In such case, if the outcome is significant does that mean there is reverse causality?\n\nI have to do some sort of robustness check for my thesis requirements", "author_fullname": "t2_5rqavi4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "panel data robustness check?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1090dhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673428308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping it is allowed to ask some questions here about analysis help&lt;/p&gt;\n\n&lt;p&gt;I have panel data analysis, i have run a fixed effects model but want to do a robustness check however what I&amp;#39;m finding is that there aren&amp;#39;t really any for fixed effects models as they already incorporate it in the main analysis? Can I just run a reverse regression as a sort of robustness check? In such case, if the outcome is significant does that mean there is reverse causality?&lt;/p&gt;\n\n&lt;p&gt;I have to do some sort of robustness check for my thesis requirements&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1090dhv", "is_robot_indexable": true, "report_reasons": null, "author": "gottschegobble", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1090dhv/panel_data_robustness_check/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1090dhv/panel_data_robustness_check/", "subreddit_subscribers": 836276, "created_utc": 1673428308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_25rf9hfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anybody give me feedback on my CV, what are the things I can improve? I am a fresher and am not getting shortlisted in any interviews. Should I do an internship first? Thanks in advance!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_109ra93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/omm3Up39i023mCJzjPthj4yH7LgfVCYyND9pUtOiiS0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673500943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/9jsklcncrjba1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/9jsklcncrjba1.png?auto=webp&amp;v=enabled&amp;s=4a945312d748159f3bd96a231a2111230fd59fc2", "width": 1262, "height": 1636}, "resolutions": [{"url": "https://preview.redd.it/9jsklcncrjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d386cdd49fbf78574c77b3bd539ee5209b3fef7f", "width": 108, "height": 140}, {"url": "https://preview.redd.it/9jsklcncrjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2479947063cb51b79b56de12e1162fe2c76e7008", "width": 216, "height": 280}, {"url": "https://preview.redd.it/9jsklcncrjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f7c8ace295d8efbe9605f0d8f0119cbb38d138f", "width": 320, "height": 414}, {"url": "https://preview.redd.it/9jsklcncrjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6d637f6195966db384516e95e47f34c6d0294f7", "width": 640, "height": 829}, {"url": "https://preview.redd.it/9jsklcncrjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24bd949760151c8a13c23bd50418474fc0731d11", "width": 960, "height": 1244}, {"url": "https://preview.redd.it/9jsklcncrjba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8145411036cd0a4dc81eafa8e4de057e122cf56e", "width": 1080, "height": 1400}], "variants": {}, "id": "1x-KSApb2HJbcRv1aW3qXsnERfRiY95jnAwV9Fh9968"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "109ra93", "is_robot_indexable": true, "report_reasons": null, "author": "Ritobroto", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109ra93/can_anybody_give_me_feedback_on_my_cv_what_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/9jsklcncrjba1.png", "subreddit_subscribers": 836276, "created_utc": 1673500943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5htuz1x1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hii i have a file which contains videos images and probably Android apps. it's a single file of 4GB and has a .main format it's meant to be used with an Android app how do I view data inside it ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109r3y2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673500390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109r3y2", "is_robot_indexable": true, "report_reasons": null, "author": "tanay2043", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109r3y2/hii_i_have_a_file_which_contains_videos_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109r3y2/hii_i_have_a_file_which_contains_videos_images/", "subreddit_subscribers": 836276, "created_utc": 1673500390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I want to predict a force plate using plantar pressure. The shape of the force plate data is a 15000x6 array, and the shape of the plantar pressure data is a 15000x89 array. I will use a regression model to predict the force plate data. When collecting data to synchronize the force plate data and plantar pressure, I will do time synchronization between the force plate and plantar pressure app. force plate and plantar pressure data will capture 50 data in 1 second. \n\n Force Plate Data: \n\n Data shape : (15000,6) \n\nhttps://preview.redd.it/y9ql48ijfjba1.png?width=525&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8b553ab76ab8e750e5b5e1106a1b969c0c3d2c25\n\n&amp;#x200B;\n\nhttps://preview.redd.it/w9t3dmvkfjba1.png?width=418&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2bcb75881b3a9c9719c6918e38f2987c9abea966\n\n Plantar Pressure Data : \n\n Data shape : (15000,89) \n\n \n\n    array([[0.0, 0.0, 91.0, 100.0, 74.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 123.0, 126.0, 3.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.0, 104.0, 75.0, 33.0, 0.0, 0.0, 0.0, 0.0, 57.0, 117.0, 123.0, 113.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 67.0, 46.0, 16.0, 0.0, 8.0, 0.0, 15.0, 51.0, 122.0, 122.0, 111.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0], \n    [0.0, 0.0, 91.0, 100.0, 74.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 123.0, 126.0, 3.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.0, 104.0, 75.0, 33.0, 0.0, 0.0, 0.0, 0.0, 57.0, 117.0, 123.0, 113.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 62.0, 68.0, 46.0, 12.0, 0.0, 3.0, 0.0, 15.0, 53.0, 124.0, 125.0, 115.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0], \n    [0.0, 0.0, 91.0, 100.0, 68.0, 6.0, 0.0, 0.0, 0.0, 0.0, 29.0, 118.0, 120.0, 2.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 100.0, 72.0, 32.0, 0.0, 0.0, 0.0, 0.0, 51.0, 113.0, 118.0, 109.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 67.0, 46.0, 16.0, 0.0, 8.0, 0.0, 15.0, 51.0, 122.0, 122.0, 111.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0]])\n\n Method 1: \n\nInput Data : (15000,89) \n\nOutput Data : (15000,6) \n\n&amp;#x200B;\n\nhttps://preview.redd.it/ixdl7jfsfjba1.png?width=829&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce5bccd25493c9ae423d64263688b0a7e27de457\n\nhttps://preview.redd.it/uk9ofjetfjba1.png?width=1638&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3fd5cf29b5fabd4b9af9673b22dc56107bd28420\n\n&amp;#x200B;\n\nhttps://preview.redd.it/hxjzo2cufjba1.png?width=1638&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8aa108c55f6d2446c9021236f6f156b540e7a914\n\n I will get good results on training, but when I try using new data to predict it the results will be bad. then I thought maybe because the plantar pressure data are so similar, it would be hard for the model to recognize it. then I tried to add data sequences to each plantar pressure data. the data sequences that I added are 1-50, the reason I added these data sequences is so that the data on plantar pressure are slightly different from one another so that the model is easier to recognize when I test using new data and I enter 1-50 because every second plantar pressure will capture 50 data. after I added the data sequence to the plantar pressure, the shape of the plantar pressure data is (15000,90) \n\n Plantar Pressure data after adding data sequence: the shape of plantar pressure data before adding data sequence is (15000,89), the shape of plantar pressure data after adding data sequence is (15000,90) \n\nhttps://preview.redd.it/v3kg3h3xfjba1.png?width=1060&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ea1a77d3f8509138b9d17c368963e28d1310a28b\n\n Method 2: \n\nInput Data : (15000,90) \n\nOutput Data : (15000,6) \n\nhttps://preview.redd.it/9wp1ioazfjba1.png?width=829&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cae4ad561e4fa77dcb772be3502a67eb040752c3\n\nhttps://preview.redd.it/s7i9erzzfjba1.png?width=1632&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cb6a85df6bbc4c893fff2e2b04bbbd0d2c09cc3e\n\nhttps://preview.redd.it/oofh8gg0gjba1.png?width=1632&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=89c9eec256e8c7d577ec9f00f3e4ecfd91ad1904\n\n so after I added the sequence data to the plantar pressure data, the prediction results from the training data and testing data will be good. my question is whether this method is allowed in data science? If yes, what method I use is called and is there a reference that is the same as the method I used in existing research", "author_fullname": "t2_end0qlqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding Data sequences as unique data on dataset for regression model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uk9ofjetfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5437739b475963a5a9f6195ad5f4858a294c756"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59acc5363ccf0a2b6c853b174b95c04e9a6e957c"}, {"y": 139, "x": 320, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aedce6935dfe7ebae88c4cf85881421911367ab3"}, {"y": 278, "x": 640, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f69f36228ea203026217e45d0ef6116466057254"}, {"y": 418, "x": 960, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08d17bbcbf3b1d6ea42f95c34ed10c402ae62bf6"}, {"y": 470, "x": 1080, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=070600d7a05db4e89ad8b6c42304e1b37bf3b236"}], "s": {"y": 714, "x": 1638, "u": "https://preview.redd.it/uk9ofjetfjba1.png?width=1638&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3fd5cf29b5fabd4b9af9673b22dc56107bd28420"}, "id": "uk9ofjetfjba1"}, "9wp1ioazfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/9wp1ioazfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f98b7193abad8309d06286f3f23b17ed2cd9a2eb"}, {"y": 151, "x": 216, "u": "https://preview.redd.it/9wp1ioazfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af2d7ad6c97168e834b23f1f83873a0dc4421963"}, {"y": 223, "x": 320, "u": "https://preview.redd.it/9wp1ioazfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f0aae23c07021179cc1420f65c2e92364a2020d"}, {"y": 447, "x": 640, "u": "https://preview.redd.it/9wp1ioazfjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f00a5ea38ceee17a37a9166d65be16e945590e2"}], "s": {"y": 580, "x": 829, "u": "https://preview.redd.it/9wp1ioazfjba1.png?width=829&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cae4ad561e4fa77dcb772be3502a67eb040752c3"}, "id": "9wp1ioazfjba1"}, "s7i9erzzfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2221ea7e415680ea01b12bcc384108a1c1bf8486"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3889641995ee00f85dc7ae75e4d9c77115c5bd96"}, {"y": 140, "x": 320, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8dbfb07965a5aa25f3b53bc77bb58334e26f00af"}, {"y": 280, "x": 640, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e56c952755c04954d8f12d2e22c2cfff03d9c0e3"}, {"y": 420, "x": 960, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46006ea6b759f65446c884c89c1dcb11d0de87fb"}, {"y": 472, "x": 1080, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fef61624cb8b3053df053fdf438c99e2a788956"}], "s": {"y": 714, "x": 1632, "u": "https://preview.redd.it/s7i9erzzfjba1.png?width=1632&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cb6a85df6bbc4c893fff2e2b04bbbd0d2c09cc3e"}, "id": "s7i9erzzfjba1"}, "ixdl7jfsfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/ixdl7jfsfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=383e993d42856a48839c77616026afcc62cdb268"}, {"y": 151, "x": 216, "u": "https://preview.redd.it/ixdl7jfsfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488b5e63286b16749750237af30ddac958e01747"}, {"y": 223, "x": 320, "u": "https://preview.redd.it/ixdl7jfsfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6dcc2db8fab04d162e4f7b739d98f4d33ad625a1"}, {"y": 447, "x": 640, "u": "https://preview.redd.it/ixdl7jfsfjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a4d92dc8333fffe1b9be699eba07143d34ea4be"}], "s": {"y": 580, "x": 829, "u": "https://preview.redd.it/ixdl7jfsfjba1.png?width=829&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce5bccd25493c9ae423d64263688b0a7e27de457"}, "id": "ixdl7jfsfjba1"}, "y9ql48ijfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/y9ql48ijfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd11ccd7f7b08c6d1cd09c32d3afed55996f9177"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/y9ql48ijfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bef9a1f88b06013b82062a3ceff7e724144b8fe"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/y9ql48ijfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eca434b59b30236ab127c6e11dbdfc906e80a1bb"}], "s": {"y": 322, "x": 525, "u": "https://preview.redd.it/y9ql48ijfjba1.png?width=525&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8b553ab76ab8e750e5b5e1106a1b969c0c3d2c25"}, "id": "y9ql48ijfjba1"}, "hxjzo2cufjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd9cbbae89b169c354a714f2bd3a50aa389bad97"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad5362f1d88f504745b1114d92a0638c5bf0add2"}, {"y": 139, "x": 320, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d385d8e6ae8d0b2203c6b0df2d52727326d64de"}, {"y": 278, "x": 640, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d4a1b3822416f9a43e4729eadce3709473dac77"}, {"y": 418, "x": 960, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36a4aadb5f813c1c440cdda91ffc32d07d6b9185"}, {"y": 470, "x": 1080, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=964cf2b4be6a2fc5f89a62b4cd380be539d8e2b1"}], "s": {"y": 714, "x": 1638, "u": "https://preview.redd.it/hxjzo2cufjba1.png?width=1638&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8aa108c55f6d2446c9021236f6f156b540e7a914"}, "id": "hxjzo2cufjba1"}, "w9t3dmvkfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/w9t3dmvkfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f722acd865ec29b3c6a6ff7bd4ea8bd901c17ce"}, {"y": 175, "x": 216, "u": "https://preview.redd.it/w9t3dmvkfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eaa46adece19735e43d9943f8645e574791bd75d"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/w9t3dmvkfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28143dc4c17ab39ed309bddd64bcf83ed14294c8"}], "s": {"y": 340, "x": 418, "u": "https://preview.redd.it/w9t3dmvkfjba1.png?width=418&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2bcb75881b3a9c9719c6918e38f2987c9abea966"}, "id": "w9t3dmvkfjba1"}, "v3kg3h3xfjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 29, "x": 108, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37fda3f21e43fb3bc32070e8e2f0d30d77584485"}, {"y": 58, "x": 216, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1644212683a9dfce1efa9314d486bd70232b0914"}, {"y": 86, "x": 320, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e19d6148083ef1e9801d9d97c88f87c1d2d1e5e"}, {"y": 172, "x": 640, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f67a719f355c48944e093456bacbaa865c5e15e"}, {"y": 258, "x": 960, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46a8ca89ef0bebaee58d1c85af71c4b84ea2f56b"}], "s": {"y": 285, "x": 1060, "u": "https://preview.redd.it/v3kg3h3xfjba1.png?width=1060&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ea1a77d3f8509138b9d17c368963e28d1310a28b"}, "id": "v3kg3h3xfjba1"}, "oofh8gg0gjba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1287933e3022d96a75b8525c443bfe4c7c3f21c4"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17264be14523f039eca041f58d9d6cdf9b2d8555"}, {"y": 140, "x": 320, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a4a0992394be6a09976834f07ebc2d9619fffcc6"}, {"y": 280, "x": 640, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77640857ed93a43643569cb9c4018e7c30a9441f"}, {"y": 420, "x": 960, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=119bbf2b1839ecb6a0251b95427b63c62d7b6926"}, {"y": 472, "x": 1080, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fe7e8b05ad82c3bf7d2ae3604e85479534566a3"}], "s": {"y": 714, "x": 1632, "u": "https://preview.redd.it/oofh8gg0gjba1.png?width=1632&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=89c9eec256e8c7d577ec9f00f3e4ecfd91ad1904"}, "id": "oofh8gg0gjba1"}}, "name": "t3_109pzie", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s8FQzbwalBWYlLGJrCiyUxOnKlwTeHA-dc8hwFNpXBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673496990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to predict a force plate using plantar pressure. The shape of the force plate data is a 15000x6 array, and the shape of the plantar pressure data is a 15000x89 array. I will use a regression model to predict the force plate data. When collecting data to synchronize the force plate data and plantar pressure, I will do time synchronization between the force plate and plantar pressure app. force plate and plantar pressure data will capture 50 data in 1 second. &lt;/p&gt;\n\n&lt;p&gt;Force Plate Data: &lt;/p&gt;\n\n&lt;p&gt;Data shape : (15000,6) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/y9ql48ijfjba1.png?width=525&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8b553ab76ab8e750e5b5e1106a1b969c0c3d2c25\"&gt;https://preview.redd.it/y9ql48ijfjba1.png?width=525&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8b553ab76ab8e750e5b5e1106a1b969c0c3d2c25&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w9t3dmvkfjba1.png?width=418&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2bcb75881b3a9c9719c6918e38f2987c9abea966\"&gt;https://preview.redd.it/w9t3dmvkfjba1.png?width=418&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2bcb75881b3a9c9719c6918e38f2987c9abea966&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Plantar Pressure Data : &lt;/p&gt;\n\n&lt;p&gt;Data shape : (15000,89) &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;array([[0.0, 0.0, 91.0, 100.0, 74.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 123.0, 126.0, 3.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.0, 104.0, 75.0, 33.0, 0.0, 0.0, 0.0, 0.0, 57.0, 117.0, 123.0, 113.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 67.0, 46.0, 16.0, 0.0, 8.0, 0.0, 15.0, 51.0, 122.0, 122.0, 111.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0], \n[0.0, 0.0, 91.0, 100.0, 74.0, 7.0, 0.0, 0.0, 0.0, 0.0, 45.0, 123.0, 126.0, 3.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 95.0, 104.0, 75.0, 33.0, 0.0, 0.0, 0.0, 0.0, 57.0, 117.0, 123.0, 113.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 62.0, 68.0, 46.0, 12.0, 0.0, 3.0, 0.0, 15.0, 53.0, 124.0, 125.0, 115.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0], \n[0.0, 0.0, 91.0, 100.0, 68.0, 6.0, 0.0, 0.0, 0.0, 0.0, 29.0, 118.0, 120.0, 2.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 89.0, 100.0, 72.0, 32.0, 0.0, 0.0, 0.0, 0.0, 51.0, 113.0, 118.0, 109.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 67.0, 46.0, 16.0, 0.0, 8.0, 0.0, 15.0, 51.0, 122.0, 122.0, 111.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 25.0, 31.0, 64.0, 82.0, 125.0, 124.0, 114.0, 18.0, 0.0, 0.0, 0.0, 24.0, 56.0, 105.0, 116.0, 124.0, 77.0, 0.0, 0.0, 0.0, 71.0, 61.0, 0.0, 0.0, 3.0, 0.0]])\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Method 1: &lt;/p&gt;\n\n&lt;p&gt;Input Data : (15000,89) &lt;/p&gt;\n\n&lt;p&gt;Output Data : (15000,6) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ixdl7jfsfjba1.png?width=829&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ce5bccd25493c9ae423d64263688b0a7e27de457\"&gt;https://preview.redd.it/ixdl7jfsfjba1.png?width=829&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ce5bccd25493c9ae423d64263688b0a7e27de457&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uk9ofjetfjba1.png?width=1638&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3fd5cf29b5fabd4b9af9673b22dc56107bd28420\"&gt;https://preview.redd.it/uk9ofjetfjba1.png?width=1638&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3fd5cf29b5fabd4b9af9673b22dc56107bd28420&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hxjzo2cufjba1.png?width=1638&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8aa108c55f6d2446c9021236f6f156b540e7a914\"&gt;https://preview.redd.it/hxjzo2cufjba1.png?width=1638&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8aa108c55f6d2446c9021236f6f156b540e7a914&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I will get good results on training, but when I try using new data to predict it the results will be bad. then I thought maybe because the plantar pressure data are so similar, it would be hard for the model to recognize it. then I tried to add data sequences to each plantar pressure data. the data sequences that I added are 1-50, the reason I added these data sequences is so that the data on plantar pressure are slightly different from one another so that the model is easier to recognize when I test using new data and I enter 1-50 because every second plantar pressure will capture 50 data. after I added the data sequence to the plantar pressure, the shape of the plantar pressure data is (15000,90) &lt;/p&gt;\n\n&lt;p&gt;Plantar Pressure data after adding data sequence: the shape of plantar pressure data before adding data sequence is (15000,89), the shape of plantar pressure data after adding data sequence is (15000,90) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v3kg3h3xfjba1.png?width=1060&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ea1a77d3f8509138b9d17c368963e28d1310a28b\"&gt;https://preview.redd.it/v3kg3h3xfjba1.png?width=1060&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ea1a77d3f8509138b9d17c368963e28d1310a28b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Method 2: &lt;/p&gt;\n\n&lt;p&gt;Input Data : (15000,90) &lt;/p&gt;\n\n&lt;p&gt;Output Data : (15000,6) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9wp1ioazfjba1.png?width=829&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cae4ad561e4fa77dcb772be3502a67eb040752c3\"&gt;https://preview.redd.it/9wp1ioazfjba1.png?width=829&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cae4ad561e4fa77dcb772be3502a67eb040752c3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s7i9erzzfjba1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cb6a85df6bbc4c893fff2e2b04bbbd0d2c09cc3e\"&gt;https://preview.redd.it/s7i9erzzfjba1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cb6a85df6bbc4c893fff2e2b04bbbd0d2c09cc3e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oofh8gg0gjba1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=89c9eec256e8c7d577ec9f00f3e4ecfd91ad1904\"&gt;https://preview.redd.it/oofh8gg0gjba1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=89c9eec256e8c7d577ec9f00f3e4ecfd91ad1904&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;so after I added the sequence data to the plantar pressure data, the prediction results from the training data and testing data will be good. my question is whether this method is allowed in data science? If yes, what method I use is called and is there a reference that is the same as the method I used in existing research&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109pzie", "is_robot_indexable": true, "report_reasons": null, "author": "Constant-Cranberry29", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109pzie/adding_data_sequences_as_unique_data_on_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109pzie/adding_data_sequences_as_unique_data_on_dataset/", "subreddit_subscribers": 836276, "created_utc": 1673496990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_mmzrq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your recent impact in your organization as a DS? What problem did you solve?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109o36f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673491581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109o36f", "is_robot_indexable": true, "report_reasons": null, "author": "ndemir", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109o36f/whats_your_recent_impact_in_your_organization_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109o36f/whats_your_recent_impact_in_your_organization_as/", "subreddit_subscribers": 836276, "created_utc": 1673491581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_74f3kq8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "lots of tutorials on sentiment analysis but seems like no one goes from analysis to insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109lfsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673484536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109lfsq", "is_robot_indexable": true, "report_reasons": null, "author": "Character-Education3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109lfsq/lots_of_tutorials_on_sentiment_analysis_but_seems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109lfsq/lots_of_tutorials_on_sentiment_analysis_but_seems/", "subreddit_subscribers": 836276, "created_utc": 1673484536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, so at my work the sales team uses a WhatsApp group chat to communicate. The format is something like: order number, client name, picture of design selected and info about design (quantity for example), then the other product, followed by a dash line to indicate the order is over and then repeat same format for new order. \n\nNow we have one guy who\u2019s only task is to copy paste that data into word and print is as purchase order. I want to automate this process by directly somehow having people input the data into WhatsApp and it getting converted and pasted to word, so then end of the day all I have to do is to print all. \n\nAny help is much appreciated.", "author_fullname": "t2_4pu77q4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help to automate a WhatsApp group chat data to word", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109hp0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673475262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, so at my work the sales team uses a WhatsApp group chat to communicate. The format is something like: order number, client name, picture of design selected and info about design (quantity for example), then the other product, followed by a dash line to indicate the order is over and then repeat same format for new order. &lt;/p&gt;\n\n&lt;p&gt;Now we have one guy who\u2019s only task is to copy paste that data into word and print is as purchase order. I want to automate this process by directly somehow having people input the data into WhatsApp and it getting converted and pasted to word, so then end of the day all I have to do is to print all. &lt;/p&gt;\n\n&lt;p&gt;Any help is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "109hp0r", "is_robot_indexable": true, "report_reasons": null, "author": "blazingdodo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/109hp0r/need_help_to_automate_a_whatsapp_group_chat_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/109hp0r/need_help_to_automate_a_whatsapp_group_chat_data/", "subreddit_subscribers": 836276, "created_utc": 1673475262.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}