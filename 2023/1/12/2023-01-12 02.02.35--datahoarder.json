{"kind": "Listing", "data": {"after": "t3_1092z9q", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3t9lh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pulled this from a Synology NAS. Over 8 years old\u2026how much more life could be reasonably expected? Haven\u2019t even powered it on to check overall health yet, just going by the disk &amp; date. Non-critical files, just trying to gauge how much I trust this disk at this age.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10973ac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 265, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 265, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/VzkJCwoWMKfDR_G-XAlanJ4iHTqgi8GaAqVhg_uVeO8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673450072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/m1uxflo82hba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?auto=webp&amp;v=enabled&amp;s=38962ad10b9ff8fc6389fecc51d6621254e638b3", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90a638729bc797b1e3d9f03e2c3b2ccd53fbee25", "width": 108, "height": 144}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20d57e9a1925ab0d3773149171223d601cd9a630", "width": 216, "height": 288}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0636517a50df9f57ff06aec405213e19c6f838c5", "width": 320, "height": 426}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea53916348a61b9094d18e1f8d8420481185323b", "width": 640, "height": 853}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b52e3920e3fc735bcc974bc2c649a5c9e94c91a9", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/m1uxflo82hba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a76e21e3a3a2f421ba4f4b50bc3010dc0d0520d0", "width": 1080, "height": 1440}], "variants": {}, "id": "rsQ04fVBKdmZ1EcVFpnc84qMLNK428HYo4GpVsYeml0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10973ac", "is_robot_indexable": true, "report_reasons": null, "author": "andytagonist", "discussion_type": null, "num_comments": 171, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10973ac/pulled_this_from_a_synology_nas_over_8_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/m1uxflo82hba1.jpg", "subreddit_subscribers": 665449, "created_utc": 1673450072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE  \n      1 Raw_Read_Error_Rate     0x000b   094   094   016    Pre-fail  Always       -       24  \n      5 Reallocated_Sector_Ct   0x0033   100   100   005    Pre-fail  Always       -       0  \n      7 Seek_Error_Rate         0x000b   100   100   067    Pre-fail  Always       -       0  \n      9 Power_On_Hours          0x0012   088   088   000    Old_age   Always       -       89407  \n     12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       141  \n    196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0  \n    198 Offline_Uncorrectable   0x0008   100   100   000    Old_age   Offline      -       0\n\nhttps://i.imgur.com/6cn7XdW.jpeg", "author_fullname": "t2_3vji6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Last night a hero retired", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1096t2w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673449342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE  \n  1 Raw_Read_Error_Rate     0x000b   094   094   016    Pre-fail  Always       -       24  \n  5 Reallocated_Sector_Ct   0x0033   100   100   005    Pre-fail  Always       -       0  \n  7 Seek_Error_Rate         0x000b   100   100   067    Pre-fail  Always       -       0  \n  9 Power_On_Hours          0x0012   088   088   000    Old_age   Always       -       89407  \n 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       141  \n196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0  \n198 Offline_Uncorrectable   0x0008   100   100   000    Old_age   Offline      -       0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.imgur.com/6cn7XdW.jpeg\"&gt;https://i.imgur.com/6cn7XdW.jpeg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?auto=webp&amp;v=enabled&amp;s=88605fa811a0ffd8f1732f1be3c0682b7abc843b", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c76e799d19862d199713325bb24aa70aa2d752e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=696aab18e2b201aa34cafc6f73219e6ab505e033", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb02ede106e02558053379c0e77ad29d7d84dd47", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e0991bd6fccb439b7740337fd503fecc9d21134", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b255513c60c8aa6438bd941b6ada00105b9f7fb5", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/gY0J1zz-l5q_Kw6LuNKqQAlwIgi1DpMdJVLSW_XI-Bs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=564684a07726b757b7424be0233fe59bff571347", "width": 1080, "height": 607}], "variants": {}, "id": "INZcdlsXcTyNZ4TQS9y1kUgLR8Hce69WjVjUjfUnkKU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1096t2w", "is_robot_indexable": true, "report_reasons": null, "author": "common_redditor", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1096t2w/last_night_a_hero_retired/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1096t2w/last_night_a_hero_retired/", "subreddit_subscribers": 665449, "created_utc": 1673449342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). \n\nI grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn't *need* to do it so I wasn't looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. \n\nI have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. \n\nLuckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.", "author_fullname": "t2_hz5u5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bought used QNAP TS431+.. Previous owner left hsi whole company on the drives.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h0eu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a funny story and a small reminder to properly handle your drives on disposal (not that I think anyone here would be this dumb). &lt;/p&gt;\n\n&lt;p&gt;I grabbed a cheap used NAS online to upgrade me from running my drives in a regular RAID box. I didn&amp;#39;t &lt;em&gt;need&lt;/em&gt; to do it so I wasn&amp;#39;t looking to spend a lot of money. Got a good deal, showed up with drives in it. Default admin passwords. &lt;/p&gt;\n\n&lt;p&gt;I have all the data once belonging to a construction company, covering every aspect of their business, going back to at least 2013. Including proposals, diagrams, pictures of their work, addresses, invoices, receipts, credit card numbers, scans of deposited checks, and checking account info. Apparently someone named Katrina decided the recycling bin was good enough. &lt;/p&gt;\n\n&lt;p&gt;Luckily for them, I am not an asshole. But holy hell does this make me feel better about my overly cautious way of dealing with old drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "109h0eu", "is_robot_indexable": true, "report_reasons": null, "author": "DeffNotTom", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h0eu/bought_used_qnap_ts431_previous_owner_left_hsi/", "subreddit_subscribers": 665449, "created_utc": 1673473617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Site's been down for a couple of days. Anyone's got the inside scoop?", "author_fullname": "t2_26dmrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UHDMV.org done?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108uczz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673408150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Site&amp;#39;s been down for a couple of days. Anyone&amp;#39;s got the inside scoop?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108uczz", "is_robot_indexable": true, "report_reasons": null, "author": "Rated-R-Ron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108uczz/uhdmvorg_done/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108uczz/uhdmvorg_done/", "subreddit_subscribers": 665449, "created_utc": 1673408150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.\n\nstarted filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, \"smr, working as intended\"\n\nonce downloads completed I figured I'd give chkdsk another pass just to be sure. 10 bad clusters found this time.\n\nI'm dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn't trust it with important data, but considering I'm stuck with it, is there anything I can do? maybe zero fill?\n\nEDIT\n\nfull chkdsk log: https://i.imgur.com/Waab8Hb.png", "author_fullname": "t2_18grx8tx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 bad clusters on recently acquired WD external", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1099y9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673459963.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1673457091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;an update to my previous post, I recently acquired 4 4tb external drives (WD, Elements). ran chkdsk on delivery, no problems found.&lt;/p&gt;\n\n&lt;p&gt;started filling them with jdownloader until the 3rd one begins to lag terribly. asked here what the problem was, &amp;quot;smr, working as intended&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;once downloads completed I figured I&amp;#39;d give chkdsk another pass just to be sure. 10 bad clusters found this time.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m dumbfounded and angry at myself because I may not be able to return it despite the warranty (3rd world problems). I know I shouldn&amp;#39;t trust it with important data, but considering I&amp;#39;m stuck with it, is there anything I can do? maybe zero fill?&lt;/p&gt;\n\n&lt;p&gt;EDIT&lt;/p&gt;\n\n&lt;p&gt;full chkdsk log: &lt;a href=\"https://i.imgur.com/Waab8Hb.png\"&gt;https://i.imgur.com/Waab8Hb.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?auto=webp&amp;v=enabled&amp;s=fa22f783b4db4bed916c680781e0f71926150b29", "width": 1324, "height": 916}, "resolutions": [{"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=365328e4f0f15ae1640e0794ffeeb0506be978ce", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02df3d9cd0ffded9da82365fd3e75535b7254778", "width": 216, "height": 149}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7f5c08ca3023ea82e4cfcd3fd24e087bbc69ca4", "width": 320, "height": 221}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0691378505539a6abecb7007d2b64691ccd6bd29", "width": 640, "height": 442}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd404e36265ed7b36c9faa1a8b82675c1510d172", "width": 960, "height": 664}, {"url": "https://external-preview.redd.it/fcajxxOKZsh_N2O5HVekMRyELF0E2pDEbujRNs9DHKI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc1948ff24faecef9cda2940048d6d093a970c24", "width": 1080, "height": 747}], "variants": {}, "id": "WRxgf3zs3hd4T5edmv4gY-a8OnqkOammTTB4c1y_Lgc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1099y9o", "is_robot_indexable": true, "report_reasons": null, "author": "h-t-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1099y9o/10_bad_clusters_on_recently_acquired_wd_external/", "subreddit_subscribers": 665449, "created_utc": 1673457091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uyo43rx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building my first server ordered 4 ironwolf nas I got 2 and 2 with different labels all manufactured within 2 months of each other. Is there any difference in these models or is it it just the same drive with different sku that was sent ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_109bu22", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c2jbX7b3UhyQurMFUhttmpCFURt2u611mr54l2OI89M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673461467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/3LFi29T.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?auto=webp&amp;v=enabled&amp;s=6710305a9cd53d5664e90e5591beab4d5edacd63", "width": 1500, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64050a9f5bc430f26fb1aedac51def6817a41cfd", "width": 108, "height": 144}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c3cfd278a50b090624057c885b6ae0f1aca5bb1", "width": 216, "height": 288}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30f98641b32882419cd8e5707e08babbff8c0ccc", "width": 320, "height": 426}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=647e785ef4717773d796e26063513786711ad06e", "width": 640, "height": 853}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49798d4dd8bf4d9770b9de0b2b668ad041f47f93", "width": 960, "height": 1280}, {"url": "https://external-preview.redd.it/3d2GuWizhnLfMrMqC38wBPtXuHOgHrNTQOtmIcUWvr0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=737def69e6194720c6a6b36d19b5d8575a583312", "width": 1080, "height": 1440}], "variants": {}, "id": "dGFmEl7G6uLJ9TlJnP-3Orf4-A5rCRB9aAQ2vW9aKBo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109bu22", "is_robot_indexable": true, "report_reasons": null, "author": "Yung_Gleesh_", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109bu22/building_my_first_server_ordered_4_ironwolf_nas_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/3LFi29T.jpg", "subreddit_subscribers": 665449, "created_utc": 1673461467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay so I have an HP Elitedesk 800 G3 mini and I would like to backup all my GDrive movies (\\~5 TB) on it. However, I don't have neither the space nor the money to buy a NAS or a DAS, leaving me with the option of buying an external HDD.\n\nThen, what's concerning me, it's the HDD's lifespan. Is there any way I can automatically turn on and off the HDD depending on if it's being used or not?  I can't just manually disconnect it from the USB because I have a Plex Server, and maybe I'm not at home at the time.\n\nThanks in advance for your help.\n\nEdit: Forgot to say that I'm using Ubuntu 22.04.", "author_fullname": "t2_y156m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way I can automatically turn on and off an external HDD depending on if it's being used or not to save its lifespan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108s0il", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673402462.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673401728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so I have an HP Elitedesk 800 G3 mini and I would like to backup all my GDrive movies (~5 TB) on it. However, I don&amp;#39;t have neither the space nor the money to buy a NAS or a DAS, leaving me with the option of buying an external HDD.&lt;/p&gt;\n\n&lt;p&gt;Then, what&amp;#39;s concerning me, it&amp;#39;s the HDD&amp;#39;s lifespan. Is there any way I can automatically turn on and off the HDD depending on if it&amp;#39;s being used or not?  I can&amp;#39;t just manually disconnect it from the USB because I have a Plex Server, and maybe I&amp;#39;m not at home at the time.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help.&lt;/p&gt;\n\n&lt;p&gt;Edit: Forgot to say that I&amp;#39;m using Ubuntu 22.04.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5TB GDrive", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108s0il", "is_robot_indexable": true, "report_reasons": null, "author": "guillembdbm8", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/108s0il/is_there_any_way_i_can_automatically_turn_on_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108s0il/is_there_any_way_i_can_automatically_turn_on_and/", "subreddit_subscribers": 665449, "created_utc": 1673401728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm struggling to understand the guides on GitHub and have some questions.\n\n1. I have a failing drive I want to \"vacate\" and found a Github thread that mentions setting the drive as read only while copying out the drive.  How can I do this via ssh commands that will override the /etc/fstab?\n\n Related: At the moment I'm having an issue where running \"sudo mount -a\" fails on some drives. Something about \"wrong fs type, bad option, bad superblock or other error\".  I don't think it's caused by MergerFS but does make using the \"sudo mount -a\" not an option, at least for now.\n\n2. The thread mentions creating a temporary pool excluding the dying drive.  My drives are all mounted to the same path and arranged as \"disk1\" and \"disk2\" etc.  I currently use \"disk*\" to mount them all.  Is there a way to mount \"disk*\" and specifically exclude \"disk5\" for example, again via ssh command?", "author_fullname": "t2_9zarh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MergerFS questions from a new user", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108x81e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673416858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to understand the guides on GitHub and have some questions.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I have a failing drive I want to &amp;quot;vacate&amp;quot; and found a Github thread that mentions setting the drive as read only while copying out the drive.  How can I do this via ssh commands that will override the /etc/fstab?&lt;/p&gt;\n\n&lt;p&gt;Related: At the moment I&amp;#39;m having an issue where running &amp;quot;sudo mount -a&amp;quot; fails on some drives. Something about &amp;quot;wrong fs type, bad option, bad superblock or other error&amp;quot;.  I don&amp;#39;t think it&amp;#39;s caused by MergerFS but does make using the &amp;quot;sudo mount -a&amp;quot; not an option, at least for now.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The thread mentions creating a temporary pool excluding the dying drive.  My drives are all mounted to the same path and arranged as &amp;quot;disk1&amp;quot; and &amp;quot;disk2&amp;quot; etc.  I currently use &amp;quot;disk&lt;em&gt;&amp;quot; to mount them all.  Is there a way to mount &amp;quot;disk&lt;/em&gt;&amp;quot; and specifically exclude &amp;quot;disk5&amp;quot; for example, again via ssh command?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108x81e", "is_robot_indexable": true, "report_reasons": null, "author": "silentdragon14", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108x81e/mergerfs_questions_from_a_new_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108x81e/mergerfs_questions_from_a_new_user/", "subreddit_subscribers": 665449, "created_utc": 1673416858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_rwbgmvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this a real Intel NIC? Not sure I should bother opening the box.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 101, "top_awarded_type": null, "hide_score": false, "name": "t3_109hmlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mgL3X4XHo2PhWx_EqbBFXzeMSzOU-qza4xRiqQbF7ws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673475095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tjbk2uan4jba1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?auto=webp&amp;v=enabled&amp;s=45263bd06de842244e547e41374bc7be001e8d28", "width": 4030, "height": 2919}, "resolutions": [{"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9a8c4bd5a05cfd72c2c85830dd498168bc670ea", "width": 108, "height": 78}, {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=343323126dd42adc7518060ba00d4692df596acd", "width": 216, "height": 156}, {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47385fc67708d852a8aacac12573edaf0252aa80", "width": 320, "height": 231}, {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c5b9f7aea5db7a3c5fa0fafb664f9bf2d4e3b4d", "width": 640, "height": 463}, {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3100860ff9bc064d7c1ffad7927866866f0e2010", "width": 960, "height": 695}, {"url": "https://preview.redd.it/tjbk2uan4jba1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9302221e7debb024fc18a2a755a4cae40bbdec6", "width": 1080, "height": 782}], "variants": {}, "id": "FaCyA_uL7S9YbyktRGy8p6xmBEmUw1bSJXdbiM_zbG0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109hmlb", "is_robot_indexable": true, "report_reasons": null, "author": "Karizmology", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109hmlb/is_this_a_real_intel_nic_not_sure_i_should_bother/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tjbk2uan4jba1.jpg", "subreddit_subscribers": 665449, "created_utc": 1673475095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nI currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.\n\nLooking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.\n\nTIA!", "author_fullname": "t2_9jlhrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need suggestions: Data migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109h2xs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673473789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I currently have about 1.3TB stored in Amazon Drive. With the retirement of that platform, I am looking to move to a new on-line option. I am currently thinking Google Drive may be the best fit at the best price.&lt;/p&gt;\n\n&lt;p&gt;Looking ahead to the data migration piece.... Can someone suggest options that would allow me to transfer these files directly from the Amazon to the Google platform? Downloading and re-uploading will be a very  s l o w   p   r   o   c   e   s   s   with my internet provider.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109h2xs", "is_robot_indexable": true, "report_reasons": null, "author": "PerpetuallyPerplxed", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109h2xs/need_suggestions_data_migration/", "subreddit_subscribers": 665449, "created_utc": 1673473789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "ArchiveBox only seems to allow a person to save *all* of one's bookmarks and I couldn't even do that because I got the following error:\n\nError while loading link! \\[1673463122.097194\\] \\[path to my browser's bookmarks file\\] \"None\"\n\n&amp;#x200B;\n\nThis error was shown after I used the following command:\n\narchivebox add --depth=1 \\[path to my browser's bookmarks file\\]\n\n&amp;#x200B;\n\nCan somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as 'HTML Only.' It wouldn't take me long to do it manually, but I figured I would finally try to do it automatically.", "author_fullname": "t2_emji9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically save all pages in a bookmarks subfolder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109d68v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673464571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ArchiveBox only seems to allow a person to save &lt;em&gt;all&lt;/em&gt; of one&amp;#39;s bookmarks and I couldn&amp;#39;t even do that because I got the following error:&lt;/p&gt;\n\n&lt;p&gt;Error while loading link! [1673463122.097194] [path to my browser&amp;#39;s bookmarks file] &amp;quot;None&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This error was shown after I used the following command:&lt;/p&gt;\n\n&lt;p&gt;archivebox add --depth=1 [path to my browser&amp;#39;s bookmarks file]&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Can somebody instruct me on how to use ArchiveBox for this or give me a different method? Right now, I just want a copy of all sites in a certain bookmarks folder as &amp;#39;HTML Only.&amp;#39; It wouldn&amp;#39;t take me long to do it manually, but I figured I would finally try to do it automatically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109d68v", "is_robot_indexable": true, "report_reasons": null, "author": "PA99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109d68v/automatically_save_all_pages_in_a_bookmarks/", "subreddit_subscribers": 665449, "created_utc": 1673464571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, \n\nI am building myself a NAS to digitize my parents' DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives\n\nI'm planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I'm worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5\" HDD, and I would hope for some more HDD Bays for future expansion.\n\nI am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn't seem to be too difficult, but I wanna make sure I haven't overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!", "author_fullname": "t2_bzoyakj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "needing a little help/reassurance with my first server build!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097xi4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, &lt;/p&gt;\n\n&lt;p&gt;I am building myself a NAS to digitize my parents&amp;#39; DVD collection, as well as store all my general data. I was tasked with removing HDDs from old PCs at work, and was able to snag a Dell X9M3X Motherboard (LGA 1155, DDR3), an intel i3-3220, 4 x 4Gb DDR3 DIMMs, a bunch of SATA Data cables, and a stock CPU Cooler, which I assume will be sufficient for a NAS. I also have a spare 550W PSU. Otherwise, I will need a case, boot drive, and storage drives&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on getting a cheap 250 gb SSD as boot drive and 2 WD Red 4Tb HDDs in Raid1 as storage. My main concern is with my motherboard and case compatibility. It is an old Dell Mobo, and I&amp;#39;m worried about the front panel connectors being compatible. Can anyone shed some light on what sort of case I should be looking for? I could still take the original case from work, but that will only hold 1 3.5&amp;quot; HDD, and I would hope for some more HDD Bays for future expansion.&lt;/p&gt;\n\n&lt;p&gt;I am at work right now and working on figuring out creating boot media for TrueNAS/FreeNAS, which doesn&amp;#39;t seem to be too difficult, but I wanna make sure I haven&amp;#39;t overlooked anything, so if you see any mistakes here, or can think of any common ones a beginner might make, let me know! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097xi4", "is_robot_indexable": true, "report_reasons": null, "author": "justinc0617", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097xi4/needing_a_little_helpreassurance_with_my_first/", "subreddit_subscribers": 665449, "created_utc": 1673452196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.\n\nAs an example, here is what I\u2019ve tried so far:\n\n    youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\nBut this returns an Unsupported URL error.\n\nImportantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.\n\nAny way to do this?", "author_fullname": "t2_151mwt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[youtube-dl] How to download all the videos belonging to a Vimeo user archived on Wayback Machine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1097ut9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673452007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d like to download all the videos from a Vimeo user whose account was archived on Wayback Machine. I know that you can use youtube-dl for this kind of thing, but from what I\u2019ve seen it can be wonky when applying it to Wayback Machine.&lt;/p&gt;\n\n&lt;p&gt;As an example, here is what I\u2019ve tried so far:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;youtube-dl https://web.archive.org/web/20150109044401/http://vimeo.com/user10047112\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But this returns an Unsupported URL error.&lt;/p&gt;\n\n&lt;p&gt;Importantly, I\u2019m NOT adding /videos after the username (i.e. user10047112/videos) and would just like to reference the Vimeo username itself when downloading all the videos.&lt;/p&gt;\n\n&lt;p&gt;Any way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1097ut9", "is_robot_indexable": true, "report_reasons": null, "author": "AsleepInTheStalks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1097ut9/youtubedl_how_to_download_all_the_videos/", "subreddit_subscribers": 665449, "created_utc": 1673452007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? \n\nI love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. \n\nThanks!", "author_fullname": "t2_jijjmnms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you BUY your ebooks from?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1096x85", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673449643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations for DRM-free bookstores out there or it\u2019s all just Kindle, Apple Books and Adobe Digital Editions? &lt;/p&gt;\n\n&lt;p&gt;I love reading and recently started hoarding books but finding legitimate non-DRM books seems impossible. Yes most DRM books can be made DRM free with De-DRM but I am kind of on the fence about giving money to DRM supported companies and potentially breaking the law by removing the DRM. I would much prefer just buying a DRM free edition even if it\u2019s more expensive. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1096x85", "is_robot_indexable": true, "report_reasons": null, "author": "clickbg", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1096x85/where_do_you_buy_your_ebooks_from/", "subreddit_subscribers": 665449, "created_utc": 1673449643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI'm hoping to get opinions on whether this is normal and if my new hard drive is ok.\n\nI just installed a new wd red plus 14tb hard drive into my windows 11 pc. I am moving large video files (8-12gb) from my older 3tb hard drive to the new empty 14tb wd red. I noticed in task manager performance tab that the wd red has fluctuating write speeds from over 200mb/s to 0mb/s. Disk usage is spiking from 0-10% to 100%. response time spike over 400ms. This happens during each single video file. The old 3tb hard drive seems normal 99-100% usage while reading, no fluctuations. I have attached the image showing what is happening. The wd red is drive D and the old hdd is drive H.\n\nhttps://preview.redd.it/hghl78lqzbba1.png?width=2560&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9bc0d0cf20b44d20291e5608b5d5e4b0fcf40151\n\nI'm also hearing some weird loud noise during the Diagnostic Short Test using  WD dashboard that I don't hear with my other hard drive. I uploaded an audio file. The sounds start at 1:05. I ran the test multiple times and it passes each time. [https://sndup.net/rdtw/](https://sndup.net/rdtw/)\n\nThank you", "author_fullname": "t2_vhzte1k3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD red plus Fluctuating write speeds during file transfer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hghl78lqzbba1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f37a1235ebec744fb026aaa03245726bb24fd2a3"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e4809cb80598e25064d9b64f662f1ec2dd23222"}, {"y": 174, "x": 320, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15513b0ebc23588db36b41bee9cda04ea9d4cd54"}, {"y": 348, "x": 640, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cbe7e448ed52afc20287d95869897dce690925e"}, {"y": 522, "x": 960, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8cc35aca2d666f10277406041c684b5a167260e"}, {"y": 587, "x": 1080, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=db5b1d6661d6d04093ca2a89b746ea0c40184cfa"}], "s": {"y": 1392, "x": 2560, "u": "https://preview.redd.it/hghl78lqzbba1.png?width=2560&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9bc0d0cf20b44d20291e5608b5d5e4b0fcf40151"}, "id": "hghl78lqzbba1"}}, "name": "t3_108tw6m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5q8JvvxXsyM4glpu-L1zNr-x_dlp-vLBbcQeFPSI2rY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673406816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping to get opinions on whether this is normal and if my new hard drive is ok.&lt;/p&gt;\n\n&lt;p&gt;I just installed a new wd red plus 14tb hard drive into my windows 11 pc. I am moving large video files (8-12gb) from my older 3tb hard drive to the new empty 14tb wd red. I noticed in task manager performance tab that the wd red has fluctuating write speeds from over 200mb/s to 0mb/s. Disk usage is spiking from 0-10% to 100%. response time spike over 400ms. This happens during each single video file. The old 3tb hard drive seems normal 99-100% usage while reading, no fluctuations. I have attached the image showing what is happening. The wd red is drive D and the old hdd is drive H.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hghl78lqzbba1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9bc0d0cf20b44d20291e5608b5d5e4b0fcf40151\"&gt;https://preview.redd.it/hghl78lqzbba1.png?width=2560&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9bc0d0cf20b44d20291e5608b5d5e4b0fcf40151&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also hearing some weird loud noise during the Diagnostic Short Test using  WD dashboard that I don&amp;#39;t hear with my other hard drive. I uploaded an audio file. The sounds start at 1:05. I ran the test multiple times and it passes each time. &lt;a href=\"https://sndup.net/rdtw/\"&gt;https://sndup.net/rdtw/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108tw6m", "is_robot_indexable": true, "report_reasons": null, "author": "Young730", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108tw6m/wd_red_plus_fluctuating_write_speeds_during_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108tw6m/wd_red_plus_fluctuating_write_speeds_during_file/", "subreddit_subscribers": 665449, "created_utc": 1673406816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)", "author_fullname": "t2_woqd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Photo sorter recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109l5sr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673483820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for something like Google Photos with smart photo sorting (eg. face, screenshots, blurry shots)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109l5sr", "is_robot_indexable": true, "report_reasons": null, "author": "slaiyfer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109l5sr/photo_sorter_recommendations/", "subreddit_subscribers": 665449, "created_utc": 1673483820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I'm located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I'm aware, but it all seemed like a good idea at the time).\n\nThe process is deceptively simple if you've never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.\n\nThe first thing you'll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.\n\nThen you'll discover that there's absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word \"asynchronous\" and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don't even see your checkboxes get checked until the requests complete.\n\nBut let's say you've checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn't you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I've seen (something like 20-30 minutes) and no \"Remember me\" button. This is a bit more of a big deal, or - as you might find out later - a very big deal.\n\nSo you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I've had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven't had that happen often with large ones, but a bunch of times with small ones.\n\nYou've finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you've had first hand experience with the downloader. (Spoilers, I know). Let's say you listen and download the downloader - pointlessly, as it turns out, since it's already there along with your Backblaze installation.\n\nYou give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.\n\nAnd then you realize the downloader has the same problem as the UI with the \"async\" concept, except Windows really, *really* doesn't like apps hogging the UI thread. So 90 percent of the time the window is \"not responding\", the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I've had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you've made a mistake of restoring to your C:\\ drive this is going to be even worse since that's also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them \"threads\"; that's not quite telling the whole story as they're entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it's hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.\n\nBut let's say you've downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there's no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there's no indication which restores you have or have not already downloaded.\n\nAnd while you've been marveling at that the unzip process has thrown a CRC error - which I really, *really* hope is just an issue with the zipping/downloading process and the actual data that's being stored on the servers is okay. If you've had the downloader hang on you there's a pretty much 100% chance you'll get that, if you've stopped and restarted the download you'll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you're lucky it's just going to be one or two files and you can restore them separately, if you're not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.\n\nSo you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the \"acceleration\" part, which for some reason works only up to some size - maybe that's some issue on my side, but I've tried multiple ones and I haven't gotten the big restores to download in parallel, only smaller ones.\n\nAnd even if you've gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they've finished a chunk, said connections are now getting redirected to the login page. I've tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don't care for the acceleration, I hope you didn't spend too much time setting up a queue of downloads (or go to bed afterwards), because that won't work either for the same reason.\n\nIronically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don't ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can't just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.\n\nNow does it mean Backblaze is a bad service? I guess not - for the price it's still a steal, and there are other options to restore. If you're in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I'm likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don't want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might've heard of the restore process being a bit iffy but it can't be that bad, right?\n\nWell, it's exactly as bad as above, no more, no less - whether that's a dealbreaker is in the eye of the beholder, but it's better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I'm hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it's really a bit disappointing that the current process is so miserable.", "author_fullname": "t2_epug6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Backblaze large restore experience (is miserable)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_109kd3j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673481815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have my 40TB hoard of data backed up to Backblaze, and with the recent acquisition of two more drives I needed to wipe my storage pool to switch it over from a simple one to a parity one. Instead of making a local copy I decided to fetch the data back from Backblaze, and since I&amp;#39;m located in Europe, instead of ordering drives and paying duty for them I opted for the download method. (A series of mistakes, I&amp;#39;m aware, but it all seemed like a good idea at the time).&lt;/p&gt;\n\n&lt;p&gt;The process is deceptively simple if you&amp;#39;ve never actually tried to go through it - either download single files directly, or select what you need and prepare a .zip to download later.&lt;/p&gt;\n\n&lt;p&gt;The first thing you&amp;#39;ll run into is the 500GB limit for a single .zip - a pain since it means you need to split up your data, but not an unreasonable limitation, if a little on the small side.&lt;/p&gt;\n\n&lt;p&gt;Then you&amp;#39;ll discover that there&amp;#39;s absolutely zero assistance for you to split your data up - you need to manually pick out files and folders to include and watch the total size (and be aware that this 500GB is decimal). At that point you may also notice that the interface to prepare restores is... not very good - nobody at Backblaze seems to have heard the word &amp;quot;asynchronous&amp;quot; and the UI is blocked on requests to the backend, so not only do you not get instant feedback on your current archive size, you don&amp;#39;t even see your checkboxes get checked until the requests complete.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve checked what you need for your first batch, got close enough to 500GB and started preparing your .zip. So you go to prepare another. You click back to the Restore screen and, if you have your backup encrypted, it asks you for the encryption key again. Wait, didn&amp;#39;t you just provide that? Well, yes, and your backup is decrypted, but on server 0002, and this time the load balancer decided to get you onto server 0014. Not a big deal. Unless you grabbed yourself a coffee in the meantime and now are staring at a login screen again because Backblaze has one of the shortest session expiration times I&amp;#39;ve seen (something like 20-30 minutes) and no &amp;quot;Remember me&amp;quot; button. This is a bit more of a big deal, or - as you might find out later - a very big deal.&lt;/p&gt;\n\n&lt;p&gt;So you prepare a few more batches, still with that same less than responsive interface, and eventually you hit the limit of 5 restores being prepared at once. So you wait. And you wait. Maybe hours, maybe as much as two days. For whatever reason restores that hit close to that 500GB mark take ages, much more than the same amount of data split across multiple 40-50 GB packs - I&amp;#39;ve had 40GB packages prepared in 5-6 minutes, while the 500GB ones took not 10, but more like 100 times more. Unless you hit a snag and the package just refuses to get prepared and you have to cancel it - I haven&amp;#39;t had that happen often with large ones, but a bunch of times with small ones.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;ve finally got one of those restores ready though, and the seven day clock to download it is ticking - so you go to download and it tells you to get yourself a Backblaze Downloader. You may ignore it now and find out that your download is capped at about 100-150 MBit even on your gigabit connection, or you may ignore it later when you&amp;#39;ve had first hand experience with the downloader. (Spoilers, I know). Let&amp;#39;s say you listen and download the downloader - pointlessly, as it turns out, since it&amp;#39;s already there along with your Backblaze installation.&lt;/p&gt;\n\n&lt;p&gt;You give it your username and password, OTP code and get a dropdown list of restores - so far, so good. You select one, pick a folder to download to, go with the recommended number of threads, and start downloading.&lt;/p&gt;\n\n&lt;p&gt;And then you realize the downloader has the same problem as the UI with the &amp;quot;async&amp;quot; concept, except Windows really, &lt;em&gt;really&lt;/em&gt; doesn&amp;#39;t like apps hogging the UI thread. So 90 percent of the time the window is &amp;quot;not responding&amp;quot;, the Close button may work eventually when it gets around to it, and the speed indicator is useless. (The progress bar turns out to be useless too as I&amp;#39;ve had downloads hit 100% with the bar lingering somewhere three quarters of the way in). If you&amp;#39;ve made a mistake of restoring to your C:\\ drive this is going to be even worse since that&amp;#39;s also where the scratch files are being written, so your disk is hit with a barrage of multiple processes at once (the downloader calls them &amp;quot;threads&amp;quot;; that&amp;#39;s not quite telling the whole story as they&amp;#39;re entirely separate processes getting spawned per 40MB chunk and killed when they finish) writing scratch files, and the downloader appending them to your target file. And the downloader constantly looks like it&amp;#39;s hanged, but it has not, unless it has because that happens sometimes as well and your nightly restore might have not gotten past ten percent.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s say you&amp;#39;ve downloaded your first batch and want to download another - except all you can do with the downloader is close it, then restart it, there&amp;#39;s no way to get back to the selection screen. And you need to provide your credentials again. And the target folder has reset to the Desktop again. And there&amp;#39;s no indication which restores you have or have not already downloaded.&lt;/p&gt;\n\n&lt;p&gt;And while you&amp;#39;ve been marveling at that the unzip process has thrown a CRC error - which I really, &lt;em&gt;really&lt;/em&gt; hope is just an issue with the zipping/downloading process and the actual data that&amp;#39;s being stored on the servers is okay. If you&amp;#39;ve had the downloader hang on you there&amp;#39;s a pretty much 100% chance you&amp;#39;ll get that, if you&amp;#39;ve stopped and restarted the download you&amp;#39;ll probably get hit by that as well, and even if everything went just fine it may still happen just because. If you&amp;#39;re lucky it&amp;#39;s just going to be one or two files and you can restore them separately, if you&amp;#39;re not and it plowed over a more sensitive portion of the .zip the entire thing is likely worthless and needs to be redownloaded.&lt;/p&gt;\n\n&lt;p&gt;So you give up on the downloader and decide to download manually - and because of that 100-150 MBit cap you get yourself a download accelerator. Great! Except for the &amp;quot;acceleration&amp;quot; part, which for some reason works only up to some size - maybe that&amp;#39;s some issue on my side, but I&amp;#39;ve tried multiple ones and I haven&amp;#39;t gotten the big restores to download in parallel, only smaller ones.&lt;/p&gt;\n\n&lt;p&gt;And even if you&amp;#39;ve gotten that download acceleration to work - remember that part about getting signed out after 30 minutes? Turns out this applies to the download link as well. And since download accelerators reestablish connections once they&amp;#39;ve finished a chunk, said connections are now getting redirected to the login page. I&amp;#39;ve tried three of those programs and neither of them managed to work that situation out, all of them eventually got all of their threads stuck and were not able to resume, leaving a dead download. And even if you don&amp;#39;t care for the acceleration, I hope you didn&amp;#39;t spend too much time setting up a queue of downloads (or go to bed afterwards), because that won&amp;#39;t work either for the same reason.&lt;/p&gt;\n\n&lt;p&gt;Ironically, the best way to get the downloads working turned out to be just downloading them in the browser - setting up far smaller chunks, so that the still occasional CRC errors don&amp;#39;t ruin your day, and downloading multiple files in parallel to saturate the connection. But it still requires multiple trips to the restore screen, you can&amp;#39;t just spend an afternoon setting up all your restores because you only have seven days to download them and you need to set them up little by little, and you may still run into issues with the downloads or the resulting zip files.&lt;/p&gt;\n\n&lt;p&gt;Now does it mean Backblaze is a bad service? I guess not - for the price it&amp;#39;s still a steal, and there are other options to restore. If you&amp;#39;re in the US the USB drives are more than likely going to be a great option with zero of the above hassle, if you can eat the egress fees B2 may be a viable option, and in the end I&amp;#39;m likely going to get my files out eventually. But it seems like a lot of people who get interested in Backblaze are in the same boat as me - they don&amp;#39;t want to spend more than the monthly fee, may not have the deposit money or live too far away for the drive restore, and they might&amp;#39;ve heard of the restore process being a bit iffy but it can&amp;#39;t be that bad, right?&lt;/p&gt;\n\n&lt;p&gt;Well, it&amp;#39;s exactly as bad as above, no more, no less - whether that&amp;#39;s a dealbreaker is in the eye of the beholder, but it&amp;#39;s better to know those things about the service you use before you end up depending on it for your data. I know the Backblaze team has been speaking of a better downloader which I&amp;#39;m hoping will not be vaporware, but even that aside there are so many things that should be such easy wins to fix - the session length issue, the downloader not hogging the UI thread, the artificial 500 GB limit - that it&amp;#39;s really a bit disappointing that the current process is so miserable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109kd3j", "is_robot_indexable": true, "report_reasons": null, "author": "Mivexil", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109kd3j/the_backblaze_large_restore_experience_is/", "subreddit_subscribers": 665449, "created_utc": 1673481815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI'm looking for a webui tool to manage my music folder.\n\nMy idea is something like that:\n\n\\- I tell the program where I will add new songs (like the rip folder)\n\n\\- It automatically detect new songs, search for tags and the move the song to the correct folder\n\n\\- from the webui I set the rules and edit metadata if needed.\n\n&amp;#x200B;\n\nDo you know anything that can do that?", "author_fullname": "t2_24u5cpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manage music folder from webui?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109jdnd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673479355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a webui tool to manage my music folder.&lt;/p&gt;\n\n&lt;p&gt;My idea is something like that:&lt;/p&gt;\n\n&lt;p&gt;- I tell the program where I will add new songs (like the rip folder)&lt;/p&gt;\n\n&lt;p&gt;- It automatically detect new songs, search for tags and the move the song to the correct folder&lt;/p&gt;\n\n&lt;p&gt;- from the webui I set the rules and edit metadata if needed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you know anything that can do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109jdnd", "is_robot_indexable": true, "report_reasons": null, "author": "TopdeckIsSkill", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109jdnd/manage_music_folder_from_webui/", "subreddit_subscribers": 665449, "created_utc": 1673479355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI would like to hear your advice about a reliable backup solution. today I use Crashplan to backup about 1tb of data, with addition of payment to google for phone camera backup (although every 3 months or so i move my phone photos to my computer)\n\n&amp;#x200B;\n\ni would like to find a backup service (hopefully free, with a GUI, but not a must) to backup all my (or my important folders)  to google drive or onedrive . i searched and saw programs like Rsync/ duplicity  but i know Reddit probably has a more solid opinion on this, which i would love to hear. it must has a possibility to Restore in case of a disaster (like PC is stolen / broken)\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_aibn51my", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup solution with onedrive/gdrive as storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_108zx5u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673426477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I would like to hear your advice about a reliable backup solution. today I use Crashplan to backup about 1tb of data, with addition of payment to google for phone camera backup (although every 3 months or so i move my phone photos to my computer)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i would like to find a backup service (hopefully free, with a GUI, but not a must) to backup all my (or my important folders)  to google drive or onedrive . i searched and saw programs like Rsync/ duplicity  but i know Reddit probably has a more solid opinion on this, which i would love to hear. it must has a possibility to Restore in case of a disaster (like PC is stolen / broken)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "108zx5u", "is_robot_indexable": true, "report_reasons": null, "author": "ellevy12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/108zx5u/backup_solution_with_onedrivegdrive_as_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/108zx5u/backup_solution_with_onedrivegdrive_as_storage/", "subreddit_subscribers": 665449, "created_utc": 1673426477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_582xz2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing Pin Tweet to IPFS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_109jicb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jvM5ok8cCSZytyXa1yzGsEM4eZjXVlVIduvnMHlJMSc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1673479680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.ipfs.tech", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.ipfs.tech/announcing-pin-tweet-to-ipfs/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?auto=webp&amp;v=enabled&amp;s=8781dbda893c73eea5a534ce394fd27749f1c0a0", "width": 2000, "height": 1124}, "resolutions": [{"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4e9602a01e6c41794c27be0975dda67fefc3313", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=efa89b156712e3446be2d89f6f4ce09bd5cc6b63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83a355a7b627c64c8e0602924f379e213b635a28", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6c5f69397b1c5b4e176a882b875c569bbbdfe1", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=544b3c4580083afe09e25ce473da552239e23a90", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/uFEfV_3FibU5HXClFaEs-7Yc1DrZ43qCfUeQjEQ-KuE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0cc95f3e9bce8798f400e5954aec4f2ce0738b3", "width": 1080, "height": 606}], "variants": {}, "id": "B2uk6TAJvETommfm85rwk4tuEHxycKfZo3h36xyAGes"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109jicb", "is_robot_indexable": true, "report_reasons": null, "author": "Spirited-Pause", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109jicb/announcing_pin_tweet_to_ipfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.ipfs.tech/announcing-pin-tweet-to-ipfs/", "subreddit_subscribers": 665449, "created_utc": 1673479680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ordered a Seagate Firecuda 520 1TB and a WD Black 850x 1TB at the same price. \n\nThe Seagate is slower but and a rated TBW of 1800TB.\nThe WD is  faster and has a rated TBW of 600TB.\n\nWhich one would you pick?\n\nThe Seagate has the Phison E16 controller, which has been fault prone I think.\nThe latest Firecuda 520 revision also has a TBW of 600. Unsure if they've made any hardware changes, or if they've adjusted it strictly because it couldn't reach its rated number.", "author_fullname": "t2_w9ilh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unraid nvme cache, a few alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_109937b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673455039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ordered a Seagate Firecuda 520 1TB and a WD Black 850x 1TB at the same price. &lt;/p&gt;\n\n&lt;p&gt;The Seagate is slower but and a rated TBW of 1800TB.\nThe WD is  faster and has a rated TBW of 600TB.&lt;/p&gt;\n\n&lt;p&gt;Which one would you pick?&lt;/p&gt;\n\n&lt;p&gt;The Seagate has the Phison E16 controller, which has been fault prone I think.\nThe latest Firecuda 520 revision also has a TBW of 600. Unsure if they&amp;#39;ve made any hardware changes, or if they&amp;#39;ve adjusted it strictly because it couldn&amp;#39;t reach its rated number.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "109937b", "is_robot_indexable": true, "report_reasons": null, "author": "drinksbeerdaily", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/109937b/unraid_nvme_cache_a_few_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/109937b/unraid_nvme_cache_a_few_alternatives/", "subreddit_subscribers": 665449, "created_utc": 1673455039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks. Not sure I'd call myself a data hoarder but I do need to start thinking about reliable backup solutions for about a decade's worth of accumulated casual home data. Unorganized old pictures, music, movie downloads, software backups, etc. I have about a dozen mixed hard drives in capacities from 250GB to 1TB. I think total there's &lt;10TB of data to be preserved but I'd like to be at least a little future-proofed.\n\nMy current \"gaming\" desktop is a Core i7-3770 from 2014, 32GB ram, RTX 2060, running Linux Mint. I like this OS and I'm not exactly a newb when it comes to computers in general. I've considered building a NAS (I have enough spare parts to build maybe 2 other systems roughly on par with a 2014 \"office\" PC) but I'm wondering if it might be better to just install a software RAID solution and plug in a bunch of drives to my current PC since I rarely use it for gaming anymore and I'm sure it's reasonably robust.\n\nIdeally here's my use case points:\n\n* This is a \"deep\" backup, something for the wife and I to copy our data onto when our daily drivers start getting full, OS needs update/wipe/reinstall, new laptop, clean up the `/home` dir, etc.\n\n* Won't be connected to the wider internet, local network access only. *Probably* won't be serving media directly but would like the capability if feasible (old movies and stuff I sometimes like to put on the big TV, probably via VLC&gt;Chromecast)\n\n* Enough redundancy that if a drive fails I can just replace it without losing data. That said I'm not looking to thrash these drives. Maybe accessing some random shit a few times a month, maybe a large backup/restore cycle once a year or so.\n\n* Easy to expand storage with little effort. We don't collect *that much* permanent data I need to save, maybe a few hundred GBs a year tops. Ideally I'd just like to be able to plug in a new drive(s) to the array and get another TB with redundancy with a few clicks.\n\n* Preferably in a format that can be easily recovered. If I bork my OS I should be able to just also reinstall the software and replicate the drive configuration and keep on chugging, worst case scenario should still be able to get the raw files off the drives directly.\n\n* Still be able to game occasionally, edit high-res photos/video etc, without having the backup solution interfere. Just power the array down when I'm not using / accessing it, temporarily suspend the software, whatever. This doesn't need to be running all the time.\n\nFor this post, I'm not needing hand-holding, more some bullet-point guidance to get me moving in the right direction. I'm thinking something like:\n\n* Buy a few 1TB SSDs (or something else? WD Reds?)\n\n* Buy a SATA3 controller? (MB only has like 3 ports)\n\n* Install [some software RAID]?\n\n* Start copying data from old HDDs?\n\n* EDIT: Maybe I should get like an 8-bay drive case with its own power supply and controller? If so is there something that could just plug into an existing SATA port and wall socket and behave like a big redundant disk when I need it, then go back in the closet?\n\nAlternatively let me know if I'm an idiot and should just buy a Synology, but I had a bad experience with an old WD Cloud NAS that crashed and I barely was able to recover stuff from it. Hopefully looking for something homegrown that I can understand and maintain myself.\n\n***\n\nextreme TL;DR: My backup solution to this point has been \"plug in an old HDD and copy some files onto it, then stick it back in the closet\". Since I now have several such \"old HDDs\" I'd like something with essentially that level of ease/convenience, but slightly more robust and future-proof.", "author_fullname": "t2_4xm2s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data storage neophyte, starting to worry about my old HDDs and need some pointers in the right direction.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1098ij1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673455388.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673453633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks. Not sure I&amp;#39;d call myself a data hoarder but I do need to start thinking about reliable backup solutions for about a decade&amp;#39;s worth of accumulated casual home data. Unorganized old pictures, music, movie downloads, software backups, etc. I have about a dozen mixed hard drives in capacities from 250GB to 1TB. I think total there&amp;#39;s &amp;lt;10TB of data to be preserved but I&amp;#39;d like to be at least a little future-proofed.&lt;/p&gt;\n\n&lt;p&gt;My current &amp;quot;gaming&amp;quot; desktop is a Core i7-3770 from 2014, 32GB ram, RTX 2060, running Linux Mint. I like this OS and I&amp;#39;m not exactly a newb when it comes to computers in general. I&amp;#39;ve considered building a NAS (I have enough spare parts to build maybe 2 other systems roughly on par with a 2014 &amp;quot;office&amp;quot; PC) but I&amp;#39;m wondering if it might be better to just install a software RAID solution and plug in a bunch of drives to my current PC since I rarely use it for gaming anymore and I&amp;#39;m sure it&amp;#39;s reasonably robust.&lt;/p&gt;\n\n&lt;p&gt;Ideally here&amp;#39;s my use case points:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;This is a &amp;quot;deep&amp;quot; backup, something for the wife and I to copy our data onto when our daily drivers start getting full, OS needs update/wipe/reinstall, new laptop, clean up the &lt;code&gt;/home&lt;/code&gt; dir, etc.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Won&amp;#39;t be connected to the wider internet, local network access only. &lt;em&gt;Probably&lt;/em&gt; won&amp;#39;t be serving media directly but would like the capability if feasible (old movies and stuff I sometimes like to put on the big TV, probably via VLC&amp;gt;Chromecast)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Enough redundancy that if a drive fails I can just replace it without losing data. That said I&amp;#39;m not looking to thrash these drives. Maybe accessing some random shit a few times a month, maybe a large backup/restore cycle once a year or so.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Easy to expand storage with little effort. We don&amp;#39;t collect &lt;em&gt;that much&lt;/em&gt; permanent data I need to save, maybe a few hundred GBs a year tops. Ideally I&amp;#39;d just like to be able to plug in a new drive(s) to the array and get another TB with redundancy with a few clicks.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Preferably in a format that can be easily recovered. If I bork my OS I should be able to just also reinstall the software and replicate the drive configuration and keep on chugging, worst case scenario should still be able to get the raw files off the drives directly.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Still be able to game occasionally, edit high-res photos/video etc, without having the backup solution interfere. Just power the array down when I&amp;#39;m not using / accessing it, temporarily suspend the software, whatever. This doesn&amp;#39;t need to be running all the time.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For this post, I&amp;#39;m not needing hand-holding, more some bullet-point guidance to get me moving in the right direction. I&amp;#39;m thinking something like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Buy a few 1TB SSDs (or something else? WD Reds?)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Buy a SATA3 controller? (MB only has like 3 ports)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Install [some software RAID]?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Start copying data from old HDDs?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;EDIT: Maybe I should get like an 8-bay drive case with its own power supply and controller? If so is there something that could just plug into an existing SATA port and wall socket and behave like a big redundant disk when I need it, then go back in the closet?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Alternatively let me know if I&amp;#39;m an idiot and should just buy a Synology, but I had a bad experience with an old WD Cloud NAS that crashed and I barely was able to recover stuff from it. Hopefully looking for something homegrown that I can understand and maintain myself.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;extreme TL;DR: My backup solution to this point has been &amp;quot;plug in an old HDD and copy some files onto it, then stick it back in the closet&amp;quot;. Since I now have several such &amp;quot;old HDDs&amp;quot; I&amp;#39;d like something with essentially that level of ease/convenience, but slightly more robust and future-proof.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1098ij1", "is_robot_indexable": true, "report_reasons": null, "author": "caligari87", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1098ij1/data_storage_neophyte_starting_to_worry_about_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1098ij1/data_storage_neophyte_starting_to_worry_about_my/", "subreddit_subscribers": 665449, "created_utc": 1673453633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to burn mkv files to blu ray as an archive. I'm treating the mkv files as data only, not for play back on a blu ray player. I'm currently using True Burner to burn (multiple) file(s) to a single disk. In order to maximize my blank disks usage I'm looking for a free windows program that can copy multiple mkv files across multiple disk. So for example, if I have 5 files at 20GB each, I'd like to burn them to 2 50GB blu ray disks where one of the files would span across disk 1 and disk 2. Any help is appreciated.\n\nTIA", "author_fullname": "t2_59tlj2i1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a free windows blu ray burning program that spans disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1096bwv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673448081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to burn mkv files to blu ray as an archive. I&amp;#39;m treating the mkv files as data only, not for play back on a blu ray player. I&amp;#39;m currently using True Burner to burn (multiple) file(s) to a single disk. In order to maximize my blank disks usage I&amp;#39;m looking for a free windows program that can copy multiple mkv files across multiple disk. So for example, if I have 5 files at 20GB each, I&amp;#39;d like to burn them to 2 50GB blu ray disks where one of the files would span across disk 1 and disk 2. Any help is appreciated.&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1096bwv", "is_robot_indexable": true, "report_reasons": null, "author": "SurenAbraham", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1096bwv/looking_for_a_free_windows_blu_ray_burning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1096bwv/looking_for_a_free_windows_blu_ray_burning/", "subreddit_subscribers": 665449, "created_utc": 1673448081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "..is there a way to control the quality in yark.\n\n..when i type the command that downloads meta-data and videos (yark refresh) it says downloading 29 videos only does it download more after they're done or what.\n\ni want to download channels from public wifi and be able to control the quality.\n\n\n..so i want to download 100 video or something in one go . and if i canceled my download and tried to download again will it download from the start (the same videos i have already downloaded)\n\n*and sorry for the bad english* .\n\nedit: you can use yt-dlp and set it up the way you like by commands and there an opensource app called **SEAL** it's a gui of yt-dlp.you can adjust quality and also control the how much you want to download of the channel. you can find the app on f-droid", "author_fullname": "t2_ick0udsi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "downloading youtube channels on phone and question about Yark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10969jf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1673450922.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673447904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;..is there a way to control the quality in yark.&lt;/p&gt;\n\n&lt;p&gt;..when i type the command that downloads meta-data and videos (yark refresh) it says downloading 29 videos only does it download more after they&amp;#39;re done or what.&lt;/p&gt;\n\n&lt;p&gt;i want to download channels from public wifi and be able to control the quality.&lt;/p&gt;\n\n&lt;p&gt;..so i want to download 100 video or something in one go . and if i canceled my download and tried to download again will it download from the start (the same videos i have already downloaded)&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;and sorry for the bad english&lt;/em&gt; .&lt;/p&gt;\n\n&lt;p&gt;edit: you can use yt-dlp and set it up the way you like by commands and there an opensource app called &lt;strong&gt;SEAL&lt;/strong&gt; it&amp;#39;s a gui of yt-dlp.you can adjust quality and also control the how much you want to download of the channel. you can find the app on f-droid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10969jf", "is_robot_indexable": true, "report_reasons": null, "author": "galaxi-the-son", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10969jf/downloading_youtube_channels_on_phone_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10969jf/downloading_youtube_channels_on_phone_and/", "subreddit_subscribers": 665449, "created_utc": 1673447904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've heard that NAS HDDs are not made for that on/off and laying around. So I am curious which drives I should buy.\n\nI am planning to buy two external cases and two 4TB drives and keeping them in sync manually with freefilesync.", "author_fullname": "t2_87bhn57g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I buy NAS or normal HDDs for an external case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1092z9q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1673438319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve heard that NAS HDDs are not made for that on/off and laying around. So I am curious which drives I should buy.&lt;/p&gt;\n\n&lt;p&gt;I am planning to buy two external cases and two 4TB drives and keeping them in sync manually with freefilesync.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1092z9q", "is_robot_indexable": true, "report_reasons": null, "author": "pocox3", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1092z9q/should_i_buy_nas_or_normal_hdds_for_an_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1092z9q/should_i_buy_nas_or_normal_hdds_for_an_external/", "subreddit_subscribers": 665449, "created_utc": 1673438319.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}