{"kind": "Listing", "data": {"after": "t3_10hryk9", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking for more things like becoming a better storyteller, organizational strategy, presentation skills, psychology, etc. I\u2019m also interested in anything financial related when it comes to data like how you valuate data. \n\nThings i\u2019ve read that i\u2019ve enjoyed are:\n- storytelling with data by cole\n- team topologies by skelton\n- thinking fast and slow by kahneman\n- resonate by duarte\n\nEdit: I believe there is misunderstanding to my question. I don\u2019t lack communication skills but i know i only know what i know. If there are books or resources out there that can build off what i already have or expand my knowledge or identify gaps i didn\u2019t know i had then i\u2019d like to read it. Things like presentation structure, negotiation strategies, team/organizational structure, goal setting, cognitive bias, etc. are all intangibles that are important when it comes to execution and collaboration.", "author_fullname": "t2_kew1pm23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good soft skill books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i087u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674379066.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674331547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for more things like becoming a better storyteller, organizational strategy, presentation skills, psychology, etc. I\u2019m also interested in anything financial related when it comes to data like how you valuate data. &lt;/p&gt;\n\n&lt;p&gt;Things i\u2019ve read that i\u2019ve enjoyed are:\n- storytelling with data by cole\n- team topologies by skelton\n- thinking fast and slow by kahneman\n- resonate by duarte&lt;/p&gt;\n\n&lt;p&gt;Edit: I believe there is misunderstanding to my question. I don\u2019t lack communication skills but i know i only know what i know. If there are books or resources out there that can build off what i already have or expand my knowledge or identify gaps i didn\u2019t know i had then i\u2019d like to read it. Things like presentation structure, negotiation strategies, team/organizational structure, goal setting, cognitive bias, etc. are all intangibles that are important when it comes to execution and collaboration.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i087u", "is_robot_indexable": true, "report_reasons": null, "author": "Critical_Chart_6513", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i087u/what_are_some_good_soft_skill_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i087u/what_are_some_good_soft_skill_books/", "subreddit_subscribers": 839654, "created_utc": 1674331547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We get spammed these questions every day, and the answer is always the same.\n\nTons of resources out there for you to fix your resume. And getting your first job is a numbers games and more about how a hiring manager vibes with you.", "author_fullname": "t2_aji4iba3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There\u2019s a weekly thread for entering DS for a reason, new grads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ibi89", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674363564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We get spammed these questions every day, and the answer is always the same.&lt;/p&gt;\n\n&lt;p&gt;Tons of resources out there for you to fix your resume. And getting your first job is a numbers games and more about how a hiring manager vibes with you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ibi89", "is_robot_indexable": true, "report_reasons": null, "author": "whowasphones", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ibi89/theres_a_weekly_thread_for_entering_ds_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ibi89/theres_a_weekly_thread_for_entering_ds_for_a/", "subreddit_subscribers": 839654, "created_utc": 1674363564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I'm trying to learn data science techniques and have just started looking at PCA. I'm seeing that the principle components are biased towards data features which are numerically large. E.g. for a dataset with estate prices and estate sqft, PCA essentially returns these two columns due to them being numerically far apart.\n\nSorry for the noob question, but I thought that PCA was good because it shed insight into interesting bits of the dataset. However, if some feature has a huge stddev/mean (i.e. is interesting), but a small absolute stddev, that gets lost, right? So, is PCA only good for similarly-sized data? Or is there some way of fixing this? Thanks!", "author_fullname": "t2_at5kn849", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCA [Beginner Question]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i3hav", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674339878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m trying to learn data science techniques and have just started looking at PCA. I&amp;#39;m seeing that the principle components are biased towards data features which are numerically large. E.g. for a dataset with estate prices and estate sqft, PCA essentially returns these two columns due to them being numerically far apart.&lt;/p&gt;\n\n&lt;p&gt;Sorry for the noob question, but I thought that PCA was good because it shed insight into interesting bits of the dataset. However, if some feature has a huge stddev/mean (i.e. is interesting), but a small absolute stddev, that gets lost, right? So, is PCA only good for similarly-sized data? Or is there some way of fixing this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i3hav", "is_robot_indexable": true, "report_reasons": null, "author": "Angry-Refrigerator", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i3hav/pca_beginner_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i3hav/pca_beginner_question/", "subreddit_subscribers": 839654, "created_utc": 1674339878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_jp6tbwl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Polars: a side-by-side comparison with Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10htp8l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9_LgBGpqUzmh9bAo2RAfypt7FU2j9MSgJMbXRQq_wtw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674314865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kevinheavey.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://kevinheavey.github.io/modern-polars/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?auto=webp&amp;v=enabled&amp;s=e172cb2c8b8342f9858ccc933693a9601a4f37c6", "width": 1080, "height": 566}, "resolutions": [{"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1d86b8271f00750615149fe484387d8e812ac44", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0043fc64683cc464a42e0f8a1a401acfaae145b9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84e108b0c589bf4d7d45e9fa6be1d8db47cd1ed8", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a0ea2c22ba3c042c1338cbec53d07c31dbb91ec", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=803d10ae4fed3973709ed16f0431d08a51919e71", "width": 960, "height": 503}, {"url": "https://external-preview.redd.it/yTuWoq2KxDZALIoNNoqWgb7aQvMHf_TxH9y-Af3HW3k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fa5ff6f59831e295eba7d286e1bc9185f822a0e", "width": 1080, "height": 566}], "variants": {}, "id": "SfIIgBAKCbAiziNUXnWi5vw-pNTYB2nZiv9y9d0YzDo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10htp8l", "is_robot_indexable": true, "report_reasons": null, "author": "caoimhin_o_h", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10htp8l/modern_polars_a_sidebyside_comparison_with_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kevinheavey.github.io/modern-polars/", "subreddit_subscribers": 839654, "created_utc": 1674314865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, \n\nI have recently created a Bayesian optimization community [https://www.reddit.com/r/BayesianOptimization/](https://www.reddit.com/r/BayesianOptimization/) Please join if you are interested on this topic.\n\n&amp;#x200B;\n\nBest,", "author_fullname": "t2_3mrai41f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bayesian optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hndoz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674293321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I have recently created a Bayesian optimization community &lt;a href=\"https://www.reddit.com/r/BayesianOptimization/\"&gt;https://www.reddit.com/r/BayesianOptimization/&lt;/a&gt; Please join if you are interested on this topic.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Best,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hndoz", "is_robot_indexable": true, "report_reasons": null, "author": "EduCGM", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hndoz/bayesian_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hndoz/bayesian_optimization/", "subreddit_subscribers": 839654, "created_utc": 1674293321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to use an example of gambling but this scenario actually applies to a more complex problem I am facing at work regarding contracts and budgets.  I am a practicing data scientist so the more technical the answer the better.  Bonus for links to git for code to look over.  Thanks in advance.\n\nLet's say I make a regression model that predicts margin of victory for all the NFL games on some weekend.  I compare those results to the advertised spread of each game and determine how I want to bet each game based on the spread.  I now have $1000 I can bet in total for the week.  Can I do something with the results of my model to optimize my asset allocation on each game?  For example, I may order my bets by largest delta between prediction and spread. The larger the delta then the more confident that my model is correct. For example in game 1, team A is picked to win by 5 points and my model says 10 points over team B.  In game 2, team C is picked to win by 5 points but my model says 6 over team D.  I interpret that as my model is more confident that game 1 will cover.\n\nI am struggling to come up with a way to quantify a deterministic method to spread my $1000 over all the games.  For the sake of simplicity, lets assume I have to spread all $1000 over 16 games to maximize my ROI.\n\nI may be over thinking this but any help would be appreciated.", "author_fullname": "t2_vn5j2lus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predict optimal asset allocation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hs979", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674313376.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674310731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to use an example of gambling but this scenario actually applies to a more complex problem I am facing at work regarding contracts and budgets.  I am a practicing data scientist so the more technical the answer the better.  Bonus for links to git for code to look over.  Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I make a regression model that predicts margin of victory for all the NFL games on some weekend.  I compare those results to the advertised spread of each game and determine how I want to bet each game based on the spread.  I now have $1000 I can bet in total for the week.  Can I do something with the results of my model to optimize my asset allocation on each game?  For example, I may order my bets by largest delta between prediction and spread. The larger the delta then the more confident that my model is correct. For example in game 1, team A is picked to win by 5 points and my model says 10 points over team B.  In game 2, team C is picked to win by 5 points but my model says 6 over team D.  I interpret that as my model is more confident that game 1 will cover.&lt;/p&gt;\n\n&lt;p&gt;I am struggling to come up with a way to quantify a deterministic method to spread my $1000 over all the games.  For the sake of simplicity, lets assume I have to spread all $1000 over 16 games to maximize my ROI.&lt;/p&gt;\n\n&lt;p&gt;I may be over thinking this but any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hs979", "is_robot_indexable": true, "report_reasons": null, "author": "Glass-Umpire4456", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hs979/predict_optimal_asset_allocation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hs979/predict_optimal_asset_allocation/", "subreddit_subscribers": 839654, "created_utc": 1674310731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI've been trying to find my first job since last summer but so far no luck. I've tried everything, from changing my resume multiple times to contacting my friends and even random people on LinkedIn for referrals. The problem is that I hardly get calls from recruiters and I've easily applied for over 500 jobs till now.\n\nAbout 2 weeks ago, I started making targeted resumes (using Job Scan) for every job that I've applied for but so far no one has contacted me. Only rejection after rejection. The mortgage for my student loan will start in April this year and I'm starting to freak out thinking that I'll never even be able to start my career.\n\nAt this point, I'm very close to giving up but just wanted to try one last time. Please let me know if I'm making any mistakes.\n\nBelow is the last job I applied for with a targeted resume and I always follow the same pattern.\n\n&amp;#x200B;\n\n**Job Description**\n\nWhat You\u2019ll Do:-\n\n*ABC Company's* Data Science Program will provide you with an opportunity to develop broad analytical expertise, work cross functionally with internal and external teams, and be a key member of our data analytics team. This development program is designed to be a launch pad for a fulfilling and successful career at *ABC Company*, helping us to continue to build an innovative, world-class *ABC Company* Retail team. The program consists of three progressive eight-month rotations in Merchandising Decision Support, Experimentation, and Data Management &amp; Business Intelligence.\n\nThe associate will perform a variety of activities within the rotations related to Data Science &amp; Analytics. These activities may include:\n\nData Science/Advanced Analytics: Provide subject matter expertise and create a broad range of data driven solutions by applying a variety of techniques to build out complex models.\n\nBusiness Insight Analyst: Responsible for providing subject matter expertise, analytics, and insights to recommend actions that will enable optimal business decisions and/or resolve complex business problems. Identify opportunities to drive business growth &amp; value.\n\nVisualization: Provide data visualization expertise and interpretation of data into meaningful insights or visuals to help facilitate business understanding of outcomes and recommendations.\n\nBusiness Intelligence: Responsible for the design/development of complex reports, dashboards, and scorecards to support business needs; ensure alignment of metrics across the organization.\n\nData Management: Participating in projects by analyzing approaches, processes, and tools to support the business data strategy.\n\n&amp;#x200B;\n\nWho You Are:-\n\n1. Creative and courageous, with the ability to manage in an environment of change and ambiguity to help us take bold, strategic moves in this rapidly evolving retail environment.\n2. Action oriented, and comfortable taking calculated risks to better serve our customers and business.\n3. Critical thinkers with the ability to analyze and visualize, to ensure continuous improvement across our entire business.\n4. Collaborative team players with superior communication and influencing skills, who build relationships easily across various stakeholder groups.\n5. If you\u2019re curious, ready to take on new challenges and open to doing things differently to help us evolve rapidly \u2013 we are looking for you.\n\n&amp;#x200B;\n\nWhat You\u2019ll Bring:-\n\n1. You have an undergraduate degree in Computer Science, Mathematics, Engineering, Quantitative Analysis, Statistics, Data Analytics or a related field and graduating between May 2021 - May 2023. Strong statistical/analytical skills are preferred.\n2. Well-versed in one or more of these listed areas: Big Data - Predictive Analytics, Optimization, Regression, Logit Modeling, Discrete choice, Simulation, Propensity Modeling; Machine Learning \u2013 Data/Text Mining, Programming, Algorithm Development, Automation Data Visualization, Natural Language Processing.\n3. Excellent verbal &amp; written communication with the ability to work and collaborate effectively in a team environment.\n4. Possess technical knowledge and on hand experience with SQL, Python, Hadoop, Spark, and Azure Cloud Tools.\n\n&amp;#x200B;\n\n[Targeted Resume Page #1](https://preview.redd.it/0zoggvsvshda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ceaa039e808ee4018826d3f529f4b373990d2b63)\n\n&amp;#x200B;\n\n[Targeted Resume Page #2](https://preview.redd.it/b07xsp2xshda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8e3e641bb1c2043628048133fd2075d562349020)\n\n&amp;#x200B;\n\n[Job Scan Report](https://preview.redd.it/6kni6z0zshda1.jpg?width=327&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9af655e16835992a8a2ea090536fe24627cc9c3c)", "author_fullname": "t2_cu2b1sid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dear Hiring Managers, please help me \ud83d\ude4f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0zoggvsvshda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66852236b8ca8c9aa4a254f4030c22c7a145bc59"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d81564a72ee54e4fc85d108e357b18a82d74c16"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b95c9a022527dc9846d51d45db4dbddd123cca3f"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf8568ceb1548aa9fb097a2a76061bbee4336042"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=deb2cbabf9c458514948621e5e21d053282c6d0d"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32a7ae95eeead4f3dcaf377b40ec82ae786ff0b0"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/0zoggvsvshda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ceaa039e808ee4018826d3f529f4b373990d2b63"}, "id": "0zoggvsvshda1"}, "b07xsp2xshda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 139, "x": 108, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26dfaccb7072aea2e0b4b58783338775e0c51285"}, {"y": 279, "x": 216, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75096b4ca53400769f0a0da77c4cbbc532a99e7b"}, {"y": 414, "x": 320, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04d1a967a8633feb61ebe5e45cbd08361a2743f0"}, {"y": 828, "x": 640, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d54b26819ef5bfb56fbe6ac40316a4b50a6f9ff"}, {"y": 1242, "x": 960, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83954c68e7b000aa76a9c5968b67394ffec810cc"}, {"y": 1397, "x": 1080, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30e32ab2743e9b8e4caebbd6ff6914f7ba8908c4"}], "s": {"y": 2200, "x": 1700, "u": "https://preview.redd.it/b07xsp2xshda1.jpg?width=1700&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8e3e641bb1c2043628048133fd2075d562349020"}, "id": "b07xsp2xshda1"}, "6kni6z0zshda1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 121, "x": 108, "u": "https://preview.redd.it/6kni6z0zshda1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe6ddfff47a0bf5d432767d55bcf57768c7d9e64"}, {"y": 243, "x": 216, "u": "https://preview.redd.it/6kni6z0zshda1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5e5dd02ae781ce3f07a3e3bcfca4295d168bdaa"}, {"y": 360, "x": 320, "u": "https://preview.redd.it/6kni6z0zshda1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eaa920303e1292807efcc521144e22299b0fa893"}], "s": {"y": 368, "x": 327, "u": "https://preview.redd.it/6kni6z0zshda1.jpg?width=327&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9af655e16835992a8a2ea090536fe24627cc9c3c"}, "id": "6kni6z0zshda1"}}, "name": "t3_10i6qed", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lFzUEAfFX92KoSUD86tdTiIrhsR11jrLyQJCdtxyIIs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674348772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to find my first job since last summer but so far no luck. I&amp;#39;ve tried everything, from changing my resume multiple times to contacting my friends and even random people on LinkedIn for referrals. The problem is that I hardly get calls from recruiters and I&amp;#39;ve easily applied for over 500 jobs till now.&lt;/p&gt;\n\n&lt;p&gt;About 2 weeks ago, I started making targeted resumes (using Job Scan) for every job that I&amp;#39;ve applied for but so far no one has contacted me. Only rejection after rejection. The mortgage for my student loan will start in April this year and I&amp;#39;m starting to freak out thinking that I&amp;#39;ll never even be able to start my career.&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;m very close to giving up but just wanted to try one last time. Please let me know if I&amp;#39;m making any mistakes.&lt;/p&gt;\n\n&lt;p&gt;Below is the last job I applied for with a targeted resume and I always follow the same pattern.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Job Description&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;What You\u2019ll Do:-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;ABC Company&amp;#39;s&lt;/em&gt; Data Science Program will provide you with an opportunity to develop broad analytical expertise, work cross functionally with internal and external teams, and be a key member of our data analytics team. This development program is designed to be a launch pad for a fulfilling and successful career at &lt;em&gt;ABC Company&lt;/em&gt;, helping us to continue to build an innovative, world-class &lt;em&gt;ABC Company&lt;/em&gt; Retail team. The program consists of three progressive eight-month rotations in Merchandising Decision Support, Experimentation, and Data Management &amp;amp; Business Intelligence.&lt;/p&gt;\n\n&lt;p&gt;The associate will perform a variety of activities within the rotations related to Data Science &amp;amp; Analytics. These activities may include:&lt;/p&gt;\n\n&lt;p&gt;Data Science/Advanced Analytics: Provide subject matter expertise and create a broad range of data driven solutions by applying a variety of techniques to build out complex models.&lt;/p&gt;\n\n&lt;p&gt;Business Insight Analyst: Responsible for providing subject matter expertise, analytics, and insights to recommend actions that will enable optimal business decisions and/or resolve complex business problems. Identify opportunities to drive business growth &amp;amp; value.&lt;/p&gt;\n\n&lt;p&gt;Visualization: Provide data visualization expertise and interpretation of data into meaningful insights or visuals to help facilitate business understanding of outcomes and recommendations.&lt;/p&gt;\n\n&lt;p&gt;Business Intelligence: Responsible for the design/development of complex reports, dashboards, and scorecards to support business needs; ensure alignment of metrics across the organization.&lt;/p&gt;\n\n&lt;p&gt;Data Management: Participating in projects by analyzing approaches, processes, and tools to support the business data strategy.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Who You Are:-&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Creative and courageous, with the ability to manage in an environment of change and ambiguity to help us take bold, strategic moves in this rapidly evolving retail environment.&lt;/li&gt;\n&lt;li&gt;Action oriented, and comfortable taking calculated risks to better serve our customers and business.&lt;/li&gt;\n&lt;li&gt;Critical thinkers with the ability to analyze and visualize, to ensure continuous improvement across our entire business.&lt;/li&gt;\n&lt;li&gt;Collaborative team players with superior communication and influencing skills, who build relationships easily across various stakeholder groups.&lt;/li&gt;\n&lt;li&gt;If you\u2019re curious, ready to take on new challenges and open to doing things differently to help us evolve rapidly \u2013 we are looking for you.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What You\u2019ll Bring:-&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;You have an undergraduate degree in Computer Science, Mathematics, Engineering, Quantitative Analysis, Statistics, Data Analytics or a related field and graduating between May 2021 - May 2023. Strong statistical/analytical skills are preferred.&lt;/li&gt;\n&lt;li&gt;Well-versed in one or more of these listed areas: Big Data - Predictive Analytics, Optimization, Regression, Logit Modeling, Discrete choice, Simulation, Propensity Modeling; Machine Learning \u2013 Data/Text Mining, Programming, Algorithm Development, Automation Data Visualization, Natural Language Processing.&lt;/li&gt;\n&lt;li&gt;Excellent verbal &amp;amp; written communication with the ability to work and collaborate effectively in a team environment.&lt;/li&gt;\n&lt;li&gt;Possess technical knowledge and on hand experience with SQL, Python, Hadoop, Spark, and Azure Cloud Tools.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0zoggvsvshda1.jpg?width=1700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ceaa039e808ee4018826d3f529f4b373990d2b63\"&gt;Targeted Resume Page #1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b07xsp2xshda1.jpg?width=1700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8e3e641bb1c2043628048133fd2075d562349020\"&gt;Targeted Resume Page #2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6kni6z0zshda1.jpg?width=327&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9af655e16835992a8a2ea090536fe24627cc9c3c\"&gt;Job Scan Report&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10i6qed", "is_robot_indexable": true, "report_reasons": null, "author": "zombie_ie_ie", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i6qed/dear_hiring_managers_please_help_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i6qed/dear_hiring_managers_please_help_me/", "subreddit_subscribers": 839654, "created_utc": 1674348772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company has what is analogous to a monthly sales forecasting model. We have used ARIMA-type models for this, but sometimes are hampered by the somewhat limited data (200 data points if we are lucky.) \n\nGiven the rise of global time series models, they may prove helpful here. My thinking would be to disaggregate historical sales by store, train a global model that projects sales volume by store, and then aggregate the forecasts to achieve a total volume forecast. We wouldn't necessarily care about any individual store's forecast, only the aggregate forecast. Having +200 stores, we could increase the data size to multiple thousands and potentially use some more data hungry models. Is anyone aware of research or resources that use a global model to project an aggregated time series? \n\nSecond, the \"cold start\" problem gets introduced in an approach like this. The problem being how do we forecast a new store's sales volume without retraining the model? My thinking is that we could use some sort of clustering technique to identify an existing store the new store is most similar too and make some assumptions about how it will behave. \n\nAnyways, I haven't used global models before, so just looking for thoughts or resources from the community.", "author_fullname": "t2_2x1e09nw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Global Time Series Model to project an aggregate series and the cold start problem.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hz0c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674328461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has what is analogous to a monthly sales forecasting model. We have used ARIMA-type models for this, but sometimes are hampered by the somewhat limited data (200 data points if we are lucky.) &lt;/p&gt;\n\n&lt;p&gt;Given the rise of global time series models, they may prove helpful here. My thinking would be to disaggregate historical sales by store, train a global model that projects sales volume by store, and then aggregate the forecasts to achieve a total volume forecast. We wouldn&amp;#39;t necessarily care about any individual store&amp;#39;s forecast, only the aggregate forecast. Having +200 stores, we could increase the data size to multiple thousands and potentially use some more data hungry models. Is anyone aware of research or resources that use a global model to project an aggregated time series? &lt;/p&gt;\n\n&lt;p&gt;Second, the &amp;quot;cold start&amp;quot; problem gets introduced in an approach like this. The problem being how do we forecast a new store&amp;#39;s sales volume without retraining the model? My thinking is that we could use some sort of clustering technique to identify an existing store the new store is most similar too and make some assumptions about how it will behave. &lt;/p&gt;\n\n&lt;p&gt;Anyways, I haven&amp;#39;t used global models before, so just looking for thoughts or resources from the community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hz0c2", "is_robot_indexable": true, "report_reasons": null, "author": "a157reverse", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hz0c2/global_time_series_model_to_project_an_aggregate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hz0c2/global_time_series_model_to_project_an_aggregate/", "subreddit_subscribers": 839654, "created_utc": 1674328461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am interested in Neurodivergence and some areas in Psychology. I also have a Pure Maths Background and intend to study Data Science. How can I get to work with Psychiatrists in this field and various Psychologists. Is there anyone here who can share their experience?", "author_fullname": "t2_3v0g0k3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science in Psychiatry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i86ia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674352977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in Neurodivergence and some areas in Psychology. I also have a Pure Maths Background and intend to study Data Science. How can I get to work with Psychiatrists in this field and various Psychologists. Is there anyone here who can share their experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i86ia", "is_robot_indexable": true, "report_reasons": null, "author": "FairandStyle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i86ia/data_science_in_psychiatry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i86ia/data_science_in_psychiatry/", "subreddit_subscribers": 839654, "created_utc": 1674352977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "You have two dies that have no numbers on them. You can put any number on any side of each dice. The goal is to have the distribution of the sum of these two dies follow a uniform distribution and contain all the values up to 12. How would you go about solving that?", "author_fullname": "t2_25zr79a1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make the sum of two dies uniform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i3t3y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674340745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You have two dies that have no numbers on them. You can put any number on any side of each dice. The goal is to have the distribution of the sum of these two dies follow a uniform distribution and contain all the values up to 12. How would you go about solving that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i3t3y", "is_robot_indexable": true, "report_reasons": null, "author": "hosseinxj0152", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i3t3y/how_to_make_the_sum_of_two_dies_uniform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i3t3y/how_to_make_the_sum_of_two_dies_uniform/", "subreddit_subscribers": 839654, "created_utc": 1674340745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My friend recently interviewed for a data science job where they asked him to open up an IDE and code up a neural network from scratch (only using numpy, no other libraries). This got me thinking, how common is this across industry for data science roles? Like realistically do tons of companies just ask you to code up logistic regression or SVM, or do they test more of your conceptual/mathematical understanding. Is coding these algorithms from scratch using numpy something I should invest time in, or is it just a select minority of companies that might ask?", "author_fullname": "t2_fjqhhwcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coding ML Algorithms from Scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ibxfj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674364994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend recently interviewed for a data science job where they asked him to open up an IDE and code up a neural network from scratch (only using numpy, no other libraries). This got me thinking, how common is this across industry for data science roles? Like realistically do tons of companies just ask you to code up logistic regression or SVM, or do they test more of your conceptual/mathematical understanding. Is coding these algorithms from scratch using numpy something I should invest time in, or is it just a select minority of companies that might ask?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ibxfj", "is_robot_indexable": true, "report_reasons": null, "author": "Unlucky_Mountain4918", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ibxfj/coding_ml_algorithms_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ibxfj/coding_ml_algorithms_from_scratch/", "subreddit_subscribers": 839654, "created_utc": 1674364994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This semester I am finishing up my undergraduate degree and have accepted a full-time position as a Data Scientist. I also have a part-time online master's admission from a top 5 school in Data Science. Since I am continuing my education and have a 3-month summer with no work lined up I was thinking of getting an internship in the DS/DA domain once again.\n\nIs this ethical or would my future employer rescind my full-time offer if they find out (Through Linkedin)?\n\nI have a decent full-time offer so I don't want to burn down any bridges for 3 months of work as an intern.\n\n\\&gt;This would be my 3rd paid DS internship\n\n[View Poll](https://www.reddit.com/poll/10i84im)", "author_fullname": "t2_6gpihliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it legal/morally ethical to do an internship prior to starting Full-Time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i84im", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674352817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This semester I am finishing up my undergraduate degree and have accepted a full-time position as a Data Scientist. I also have a part-time online master&amp;#39;s admission from a top 5 school in Data Science. Since I am continuing my education and have a 3-month summer with no work lined up I was thinking of getting an internship in the DS/DA domain once again.&lt;/p&gt;\n\n&lt;p&gt;Is this ethical or would my future employer rescind my full-time offer if they find out (Through Linkedin)?&lt;/p&gt;\n\n&lt;p&gt;I have a decent full-time offer so I don&amp;#39;t want to burn down any bridges for 3 months of work as an intern.&lt;/p&gt;\n\n&lt;p&gt;&amp;gt;This would be my 3rd paid DS internship&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10i84im\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "10i84im", "is_robot_indexable": true, "report_reasons": null, "author": "wardrobe_creator", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1674612017779, "options": [{"text": "Doesn't matter. Get an internship", "id": "21160760"}, {"text": "Not worth the risk.", "id": "21160761"}, {"text": "\ud83c\udf7f", "id": "21160762"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 416, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i84im/is_it_legalmorally_ethical_to_do_an_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/10i84im/is_it_legalmorally_ethical_to_do_an_internship/", "subreddit_subscribers": 839654, "created_utc": 1674352817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for books that'll help me approach data-related problems effectively. Especially books related to critical thinking, problem-solving, segmenting and sequencing problems into chunks, and asking questions.  \n\n\nAny info would be greatly appreciated.\n\nThanks in advance!", "author_fullname": "t2_h2124m47", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Books to refine my thought process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i2sab", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674338087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for books that&amp;#39;ll help me approach data-related problems effectively. Especially books related to critical thinking, problem-solving, segmenting and sequencing problems into chunks, and asking questions.  &lt;/p&gt;\n\n&lt;p&gt;Any info would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i2sab", "is_robot_indexable": true, "report_reasons": null, "author": "nutherlove", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i2sab/books_to_refine_my_thought_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i2sab/books_to_refine_my_thought_process/", "subreddit_subscribers": 839654, "created_utc": 1674338087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all!\n\nI\u2019m currently working on my MS in Data Science and I\u2019m learning a ton of Python. I\u2019m comfortable with my understanding of the material we\u2019ve learned so far, so I\u2019m looking to work ahead and just make sure I have an excellent foundation. \n\nI\u2019m having a hard time trying to figure out what\u2019s actually valuable to learn for someone trying to work in DS in the future. I don\u2019t want to spend my time learning things that would be most useful for a Software Engineer or Developer when I could ensure my DS toolkit is very well equipped. \n\nI know visualization, data cleaning and statistics are areas that are key to being a good DS, but I know they\u2019re part of my masters curriculum. However, I\u2019m not sure something like Data Structures and Algorithms would be a part of it. Would something like that be valuable to invest some time into?", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differentiating what Python knowledge a DS would need vs. a developer/engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hu7sz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674316268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently working on my MS in Data Science and I\u2019m learning a ton of Python. I\u2019m comfortable with my understanding of the material we\u2019ve learned so far, so I\u2019m looking to work ahead and just make sure I have an excellent foundation. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m having a hard time trying to figure out what\u2019s actually valuable to learn for someone trying to work in DS in the future. I don\u2019t want to spend my time learning things that would be most useful for a Software Engineer or Developer when I could ensure my DS toolkit is very well equipped. &lt;/p&gt;\n\n&lt;p&gt;I know visualization, data cleaning and statistics are areas that are key to being a good DS, but I know they\u2019re part of my masters curriculum. However, I\u2019m not sure something like Data Structures and Algorithms would be a part of it. Would something like that be valuable to invest some time into?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hu7sz", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hu7sz/differentiating_what_python_knowledge_a_ds_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hu7sz/differentiating_what_python_knowledge_a_ds_would/", "subreddit_subscribers": 839654, "created_utc": 1674316268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a data scientist, what is your worst day? What carrier related event can happen to ruin your day?", "author_fullname": "t2_vmjrs95x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a bad day", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ho9xv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674296882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data scientist, what is your worst day? What carrier related event can happen to ruin your day?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ho9xv", "is_robot_indexable": true, "report_reasons": null, "author": "Naadiyaar", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ho9xv/what_is_a_bad_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ho9xv/what_is_a_bad_day/", "subreddit_subscribers": 839654, "created_utc": 1674296882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone. I'm 29 years old and thinking of upgrading my skillset to apply for any junior data analyst job. I'm currently working in sales/admin in a travel company. I graduated 4 years ago with a biochem degree so I don't really have any background in CS.\n\nI feel like the work that I've been doing has become mundane and don't see myself working here for 10-20 years. I've worked with data back in uni but that's pretty much it. \n\nI started learning Python a few weeks ago. I absolutely love it and it really taught me a new way to think.\n\nIs it realistic to switch career to data analyst or any data-related roles if I don't have any prior experience working in the industry?", "author_fullname": "t2_1szzkj1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career shift to data-related role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ieqt9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674375593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I&amp;#39;m 29 years old and thinking of upgrading my skillset to apply for any junior data analyst job. I&amp;#39;m currently working in sales/admin in a travel company. I graduated 4 years ago with a biochem degree so I don&amp;#39;t really have any background in CS.&lt;/p&gt;\n\n&lt;p&gt;I feel like the work that I&amp;#39;ve been doing has become mundane and don&amp;#39;t see myself working here for 10-20 years. I&amp;#39;ve worked with data back in uni but that&amp;#39;s pretty much it. &lt;/p&gt;\n\n&lt;p&gt;I started learning Python a few weeks ago. I absolutely love it and it really taught me a new way to think.&lt;/p&gt;\n\n&lt;p&gt;Is it realistic to switch career to data analyst or any data-related roles if I don&amp;#39;t have any prior experience working in the industry?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ieqt9", "is_robot_indexable": true, "report_reasons": null, "author": "iqbalmatyaakob", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ieqt9/career_shift_to_datarelated_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ieqt9/career_shift_to_datarelated_role/", "subreddit_subscribers": 839654, "created_utc": 1674375593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What percentage of your time is learning new stuff vs doing stuff you already know? I\u2019ve been spending a ton of time at my job learning new things and wondering if that is normal for this career?", "author_fullname": "t2_9zsgof9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What percentage of your time is spent learning new things (ie new technologies, studying stats etc)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ic2ru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674365513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What percentage of your time is learning new stuff vs doing stuff you already know? I\u2019ve been spending a ton of time at my job learning new things and wondering if that is normal for this career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ic2ru", "is_robot_indexable": true, "report_reasons": null, "author": "miketythhon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ic2ru/what_percentage_of_your_time_is_spent_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ic2ru/what_percentage_of_your_time_is_spent_learning/", "subreddit_subscribers": 839654, "created_utc": 1674365513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_115ako", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good online websites for teaching myself machine learning? (I already have a strong programming background, and know Python like the back of my hand). Thanks.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i7kxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674351202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i7kxo", "is_robot_indexable": true, "report_reasons": null, "author": "secretid89", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i7kxo/what_are_some_good_online_websites_for_teaching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i7kxo/what_are_some_good_online_websites_for_teaching/", "subreddit_subscribers": 839654, "created_utc": 1674351202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Blog post: [https://anywidget.dev/blog/introducing-anywidget](https://anywidget.dev/blog/introducing-anywidget)\n\nGitHub: [https://github.com/manzt/anywidget](https://github.com/manzt/anywidget)\n\nHi all \u2013 I'm excited to introduce **anywidget**, a new Python library that makes creating and sharing custom [Jupyter Widgets](https://ipywidgets.readthedocs.io/en/stable/) easy. No fiddling with messy build configs, packaging, or bundlers. Just start coding!\n\n**anywidget** is *not* a new widgets framework, but rather an abstraction around regular Jupyter Widgets that leverages modern [ECMAScript modules (ESM)](https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/). It solves a painful packaging problem for all previous widget authors, lowering the barrier to entry for many Python devs with limited front-end experience.\n\nThe project is new and still under active development, but ready for testing. Learn more in the [announcement](https://anywidget.dev/blog/introducing-anywidget) or on [GitHub](https://github.com/manzt/anywidget).", "author_fullname": "t2_gdvju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing anywidget: Custom Jupyter Widgets Made Easy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hy1bz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674326051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Blog post: &lt;a href=\"https://anywidget.dev/blog/introducing-anywidget\"&gt;https://anywidget.dev/blog/introducing-anywidget&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub: &lt;a href=\"https://github.com/manzt/anywidget\"&gt;https://github.com/manzt/anywidget&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi all \u2013 I&amp;#39;m excited to introduce &lt;strong&gt;anywidget&lt;/strong&gt;, a new Python library that makes creating and sharing custom &lt;a href=\"https://ipywidgets.readthedocs.io/en/stable/\"&gt;Jupyter Widgets&lt;/a&gt; easy. No fiddling with messy build configs, packaging, or bundlers. Just start coding!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;anywidget&lt;/strong&gt; is &lt;em&gt;not&lt;/em&gt; a new widgets framework, but rather an abstraction around regular Jupyter Widgets that leverages modern &lt;a href=\"https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/\"&gt;ECMAScript modules (ESM)&lt;/a&gt;. It solves a painful packaging problem for all previous widget authors, lowering the barrier to entry for many Python devs with limited front-end experience.&lt;/p&gt;\n\n&lt;p&gt;The project is new and still under active development, but ready for testing. Learn more in the &lt;a href=\"https://anywidget.dev/blog/introducing-anywidget\"&gt;announcement&lt;/a&gt; or on &lt;a href=\"https://github.com/manzt/anywidget\"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?auto=webp&amp;v=enabled&amp;s=80a9f63098746557df8574789147335128d53999", "width": 2994, "height": 1342}, "resolutions": [{"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e6e930ec81588d20d82e92bcda459f01cd2bb08", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=536dd955afc83cfcbc9808b20e1796a5e53ab9a8", "width": 216, "height": 96}, {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c2dc560980b240c8d1ac20502aa2b04db8ed660", "width": 320, "height": 143}, {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15aa398e4e135479e1a6b5725b78ebe5a2c247c4", "width": 640, "height": 286}, {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12167624c5df39e5765629075c61136a7b47d9c9", "width": 960, "height": 430}, {"url": "https://external-preview.redd.it/0YSrzMRORlxgjwuUoXpn8iGc5IJjNwOKmS_u5kzjWgQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6996960606d380e7d7d103adf2a355a4a6b2b75", "width": 1080, "height": 484}], "variants": {}, "id": "93BBXcVYycswo7uPWdpSN9f4u7MmphlqPCbCeGH3m3o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hy1bz", "is_robot_indexable": true, "report_reasons": null, "author": "manzt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hy1bz/introducing_anywidget_custom_jupyter_widgets_made/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hy1bz/introducing_anywidget_custom_jupyter_widgets_made/", "subreddit_subscribers": 839654, "created_utc": 1674326051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Link [here.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Q] Why is there no Beta value (Power Analysis) mentioned in the null hypothesis test in this method?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hpgb3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674301588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Link &lt;a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\"&gt;here.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hpgb3", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hpgb3/q_why_is_there_no_beta_value_power_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hpgb3/q_why_is_there_no_beta_value_power_analysis/", "subreddit_subscribers": 839654, "created_utc": 1674301588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " The course is about to start in January, and if we set up a Whatsapp group or Discord, we can replicate a 'classroom' environment.\n\nA bit about me: I'm a mechanical engineering graduate from Cape Town, South Africa now working as Data Scientist/Data Analyst/Data engineer in a Fintech startup. I'm studying this course because I just know first-year stats.", "author_fullname": "t2_vmnhefbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone interested in studying MITs micromasters in Statistics and Data Science. How about a study group?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10idot3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674371455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The course is about to start in January, and if we set up a Whatsapp group or Discord, we can replicate a &amp;#39;classroom&amp;#39; environment.&lt;/p&gt;\n\n&lt;p&gt;A bit about me: I&amp;#39;m a mechanical engineering graduate from Cape Town, South Africa now working as Data Scientist/Data Analyst/Data engineer in a Fintech startup. I&amp;#39;m studying this course because I just know first-year stats.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10idot3", "is_robot_indexable": true, "report_reasons": null, "author": "tootieloolie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10idot3/is_anyone_interested_in_studying_mits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10idot3/is_anyone_interested_in_studying_mits/", "subreddit_subscribers": 839654, "created_utc": 1674371455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I love to learn about ai and use the to create new things. I started learning python  and want the resources to become data scientist. I used to read the posts in this group and ive seen lot of people others ro clear the doubts in ds stream. To all the data scientists and analyists please provide me resources. I will note everything and will start the journey. \n\nThank you", "author_fullname": "t2_tq314yjs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources to become Data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10idmfl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674371211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love to learn about ai and use the to create new things. I started learning python  and want the resources to become data scientist. I used to read the posts in this group and ive seen lot of people others ro clear the doubts in ds stream. To all the data scientists and analyists please provide me resources. I will note everything and will start the journey. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10idmfl", "is_robot_indexable": true, "report_reasons": null, "author": "DetectiveInformal214", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10idmfl/resources_to_become_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10idmfl/resources_to_become_data_scientist/", "subreddit_subscribers": 839654, "created_utc": 1674371211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I am relatively very new to R so apologies for the redundancy. \n\nI have a file with trade data from Can to USA for a few years. The data shows exact amounts from two points example ( Ontario-Alabama, Ontario-California). The observations are monthly. I have to update the file with new observations (latest in the file as of now in Jun 2021). I was wondering if there is anyway to write a script that could match the destinations and plug in the new observations where they belong. Any help would be greatly appreciated as I would really hate to do it the old-school paste way (for the sake of my sanity lol) Thank you!", "author_fullname": "t2_8imefv4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data updating project help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10iazv8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674361829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am relatively very new to R so apologies for the redundancy. &lt;/p&gt;\n\n&lt;p&gt;I have a file with trade data from Can to USA for a few years. The data shows exact amounts from two points example ( Ontario-Alabama, Ontario-California). The observations are monthly. I have to update the file with new observations (latest in the file as of now in Jun 2021). I was wondering if there is anyway to write a script that could match the destinations and plug in the new observations where they belong. Any help would be greatly appreciated as I would really hate to do it the old-school paste way (for the sake of my sanity lol) Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10iazv8", "is_robot_indexable": true, "report_reasons": null, "author": "Afraid-Confidence683", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10iazv8/data_updating_project_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10iazv8/data_updating_project_help/", "subreddit_subscribers": 839654, "created_utc": 1674361829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If one has a dataset on 400 individuals through time. \n\nX variables are: person ID, age group (Binary i.e OLD 1 and Young 2), average calories eaten in a day, the average amount of cigarettes smoked in a day, and the average amount of dentist appointments in a year. \n\nY variable to be predicted is: the number of teeth in the mouth of each patient.\n\nMy idea was that one could run 400 different LSTM time series models on each individual to predict the number of teeth in that individual's mouth. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\nMy question is! These predictions would not have gained any information from the other predictions, or the data from the other persons. Is there a way you know of linking this information? \n\n&amp;#x200B;\n\nFor example, if one was to train a model on an OLD patient, is there any way that the model can learn that OLD patients have tended to have less teeth in their mouths in the other models/data, so the model incorporates 'less teeth in the mouth' to this old patients predictions? \n\n&amp;#x200B;\n\nOr maybe I am not thinking about this correctly.", "author_fullname": "t2_69fg2p0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to link information in an LSTM Model. Linking information Between LSTM Models [P]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i3u42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674340819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If one has a dataset on 400 individuals through time. &lt;/p&gt;\n\n&lt;p&gt;X variables are: person ID, age group (Binary i.e OLD 1 and Young 2), average calories eaten in a day, the average amount of cigarettes smoked in a day, and the average amount of dentist appointments in a year. &lt;/p&gt;\n\n&lt;p&gt;Y variable to be predicted is: the number of teeth in the mouth of each patient.&lt;/p&gt;\n\n&lt;p&gt;My idea was that one could run 400 different LSTM time series models on each individual to predict the number of teeth in that individual&amp;#39;s mouth. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is! These predictions would not have gained any information from the other predictions, or the data from the other persons. Is there a way you know of linking this information? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example, if one was to train a model on an OLD patient, is there any way that the model can learn that OLD patients have tended to have less teeth in their mouths in the other models/data, so the model incorporates &amp;#39;less teeth in the mouth&amp;#39; to this old patients predictions? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or maybe I am not thinking about this correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10i3u42", "is_robot_indexable": true, "report_reasons": null, "author": "RhiteousRhino", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10i3u42/how_to_link_information_in_an_lstm_model_linking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10i3u42/how_to_link_information_in_an_lstm_model_linking/", "subreddit_subscribers": 839654, "created_utc": 1674340819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So today I had a DS online interview. It included Python, SQL, ML and stat theory. I was able to solve ML and stat theory questions and SQL but Python coding was hard. It involved Leetcode hard questions. I am feeling quite demotivated and need help from Experienced DS folks on how to go about it.", "author_fullname": "t2_5eus9vcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help in preparations. Any suggestions how to go about it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hryk9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674309837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So today I had a DS online interview. It included Python, SQL, ML and stat theory. I was able to solve ML and stat theory questions and SQL but Python coding was hard. It involved Leetcode hard questions. I am feeling quite demotivated and need help from Experienced DS folks on how to go about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10hryk9", "is_robot_indexable": true, "report_reasons": null, "author": "honwave", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10hryk9/i_need_help_in_preparations_any_suggestions_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10hryk9/i_need_help_in_preparations_any_suggestions_how/", "subreddit_subscribers": 839654, "created_utc": 1674309837.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}