{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are you telling me that, to build a fact and dim table. I have to take eg a sales table from a source DB then split it up into two tables? Extracting the facts and dimensions?\n\nThat doesn\u2019t make too much sense to me, seems like a lot of extra work either in the ETL pipeline or in the Warehouse.\n\nWhy not just flatten everything?\n\nUPDATE: We\u2019re having a healthy discussion here. It seems to be a triggering topic and certainly some people might not enjoy reading some of the challenging comments. Some people react to them well.\n\nPlease offer your views rather than simply downvoting an walking away. Neither of us have learnt anything in that process. You haven\u2019t validated your understanding and I still have the same view/understanding.\n\nUpdate 1:\n\nThis has been a great discussion so far I really wish we had an option to summarise all the comments here. I\u2019m going to summarise where we are so far with an \u2018update 2\u2019. Would be a shame to waste all of the knowledge presented here.\n\nI totally understand that things can get heated since we could assume my prior knowledge and bias or motivations for this post. \n\nPersonally I think it\u2019s been great. Having a bunch of engineers in a room debating, teaching, clarifying and challenging each other is an amazing thing. We summarise what we\u2019ve discussed then we go on with our self development. Some of us will have validated what we know, taught others, have been challenged, got annoyed etc which is super if you ask me!", "author_fullname": "t2_ggg0wfmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fact &amp; Dim tables - you\u2019re splitting up your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i7rmx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674404536.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674351748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you telling me that, to build a fact and dim table. I have to take eg a sales table from a source DB then split it up into two tables? Extracting the facts and dimensions?&lt;/p&gt;\n\n&lt;p&gt;That doesn\u2019t make too much sense to me, seems like a lot of extra work either in the ETL pipeline or in the Warehouse.&lt;/p&gt;\n\n&lt;p&gt;Why not just flatten everything?&lt;/p&gt;\n\n&lt;p&gt;UPDATE: We\u2019re having a healthy discussion here. It seems to be a triggering topic and certainly some people might not enjoy reading some of the challenging comments. Some people react to them well.&lt;/p&gt;\n\n&lt;p&gt;Please offer your views rather than simply downvoting an walking away. Neither of us have learnt anything in that process. You haven\u2019t validated your understanding and I still have the same view/understanding.&lt;/p&gt;\n\n&lt;p&gt;Update 1:&lt;/p&gt;\n\n&lt;p&gt;This has been a great discussion so far I really wish we had an option to summarise all the comments here. I\u2019m going to summarise where we are so far with an \u2018update 2\u2019. Would be a shame to waste all of the knowledge presented here.&lt;/p&gt;\n\n&lt;p&gt;I totally understand that things can get heated since we could assume my prior knowledge and bias or motivations for this post. &lt;/p&gt;\n\n&lt;p&gt;Personally I think it\u2019s been great. Having a bunch of engineers in a room debating, teaching, clarifying and challenging each other is an amazing thing. We summarise what we\u2019ve discussed then we go on with our self development. Some of us will have validated what we know, taught others, have been challenged, got annoyed etc which is super if you ask me!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10i7rmx", "is_robot_indexable": true, "report_reasons": null, "author": "camelCaseInsensitive", "discussion_type": null, "num_comments": 96, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i7rmx/fact_dim_tables_youre_splitting_up_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i7rmx/fact_dim_tables_youre_splitting_up_your_data/", "subreddit_subscribers": 87074, "created_utc": 1674351748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_owff7qyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built an LLM-powered tool that can understand the structure of any website and extract the desired data in the format you want.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_10ijsqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/me6caa1sklda1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/me6caa1sklda1/DASH_96.mp4", "dash_url": "https://v.redd.it/me6caa1sklda1/DASHPlaylist.mpd?a=1677004790%2CZTZiNzgyYmQyMDU5YThhYTVlYmNkYzgxNGQ5ZTQ0ZjViOGZmZjkxMjE3NmQ5YzA5ZjI0OWQ4YTU3NGVlZDA1NQ%3D%3D&amp;v=1&amp;f=sd", "duration": 22, "hls_url": "https://v.redd.it/me6caa1sklda1/HLSPlaylist.m3u8?a=1677004790%2CMzEyMTNlMjJlZjE5M2E5ZjFhMTI4YTZhNzhjOTQwMWYxZDY4MWZiMmNhYTIxNTY1OWUxY2U1ODhhYWU3MTNmMg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pWDKFw5xpKPbWbs0ONmzMCtae40ap-HGNXJXD1zYf8s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674394485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/me6caa1sklda1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5cfd2e977cb2fb3c1a4e5796b4fb16f73eaeab9b", "width": 1920, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2aa00cf482eacb45de64cd69f589ea10f7f63a0a", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3014cb3af92d25c516c60e318e0f68137f8ef07b", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=32e66331aee72aa2f4d5b77153bd40746d1d364c", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5a90589400f54bb23222f0e2c91285f8225ce1ef", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1c193e109d3661c589733883c8e2567d59da0bda", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/mkNEEnqOEx5vXS1sPpN1EYc7SC5TdSnB8foksa0kIwg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=871e8e3797f20e8cdb4c4b7e99f687e0b1f5638b", "width": 1080, "height": 675}], "variants": {}, "id": "WSkVoXzMKn-584JKkJVRKHEQNCw726pZq43TSrJlALs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10ijsqy", "is_robot_indexable": true, "report_reasons": null, "author": "madredditscientist", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ijsqy/i_built_an_llmpowered_tool_that_can_understand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/me6caa1sklda1", "subreddit_subscribers": 87074, "created_utc": 1674394485.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/me6caa1sklda1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/me6caa1sklda1/DASH_96.mp4", "dash_url": "https://v.redd.it/me6caa1sklda1/DASHPlaylist.mpd?a=1677004790%2CZTZiNzgyYmQyMDU5YThhYTVlYmNkYzgxNGQ5ZTQ0ZjViOGZmZjkxMjE3NmQ5YzA5ZjI0OWQ4YTU3NGVlZDA1NQ%3D%3D&amp;v=1&amp;f=sd", "duration": 22, "hls_url": "https://v.redd.it/me6caa1sklda1/HLSPlaylist.m3u8?a=1677004790%2CMzEyMTNlMjJlZjE5M2E5ZjFhMTI4YTZhNzhjOTQwMWYxZDY4MWZiMmNhYTIxNTY1OWUxY2U1ODhhYWU3MTNmMg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Switching to Macbook pro 16\u201d\n\nHi guys. I wanna ask some advise. \nI currently have my personal machine, a 32gb , 1Tb , ryzen 5900hx 16in lenovo ideapad pro. I use this to do some machine learning, data engg and other stuff. But planning to sell this and just get the macbook pro. I dunno but i really am hook with the power and beauty of the mbp.\nIs it still worth it to buy a macbook pro 16\u201d m1 chip given my current machine? Gonna use it for coding din , ml, and maybe software development.\nThanks sa insights!", "author_fullname": "t2_6k3bzwix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching to macbook pro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ig5ca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674381379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Switching to Macbook pro 16\u201d&lt;/p&gt;\n\n&lt;p&gt;Hi guys. I wanna ask some advise. \nI currently have my personal machine, a 32gb , 1Tb , ryzen 5900hx 16in lenovo ideapad pro. I use this to do some machine learning, data engg and other stuff. But planning to sell this and just get the macbook pro. I dunno but i really am hook with the power and beauty of the mbp.\nIs it still worth it to buy a macbook pro 16\u201d m1 chip given my current machine? Gonna use it for coding din , ml, and maybe software development.\nThanks sa insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ig5ca", "is_robot_indexable": true, "report_reasons": null, "author": "petes0707", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ig5ca/switching_to_macbook_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ig5ca/switching_to_macbook_pro/", "subreddit_subscribers": 87074, "created_utc": 1674381379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data Engineering involves a lot of hands-on work on the cloud. \n\nBut given that cloud resources are expensive, how can one learn Apache Spark, Kafka, Docker, Kubernetes etc on the cloud for free? This is the biggest hesitation I am facing to learn data engineering else I am very interested. Yes I can implement locally but professionally we need to work on the cloud so want to implement the same.", "author_fullname": "t2_6hp3gp78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn DE on cloud for free/cheaper cost", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i1zl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674336011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Engineering involves a lot of hands-on work on the cloud. &lt;/p&gt;\n\n&lt;p&gt;But given that cloud resources are expensive, how can one learn Apache Spark, Kafka, Docker, Kubernetes etc on the cloud for free? This is the biggest hesitation I am facing to learn data engineering else I am very interested. Yes I can implement locally but professionally we need to work on the cloud so want to implement the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10i1zl2", "is_robot_indexable": true, "report_reasons": null, "author": "rohetoric", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i1zl2/learn_de_on_cloud_for_freecheaper_cost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i1zl2/learn_de_on_cloud_for_freecheaper_cost/", "subreddit_subscribers": 87074, "created_utc": 1674336011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background:\nI am one of two data engineers (joined 6 months ago) at a health tech startup with ~250 employees that just finished its fifth VC funding round. We have buy in from leadership to change the way we treat and think about data. I plan to present to our Chief Strategy Officer who is asking for self serve reporting when we are still getting the fundamentals in place. \n\nMy thoughts so far, abbreviated:\n\n- Establish importance of Data Literacy for these folks and Data Strategy for the company\n- High level view of how DE is handling things today (what is ELT?; what are the tools we are using, generally?; where does our data come from?; how are we using the data today in the business?)\n- DE concepts: ELT pipelines, data storage (data lake vs data warehouse), data modeling, data quality and observability, etc\n- Organizational concepts: Data stewards, avoiding data silos, data catalogues, etc\n- External integration concepts: SLAs, data dictionaries from vendors, involvement of DE in negotiations, etc\n- Data maturity curve discussion\n- How can we make better use of our data?\n- Provide measurable goals for concrete change in the next 1, 2, and 5 years", "author_fullname": "t2_fvc57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What topics should I focus on in a Data Literacy/Data Strategy presentation to non/semi-technical leaders at my startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i6k1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674348266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background:\nI am one of two data engineers (joined 6 months ago) at a health tech startup with ~250 employees that just finished its fifth VC funding round. We have buy in from leadership to change the way we treat and think about data. I plan to present to our Chief Strategy Officer who is asking for self serve reporting when we are still getting the fundamentals in place. &lt;/p&gt;\n\n&lt;p&gt;My thoughts so far, abbreviated:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Establish importance of Data Literacy for these folks and Data Strategy for the company&lt;/li&gt;\n&lt;li&gt;High level view of how DE is handling things today (what is ELT?; what are the tools we are using, generally?; where does our data come from?; how are we using the data today in the business?)&lt;/li&gt;\n&lt;li&gt;DE concepts: ELT pipelines, data storage (data lake vs data warehouse), data modeling, data quality and observability, etc&lt;/li&gt;\n&lt;li&gt;Organizational concepts: Data stewards, avoiding data silos, data catalogues, etc&lt;/li&gt;\n&lt;li&gt;External integration concepts: SLAs, data dictionaries from vendors, involvement of DE in negotiations, etc&lt;/li&gt;\n&lt;li&gt;Data maturity curve discussion&lt;/li&gt;\n&lt;li&gt;How can we make better use of our data?&lt;/li&gt;\n&lt;li&gt;Provide measurable goals for concrete change in the next 1, 2, and 5 years&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10i6k1g", "is_robot_indexable": true, "report_reasons": null, "author": "Pleahey7", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i6k1g/what_topics_should_i_focus_on_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i6k1g/what_topics_should_i_focus_on_in_a_data/", "subreddit_subscribers": 87074, "created_utc": 1674348266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know there are another posts about this but let me share my experience.\n\nI am 54 years old,  32 years of experience in IT and 30 years of experience as Infrastructure DBA. Focused in Oracle but also DBs. I started with Oracle 7.0.15 in 1994.\n\nI moved to US in 2018 and I started an US position as Exadata DBA + Goldengate 2 years ago.\n\nBut I know that a \"root\" DBA is a job will disappear or reduce.\n\nI have a good logic (but I don't have coding) and I usually have complex shell scripts with bath + python + perl and sometimes a bit of Linux C.\n\nWhat's the best roadmap to move to DE.\n\nJust thinking in better remuneration and a better employability.\n\n&amp;#x200B;\n\nThank you", "author_fullname": "t2_8dke1w85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking to move to DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ikbh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674396082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are another posts about this but let me share my experience.&lt;/p&gt;\n\n&lt;p&gt;I am 54 years old,  32 years of experience in IT and 30 years of experience as Infrastructure DBA. Focused in Oracle but also DBs. I started with Oracle 7.0.15 in 1994.&lt;/p&gt;\n\n&lt;p&gt;I moved to US in 2018 and I started an US position as Exadata DBA + Goldengate 2 years ago.&lt;/p&gt;\n\n&lt;p&gt;But I know that a &amp;quot;root&amp;quot; DBA is a job will disappear or reduce.&lt;/p&gt;\n\n&lt;p&gt;I have a good logic (but I don&amp;#39;t have coding) and I usually have complex shell scripts with bath + python + perl and sometimes a bit of Linux C.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best roadmap to move to DE.&lt;/p&gt;\n\n&lt;p&gt;Just thinking in better remuneration and a better employability.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10ikbh5", "is_robot_indexable": true, "report_reasons": null, "author": "MarceloGW0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ikbh5/thinking_to_move_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ikbh5/thinking_to_move_to_de/", "subreddit_subscribers": 87074, "created_utc": 1674396082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, recently joined a new org as Data Engineer and work involves mostly working on Snowflake. As part of an organisation initiative, my org wants me and my teammates to complete the SnowPro Core certification. I need to sit for the exam latest by March end so have close to 2 months to prepare. Can someone point me to any specific resources/ learning plan for the same. I have mid level background in SQL and RDBMS. Any free/paid (Udemy) resources would be appreciated. Thanks!", "author_fullname": "t2_c5dl0kbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SnowPro Core Certification Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ienm6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674375258.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, recently joined a new org as Data Engineer and work involves mostly working on Snowflake. As part of an organisation initiative, my org wants me and my teammates to complete the SnowPro Core certification. I need to sit for the exam latest by March end so have close to 2 months to prepare. Can someone point me to any specific resources/ learning plan for the same. I have mid level background in SQL and RDBMS. Any free/paid (Udemy) resources would be appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ienm6", "is_robot_indexable": true, "report_reasons": null, "author": "akanerdcaps", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ienm6/snowpro_core_certification_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ienm6/snowpro_core_certification_resources/", "subreddit_subscribers": 87074, "created_utc": 1674375258.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nGot a request to manage our data changes on MySQL and Postgres.\nNeed to have integration to bitbucket, allow scheduling deploys , applying rollback code if necessary.\nAny additional features will be welcome.\n\nI'm currently looking into liquidbase..\nAny thoughts? Suggestions?\nMany thanks!", "author_fullname": "t2_rdyic8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Db changes (Optional as part of the cicd)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10idara", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674375563.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674369997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nGot a request to manage our data changes on MySQL and Postgres.\nNeed to have integration to bitbucket, allow scheduling deploys , applying rollback code if necessary.\nAny additional features will be welcome.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking into liquidbase..\nAny thoughts? Suggestions?\nMany thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10idara", "is_robot_indexable": true, "report_reasons": null, "author": "DimskyTheGreen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10idara/managing_db_changes_optional_as_part_of_the_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10idara/managing_db_changes_optional_as_part_of_the_cicd/", "subreddit_subscribers": 87074, "created_utc": 1674369997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12wi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source High Performance Data Integration Framework in Go (Fivetran, Airbyte alternative)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_10io4c1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4N9i4w8vO1rin1vFc5qfYWeI61csnwmcp-Jkn_k3qTw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674406347.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "http://github.com/cloudquery/cloudquery", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?auto=webp&amp;v=enabled&amp;s=effef686820d2a38a8b5490cb711a9d4d1b95251", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25365675f9c2a8865edf69d9dc8c5fb3ef47ce1e", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8771807ddfacdbd6e1ddfeb0d1a2917b1a5e1a4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3fa345ec0db7dd433fa8584128fbf6632ec98fc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05b658130454e5b461b41282abf89b5778677353", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0db9a2c22e52c261e0a8bfd8cfc4811bbaec24e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1FXwc0VEuwDqox9UVPiY0gylvv0VkqkzLacNi0YAzdg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=049861cfb294899909bc4fe2bfed577d9467a274", "width": 1080, "height": 540}], "variants": {}, "id": "j3Mt88SilW8vh9xaQAnvKELOvuKm_qKw4DQUBdALyKM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10io4c1", "is_robot_indexable": true, "report_reasons": null, "author": "jekapats", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10io4c1/open_source_high_performance_data_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://github.com/cloudquery/cloudquery", "subreddit_subscribers": 87074, "created_utc": 1674406347.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently applied for a data science role at a small marketing agency. Based on conversations with the CEO and some of the staff it seems that I will also be responsible in setting up a data infrastucture for the company as well (my official role is apparently Data Engineering Assistant).\n\nThe data that we will use come from  social media APIs such as Google Analytics to monitor the clients' social media page and posts to build a report and to monitor our ad performance. \n\nCurrently the team downloads these data manually and process them, but I will mainly help them build an automated pipeline process and feed them to my ML models. I only have experience on data analytics stuff on Python, and I am not entirely sure how can I set up an infrastructure at the company.\n\nI have built a script that automatically pulls data from Google Analytics but I am confused as to where to store them. The team can just run these script on their own machine but it seems clunky and it would be hard to feed them into my ML models.\n\nI was thinking about a centralised system, like building a LAN server that runs 24/7 Python scripts pulling daily data from different APIs to feed them directly into my models, and create reports on excel which the team can just download them. There would also be an SQL server here, but it seems that I am the only one that knows SQL so I am the only one that can query it.\n\nWith cloud, I was thinking that it would be difficult to automatically process the data especially because currently the process is pulling data from APIs using Python scripts and that feeding them into an ML algorithm would also be hard. \n\nWhat do you think would be the best solution and is there any tips that you might have?", "author_fullname": "t2_2knag8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a brand new data infrastructure for a small company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ilsgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674400278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently applied for a data science role at a small marketing agency. Based on conversations with the CEO and some of the staff it seems that I will also be responsible in setting up a data infrastucture for the company as well (my official role is apparently Data Engineering Assistant).&lt;/p&gt;\n\n&lt;p&gt;The data that we will use come from  social media APIs such as Google Analytics to monitor the clients&amp;#39; social media page and posts to build a report and to monitor our ad performance. &lt;/p&gt;\n\n&lt;p&gt;Currently the team downloads these data manually and process them, but I will mainly help them build an automated pipeline process and feed them to my ML models. I only have experience on data analytics stuff on Python, and I am not entirely sure how can I set up an infrastructure at the company.&lt;/p&gt;\n\n&lt;p&gt;I have built a script that automatically pulls data from Google Analytics but I am confused as to where to store them. The team can just run these script on their own machine but it seems clunky and it would be hard to feed them into my ML models.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about a centralised system, like building a LAN server that runs 24/7 Python scripts pulling daily data from different APIs to feed them directly into my models, and create reports on excel which the team can just download them. There would also be an SQL server here, but it seems that I am the only one that knows SQL so I am the only one that can query it.&lt;/p&gt;\n\n&lt;p&gt;With cloud, I was thinking that it would be difficult to automatically process the data especially because currently the process is pulling data from APIs using Python scripts and that feeding them into an ML algorithm would also be hard. &lt;/p&gt;\n\n&lt;p&gt;What do you think would be the best solution and is there any tips that you might have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ilsgt", "is_robot_indexable": true, "report_reasons": null, "author": "lordgriefter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ilsgt/creating_a_brand_new_data_infrastructure_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ilsgt/creating_a_brand_new_data_infrastructure_for_a/", "subreddit_subscribers": 87074, "created_utc": 1674400278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We publish our processed data on aws as athena tables or/and parquet files on S3 for the data analysts and data scientists. we do all transformations with glue and spark. we have now considered switching to iceberg, as it brings a lot of advantages (schema evolution, time travel etc... )\n\nData Scientists need a lot of sagemaker and access S3 directly to read the data with pandas. But since iceberg does everything with tables, I wonder if this can cause problems for the data scientists, since it is no longer so easy to read from s3.\n\ndoes anyone have experience with this issue? could it cause problems here?", "author_fullname": "t2_lagrx3zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Iceberg as default storage type?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ifr33", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674379706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We publish our processed data on aws as athena tables or/and parquet files on S3 for the data analysts and data scientists. we do all transformations with glue and spark. we have now considered switching to iceberg, as it brings a lot of advantages (schema evolution, time travel etc... )&lt;/p&gt;\n\n&lt;p&gt;Data Scientists need a lot of sagemaker and access S3 directly to read the data with pandas. But since iceberg does everything with tables, I wonder if this can cause problems for the data scientists, since it is no longer so easy to read from s3.&lt;/p&gt;\n\n&lt;p&gt;does anyone have experience with this issue? could it cause problems here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ifr33", "is_robot_indexable": true, "report_reasons": null, "author": "VegetableRecord2633", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ifr33/apache_iceberg_as_default_storage_type/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ifr33/apache_iceberg_as_default_storage_type/", "subreddit_subscribers": 87074, "created_utc": 1674379706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nCurious what the best practices are (or how you personally do it) for handling variables and parameters that are environment specific during a release (and thus needs to be overridden). Example: connection string to your source system (dev) that needs to be changed to e.g. the source system in prod.\n\nI know you can create env specific variables in e.g. Github or Gitlab, and assign those a different value depending on the job/stage in your release pipeline. However, I can imagine that as your project becomes bigger, it'll be a headache to maintain a large number of variables through this feature.\n\nOther option I can think of is to use a SQL database to store all your variables and parameters in a metadata table for each environment. This way you only need to override the connection string to this database.\n\nThanks in advance!", "author_fullname": "t2_2gkhkev6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] CI/CD - environment specific variables during release", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i3q3q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674340522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Curious what the best practices are (or how you personally do it) for handling variables and parameters that are environment specific during a release (and thus needs to be overridden). Example: connection string to your source system (dev) that needs to be changed to e.g. the source system in prod.&lt;/p&gt;\n\n&lt;p&gt;I know you can create env specific variables in e.g. Github or Gitlab, and assign those a different value depending on the job/stage in your release pipeline. However, I can imagine that as your project becomes bigger, it&amp;#39;ll be a headache to maintain a large number of variables through this feature.&lt;/p&gt;\n\n&lt;p&gt;Other option I can think of is to use a SQL database to store all your variables and parameters in a metadata table for each environment. This way you only need to override the connection string to this database.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10i3q3q", "is_robot_indexable": true, "report_reasons": null, "author": "Jysunity", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i3q3q/question_cicd_environment_specific_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i3q3q/question_cicd_environment_specific_variables/", "subreddit_subscribers": 87074, "created_utc": 1674340522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of the data we are asked to make available for analysis are time series, yet we tend to only focus on the fact that we will run aggregations, so we conclude that we should use OLAP oriented databases. But what about time series databases, what would make them better to run OLAP queries over time series?", "author_fullname": "t2_7nogk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes a time series oriented database (ex: QuestDB) more efficient for OLAP on time series than an OLAP \"only\" oriented database (ex: DuckDB) technically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ip1br", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674408627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of the data we are asked to make available for analysis are time series, yet we tend to only focus on the fact that we will run aggregations, so we conclude that we should use OLAP oriented databases. But what about time series databases, what would make them better to run OLAP queries over time series?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer and Architect ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ip1br", "is_robot_indexable": true, "report_reasons": null, "author": "_Oce_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10ip1br/what_makes_a_time_series_oriented_database_ex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ip1br/what_makes_a_time_series_oriented_database_ex/", "subreddit_subscribers": 87074, "created_utc": 1674408627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently joined as a junior DE at a company. I am truly intrigued by the field and have a habit of taking a stroll in the databases, looking at the data that's in the tables.\n\n There's a table I came across which has 1 Trillion rows. Isn't that a lot? The table is like 170+TBs and I'm skeptical if the infrastructure should have such massive tables. Let me know if that's a problem I should be talking about with my seniors.\n\nIt is a table on Snowflake and is a raw table for data coming in daily from some source. \n\nThanks in advance!", "author_fullname": "t2_axxxuxmv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 Trillion Rows!?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ilw17", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674400557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently joined as a junior DE at a company. I am truly intrigued by the field and have a habit of taking a stroll in the databases, looking at the data that&amp;#39;s in the tables.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a table I came across which has 1 Trillion rows. Isn&amp;#39;t that a lot? The table is like 170+TBs and I&amp;#39;m skeptical if the infrastructure should have such massive tables. Let me know if that&amp;#39;s a problem I should be talking about with my seniors.&lt;/p&gt;\n\n&lt;p&gt;It is a table on Snowflake and is a raw table for data coming in daily from some source. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ilw17", "is_robot_indexable": true, "report_reasons": null, "author": "sluuurpyy", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ilw17/1_trillion_rows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ilw17/1_trillion_rows/", "subreddit_subscribers": 87074, "created_utc": 1674400557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to transition to this medium term so some information might help the transition.", "author_fullname": "t2_2pxsf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of skills are required to work as a data engineer in biology/biotech companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ipqii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674410405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to transition to this medium term so some information might help the transition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10ipqii", "is_robot_indexable": true, "report_reasons": null, "author": "blue_trains_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ipqii/what_kind_of_skills_are_required_to_work_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ipqii/what_kind_of_skills_are_required_to_work_as_a/", "subreddit_subscribers": 87074, "created_utc": 1674410405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow data scientists/engineers!!\n\nI'd like to ask if you guys opt Spark over Hadoop for your data projects. \n\nIn my research, I see a lot of articles that says that Hadoop is getting outdated and Spark's replacing it, but still want to make sure if this is true trend. \n\nPlease share your opinion. Thx!!", "author_fullname": "t2_92h4yobe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hadoop or Spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ipeue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674409582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow data scientists/engineers!!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to ask if you guys opt Spark over Hadoop for your data projects. &lt;/p&gt;\n\n&lt;p&gt;In my research, I see a lot of articles that says that Hadoop is getting outdated and Spark&amp;#39;s replacing it, but still want to make sure if this is true trend. &lt;/p&gt;\n\n&lt;p&gt;Please share your opinion. Thx!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ipeue", "is_robot_indexable": true, "report_reasons": null, "author": "grabthemomentum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ipeue/hadoop_or_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ipeue/hadoop_or_spark/", "subreddit_subscribers": 87074, "created_utc": 1674409582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently building a new personal project, where I want to use dbt to transform data in redshift. Everything should be scheduled using Airflow which is deployed with docker on an ec2 instance. I furthermore want to integrate great expectations to do tests on the data.\n\nI am thinking about how to integrate dbt and great expectations in the pipeline.\n\nThe easiest solution would be to put both the dbt folder and the great expectations folder in a folder with the dag in airflows dag folder. But wouldn\u2019t this be a bit unprofessional, even for a project with the purpose of skill showcase? \n\nHave you got ideas where to deploy dbt and great expectations and it being accessible by airflow? (I would like to avoid MWAA).\n\nThanks a lot :)", "author_fullname": "t2_v219tksh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to integrate great expectations and dbt with Airflow on AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10im7hb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674401956.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674401421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently building a new personal project, where I want to use dbt to transform data in redshift. Everything should be scheduled using Airflow which is deployed with docker on an ec2 instance. I furthermore want to integrate great expectations to do tests on the data.&lt;/p&gt;\n\n&lt;p&gt;I am thinking about how to integrate dbt and great expectations in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;The easiest solution would be to put both the dbt folder and the great expectations folder in a folder with the dag in airflows dag folder. But wouldn\u2019t this be a bit unprofessional, even for a project with the purpose of skill showcase? &lt;/p&gt;\n\n&lt;p&gt;Have you got ideas where to deploy dbt and great expectations and it being accessible by airflow? (I would like to avoid MWAA).&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10im7hb", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Hand-577", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10im7hb/how_to_integrate_great_expectations_and_dbt_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10im7hb/how_to_integrate_great_expectations_and_dbt_with/", "subreddit_subscribers": 87074, "created_utc": 1674401421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We utilize Databricks (and yes, that includes developing in notebooks), and while I have been successful employing parameterized notebooks for our Bronze, Silver, and Gold layers, I am struggling to come up with a means of streamlining our data extraction.\n\nVast majority of our data is batched and is gathered from various REST API endpoints. We currently save the data as JSON files into our lake, very little (if anything) is done to the raw data unless we need to inject dates or identifiers. From there, everything is processed in parameterized notebooks (though we are looking in employing dbt for transformations and modeling in the future).\n\nWe do this work entirely in Python so I have looked into using something like Singer or Airbyte in the hopes of effectively creating templated jobs, but I'm not sure if that would end up being overkill for our smaller datasets.\n\nMost data sources require me to build custom connectors, but some could utilize the pre-built taps or connectors available in Singer and Airbyte which is why I'm currently considering them (obviously I could also build my own connectors using with them as well). I'm trying to cut down on code reuse and while I know I can just build my own packages and import them as wheel files, I'm not sure if that's the best way to go.\n\nLooking for feedback on experiences with either of these frameworks (or others). Are they worth it, or should I look into building our own simple framework or package(s) that does something similar (at the risk of reinventing the wheel)?", "author_fullname": "t2_v85tqybf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Should I Go About Templating or Standardizing Data Extraction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i477p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674341789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We utilize Databricks (and yes, that includes developing in notebooks), and while I have been successful employing parameterized notebooks for our Bronze, Silver, and Gold layers, I am struggling to come up with a means of streamlining our data extraction.&lt;/p&gt;\n\n&lt;p&gt;Vast majority of our data is batched and is gathered from various REST API endpoints. We currently save the data as JSON files into our lake, very little (if anything) is done to the raw data unless we need to inject dates or identifiers. From there, everything is processed in parameterized notebooks (though we are looking in employing dbt for transformations and modeling in the future).&lt;/p&gt;\n\n&lt;p&gt;We do this work entirely in Python so I have looked into using something like Singer or Airbyte in the hopes of effectively creating templated jobs, but I&amp;#39;m not sure if that would end up being overkill for our smaller datasets.&lt;/p&gt;\n\n&lt;p&gt;Most data sources require me to build custom connectors, but some could utilize the pre-built taps or connectors available in Singer and Airbyte which is why I&amp;#39;m currently considering them (obviously I could also build my own connectors using with them as well). I&amp;#39;m trying to cut down on code reuse and while I know I can just build my own packages and import them as wheel files, I&amp;#39;m not sure if that&amp;#39;s the best way to go.&lt;/p&gt;\n\n&lt;p&gt;Looking for feedback on experiences with either of these frameworks (or others). Are they worth it, or should I look into building our own simple framework or package(s) that does something similar (at the risk of reinventing the wheel)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10i477p", "is_robot_indexable": true, "report_reasons": null, "author": "YHJTC", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i477p/how_should_i_go_about_templating_or_standardizing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i477p/how_should_i_go_about_templating_or_standardizing/", "subreddit_subscribers": 87074, "created_utc": 1674341789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The Official Apache Airflow Solution allows devs to sync DAGs through [Git Sync](https://airflow.apache.org/docs/helm-chart/stable/manage-dags-files.html#mounting-dags-from-a-private-github-repo-using-git-sync-sidecar) from their Git repo. However, this feature does not exist for plugins ([Github Issue](https://github.com/apache/airflow/issues/11708)). Any workaround or do you just keep deploying a new Airflow Image whenever a plugin change occurs similar to this [example](https://towardsdatascience.com/deploying-airflow-on-google-kubernetes-engine-with-helm-part-two-f833b0a3b0b1)? \n\nWould running DAGs be cancelled by the system whenever an Airflow image needs to be deployed?", "author_fullname": "t2_f4rnp5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow Plugin Syncing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i0kb8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674333163.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674332395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The Official Apache Airflow Solution allows devs to sync DAGs through &lt;a href=\"https://airflow.apache.org/docs/helm-chart/stable/manage-dags-files.html#mounting-dags-from-a-private-github-repo-using-git-sync-sidecar\"&gt;Git Sync&lt;/a&gt; from their Git repo. However, this feature does not exist for plugins (&lt;a href=\"https://github.com/apache/airflow/issues/11708\"&gt;Github Issue&lt;/a&gt;). Any workaround or do you just keep deploying a new Airflow Image whenever a plugin change occurs similar to this &lt;a href=\"https://towardsdatascience.com/deploying-airflow-on-google-kubernetes-engine-with-helm-part-two-f833b0a3b0b1\"&gt;example&lt;/a&gt;? &lt;/p&gt;\n\n&lt;p&gt;Would running DAGs be cancelled by the system whenever an Airflow image needs to be deployed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10i0kb8", "is_robot_indexable": true, "report_reasons": null, "author": "alwaysSearching23", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i0kb8/airflow_plugin_syncing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i0kb8/airflow_plugin_syncing/", "subreddit_subscribers": 87074, "created_utc": 1674332395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello rdataengineering!\n\nSo I\u2019m doing a class assignment with a rather long business case and they want us to create an *Entity-Relationship Model* (*ERD*) that is in *Third Normal Form* (*3NF*). I\u2019ve been racking my brain around the problem for 3 days now and honestly haven\u2019t made too much progress because I\u2019m just not sure how you parse out what is an **entity vs. what is not an entity**. You can make the ERD super broad or super granular depending on how many entities you create. Some things should be entities and some things should not be entities, rather they should be some attribute that\u2019s part of some entity.  I'm really not sure how you have the intuition to know that something is an entity right away. How do you determine if something should be an entity vs. something that should be an attribute within an entity? Thank you!\n\n**Tl;dr**: Given a crazy business case, how do you determine the entities? What is the thing you look for to know whether something should be an entity vs. just some attribute?", "author_fullname": "t2_odgjtbb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling: How do you determine if something is an entity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10hyv1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674328088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello rdataengineering!&lt;/p&gt;\n\n&lt;p&gt;So I\u2019m doing a class assignment with a rather long business case and they want us to create an &lt;em&gt;Entity-Relationship Model&lt;/em&gt; (&lt;em&gt;ERD&lt;/em&gt;) that is in &lt;em&gt;Third Normal Form&lt;/em&gt; (&lt;em&gt;3NF&lt;/em&gt;). I\u2019ve been racking my brain around the problem for 3 days now and honestly haven\u2019t made too much progress because I\u2019m just not sure how you parse out what is an &lt;strong&gt;entity vs. what is not an entity&lt;/strong&gt;. You can make the ERD super broad or super granular depending on how many entities you create. Some things should be entities and some things should not be entities, rather they should be some attribute that\u2019s part of some entity.  I&amp;#39;m really not sure how you have the intuition to know that something is an entity right away. How do you determine if something should be an entity vs. something that should be an attribute within an entity? Thank you!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tl;dr&lt;/strong&gt;: Given a crazy business case, how do you determine the entities? What is the thing you look for to know whether something should be an entity vs. just some attribute?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10hyv1p", "is_robot_indexable": true, "report_reasons": null, "author": "BruceWayne_92", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10hyv1p/data_modeling_how_do_you_determine_if_something/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10hyv1p/data_modeling_how_do_you_determine_if_something/", "subreddit_subscribers": 87074, "created_utc": 1674328088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data scientist, I usually just go pd.to_sql(table) and forget about it. Now a colleague has left and I'm thrust into a data engineering role.\n\nLiterally clueless about how to management foreign keys, etc. Appreciate any resources or tutorials for managing schemas, etc.", "author_fullname": "t2_regy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist needing to learn proper data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10i0y5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674333332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data scientist, I usually just go pd.to_sql(table) and forget about it. Now a colleague has left and I&amp;#39;m thrust into a data engineering role.&lt;/p&gt;\n\n&lt;p&gt;Literally clueless about how to management foreign keys, etc. Appreciate any resources or tutorials for managing schemas, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10i0y5u", "is_robot_indexable": true, "report_reasons": null, "author": "powerforward1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10i0y5u/data_scientist_needing_to_learn_proper_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10i0y5u/data_scientist_needing_to_learn_proper_data/", "subreddit_subscribers": 87074, "created_utc": 1674333332.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}