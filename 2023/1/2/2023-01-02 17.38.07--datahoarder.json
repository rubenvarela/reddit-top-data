{"kind": "Listing", "data": {"after": "t3_1016035", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.\n\nBelow is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.\n\n# There are a number of external factors that can impact or influence the availability of information on the internet. \n\n&amp;#x200B;\n\n* Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo \\[[1](https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/)\\] \\[[2](https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480)\\] \\[[3](https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/)\\] \\[[4](https://www.wired.co.uk/article/lets-play-youtube-crackdown)\\], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. \n* Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. \n* Environmental disasters or internal societal discourse leading to the destruction or [sabotage](https://en.wikipedia.org/wiki/2021_South_African_unrest) of local and state infrastructure. \n* User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. \n* Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. \n\n&amp;#x200B;", "author_fullname": "t2_o8wjc", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Reasons for why data hoarding is important and why you should start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100o9fo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 560, "total_awards_received": 5, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 560, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 2, "gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672593652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.&lt;/p&gt;\n\n&lt;p&gt;Below is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.&lt;/p&gt;\n\n&lt;h1&gt;There are a number of external factors that can impact or influence the availability of information on the internet.&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo [&lt;a href=\"https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/\"&gt;1&lt;/a&gt;] [&lt;a href=\"https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480\"&gt;2&lt;/a&gt;] [&lt;a href=\"https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/\"&gt;3&lt;/a&gt;] [&lt;a href=\"https://www.wired.co.uk/article/lets-play-youtube-crackdown\"&gt;4&lt;/a&gt;], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. &lt;/li&gt;\n&lt;li&gt;Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. &lt;/li&gt;\n&lt;li&gt;Environmental disasters or internal societal discourse leading to the destruction or &lt;a href=\"https://en.wikipedia.org/wiki/2021_South_African_unrest\"&gt;sabotage&lt;/a&gt; of local and state infrastructure. &lt;/li&gt;\n&lt;li&gt;User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. &lt;/li&gt;\n&lt;li&gt;Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?auto=webp&amp;s=c387f574702b9ed7c68f698f7fa60d3c32211671", "width": 1800, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb9ab3549c9f5cc04cb293a047279f42604c60fd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7290288a77475dc5eb9e611bf255005806be1f4f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a84b6bc449101a95d8f26aba49a1e373c5f7f05b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41b14dbcff1f1c5660bbb986002af4d35c724c77", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4eb9f48e1255ec76179e227b7f255cae2381d077", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39312c08074837719f03b915499b7495eeb170f7", "width": 1080, "height": 540}], "variants": {}, "id": "8L_qxpBRz4_edl-TBfsKsZva8bCq3Eo_1KrJqCdCbVo"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 2, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 30, "id": "award_b4ff447e-05a5-42dc-9002-63568807cfe6", "penny_donate": null, "award_sub_type": "PREMIUM", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/Illuminati_128.png", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "A glowing commendation for all to see", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 2048, "name": "All-Seeing Upvote", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=16&amp;height=16&amp;auto=webp&amp;s=978c93744e53b8c9305467a7be792e5c401eac6c", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=32&amp;height=32&amp;auto=webp&amp;s=d2ee343eef5048ad3add75d4a4d4e3922bb9565a", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=48&amp;height=48&amp;auto=webp&amp;s=7d216fd3a05c61d9fb75b27092844c546d958f14", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=64&amp;height=64&amp;auto=webp&amp;s=b76693f84fd19b04d0c0444a9812d812105e2d8f", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png?width=128&amp;height=128&amp;auto=webp&amp;s=5353352ae9f443c353ef0b7725dabcfc1b3829a5", "width": 128, "height": 128}], "icon_format": "APNG", "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_q0gj4/am40b8b08l581_All-SeeingUpvote2.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "award_43c43a35-15c5-4f73-91ef-fe538426435a", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=e84e08de4b1352e679d612c063584341f56bc2b5", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=d01d7a3286bb55c235e217736c78c66e2d7d0c18", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=6ae7d390be614e44f1ec06141d0ba51d65494bff", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=1c88befd3d95c2ea37b95a7132db98d8a8730ae1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=f97d6987f6545f6cb659f1fce7c304278a92f762", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Prayers up for the blessed. Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Bless Up (Pro)", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=16&amp;height=16&amp;auto=webp&amp;s=e84e08de4b1352e679d612c063584341f56bc2b5", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=32&amp;height=32&amp;auto=webp&amp;s=d01d7a3286bb55c235e217736c78c66e2d7d0c18", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=48&amp;height=48&amp;auto=webp&amp;s=6ae7d390be614e44f1ec06141d0ba51d65494bff", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=64&amp;height=64&amp;auto=webp&amp;s=1c88befd3d95c2ea37b95a7132db98d8a8730ae1", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png?width=128&amp;height=128&amp;auto=webp&amp;s=f97d6987f6545f6cb659f1fce7c304278a92f762", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/xe5mw55w5v541_BlessUp.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100o9fo", "is_robot_indexable": true, "report_reasons": null, "author": "ReclusiveEagle", "discussion_type": null, "num_comments": 119, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "subreddit_subscribers": 663434, "created_utc": 1672593652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cable management is overrated when you have 27 drives in a case to cable up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1012unv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": "", "subreddit_type": "public", "ups": 154, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_sxos8", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 154, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d726UNwNfz5lz-dJ0VPEs_Fx-TVjTcaYRCKKFhho-AE.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "homelab", "selftext": "", "author_fullname": "t2_sxos8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cable management is overrated when you have 27 drives in a case to cable up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/homelab", "hidden": false, "pwls": 6, "link_flair_css_class": "labporn", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zxmvnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 113, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "8fc1a448-bbcf-11e4-9649-22000b2b8291", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "LabPorn", "can_mod_post": false, "score": 113, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d726UNwNfz5lz-dJ0VPEs_Fx-TVjTcaYRCKKFhho-AE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672265950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tll16p189r8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&amp;s=4955f34473be257ad52740705bf174c7dd3ea796", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18443b5d831978ffc0207945de453c03c5ec85f2", "width": 108, "height": 144}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42a8e5831cf7970311f608fee789f7e65022c690", "width": 216, "height": 288}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd90f4b4ab31821e75b1ebbe9ee1dc0607a873ab", "width": 320, "height": 426}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3aae096a530d32a0a9a0bf339f9239bf099609d", "width": 640, "height": 853}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93bb8e132bafde73f20637f3339b65dad13ad6e4", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2533df342d16b9a60e766261eb91e841992ddd43", "width": 1080, "height": 1440}], "variants": {}, "id": "NmEF_4HyikbEgclxnzrqS1QFw0yZJYX2sRtcKSW1Zrs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6f351106-322a-11e6-99ab-0e9de4a16811", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DL60 G9 / 2 x DL360e G8 / DL380p G8  / SA120", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2ubz7", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8c00", "id": "zxmvnh", "is_robot_indexable": true, "report_reasons": null, "author": "iamcts", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/homelab/comments/zxmvnh/cable_management_is_overrated_when_you_have_27/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tll16p189r8a1.jpg", "subreddit_subscribers": 541858, "created_utc": 1672265950.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672632541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tll16p189r8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&amp;s=4955f34473be257ad52740705bf174c7dd3ea796", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18443b5d831978ffc0207945de453c03c5ec85f2", "width": 108, "height": 144}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42a8e5831cf7970311f608fee789f7e65022c690", "width": 216, "height": 288}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd90f4b4ab31821e75b1ebbe9ee1dc0607a873ab", "width": 320, "height": 426}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3aae096a530d32a0a9a0bf339f9239bf099609d", "width": 640, "height": 853}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93bb8e132bafde73f20637f3339b65dad13ad6e4", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2533df342d16b9a60e766261eb91e841992ddd43", "width": 1080, "height": 1440}], "variants": {}, "id": "NmEF_4HyikbEgclxnzrqS1QFw0yZJYX2sRtcKSW1Zrs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1012unv", "is_robot_indexable": true, "report_reasons": null, "author": "iamcts", "discussion_type": null, "num_comments": 22, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zxmvnh", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1012unv/cable_management_is_overrated_when_you_have_27/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tll16p189r8a1.jpg", "subreddit_subscribers": 663434, "created_utc": 1672632541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are times where it\u2019s obviously preferable to have the highest quality version of a piece of content you can find, especially if it\u2019s harder to come by. but sometimes it feels wasteful. It\u2019s not like I have unlimited storage space, especially if I want to keep backups of everything. Like do I really need 200 GBs worth of Lost? I\u2019ll go for the highest quality versions of movies or TV shows that have special meaning to me, but for content I\u2019m less interested in and just want to have around, 720p is fine. Lowest I\u2019ve gone is 360p, mainly for long-running old shows that never had great picture quality to begin with.", "author_fullname": "t2_tggommtv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you always go for the highest available quality version of everything?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10197uf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672654508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are times where it\u2019s obviously preferable to have the highest quality version of a piece of content you can find, especially if it\u2019s harder to come by. but sometimes it feels wasteful. It\u2019s not like I have unlimited storage space, especially if I want to keep backups of everything. Like do I really need 200 GBs worth of Lost? I\u2019ll go for the highest quality versions of movies or TV shows that have special meaning to me, but for content I\u2019m less interested in and just want to have around, 720p is fine. Lowest I\u2019ve gone is 360p, mainly for long-running old shows that never had great picture quality to begin with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10197uf", "is_robot_indexable": true, "report_reasons": null, "author": "bobisnotmyuncIe", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10197uf/do_you_always_go_for_the_highest_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10197uf/do_you_always_go_for_the_highest_available/", "subreddit_subscribers": 663434, "created_utc": 1672654508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://iwataasks.nintendo.com/\n\nRecently,  Nintendo started unlisting some of their other pages. I worry that these interviews are at risk.\n\nThe site consists of a series of static pages that are all linking to each other, like a mini encyclopedia.\n\nI tried backing them up before, but I am not good enough at scripting to pull it off.\n\nWould really love it if someone could do this and maybe end up with a folder with all the htmls in there.", "author_fullname": "t2_13ta0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would someone here be kind enough to help archive the Iwata Asks interviews ? they're at risk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100v3q5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672611280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://iwataasks.nintendo.com/\"&gt;https://iwataasks.nintendo.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Recently,  Nintendo started unlisting some of their other pages. I worry that these interviews are at risk.&lt;/p&gt;\n\n&lt;p&gt;The site consists of a series of static pages that are all linking to each other, like a mini encyclopedia.&lt;/p&gt;\n\n&lt;p&gt;I tried backing them up before, but I am not good enough at scripting to pull it off.&lt;/p&gt;\n\n&lt;p&gt;Would really love it if someone could do this and maybe end up with a folder with all the htmls in there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bcqp--ico1bkbdkyXM3VsvPpZZHVWVWbdKfevw_FULU.jpg?auto=webp&amp;s=76cd6bb483523bbbeb55273d09b420f83e34ac60", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/bcqp--ico1bkbdkyXM3VsvPpZZHVWVWbdKfevw_FULU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fd3d804620e6f484098642c8f12b31bd61cf809", "width": 108, "height": 108}], "variants": {}, "id": "0BAKiuUVkKOay40_Zq_YOhb3Z5zEY9Idr6bSaGaminI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100v3q5", "is_robot_indexable": true, "report_reasons": null, "author": "mekilat", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/", "subreddit_subscribers": 663434, "created_utc": 1672611280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "PR4100 reporting 2x bad disk. Can you help me diagnose what I am looking at?  Can I just reboot this and hope it goes away, or should I be buying new disk?  Thanks", "author_fullname": "t2_jcbg4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Help with SMART data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 127, "top_awarded_type": null, "hide_score": false, "media_metadata": {"52hgjzyzhi9a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 98, "x": 108, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0f4dea253d6b48fa38b7025ab67c5bef2d170aa"}, {"y": 197, "x": 216, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=87f601db26d8332211cfc95c3a8ab7a9ed918d30"}, {"y": 292, "x": 320, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=400e70c737df5a6ee99aaaa8702a5bf48c75aa5d"}, {"y": 584, "x": 640, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=390d373bb093dc445dce4c5d5d12e36a5c1a6fac"}, {"y": 876, "x": 960, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e00afad19227a106780a29f28a19fe5d338ab55b"}, {"y": 986, "x": 1080, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9458f1717d4bf077ec33349104c80c8b6cce580e"}], "s": {"y": 1479, "x": 1620, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=1620&amp;format=pjpg&amp;auto=webp&amp;s=e685630f15afa051fb33229c8360cfc74c8c2cf4"}, "id": "52hgjzyzhi9a1"}, "g6kfvzyzhi9a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f6d72d5571d6e3cfd12f5f91ef2bdae9a33b3698"}, {"y": 276, "x": 216, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69b87f8c6cd7fb6fe8cec19d688e72fe8cb4a89d"}, {"y": 410, "x": 320, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=945ef2ad603c7f685f86caeb99f65b94377af82f"}, {"y": 820, "x": 640, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac820b319449600465a31c3dce97e63b900c589b"}, {"y": 1230, "x": 960, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=759142b7ea3619b32dfae96a1eda0f0e507fe37a"}, {"y": 1384, "x": 1080, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2af320e778beab50f543b7df24f8ba65ea49ecfa"}], "s": {"y": 2048, "x": 1598, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=1598&amp;format=pjpg&amp;auto=webp&amp;s=496e878d564e2dcc39809fac75082dc9ecb98137"}, "id": "g6kfvzyzhi9a1"}}, "name": "t3_100w2io", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 11, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "52hgjzyzhi9a1", "id": 225211750}, {"media_id": "g6kfvzyzhi9a1", "id": 225211751}]}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E8J3X0D2PjsIGYbdFslSM58jzWKK9BTmyFQAOiN4UZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672613781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PR4100 reporting 2x bad disk. Can you help me diagnose what I am looking at?  Can I just reboot this and hope it goes away, or should I be buying new disk?  Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/100w2io", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100w2io", "is_robot_indexable": true, "report_reasons": null, "author": "CactusJ", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100w2io/help_with_smart_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/100w2io", "subreddit_subscribers": 663434, "created_utc": 1672613781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been data hoarding for about a year now. I've bought several external hard drives ranging from 1TB-5TB to store everything (Seagate and WD). I didn't have too much data at first, and I like how they are portable and easy to plug and play on other devices.\n\nMy question is, would it be more cost effective to buy internal hard drives like 3.5\" NAS HDDs and buy a cheap enclosure to go with it? For example I've seen 10TB+ Internal Drives sell for cheaper than  pre-enclosed external ones, but I dont know if I would need an extra power source other then the USB plug that comes with a portable enclosure. I also wouldn't be opposed to go with a smaller drive if the extra power is needed on larger drives.\n\nI am no where near setting up a home server or using a cloud based system, just looking to plug into the TV through USB for now.", "author_fullname": "t2_5yypda5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Vs. Internal Hard Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100spir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been data hoarding for about a year now. I&amp;#39;ve bought several external hard drives ranging from 1TB-5TB to store everything (Seagate and WD). I didn&amp;#39;t have too much data at first, and I like how they are portable and easy to plug and play on other devices.&lt;/p&gt;\n\n&lt;p&gt;My question is, would it be more cost effective to buy internal hard drives like 3.5&amp;quot; NAS HDDs and buy a cheap enclosure to go with it? For example I&amp;#39;ve seen 10TB+ Internal Drives sell for cheaper than  pre-enclosed external ones, but I dont know if I would need an extra power source other then the USB plug that comes with a portable enclosure. I also wouldn&amp;#39;t be opposed to go with a smaller drive if the extra power is needed on larger drives.&lt;/p&gt;\n\n&lt;p&gt;I am no where near setting up a home server or using a cloud based system, just looking to plug into the TV through USB for now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100spir", "is_robot_indexable": true, "report_reasons": null, "author": "wtfhmmm", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/", "subreddit_subscribers": 663434, "created_utc": 1672605270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok, so I've been looking into ripping my blu-rays for a bit. From my understanding you may need to flash specific drives if you intend on ripping 4k UHD disks. I found the MakeMKV post about flashing drives but I'm still a bit confused\n\n1. I intend on only ripping non-UHD disks for the forseeable future. Do I need to flash the drive anyways, or is that only for ripping UHD?\n2. I saw that I could use an LG WH14NS40 or LG WH16NS40. I would need an enclosure. Would buying them straight from Amazon be an okay method?", "author_fullname": "t2_lge1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A few questions about Blu-rays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ul8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672610022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, so I&amp;#39;ve been looking into ripping my blu-rays for a bit. From my understanding you may need to flash specific drives if you intend on ripping 4k UHD disks. I found the MakeMKV post about flashing drives but I&amp;#39;m still a bit confused&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I intend on only ripping non-UHD disks for the forseeable future. Do I need to flash the drive anyways, or is that only for ripping UHD?&lt;/li&gt;\n&lt;li&gt;I saw that I could use an LG WH14NS40 or LG WH16NS40. I would need an enclosure. Would buying them straight from Amazon be an okay method?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ul8z", "is_robot_indexable": true, "report_reasons": null, "author": "delasislas", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/", "subreddit_subscribers": 663434, "created_utc": 1672610022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello hoaders , \n\nI am relatively new to this community and I have the most basic question but I still gotta ask \n\nI have a large movie/tv series library on me , till now I am storing the data on 5tb WD external hardrive I bought but I don't feel reliable on the hardrive since it is a physical one and my only source of backup for now   \nSo my question is what are the reliable ways of backing my 3tb data securely and In a controlled budget though. As I told I new to this community so Kindly explain your responses as much as you can   \n\n\nthanks and a very happy new year", "author_fullname": "t2_8rzf8b0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3Tb backup advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100stk0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello hoaders , &lt;/p&gt;\n\n&lt;p&gt;I am relatively new to this community and I have the most basic question but I still gotta ask &lt;/p&gt;\n\n&lt;p&gt;I have a large movie/tv series library on me , till now I am storing the data on 5tb WD external hardrive I bought but I don&amp;#39;t feel reliable on the hardrive since it is a physical one and my only source of backup for now&lt;br/&gt;\nSo my question is what are the reliable ways of backing my 3tb data securely and In a controlled budget though. As I told I new to this community so Kindly explain your responses as much as you can   &lt;/p&gt;\n\n&lt;p&gt;thanks and a very happy new year&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100stk0", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Artist_95", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100stk0/3tb_backup_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100stk0/3tb_backup_advice/", "subreddit_subscribers": 663434, "created_utc": 1672605567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I really like the Idea of Backblaze Personal Backup, where you just install their client and the entire computer gets synced to a remote location.  \nSo you guys know of similar software to this, which I could connect to my own private network drive? I don't seem to find anything that does \"whole pc backup, no questions asked\".  \n  \nThanks in advance!", "author_fullname": "t2_enms1n0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze style backup software (but selfhosted?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100sly7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really like the Idea of Backblaze Personal Backup, where you just install their client and the entire computer gets synced to a remote location.&lt;br/&gt;\nSo you guys know of similar software to this, which I could connect to my own private network drive? I don&amp;#39;t seem to find anything that does &amp;quot;whole pc backup, no questions asked&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100sly7", "is_robot_indexable": true, "report_reasons": null, "author": "sideprojects1337", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/", "subreddit_subscribers": 663434, "created_utc": 1672605013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First, I would like to apologize for the wall of text below. It's tough to digest since English is not my native language.\n\nUsing YouTube to store videos: I have done my homework and agree with the consensus. This is a bad idea. A significant risk of a ban at any moment without ever getting a chance to appeal or interact with a human being, let alone a chance to recover the data, a significant drop in quality across the board, the sudden apparition of exotic formats compatible with nothing, it goes on and on. Some have tried and are here to tell their horror stories on this sub.\n\nMy case is a bit different, though.\n\nA bit of background for you to get a rough picture of where I'll be standing for the next 18 months-ish (hopefully less than that).\n\nIn 48 hours, I will be homeless. I sold my decent NAS and the disks a few months ago to pay for gas and food. I've sold 90% of everything I had, and 10% left has no value and will be left on the sidewalk or discarded after calling a charity organization.\n\nI'm doing my best to bounce and have a realistic plan. Not some stuff written on a napkin, I've projected infrastructure, funding, I have a timeline to stick to, etc. Something solid.\n\nThis plan requires me to temporarily store about 900Gb of footage + without sound in high definition: mostly 4k but some 8k as well :(\n\nIn another life, I was running a small yet monetized YouTube channel. There are around 5k subs left (bots and dead people). This channel is 12 years old; everything is in the green with YT' ToS.\n\nThe post starts here: I've uploaded 200 Gb of footage in 10 days on my old YouTube channel. I've covered my tracks (I feel extra stupid after writing this) by populating correctly and accurately all the fields for each video, such as an original title, location, description, tags, etc. Since each vid is 20 s to 4 minutes long, this is a lot of work put towards failure. Remember, this content has no sound, so I've even added copyright-free music from the YouTube library to everything. This content is 100% original, I'm the only person appearing on some videos, but those videos can reveal vehicle location and rotation (no plates visible). So far, so good (standings). I've hit the daily upload limitations twice, though. No need to mention this is done manually. Videos are either flagged as unlisted or draft; high-definition rendering takes ages if I flag those private, and it's not the end of the world if it leaks.\n\nQuestion: should I keep on spending precious time on this? And finally, a critical question: please tell me if there is a better way to do this. I can pay just under the equivalent of $10 US a month if it comes with a price tag.\n\nCongratulations on making it that far into the post.", "author_fullname": "t2_inxy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A slightly different case of storing videos on YouTube. Comments and alternative solutions welcome.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100qb56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672599070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, I would like to apologize for the wall of text below. It&amp;#39;s tough to digest since English is not my native language.&lt;/p&gt;\n\n&lt;p&gt;Using YouTube to store videos: I have done my homework and agree with the consensus. This is a bad idea. A significant risk of a ban at any moment without ever getting a chance to appeal or interact with a human being, let alone a chance to recover the data, a significant drop in quality across the board, the sudden apparition of exotic formats compatible with nothing, it goes on and on. Some have tried and are here to tell their horror stories on this sub.&lt;/p&gt;\n\n&lt;p&gt;My case is a bit different, though.&lt;/p&gt;\n\n&lt;p&gt;A bit of background for you to get a rough picture of where I&amp;#39;ll be standing for the next 18 months-ish (hopefully less than that).&lt;/p&gt;\n\n&lt;p&gt;In 48 hours, I will be homeless. I sold my decent NAS and the disks a few months ago to pay for gas and food. I&amp;#39;ve sold 90% of everything I had, and 10% left has no value and will be left on the sidewalk or discarded after calling a charity organization.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing my best to bounce and have a realistic plan. Not some stuff written on a napkin, I&amp;#39;ve projected infrastructure, funding, I have a timeline to stick to, etc. Something solid.&lt;/p&gt;\n\n&lt;p&gt;This plan requires me to temporarily store about 900Gb of footage + without sound in high definition: mostly 4k but some 8k as well :(&lt;/p&gt;\n\n&lt;p&gt;In another life, I was running a small yet monetized YouTube channel. There are around 5k subs left (bots and dead people). This channel is 12 years old; everything is in the green with YT&amp;#39; ToS.&lt;/p&gt;\n\n&lt;p&gt;The post starts here: I&amp;#39;ve uploaded 200 Gb of footage in 10 days on my old YouTube channel. I&amp;#39;ve covered my tracks (I feel extra stupid after writing this) by populating correctly and accurately all the fields for each video, such as an original title, location, description, tags, etc. Since each vid is 20 s to 4 minutes long, this is a lot of work put towards failure. Remember, this content has no sound, so I&amp;#39;ve even added copyright-free music from the YouTube library to everything. This content is 100% original, I&amp;#39;m the only person appearing on some videos, but those videos can reveal vehicle location and rotation (no plates visible). So far, so good (standings). I&amp;#39;ve hit the daily upload limitations twice, though. No need to mention this is done manually. Videos are either flagged as unlisted or draft; high-definition rendering takes ages if I flag those private, and it&amp;#39;s not the end of the world if it leaks.&lt;/p&gt;\n\n&lt;p&gt;Question: should I keep on spending precious time on this? And finally, a critical question: please tell me if there is a better way to do this. I can pay just under the equivalent of $10 US a month if it comes with a price tag.&lt;/p&gt;\n\n&lt;p&gt;Congratulations on making it that far into the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100qb56", "is_robot_indexable": true, "report_reasons": null, "author": "-Nicolas-", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/", "subreddit_subscribers": 663434, "created_utc": 1672599070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t want to pay for iCloud as buying actual storage is much cheaper, at least in the long run. I have a Windows PC that\u2019s on 24/7 and it has a 1TB SSD, which has ~500GB free, more than enough for my photos and videos.", "author_fullname": "t2_kygivbfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I back up my iPhone\u2019s gallery to my PC automatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ziri", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672622872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t want to pay for iCloud as buying actual storage is much cheaper, at least in the long run. I have a Windows PC that\u2019s on 24/7 and it has a 1TB SSD, which has ~500GB free, more than enough for my photos and videos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ziri", "is_robot_indexable": true, "report_reasons": null, "author": "ffsstfualready", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/", "subreddit_subscribers": 663434, "created_utc": 1672622872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The easy answer: RETWEET.  \n\n\nWhen you download your archive, for some reason just a simple retweet saves all media contained in a tweet.  What I consider insane is what is shown by in the \"Likes\" tab in the archive is almost nothing - ONLY the text and 2 LINKS POINTING TO THE SAME TWEET (wtf?). A retweet has the same content but saves the **IMAGES** and **VIDEOS** and the author's **USERNAME** which for some reason that is beyond me the \"Likes\" tab does not.\n\n\"Quote Retweets\" suffer the same problem as \"Likes\" so it might be better to retweet before quoting.\n\nDownloading data from the Twitter itself is infinitely better since it is complete than using any app so there are two options:\n\n1. **Retweet Everything**\n2. **Extract Links from Archive then Create an App to Retweet Everything**\n\nThe problem with the 1st option is that it fills your follower's timeline and that is a problem. You can make a 2nd account to personally retweet the same stuff but that's just as exhausting.\n\nThe 2nd option is probably more feasible but the best I can probably do is extract the tweet link from the archive but that's basically it. I'd imagine a dummy account is needed where an app is fed with a list of links to retweet. Archiving the dummy account saves everything from the main account. \n\n&amp;#x200B;\n\n*I really don't know how to implement the 2nd option and I only know basic stuff in using the API which I think can be done there* (for now?) but I'm hoping some data god will see this and is able to lend their power in creating one. I'm just a bit sick of using apps - it's either incomplete, extremely slow, or does not have the complete data.  Also, the lack of the use of API for saving account data is kinda, in general, iffy for me.\n\nI think I understand the data storage implication of not saving media from likes since it probably outnumbers tweets by a lot, and they are not bounded by daily limits. Still, I think the way they are handling when you do want to archive is insanity. Speaking of limits - twitter has a daily limit of 2400 tweets but I think that is more than enough to save an entire account within a day.", "author_fullname": "t2_n62192z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to save media from tweets, likes, and bookmarks in Twitter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100plzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672598186.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672597251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The easy answer: RETWEET.  &lt;/p&gt;\n\n&lt;p&gt;When you download your archive, for some reason just a simple retweet saves all media contained in a tweet.  What I consider insane is what is shown by in the &amp;quot;Likes&amp;quot; tab in the archive is almost nothing - ONLY the text and 2 LINKS POINTING TO THE SAME TWEET (wtf?). A retweet has the same content but saves the &lt;strong&gt;IMAGES&lt;/strong&gt; and &lt;strong&gt;VIDEOS&lt;/strong&gt; and the author&amp;#39;s &lt;strong&gt;USERNAME&lt;/strong&gt; which for some reason that is beyond me the &amp;quot;Likes&amp;quot; tab does not.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Quote Retweets&amp;quot; suffer the same problem as &amp;quot;Likes&amp;quot; so it might be better to retweet before quoting.&lt;/p&gt;\n\n&lt;p&gt;Downloading data from the Twitter itself is infinitely better since it is complete than using any app so there are two options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Retweet Everything&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Extract Links from Archive then Create an App to Retweet Everything&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problem with the 1st option is that it fills your follower&amp;#39;s timeline and that is a problem. You can make a 2nd account to personally retweet the same stuff but that&amp;#39;s just as exhausting.&lt;/p&gt;\n\n&lt;p&gt;The 2nd option is probably more feasible but the best I can probably do is extract the tweet link from the archive but that&amp;#39;s basically it. I&amp;#39;d imagine a dummy account is needed where an app is fed with a list of links to retweet. Archiving the dummy account saves everything from the main account. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I really don&amp;#39;t know how to implement the 2nd option and I only know basic stuff in using the API which I think can be done there&lt;/em&gt; (for now?) but I&amp;#39;m hoping some data god will see this and is able to lend their power in creating one. I&amp;#39;m just a bit sick of using apps - it&amp;#39;s either incomplete, extremely slow, or does not have the complete data.  Also, the lack of the use of API for saving account data is kinda, in general, iffy for me.&lt;/p&gt;\n\n&lt;p&gt;I think I understand the data storage implication of not saving media from likes since it probably outnumbers tweets by a lot, and they are not bounded by daily limits. Still, I think the way they are handling when you do want to archive is insanity. Speaking of limits - twitter has a daily limit of 2400 tweets but I think that is more than enough to save an entire account within a day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100plzr", "is_robot_indexable": true, "report_reasons": null, "author": "Altrigeo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100plzr/how_to_save_media_from_tweets_likes_and_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100plzr/how_to_save_media_from_tweets_likes_and_bookmarks/", "subreddit_subscribers": 663434, "created_utc": 1672597251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellas, I have a few channels I scrape occasionally on Bitchute using a custom script I wrote and using yt-dlp. I've noticed that a lot of older videos no longer archive, and when I check the videos on Bitchute they no longer load - so it's not an issue with my script or yt-dlp. The latest channel I tried to archive cut off at a video on December 3, 2019 - and all videos older than that are no longer playing on the website. \n\nIs this an issue with Bitchute automatically no longer hosting videos once they've been uploaded for a certain amount of time? Anyone else run into this problem? Any input is helpful. Thanks guys.", "author_fullname": "t2_p9vg3wjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone having problem archiving Bitchute channels using yt-dlp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100plvd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672597242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellas, I have a few channels I scrape occasionally on Bitchute using a custom script I wrote and using yt-dlp. I&amp;#39;ve noticed that a lot of older videos no longer archive, and when I check the videos on Bitchute they no longer load - so it&amp;#39;s not an issue with my script or yt-dlp. The latest channel I tried to archive cut off at a video on December 3, 2019 - and all videos older than that are no longer playing on the website. &lt;/p&gt;\n\n&lt;p&gt;Is this an issue with Bitchute automatically no longer hosting videos once they&amp;#39;ve been uploaded for a certain amount of time? Anyone else run into this problem? Any input is helpful. Thanks guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100plvd", "is_robot_indexable": true, "report_reasons": null, "author": "TCIE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/", "subreddit_subscribers": 663434, "created_utc": 1672597242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a bunch of Sans Digital  4 bay eSATA external cases. I also just recently went through and upgraded a the drives in my servers. So I also have a bunch of unused hard disks. I was wondering if anyone knew of a way to convert the Sans Digital 4 bay eSATA cases to SAS. When I open up one of the Sans Digital cases, I see that there is a single eSATA to SATA cable running to the backplane. There is another ribbon cable for the activity lights and a couple molex connectors to the backplane.   \n\n\nWould this be worthwhile or just more trouble than its worth? If so, what are some decent, inexpensive, alternatives for an external 4/8bay SAS enclosures? I have about 20 drives I'd like to repurpose.   \n\n\nThanks!", "author_fullname": "t2_n0wog3nx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sans Digital 4 bay eSATA conversion to SAS ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_101ggu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672676305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of Sans Digital  4 bay eSATA external cases. I also just recently went through and upgraded a the drives in my servers. So I also have a bunch of unused hard disks. I was wondering if anyone knew of a way to convert the Sans Digital 4 bay eSATA cases to SAS. When I open up one of the Sans Digital cases, I see that there is a single eSATA to SATA cable running to the backplane. There is another ribbon cable for the activity lights and a couple molex connectors to the backplane.   &lt;/p&gt;\n\n&lt;p&gt;Would this be worthwhile or just more trouble than its worth? If so, what are some decent, inexpensive, alternatives for an external 4/8bay SAS enclosures? I have about 20 drives I&amp;#39;d like to repurpose.   &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "101ggu6", "is_robot_indexable": true, "report_reasons": null, "author": "Dan_Gun", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/101ggu6/sans_digital_4_bay_esata_conversion_to_sas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/101ggu6/sans_digital_4_bay_esata_conversion_to_sas/", "subreddit_subscribers": 663434, "created_utc": 1672676305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have 10 Terabytes of drive capcity But I am in process of upgrading my pc.\n\nNot Sure If I should take drives and build cheap server or buy nas most of the storage is HDD.\n\nMy concern is power but engegy prices are so high in the United Kingdom would it just be cheaper to a buy a nas?", "author_fullname": "t2_mhtwxne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help optimizing storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100zihf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672622847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have 10 Terabytes of drive capcity But I am in process of upgrading my pc.&lt;/p&gt;\n\n&lt;p&gt;Not Sure If I should take drives and build cheap server or buy nas most of the storage is HDD.&lt;/p&gt;\n\n&lt;p&gt;My concern is power but engegy prices are so high in the United Kingdom would it just be cheaper to a buy a nas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100zihf", "is_robot_indexable": true, "report_reasons": null, "author": "drjonsmith", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/", "subreddit_subscribers": 663434, "created_utc": 1672622847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nPlease, anyone can detailed explain the difference about use sync function anb backup function.\n\nOther thing, i have deleted files from pc and the files dont get deleted in cloud and the software started to download them again, my objetive is to sync but i constantly move files trough folders and drives and i need the files get deleted on cloud and dont be downloaded again. Anyone can share some information to help? Thanks.", "author_fullname": "t2_uavj7l2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference btween backup and sync options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10112rw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672627271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please, anyone can detailed explain the difference about use sync function anb backup function.&lt;/p&gt;\n\n&lt;p&gt;Other thing, i have deleted files from pc and the files dont get deleted in cloud and the software started to download them again, my objetive is to sync but i constantly move files trough folders and drives and i need the files get deleted on cloud and dont be downloaded again. Anyone can share some information to help? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10112rw", "is_robot_indexable": true, "report_reasons": null, "author": "chaos4455", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10112rw/difference_btween_backup_and_sync_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10112rw/difference_btween_backup_and_sync_options/", "subreddit_subscribers": 663434, "created_utc": 1672627271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I just bought a refurbished R720xd with 2 SSD, 12 HDD and a PERC H710p raid controller. I plan to used some of the HDD for backup.\n\nAt day 1 the raid controller was working and I configured the RAID. But after rebooting to install the OS, the controller fell into fault state 'F/W in fault state - MFI Register State 0xF0010002. Adapter at Baseport is not responding'. \n\nI tried several things such as removing the HDD, removing the controller, the battery and plugging back, also a video on how to recover a H710 on YT but nothing worked at the moment. Do you have any idea on what to do ?", "author_fullname": "t2_49n54vd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100s3lw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672603689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I just bought a refurbished R720xd with 2 SSD, 12 HDD and a PERC H710p raid controller. I plan to used some of the HDD for backup.&lt;/p&gt;\n\n&lt;p&gt;At day 1 the raid controller was working and I configured the RAID. But after rebooting to install the OS, the controller fell into fault state &amp;#39;F/W in fault state - MFI Register State 0xF0010002. Adapter at Baseport is not responding&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;I tried several things such as removing the HDD, removing the controller, the battery and plugging back, also a video on how to recover a H710 on YT but nothing worked at the moment. Do you have any idea on what to do ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100s3lw", "is_robot_indexable": true, "report_reasons": null, "author": "jeansami", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100s3lw/new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100s3lw/new_server/", "subreddit_subscribers": 663434, "created_utc": 1672603689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for recs for a way to merge different backups (whatsapp, signal, text message databases) into a central offline db with some sort of search ability. Can anyone suggest the best way to go about this?\n\nI'm comfortable with tech-heavy solutions and can get all the data from my encrypted backups.", "author_fullname": "t2_16u9go", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation for multi-channel message backup solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100r4er", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672601194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for recs for a way to merge different backups (whatsapp, signal, text message databases) into a central offline db with some sort of search ability. Can anyone suggest the best way to go about this?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m comfortable with tech-heavy solutions and can get all the data from my encrypted backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100r4er", "is_robot_indexable": true, "report_reasons": null, "author": "Thund3r_Struck", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/", "subreddit_subscribers": 663434, "created_utc": 1672601194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, i have alot of good and bad quality videos but the most of these are really big and uncomprimised, is there a \"magic\" way, that i cant drag and drop the root directory and i will get small files with little quality loss ?  \n\n\nUntil now I use the Shutterencoder but to configure the settings for each series new again is really annoying.", "author_fullname": "t2_m1xszpa0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to compress video files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100oeys", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672594074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i have alot of good and bad quality videos but the most of these are really big and uncomprimised, is there a &amp;quot;magic&amp;quot; way, that i cant drag and drop the root directory and i will get small files with little quality loss ?  &lt;/p&gt;\n\n&lt;p&gt;Until now I use the Shutterencoder but to configure the settings for each series new again is really annoying.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100oeys", "is_robot_indexable": true, "report_reasons": null, "author": "InternalPercentage88", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100oeys/how_to_compress_video_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100oeys/how_to_compress_video_files/", "subreddit_subscribers": 663434, "created_utc": 1672594074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Finally throwing in the towel here; spent hours trying to figure this out to no success. Any help? Imgur album at [https://imgur.com/a/4lUMDfC](https://imgur.com/a/4lUMDfC). Site in question's NSFW, but the content I'm looking for help with isn't.\n\nIdea here is that I'd like to use gallery-dl's extractor to REPLICATE [aryion](https://aryion.com)'s gallery folder structure up to four levels deep; they're structured where individual artists are able to organize works into individual custom folders akin to local storage, so you'll often encounter content that's subcatergorized via multiple iterations (IE 'gallery', 'content type', 'work sequence'). \\\\Gallery\\_DL\\\\gallery-dl.exe -K [https://aryion.com](https://aryion.com)/\\*\\*\\* will show you quick that this information is sent from the api via the 'path\\[N\\]' container...\n\nBut the problem is, I simply cannot reverse engineer a working solution to get more than one iteration deep into that file structure, and not for lack of trying. I keep getting either invalid syntax errors (IE, my uneducated scripting's borked), 'index out of range' errors (IE, gallery-dl is attempting to read 'path\\[N\\]' and finding that data empty, as in calling path\\[3\\] when only paths \\[0\\] and \\[1\\] exist), or else creating a local directory that only partially captures what I'm looking to create.\n\nDue to the nature of the site I can't really recommend trying my exact usecase out yourself ^((this is where I feebly but truthfully claim I'm just using this user specifically as a blind example)) , but I figure the examples in that gallery should show what I'm going for well enough. I'm 1000% certain there's some filesystem function or obvious command what'll allow for a far cleaner 'foreach' style solution than my current hacked-together if-thans, but given I haven't been able to dig up a single similar example to work off of I'm looking for any direction I can get. Thanks!\n\n\\-When I try to get this all done with a single directory line hashing out \"{path\\[0\\]}, {path\\[1\\]}, etc\" in sequence, **this creates a series of \"None\" folders as deep as the number of paths I'm asking it look for**; this made me think I could axe any process where the api was returning 'null' or 'none' via a !=, but I didn't find any success on that front. I also thought the issue might be with the fact that any given {path\\[\\*\\]} in fact equates to a list of full filepath strings - and clearly not knowing how to call just one string specifically, I tried asking functions to only run if '{path\\[x\\]} = \\*', the idea there being that a wildcard might inherently exclude null values - but no joy on that either.\n\n\\-The closest I've gotten is a **single iteration of foldering** \\- IE, the base artist folder and a single subcategory, with all content within that sub all lumped together . You can see this in the album...\n\n\\-But the default behavior of Gallery-DL without any \"directory\" instructions comes annoyingly close, too. This creates sub-subfolders, but does not place them ***in*** their respective level 1 subfolders. Which is to say it creates /mainfolder/ and a /mainfolder/subfolder directory, but then ***also*** numerous /mainfolder/subfolder-subsubfolder directories. Meaning it's clearly capable of reading the deeper folder levels, then interpreting the script as  something like \"{artist}\", \"{path\\[0\\]}-\"{path\\[1\\]}\". **I just want to be able to capture the per-content paths in the same way, to then use however I'd like.**", "author_fullname": "t2_likkt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-DL Folder Iteration - How to Create Variable Sub-Directories / continue past null api calls?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1016chi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672645482.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672643845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Finally throwing in the towel here; spent hours trying to figure this out to no success. Any help? Imgur album at &lt;a href=\"https://imgur.com/a/4lUMDfC\"&gt;https://imgur.com/a/4lUMDfC&lt;/a&gt;. Site in question&amp;#39;s NSFW, but the content I&amp;#39;m looking for help with isn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Idea here is that I&amp;#39;d like to use gallery-dl&amp;#39;s extractor to REPLICATE &lt;a href=\"https://aryion.com\"&gt;aryion&lt;/a&gt;&amp;#39;s gallery folder structure up to four levels deep; they&amp;#39;re structured where individual artists are able to organize works into individual custom folders akin to local storage, so you&amp;#39;ll often encounter content that&amp;#39;s subcatergorized via multiple iterations (IE &amp;#39;gallery&amp;#39;, &amp;#39;content type&amp;#39;, &amp;#39;work sequence&amp;#39;). \\Gallery_DL\\gallery-dl.exe -K &lt;a href=\"https://aryion.com\"&gt;https://aryion.com&lt;/a&gt;/*** will show you quick that this information is sent from the api via the &amp;#39;path[N]&amp;#39; container...&lt;/p&gt;\n\n&lt;p&gt;But the problem is, I simply cannot reverse engineer a working solution to get more than one iteration deep into that file structure, and not for lack of trying. I keep getting either invalid syntax errors (IE, my uneducated scripting&amp;#39;s borked), &amp;#39;index out of range&amp;#39; errors (IE, gallery-dl is attempting to read &amp;#39;path[N]&amp;#39; and finding that data empty, as in calling path[3] when only paths [0] and [1] exist), or else creating a local directory that only partially captures what I&amp;#39;m looking to create.&lt;/p&gt;\n\n&lt;p&gt;Due to the nature of the site I can&amp;#39;t really recommend trying my exact usecase out yourself &lt;sup&gt;(this is where I feebly but truthfully claim I&amp;#39;m just using this user specifically as a blind example&lt;/sup&gt;) , but I figure the examples in that gallery should show what I&amp;#39;m going for well enough. I&amp;#39;m 1000% certain there&amp;#39;s some filesystem function or obvious command what&amp;#39;ll allow for a far cleaner &amp;#39;foreach&amp;#39; style solution than my current hacked-together if-thans, but given I haven&amp;#39;t been able to dig up a single similar example to work off of I&amp;#39;m looking for any direction I can get. Thanks!&lt;/p&gt;\n\n&lt;p&gt;-When I try to get this all done with a single directory line hashing out &amp;quot;{path[0]}, {path[1]}, etc&amp;quot; in sequence, &lt;strong&gt;this creates a series of &amp;quot;None&amp;quot; folders as deep as the number of paths I&amp;#39;m asking it look for&lt;/strong&gt;; this made me think I could axe any process where the api was returning &amp;#39;null&amp;#39; or &amp;#39;none&amp;#39; via a !=, but I didn&amp;#39;t find any success on that front. I also thought the issue might be with the fact that any given {path[*]} in fact equates to a list of full filepath strings - and clearly not knowing how to call just one string specifically, I tried asking functions to only run if &amp;#39;{path[x]} = *&amp;#39;, the idea there being that a wildcard might inherently exclude null values - but no joy on that either.&lt;/p&gt;\n\n&lt;p&gt;-The closest I&amp;#39;ve gotten is a &lt;strong&gt;single iteration of foldering&lt;/strong&gt; - IE, the base artist folder and a single subcategory, with all content within that sub all lumped together . You can see this in the album...&lt;/p&gt;\n\n&lt;p&gt;-But the default behavior of Gallery-DL without any &amp;quot;directory&amp;quot; instructions comes annoyingly close, too. This creates sub-subfolders, but does not place them &lt;strong&gt;&lt;em&gt;in&lt;/em&gt;&lt;/strong&gt; their respective level 1 subfolders. Which is to say it creates /mainfolder/ and a /mainfolder/subfolder directory, but then &lt;strong&gt;&lt;em&gt;also&lt;/em&gt;&lt;/strong&gt; numerous /mainfolder/subfolder-subsubfolder directories. Meaning it&amp;#39;s clearly capable of reading the deeper folder levels, then interpreting the script as  something like &amp;quot;{artist}&amp;quot;, &amp;quot;{path[0]}-&amp;quot;{path[1]}&amp;quot;. &lt;strong&gt;I just want to be able to capture the per-content paths in the same way, to then use however I&amp;#39;d like.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?auto=webp&amp;s=6a09fa9a44ef8d270e85eb9fce036c635a27c9c6", "width": 1333, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ca0aa3d618515f518a3dc1c5b3fdeb0b6d0d3b4", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=214bee8c15877cd432d591b1a1f5eb61a670504b", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa74c26ebab9795fa0687030ff1bab09cb22a197", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f409ff3647c70d64b585317dc121f12b9c122b8b", "width": 640, "height": 326}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61f7c6d47dcf3f418dce45472903814c88b12377", "width": 960, "height": 489}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5dcd4b89386a4d35ac506934d19e9544c5d58cb9", "width": 1080, "height": 550}], "variants": {}, "id": "bFuSCucOh6zCAsiPW6kAjd2DRdstJmukjT1dZG8ecLA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1016chi", "is_robot_indexable": true, "report_reasons": null, "author": "gwre", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/", "subreddit_subscribers": 663434, "created_utc": 1672643845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any recommendations for a DAS drawer? Looking for 12-40 bays. Currently using an MSA60 that I've had forever and 4 lanes of 3Gb SAS is a bit of a choke. 6G would be fine, 12G preferred.. I remember there was a Lenovo that also had a couple 2.5\" bays that might be good for what I'm doing, but I don't know what the model # was.", "author_fullname": "t2_e7jo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DAS drawer recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100tu5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672608156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations for a DAS drawer? Looking for 12-40 bays. Currently using an MSA60 that I&amp;#39;ve had forever and 4 lanes of 3Gb SAS is a bit of a choke. 6G would be fine, 12G preferred.. I remember there was a Lenovo that also had a couple 2.5&amp;quot; bays that might be good for what I&amp;#39;m doing, but I don&amp;#39;t know what the model # was.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100tu5q", "is_robot_indexable": true, "report_reasons": null, "author": "frankd412", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/", "subreddit_subscribers": 663434, "created_utc": 1672608156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://streamable.com/tv3pct](https://streamable.com/tv3pct)\n\nI bought this a few days ago, actually this is a replacement because the original drive that the seller sent me had the same clicking noise issue. Is the hard drive faulty or there's something wrong with PC components? I'd tried removing my gpu, one of my 8gb ram, fan case, buying new sata cables, trying different sata ports and power cable but the issue still persists. The clicking happens when loading a game, copying/reading files, during gameplay.", "author_fullname": "t2_qmzj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my brand new Seagate hard drive faulty? Clicking noise issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100tpwy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672607862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://streamable.com/tv3pct\"&gt;https://streamable.com/tv3pct&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I bought this a few days ago, actually this is a replacement because the original drive that the seller sent me had the same clicking noise issue. Is the hard drive faulty or there&amp;#39;s something wrong with PC components? I&amp;#39;d tried removing my gpu, one of my 8gb ram, fan case, buying new sata cables, trying different sata ports and power cable but the issue still persists. The clicking happens when loading a game, copying/reading files, during gameplay.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cAYii764SmKPPgxd7jjzV4XmvnBSoFdQFaHBqkV2Qyk.jpg?auto=webp&amp;s=e6a62009105ccda0002eeec88ad5932c905c3ee9", "width": 368, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/cAYii764SmKPPgxd7jjzV4XmvnBSoFdQFaHBqkV2Qyk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c741081acb6d6cba57a296b44f56074a18390342", "width": 108, "height": 187}, {"url": "https://external-preview.redd.it/cAYii764SmKPPgxd7jjzV4XmvnBSoFdQFaHBqkV2Qyk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83e03c060a6123adc7e00a7ae87bf87a5d00c040", "width": 216, "height": 375}, {"url": "https://external-preview.redd.it/cAYii764SmKPPgxd7jjzV4XmvnBSoFdQFaHBqkV2Qyk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8f7dd8472ebea1c9fda173058f911a1c665fc334", "width": 320, "height": 556}], "variants": {}, "id": "7zFHqO1RfC42xNVOSrBee2jNMY6HK9rdHEPe2LABvJQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100tpwy", "is_robot_indexable": true, "report_reasons": null, "author": "ArDux", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100tpwy/is_my_brand_new_seagate_hard_drive_faulty/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100tpwy/is_my_brand_new_seagate_hard_drive_faulty/", "subreddit_subscribers": 663434, "created_utc": 1672607862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to have a NAS with two requirements. It must have ECC memory and ZFS. I'm looking at TrueNAS software for the ZFS, but I am a bit lost on the ECC part.\n\nI am considering getting one of the TrueNAS systems, but that's a big splurge. $1000+ and that's not even including the cost of the drives themselves.\n\nI have seen on PC Part Picker that I can get ECC compatible processors in the $50 range, but the motherboards are in the $500 range (yikes). Still better than buying a TrueNAS machine, but once I've bought all the other parts (RAM, power supply, graphics card, case) I could see it being closer in price to the expensive TruaNAS.\n\nI think I've discovered a good option. On both Amazon and eBay are a lot of refurbished Dell and HP Xeon desktops. They vary in price from $100-500. The Xeon and motherboard should be ECC compatible. I don't know if the RAM is since these are refurbished machines, but buying my own ECC RAM is something I could do. This isn't the only computer I've looked at, but an example of the kinds that I've seen: [https://www.amazon.com/Dell-Precision-T5810-Mid-Tower-Workstation/dp/B07NPC33PB/ref=sr\\_1\\_3?crid=13EZXTI6EGDKC&amp;keywords=xeon+desktop&amp;qid=1672604892&amp;sprefix=xeon%2Caps%2C1148&amp;sr=8-3](https://www.amazon.com/Dell-Precision-T5810-Mid-Tower-Workstation/dp/B07NPC33PB/ref=sr_1_3?crid=13EZXTI6EGDKC&amp;keywords=xeon+desktop&amp;qid=1672604892&amp;sprefix=xeon%2Caps%2C1148&amp;sr=8-3)\n\nThese computers are typically advertised as coming with some type of storage, but I would just gut them and add my own storage (hard drives plus a small boot SSD). The only downside is that most of these computers seem to only have two 3.5 inch hard drive bays. Buying one might be the most cost effective way to get all ECC parts and I could just install them in my own case, but I'd rather not go the full cannibalization route. Also, some of these computers have TWO Xeon processors! Interesting, but I don't know anything about dual processor set ups.\n\nSorry if I sound like a total noob. I kind of know about some of this stuff through osmosis (watched lots of YouTube and I browse this forum a lot), but some of this stuff is really heady. I think I'm most serious about the refurbished \"former business\" computer route, so if any of you got something I should know about doing that, please let me know.", "author_fullname": "t2_nvqqiopc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS Advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100t2ol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672606252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to have a NAS with two requirements. It must have ECC memory and ZFS. I&amp;#39;m looking at TrueNAS software for the ZFS, but I am a bit lost on the ECC part.&lt;/p&gt;\n\n&lt;p&gt;I am considering getting one of the TrueNAS systems, but that&amp;#39;s a big splurge. $1000+ and that&amp;#39;s not even including the cost of the drives themselves.&lt;/p&gt;\n\n&lt;p&gt;I have seen on PC Part Picker that I can get ECC compatible processors in the $50 range, but the motherboards are in the $500 range (yikes). Still better than buying a TrueNAS machine, but once I&amp;#39;ve bought all the other parts (RAM, power supply, graphics card, case) I could see it being closer in price to the expensive TruaNAS.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;ve discovered a good option. On both Amazon and eBay are a lot of refurbished Dell and HP Xeon desktops. They vary in price from $100-500. The Xeon and motherboard should be ECC compatible. I don&amp;#39;t know if the RAM is since these are refurbished machines, but buying my own ECC RAM is something I could do. This isn&amp;#39;t the only computer I&amp;#39;ve looked at, but an example of the kinds that I&amp;#39;ve seen: &lt;a href=\"https://www.amazon.com/Dell-Precision-T5810-Mid-Tower-Workstation/dp/B07NPC33PB/ref=sr_1_3?crid=13EZXTI6EGDKC&amp;amp;keywords=xeon+desktop&amp;amp;qid=1672604892&amp;amp;sprefix=xeon%2Caps%2C1148&amp;amp;sr=8-3\"&gt;https://www.amazon.com/Dell-Precision-T5810-Mid-Tower-Workstation/dp/B07NPC33PB/ref=sr_1_3?crid=13EZXTI6EGDKC&amp;amp;keywords=xeon+desktop&amp;amp;qid=1672604892&amp;amp;sprefix=xeon%2Caps%2C1148&amp;amp;sr=8-3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;These computers are typically advertised as coming with some type of storage, but I would just gut them and add my own storage (hard drives plus a small boot SSD). The only downside is that most of these computers seem to only have two 3.5 inch hard drive bays. Buying one might be the most cost effective way to get all ECC parts and I could just install them in my own case, but I&amp;#39;d rather not go the full cannibalization route. Also, some of these computers have TWO Xeon processors! Interesting, but I don&amp;#39;t know anything about dual processor set ups.&lt;/p&gt;\n\n&lt;p&gt;Sorry if I sound like a total noob. I kind of know about some of this stuff through osmosis (watched lots of YouTube and I browse this forum a lot), but some of this stuff is really heady. I think I&amp;#39;m most serious about the refurbished &amp;quot;former business&amp;quot; computer route, so if any of you got something I should know about doing that, please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100t2ol", "is_robot_indexable": true, "report_reasons": null, "author": "last_escape_pod", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100t2ol/nas_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100t2ol/nas_advice/", "subreddit_subscribers": 663434, "created_utc": 1672606252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently using a setup with Radarr, Sonarr, Bazarr &amp; Jellyfin and i've split my media archive into 2 sets of files. An archive directory and a staging directory where archive contains my 'curated' files with verified subtitles and staging contains the files as fetched by Radarr, Sonarr &amp; Bazarr. I move them manually when i verified them.\n\nBut, i hope to automate this, does anyone know if there is a script/tool for this? By combining information from Radarr, Sonarr &amp; Bazarr i can figure out if a movie/season is complete and has subtitles.", "author_fullname": "t2_hak8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Script to curate downloaded media from *arr", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1018lwe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672652223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently using a setup with Radarr, Sonarr, Bazarr &amp;amp; Jellyfin and i&amp;#39;ve split my media archive into 2 sets of files. An archive directory and a staging directory where archive contains my &amp;#39;curated&amp;#39; files with verified subtitles and staging contains the files as fetched by Radarr, Sonarr &amp;amp; Bazarr. I move them manually when i verified them.&lt;/p&gt;\n\n&lt;p&gt;But, i hope to automate this, does anyone know if there is a script/tool for this? By combining information from Radarr, Sonarr &amp;amp; Bazarr i can figure out if a movie/season is complete and has subtitles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1018lwe", "is_robot_indexable": true, "report_reasons": null, "author": "oddish2211", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1018lwe/script_to_curate_downloaded_media_from_arr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1018lwe/script_to_curate_downloaded_media_from_arr/", "subreddit_subscribers": 663434, "created_utc": 1672652223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using MG08ACA16TE (MG08) for recording TV broadcasts 24/7 in my bedroom. Unfortunately the HDD is not that quiet. [It has thudding sound like others in this sub mentioned.](https://www.reddit.com/r/DataHoarder/comments/xomoea/is_this_thudding_sound_normal_toshiba_mg08_drive/)  Not unbearable, but it would be nice if I can get rid of it. I'm thinking of replacing that drive with larger one, and repurposing MG08 for backup drive, or for NAS drive which I only power on with Wake on LAN when I need it.\n\nTo minimize power consumption I only want to use single drive. WD is the only manufacturer that makes 22TB drive. Which model is quieter, WD221PURP (Purple Pro) or WD221KFGX (Red Pro)? On datasheets both models have the same acoustics (same dBA), so the actual noise level when used at home is also the same?\n\nUltrastar/Gold model has the same dbA value on datasheets too but consumes more power than those 2 models.\n\n[https://documents.westerndigital.com/content/dam/doc-library/en\\_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf)\n\n[https://documents.westerndigital.com/content/dam/doc-library/en\\_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf)", "author_fullname": "t2_13pr7xbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which WD 22TB HDD is quieter, WD Red Pro or WD Purple Pro?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1016035", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672642972.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672642703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using MG08ACA16TE (MG08) for recording TV broadcasts 24/7 in my bedroom. Unfortunately the HDD is not that quiet. &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/xomoea/is_this_thudding_sound_normal_toshiba_mg08_drive/\"&gt;It has thudding sound like others in this sub mentioned.&lt;/a&gt;  Not unbearable, but it would be nice if I can get rid of it. I&amp;#39;m thinking of replacing that drive with larger one, and repurposing MG08 for backup drive, or for NAS drive which I only power on with Wake on LAN when I need it.&lt;/p&gt;\n\n&lt;p&gt;To minimize power consumption I only want to use single drive. WD is the only manufacturer that makes 22TB drive. Which model is quieter, WD221PURP (Purple Pro) or WD221KFGX (Red Pro)? On datasheets both models have the same acoustics (same dBA), so the actual noise level when used at home is also the same?&lt;/p&gt;\n\n&lt;p&gt;Ultrastar/Gold model has the same dbA value on datasheets too but consumes more power than those 2 models.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1016035", "is_robot_indexable": true, "report_reasons": null, "author": "vroad_x", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1016035/which_wd_22tb_hdd_is_quieter_wd_red_pro_or_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1016035/which_wd_22tb_hdd_is_quieter_wd_red_pro_or_wd/", "subreddit_subscribers": 663434, "created_utc": 1672642703.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}