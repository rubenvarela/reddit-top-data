{"kind": "Listing", "data": {"after": "t3_100r4er", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.\n\nBelow is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.\n\n# There are a number of external factors that can impact or influence the availability of information on the internet. \n\n&amp;#x200B;\n\n* Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo \\[[1](https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/)\\] \\[[2](https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480)\\] \\[[3](https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/)\\] \\[[4](https://www.wired.co.uk/article/lets-play-youtube-crackdown)\\], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. \n* Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. \n* Environmental disasters or internal societal discourse leading to the destruction or [sabotage](https://en.wikipedia.org/wiki/2021_South_African_unrest) of local and state infrastructure. \n* User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. \n* Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. \n\n&amp;#x200B;", "author_fullname": "t2_o8wjc", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Reasons for why data hoarding is important and why you should start", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100o9fo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 307, "total_awards_received": 3, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 307, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 2, "gid_2": 1}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672593652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are many reason for why data hoarding is more than just stockpiling publicly available information. Most people see content on the internet as continuous. However, take 5 pages from 10 different websites, comeback in 3 months and you will quickly realize half the links are broken, content has changed or has been completely lost. Everyday thousands of new websites are created and shut down.&lt;/p&gt;\n\n&lt;p&gt;Below is a short summery of how information or access to information can be lost forever and why its important to save everything that is relevant, inspirational or entertaining to you.&lt;/p&gt;\n\n&lt;h1&gt;There are a number of external factors that can impact or influence the availability of information on the internet.&lt;/h1&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Governments may seize entire websites or implement internet shutdowns without notice. Takedown notices may be issued legitimately or illegitimately based on copyright disputes, malice or in cases of companies like Nintendo [&lt;a href=\"https://gamerant.com/nintendo-takedown-notice-25-year-old-super-mario-64-strategy-guide/\"&gt;1&lt;/a&gt;] [&lt;a href=\"https://kotaku.com/nintendo-steamgriddb-dmca-takedown-steam-icons-fan-art-1849813480\"&gt;2&lt;/a&gt;] [&lt;a href=\"https://arstechnica.com/gaming/2018/08/emuparadise-shuts-down-rom-downloads-amid-lawsuit-fears/\"&gt;3&lt;/a&gt;] [&lt;a href=\"https://www.wired.co.uk/article/lets-play-youtube-crackdown\"&gt;4&lt;/a&gt;], for total control of their IP regardless of fan made content, preservation or regards to privately owned physical property. &lt;/li&gt;\n&lt;li&gt;Pages may change over time including the content and information contained within them. Links to pages and content may change, break or be removed. Owners may be unable or uninterested in maintaining or paying for their site. Choosing to shut it down instead. &lt;/li&gt;\n&lt;li&gt;Environmental disasters or internal societal discourse leading to the destruction or &lt;a href=\"https://en.wikipedia.org/wiki/2021_South_African_unrest\"&gt;sabotage&lt;/a&gt; of local and state infrastructure. &lt;/li&gt;\n&lt;li&gt;User accounts and posts may be deleted, banned, suspended or removed - either by the users themselves, moderators or automatically by content moderation algorithms. Content may be removed regardless of reasoning, justification or even out of spite/malice by third parties and moderators. Users have very little control over the lifespan and availability of their posts and are at the whim of algorithms, reports, sudden policy changes or users with elevated privileges. &lt;/li&gt;\n&lt;li&gt;Websites, webpages, media and information can all be paywalled, region locked or may change based on your geographic location, credit card issuer or nationality. These practices are predatory and even discriminatory and only serve to fragment/limit access to information based on regional stereotypes, obscure internal policies, Government regulations and greed. The only acceptable exception to paywalls are stores, user created content and on demand services such as streaming sites. However, most if not all of these stores and streaming sites have implemented region locking. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?auto=webp&amp;s=c387f574702b9ed7c68f698f7fa60d3c32211671", "width": 1800, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb9ab3549c9f5cc04cb293a047279f42604c60fd", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7290288a77475dc5eb9e611bf255005806be1f4f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a84b6bc449101a95d8f26aba49a1e373c5f7f05b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41b14dbcff1f1c5660bbb986002af4d35c724c77", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4eb9f48e1255ec76179e227b7f255cae2381d077", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZybyKowCFEd-nfPD69Cl4b-aTM_0-kX-bMYCWx_N3zo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=39312c08074837719f03b915499b7495eeb170f7", "width": 1080, "height": 540}], "variants": {}, "id": "8L_qxpBRz4_edl-TBfsKsZva8bCq3Eo_1KrJqCdCbVo"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 2, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100o9fo", "is_robot_indexable": true, "report_reasons": null, "author": "ReclusiveEagle", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100o9fo/reasons_for_why_data_hoarding_is_important_and/", "subreddit_subscribers": 663375, "created_utc": 1672593652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://iwataasks.nintendo.com/\n\nRecently,  Nintendo started unlisting some of their other pages. I worry that these interviews are at risk.\n\nThe site consists of a series of static pages that are all linking to each other, like a mini encyclopedia.\n\nI tried backing them up before, but I am not good enough at scripting to pull it off.\n\nWould really love it if someone could do this and maybe end up with a folder with all the htmls in there.", "author_fullname": "t2_13ta0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would someone here be kind enough to help archive the Iwata Asks interviews ? they're at risk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100v3q5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672611280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://iwataasks.nintendo.com/\"&gt;https://iwataasks.nintendo.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Recently,  Nintendo started unlisting some of their other pages. I worry that these interviews are at risk.&lt;/p&gt;\n\n&lt;p&gt;The site consists of a series of static pages that are all linking to each other, like a mini encyclopedia.&lt;/p&gt;\n\n&lt;p&gt;I tried backing them up before, but I am not good enough at scripting to pull it off.&lt;/p&gt;\n\n&lt;p&gt;Would really love it if someone could do this and maybe end up with a folder with all the htmls in there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bcqp--ico1bkbdkyXM3VsvPpZZHVWVWbdKfevw_FULU.jpg?auto=webp&amp;s=76cd6bb483523bbbeb55273d09b420f83e34ac60", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/bcqp--ico1bkbdkyXM3VsvPpZZHVWVWbdKfevw_FULU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4fd3d804620e6f484098642c8f12b31bd61cf809", "width": 108, "height": 108}], "variants": {}, "id": "0BAKiuUVkKOay40_Zq_YOhb3Z5zEY9Idr6bSaGaminI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "100v3q5", "is_robot_indexable": true, "report_reasons": null, "author": "mekilat", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100v3q5/would_someone_here_be_kind_enough_to_help_archive/", "subreddit_subscribers": 663375, "created_utc": 1672611280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "PR4100 reporting 2x bad disk. Can you help me diagnose what I am looking at?  Can I just reboot this and hope it goes away, or should I be buying new disk?  Thanks", "author_fullname": "t2_jcbg4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Help with SMART data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 127, "top_awarded_type": null, "hide_score": false, "media_metadata": {"52hgjzyzhi9a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 98, "x": 108, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0f4dea253d6b48fa38b7025ab67c5bef2d170aa"}, {"y": 197, "x": 216, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=87f601db26d8332211cfc95c3a8ab7a9ed918d30"}, {"y": 292, "x": 320, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=400e70c737df5a6ee99aaaa8702a5bf48c75aa5d"}, {"y": 584, "x": 640, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=390d373bb093dc445dce4c5d5d12e36a5c1a6fac"}, {"y": 876, "x": 960, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e00afad19227a106780a29f28a19fe5d338ab55b"}, {"y": 986, "x": 1080, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9458f1717d4bf077ec33349104c80c8b6cce580e"}], "s": {"y": 1479, "x": 1620, "u": "https://preview.redd.it/52hgjzyzhi9a1.jpg?width=1620&amp;format=pjpg&amp;auto=webp&amp;s=e685630f15afa051fb33229c8360cfc74c8c2cf4"}, "id": "52hgjzyzhi9a1"}, "g6kfvzyzhi9a1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 138, "x": 108, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f6d72d5571d6e3cfd12f5f91ef2bdae9a33b3698"}, {"y": 276, "x": 216, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69b87f8c6cd7fb6fe8cec19d688e72fe8cb4a89d"}, {"y": 410, "x": 320, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=945ef2ad603c7f685f86caeb99f65b94377af82f"}, {"y": 820, "x": 640, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac820b319449600465a31c3dce97e63b900c589b"}, {"y": 1230, "x": 960, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=759142b7ea3619b32dfae96a1eda0f0e507fe37a"}, {"y": 1384, "x": 1080, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2af320e778beab50f543b7df24f8ba65ea49ecfa"}], "s": {"y": 2048, "x": 1598, "u": "https://preview.redd.it/g6kfvzyzhi9a1.jpg?width=1598&amp;format=pjpg&amp;auto=webp&amp;s=496e878d564e2dcc39809fac75082dc9ecb98137"}, "id": "g6kfvzyzhi9a1"}}, "name": "t3_100w2io", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 12, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "52hgjzyzhi9a1", "id": 225211750}, {"media_id": "g6kfvzyzhi9a1", "id": 225211751}]}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E8J3X0D2PjsIGYbdFslSM58jzWKK9BTmyFQAOiN4UZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672613781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PR4100 reporting 2x bad disk. Can you help me diagnose what I am looking at?  Can I just reboot this and hope it goes away, or should I be buying new disk?  Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/100w2io", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100w2io", "is_robot_indexable": true, "report_reasons": null, "author": "CactusJ", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100w2io/help_with_smart_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/100w2io", "subreddit_subscribers": 663375, "created_utc": 1672613781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cable management is overrated when you have 27 drives in a case to cable up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1012unv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": "", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_sxos8", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d726UNwNfz5lz-dJ0VPEs_Fx-TVjTcaYRCKKFhho-AE.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "homelab", "selftext": "", "author_fullname": "t2_sxos8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cable management is overrated when you have 27 drives in a case to cable up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/homelab", "hidden": false, "pwls": 6, "link_flair_css_class": "labporn", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_zxmvnh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 101, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "8fc1a448-bbcf-11e4-9649-22000b2b8291", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "LabPorn", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d726UNwNfz5lz-dJ0VPEs_Fx-TVjTcaYRCKKFhho-AE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1672265950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tll16p189r8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&amp;s=4955f34473be257ad52740705bf174c7dd3ea796", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18443b5d831978ffc0207945de453c03c5ec85f2", "width": 108, "height": 144}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42a8e5831cf7970311f608fee789f7e65022c690", "width": 216, "height": 288}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd90f4b4ab31821e75b1ebbe9ee1dc0607a873ab", "width": 320, "height": 426}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3aae096a530d32a0a9a0bf339f9239bf099609d", "width": 640, "height": 853}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93bb8e132bafde73f20637f3339b65dad13ad6e4", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2533df342d16b9a60e766261eb91e841992ddd43", "width": 1080, "height": 1440}], "variants": {}, "id": "NmEF_4HyikbEgclxnzrqS1QFw0yZJYX2sRtcKSW1Zrs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6f351106-322a-11e6-99ab-0e9de4a16811", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DL60 G9 / 2 x DL360e G8 / DL380p G8  / SA120", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2ubz7", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8c00", "id": "zxmvnh", "is_robot_indexable": true, "report_reasons": null, "author": "iamcts", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/homelab/comments/zxmvnh/cable_management_is_overrated_when_you_have_27/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tll16p189r8a1.jpg", "subreddit_subscribers": 541756, "created_utc": 1672265950.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1672632541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tll16p189r8a1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tll16p189r8a1.jpg?auto=webp&amp;s=4955f34473be257ad52740705bf174c7dd3ea796", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=18443b5d831978ffc0207945de453c03c5ec85f2", "width": 108, "height": 144}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42a8e5831cf7970311f608fee789f7e65022c690", "width": 216, "height": 288}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd90f4b4ab31821e75b1ebbe9ee1dc0607a873ab", "width": 320, "height": 426}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f3aae096a530d32a0a9a0bf339f9239bf099609d", "width": 640, "height": 853}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=93bb8e132bafde73f20637f3339b65dad13ad6e4", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/tll16p189r8a1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2533df342d16b9a60e766261eb91e841992ddd43", "width": 1080, "height": 1440}], "variants": {}, "id": "NmEF_4HyikbEgclxnzrqS1QFw0yZJYX2sRtcKSW1Zrs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1012unv", "is_robot_indexable": true, "report_reasons": null, "author": "iamcts", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_zxmvnh", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1012unv/cable_management_is_overrated_when_you_have_27/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tll16p189r8a1.jpg", "subreddit_subscribers": 663375, "created_utc": 1672632541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok, so I've been looking into ripping my blu-rays for a bit. From my understanding you may need to flash specific drives if you intend on ripping 4k UHD disks. I found the MakeMKV post about flashing drives but I'm still a bit confused\n\n1. I intend on only ripping non-UHD disks for the forseeable future. Do I need to flash the drive anyways, or is that only for ripping UHD?\n2. I saw that I could use an LG WH14NS40 or LG WH16NS40. I would need an enclosure. Would buying them straight from Amazon be an okay method?", "author_fullname": "t2_lge1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A few questions about Blu-rays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ul8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672610022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, so I&amp;#39;ve been looking into ripping my blu-rays for a bit. From my understanding you may need to flash specific drives if you intend on ripping 4k UHD disks. I found the MakeMKV post about flashing drives but I&amp;#39;m still a bit confused&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I intend on only ripping non-UHD disks for the forseeable future. Do I need to flash the drive anyways, or is that only for ripping UHD?&lt;/li&gt;\n&lt;li&gt;I saw that I could use an LG WH14NS40 or LG WH16NS40. I would need an enclosure. Would buying them straight from Amazon be an okay method?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ul8z", "is_robot_indexable": true, "report_reasons": null, "author": "delasislas", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ul8z/a_few_questions_about_blurays/", "subreddit_subscribers": 663375, "created_utc": 1672610022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hello hoaders , \n\nI am relatively new to this community and I have the most basic question but I still gotta ask \n\nI have a large movie/tv series library on me , till now I am storing the data on 5tb WD external hardrive I bought but I don't feel reliable on the hardrive since it is a physical one and my only source of backup for now   \nSo my question is what are the reliable ways of backing my 3tb data securely and In a controlled budget though. As I told I new to this community so Kindly explain your responses as much as you can   \n\n\nthanks and a very happy new year", "author_fullname": "t2_8rzf8b0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3Tb backup advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100stk0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello hoaders , &lt;/p&gt;\n\n&lt;p&gt;I am relatively new to this community and I have the most basic question but I still gotta ask &lt;/p&gt;\n\n&lt;p&gt;I have a large movie/tv series library on me , till now I am storing the data on 5tb WD external hardrive I bought but I don&amp;#39;t feel reliable on the hardrive since it is a physical one and my only source of backup for now&lt;br/&gt;\nSo my question is what are the reliable ways of backing my 3tb data securely and In a controlled budget though. As I told I new to this community so Kindly explain your responses as much as you can   &lt;/p&gt;\n\n&lt;p&gt;thanks and a very happy new year&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100stk0", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Artist_95", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100stk0/3tb_backup_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100stk0/3tb_backup_advice/", "subreddit_subscribers": 663375, "created_utc": 1672605567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been data hoarding for about a year now. I've bought several external hard drives ranging from 1TB-5TB to store everything (Seagate and WD). I didn't have too much data at first, and I like how they are portable and easy to plug and play on other devices.\n\nMy question is, would it be more cost effective to buy internal hard drives like 3.5\" NAS HDDs and buy a cheap enclosure to go with it? For example I've seen 10TB+ Internal Drives sell for cheaper than  pre-enclosed external ones, but I dont know if I would need an extra power source other then the USB plug that comes with a portable enclosure. I also wouldn't be opposed to go with a smaller drive if the extra power is needed on larger drives.\n\nI am no where near setting up a home server or using a cloud based system, just looking to plug into the TV through USB for now.", "author_fullname": "t2_5yypda5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Vs. Internal Hard Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100spir", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been data hoarding for about a year now. I&amp;#39;ve bought several external hard drives ranging from 1TB-5TB to store everything (Seagate and WD). I didn&amp;#39;t have too much data at first, and I like how they are portable and easy to plug and play on other devices.&lt;/p&gt;\n\n&lt;p&gt;My question is, would it be more cost effective to buy internal hard drives like 3.5&amp;quot; NAS HDDs and buy a cheap enclosure to go with it? For example I&amp;#39;ve seen 10TB+ Internal Drives sell for cheaper than  pre-enclosed external ones, but I dont know if I would need an extra power source other then the USB plug that comes with a portable enclosure. I also wouldn&amp;#39;t be opposed to go with a smaller drive if the extra power is needed on larger drives.&lt;/p&gt;\n\n&lt;p&gt;I am no where near setting up a home server or using a cloud based system, just looking to plug into the TV through USB for now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100spir", "is_robot_indexable": true, "report_reasons": null, "author": "wtfhmmm", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100spir/external_vs_internal_hard_drives/", "subreddit_subscribers": 663375, "created_utc": 1672605270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello sub\nPlease advise what's a cheap Nas adapter that can help me put my 16tb wdd USB HDD on my own as a network drive?\n\nI'd eventually like to use rclone on my PCs/phone to backup content into it.\n\nThanks", "author_fullname": "t2_72g3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advise : home backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100h1bm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672569280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello sub\nPlease advise what&amp;#39;s a cheap Nas adapter that can help me put my 16tb wdd USB HDD on my own as a network drive?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d eventually like to use rclone on my PCs/phone to backup content into it.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100h1bm", "is_robot_indexable": true, "report_reasons": null, "author": "justbflat", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100h1bm/need_advise_home_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100h1bm/need_advise_home_backup/", "subreddit_subscribers": 663375, "created_utc": 1672569280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hiya, I'm looking for any tool that downloads all images from a Reddit account, cheers", "author_fullname": "t2_ccp6tq5p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit account scraper?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100gw0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672568632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiya, I&amp;#39;m looking for any tool that downloads all images from a Reddit account, cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100gw0k", "is_robot_indexable": true, "report_reasons": null, "author": "LunaKindaExists", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100gw0k/reddit_account_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100gw0k/reddit_account_scraper/", "subreddit_subscribers": 663375, "created_utc": 1672568632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t want to pay for iCloud as buying actual storage is much cheaper, at least in the long run. I have a Windows PC that\u2019s on 24/7 and it has a 1TB SSD, which has ~500GB free, more than enough for my photos and videos.", "author_fullname": "t2_kygivbfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I back up my iPhone\u2019s gallery to my PC automatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ziri", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672622872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t want to pay for iCloud as buying actual storage is much cheaper, at least in the long run. I have a Windows PC that\u2019s on 24/7 and it has a 1TB SSD, which has ~500GB free, more than enough for my photos and videos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ziri", "is_robot_indexable": true, "report_reasons": null, "author": "ffsstfualready", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ziri/how_can_i_back_up_my_iphones_gallery_to_my_pc/", "subreddit_subscribers": 663375, "created_utc": 1672622872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I really like the Idea of Backblaze Personal Backup, where you just install their client and the entire computer gets synced to a remote location.  \nSo you guys know of similar software to this, which I could connect to my own private network drive? I don't seem to find anything that does \"whole pc backup, no questions asked\".  \n  \nThanks in advance!", "author_fullname": "t2_enms1n0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze style backup software (but selfhosted?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100sly7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672605013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really like the Idea of Backblaze Personal Backup, where you just install their client and the entire computer gets synced to a remote location.&lt;br/&gt;\nSo you guys know of similar software to this, which I could connect to my own private network drive? I don&amp;#39;t seem to find anything that does &amp;quot;whole pc backup, no questions asked&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100sly7", "is_robot_indexable": true, "report_reasons": null, "author": "sideprojects1337", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100sly7/backblaze_style_backup_software_but_selfhosted/", "subreddit_subscribers": 663375, "created_utc": 1672605013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First, I would like to apologize for the wall of text below. It's tough to digest since English is not my native language.\n\nUsing YouTube to store videos: I have done my homework and agree with the consensus. This is a bad idea. A significant risk of a ban at any moment without ever getting a chance to appeal or interact with a human being, let alone a chance to recover the data, a significant drop in quality across the board, the sudden apparition of exotic formats compatible with nothing, it goes on and on. Some have tried and are here to tell their horror stories on this sub.\n\nMy case is a bit different, though.\n\nA bit of background for you to get a rough picture of where I'll be standing for the next 18 months-ish (hopefully less than that).\n\nIn 48 hours, I will be homeless. I sold my decent NAS and the disks a few months ago to pay for gas and food. I've sold 90% of everything I had, and 10% left has no value and will be left on the sidewalk or discarded after calling a charity organization.\n\nI'm doing my best to bounce and have a realistic plan. Not some stuff written on a napkin, I've projected infrastructure, funding, I have a timeline to stick to, etc. Something solid.\n\nThis plan requires me to temporarily store about 900Gb of footage + without sound in high definition: mostly 4k but some 8k as well :(\n\nIn another life, I was running a small yet monetized YouTube channel. There are around 5k subs left (bots and dead people). This channel is 12 years old; everything is in the green with YT' ToS.\n\nThe post starts here: I've uploaded 200 Gb of footage in 10 days on my old YouTube channel. I've covered my tracks (I feel extra stupid after writing this) by populating correctly and accurately all the fields for each video, such as an original title, location, description, tags, etc. Since each vid is 20 s to 4 minutes long, this is a lot of work put towards failure. Remember, this content has no sound, so I've even added copyright-free music from the YouTube library to everything. This content is 100% original, I'm the only person appearing on some videos, but those videos can reveal vehicle location and rotation (no plates visible). So far, so good (standings). I've hit the daily upload limitations twice, though. No need to mention this is done manually. Videos are either flagged as unlisted or draft; high-definition rendering takes ages if I flag those private, and it's not the end of the world if it leaks.\n\nQuestion: should I keep on spending precious time on this? And finally, a critical question: please tell me if there is a better way to do this. I can pay just under the equivalent of $10 US a month if it comes with a price tag.\n\nCongratulations on making it that far into the post.", "author_fullname": "t2_inxy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A slightly different case of storing videos on YouTube. Comments and alternative solutions welcome.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100qb56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672599070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, I would like to apologize for the wall of text below. It&amp;#39;s tough to digest since English is not my native language.&lt;/p&gt;\n\n&lt;p&gt;Using YouTube to store videos: I have done my homework and agree with the consensus. This is a bad idea. A significant risk of a ban at any moment without ever getting a chance to appeal or interact with a human being, let alone a chance to recover the data, a significant drop in quality across the board, the sudden apparition of exotic formats compatible with nothing, it goes on and on. Some have tried and are here to tell their horror stories on this sub.&lt;/p&gt;\n\n&lt;p&gt;My case is a bit different, though.&lt;/p&gt;\n\n&lt;p&gt;A bit of background for you to get a rough picture of where I&amp;#39;ll be standing for the next 18 months-ish (hopefully less than that).&lt;/p&gt;\n\n&lt;p&gt;In 48 hours, I will be homeless. I sold my decent NAS and the disks a few months ago to pay for gas and food. I&amp;#39;ve sold 90% of everything I had, and 10% left has no value and will be left on the sidewalk or discarded after calling a charity organization.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m doing my best to bounce and have a realistic plan. Not some stuff written on a napkin, I&amp;#39;ve projected infrastructure, funding, I have a timeline to stick to, etc. Something solid.&lt;/p&gt;\n\n&lt;p&gt;This plan requires me to temporarily store about 900Gb of footage + without sound in high definition: mostly 4k but some 8k as well :(&lt;/p&gt;\n\n&lt;p&gt;In another life, I was running a small yet monetized YouTube channel. There are around 5k subs left (bots and dead people). This channel is 12 years old; everything is in the green with YT&amp;#39; ToS.&lt;/p&gt;\n\n&lt;p&gt;The post starts here: I&amp;#39;ve uploaded 200 Gb of footage in 10 days on my old YouTube channel. I&amp;#39;ve covered my tracks (I feel extra stupid after writing this) by populating correctly and accurately all the fields for each video, such as an original title, location, description, tags, etc. Since each vid is 20 s to 4 minutes long, this is a lot of work put towards failure. Remember, this content has no sound, so I&amp;#39;ve even added copyright-free music from the YouTube library to everything. This content is 100% original, I&amp;#39;m the only person appearing on some videos, but those videos can reveal vehicle location and rotation (no plates visible). So far, so good (standings). I&amp;#39;ve hit the daily upload limitations twice, though. No need to mention this is done manually. Videos are either flagged as unlisted or draft; high-definition rendering takes ages if I flag those private, and it&amp;#39;s not the end of the world if it leaks.&lt;/p&gt;\n\n&lt;p&gt;Question: should I keep on spending precious time on this? And finally, a critical question: please tell me if there is a better way to do this. I can pay just under the equivalent of $10 US a month if it comes with a price tag.&lt;/p&gt;\n\n&lt;p&gt;Congratulations on making it that far into the post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100qb56", "is_robot_indexable": true, "report_reasons": null, "author": "-Nicolas-", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100qb56/a_slightly_different_case_of_storing_videos_on/", "subreddit_subscribers": 663375, "created_utc": 1672599070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellas, I have a few channels I scrape occasionally on Bitchute using a custom script I wrote and using yt-dlp. I've noticed that a lot of older videos no longer archive, and when I check the videos on Bitchute they no longer load - so it's not an issue with my script or yt-dlp. The latest channel I tried to archive cut off at a video on December 3, 2019 - and all videos older than that are no longer playing on the website. \n\nIs this an issue with Bitchute automatically no longer hosting videos once they've been uploaded for a certain amount of time? Anyone else run into this problem? Any input is helpful. Thanks guys.", "author_fullname": "t2_p9vg3wjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone having problem archiving Bitchute channels using yt-dlp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100plvd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672597242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellas, I have a few channels I scrape occasionally on Bitchute using a custom script I wrote and using yt-dlp. I&amp;#39;ve noticed that a lot of older videos no longer archive, and when I check the videos on Bitchute they no longer load - so it&amp;#39;s not an issue with my script or yt-dlp. The latest channel I tried to archive cut off at a video on December 3, 2019 - and all videos older than that are no longer playing on the website. &lt;/p&gt;\n\n&lt;p&gt;Is this an issue with Bitchute automatically no longer hosting videos once they&amp;#39;ve been uploaded for a certain amount of time? Anyone else run into this problem? Any input is helpful. Thanks guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100plvd", "is_robot_indexable": true, "report_reasons": null, "author": "TCIE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100plvd/anyone_having_problem_archiving_bitchute_channels/", "subreddit_subscribers": 663375, "created_utc": 1672597242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**First, a disclaimer:** I'm aware media is generally already compress. Storage capacity is not an issue currently, but it's something I'm curious about and want to learn. \n\n**1)** Do any of you use compression, in any form, for either backups, local storage, or cloud?\n\n####Files I'm considering compressing:\n \n**2)** I have a LOT of games downloaded, which I do not *currently* play, but plan on returning to. One example would me Skyrim +150 Mods, which took weeks to figure out the right combination of mods \n\n**3)** I have about 500 GB - 1TB or so of old data that I'm **slowly** going through, and deleting or saving anything that's personally important. The data is from either: My old harddrives, my deceased dad's PC, an old WD passport, and an old backup folder that is partially corrupt but has some salvigable important files\n\n**4)** I'm not sure if RAR or 7-zip compression does anything for lossless media, so this part might not be relevant: but I have a lot of upscaled photos and videos; some of which are saved as PNG or ProRes, and are essentially lossless. Some pictures are 150mb each. I'm still fairly new at upscaling, and later on this will probably be less of an issue, but the reason some files are lossless is because:\n\n* Some select, important media I used ProRes or PNG for that I may plan on printing, or using in other software like Premiere and Photoshop. \n* Some photos had very small artifacts on the JPG Codec that weren't in PNG\n* some upscaling issues on various codec formats (either software-side errors, or time)\n* some issues at the time with using h.265 or vp9 format (software issue that was patched and fixed). But as a result I used h.264 or ProRes on\n* poor knowledge on compatibility issues when using various codecs (h.265, h.264, av1, vp9, etc) on supported devices (android, windows, Apple), transferring them, uploading to a cloud service (g.drive, g.photos), supported programs, etc.\n\nHopefully when I learn a bit more about the above, and with some software issues patched, I'll be able to use the right codec to compress files.", "author_fullname": "t2_cs86j6jo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some questions on compression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100ikdy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672575819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;First, a disclaimer:&lt;/strong&gt; I&amp;#39;m aware media is generally already compress. Storage capacity is not an issue currently, but it&amp;#39;s something I&amp;#39;m curious about and want to learn. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; Do any of you use compression, in any form, for either backups, local storage, or cloud?&lt;/p&gt;\n\n&lt;h4&gt;Files I&amp;#39;m considering compressing:&lt;/h4&gt;\n\n&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; I have a LOT of games downloaded, which I do not &lt;em&gt;currently&lt;/em&gt; play, but plan on returning to. One example would me Skyrim +150 Mods, which took weeks to figure out the right combination of mods &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; I have about 500 GB - 1TB or so of old data that I&amp;#39;m &lt;strong&gt;slowly&lt;/strong&gt; going through, and deleting or saving anything that&amp;#39;s personally important. The data is from either: My old harddrives, my deceased dad&amp;#39;s PC, an old WD passport, and an old backup folder that is partially corrupt but has some salvigable important files&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;4)&lt;/strong&gt; I&amp;#39;m not sure if RAR or 7-zip compression does anything for lossless media, so this part might not be relevant: but I have a lot of upscaled photos and videos; some of which are saved as PNG or ProRes, and are essentially lossless. Some pictures are 150mb each. I&amp;#39;m still fairly new at upscaling, and later on this will probably be less of an issue, but the reason some files are lossless is because:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some select, important media I used ProRes or PNG for that I may plan on printing, or using in other software like Premiere and Photoshop. &lt;/li&gt;\n&lt;li&gt;Some photos had very small artifacts on the JPG Codec that weren&amp;#39;t in PNG&lt;/li&gt;\n&lt;li&gt;some upscaling issues on various codec formats (either software-side errors, or time)&lt;/li&gt;\n&lt;li&gt;some issues at the time with using h.265 or vp9 format (software issue that was patched and fixed). But as a result I used h.264 or ProRes on&lt;/li&gt;\n&lt;li&gt;poor knowledge on compatibility issues when using various codecs (h.265, h.264, av1, vp9, etc) on supported devices (android, windows, Apple), transferring them, uploading to a cloud service (g.drive, g.photos), supported programs, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Hopefully when I learn a bit more about the above, and with some software issues patched, I&amp;#39;ll be able to use the right codec to compress files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100ikdy", "is_robot_indexable": true, "report_reasons": null, "author": "NegativelyMagnetic", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100ikdy/some_questions_on_compression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100ikdy/some_questions_on_compression/", "subreddit_subscribers": 663375, "created_utc": 1672575819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have 10 Terabytes of drive capcity But I am in process of upgrading my pc.\n\nNot Sure If I should take drives and build cheap server or buy nas most of the storage is HDD.\n\nMy concern is power but engegy prices are so high in the United Kingdom would it just be cheaper to a buy a nas?", "author_fullname": "t2_mhtwxne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help optimizing storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100zihf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672622847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have 10 Terabytes of drive capcity But I am in process of upgrading my pc.&lt;/p&gt;\n\n&lt;p&gt;Not Sure If I should take drives and build cheap server or buy nas most of the storage is HDD.&lt;/p&gt;\n\n&lt;p&gt;My concern is power but engegy prices are so high in the United Kingdom would it just be cheaper to a buy a nas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100zihf", "is_robot_indexable": true, "report_reasons": null, "author": "drjonsmith", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100zihf/i_need_help_optimizing_storage/", "subreddit_subscribers": 663375, "created_utc": 1672622847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The easy answer: RETWEET.  \n\n\nWhen you download your archive, for some reason just a simple retweet saves all media contained in a tweet.  What I consider insane is what is shown by in the \"Likes\" tab in the archive is almost nothing - ONLY the text and 2 LINKS POINTING TO THE SAME TWEET (wtf?). A retweet has the same content but saves the **IMAGES** and **VIDEOS** and the author's **USERNAME** which for some reason that is beyond me the \"Likes\" tab does not.\n\n\"Quote Retweets\" suffer the same problem as \"Likes\" so it might be better to retweet before quoting.\n\nDownloading data from the Twitter itself is infinitely better since it is complete than using any app so there are two options:\n\n1. **Retweet Everything**\n2. **Extract Links from Archive then Create an App to Retweet Everything**\n\nThe problem with the 1st option is that it fills your follower's timeline and that is a problem. You can make a 2nd account to personally retweet the same stuff but that's just as exhausting.\n\nThe 2nd option is probably more feasible but the best I can probably do is extract the tweet link from the archive but that's basically it. I'd imagine a dummy account is needed where an app is fed with a list of links to retweet. Archiving the dummy account saves everything from the main account. \n\n&amp;#x200B;\n\n*I really don't know how to implement the 2nd option and I only know basic stuff in using the API which I think can be done there* (for now?) but I'm hoping some data god will see this and is able to lend their power in creating one. I'm just a bit sick of using apps - it's either incomplete, extremely slow, or does not have the complete data.  Also, the lack of the use of API for saving account data is kinda, in general, iffy for me.\n\nI think I understand the data storage implication of not saving media from likes since it probably outnumbers tweets by a lot, and they are not bounded by daily limits. Still, I think the way they are handling when you do want to archive is insanity. Speaking of limits - twitter has a daily limit of 2400 tweets but I think that is more than enough to save an entire account within a day.", "author_fullname": "t2_n62192z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to save media from tweets, likes, and bookmarks in Twitter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100plzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672598186.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672597251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The easy answer: RETWEET.  &lt;/p&gt;\n\n&lt;p&gt;When you download your archive, for some reason just a simple retweet saves all media contained in a tweet.  What I consider insane is what is shown by in the &amp;quot;Likes&amp;quot; tab in the archive is almost nothing - ONLY the text and 2 LINKS POINTING TO THE SAME TWEET (wtf?). A retweet has the same content but saves the &lt;strong&gt;IMAGES&lt;/strong&gt; and &lt;strong&gt;VIDEOS&lt;/strong&gt; and the author&amp;#39;s &lt;strong&gt;USERNAME&lt;/strong&gt; which for some reason that is beyond me the &amp;quot;Likes&amp;quot; tab does not.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Quote Retweets&amp;quot; suffer the same problem as &amp;quot;Likes&amp;quot; so it might be better to retweet before quoting.&lt;/p&gt;\n\n&lt;p&gt;Downloading data from the Twitter itself is infinitely better since it is complete than using any app so there are two options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Retweet Everything&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Extract Links from Archive then Create an App to Retweet Everything&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problem with the 1st option is that it fills your follower&amp;#39;s timeline and that is a problem. You can make a 2nd account to personally retweet the same stuff but that&amp;#39;s just as exhausting.&lt;/p&gt;\n\n&lt;p&gt;The 2nd option is probably more feasible but the best I can probably do is extract the tweet link from the archive but that&amp;#39;s basically it. I&amp;#39;d imagine a dummy account is needed where an app is fed with a list of links to retweet. Archiving the dummy account saves everything from the main account. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;I really don&amp;#39;t know how to implement the 2nd option and I only know basic stuff in using the API which I think can be done there&lt;/em&gt; (for now?) but I&amp;#39;m hoping some data god will see this and is able to lend their power in creating one. I&amp;#39;m just a bit sick of using apps - it&amp;#39;s either incomplete, extremely slow, or does not have the complete data.  Also, the lack of the use of API for saving account data is kinda, in general, iffy for me.&lt;/p&gt;\n\n&lt;p&gt;I think I understand the data storage implication of not saving media from likes since it probably outnumbers tweets by a lot, and they are not bounded by daily limits. Still, I think the way they are handling when you do want to archive is insanity. Speaking of limits - twitter has a daily limit of 2400 tweets but I think that is more than enough to save an entire account within a day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100plzr", "is_robot_indexable": true, "report_reasons": null, "author": "Altrigeo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100plzr/how_to_save_media_from_tweets_likes_and_bookmarks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100plzr/how_to_save_media_from_tweets_likes_and_bookmarks/", "subreddit_subscribers": 663375, "created_utc": 1672597251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Finally throwing in the towel here; spent hours trying to figure this out to no success. Any help? Imgur album at [https://imgur.com/a/4lUMDfC](https://imgur.com/a/4lUMDfC). Site in question's NSFW, but the content I'm looking for help with isn't.\n\nIdea here is that I'd like to use gallery-dl's extractor to REPLICATE [aryion](https://aryion.com)'s gallery folder structure up to four levels deep; they're structured where individual artists are able to organize works into individual custom folders akin to local storage, so you'll often encounter content that's subcatergorized via multiple iterations (IE 'gallery', 'content type', 'work sequence'). \\\\Gallery\\_DL\\\\gallery-dl.exe -K [https://aryion.com](https://aryion.com)/\\*\\*\\* will show you quick that this information is sent from the api via the 'path\\[N\\]' container...\n\nBut the problem is, I simply cannot reverse engineer a working solution to get more than one iteration deep into that file structure, and not for lack of trying. I keep getting either invalid syntax errors (IE, my uneducated scripting's borked), 'index out of range' errors (IE, gallery-dl is attempting to read 'path\\[N\\]' and finding that data empty, as in calling path\\[3\\] when only paths \\[0\\] and \\[1\\] exist), or else creating a local directory that only partially captures what I'm looking to create.\n\nDue to the nature of the site I can't really recommend trying my exact usecase out yourself ^((this is where I feebly but truthfully claim I'm just using this user specifically as a blind example)) , but I figure the examples in that gallery should show what I'm going for well enough. I'm 1000% certain there's some filesystem function or obvious command what'll allow for a far cleaner 'foreach' style solution than my current hacked-together if-thans, but given I haven't been able to dig up a single similar example to work off of I'm looking for any direction I can get. Thanks!\n\n\\-When I try to get this all done with a single directory line hashing out \"{path\\[0\\]}, {path\\[1\\]}, etc\" in sequence, **this creates a series of \"None\" folders as deep as the number of paths I'm asking it look for**; this made me think I could axe any process where the api was returning 'null' or 'none' via a !=, but I didn't find any success on that front. I also thought the issue might be with the fact that any given {path\\[\\*\\]} in fact equates to a list of full filepath strings - and clearly not knowing how to call just one string specifically, I tried asking functions to only run if '{path\\[x\\]} = \\*', the idea there being that a wildcard might inherently exclude null values - but no joy on that either.\n\n\\-The closest I've gotten is a **single iteration of foldering** \\- IE, the base artist folder and a single subcategory, with all content within that sub all lumped together . You can see this in the album...\n\n\\-But the default behavior of Gallery-DL without any \"directory\" instructions comes annoyingly close, too. This creates sub-subfolders, but does not place them ***in*** their respective level 1 subfolders. Which is to say it creates /mainfolder/ and a /mainfolder/subfolder directory, but then ***also*** numerous /mainfolder/subfolder-subsubfolder directories. Meaning it's clearly capable of reading the deeper folder levels, then interpreting the script as  something like \"{artist}\", \"{path\\[0\\]}-\"{path\\[1\\]}\". **I just want to be able to capture the per-content paths in the same way, to then use however I'd like.**", "author_fullname": "t2_likkt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-DL Folder Iteration - How to Create Variable Sub-Directories / continue past null api calls?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1016chi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672645482.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1672643845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Finally throwing in the towel here; spent hours trying to figure this out to no success. Any help? Imgur album at &lt;a href=\"https://imgur.com/a/4lUMDfC\"&gt;https://imgur.com/a/4lUMDfC&lt;/a&gt;. Site in question&amp;#39;s NSFW, but the content I&amp;#39;m looking for help with isn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Idea here is that I&amp;#39;d like to use gallery-dl&amp;#39;s extractor to REPLICATE &lt;a href=\"https://aryion.com\"&gt;aryion&lt;/a&gt;&amp;#39;s gallery folder structure up to four levels deep; they&amp;#39;re structured where individual artists are able to organize works into individual custom folders akin to local storage, so you&amp;#39;ll often encounter content that&amp;#39;s subcatergorized via multiple iterations (IE &amp;#39;gallery&amp;#39;, &amp;#39;content type&amp;#39;, &amp;#39;work sequence&amp;#39;). \\Gallery_DL\\gallery-dl.exe -K &lt;a href=\"https://aryion.com\"&gt;https://aryion.com&lt;/a&gt;/*** will show you quick that this information is sent from the api via the &amp;#39;path[N]&amp;#39; container...&lt;/p&gt;\n\n&lt;p&gt;But the problem is, I simply cannot reverse engineer a working solution to get more than one iteration deep into that file structure, and not for lack of trying. I keep getting either invalid syntax errors (IE, my uneducated scripting&amp;#39;s borked), &amp;#39;index out of range&amp;#39; errors (IE, gallery-dl is attempting to read &amp;#39;path[N]&amp;#39; and finding that data empty, as in calling path[3] when only paths [0] and [1] exist), or else creating a local directory that only partially captures what I&amp;#39;m looking to create.&lt;/p&gt;\n\n&lt;p&gt;Due to the nature of the site I can&amp;#39;t really recommend trying my exact usecase out yourself &lt;sup&gt;(this is where I feebly but truthfully claim I&amp;#39;m just using this user specifically as a blind example&lt;/sup&gt;) , but I figure the examples in that gallery should show what I&amp;#39;m going for well enough. I&amp;#39;m 1000% certain there&amp;#39;s some filesystem function or obvious command what&amp;#39;ll allow for a far cleaner &amp;#39;foreach&amp;#39; style solution than my current hacked-together if-thans, but given I haven&amp;#39;t been able to dig up a single similar example to work off of I&amp;#39;m looking for any direction I can get. Thanks!&lt;/p&gt;\n\n&lt;p&gt;-When I try to get this all done with a single directory line hashing out &amp;quot;{path[0]}, {path[1]}, etc&amp;quot; in sequence, &lt;strong&gt;this creates a series of &amp;quot;None&amp;quot; folders as deep as the number of paths I&amp;#39;m asking it look for&lt;/strong&gt;; this made me think I could axe any process where the api was returning &amp;#39;null&amp;#39; or &amp;#39;none&amp;#39; via a !=, but I didn&amp;#39;t find any success on that front. I also thought the issue might be with the fact that any given {path[*]} in fact equates to a list of full filepath strings - and clearly not knowing how to call just one string specifically, I tried asking functions to only run if &amp;#39;{path[x]} = *&amp;#39;, the idea there being that a wildcard might inherently exclude null values - but no joy on that either.&lt;/p&gt;\n\n&lt;p&gt;-The closest I&amp;#39;ve gotten is a &lt;strong&gt;single iteration of foldering&lt;/strong&gt; - IE, the base artist folder and a single subcategory, with all content within that sub all lumped together . You can see this in the album...&lt;/p&gt;\n\n&lt;p&gt;-But the default behavior of Gallery-DL without any &amp;quot;directory&amp;quot; instructions comes annoyingly close, too. This creates sub-subfolders, but does not place them &lt;strong&gt;&lt;em&gt;in&lt;/em&gt;&lt;/strong&gt; their respective level 1 subfolders. Which is to say it creates /mainfolder/ and a /mainfolder/subfolder directory, but then &lt;strong&gt;&lt;em&gt;also&lt;/em&gt;&lt;/strong&gt; numerous /mainfolder/subfolder-subsubfolder directories. Meaning it&amp;#39;s clearly capable of reading the deeper folder levels, then interpreting the script as  something like &amp;quot;{artist}&amp;quot;, &amp;quot;{path[0]}-&amp;quot;{path[1]}&amp;quot;. &lt;strong&gt;I just want to be able to capture the per-content paths in the same way, to then use however I&amp;#39;d like.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?auto=webp&amp;s=6a09fa9a44ef8d270e85eb9fce036c635a27c9c6", "width": 1333, "height": 679}, "resolutions": [{"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ca0aa3d618515f518a3dc1c5b3fdeb0b6d0d3b4", "width": 108, "height": 55}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=214bee8c15877cd432d591b1a1f5eb61a670504b", "width": 216, "height": 110}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa74c26ebab9795fa0687030ff1bab09cb22a197", "width": 320, "height": 163}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f409ff3647c70d64b585317dc121f12b9c122b8b", "width": 640, "height": 326}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61f7c6d47dcf3f418dce45472903814c88b12377", "width": 960, "height": 489}, {"url": "https://external-preview.redd.it/5mfBDBBclWDjmVxxE0irz0Ga5uciQUoD4Nh4Sp4PJbI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5dcd4b89386a4d35ac506934d19e9544c5d58cb9", "width": 1080, "height": 550}], "variants": {}, "id": "bFuSCucOh6zCAsiPW6kAjd2DRdstJmukjT1dZG8ecLA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1016chi", "is_robot_indexable": true, "report_reasons": null, "author": "gwre", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1016chi/gallerydl_folder_iteration_how_to_create_variable/", "subreddit_subscribers": 663375, "created_utc": 1672643845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nPlease, anyone can detailed explain the difference about use sync function anb backup function.\n\nOther thing, i have deleted files from pc and the files dont get deleted in cloud and the software started to download them again, my objetive is to sync but i constantly move files trough folders and drives and i need the files get deleted on cloud and dont be downloaded again. Anyone can share some information to help? Thanks.", "author_fullname": "t2_uavj7l2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference btween backup and sync options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10112rw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672627271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please, anyone can detailed explain the difference about use sync function anb backup function.&lt;/p&gt;\n\n&lt;p&gt;Other thing, i have deleted files from pc and the files dont get deleted in cloud and the software started to download them again, my objetive is to sync but i constantly move files trough folders and drives and i need the files get deleted on cloud and dont be downloaded again. Anyone can share some information to help? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10112rw", "is_robot_indexable": true, "report_reasons": null, "author": "chaos4455", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10112rw/difference_btween_backup_and_sync_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10112rw/difference_btween_backup_and_sync_options/", "subreddit_subscribers": 663375, "created_utc": 1672627271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I just bought a refurbished R720xd with 2 SSD, 12 HDD and a PERC H710p raid controller. I plan to used some of the HDD for backup.\n\nAt day 1 the raid controller was working and I configured the RAID. But after rebooting to install the OS, the controller fell into fault state 'F/W in fault state - MFI Register State 0xF0010002. Adapter at Baseport is not responding'. \n\nI tried several things such as removing the HDD, removing the controller, the battery and plugging back, also a video on how to recover a H710 on YT but nothing worked at the moment. Do you have any idea on what to do ?", "author_fullname": "t2_49n54vd8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100s3lw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672603689.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I just bought a refurbished R720xd with 2 SSD, 12 HDD and a PERC H710p raid controller. I plan to used some of the HDD for backup.&lt;/p&gt;\n\n&lt;p&gt;At day 1 the raid controller was working and I configured the RAID. But after rebooting to install the OS, the controller fell into fault state &amp;#39;F/W in fault state - MFI Register State 0xF0010002. Adapter at Baseport is not responding&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;I tried several things such as removing the HDD, removing the controller, the battery and plugging back, also a video on how to recover a H710 on YT but nothing worked at the moment. Do you have any idea on what to do ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100s3lw", "is_robot_indexable": true, "report_reasons": null, "author": "jeansami", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100s3lw/new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100s3lw/new_server/", "subreddit_subscribers": 663375, "created_utc": 1672603689.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is MTBF the same as \"Reliability\" Cycles...?\n\nHello\n\nI wanna buy a new HDD, im choosing between:\n\n&amp;#x200B;\n\nToshiba P300 6TB (HDWD260UZSVA)\n\nand\n\nSeagate BarraCuda 6TB ( ST6000DM003)\n\n&amp;#x200B;\n\nIn the shop in my country, in my language (not english) it says for Toshiba: \"MTBF 600000 hours\" and for Seagate: \"Reliability 300000 cycles\".\n\n&amp;#x200B;\n\nIs \"MTBF\" (Mean time Before Failure) the same as \"Reliability Cycles\"...? I did the translation from my language to english as good as i can.\n\nAre they the same?\n\nIf not, which one is Better?\n\n&amp;#x200B;\n\n600 000 Hours MTBF\n\nor\n\n300 000 Reliability Cycles?\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_1sl55e5m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is MTBF the same as \"Reliability\" Cycles...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100m09a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672587219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is MTBF the same as &amp;quot;Reliability&amp;quot; Cycles...?&lt;/p&gt;\n\n&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I wanna buy a new HDD, im choosing between:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Toshiba P300 6TB (HDWD260UZSVA)&lt;/p&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;p&gt;Seagate BarraCuda 6TB ( ST6000DM003)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In the shop in my country, in my language (not english) it says for Toshiba: &amp;quot;MTBF 600000 hours&amp;quot; and for Seagate: &amp;quot;Reliability 300000 cycles&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is &amp;quot;MTBF&amp;quot; (Mean time Before Failure) the same as &amp;quot;Reliability Cycles&amp;quot;...? I did the translation from my language to english as good as i can.&lt;/p&gt;\n\n&lt;p&gt;Are they the same?&lt;/p&gt;\n\n&lt;p&gt;If not, which one is Better?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;600 000 Hours MTBF&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;300 000 Reliability Cycles?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100m09a", "is_robot_indexable": true, "report_reasons": null, "author": "ThomasHasThomas", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100m09a/is_mtbf_the_same_as_reliability_cycles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100m09a/is_mtbf_the_same_as_reliability_cycles/", "subreddit_subscribers": 663375, "created_utc": 1672587219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using MG08ACA16TE (MG08) for recording TV broadcasts 24/7 in my bedroom. Unfortunately the HDD is not that quiet. [It has thudding sound like others in this sub mentioned.](https://www.reddit.com/r/DataHoarder/comments/xomoea/is_this_thudding_sound_normal_toshiba_mg08_drive/)  Not unbearable, but it would be nice if I can get rid of it. I'm thinking of replacing that drive with larger one, and repurposing MG08 for backup drive, or for NAS drive which I only power on with Wake on LAN when I need it.\n\nTo minimize power consumption I only want to use single drive. WD is the only manufacturer that makes 22TB drive. Which model is quieter, WD221PURP (Purple Pro) or WD221KFGX (Red Pro)? On datasheets both models have the same acoustics (same dBA), so the actual noise level when used at home is also the same?\n\nUltrastar/Gold model has the same dbA value on datasheets too but consumes more power than those 2 models.\n\n[https://documents.westerndigital.com/content/dam/doc-library/en\\_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf)\n\n[https://documents.westerndigital.com/content/dam/doc-library/en\\_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf](https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf)", "author_fullname": "t2_13pr7xbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which WD 22TB HDD is quieter, WD Red Pro or WD Purple Pro?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1016035", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1672642972.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672642703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using MG08ACA16TE (MG08) for recording TV broadcasts 24/7 in my bedroom. Unfortunately the HDD is not that quiet. &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/xomoea/is_this_thudding_sound_normal_toshiba_mg08_drive/\"&gt;It has thudding sound like others in this sub mentioned.&lt;/a&gt;  Not unbearable, but it would be nice if I can get rid of it. I&amp;#39;m thinking of replacing that drive with larger one, and repurposing MG08 for backup drive, or for NAS drive which I only power on with Wake on LAN when I need it.&lt;/p&gt;\n\n&lt;p&gt;To minimize power consumption I only want to use single drive. WD is the only manufacturer that makes 22TB drive. Which model is quieter, WD221PURP (Purple Pro) or WD221KFGX (Red Pro)? On datasheets both models have the same acoustics (same dBA), so the actual noise level when used at home is also the same?&lt;/p&gt;\n\n&lt;p&gt;Ultrastar/Gold model has the same dbA value on datasheets too but consumes more power than those 2 models.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-red-pro-hdd/product-brief-western-digital-wd-red-pro-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-purple-pro-hdd/product-brief-wd-purple-pro-sata-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1016035", "is_robot_indexable": true, "report_reasons": null, "author": "vroad_x", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1016035/which_wd_22tb_hdd_is_quieter_wd_red_pro_or_wd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1016035/which_wd_22tb_hdd_is_quieter_wd_red_pro_or_wd/", "subreddit_subscribers": 663375, "created_utc": 1672642703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My online class uses Yuzu as the books. This service is through Barnes &amp; Noble. I only have access to the books during the class and for some of the books I feel I will need the information long after I am done with the course but still while I am in school.  I know I can just do a snip of each screen and save it but that is rather cumbersome and wouldn't let me search the pages. Any suggestions on how I can store this book on my PC long term?", "author_fullname": "t2_9p63ytht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I can't find a way to save a textbook on my PC from the Yuzu service", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1012l96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672631775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My online class uses Yuzu as the books. This service is through Barnes &amp;amp; Noble. I only have access to the books during the class and for some of the books I feel I will need the information long after I am done with the course but still while I am in school.  I know I can just do a snip of each screen and save it but that is rather cumbersome and wouldn&amp;#39;t let me search the pages. Any suggestions on how I can store this book on my PC long term?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1012l96", "is_robot_indexable": true, "report_reasons": null, "author": "AnOriginalName2021", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1012l96/i_cant_find_a_way_to_save_a_textbook_on_my_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1012l96/i_cant_find_a_way_to_save_a_textbook_on_my_pc/", "subreddit_subscribers": 663375, "created_utc": 1672631775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have hundreds and possibly thousands of older photos I want to digitize and save. \nThe Epson FastPhoto seems like the way to go, but is expensive. \n\nMy thought is that I could put 4 pictures on my flatbed scanner then divide them up once I scan it. Seems like it would be faster than scanning one picture at a time.  \n\nHas anyone used a flatbed scanner to save old photos? What do you recommend? \n\nEDIT: forgot to add.... I would like to buy an external HD to save the photos on. Is there a plug and play HD that I can move from one computer to another if needed? The last one I had many years ago was a major pain to use and required one to use western digital a software and I hated it. \nThank you", "author_fullname": "t2_4ol84now", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I scan 4 photos at once on my flatbed scanner then divide them into individual pictures to save them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100xgs1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672617361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hundreds and possibly thousands of older photos I want to digitize and save. \nThe Epson FastPhoto seems like the way to go, but is expensive. &lt;/p&gt;\n\n&lt;p&gt;My thought is that I could put 4 pictures on my flatbed scanner then divide them up once I scan it. Seems like it would be faster than scanning one picture at a time.  &lt;/p&gt;\n\n&lt;p&gt;Has anyone used a flatbed scanner to save old photos? What do you recommend? &lt;/p&gt;\n\n&lt;p&gt;EDIT: forgot to add.... I would like to buy an external HD to save the photos on. Is there a plug and play HD that I can move from one computer to another if needed? The last one I had many years ago was a major pain to use and required one to use western digital a software and I hated it. \nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100xgs1", "is_robot_indexable": true, "report_reasons": null, "author": "EverySingleMinute", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100xgs1/can_i_scan_4_photos_at_once_on_my_flatbed_scanner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100xgs1/can_i_scan_4_photos_at_once_on_my_flatbed_scanner/", "subreddit_subscribers": 663375, "created_utc": 1672617361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Any recommendations for a DAS drawer? Looking for 12-40 bays. Currently using an MSA60 that I've had forever and 4 lanes of 3Gb SAS is a bit of a choke. 6G would be fine, 12G preferred.. I remember there was a Lenovo that also had a couple 2.5\" bays that might be good for what I'm doing, but I don't know what the model # was.", "author_fullname": "t2_e7jo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DAS drawer recommendations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100tu5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672608156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recommendations for a DAS drawer? Looking for 12-40 bays. Currently using an MSA60 that I&amp;#39;ve had forever and 4 lanes of 3Gb SAS is a bit of a choke. 6G would be fine, 12G preferred.. I remember there was a Lenovo that also had a couple 2.5&amp;quot; bays that might be good for what I&amp;#39;m doing, but I don&amp;#39;t know what the model # was.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100tu5q", "is_robot_indexable": true, "report_reasons": null, "author": "frankd412", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100tu5q/das_drawer_recommendations/", "subreddit_subscribers": 663375, "created_utc": 1672608156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for recs for a way to merge different backups (whatsapp, signal, text message databases) into a central offline db with some sort of search ability. Can anyone suggest the best way to go about this?\n\nI'm comfortable with tech-heavy solutions and can get all the data from my encrypted backups.", "author_fullname": "t2_16u9go", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation for multi-channel message backup solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_100r4er", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1672601194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for recs for a way to merge different backups (whatsapp, signal, text message databases) into a central offline db with some sort of search ability. Can anyone suggest the best way to go about this?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m comfortable with tech-heavy solutions and can get all the data from my encrypted backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "100r4er", "is_robot_indexable": true, "report_reasons": null, "author": "Thund3r_Struck", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/100r4er/recommendation_for_multichannel_message_backup/", "subreddit_subscribers": 663375, "created_utc": 1672601194.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}