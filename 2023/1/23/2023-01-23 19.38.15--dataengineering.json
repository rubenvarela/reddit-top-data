{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ggio6wps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Is Databricks's autoscaling cost efficient?\" - We take a deep dive with the TPC-DS benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10jfgxm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b_KdZkJwiQj1rTbtg4P_c8pMtKT9rMq5YMn0KV5apTY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1674488625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jeffchousync/is-databrickss-autoscaling-cost-efficient-610e6ece4831", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?auto=webp&amp;v=enabled&amp;s=704027bca845b6d95149fadbce17d0d317ac7686", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=784a1e2ed076a4f03aea5223529b76e9981496b6", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=04fb76b375b06bd72fe8336444568f14dd5308a5", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e57d7113012a7b5cb6a4f13dde3852e8765662f5", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6e86017fc8279c8dc5f0f164538604e931d029c", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fbf349392eed31e6c6c0f506689ec431f1bdca6", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/aYFTorRbi51aUmx2F5kFBnIkjNkCwdfNltJuXdKWvAs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e08f8c70f8e3ee514cf62bd39ff951a4e7c4a54", "width": 1080, "height": 720}], "variants": {}, "id": "jk_zmYBFc4Ic_fBVeBsjIZA9avp8JovVuVkJ7pxqlXk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10jfgxm", "is_robot_indexable": true, "report_reasons": null, "author": "gobstopper_chicken", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jfgxm/is_databrickss_autoscaling_cost_efficient_we_take/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jeffchousync/is-databrickss-autoscaling-cost-efficient-610e6ece4831", "subreddit_subscribers": 87193, "created_utc": 1674488625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, hope you are doing great. \n\nI've been doing Data engineer Jobs for 2 years, tomorrow is my first day as a Data Analyst in a big retail company in my country. As far as i understood in the technical interview, they don't have a modern Data driven architecture, wich I'm sure I'd like to migrate in some near future, by now, i want to be focused in data analytics. So, I've seen quite a bit of videos and posts talking about the impact of BI in analytics, i'm getting into a place where they want me to find KPI, make reports and everything a Data Amalyst has to do.\n\n- How can i make an impact in the business using data analytics/BI/data science?\n\n- is there a standard for retail analytics? What are some areas that can get benefits from analytics?\n\n- what are some best practices for a data analyst with solid Data engineering background? I feel quite anxious because i feel that i can make a real impact but must be patient and make thing right in the right time.\n\n\nThanks for reading me!!! I hope this thread can help anyone going through a work transition.", "author_fullname": "t2_39jk39ho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "switching from DE to DA.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10j2daq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674443775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, hope you are doing great. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been doing Data engineer Jobs for 2 years, tomorrow is my first day as a Data Analyst in a big retail company in my country. As far as i understood in the technical interview, they don&amp;#39;t have a modern Data driven architecture, wich I&amp;#39;m sure I&amp;#39;d like to migrate in some near future, by now, i want to be focused in data analytics. So, I&amp;#39;ve seen quite a bit of videos and posts talking about the impact of BI in analytics, i&amp;#39;m getting into a place where they want me to find KPI, make reports and everything a Data Amalyst has to do.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;How can i make an impact in the business using data analytics/BI/data science?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;is there a standard for retail analytics? What are some areas that can get benefits from analytics?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;what are some best practices for a data analyst with solid Data engineering background? I feel quite anxious because i feel that i can make a real impact but must be patient and make thing right in the right time.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks for reading me!!! I hope this thread can help anyone going through a work transition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10j2daq", "is_robot_indexable": true, "report_reasons": null, "author": "Rokuzov", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10j2daq/switching_from_de_to_da/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10j2daq/switching_from_de_to_da/", "subreddit_subscribers": 87193, "created_utc": 1674443775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently studying python / sql in order to try my chances into changing careers And I have the opportunity via Microsoft Enterprise Skills Initiative to participate in a free 4 day training session for DP-203. I might also have the opportunity to get a discount in the exam after the training.\n\nGiven the fact that I don't have relevant work experience and I have seen Azure's capabilities only in theory in similar sessions, do you think that it is worth devoting time and effort for the training + exam?", "author_fullname": "t2_sye55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft DP-203 for a newbie.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10j6alm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674457001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently studying python / sql in order to try my chances into changing careers And I have the opportunity via Microsoft Enterprise Skills Initiative to participate in a free 4 day training session for DP-203. I might also have the opportunity to get a discount in the exam after the training.&lt;/p&gt;\n\n&lt;p&gt;Given the fact that I don&amp;#39;t have relevant work experience and I have seen Azure&amp;#39;s capabilities only in theory in similar sessions, do you think that it is worth devoting time and effort for the training + exam?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10j6alm", "is_robot_indexable": true, "report_reasons": null, "author": "Vandertroll89", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10j6alm/microsoft_dp203_for_a_newbie/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10j6alm/microsoft_dp203_for_a_newbie/", "subreddit_subscribers": 87193, "created_utc": 1674457001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI\u2019ve made a few ETLs using pandas, for personal projects as well as for work and it has come very handy.\n\nPandas is very memory intensive so it\u2019s not a good solution for large datasets, which is something I\u2019m facing currently.\n\nI\u2019ve heard that using pure python is a good step before using Spark, but I can\u2019t find an example of ETL using just pure python.\n\nHow would that work? Is there an example script for an ETL without using pandas? \n\nAny help would be appreciated!", "author_fullname": "t2_pcb7q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL using pure python (no Pandas)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jgwfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674492186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve made a few ETLs using pandas, for personal projects as well as for work and it has come very handy.&lt;/p&gt;\n\n&lt;p&gt;Pandas is very memory intensive so it\u2019s not a good solution for large datasets, which is something I\u2019m facing currently.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve heard that using pure python is a good step before using Spark, but I can\u2019t find an example of ETL using just pure python.&lt;/p&gt;\n\n&lt;p&gt;How would that work? Is there an example script for an ETL without using pandas? &lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jgwfs", "is_robot_indexable": true, "report_reasons": null, "author": "IceStallion", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jgwfs/etl_using_pure_python_no_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jgwfs/etl_using_pure_python_no_pandas/", "subreddit_subscribers": 87193, "created_utc": 1674492186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everybody !\n\nI have a spark job that is composed as fellows:\n\n1. read static dataFrame from Delta Lake.\n2. read a stream of dataFrame from Delta Lake.\n3. join the stream with the static.\n4. do a flatMapGroupsWithState.\n5. write output.\n\nThe problem is I have a different output from what I expected, like I lost events on `flatMapGroupsWithState`. Not only that, but the output is random. When I re-run with the same input, I get different output.\n\nBut when I added `.coalesce(1)` in the writing operation I always got the desired output in LocalMode but not in ClusterMode.\n\nI also asked in [StackOverflow](https://stackoverflow.com/questions/75209721/spark-flatmapgroupswithstate-random-lost-events).\n\nThank you in advance !", "author_fullname": "t2_m0ecu4ky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark flatMapGroupsWithState random lost events", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jc2is", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1674487100.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674479227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody !&lt;/p&gt;\n\n&lt;p&gt;I have a spark job that is composed as fellows:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;read static dataFrame from Delta Lake.&lt;/li&gt;\n&lt;li&gt;read a stream of dataFrame from Delta Lake.&lt;/li&gt;\n&lt;li&gt;join the stream with the static.&lt;/li&gt;\n&lt;li&gt;do a flatMapGroupsWithState.&lt;/li&gt;\n&lt;li&gt;write output.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The problem is I have a different output from what I expected, like I lost events on &lt;code&gt;flatMapGroupsWithState&lt;/code&gt;. Not only that, but the output is random. When I re-run with the same input, I get different output.&lt;/p&gt;\n\n&lt;p&gt;But when I added &lt;code&gt;.coalesce(1)&lt;/code&gt; in the writing operation I always got the desired output in LocalMode but not in ClusterMode.&lt;/p&gt;\n\n&lt;p&gt;I also asked in &lt;a href=\"https://stackoverflow.com/questions/75209721/spark-flatmapgroupswithstate-random-lost-events\"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10jc2is", "is_robot_indexable": true, "report_reasons": null, "author": "Dhia_lunar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jc2is/spark_flatmapgroupswithstate_random_lost_events/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jc2is/spark_flatmapgroupswithstate_random_lost_events/", "subreddit_subscribers": 87193, "created_utc": 1674479227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Preface this with I'm a beginner here! Wondering what is the best way to validate data from S3 to Snowflake?\n\nI'm using COPY INTOs to load csv files from an S3 bucket into a set of raw tables.\n\nIdeally would like to do some basic data checks like verify files are fully loaded i.e source = target table\nand store them in a table in snowflake too  or check if certain columns are null\n\nI know you can use use the information schema but ideally like my own table to use if that makes sense\n\n\nAny help would he greatly appreciated", "author_fullname": "t2_u4449", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Checks / Verifications from S3 to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ix5u5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674428829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Preface this with I&amp;#39;m a beginner here! Wondering what is the best way to validate data from S3 to Snowflake?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using COPY INTOs to load csv files from an S3 bucket into a set of raw tables.&lt;/p&gt;\n\n&lt;p&gt;Ideally would like to do some basic data checks like verify files are fully loaded i.e source = target table\nand store them in a table in snowflake too  or check if certain columns are null&lt;/p&gt;\n\n&lt;p&gt;I know you can use use the information schema but ideally like my own table to use if that makes sense&lt;/p&gt;\n\n&lt;p&gt;Any help would he greatly appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ix5u5", "is_robot_indexable": true, "report_reasons": null, "author": "bulbasaur2016", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ix5u5/data_checks_verifications_from_s3_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ix5u5/data_checks_verifications_from_s3_to_snowflake/", "subreddit_subscribers": 87193, "created_utc": 1674428829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am an analyst looking to transition over to the DE world. I have been casually looking at job postings and am having a hard time determining whether roles are analytical or platform oriented. From what I understand, DE roles these days are starting to fall into one of these categories. But I know it can vary greatly by company/specific role. I am definitely leaning towards the analytics side just based on my skills and interests; I would like to spend my time applying to roles that are in this space. \n\nAre there any telltale signs that a DE role falls more so into one of those two buckets? For instance are there tools a platform engineer uses that a analytics engineer would never use, or vice versa? Or certain responsibilities that a recruiter might list for one but not the other? Thanks in advance!", "author_fullname": "t2_fldpe8jx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a job posting an Analytics Engineer or Platform Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10j3bvu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1674446776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an analyst looking to transition over to the DE world. I have been casually looking at job postings and am having a hard time determining whether roles are analytical or platform oriented. From what I understand, DE roles these days are starting to fall into one of these categories. But I know it can vary greatly by company/specific role. I am definitely leaning towards the analytics side just based on my skills and interests; I would like to spend my time applying to roles that are in this space. &lt;/p&gt;\n\n&lt;p&gt;Are there any telltale signs that a DE role falls more so into one of those two buckets? For instance are there tools a platform engineer uses that a analytics engineer would never use, or vice versa? Or certain responsibilities that a recruiter might list for one but not the other? Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10j3bvu", "is_robot_indexable": true, "report_reasons": null, "author": "DefiniteKook", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10j3bvu/is_a_job_posting_an_analytics_engineer_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10j3bvu/is_a_job_posting_an_analytics_engineer_or/", "subreddit_subscribers": 87193, "created_utc": 1674446776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it's now fully automated.\n\nI used Python to extract data from [API-FOOTBALL](https://rapidapi.com/api-sports/api/API-FOOTBALL) which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery. \n\nThe API didn't have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run). I used [this guide](https://go.dev/doc/tutorial/web-service-gin) to build it.\n\nAll of the Python files are in a Docker container which is hosted on [Artifact Registry](https://cloud.google.com/artifact-registry).\n\nThe infrastructure takes places on Google Cloud. I use [Cloud Scheduler](https://cloud.google.com/scheduler) to trigger the execution of a Cloud Run Job which in turn runs `main.py` which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.\n\nI was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use [GitHub Actions](https://docs.github.com/en/actions) to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the `main` branch.\n\nOne caveat with the workflow is that it only supports deploying as a Service which didn't work for this project. Luckily, I found this [pull request](https://github.com/google-github-actions/deploy-cloudrun/pull/422) where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.\n\nHere is the [Streamlit dashboard](https://premierleague.streamlit.app/). It\u2019s not great but will continue to improve it now that the backbone is in place. \n\nHere is the [GitHub repo](https://github.com/digitalghost-dev/football-data-pipeline).\n\nHere is a more [detailed document](https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html) on what's needed to build it.\n\nFlowchart:\n\n(Sorry if it's a mess. It's the best design I could think of.\n\nhttps://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26a41a431999b032e52f7529da2cb9493a02b92e", "author_fullname": "t2_bix7v2w5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Another data project, this time with Python, Go, (some SQL), Docker, Google Cloud Services, Streamlit, and GitHub Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": true, "media_metadata": {"k3oz0nmm7uda1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9e507b23b0641f354fbf0147580c807885a5bdb"}, {"y": 117, "x": 216, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9219e21b1aa10a9a19de1f17f3374c7c327768bf"}, {"y": 174, "x": 320, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4972b66ec4566b85953f8488dc15678c2b560e15"}, {"y": 348, "x": 640, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=23ca2789cd5e1046bbbff6283df78055a2668238"}, {"y": 522, "x": 960, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adddab3cfceae9c54d00a7cbf61f3b76872571df"}, {"y": 587, "x": 1080, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=79b011fe0354b7ebc0b043144bd38b7f6736cf2a"}], "s": {"y": 1475, "x": 2711, "u": "https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=26a41a431999b032e52f7529da2cb9493a02b92e"}, "id": "k3oz0nmm7uda1"}}, "name": "t3_10jjsfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/S_VhRppmfdheeScHxGjesOU_4jt49_t2WyC3BWhIhT8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1674498997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my second data project. I wanted to build an automated dashboard that refreshed daily with data/statistics from the current season of the Premier League. After a couple of months of building, it&amp;#39;s now fully automated.&lt;/p&gt;\n\n&lt;p&gt;I used Python to extract data from &lt;a href=\"https://rapidapi.com/api-sports/api/API-FOOTBALL\"&gt;API-FOOTBALL&lt;/a&gt; which is hosted on RapidAPI (very easy to work with), clean up the data and build dataframes, then load in BigQuery. &lt;/p&gt;\n\n&lt;p&gt;The API didn&amp;#39;t have data on stadium locations (lat and lon coordinates) so I took the opportunity to build one with Go and Gin. This API endpoint is hosted on &lt;a href=\"https://cloud.google.com/run/docs/overview/what-is-cloud-run\"&gt;Cloud Run&lt;/a&gt;. I used &lt;a href=\"https://go.dev/doc/tutorial/web-service-gin\"&gt;this guide&lt;/a&gt; to build it.&lt;/p&gt;\n\n&lt;p&gt;All of the Python files are in a Docker container which is hosted on &lt;a href=\"https://cloud.google.com/artifact-registry\"&gt;Artifact Registry&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The infrastructure takes places on Google Cloud. I use &lt;a href=\"https://cloud.google.com/scheduler\"&gt;Cloud Scheduler&lt;/a&gt; to trigger the execution of a Cloud Run Job which in turn runs &lt;code&gt;main.py&lt;/code&gt; which runs the classes from the other Python files. (a Job is different than a Service. Jobs are still in preview). The Job uses the latest Docker digest (image) that is in Artifact Registry.&lt;/p&gt;\n\n&lt;p&gt;I was going to stop the project there but decided that learning/implementing CI/CD would only benefit the project and myself so I use &lt;a href=\"https://docs.github.com/en/actions\"&gt;GitHub Actions&lt;/a&gt; to build a new Docker image, upload it to Artifact Registry, then deploy to Cloud Run as a Job when a commit is made to the &lt;code&gt;main&lt;/code&gt; branch.&lt;/p&gt;\n\n&lt;p&gt;One caveat with the workflow is that it only supports deploying as a Service which didn&amp;#39;t work for this project. Luckily, I found this &lt;a href=\"https://github.com/google-github-actions/deploy-cloudrun/pull/422\"&gt;pull request&lt;/a&gt; where a user modified the code to allow deployment as a Job. This was a godsend and was the final piece of the puzzle.&lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://premierleague.streamlit.app/\"&gt;Streamlit dashboard&lt;/a&gt;. It\u2019s not great but will continue to improve it now that the backbone is in place. &lt;/p&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/digitalghost-dev/football-data-pipeline\"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is a more &lt;a href=\"https://storage.googleapis.com/website-storage-bucket/docs/football-data-pipeline-doc.html\"&gt;detailed document&lt;/a&gt; on what&amp;#39;s needed to build it.&lt;/p&gt;\n\n&lt;p&gt;Flowchart:&lt;/p&gt;\n\n&lt;p&gt;(Sorry if it&amp;#39;s a mess. It&amp;#39;s the best design I could think of.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=26a41a431999b032e52f7529da2cb9493a02b92e\"&gt;https://preview.redd.it/k3oz0nmm7uda1.png?width=2711&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=26a41a431999b032e52f7529da2cb9493a02b92e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?auto=webp&amp;v=enabled&amp;s=6598074286d59906d5c44247a4a696ed5b419537", "width": 2711, "height": 1475}, "resolutions": [{"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c1d3e1093d3e56d69e91a37697b7f5f240dcadb", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d7da8a2b5d6bb21afe4bd7f410416a08b2c233d", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e38ec4ed8e956c4cac666b17df282e74a488dc7", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9f0558b459b606ad122e78d3512a5710025a62c", "width": 640, "height": 348}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=51f6dc574858c1fbf5d532628844b2a7f3d25add", "width": 960, "height": 522}, {"url": "https://external-preview.redd.it/xBHA4ELPSDav5ZVxE456KBARw8gkohmcMGvQfmlCDQ8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=547334d5b61f6d6ea203bd177c974c9f6069b393", "width": 1080, "height": 587}], "variants": {}, "id": "3uckV975S_JuS7Qnrom3RWIKq9VdiWq91CsXQwedgh8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10jjsfp", "is_robot_indexable": true, "report_reasons": null, "author": "digitalghost-dev", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jjsfp/another_data_project_this_time_with_python_go/", "subreddit_subscribers": 87193, "created_utc": 1674498997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a post about creating a CICD pipeline using Github Actions for ETL jobs. I wanted to share with folks here for feedback and suggestions on how to improve/optimize my recommendations.  [https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication](https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication)", "author_fullname": "t2_vhiekvgo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CICD for data pipelines using Github Actions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10jcc8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1674480046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a post about creating a CICD pipeline using Github Actions for ETL jobs. I wanted to share with folks here for feedback and suggestions on how to improve/optimize my recommendations.  &lt;a href=\"https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication\"&gt;https://www.upsolver.com/blog/change-data-capture-cdc-etl-pipelines-for-real-time-replication&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?auto=webp&amp;v=enabled&amp;s=61f05f5efdaab9d2aadb67b4f8445aa456d39b88", "width": 1856, "height": 765}, "resolutions": [{"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=015542d9fc1aaec0d3e31d33b54fcecf121c5789", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e8b2ac637ca1fcb666232302c8041d6669c050c", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7c752c33f853c46268d2c351eb99cd1bf8688ee", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4616db014136813f2ec66d19a7725b794e6fe70", "width": 640, "height": 263}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c81d8aefcab4d7198ea1cff071cf1e2e11e6d81", "width": 960, "height": 395}, {"url": "https://external-preview.redd.it/A15wGK1xd9DrI4XAKXVOty9XP2QOi6yCUMeKrj3ySD0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c3386602bfced0f3c4ff23aae85924db63e9a9c0", "width": 1080, "height": 445}], "variants": {}, "id": "a2TEN80IVj95i-oqeVGuwTnpm5OLg60lPCujEK133ss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10jcc8l", "is_robot_indexable": true, "report_reasons": null, "author": "royondata", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10jcc8l/cicd_for_data_pipelines_using_github_actions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10jcc8l/cicd_for_data_pipelines_using_github_actions/", "subreddit_subscribers": 87193, "created_utc": 1674480046.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}