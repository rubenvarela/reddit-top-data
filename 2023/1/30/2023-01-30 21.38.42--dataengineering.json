{"kind": "Listing", "data": {"after": "t3_10pa7sp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6h7i3jke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Review. Could use some advice as well. Do you think I'll have trouble landing interviews? Should I be applying for mid-level Data Engineer positions? Are there any skills that I should work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10p0mzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Tv7SwsmUrgnveLdH0w5FKq2Sr-DcQzlUiD80y37WEjY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675081431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qdp2lc5jb6fa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?auto=webp&amp;v=enabled&amp;s=22772d13a13f291aa1ccc221da1880b67bdd3970", "width": 1700, "height": 2200}, "resolutions": [{"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b09fd342ede8e6e48cea1ec376cd96d8414a8fc6", "width": 108, "height": 139}, {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=689e11483cb961b8a135105b8fc4ccdece6654f2", "width": 216, "height": 279}, {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d552cd4f97572407fec2fb95f1d27f23bd5d3342", "width": 320, "height": 414}, {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6a8b5db299f3e5d8030365dbb6a5fc3a9060688", "width": 640, "height": 828}, {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=674493bd81a6bb576c07f443ea1e71099549f9a8", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/qdp2lc5jb6fa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=918dd7fb087d1ef8b417f444c3db989fde49822f", "width": 1080, "height": 1397}], "variants": {}, "id": "myRmrE80LjpYaEhDB4-TY2Bt9lkvJYcNnt0UH9PQAlU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10p0mzs", "is_robot_indexable": true, "report_reasons": null, "author": "DullAd6899", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p0mzs/resume_review_could_use_some_advice_as_well_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qdp2lc5jb6fa1.jpg", "subreddit_subscribers": 87960, "created_utc": 1675081431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\n&amp;#x200B;\n\nIf you look at my post history on this sub, you will see that I am a data engineer (7 YoE) who was given the task of creating an enterprise data lake with the goal of ingesting hundreds of data sources in near real-time. This has been my task for the last 6-8 months.\n\nAfter months of hard working all alone, where I started with an empty AWS account, I managed to have a production-ready architecture (all automated with terraform, CI/CD pipelines with automated testing for ETL and streaming apps, real-time monitoring, etc.), and streaming jobs with latency under 5 minutes. Everything was wisely cost-optimized.\n\nFast-forward to last week: less than one month before the go-live, my company decides to ditch everything I've been working on to do the same thing on Snowflake (same performance, 3x the price), and the implementation will be led by a colleague of mine.\n\n&amp;#x200B;\n\nI was a bit resented to my manager, and told him that if something was wrong with my job, he could have told me in advance by sharing their feedback, but they keep insisting that all of this occurred \"randomly\" and is not related to the quality of my job.\n\n&amp;#x200B;\n\nBeing stripped of so many responsibilities - and authority - all of a sudden, is not pleasant. I was prospected a growth path where several DE would have been hired to work with me and I would have become senior/lead DE in 6-12 months. All of this is gone.\n\nI still have to do a 1-1 meeting with my manager to understand what I am supposed to work from now on, and if the company is still planning to make me grow internally or not.\n\n&amp;#x200B;\n\nSo I have some questions:\n\n1. Do you think it's time for me to start looking around? (job market is not that great at the moment though)\n2. Can you help me seeing all of this under a more \"positive\" perspective (if possible at all)?\n3. Given these huge changes, can you anticipate what my future tasks will be related to, and what goals should I set to still be perceived as a valid asset so that my growth inside the company is not compromised?", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for some career advice/guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10owhkk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675065971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you look at my post history on this sub, you will see that I am a data engineer (7 YoE) who was given the task of creating an enterprise data lake with the goal of ingesting hundreds of data sources in near real-time. This has been my task for the last 6-8 months.&lt;/p&gt;\n\n&lt;p&gt;After months of hard working all alone, where I started with an empty AWS account, I managed to have a production-ready architecture (all automated with terraform, CI/CD pipelines with automated testing for ETL and streaming apps, real-time monitoring, etc.), and streaming jobs with latency under 5 minutes. Everything was wisely cost-optimized.&lt;/p&gt;\n\n&lt;p&gt;Fast-forward to last week: less than one month before the go-live, my company decides to ditch everything I&amp;#39;ve been working on to do the same thing on Snowflake (same performance, 3x the price), and the implementation will be led by a colleague of mine.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was a bit resented to my manager, and told him that if something was wrong with my job, he could have told me in advance by sharing their feedback, but they keep insisting that all of this occurred &amp;quot;randomly&amp;quot; and is not related to the quality of my job.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Being stripped of so many responsibilities - and authority - all of a sudden, is not pleasant. I was prospected a growth path where several DE would have been hired to work with me and I would have become senior/lead DE in 6-12 months. All of this is gone.&lt;/p&gt;\n\n&lt;p&gt;I still have to do a 1-1 meeting with my manager to understand what I am supposed to work from now on, and if the company is still planning to make me grow internally or not.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I have some questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you think it&amp;#39;s time for me to start looking around? (job market is not that great at the moment though)&lt;/li&gt;\n&lt;li&gt;Can you help me seeing all of this under a more &amp;quot;positive&amp;quot; perspective (if possible at all)?&lt;/li&gt;\n&lt;li&gt;Given these huge changes, can you anticipate what my future tasks will be related to, and what goals should I set to still be perceived as a valid asset so that my growth inside the company is not compromised?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10owhkk", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10owhkk/looking_for_some_career_adviceguidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10owhkk/looking_for_some_career_adviceguidance/", "subreddit_subscribers": 87960, "created_utc": 1675065971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do I need to set up some kind of pipeline to get the data off the Pi?\n\nOr can my R scripts point directly to the DB on the Pi?\n\nI know this must sound really dumb. I can't seem to get traction with my searches.  Really appreciate any help.", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal project: I'm logging sensor data to Sqlite on a Raspberry Pi. I want to make some pretty visuals with R using the data, but unsure about my options for making the data accessible to R.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oqjgf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675046671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do I need to set up some kind of pipeline to get the data off the Pi?&lt;/p&gt;\n\n&lt;p&gt;Or can my R scripts point directly to the DB on the Pi?&lt;/p&gt;\n\n&lt;p&gt;I know this must sound really dumb. I can&amp;#39;t seem to get traction with my searches.  Really appreciate any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10oqjgf", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10oqjgf/personal_project_im_logging_sensor_data_to_sqlite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10oqjgf/personal_project_im_logging_sensor_data_to_sqlite/", "subreddit_subscribers": 87960, "created_utc": 1675046671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i am currently creating my first personal portfolio project that I could showcase when applying for Data Engineering jobs. I just want to know what you guys think of the project\n\nProcess:\n1. download steam apps/games data from 2 source: steamspy and steamwebstore api. steamspy would be downloaded daily, steamwebstore api on monthly basis. these data are in json format and converted to parquet using pandas and saved locally.\n\n2. The saved parquet files are then transformed using PySpark, possibly joining the data from steamspy and steamwebstore\n\n3. From pyspark, I will load the data into postgresql for possible further transformation and then visualization\n\nI will orchestrate all of these using Airflow and Dockerized so that others may be able to try and test it.\n\ncurrently working on the python/pyspark script to transform the data. \n\nDockerizing the pyspark with airflow might have been the most tricky part so far on this project.\n\nI would like to hear what you guys think. Comments and Suggestions are highly appreciated!", "author_fullname": "t2_sd0dbdkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie Portfolio Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p0bet", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675080350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i am currently creating my first personal portfolio project that I could showcase when applying for Data Engineering jobs. I just want to know what you guys think of the project&lt;/p&gt;\n\n&lt;p&gt;Process:\n1. download steam apps/games data from 2 source: steamspy and steamwebstore api. steamspy would be downloaded daily, steamwebstore api on monthly basis. these data are in json format and converted to parquet using pandas and saved locally.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;The saved parquet files are then transformed using PySpark, possibly joining the data from steamspy and steamwebstore&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;From pyspark, I will load the data into postgresql for possible further transformation and then visualization&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I will orchestrate all of these using Airflow and Dockerized so that others may be able to try and test it.&lt;/p&gt;\n\n&lt;p&gt;currently working on the python/pyspark script to transform the data. &lt;/p&gt;\n\n&lt;p&gt;Dockerizing the pyspark with airflow might have been the most tricky part so far on this project.&lt;/p&gt;\n\n&lt;p&gt;I would like to hear what you guys think. Comments and Suggestions are highly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10p0bet", "is_robot_indexable": true, "report_reasons": null, "author": "rey-techshifterPH", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p0bet/newbie_portfolio_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p0bet/newbie_portfolio_project/", "subreddit_subscribers": 87960, "created_utc": 1675080350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for a tool that has a functionality that I have not been able to find (in my limited googling).\n\n&amp;#x200B;\n\nI'm developing a pipeline that is pretty linear and written in pure python - nothing really run concurrently, each steps is executing after the previous, etc. It has many steps though, so editing and creating new steps in the pipeline takes a lot of time because I have to wait for the previous steps to execute before it gets to the latest step in the pipeline.\n\n&amp;#x200B;\n\nI'm looking for a way to save the state of the data after it completes a certain step, and then run the last step using the data in the modified form.\n\n&amp;#x200B;\n\nFor example: I have a pipeline with 4 steps - Extract JSON1, Extract JSON2, Create a DataFrame from both JSONs, Store it in a Database. If I have already developed steps 1-3, I don't want to have to keep rerunning the whole script to develop step 4. I would want to automatically save the output from the previous steps, and just work on step 4 with the data already collected/modified.\n\n&amp;#x200B;\n\nI know that I could simply save the data in it's own file and do it all manually, but I was wondering if a tool already existed where you could work with the data sequentially and essentially save the state of the data and just work with it that way. This would be a great time saver for me!\n\n&amp;#x200B;\n\nAny help is appreciated, thanks!", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this tool already exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ojtcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675029226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a tool that has a functionality that I have not been able to find (in my limited googling).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m developing a pipeline that is pretty linear and written in pure python - nothing really run concurrently, each steps is executing after the previous, etc. It has many steps though, so editing and creating new steps in the pipeline takes a lot of time because I have to wait for the previous steps to execute before it gets to the latest step in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a way to save the state of the data after it completes a certain step, and then run the last step using the data in the modified form.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example: I have a pipeline with 4 steps - Extract JSON1, Extract JSON2, Create a DataFrame from both JSONs, Store it in a Database. If I have already developed steps 1-3, I don&amp;#39;t want to have to keep rerunning the whole script to develop step 4. I would want to automatically save the output from the previous steps, and just work on step 4 with the data already collected/modified.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know that I could simply save the data in it&amp;#39;s own file and do it all manually, but I was wondering if a tool already existed where you could work with the data sequentially and essentially save the state of the data and just work with it that way. This would be a great time saver for me!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ojtcs", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ojtcs/does_this_tool_already_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ojtcs/does_this_tool_already_exist/", "subreddit_subscribers": 87960, "created_utc": 1675029226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Like the best practices to handle errors in different scenarios.  The price of mili-second-level latency.   How to handle new data and pre-existing data in a unified way. \n\nThe pitfalls one can encounter when building a pipeline.\n\nThings like that.\n\nThe book can be tool-agnostic, or telling all these patterns with specific tools.", "author_fullname": "t2_10j5re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a book about data streaming patterns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oqttx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675047537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like the best practices to handle errors in different scenarios.  The price of mili-second-level latency.   How to handle new data and pre-existing data in a unified way. &lt;/p&gt;\n\n&lt;p&gt;The pitfalls one can encounter when building a pipeline.&lt;/p&gt;\n\n&lt;p&gt;Things like that.&lt;/p&gt;\n\n&lt;p&gt;The book can be tool-agnostic, or telling all these patterns with specific tools.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10oqttx", "is_robot_indexable": true, "report_reasons": null, "author": "shaunyip", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10oqttx/is_there_a_book_about_data_streaming_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10oqttx/is_there_a_book_about_data_streaming_patterns/", "subreddit_subscribers": 87960, "created_utc": 1675047537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We generally prefer to work with tools (CRM, warehouse, etc), which provide easy integration options. What sources of data have caused you the most trouble when attempting to extract data? Also feel free to share any that are exceptionally easy to use.", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most painful/frustrating system or vendor you have to pull data out of?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p6b6k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675094260.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We generally prefer to work with tools (CRM, warehouse, etc), which provide easy integration options. What sources of data have caused you the most trouble when attempting to extract data? Also feel free to share any that are exceptionally easy to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10p6b6k", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10p6b6k/what_is_the_most_painfulfrustrating_system_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p6b6k/what_is_the_most_painfulfrustrating_system_or/", "subreddit_subscribers": 87960, "created_utc": 1675094260.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resume Review. Could use some advice as well. Do you think I'll have trouble landing interviews? Should I be applying for mid-level Data Engineer positions? Are there any skills that I should work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10olr3x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": "transparent", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/X0v5YQppqZC67VSJj6TiMd2YEcnrBfR6kp_qc1kak5s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675033893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1uh87nm7e2fa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?auto=webp&amp;v=enabled&amp;s=9d7b0e69f230df987ff9124284a507c37b3126b6", "width": 1224, "height": 1492}, "resolutions": [{"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=066c70520b5270b3fa2a72cb674902536c93416c", "width": 108, "height": 131}, {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71278438e1b8016ef79a604d60d802c108ffa3f1", "width": 216, "height": 263}, {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f526134f123cf1d34921a05e66e70798124ddd8", "width": 320, "height": 390}, {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96aaee26034776197b65e926ab12b42c5601216e", "width": 640, "height": 780}, {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58b60ab77613359ca6e5d07199c4397e0f84eedb", "width": 960, "height": 1170}, {"url": "https://preview.redd.it/1uh87nm7e2fa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bdbfb0c2e7f60de3ddeee8fa83c95f8760fa6db3", "width": 1080, "height": 1316}], "variants": {}, "id": "kx0L-I4rUIq626KrhrgQZJGgfewYaR0RTjEQN0WFywA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10olr3x", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10olr3x/resume_review_could_use_some_advice_as_well_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1uh87nm7e2fa1.png", "subreddit_subscribers": 87960, "created_utc": 1675033893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI've been a data engineer for years but still struggle to setup my local environment for data development. So I converted jupyter &amp; airflow into plug-n-play apps and wrote a tutorial on how to set them up for local data development. Let me know if you think this is a good approach and happy to answer any questions :)\n\n[https://www.datain30.com/p/data-development-using-jupyter-and](https://www.datain30.com/p/data-development-using-jupyter-and)", "author_fullname": "t2_insol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to setup Jupyter &amp; Airflow for data development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p78an", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675096559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a data engineer for years but still struggle to setup my local environment for data development. So I converted jupyter &amp;amp; airflow into plug-n-play apps and wrote a tutorial on how to set them up for local data development. Let me know if you think this is a good approach and happy to answer any questions :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datain30.com/p/data-development-using-jupyter-and\"&gt;https://www.datain30.com/p/data-development-using-jupyter-and&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/E8FxIvXsoENn6VaVaJnNu-X9kY6ROc1nWGKZquDZqpY.jpg?auto=webp&amp;v=enabled&amp;s=d57acccd37cd2dc1ed1aeda26688d7d7b051a00a", "width": 256, "height": 256}, "resolutions": [{"url": "https://external-preview.redd.it/E8FxIvXsoENn6VaVaJnNu-X9kY6ROc1nWGKZquDZqpY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d03520cfe2eaabc83c52d699ad2f7dd25e528a42", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/E8FxIvXsoENn6VaVaJnNu-X9kY6ROc1nWGKZquDZqpY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc5d9d0177622d49dab11896441e5572bad8637a", "width": 216, "height": 216}], "variants": {}, "id": "fZc830sC60fmrpFMh1DzkGdJurbm_CKNAvt6rJyk86E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10p78an", "is_robot_indexable": true, "report_reasons": null, "author": "ashpreetbedi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p78an/how_to_setup_jupyter_airflow_for_data_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p78an/how_to_setup_jupyter_airflow_for_data_development/", "subreddit_subscribers": 87960, "created_utc": 1675096559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I joined a new team recently and our core analytics pipelines seem very inefficient. Every new feature we build doesn't roll up into a common pipeline but requires it's own brand new one with custom logic to account for some it's new logging. On prior teams, new features were able to leverage existing loggings, modify a field or two, and it'd roll up into existing artifacts with minimal DE investment (and a smooth understanding of how to do logging for SWE).  The current process thus doesn't scale; for every new feature, we either have dedicated DE support or we don't have insight into it.\n\n\n\nGoogle tells me all of my problems can be solved with real-time streaming, deterministic pipelines, Snowflake, AWS, or Looker. But this isn't a tech problem.  This is a general \"this is how to think about building analytics systems\" problem.\n\n\nI'm trying to rethink how our team builds it's analytics artifacts and wondering if there are broad ways to think about logging and/or pipelines to scale analytics.", "author_fullname": "t2_fo0y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some data modeling principles, best practices, or frameworks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p5s5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675093827.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675092964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a new team recently and our core analytics pipelines seem very inefficient. Every new feature we build doesn&amp;#39;t roll up into a common pipeline but requires it&amp;#39;s own brand new one with custom logic to account for some it&amp;#39;s new logging. On prior teams, new features were able to leverage existing loggings, modify a field or two, and it&amp;#39;d roll up into existing artifacts with minimal DE investment (and a smooth understanding of how to do logging for SWE).  The current process thus doesn&amp;#39;t scale; for every new feature, we either have dedicated DE support or we don&amp;#39;t have insight into it.&lt;/p&gt;\n\n&lt;p&gt;Google tells me all of my problems can be solved with real-time streaming, deterministic pipelines, Snowflake, AWS, or Looker. But this isn&amp;#39;t a tech problem.  This is a general &amp;quot;this is how to think about building analytics systems&amp;quot; problem.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to rethink how our team builds it&amp;#39;s analytics artifacts and wondering if there are broad ways to think about logging and/or pipelines to scale analytics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10p5s5y", "is_robot_indexable": true, "report_reasons": null, "author": "sharpchicity", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p5s5y/what_are_some_data_modeling_principles_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p5s5y/what_are_some_data_modeling_principles_best/", "subreddit_subscribers": 87960, "created_utc": 1675092964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dpzgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Drift Detection and Model Monitoring | Free Masterclass", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10ozl7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9h6aU2bmkZIoC1O2s20nAGjhtSvgL0NeF8VBrYCuEcY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675077721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "eventbrite.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.eventbrite.com/e/data-drift-detection-and-model-monitoring-free-masterclass-tickets-528042688897?aff=reddit", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?auto=webp&amp;v=enabled&amp;s=85c8d1b3484363876859324af88f94ca1d1edcba", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59026d3217b3eecd392662d0e21dc4a8ae2eb5e2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b7de445310e4ac72daba762f24eddab83b6eca3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e53fe10df8f5fd87aa0bef70722e538f506b0c7", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4981cd252496cc5f2cb3aee53abc57b27f64e7fb", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Fb0_BLQGPV9mfx4V6tieZa-Xn5GFxrzsXjeTwJIe7Ns.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f6720ff682c2a778e6054d0f7db3907b54e898a1", "width": 960, "height": 480}], "variants": {}, "id": "-5UuaP55ND4qDKcIA1cVfkDvThgE0HGL4u8866lu0OQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10ozl7j", "is_robot_indexable": true, "report_reasons": null, "author": "Reginald_Martin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ozl7j/data_drift_detection_and_model_monitoring_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.eventbrite.com/e/data-drift-detection-and-model-monitoring-free-masterclass-tickets-528042688897?aff=reddit", "subreddit_subscribers": 87960, "created_utc": 1675077721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you typically preform Orchestration for your batch ETL/ELT processes in your organization? This poll is meant to show which Tools are popular in the data engineering space. \n\nA couple months ago there was a similar poll on [What IDE Data Engineers Use](https://www.reddit.com/r/dataengineering/comments/zdd7lv/what_sql_ideeditor_do_you_use/), which got a surprising number of contributions. I thought the results there were quite insightful and so wanted to follow up with this poll. \n\nThe question is somewhat tricky, as some tools do orchestration and ETL, (e.g. Informatica) whereas other tools are just for orchestration (e.g. Airflow), and some unlisted tools are just for transformation (e.g. DBT). I tried my best to bin them thematically.\n\n[View Poll](https://www.reddit.com/poll/10ouixw)", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Orchestration Tool do you use for batch ETL/ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ouixw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675058879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you typically preform Orchestration for your batch ETL/ELT processes in your organization? This poll is meant to show which Tools are popular in the data engineering space. &lt;/p&gt;\n\n&lt;p&gt;A couple months ago there was a similar poll on &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/zdd7lv/what_sql_ideeditor_do_you_use/\"&gt;What IDE Data Engineers Use&lt;/a&gt;, which got a surprising number of contributions. I thought the results there were quite insightful and so wanted to follow up with this poll. &lt;/p&gt;\n\n&lt;p&gt;The question is somewhat tricky, as some tools do orchestration and ETL, (e.g. Informatica) whereas other tools are just for orchestration (e.g. Airflow), and some unlisted tools are just for transformation (e.g. DBT). I tried my best to bin them thematically.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10ouixw\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ouixw", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675663679161, "options": [{"text": "Traditional UI Tool (SSIS, Informatica, Talend, FiveTran, or similar)", "id": "21319493"}, {"text": "Cloud Tool (Azure Data Factory, Google Dataflow, AWS Glue)", "id": "21319494"}, {"text": "Modern Proprietary Tool (Databricks, Trifacta)", "id": "21319495"}, {"text": "Open source Tools (Airflow, Dagster, Argo, Prefect, Luigi)", "id": "21319496"}, {"text": "Pure Code (Python/Java/Scala/Go) + Scheduler (e.g. CronJob/Task Scheduler)", "id": "21319497"}, {"text": "See Results/Other (Add in Comments)", "id": "21319498"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 568, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ouixw/what_orchestration_tool_do_you_use_for_batch/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10ouixw/what_orchestration_tool_do_you_use_for_batch/", "subreddit_subscribers": 87960, "created_utc": 1675058879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been doing some research into data contracts for an upcoming project over the last few weeks and was a little confused by some of the hype. Most of the solutions either seemed way too abstract or relied on pretty mature streaming systems that my company wasn't going to invest in. I saw this article which provided what seems like the clearest and most straightforward approach to implementing a contract on top of the DW. Thought it would be good to share for other folks who don't get it or couldn't find a use case. \n\n&amp;#x200B;\n\n[https://dataproducts.substack.com/p/data-contracts-for-the-warehouse](https://dataproducts.substack.com/p/data-contracts-for-the-warehouse)", "author_fullname": "t2_sv6ixmdq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Contracts for the Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pab1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675104002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been doing some research into data contracts for an upcoming project over the last few weeks and was a little confused by some of the hype. Most of the solutions either seemed way too abstract or relied on pretty mature streaming systems that my company wasn&amp;#39;t going to invest in. I saw this article which provided what seems like the clearest and most straightforward approach to implementing a contract on top of the DW. Thought it would be good to share for other folks who don&amp;#39;t get it or couldn&amp;#39;t find a use case. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dataproducts.substack.com/p/data-contracts-for-the-warehouse\"&gt;https://dataproducts.substack.com/p/data-contracts-for-the-warehouse&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?auto=webp&amp;v=enabled&amp;s=a2d39c2f1a11d7a5863f845ae26d059d4e6319d0", "width": 1200, "height": 386}, "resolutions": [{"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a0d1d01506942b794316b857ac020d08fabd9c5", "width": 108, "height": 34}, {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=874fc86e0b0ee4b07c7e2457576798b590b99083", "width": 216, "height": 69}, {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d62c828a87f834510845b3a1fd15f8f44bb07e91", "width": 320, "height": 102}, {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57b00a276afc2192e519b4cf81df955d6ec5fad2", "width": 640, "height": 205}, {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72bb883d020dcd0d41f02237f3742ef6b8931e35", "width": 960, "height": 308}, {"url": "https://external-preview.redd.it/_upMfYqszjfVNg-P5gm6jhkaDR3rXkNr_s3nF_P9Xgc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fa93bb64b2d5241f29d5107c316bd97b67cc8cb", "width": 1080, "height": 347}], "variants": {}, "id": "ADIdtcpQxX8vf0vWMInYjwkK1HCF_5ytqtQeH9rfEmk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10pab1p", "is_robot_indexable": true, "report_reasons": null, "author": "Immediate-Impact-215", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pab1p/data_contracts_for_the_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pab1p/data_contracts_for_the_data_warehouse/", "subreddit_subscribers": 87960, "created_utc": 1675104002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there. I\u2019m currently at my first DBA role the last 5 months. Im also a SQL developer so it\u2019s kind of a dual role. We manage backups, restore, manage servers, use PostgreSQL, run scripts for data migration, develop, edit queries. \n\nI work with data engineers on my team but they\u2019re the leaders and they work with powershell, DWH, AWS, optimization, design DB\u2019s, etc. \n\nI tell them I want to be like them and become a data engineer. Should I have a few years experience doing what I\u2019m doing? It seems apparent that data engineer isn\u2019t really an entry level role. Im learning all that I can from them. \n\nWhat should I do to ensure I can become one? How should I bring it up to my boss? (He\u2019s the director of DB Operations)", "author_fullname": "t2_vgfkw3kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to go from DBA to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ooyyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675042590.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675042261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there. I\u2019m currently at my first DBA role the last 5 months. Im also a SQL developer so it\u2019s kind of a dual role. We manage backups, restore, manage servers, use PostgreSQL, run scripts for data migration, develop, edit queries. &lt;/p&gt;\n\n&lt;p&gt;I work with data engineers on my team but they\u2019re the leaders and they work with powershell, DWH, AWS, optimization, design DB\u2019s, etc. &lt;/p&gt;\n\n&lt;p&gt;I tell them I want to be like them and become a data engineer. Should I have a few years experience doing what I\u2019m doing? It seems apparent that data engineer isn\u2019t really an entry level role. Im learning all that I can from them. &lt;/p&gt;\n\n&lt;p&gt;What should I do to ensure I can become one? How should I bring it up to my boss? (He\u2019s the director of DB Operations)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ooyyn", "is_robot_indexable": true, "report_reasons": null, "author": "AirDrawnAbility", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ooyyn/want_to_go_from_dba_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ooyyn/want_to_go_from_dba_to_data_engineer/", "subreddit_subscribers": 87960, "created_utc": 1675042261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Consider the UI, logging, debugging, CI/CD (for jobs and images).\n\nAlso, OpenSource is a significant factor :)\n\n&amp;#x200B;\n\nif there's any \\*major\\* system that I missed - please DM and I'll add it\n\n[View Poll](https://www.reddit.com/poll/10p9e41)", "author_fullname": "t2_bh9jm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which system would you use for job scheduling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p9e41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675101833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consider the UI, logging, debugging, CI/CD (for jobs and images).&lt;/p&gt;\n\n&lt;p&gt;Also, OpenSource is a significant factor :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;if there&amp;#39;s any *major* system that I missed - please DM and I&amp;#39;ll add it&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10p9e41\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10p9e41", "is_robot_indexable": true, "report_reasons": null, "author": "blorby", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675361033255, "options": [{"text": "Dagster", "id": "21327823"}, {"text": "KubeFlow", "id": "21327824"}, {"text": "AirFlow", "id": "21327825"}, {"text": "Jenkins", "id": "21327826"}, {"text": "Prefect", "id": "21327827"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 49, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p9e41/which_system_would_you_use_for_job_scheduling/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10p9e41/which_system_would_you_use_for_job_scheduling/", "subreddit_subscribers": 87960, "created_utc": 1675101833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in process of building new data infrastructure and we want to avoid using Spark.\n\nI am thinking of 2 possible ways.\n\n1. Python apps to load data to S3 data lake - Trino as SQL query engine - let end users use Trino to access data\n2. Python apps to load data to S3 data lake - python apps (pandas/polars/dask) that transform raw data from data lake into RDBMS (TimescaleDB) - let users use RDBMS to access data\n\nIs there any other way in general? Or why should we prefer one way over another? I am a little bit apessimistic about the Trino way as we need Hive metastore for that and also Trino would become a single point of failure - as if Trino would not run, no one would get to the data.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data architecture without Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p97nr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675101421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in process of building new data infrastructure and we want to avoid using Spark.&lt;/p&gt;\n\n&lt;p&gt;I am thinking of 2 possible ways.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python apps to load data to S3 data lake - Trino as SQL query engine - let end users use Trino to access data&lt;/li&gt;\n&lt;li&gt;Python apps to load data to S3 data lake - python apps (pandas/polars/dask) that transform raw data from data lake into RDBMS (TimescaleDB) - let users use RDBMS to access data&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is there any other way in general? Or why should we prefer one way over another? I am a little bit apessimistic about the Trino way as we need Hive metastore for that and also Trino would become a single point of failure - as if Trino would not run, no one would get to the data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10p97nr", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p97nr/data_architecture_without_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p97nr/data_architecture_without_spark/", "subreddit_subscribers": 87960, "created_utc": 1675101421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, all! Long time lurker. Is there any open source database for a traditional OLAP Data Warehouse? \n\nI was looking into Citus but I'm not sure if that is the right choice. Pinot/Druid seem to 'realtime' for our use cases.\n\nThe majority of data will be events from either email/push communication and web form registrations. (Around 250k to 1m events a day) Consumed via Dashboards (majority daily extracts and a with few hourly extracts)\n\nPublic cloud seems to be a no go for management. (Existing contracts that need to be renegotiated + GDPR fears) \n\n\nThanks &amp; feel free to ask questions.", "author_fullname": "t2_i7mwf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open Source Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p9207", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675101034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, all! Long time lurker. Is there any open source database for a traditional OLAP Data Warehouse? &lt;/p&gt;\n\n&lt;p&gt;I was looking into Citus but I&amp;#39;m not sure if that is the right choice. Pinot/Druid seem to &amp;#39;realtime&amp;#39; for our use cases.&lt;/p&gt;\n\n&lt;p&gt;The majority of data will be events from either email/push communication and web form registrations. (Around 250k to 1m events a day) Consumed via Dashboards (majority daily extracts and a with few hourly extracts)&lt;/p&gt;\n\n&lt;p&gt;Public cloud seems to be a no go for management. (Existing contracts that need to be renegotiated + GDPR fears) &lt;/p&gt;\n\n&lt;p&gt;Thanks &amp;amp; feel free to ask questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10p9207", "is_robot_indexable": true, "report_reasons": null, "author": "Kiliangg", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p9207/open_source_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p9207/open_source_data_warehouse/", "subreddit_subscribers": 87960, "created_utc": 1675101034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am currently working on a project that includes:\n\n* 4 on-premises servers each in a country\n* 40 tables per server (160 total)\n* Daily load of max 20 GB (including incremental and full loads)\n* ADF with a **for each** activity to copy the tables to blob storage as csv/usv files\n\nI need to setup an **on-premises server** that will be connected to the 4 servers and will host the **self-hosted integration runtime** where I will be pulling the data from. Can you help figure out what are the hardware specs that I need for this server (Cores, RAM, OS, etc...) and if you can explain how do I estimate these specs will be helpful?\n\nThank you in advance", "author_fullname": "t2_4k4ezlgc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure self-hosted integration runtime hardware", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p7w7p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675098223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project that includes:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;4 on-premises servers each in a country&lt;/li&gt;\n&lt;li&gt;40 tables per server (160 total)&lt;/li&gt;\n&lt;li&gt;Daily load of max 20 GB (including incremental and full loads)&lt;/li&gt;\n&lt;li&gt;ADF with a &lt;strong&gt;for each&lt;/strong&gt; activity to copy the tables to blob storage as csv/usv files&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I need to setup an &lt;strong&gt;on-premises server&lt;/strong&gt; that will be connected to the 4 servers and will host the &lt;strong&gt;self-hosted integration runtime&lt;/strong&gt; where I will be pulling the data from. Can you help figure out what are the hardware specs that I need for this server (Cores, RAM, OS, etc...) and if you can explain how do I estimate these specs will be helpful?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10p7w7p", "is_robot_indexable": true, "report_reasons": null, "author": "wissamimad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10p7w7p/azure_selfhosted_integration_runtime_hardware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10p7w7p/azure_selfhosted_integration_runtime_hardware/", "subreddit_subscribers": 87960, "created_utc": 1675098223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, \n\nI'm working on a data engineering project ( knowing that my back ground is data science ) \n\nThe outline of the project is the following : \n\n* We have a certain directory that is shared between local hosts in the intranet, new files (with different formats : csv, xlsx) are added periodically.\n* The directory should therefore be watched for changes to trigger the pipeline.\n* After getting the data from the directory and persisting it in a database, It is possible to modify the data through certain predefined business rules.\n\nI though about using airflow and dbt.\n\nWith the help of airflow's FileSensor i can check for changes in directory to trigger the pipeline that consist of a first task which is create\\_table (in a already built database), after that I would use pandas to read the last added files and then load them to the database.\n\nFrom this point, I can use dbt to transform the data, knowing that I have to expose an API to be able to talk to the front end about which business rule to use ( I can enroll all of the above mentioned steps in a FastAPI app) \n\n&amp;#x200B;\n\nWhat do you think about the architecture and stack I'm using ? is it efficient to address this project ?", "author_fullname": "t2_453gi8yu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT pipeline using airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ozaz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675076658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a data engineering project ( knowing that my back ground is data science ) &lt;/p&gt;\n\n&lt;p&gt;The outline of the project is the following : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We have a certain directory that is shared between local hosts in the intranet, new files (with different formats : csv, xlsx) are added periodically.&lt;/li&gt;\n&lt;li&gt;The directory should therefore be watched for changes to trigger the pipeline.&lt;/li&gt;\n&lt;li&gt;After getting the data from the directory and persisting it in a database, It is possible to modify the data through certain predefined business rules.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I though about using airflow and dbt.&lt;/p&gt;\n\n&lt;p&gt;With the help of airflow&amp;#39;s FileSensor i can check for changes in directory to trigger the pipeline that consist of a first task which is create_table (in a already built database), after that I would use pandas to read the last added files and then load them to the database.&lt;/p&gt;\n\n&lt;p&gt;From this point, I can use dbt to transform the data, knowing that I have to expose an API to be able to talk to the front end about which business rule to use ( I can enroll all of the above mentioned steps in a FastAPI app) &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What do you think about the architecture and stack I&amp;#39;m using ? is it efficient to address this project ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10ozaz9", "is_robot_indexable": true, "report_reasons": null, "author": "JustRoof4465", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ozaz9/elt_pipeline_using_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ozaz9/elt_pipeline_using_airflow/", "subreddit_subscribers": 87960, "created_utc": 1675076658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to create a pipeline that downloads daily data from public APIs, say Reddit posts or Facebook ads data. The data then will be put into a BigQuery database and sent as excel files on email or uploaded to a google drive as sheets. What is the best solution for this? I tried looking at Airflow, cloud composer or cloud scheduler but I am not sure if these tools are meant to do these.", "author_fullname": "t2_2knag8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatically download data from public APIs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oy3wi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675072214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create a pipeline that downloads daily data from public APIs, say Reddit posts or Facebook ads data. The data then will be put into a BigQuery database and sent as excel files on email or uploaded to a google drive as sheets. What is the best solution for this? I tried looking at Airflow, cloud composer or cloud scheduler but I am not sure if these tools are meant to do these.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10oy3wi", "is_robot_indexable": true, "report_reasons": null, "author": "lordgriefter", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10oy3wi/automatically_download_data_from_public_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10oy3wi/automatically_download_data_from_public_apis/", "subreddit_subscribers": 87960, "created_utc": 1675072214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an Azure Databricks instance which for whatever reason just can't seem to see an FTP server that is within our network. We had port 21 opened through the firewall, then 22, but still nothing. The same FTP server is visible from my local machine which im using for development, I can connect and do stuff, but from databricks I can't connect.\n\nI'm looking for ideas what could be wrong, because this issue has been on our shoulders for weeks now, we can't seem to make a way forward and at this point the rest of my hair on my bald head is falling out.\n\nI'm using the built-in ftplib python library to connect. A very simple code is then ran:\n\n    import ftplib\n    ftp = ftplib.FTP(\"hostname\")\n\nThis gets a timeout error. The same code on my local machine works wonderfully. What are your experiences? Is there anything we should consider? Google doesn't seem to be too helpful at this time.", "author_fullname": "t2_hp7r8vez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Databricks can't see our FTP server - looking for ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10pdcna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675111197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an Azure Databricks instance which for whatever reason just can&amp;#39;t seem to see an FTP server that is within our network. We had port 21 opened through the firewall, then 22, but still nothing. The same FTP server is visible from my local machine which im using for development, I can connect and do stuff, but from databricks I can&amp;#39;t connect.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for ideas what could be wrong, because this issue has been on our shoulders for weeks now, we can&amp;#39;t seem to make a way forward and at this point the rest of my hair on my bald head is falling out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using the built-in ftplib python library to connect. A very simple code is then ran:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import ftplib\nftp = ftplib.FTP(&amp;quot;hostname&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This gets a timeout error. The same code on my local machine works wonderfully. What are your experiences? Is there anything we should consider? Google doesn&amp;#39;t seem to be too helpful at this time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10pdcna", "is_robot_indexable": true, "report_reasons": null, "author": "Labanc_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pdcna/azure_databricks_cant_see_our_ftp_server_looking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pdcna/azure_databricks_cant_see_our_ftp_server_looking/", "subreddit_subscribers": 87960, "created_utc": 1675111197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Luckily most of what I do is in Spark and I am fortunate enough to work with tables that are maintained by IT. Though, when I have to use Sqoop to get data from another source it is a complete nightmare. The error messages aren\u2019t helpful and it really just feels like a black box. \n\nLeveraging this tool is one skill for DE that I have been struggling with for a long time. Does anyone have any advice for improving with the tool?", "author_fullname": "t2_cdlr4ijm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sqoop Problems/Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10pd1cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675110445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Luckily most of what I do is in Spark and I am fortunate enough to work with tables that are maintained by IT. Though, when I have to use Sqoop to get data from another source it is a complete nightmare. The error messages aren\u2019t helpful and it really just feels like a black box. &lt;/p&gt;\n\n&lt;p&gt;Leveraging this tool is one skill for DE that I have been struggling with for a long time. Does anyone have any advice for improving with the tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pd1cb", "is_robot_indexable": true, "report_reasons": null, "author": "Babbage224", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pd1cb/sqoop_problemsadvice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pd1cb/sqoop_problemsadvice/", "subreddit_subscribers": 87960, "created_utc": 1675110445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering! I just applied to a DE job that focuses more on data governance and data privacy. Any insights on this field of data engineering? What usually is your day-to-day activity and would this still be a trend 5-10 years from now. My past experiences are usually focused on etl/elt,cloud, and data migration. This is a new space for me and I would like to gather some of your insights. Thank you!", "author_fullname": "t2_4zm6htus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future on Data Governance and Data Privacy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10pchzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675109146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I just applied to a DE job that focuses more on data governance and data privacy. Any insights on this field of data engineering? What usually is your day-to-day activity and would this still be a trend 5-10 years from now. My past experiences are usually focused on etl/elt,cloud, and data migration. This is a new space for me and I would like to gather some of your insights. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10pchzm", "is_robot_indexable": true, "report_reasons": null, "author": "lanceanity", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pchzm/future_on_data_governance_and_data_privacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pchzm/future_on_data_governance_and_data_privacy/", "subreddit_subscribers": 87960, "created_utc": 1675109146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there!\nWhat\u2019s your recommendation? I\u2019ve been working with nginx in the past but was more or less I have a web developer background. Is nginx a thing in the data engineering domain or are there other (maybe easier to setup) tools?", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse Proxy and Load Balancer for small to medium data engineering projects.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10pc5w2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675108378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!\nWhat\u2019s your recommendation? I\u2019ve been working with nginx in the past but was more or less I have a web developer background. Is nginx a thing in the data engineering domain or are there other (maybe easier to setup) tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pc5w2", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pc5w2/reverse_proxy_and_load_balancer_for_small_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pc5w2/reverse_proxy_and_load_balancer_for_small_to/", "subreddit_subscribers": 87960, "created_utc": 1675108378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked the last 4 years as a Data Steward, Data Consultant and the last couple months as a Data Engineer. Now I'm looking to advance my career and land a job as a Big Data Engineer at Booking.com.\n\nI'm considering a MBA in Big Data &amp; Analytics at the University of Amsterdam, but I'm wondering if it will significantly improve my chances. I have a Bachelors in Business Administration, I landed my current job on work experience and figured that the MBA will push my profile to the next level.\n\nAre there any Data Engineers that did an MBA and want to share there experience? Or recruiters that can confirm or deny that it offers a significant advantage in the selection process?", "author_fullname": "t2_9szmjnv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does an MBA provide a significant advantage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pa7sp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675103783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked the last 4 years as a Data Steward, Data Consultant and the last couple months as a Data Engineer. Now I&amp;#39;m looking to advance my career and land a job as a Big Data Engineer at Booking.com.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering a MBA in Big Data &amp;amp; Analytics at the University of Amsterdam, but I&amp;#39;m wondering if it will significantly improve my chances. I have a Bachelors in Business Administration, I landed my current job on work experience and figured that the MBA will push my profile to the next level.&lt;/p&gt;\n\n&lt;p&gt;Are there any Data Engineers that did an MBA and want to share there experience? Or recruiters that can confirm or deny that it offers a significant advantage in the selection process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10pa7sp", "is_robot_indexable": true, "report_reasons": null, "author": "AbbreviationsShot240", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pa7sp/does_an_mba_provide_a_significant_advantage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pa7sp/does_an_mba_provide_a_significant_advantage/", "subreddit_subscribers": 87960, "created_utc": 1675103783.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}