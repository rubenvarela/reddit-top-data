{"kind": "Listing", "data": {"after": "t3_10onf98", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_f3kfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas Illustrated: The Visual Guide to Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_10owdbz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Tgjzgp-DRiYdkmqA9QEjUMFcWJ-_YYSeRs_r42Ocz44.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675065556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "betterprogramming.pub", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://betterprogramming.pub/pandas-illustrated-the-definitive-visual-guide-to-pandas-c31fa921a43", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?auto=webp&amp;v=enabled&amp;s=9ccebaf281ea48dd2dc6a45db96cd7a066e804fe", "width": 1060, "height": 607}, "resolutions": [{"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c4b093e08bb12c95353e7348a8a69d2b9189ae", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=189ce26a47caacbeaaac734b9f0f935fead6617f", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c0202e7f020c3059822dd05d12a93d00ca3fd64", "width": 320, "height": 183}, {"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32672e8fb6772a12bb49dd2e38e07470bb5221b9", "width": 640, "height": 366}, {"url": "https://external-preview.redd.it/Np_zq3cdyi-27bPhWjH_aZ8Ft-twQ2GPNOeQG4O5GuE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc309d562946020f8adc5dd81df86ba0b4339281", "width": 960, "height": 549}], "variants": {}, "id": "yaoGEn8SmKZdsXg7w0-i3q7DXtxQqhH99698zkdg-i4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10owdbz", "is_robot_indexable": true, "report_reasons": null, "author": "jettico", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10owdbz/pandas_illustrated_the_visual_guide_to_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://betterprogramming.pub/pandas-illustrated-the-definitive-visual-guide-to-pandas-c31fa921a43", "subreddit_subscribers": 842873, "created_utc": 1675065556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My best friend has a new job and was asked which laptop she want to have for her data science job.\nShe has to deal with a lot of data, but also has to hold presentations and the laptop shouldn\u2019t be too thick, so preferably in ultrabook style.\n\nThe price range is up to ~3200$.\n\nWhich one would you recommend? \ud83d\ude0a\ud83d\ude0a\n\nShe is a windows user but has an iphone, so open to mac, but some software she is using like SAS is not optimized for mac, she said.", "author_fullname": "t2_emdvp6qs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which laptop would you recommend for data scientist / statistician?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10okxxd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675031911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My best friend has a new job and was asked which laptop she want to have for her data science job.\nShe has to deal with a lot of data, but also has to hold presentations and the laptop shouldn\u2019t be too thick, so preferably in ultrabook style.&lt;/p&gt;\n\n&lt;p&gt;The price range is up to ~3200$.&lt;/p&gt;\n\n&lt;p&gt;Which one would you recommend? \ud83d\ude0a\ud83d\ude0a&lt;/p&gt;\n\n&lt;p&gt;She is a windows user but has an iphone, so open to mac, but some software she is using like SAS is not optimized for mac, she said.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10okxxd", "is_robot_indexable": true, "report_reasons": null, "author": "lattecoffeegirl", "discussion_type": null, "num_comments": 86, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10okxxd/which_laptop_would_you_recommend_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10okxxd/which_laptop_would_you_recommend_for_data/", "subreddit_subscribers": 842873, "created_utc": 1675031911.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m feeling so lost here guys. Back in the spring I signed up for Merit America\u2019s Data Analyst program and finished in November. I\u2019ve been putting out applications like crazy and not a word back on anything.\n\nOn one hand this part isn\u2019t a shock, it lines up with everything I\u2019ve been told about what to expect. But somehow I\u2019m still losing my mind here. \n\nAll I ever wanted was a job that pays well and that I can get out of bed in the morning for. Data seemed great. I guess I was naive because I wasn\u2019t expecting all this added career development networking LinkedIn bs to be a part of it. \n\nI see people on Reddit saying that I\u2019m probably not going to get a data job first thing, on account of zero experience. No, you have to \u201cget your foot in the door\u201d doing god knows what else in some other job and hope you can spend enough time looking at a spreadsheet to put it on your resume using flowery hyperbolic marketing horse s. What other job am I supposed to apply for? I\u2019m in data because I don\u2019t have any other skills! This was my last god forsaken hope. \n\nI don\u2019t know what I\u2019m supposed to do. Career development is so f\u2019d. I don\u2019t care about any of this, I just need money and to not spend 40 hrs a week wishing I was unconscious. Why is this so hard.", "author_fullname": "t2_9qcjxa22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m so lost.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10osfdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675052172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m feeling so lost here guys. Back in the spring I signed up for Merit America\u2019s Data Analyst program and finished in November. I\u2019ve been putting out applications like crazy and not a word back on anything.&lt;/p&gt;\n\n&lt;p&gt;On one hand this part isn\u2019t a shock, it lines up with everything I\u2019ve been told about what to expect. But somehow I\u2019m still losing my mind here. &lt;/p&gt;\n\n&lt;p&gt;All I ever wanted was a job that pays well and that I can get out of bed in the morning for. Data seemed great. I guess I was naive because I wasn\u2019t expecting all this added career development networking LinkedIn bs to be a part of it. &lt;/p&gt;\n\n&lt;p&gt;I see people on Reddit saying that I\u2019m probably not going to get a data job first thing, on account of zero experience. No, you have to \u201cget your foot in the door\u201d doing god knows what else in some other job and hope you can spend enough time looking at a spreadsheet to put it on your resume using flowery hyperbolic marketing horse s. What other job am I supposed to apply for? I\u2019m in data because I don\u2019t have any other skills! This was my last god forsaken hope. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know what I\u2019m supposed to do. Career development is so f\u2019d. I don\u2019t care about any of this, I just need money and to not spend 40 hrs a week wishing I was unconscious. Why is this so hard.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10osfdh", "is_robot_indexable": true, "report_reasons": null, "author": "TimeForBagel", "discussion_type": null, "num_comments": 87, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10osfdh/im_so_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10osfdh/im_so_lost/", "subreddit_subscribers": 842873, "created_utc": 1675052172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I haven't touched excel in years \n\nI prefer to use google sheets because:\n\n1. It's collaborative through your Google account\n2. Free\n3. I don't often/ never have to use the advanced functions of Excel\n\nWhat about you guys?", "author_fullname": "t2_6lvuczf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Sheets or MS Excel, which one do you prefer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oqoc8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675047059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t touched excel in years &lt;/p&gt;\n\n&lt;p&gt;I prefer to use google sheets because:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;It&amp;#39;s collaborative through your Google account&lt;/li&gt;\n&lt;li&gt;Free&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t often/ never have to use the advanced functions of Excel&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What about you guys?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oqoc8", "is_robot_indexable": true, "report_reasons": null, "author": "RexFury101", "discussion_type": null, "num_comments": 89, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oqoc8/google_sheets_or_ms_excel_which_one_do_you_prefer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oqoc8/google_sheets_or_ms_excel_which_one_do_you_prefer/", "subreddit_subscribers": 842873, "created_utc": 1675047059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve recently been laid off from my Data Science role in the UK. Currently looking for some ways to make ends meet whilst I look for another full-time role, and was wondering if anyone had some experience with contract or freelance data science work.\n\nI\u2019m most intrigued to know:\n\n1) What the best way to find these roles would be. Seems to be quite a few platforms, if I used one I\u2019d be unsure how to choose between them.\n2) If this would be appropriate for me. I\u2019ve only got 1.5 years of commercial DS experience post-uni, largely designing models and putting models into production.", "author_fullname": "t2_mh632", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions re: freelance DS work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10od4b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675013313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve recently been laid off from my Data Science role in the UK. Currently looking for some ways to make ends meet whilst I look for another full-time role, and was wondering if anyone had some experience with contract or freelance data science work.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m most intrigued to know:&lt;/p&gt;\n\n&lt;p&gt;1) What the best way to find these roles would be. Seems to be quite a few platforms, if I used one I\u2019d be unsure how to choose between them.\n2) If this would be appropriate for me. I\u2019ve only got 1.5 years of commercial DS experience post-uni, largely designing models and putting models into production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10od4b0", "is_robot_indexable": true, "report_reasons": null, "author": "JxLes", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10od4b0/questions_re_freelance_ds_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10od4b0/questions_re_freelance_ds_work/", "subreddit_subscribers": 842873, "created_utc": 1675013313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/pzmy5m9yp5fa1.png?width=660&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b4d2ced783a21fd3bc0aca2a421dee490631bd44", "author_fullname": "t2_k7ds1cx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this how it really works?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 126, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pzmy5m9yp5fa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 97, "x": 108, "u": "https://preview.redd.it/pzmy5m9yp5fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b17d7064a58123d1152fd3d926ac666da22b5896"}, {"y": 195, "x": 216, "u": "https://preview.redd.it/pzmy5m9yp5fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b33aba7a6e3bb5198b42aebdda158ea884c0482"}, {"y": 289, "x": 320, "u": "https://preview.redd.it/pzmy5m9yp5fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a2e89faec781b72a973e90dd0abd2a96716116e"}, {"y": 579, "x": 640, "u": "https://preview.redd.it/pzmy5m9yp5fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec196c5e3fc2f61f0bd6aa8c53d52909e9b9d4ca"}], "s": {"y": 598, "x": 660, "u": "https://preview.redd.it/pzmy5m9yp5fa1.png?width=660&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b4d2ced783a21fd3bc0aca2a421dee490631bd44"}, "id": "pzmy5m9yp5fa1"}}, "name": "t3_10oymqd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/o-UEwYmlN9z2yL74NAGS2ZaIEg5yQrMGf2JRQjKDaC4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675074193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pzmy5m9yp5fa1.png?width=660&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=b4d2ced783a21fd3bc0aca2a421dee490631bd44\"&gt;https://preview.redd.it/pzmy5m9yp5fa1.png?width=660&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=b4d2ced783a21fd3bc0aca2a421dee490631bd44&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oymqd", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Put8678", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oymqd/is_this_how_it_really_works/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oymqd/is_this_how_it_really_works/", "subreddit_subscribers": 842873, "created_utc": 1675074193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vkom8wkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PageRank Algorithm for Graph Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_10oyeup", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/10y90BGvVE5bSm58ubgEclcnxWMHhDDqDW-VOdSiDIM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675073358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/pagerank-algorithm-for-graph-databases", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?auto=webp&amp;v=enabled&amp;s=5d38b6297d2c8d419a6c2a84c92a0a7fff955de4", "width": 2400, "height": 1318}, "resolutions": [{"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=707db689252c99e6fcadeb8fc521f626980bee0f", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44dde37f3a13be88105dd215da98e3c781fdabba", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c369f7cf5e7834de517a591551678aa2002878a0", "width": 320, "height": 175}, {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20c2d74cbd060b30f46f885749fd8af42aa4fe6e", "width": 640, "height": 351}, {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e33cc1b47d8ee1eedfff2aebe3688de5ab7dc3ba", "width": 960, "height": 527}, {"url": "https://external-preview.redd.it/vq3rqHQKV-_4B9BzwnLSj6kovahoexwKA3x5LRpKxTc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b02a839022a91e6549c2a4f7c3544f4f651c4ef", "width": 1080, "height": 593}], "variants": {}, "id": "94zGA_XS-slinh_NmUJL479WXJMOg4e1T0eaQZcFZRo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oyeup", "is_robot_indexable": true, "report_reasons": null, "author": "JuYuJu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oyeup/pagerank_algorithm_for_graph_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/pagerank-algorithm-for-graph-databases", "subreddit_subscribers": 842873, "created_utc": 1675073358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 30 Jan, 2023 - 06 Feb, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10otaw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675054870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10otaw3", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 8, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10otaw3/weekly_entering_transitioning_thread_30_jan_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/10otaw3/weekly_entering_transitioning_thread_30_jan_2023/", "subreddit_subscribers": 842873, "created_utc": 1675054870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "FYI I'm still a student so if there's sth I'm missing and/or misunderstanding, do enlightment me on this topic. Esp. from the perspective of practitioners in the real work setting.\n\nWhen it comes to hyperparams tuning, I've always been directed to using GridSearchCV or RandomSearchCV and that's the end of that. However, I've never really felt that those 2 are the best methods as the former seems to be rather arbitrary and the latter, well, simply random. After more research, I found out abt Bayesian optimization and based on my experience using it so far, it's always outperformed GridSearchCV and RandomSearchCV.\n\nIf u're a practitioner in the field, do u use Bayesian optimization for hyperparams tuning or not? Is there perhaps a more practical reason as to why/why not? (e.g. from a computing cost perspective, etc.)? Since GridSearchCV and RandomSearchCV are so prevalent, it appears that they're the go to method for hyperparams tuning altho they're suboptimal compared to Bayesian optimization - even some practitioners I've managed to ask abt the subject actually do know abt Bayesian optimization as a concept but don't rly use it in production.\n\nAppreciate it and thanks for the insights in advance!", "author_fullname": "t2_lp3x6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hyperparams tuning w/ Bayesian optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oclb7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675044396.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675012052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;FYI I&amp;#39;m still a student so if there&amp;#39;s sth I&amp;#39;m missing and/or misunderstanding, do enlightment me on this topic. Esp. from the perspective of practitioners in the real work setting.&lt;/p&gt;\n\n&lt;p&gt;When it comes to hyperparams tuning, I&amp;#39;ve always been directed to using GridSearchCV or RandomSearchCV and that&amp;#39;s the end of that. However, I&amp;#39;ve never really felt that those 2 are the best methods as the former seems to be rather arbitrary and the latter, well, simply random. After more research, I found out abt Bayesian optimization and based on my experience using it so far, it&amp;#39;s always outperformed GridSearchCV and RandomSearchCV.&lt;/p&gt;\n\n&lt;p&gt;If u&amp;#39;re a practitioner in the field, do u use Bayesian optimization for hyperparams tuning or not? Is there perhaps a more practical reason as to why/why not? (e.g. from a computing cost perspective, etc.)? Since GridSearchCV and RandomSearchCV are so prevalent, it appears that they&amp;#39;re the go to method for hyperparams tuning altho they&amp;#39;re suboptimal compared to Bayesian optimization - even some practitioners I&amp;#39;ve managed to ask abt the subject actually do know abt Bayesian optimization as a concept but don&amp;#39;t rly use it in production.&lt;/p&gt;\n\n&lt;p&gt;Appreciate it and thanks for the insights in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oclb7", "is_robot_indexable": true, "report_reasons": null, "author": "YsrYsl", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oclb7/hyperparams_tuning_w_bayesian_optimization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oclb7/hyperparams_tuning_w_bayesian_optimization/", "subreddit_subscribers": 842873, "created_utc": 1675012052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am already working for a startup. Things are good and only problem I have is there is no senior to guide me. I was handling all the tasks so far and I was really putting my soul in thr solution by finding the best possible solution online and applying it.  \n\nI had this interview today. It is one of the most prestigious banks in my country.  Tbh questions were pretty basic. And i failed to answer them througly since i havent used them. what made me happy is I almost did it. All the questions asked were thr things that bothet my mind and i was looking for a chance to actually deal with them during real projects. Not just reading about them. Because there is a lot on my plate rn. (non CS background ) \n\nI realized I was stressed out at first but then I realized i really enjoy the questions. This is a first for me. I really enjoy this field and working feels like solving puzzles. I just wanted to share this. I am already feeling too old (29m) but I like that i am sure this is what i would like to do.", "author_fullname": "t2_qzy7otr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just had an DS interview. I failed and I am glad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p19m5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675083488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am already working for a startup. Things are good and only problem I have is there is no senior to guide me. I was handling all the tasks so far and I was really putting my soul in thr solution by finding the best possible solution online and applying it.  &lt;/p&gt;\n\n&lt;p&gt;I had this interview today. It is one of the most prestigious banks in my country.  Tbh questions were pretty basic. And i failed to answer them througly since i havent used them. what made me happy is I almost did it. All the questions asked were thr things that bothet my mind and i was looking for a chance to actually deal with them during real projects. Not just reading about them. Because there is a lot on my plate rn. (non CS background ) &lt;/p&gt;\n\n&lt;p&gt;I realized I was stressed out at first but then I realized i really enjoy the questions. This is a first for me. I really enjoy this field and working feels like solving puzzles. I just wanted to share this. I am already feeling too old (29m) but I like that i am sure this is what i would like to do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10p19m5", "is_robot_indexable": true, "report_reasons": null, "author": "karaposu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p19m5/i_just_had_an_ds_interview_i_failed_and_i_am_glad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10p19m5/i_just_had_an_ds_interview_i_failed_and_i_am_glad/", "subreddit_subscribers": 842873, "created_utc": 1675083488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a basic foundation in in subject and I have even developed my own code to generate some interactive 3D graph networks however I also recognize that I am no expert in the subject so I'm looking for some reccomendations on some good books for self study. \n\n&amp;#x200B;\n\nIdeally, the book would focus more on the math and logic as I can develop the code to implement this myself and realistically the applications at work call for something more powerful than networkX.", "author_fullname": "t2_4cx92o4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Recommendations for Network Graphs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ob7xw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675008596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a basic foundation in in subject and I have even developed my own code to generate some interactive 3D graph networks however I also recognize that I am no expert in the subject so I&amp;#39;m looking for some reccomendations on some good books for self study. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ideally, the book would focus more on the math and logic as I can develop the code to implement this myself and realistically the applications at work call for something more powerful than networkX.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ob7xw", "is_robot_indexable": true, "report_reasons": null, "author": "theRealDavidDavis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ob7xw/book_recommendations_for_network_graphs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ob7xw/book_recommendations_for_network_graphs/", "subreddit_subscribers": 842873, "created_utc": 1675008596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, DS gang. I have to vent a bit and ask for advice/opinions. I'm a DS in a mid-sized company, and I find myself in a situation where I want to quit my job like today. I already have an offer and am interviewing with multiple other companies, and things are going well on that account. \n\nAt home, I'm taking care of someone who needs around the clock supervision, and I do have help with this, so I'm able to work with minor interruptions during the day. But my company has been working me to the bone the last few months, and I have a deadline for a project that involves a new large source of revenue for the company. I do want to get them over the finish line with this, but I really don't want to spend any more time than that. I feel exhausted. \n\nI also live in a medium-sized city, and so everyone knows everyone in the tech field here. \n\nGiven all that, in terms of a one week notice, two week notice, or waiting until I can do proper hand-offs, what should I do? I also have to say I have an amazing team (management is pretty garbage, though), and I'd be sad to leave them in a tough spot. What would you do?", "author_fullname": "t2_g51cu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to decide my timeline for resigning, multiple factors, please chime in!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10p4ram", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675090592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, DS gang. I have to vent a bit and ask for advice/opinions. I&amp;#39;m a DS in a mid-sized company, and I find myself in a situation where I want to quit my job like today. I already have an offer and am interviewing with multiple other companies, and things are going well on that account. &lt;/p&gt;\n\n&lt;p&gt;At home, I&amp;#39;m taking care of someone who needs around the clock supervision, and I do have help with this, so I&amp;#39;m able to work with minor interruptions during the day. But my company has been working me to the bone the last few months, and I have a deadline for a project that involves a new large source of revenue for the company. I do want to get them over the finish line with this, but I really don&amp;#39;t want to spend any more time than that. I feel exhausted. &lt;/p&gt;\n\n&lt;p&gt;I also live in a medium-sized city, and so everyone knows everyone in the tech field here. &lt;/p&gt;\n\n&lt;p&gt;Given all that, in terms of a one week notice, two week notice, or waiting until I can do proper hand-offs, what should I do? I also have to say I have an amazing team (management is pretty garbage, though), and I&amp;#39;d be sad to leave them in a tough spot. What would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10p4ram", "is_robot_indexable": true, "report_reasons": null, "author": "chunkychapstick", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p4ram/trying_to_decide_my_timeline_for_resigning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10p4ram/trying_to_decide_my_timeline_for_resigning/", "subreddit_subscribers": 842873, "created_utc": 1675090592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am about to complete my Economics PhD and am currently transitioning to DS.\n\nI have 2.5 years of quantitative finance and algorithmic trading experience and also ran the trading club at my university for 4 years.\n\nYes, I know that I could go back to finance, but I want a new challenge with a better WLB. \n\nWould these 6.5 years of QF and AT be considered as relevant job experience? Should I add my projects to my DS-related GitHub and portfolio?", "author_fullname": "t2_uliwvhaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would algorithmic trading experience and associated projects constitute 'relevant' experience when transitioning to DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10p3arr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675087599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am about to complete my Economics PhD and am currently transitioning to DS.&lt;/p&gt;\n\n&lt;p&gt;I have 2.5 years of quantitative finance and algorithmic trading experience and also ran the trading club at my university for 4 years.&lt;/p&gt;\n\n&lt;p&gt;Yes, I know that I could go back to finance, but I want a new challenge with a better WLB. &lt;/p&gt;\n\n&lt;p&gt;Would these 6.5 years of QF and AT be considered as relevant job experience? Should I add my projects to my DS-related GitHub and portfolio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10p3arr", "is_robot_indexable": true, "report_reasons": null, "author": "DL-ML-DS-Aspirant", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p3arr/would_algorithmic_trading_experience_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10p3arr/would_algorithmic_trading_experience_and/", "subreddit_subscribers": 842873, "created_utc": 1675087599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1r5ndq0u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Determine the constant values of a function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9g6w0okvd6fa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ce7844327ee1c4a40a4e94f95d89d73fa982325"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3880df00ce14c018557db859f3cb63e097d0c84c"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef9b48610a06fa3eb76e80d5ca2fab3861fc375"}, {"y": 256, "x": 640, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ebe870f1d2aca0f2cbd446db0d626db9088d241c"}, {"y": 384, "x": 960, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dad044b30738bec5b7acf2d76ffd4c9bc67c4782"}, {"y": 432, "x": 1080, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fff45af95833a7997780139ca167d9e12061b4e6"}], "s": {"y": 1600, "x": 4000, "u": "https://preview.redd.it/9g6w0okvd6fa1.png?width=4000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=af9393d8d27326e5a7c6c5595594f6a3b078c67d"}, "id": "9g6w0okvd6fa1"}, "lzdolsage6fa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4787dcfb372ddee359aa8bbe40ec6916e4768b3c"}, {"y": 131, "x": 216, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b70e70acda6a5be56787068912df2065d94f9eb"}, {"y": 194, "x": 320, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f908feb4bb81409fb72a44eed2ed760f518f1374"}, {"y": 388, "x": 640, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ec7fc5a247b7476aff4d57f1e04ef1214718d517"}, {"y": 582, "x": 960, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f03a767b97cde477b53f7c017d3f73b7817d50c5"}, {"y": 655, "x": 1080, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=950e8311a7e55358559e963df6ae2b862e24256b"}], "s": {"y": 920, "x": 1516, "u": "https://preview.redd.it/lzdolsage6fa1.png?width=1516&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d6d9d842df5511ae416a056430090394fc05494e"}, "id": "lzdolsage6fa1"}, "j9g6pu7zd6fa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00449bbfcdf324eb1ae07353a4fb28c2d313068c"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d11a0f0b31d22a13ea5298bf0d078be7fb8b1f2"}, {"y": 110, "x": 320, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abc99e01b45443ca10239107446c95b8742535ea"}, {"y": 221, "x": 640, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed263b685b63716022435439e73af59ce8ed0025"}, {"y": 332, "x": 960, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81d40dca5cb7bed6cfab77b32f769789ec217d36"}, {"y": 373, "x": 1080, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06ead84edc467d61dc044d73ecb18c6df8674968"}], "s": {"y": 900, "x": 2600, "u": "https://preview.redd.it/j9g6pu7zd6fa1.png?width=2600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9e6a11496bbf0e1ca98f8865186ad9c014dafee1"}, "id": "j9g6pu7zd6fa1"}, "di7f6w6uf6fa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 137, "x": 108, "u": "https://preview.redd.it/di7f6w6uf6fa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d767ea00deaf87a319bc6f2e314d5451acc546cf"}, {"y": 275, "x": 216, "u": "https://preview.redd.it/di7f6w6uf6fa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf6b4b95e9910d0cfa37b7199efd1d4dcde22604"}, {"y": 408, "x": 320, "u": "https://preview.redd.it/di7f6w6uf6fa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1edfa197ced605f584c9f9eba7a0b41892de8722"}, {"y": 816, "x": 640, "u": "https://preview.redd.it/di7f6w6uf6fa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18691c809646322255639f9f539b1678aadfebef"}], "s": {"y": 865, "x": 678, "u": "https://preview.redd.it/di7f6w6uf6fa1.png?width=678&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d62369d4560b4db0191e0fde51b8f1b3dbc66290"}, "id": "di7f6w6uf6fa1"}}, "name": "t3_10p17i5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "This is one of my functions, and its approximation with the values (for the positive and negative values of z, as the function is not symmetrical). ", "media_id": "9g6w0okvd6fa1", "id": 235171681}, {"caption": "here is the 'b' value on the function. The function is ~ a* sin(x/b) * e^(d*cos(f*x/b)) ", "media_id": "j9g6pu7zd6fa1", "id": 235171682}, {"caption": "the 'b' value on the geometry. I have the g' value that I want to correlate with 'a' and 'd', and some other geometry dimensions  (thickness, for example)", "media_id": "lzdolsage6fa1", "id": 235171683}, {"caption": "the report that I get from the lmfit analysis.  ", "media_id": "di7f6w6uf6fa1", "id": 235171684}]}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M3QN75bMTyBCWfTqncHtMxy0DdHWS3iqysImOT81Fao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675083294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10p17i5", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "10p17i5", "is_robot_indexable": true, "report_reasons": null, "author": "WoOfnt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p17i5/determine_the_constant_values_of_a_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10p17i5", "subreddit_subscribers": 842873, "created_utc": 1675083294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\"  **The AI, called ProGen, works in a similar way to** [**AIs that can generate text**](https://www.newscientist.com/article/2353751-ai-chatbots-could-hit-a-ceiling-after-2026-as-training-data-runs-dry/)**. ProGen learned how to generate new proteins by learning the grammar of how amino acids combine to form 280 million existing proteins. Instead of the researchers choosing a topic for the AI to write about, they could specify a group of similar proteins for it to focus on. In this case, they chose a group of proteins with antimicrobial activity**. \"  \n\n\n[https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm\\_term=Autofeed&amp;utm\\_campaign=echobox&amp;utm\\_medium=social&amp;utm\\_source=Twitter#Echobox=1675041628](https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm_term=Autofeed&amp;utm_campaign=echobox&amp;utm_medium=social&amp;utm_source=Twitter#Echobox=1675041628)", "author_fullname": "t2_dmsa7ath", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI has designed bacteria-killing proteins from scratch \u2013 and they work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ouyyc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675060369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;  &lt;strong&gt;The AI, called ProGen, works in a similar way to&lt;/strong&gt; &lt;a href=\"https://www.newscientist.com/article/2353751-ai-chatbots-could-hit-a-ceiling-after-2026-as-training-data-runs-dry/\"&gt;&lt;strong&gt;AIs that can generate text&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;. ProGen learned how to generate new proteins by learning the grammar of how amino acids combine to form 280 million existing proteins. Instead of the researchers choosing a topic for the AI to write about, they could specify a group of similar proteins for it to focus on. In this case, they chose a group of proteins with antimicrobial activity&lt;/strong&gt;. &amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm_term=Autofeed&amp;amp;utm_campaign=echobox&amp;amp;utm_medium=social&amp;amp;utm_source=Twitter#Echobox=1675041628\"&gt;https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm_term=Autofeed&amp;amp;utm_campaign=echobox&amp;amp;utm_medium=social&amp;amp;utm_source=Twitter#Echobox=1675041628&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?auto=webp&amp;v=enabled&amp;s=f77eae709d25b80a65e1988ac40cbb88b373e7a0", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=842c3ecfa7124693515080e86bc3958a50b9629c", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f5c2125197631e94c5ae3ca8af88d1e635baef4", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea22e3e6fa197b48a1c7fd021b08991a3b820a22", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6d96ee0f0de8f1e033fbbf09b491d05e6880b30", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c299bf81d3ef27980279f424fe9de6d4afdd833c", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/bSWVXNUoUYy_tzRws8Cm3E8dfKoqsJMn7wZGBDHh15A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58235bea6dc7978263b14a427a1590dfdd423aef", "width": 1080, "height": 720}], "variants": {}, "id": "L7p7uMDtmogHilnzzcJg_JlA4scVWEuAJMU_VkJC1oE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ouyyc", "is_robot_indexable": true, "report_reasons": null, "author": "Vedarham29", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ouyyc/ai_has_designed_bacteriakilling_proteins_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ouyyc/ai_has_designed_bacteriakilling_proteins_from/", "subreddit_subscribers": 842873, "created_utc": 1675060369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a psychology student, but I've been working had at learning how to program in Java by myself. When I walked into the room of my psychology professor, a CS professor was there and introduced himself. My professor told him how into programming I am and I also explained to him what I've been learning. He mentioned a data science paid internship that I could apply for. He didn't say he wanted me to join or anything, just an offer.\n\nWhen I looked at the application, I barely meet any of the requirements to even be looked at as a possible candidate over other students who've actually been studying this for their degree. They ask about related data science classes and projects. They also ask how experienced you are in Python, SQL, and a free other languages, frameworks, and databases. It's still very early, should I apply now and say I have very little experience with these or try learn and get familiar with them so I can say I'm somewhat experienced with these?\n\nWhat way would give me the best chance at getting picked for the internship??", "author_fullname": "t2_7ptqclcn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instructor told me I could sign up for and internship but I'm unqualified", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oq2u0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675045324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a psychology student, but I&amp;#39;ve been working had at learning how to program in Java by myself. When I walked into the room of my psychology professor, a CS professor was there and introduced himself. My professor told him how into programming I am and I also explained to him what I&amp;#39;ve been learning. He mentioned a data science paid internship that I could apply for. He didn&amp;#39;t say he wanted me to join or anything, just an offer.&lt;/p&gt;\n\n&lt;p&gt;When I looked at the application, I barely meet any of the requirements to even be looked at as a possible candidate over other students who&amp;#39;ve actually been studying this for their degree. They ask about related data science classes and projects. They also ask how experienced you are in Python, SQL, and a free other languages, frameworks, and databases. It&amp;#39;s still very early, should I apply now and say I have very little experience with these or try learn and get familiar with them so I can say I&amp;#39;m somewhat experienced with these?&lt;/p&gt;\n\n&lt;p&gt;What way would give me the best chance at getting picked for the internship??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oq2u0", "is_robot_indexable": true, "report_reasons": null, "author": "-ItsCrazyOutHere-", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oq2u0/instructor_told_me_i_could_sign_up_for_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oq2u0/instructor_told_me_i_could_sign_up_for_and/", "subreddit_subscribers": 842873, "created_utc": 1675045324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was looking at Databricks because it integrates with AWS services like Kinesis, but it looks to me like SageMaker is a direct competitor to Databricks? We are heavily using AWS, is there any reason to add DataBricks into the stack or odes SageMaker fill the same role?   \n\n\nThank you :)", "author_fullname": "t2_nxg7gvj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference in usecases for AWS Sagemaker vs Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10onuzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675039279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking at Databricks because it integrates with AWS services like Kinesis, but it looks to me like SageMaker is a direct competitor to Databricks? We are heavily using AWS, is there any reason to add DataBricks into the stack or odes SageMaker fill the same role?   &lt;/p&gt;\n\n&lt;p&gt;Thank you :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10onuzz", "is_robot_indexable": true, "report_reasons": null, "author": "AdSecure5364", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10onuzz/difference_in_usecases_for_aws_sagemaker_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10onuzz/difference_in_usecases_for_aws_sagemaker_vs/", "subreddit_subscribers": 842873, "created_utc": 1675039279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The ResNet paper by Kaiming He et al. does not use dropout for the models. A lot of models prior to ResNets, such as AlexNet and VGGNet gained from using dropout.\n\nWhy did the authors choose not to use dropout for ResNets ? Is it because they use L2 regularization(weight decay) and batch normalization which are forms of regularization which can substitute dropout regularization ?", "author_fullname": "t2_atq1gig1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why did the original ResNet paper not use dropout?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ol900", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675032680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The ResNet paper by Kaiming He et al. does not use dropout for the models. A lot of models prior to ResNets, such as AlexNet and VGGNet gained from using dropout.&lt;/p&gt;\n\n&lt;p&gt;Why did the authors choose not to use dropout for ResNets ? Is it because they use L2 regularization(weight decay) and batch normalization which are forms of regularization which can substitute dropout regularization ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ol900", "is_robot_indexable": true, "report_reasons": null, "author": "V1bicycle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ol900/why_did_the_original_resnet_paper_not_use_dropout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ol900/why_did_the_original_resnet_paper_not_use_dropout/", "subreddit_subscribers": 842873, "created_utc": 1675032680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Inspired by r/cscareerquestions.\n\nThat post seems to be getting a lot of attention and helpful answers. Just trying to do the same for the DS community.", "author_fullname": "t2_bv171ji2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the most in demand skills of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ohsog", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675024459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Inspired by &lt;a href=\"/r/cscareerquestions\"&gt;r/cscareerquestions&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;That post seems to be getting a lot of attention and helpful answers. Just trying to do the same for the DS community.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ohsog", "is_robot_indexable": true, "report_reasons": null, "author": "quite--average", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ohsog/what_are_the_most_in_demand_skills_of_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ohsog/what_are_the_most_in_demand_skills_of_2023/", "subreddit_subscribers": 842873, "created_utc": 1675024459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi.\n\nI'm looking for an example of a good github repo that can be used in CV.  \nI have a lot of work that I'd like to showcase with out of the box thinking approaches that I have utilized before.\n\nIf somebody can please link me to a good github repo that they see is if high grade, please let me know.\n\nThank you.\n\nRegards.", "author_fullname": "t2_of5gy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can somebody please point me to a good github repo for DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10p2lqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675086356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for an example of a good github repo that can be used in CV.&lt;br/&gt;\nI have a lot of work that I&amp;#39;d like to showcase with out of the box thinking approaches that I have utilized before.&lt;/p&gt;\n\n&lt;p&gt;If somebody can please link me to a good github repo that they see is if high grade, please let me know.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n\n&lt;p&gt;Regards.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10p2lqt", "is_robot_indexable": true, "report_reasons": null, "author": "hajduken", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p2lqt/can_somebody_please_point_me_to_a_good_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10p2lqt/can_somebody_please_point_me_to_a_good_github/", "subreddit_subscribers": 842873, "created_utc": 1675086356.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi dear community, \n\nI'm a big data analytics student. \n\nworking on my end of studies project, it's about sentiment analysis on Facebook posts (Comments), comments usually are written in a local language ( Algerian Dialect) \n\nI want to know if there are some technics I should be using to train ML models on this dataset . \n\nYour help would mean a lot. \n\nI'm also open for any questions regarding this topic , let's exchange on this one .", "author_fullname": "t2_vc9ctogk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Natural Language Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10p2321", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675085333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi dear community, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a big data analytics student. &lt;/p&gt;\n\n&lt;p&gt;working on my end of studies project, it&amp;#39;s about sentiment analysis on Facebook posts (Comments), comments usually are written in a local language ( Algerian Dialect) &lt;/p&gt;\n\n&lt;p&gt;I want to know if there are some technics I should be using to train ML models on this dataset . &lt;/p&gt;\n\n&lt;p&gt;Your help would mean a lot. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also open for any questions regarding this topic , let&amp;#39;s exchange on this one .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10p2321", "is_robot_indexable": true, "report_reasons": null, "author": "ikbal_gambit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10p2321/local_natural_language_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10p2321/local_natural_language_processing/", "subreddit_subscribers": 842873, "created_utc": 1675085333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\nI am new to data analytics. \nAnd just got an internship. \n\nHave to update these google sheets everyday and was trying to automate it.\nIs there anyway i cab automatically update these sheets, that is new data gets added every 24hrs or less?\nThe things is, it needs to go through my email as the data is available through access only and I have the access..\n\nFor now, I download the data using a link into csv file everyday and upload it to the Gsheets.\n\nAny suggestions of help is very happily appreciated.?", "author_fullname": "t2_to2zerrm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GSheets automatic update.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ozcfa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675076806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am new to data analytics. \nAnd just got an internship. &lt;/p&gt;\n\n&lt;p&gt;Have to update these google sheets everyday and was trying to automate it.\nIs there anyway i cab automatically update these sheets, that is new data gets added every 24hrs or less?\nThe things is, it needs to go through my email as the data is available through access only and I have the access..&lt;/p&gt;\n\n&lt;p&gt;For now, I download the data using a link into csv file everyday and upload it to the Gsheets.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions of help is very happily appreciated.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ozcfa", "is_robot_indexable": true, "report_reasons": null, "author": "hear_to_laugh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ozcfa/gsheets_automatic_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ozcfa/gsheets_automatic_update/", "subreddit_subscribers": 842873, "created_utc": 1675076806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Keen to have an open discussion around clustering.\n1) Is HDBSCAN actually preferred over K-means in industry applications?\n2) How do you choose your features? There is several approaches: Principal Feature Analysis and looping through the features leaving one out at a time.\n\nCouple of useful links:\n1) Principal Feature Analysis: https://datascience.stackexchange.com/questions/67040/how-to-do-feature-selection-for-clustering-and-implement-it-in-python\n\nA paper on PFA: https://www.hindawi.com/journals/cmmm/2013/645921/", "author_fullname": "t2_vqwkfiup", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS especially in retail: which clustering method do you use? Is HDBSCAN always a better choice than K-means!? How do you select your features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10oz7rg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675076370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keen to have an open discussion around clustering.\n1) Is HDBSCAN actually preferred over K-means in industry applications?\n2) How do you choose your features? There is several approaches: Principal Feature Analysis and looping through the features leaving one out at a time.&lt;/p&gt;\n\n&lt;p&gt;Couple of useful links:\n1) Principal Feature Analysis: &lt;a href=\"https://datascience.stackexchange.com/questions/67040/how-to-do-feature-selection-for-clustering-and-implement-it-in-python\"&gt;https://datascience.stackexchange.com/questions/67040/how-to-do-feature-selection-for-clustering-and-implement-it-in-python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A paper on PFA: &lt;a href=\"https://www.hindawi.com/journals/cmmm/2013/645921/\"&gt;https://www.hindawi.com/journals/cmmm/2013/645921/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B5bQf2_c-6I4oChpo-ax66ErOTM-5H-22NiVGgZW21w.jpg?auto=webp&amp;v=enabled&amp;s=5cc1b6183b2291e0f03a665be334ee5285810894", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/B5bQf2_c-6I4oChpo-ax66ErOTM-5H-22NiVGgZW21w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25fd431e44dfb3ab59737026444d79975c7db3fd", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/B5bQf2_c-6I4oChpo-ax66ErOTM-5H-22NiVGgZW21w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=27df6c19694f07fcc8cf7ad2b22223fb28ee33e8", "width": 216, "height": 216}], "variants": {}, "id": "5np4J6mUzXYNu4qMlPrcnxOiqRs73wn9wB2s0b8TWkY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10oz7rg", "is_robot_indexable": true, "report_reasons": null, "author": "Living_Teaching9410", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10oz7rg/ds_especially_in_retail_which_clustering_method/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10oz7rg/ds_especially_in_retail_which_clustering_method/", "subreddit_subscribers": 842873, "created_utc": 1675076370.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data scientist, with MSc and PhD plus many years of work experiences in various work settings. I also have developed app using various framework, and have made side projects like trading bots. Other than python, I also know sql and some html, css, js, solidity. Should I use the term full stack DS on my CV, or is it not well know or pretentious per se?", "author_fullname": "t2_17d42esw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is full stack data scientist a term I should use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ov6om", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675061144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data scientist, with MSc and PhD plus many years of work experiences in various work settings. I also have developed app using various framework, and have made side projects like trading bots. Other than python, I also know sql and some html, css, js, solidity. Should I use the term full stack DS on my CV, or is it not well know or pretentious per se?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ov6om", "is_robot_indexable": true, "report_reasons": null, "author": "Guyserbun007", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ov6om/is_full_stack_data_scientist_a_term_i_should_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ov6om/is_full_stack_data_scientist_a_term_i_should_use/", "subreddit_subscribers": 842873, "created_utc": 1675061144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! \nI'm working on a project building multi class classifier. As a part of it I'm required to evaluate my machine learning model on different sets of test data. Consider each test data represents a different section/location. \n\nHowever, we want to present a single metric combining the results on all of these location through aggregation. The location specific test data can be of different size and different label distribution. Right now, we average the result obtained for each location. For example final result = average ( acc of location 1 + acc of loc 2 + acc of loc 3)\nAcc - accuracy. \n\nIs there any other way to reflect the dataset size and label distribution while combining results from multiple test data?", "author_fullname": "t2_hj73jijt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[D] Combining results from multiple test dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10onf98", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675038133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! \nI&amp;#39;m working on a project building multi class classifier. As a part of it I&amp;#39;m required to evaluate my machine learning model on different sets of test data. Consider each test data represents a different section/location. &lt;/p&gt;\n\n&lt;p&gt;However, we want to present a single metric combining the results on all of these location through aggregation. The location specific test data can be of different size and different label distribution. Right now, we average the result obtained for each location. For example final result = average ( acc of location 1 + acc of loc 2 + acc of loc 3)\nAcc - accuracy. &lt;/p&gt;\n\n&lt;p&gt;Is there any other way to reflect the dataset size and label distribution while combining results from multiple test data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10onf98", "is_robot_indexable": true, "report_reasons": null, "author": "channel-hopper-", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10onf98/d_combining_results_from_multiple_test_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10onf98/d_combining_results_from_multiple_test_dataset/", "subreddit_subscribers": 842873, "created_utc": 1675038133.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}