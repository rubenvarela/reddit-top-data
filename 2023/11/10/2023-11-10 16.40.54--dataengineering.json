{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Though I am a data engineer by trade, I am often find myself as the in-house de facto data analyst.\n\nMy own experience has been that I often use about an equal mix of SQL and Python to work on data analysis requests. But it\u2019s not set in stone. For quick requests, I usually go with SQL. For more complex ones, I will rely on Python and Jupyter notebooks.\n\nI am the only one in this situation? Do you go for SQL, Python (R?) or some other language?\n\nJust wondering. Thanks.", "author_fullname": "t2_8hos5mrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL versus Python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rpfn3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699570302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Though I am a data engineer by trade, I am often find myself as the in-house de facto data analyst.&lt;/p&gt;\n\n&lt;p&gt;My own experience has been that I often use about an equal mix of SQL and Python to work on data analysis requests. But it\u2019s not set in stone. For quick requests, I usually go with SQL. For more complex ones, I will rely on Python and Jupyter notebooks.&lt;/p&gt;\n\n&lt;p&gt;I am the only one in this situation? Do you go for SQL, Python (R?) or some other language?&lt;/p&gt;\n\n&lt;p&gt;Just wondering. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rpfn3", "is_robot_indexable": true, "report_reasons": null, "author": "BatCommercial7523", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rpfn3/sql_versus_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rpfn3/sql_versus_python/", "subreddit_subscribers": 138964, "created_utc": 1699570302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apache Iceberg co-founder Ryan Blue recently published [a post](https://tabular.io/blog/iceberg-hudi-acid-guarantees/) in which he made a case that \"Iceberg is reliable and Apache Hudi is not\". \n\nVinoth Chandar responded with his [own take](https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees) bringing receipts and demonstrated Iceberg's own set of problems.\n\nThere are a lot of technicalities in both posts, but the biggest focus is on ACID guarantees in both systems and the difference in approaches to fulfill them.\n\nPersonally I think that transaction guarantees aren't as important in modern data lakes (will be happy to see examples of the opposite). \n\nWho is more convincing in your opinion?  ", "author_fullname": "t2_ntpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg vs Hudi beef over ACID guarantees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rm18a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699561206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apache Iceberg co-founder Ryan Blue recently published &lt;a href=\"https://tabular.io/blog/iceberg-hudi-acid-guarantees/\"&gt;a post&lt;/a&gt; in which he made a case that &amp;quot;Iceberg is reliable and Apache Hudi is not&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;Vinoth Chandar responded with his &lt;a href=\"https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees\"&gt;own take&lt;/a&gt; bringing receipts and demonstrated Iceberg&amp;#39;s own set of problems.&lt;/p&gt;\n\n&lt;p&gt;There are a lot of technicalities in both posts, but the biggest focus is on ACID guarantees in both systems and the difference in approaches to fulfill them.&lt;/p&gt;\n\n&lt;p&gt;Personally I think that transaction guarantees aren&amp;#39;t as important in modern data lakes (will be happy to see examples of the opposite). &lt;/p&gt;\n\n&lt;p&gt;Who is more convincing in your opinion?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?auto=webp&amp;s=b755d01d8028b7816e27daac9da363452b503031", "width": 1461, "height": 995}, "resolutions": [{"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3570e62f22eefab1224d9f2cdf43e9e1def4d2dc", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1719655f5ef922b6f39c8f111ae35eb06f7448a", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=818f132476f9f5f66cbea96b5e4b202947df1102", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a328cf34aa67b94d5d871250161a73d2d2080efb", "width": 640, "height": 435}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=076014ca1167676c6cff73b5448acab4f6a95b7f", "width": 960, "height": 653}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=63331e9ddc9fe0af81c573e159bb192a34b3ccef", "width": 1080, "height": 735}], "variants": {}, "id": "E9d225te2hmOoFPeBhFoVU_8KtIwcxJK6c1pQ0OSsAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rm18a", "is_robot_indexable": true, "report_reasons": null, "author": "DCman1993", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rm18a/iceberg_vs_hudi_beef_over_acid_guarantees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rm18a/iceberg_vs_hudi_beef_over_acid_guarantees/", "subreddit_subscribers": 138964, "created_utc": 1699561206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All -- Curious to understand what industry, tech stack, business use case , and any other information you can provide on how your lakehouse is set up.\n\nI haven't moved away from using a DWH like Snowflake/BQ, data ingestion tools like airbyte, and data integration tools like Talend so the idea of doing ETL in a Lakehouse and setting it up seems foreign to me.\n\n&amp;#x200B;", "author_fullname": "t2_zhg21", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse Architectures - How does it look like for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ru5vh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699584068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All -- Curious to understand what industry, tech stack, business use case , and any other information you can provide on how your lakehouse is set up.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t moved away from using a DWH like Snowflake/BQ, data ingestion tools like airbyte, and data integration tools like Talend so the idea of doing ETL in a Lakehouse and setting it up seems foreign to me.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ru5vh", "is_robot_indexable": true, "report_reasons": null, "author": "studentofarkad", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ru5vh/lakehouse_architectures_how_does_it_look_like_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ru5vh/lakehouse_architectures_how_does_it_look_like_for/", "subreddit_subscribers": 138964, "created_utc": 1699584068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am seeking suggestions on how everyone is scheduling jobs(python files, bat files). Our scale is pretty small and windows scheduler works just fine. But I am exploring better options. I am not interested in airflow as it is a lot of effort and not required for the scale we operate in.", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job scheduling suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rs1x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699577683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am seeking suggestions on how everyone is scheduling jobs(python files, bat files). Our scale is pretty small and windows scheduler works just fine. But I am exploring better options. I am not interested in airflow as it is a lot of effort and not required for the scale we operate in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rs1x1", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rs1x1/job_scheduling_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rs1x1/job_scheduling_suggestions/", "subreddit_subscribers": 138964, "created_utc": 1699577683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am no beginner, but I am not fully independent yet either. On my project, we have a tech lead who writes powerful, but confusing code. There are no comments. It's like a labyrinth. He sometimes changes things without communicating it. He communicates some things long before they become relevant, and then he gets angry, when I don't remember that particular sentence from weeks ago, which explains that one specific problem I ran into today.     ", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you deal with a tech lead that doesn't communicate, doesn't comment, but expects you to understand their code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rzyiy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699606374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am no beginner, but I am not fully independent yet either. On my project, we have a tech lead who writes powerful, but confusing code. There are no comments. It&amp;#39;s like a labyrinth. He sometimes changes things without communicating it. He communicates some things long before they become relevant, and then he gets angry, when I don&amp;#39;t remember that particular sentence from weeks ago, which explains that one specific problem I ran into today.     &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17rzyiy", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rzyiy/how_would_you_deal_with_a_tech_lead_that_doesnt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rzyiy/how_would_you_deal_with_a_tech_lead_that_doesnt/", "subreddit_subscribers": 138964, "created_utc": 1699606374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark vs Polars. Real-life Test Case.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_17rgqew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kkp2IHV-d9K4qxCreRUBHRMpxDbQja8zm2uy4ir_t9s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699547114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/spark-vs-polars-real-life-test-case", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?auto=webp&amp;s=05070bacd4a0da79f6046605095ac21e2a412110", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dcefe80c15cbc886d27599c0d78b64bb3437c76", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9da237db45150d1845251e30e77574111f522029", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2722ebccff0065a23e3f25cf6ee802a5d24d1780", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eaca7ec4ba648c9e2c0bc16c7609e8673d3ad1a7", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bdecdac1c48e05a76f952f3436505bad61c4ac38", "width": 960, "height": 562}], "variants": {}, "id": "Q-RjjX_SqLLA22Omd29gCQitPbQgOOnRbDnPdTf_vuk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rgqew", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rgqew/spark_vs_polars_reallife_test_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/spark-vs-polars-real-life-test-case", "subreddit_subscribers": 138964, "created_utc": 1699547114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is moving all of our remaining ingestion from Databricks to Snowflake. We are debating whether to use DBT Incremental models or Snowflake Tasks and Streams.   \nWe currently use Databricks notebooks for ingestion then materialise in Snowflake.\n\nOur main concerns are about maintainability and the ability to recover from anomalies. Really interested in taking advice from anyone who has experience.", "author_fullname": "t2_sl8u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Ingestion using Tasks and Streams VS Airflow and DBT Incremental Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17s3qpg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699621988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is moving all of our remaining ingestion from Databricks to Snowflake. We are debating whether to use DBT Incremental models or Snowflake Tasks and Streams.&lt;br/&gt;\nWe currently use Databricks notebooks for ingestion then materialise in Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Our main concerns are about maintainability and the ability to recover from anomalies. Really interested in taking advice from anyone who has experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17s3qpg", "is_robot_indexable": true, "report_reasons": null, "author": "kali042", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s3qpg/snowflake_ingestion_using_tasks_and_streams_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s3qpg/snowflake_ingestion_using_tasks_and_streams_vs/", "subreddit_subscribers": 138964, "created_utc": 1699621988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI\u2019ve been thinking a lot lately with different data warehousing projects I\u2019ve worked on, and have frequently come back to the idea that it feels like the current warehousing approach of syncing a source database, applying business logic to source data, then loading it to dimension and fact tables feels\u2026 wrong. As software engineers, what we are inherently doing is creating strong coupling between the data source and our system\u2019s representation of data, THEN also duplicating every single piece of relevant business logic the source application defines.\n\nI\u2019d love to have a discussion on the thought of having source applications publish domain events specifically for data warehouse consumption (they\u2019re a monolithic architecture). The problems that I see with this approach aren\u2019t particularly around an internal application / data source, but the 3rd party source that allows database access to a read replica but won\u2019t change their application logic for us. Can anyone think of any other organizational or architectural reasons why you wouldn\u2019t want to move to this approach?\n\nThe reason this has been top of mind has been that a mobile client was the primary data source for a previous warehousing project, where every notable action / user journey was captured as an event and series of events. That was, by far, the most successful data project I\u2019ve been a part of, and I\u2019ve been trying to deconstruct the reasons why it was so successful. I primarily see it as a result of a strong separation of concerns across systems and the developers of the data source being forced to think about how they represent data during the development cycle, but would love to get others thoughts.", "author_fullname": "t2_9zvt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event Based Data Warehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rmv0b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699563510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been thinking a lot lately with different data warehousing projects I\u2019ve worked on, and have frequently come back to the idea that it feels like the current warehousing approach of syncing a source database, applying business logic to source data, then loading it to dimension and fact tables feels\u2026 wrong. As software engineers, what we are inherently doing is creating strong coupling between the data source and our system\u2019s representation of data, THEN also duplicating every single piece of relevant business logic the source application defines.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to have a discussion on the thought of having source applications publish domain events specifically for data warehouse consumption (they\u2019re a monolithic architecture). The problems that I see with this approach aren\u2019t particularly around an internal application / data source, but the 3rd party source that allows database access to a read replica but won\u2019t change their application logic for us. Can anyone think of any other organizational or architectural reasons why you wouldn\u2019t want to move to this approach?&lt;/p&gt;\n\n&lt;p&gt;The reason this has been top of mind has been that a mobile client was the primary data source for a previous warehousing project, where every notable action / user journey was captured as an event and series of events. That was, by far, the most successful data project I\u2019ve been a part of, and I\u2019ve been trying to deconstruct the reasons why it was so successful. I primarily see it as a result of a strong separation of concerns across systems and the developers of the data source being forced to think about how they represent data during the development cycle, but would love to get others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rmv0b", "is_robot_indexable": true, "report_reasons": null, "author": "alexisprince", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rmv0b/event_based_data_warehousing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rmv0b/event_based_data_warehousing/", "subreddit_subscribers": 138964, "created_utc": 1699563510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Three years ago - I made a benchmark of the data catalog landscape. The market has evolved so much that I decided to update it. \n\nDo you feel like any feature/tool is missing? I'm trying to make this resource as accurate as possible so if you have suggestions - don't hesitate to shoot them my way. \n\nFull benchmark here: [https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0](https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0)\n\n&amp;#x200B;\n\n[Full benchmark](https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;format=png&amp;auto=webp&amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4)", "author_fullname": "t2_9blh4yzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data Catalog tools benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fkk9xfs30ezb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac41babea0a10264514231f929a806294477aff"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=914212ea847e3de776133ab1ff84ab447e14581f"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f223c3c14eda9e720c886392a10086901ce15112"}, {"y": 356, "x": 640, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9b480c52a69c49b1fbc03dde4bb1cec8de184f2"}, {"y": 535, "x": 960, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d7aa2ded635f5af05fc433a3723af77300f9acbf"}, {"y": 601, "x": 1080, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeeb142f21772b252f69fc0b33bac122436bad36"}], "s": {"y": 1342, "x": 2408, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;format=png&amp;auto=webp&amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4"}, "id": "fkk9xfs30ezb1"}}, "name": "t3_17rn2mn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aVVB55qsUCH-TIHHq_7dO0tJhNbhz7MAc159Ecii_dA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1699564076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Three years ago - I made a benchmark of the data catalog landscape. The market has evolved so much that I decided to update it. &lt;/p&gt;\n\n&lt;p&gt;Do you feel like any feature/tool is missing? I&amp;#39;m trying to make this resource as accurate as possible so if you have suggestions - don&amp;#39;t hesitate to shoot them my way. &lt;/p&gt;\n\n&lt;p&gt;Full benchmark here: &lt;a href=\"https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0\"&gt;https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4\"&gt;Full benchmark&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?auto=webp&amp;s=874e1ed6dc2a7b4597c3433ddc627667e3c784a4", "width": 2000, "height": 533}, "resolutions": [{"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8739deea072d2eeef24f483c36e0daf1f28a5fec", "width": 108, "height": 28}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cde91b7f4bc2affd28d0df5216cf38dc2d196e2", "width": 216, "height": 57}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0bc14863c466929cb3844107eb321aab8829fc3", "width": 320, "height": 85}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a11bee81df46bf65d6b402c7c55cfcb4887ce1e", "width": 640, "height": 170}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87dc926d373fb50e35ecf0d303ffdb10b44b8db2", "width": 960, "height": 255}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=25101900e35ac2d38d0d1340f33a8255881ad6da", "width": 1080, "height": 287}], "variants": {}, "id": "coOYg5Xd4CLO-xHaYB_9pwauwVHF8Mte1l6ZoFyD3eA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rn2mn", "is_robot_indexable": true, "report_reasons": null, "author": "Strict_Algae3766", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rn2mn/data_catalog_tools_benchmark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rn2mn/data_catalog_tools_benchmark/", "subreddit_subscribers": 138964, "created_utc": 1699564076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Powering the Shift Left movement: Git-based systems as a catalyst for democratized data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17rlhuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ztA62vk0iHwC9KGEWZLzl1zuALJkN2-2Kb-Zfeb4KpY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699559722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/analytics-engineering-data-democratization/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?auto=webp&amp;s=cc4a14c9b4751d940ec160c32779c4715cc5a2f7", "width": 1456, "height": 816}, "resolutions": [{"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69b7c4d5855b32c128d0e635059a053dc2080357", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c2f5b7f0c69655c49e2e0bc6cd4935abb87f102", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2f157423200a9ff8391c14e523df87facb03b3f", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=70ed293048deaa7535ae966a39b9d73a6eadf65e", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=74658f8119d8671c9e1fe1074804af1e7908e1f3", "width": 960, "height": 538}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c71f4efed5e3e4c44de939a814805471730ab362", "width": 1080, "height": 605}], "variants": {}, "id": "JGSou7MMFeVJk4xEFHlT_ziXQH7NzKiDwRJsFZMgJgI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rlhuz", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rlhuz/powering_the_shift_left_movement_gitbased_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/analytics-engineering-data-democratization/", "subreddit_subscribers": 138964, "created_utc": 1699559722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am new to Airflow and I have a question. We have an existing DAG(a&gt;b&gt;c&gt;d&gt;e&gt;f) consisting of Glue jobs(the Glue jobs have date as their input), that processes data for a given date and writes it to an S3 bucket with the partition dataset\\_date=$date. The team has asked me to create a backfill DAG that is different from the original DAG in two ways:\n\n1. The task sequence will be different:Original DAG: a&gt;b&gt;c&gt;d&gt;e&gt;fBackfill DAG: a&gt;b&gt;c&gt;d\n2. The backfill DAG will have two date parameters, start\\_dateand end\\_date, instead of one. The DAG needs to run individually for all dates in the specified range.\n\nHere are my specific questions:\n\n1. Is there a better way to create the backfill DAG than copying and pasting the code from the original DAG and removing the last two steps?\n2. How do I add the start\\_dateand end\\_dateparameters to the backfill DAG and make it run individually for all dates in the specified range?\n\nThanks in advance for your help!", "author_fullname": "t2_43bvcl6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Airflow: How to create a backfill DAG with a different task sequence and start/end date parameters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ro2oo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699566939.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699566691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am new to Airflow and I have a question. We have an existing DAG(a&amp;gt;b&amp;gt;c&amp;gt;d&amp;gt;e&amp;gt;f) consisting of Glue jobs(the Glue jobs have date as their input), that processes data for a given date and writes it to an S3 bucket with the partition dataset_date=$date. The team has asked me to create a backfill DAG that is different from the original DAG in two ways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The task sequence will be different:Original DAG: a&amp;gt;b&amp;gt;c&amp;gt;d&amp;gt;e&amp;gt;fBackfill DAG: a&amp;gt;b&amp;gt;c&amp;gt;d&lt;/li&gt;\n&lt;li&gt;The backfill DAG will have two date parameters, start_dateand end_date, instead of one. The DAG needs to run individually for all dates in the specified range.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here are my specific questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a better way to create the backfill DAG than copying and pasting the code from the original DAG and removing the last two steps?&lt;/li&gt;\n&lt;li&gt;How do I add the start_dateand end_dateparameters to the backfill DAG and make it run individually for all dates in the specified range?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ro2oo", "is_robot_indexable": true, "report_reasons": null, "author": "therobot20", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ro2oo/new_to_airflow_how_to_create_a_backfill_dag_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ro2oo/new_to_airflow_how_to_create_a_backfill_dag_with/", "subreddit_subscribers": 138964, "created_utc": 1699566691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I got a lot of great engagement from here on a prior article of mine \"Graduating from ETL Developer to Data Engineer.\" So I thought I'd share my latest because I suspect it will be controversial for this audience. I'm really interested in your perspective, do you \"develop in prod?\" What really is \"prod\" anyway? Thanks for any feedback.\n\n[https://medium.com/@ericmccarty/the-data-engineering-case-for-developing-in-prod-6f0fb3a2eeee](https://medium.com/@ericmccarty/the-data-engineering-case-for-developing-in-prod-6f0fb3a2eeee)", "author_fullname": "t2_enu2a2uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Engineering Case for Developing in Prod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17s5j6k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699627645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I got a lot of great engagement from here on a prior article of mine &amp;quot;Graduating from ETL Developer to Data Engineer.&amp;quot; So I thought I&amp;#39;d share my latest because I suspect it will be controversial for this audience. I&amp;#39;m really interested in your perspective, do you &amp;quot;develop in prod?&amp;quot; What really is &amp;quot;prod&amp;quot; anyway? Thanks for any feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@ericmccarty/the-data-engineering-case-for-developing-in-prod-6f0fb3a2eeee\"&gt;https://medium.com/@ericmccarty/the-data-engineering-case-for-developing-in-prod-6f0fb3a2eeee&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?auto=webp&amp;s=8c8b1e8bd0aa936cf58bb389d1062cf107b6a645", "width": 1200, "height": 797}, "resolutions": [{"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=85ae90aacec5cb08f8357c9188629536212ea6ec", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=90a3c9b50b22d790df4bd6fc763a7893d39ba372", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff31d64bc8abe1415a3d98d314076f5d68a1d551", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5863c6ed335abcf4e55099599c5e4723ae897206", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23117a90820f9961a4584c1ca7672078e3b4f2dd", "width": 960, "height": 637}, {"url": "https://external-preview.redd.it/7EzItAuGlKxB0FtHqGyE_VkrucPAolRonto8O62XPIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0cbdee15fc51df770e7251377215b6455c4943d7", "width": 1080, "height": 717}], "variants": {}, "id": "R8qHWYfIrPpp1STtRm_G5vEkHRF48SJpMkERzVHMaAU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17s5j6k", "is_robot_indexable": true, "report_reasons": null, "author": "jemccarty", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s5j6k/the_data_engineering_case_for_developing_in_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s5j6k/the_data_engineering_case_for_developing_in_prod/", "subreddit_subscribers": 138964, "created_utc": 1699627645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\nI'm trying to apply python code on a table stored in AWS. My approach was to query the whole table through Athena in an EC2 instance and store it in a dataframe and apply the python code there. However, this request is taking a long time and was wondering if there was a way to cut down the time or a different approach. For reference, the table is around \\~160 GB.", "author_fullname": "t2_mtcyhvalq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying Python Code to Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rur6k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699585904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to apply python code on a table stored in AWS. My approach was to query the whole table through Athena in an EC2 instance and store it in a dataframe and apply the python code there. However, this request is taking a long time and was wondering if there was a way to cut down the time or a different approach. For reference, the table is around ~160 GB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17rur6k", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed_Brick_7982", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rur6k/applying_python_code_to_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rur6k/applying_python_code_to_big_data/", "subreddit_subscribers": 138964, "created_utc": 1699585904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello dataengineers. I have been working with banking customers for the past 15 years. My roles were predominantly on the lines of Data Analyst and Data Engineer. \n\nI am now in the UK working due a big bank and see a lot of demand for Data engineers in big retail chains like M&amp;S, Sainsbury's etc., So am checking here with people who work in similar domains, do you think it's worth it to shift from banking to retail domain?\n\nTo be a good data engineer for a large bank, it's necessary to know basic banking concepts and understand the data within. Plus you are working as a specialist that other banks would prefer to work with. Is there any such specific domain knowledge required to work in retail domain?", "author_fullname": "t2_5tl1q2i9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working in Bank Vs Retail chain", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17s725j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699631929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello dataengineers. I have been working with banking customers for the past 15 years. My roles were predominantly on the lines of Data Analyst and Data Engineer. &lt;/p&gt;\n\n&lt;p&gt;I am now in the UK working due a big bank and see a lot of demand for Data engineers in big retail chains like M&amp;amp;S, Sainsbury&amp;#39;s etc., So am checking here with people who work in similar domains, do you think it&amp;#39;s worth it to shift from banking to retail domain?&lt;/p&gt;\n\n&lt;p&gt;To be a good data engineer for a large bank, it&amp;#39;s necessary to know basic banking concepts and understand the data within. Plus you are working as a specialist that other banks would prefer to work with. Is there any such specific domain knowledge required to work in retail domain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17s725j", "is_robot_indexable": true, "report_reasons": null, "author": "vaasagan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s725j/working_in_bank_vs_retail_chain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s725j/working_in_bank_vs_retail_chain/", "subreddit_subscribers": 138964, "created_utc": 1699631929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really love the idea of Trino and what it's trying to do, but it's always marketed as a federated query service, not a data warehouse. Is using Trino as a pure DWH still a good idea, and does it stack up against other similar services like Databricks, as far as creating a lakehouse on top of your data lake?\n\nI'm thinking dbt + Trino would be one of the more powerful combos in the DE space, but I rarely see it talked about.", "author_fullname": "t2_thw4nqfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are people still using Trino to query their data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17s6f2f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699630188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really love the idea of Trino and what it&amp;#39;s trying to do, but it&amp;#39;s always marketed as a federated query service, not a data warehouse. Is using Trino as a pure DWH still a good idea, and does it stack up against other similar services like Databricks, as far as creating a lakehouse on top of your data lake?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking dbt + Trino would be one of the more powerful combos in the DE space, but I rarely see it talked about.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17s6f2f", "is_robot_indexable": true, "report_reasons": null, "author": "BoofThatShit720", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s6f2f/are_people_still_using_trino_to_query_their_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s6f2f/are_people_still_using_trino_to_query_their_data/", "subreddit_subscribers": 138964, "created_utc": 1699630188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sharing this as I have been struggling to find good resources on \"Top 10 data catalogs\" without too much bullshit. A company called CastorDoc release it last week. It has its own biais but overall really comprehensive &amp; reliable.  \n\n\nLink to [full data catalog market analysis](https://www.castordoc.com/blog/data-catalog-benchmark)  \nLink to [data catalog tools list &amp; benchmark](https://notion.castordoc.com/catalog-of-catalogs)\n\n  \n", "author_fullname": "t2_d630taql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17s5g05", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699627373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing this as I have been struggling to find good resources on &amp;quot;Top 10 data catalogs&amp;quot; without too much bullshit. A company called CastorDoc release it last week. It has its own biais but overall really comprehensive &amp;amp; reliable.  &lt;/p&gt;\n\n&lt;p&gt;Link to &lt;a href=\"https://www.castordoc.com/blog/data-catalog-benchmark\"&gt;full data catalog market analysis&lt;/a&gt;&lt;br/&gt;\nLink to &lt;a href=\"https://notion.castordoc.com/catalog-of-catalogs\"&gt;data catalog tools list &amp;amp; benchmark&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?auto=webp&amp;s=762f3f1d254ff632065e7c9662b9b54f170cd928", "width": 1320, "height": 622}, "resolutions": [{"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b105e52969b8773c553fdfaea727d2bc446b296", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0e08f63e73fb2d5fcb505aacff0b3d239889cb8e", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=09455a5c7ab8390ab2e9ddc5f324864c04bf9caf", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=14733a430edbd3f4b52f388769f19e42066f4a2b", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fb10862e1a434497118a4db7898934dcaf3abcf2", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/BFW2SkK7v7pF2fMoI0rfb7gmPTSwqrrlK0xOjSNeikM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99248faca027097e4cf44e4e8dbd8182e51a7cd9", "width": 1080, "height": 508}], "variants": {}, "id": "Q0yWqQYPgnv0U4CAkiGinZH4rooO-9TwdnuAF3ZC3ZU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17s5g05", "is_robot_indexable": true, "report_reasons": null, "author": "unsupervised_cluster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s5g05/data_catalog_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s5g05/data_catalog_tools/", "subreddit_subscribers": 138964, "created_utc": 1699627373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I haven\u2019t seen much on this in terms of structure or mock interviews so wanted to ask if anyone is up for few data pipeline/architecture mock design interviews over the next week?", "author_fullname": "t2_bl8sgwf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mock interviews for data architectures and data pipeline design rounds (mid level)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rzs4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699605541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I haven\u2019t seen much on this in terms of structure or mock interviews so wanted to ask if anyone is up for few data pipeline/architecture mock design interviews over the next week?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17rzs4x", "is_robot_indexable": true, "report_reasons": null, "author": "No-Candidate-5449", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rzs4x/mock_interviews_for_data_architectures_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rzs4x/mock_interviews_for_data_architectures_and_data/", "subreddit_subscribers": 138964, "created_utc": 1699605541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do DEs need to specialize in order to become a lead / principal?   \nThere is SO much evolution in methodology, tooling, and with AI in the mix, it seems like there is more to learn than one could keep up with while holding a full-time job 9-5 and not obsessing over work during their \"personal time\"\n\nContrast to when I was a lead BI engineer who was comfortable taking on any opening with that title.  \n", "author_fullname": "t2_dxmxxpnb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lead / Principal expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rufpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699584935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do DEs need to specialize in order to become a lead / principal?&lt;br/&gt;\nThere is SO much evolution in methodology, tooling, and with AI in the mix, it seems like there is more to learn than one could keep up with while holding a full-time job 9-5 and not obsessing over work during their &amp;quot;personal time&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Contrast to when I was a lead BI engineer who was comfortable taking on any opening with that title.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rufpq", "is_robot_indexable": true, "report_reasons": null, "author": "NotAfraidToAsk_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rufpq/lead_principal_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rufpq/lead_principal_expectations/", "subreddit_subscribers": 138964, "created_utc": 1699584935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,   \nI was recently asked in an interview to go over an example of an architecture decision/design choice or tradeoffs I made while building a data pipeline and wasn't able to think of anything.   \n\n\nI am reaching out to the community to see if anyone can share their experiences about this so that I can learn and gain knowledge. Thank you ", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trade-offs while building a pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rrocs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699576588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;br/&gt;\nI was recently asked in an interview to go over an example of an architecture decision/design choice or tradeoffs I made while building a data pipeline and wasn&amp;#39;t able to think of anything.   &lt;/p&gt;\n\n&lt;p&gt;I am reaching out to the community to see if anyone can share their experiences about this so that I can learn and gain knowledge. Thank you &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17rrocs", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17rrocs/tradeoffs_while_building_a_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rrocs/tradeoffs_while_building_a_pipeline/", "subreddit_subscribers": 138964, "created_utc": 1699576588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am looking for some advice on whether I am missing something simple. I want to add a dataframe as a new table into a database (say IBM or SQL Server) using Python. Do I need to create a blank table and define all the fields first or is there a way I can transfer the schema of my dataframe directly to a table?\n\nThank you in advance!", "author_fullname": "t2_lr9zwi4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ro6jg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699566975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am looking for some advice on whether I am missing something simple. I want to add a dataframe as a new table into a database (say IBM or SQL Server) using Python. Do I need to create a blank table and define all the fields first or is there a way I can transfer the schema of my dataframe directly to a table?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ro6jg", "is_robot_indexable": true, "report_reasons": null, "author": "dphigravity", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ro6jg/newbie_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ro6jg/newbie_help/", "subreddit_subscribers": 138964, "created_utc": 1699566975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a final round interview with the hiring manager for a data engineer intern position. I\u2019m not sure what kind of question I should have prepared to ask them during the interview. Does anyone have any suggestions or advice about what to ask.", "author_fullname": "t2_3xmv0yu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions to ask hiring manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rky00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699558262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a final round interview with the hiring manager for a data engineer intern position. I\u2019m not sure what kind of question I should have prepared to ask them during the interview. Does anyone have any suggestions or advice about what to ask.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17rky00", "is_robot_indexable": true, "report_reasons": null, "author": "ChubbyFruit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rky00/questions_to_ask_hiring_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rky00/questions_to_ask_hiring_manager/", "subreddit_subscribers": 138964, "created_utc": 1699558262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is doing just some very rudimentary stuff with langchain, and I feel that we can definitely improve on that to get more relevant info.", "author_fullname": "t2_nllj02sel", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your tricks for better RAG?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17s20qd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699615777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is doing just some very rudimentary stuff with langchain, and I feel that we can definitely improve on that to get more relevant info.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17s20qd", "is_robot_indexable": true, "report_reasons": null, "author": "istinetz_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17s20qd/what_are_your_tricks_for_better_rag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17s20qd/what_are_your_tricks_for_better_rag/", "subreddit_subscribers": 138964, "created_utc": 1699615777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the big takeaway from all this?  Seems like things are heating up between these two formats. \n\n[https://tabular.io/blog/iceberg-hudi-acid-guarantees/](https://tabular.io/blog/iceberg-hudi-acid-guarantees/)\n\n2 days later\u2026.\n\n[https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees](https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees)", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg vs Hudi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rl6j7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699558891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the big takeaway from all this?  Seems like things are heating up between these two formats. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://tabular.io/blog/iceberg-hudi-acid-guarantees/\"&gt;https://tabular.io/blog/iceberg-hudi-acid-guarantees/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;2 days later\u2026.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees\"&gt;https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?auto=webp&amp;s=b755d01d8028b7816e27daac9da363452b503031", "width": 1461, "height": 995}, "resolutions": [{"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3570e62f22eefab1224d9f2cdf43e9e1def4d2dc", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1719655f5ef922b6f39c8f111ae35eb06f7448a", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=818f132476f9f5f66cbea96b5e4b202947df1102", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a328cf34aa67b94d5d871250161a73d2d2080efb", "width": 640, "height": 435}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=076014ca1167676c6cff73b5448acab4f6a95b7f", "width": 960, "height": 653}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=63331e9ddc9fe0af81c573e159bb192a34b3ccef", "width": 1080, "height": 735}], "variants": {}, "id": "E9d225te2hmOoFPeBhFoVU_8KtIwcxJK6c1pQ0OSsAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rl6j7", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rl6j7/iceberg_vs_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rl6j7/iceberg_vs_hudi/", "subreddit_subscribers": 138964, "created_utc": 1699558891.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}