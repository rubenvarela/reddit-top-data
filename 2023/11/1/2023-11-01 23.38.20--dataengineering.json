{"kind": "Listing", "data": {"after": "t3_17lhumb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For 25 years, I never fired anyone.  And yet, this is the third guy I've fired in the last 18 months.  Granted, I wasn't the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made *zero* effort to integrate into the organisation.\n\nAre we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don't need to make any kind of effort anymore?  Do they think they can just \"wing it\"?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?\n\nI feel like shit, because as much as this guy only has himself to blame, I'm still turfing him out in November, in a shitty, shitty job market.", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So I had to fire a guy today...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l0elt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698800401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For 25 years, I never fired anyone.  And yet, this is the third guy I&amp;#39;ve fired in the last 18 months.  Granted, I wasn&amp;#39;t the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made &lt;em&gt;zero&lt;/em&gt; effort to integrate into the organisation.&lt;/p&gt;\n\n&lt;p&gt;Are we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don&amp;#39;t need to make any kind of effort anymore?  Do they think they can just &amp;quot;wing it&amp;quot;?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?&lt;/p&gt;\n\n&lt;p&gt;I feel like shit, because as much as this guy only has himself to blame, I&amp;#39;m still turfing him out in November, in a shitty, shitty job market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l0elt", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "subreddit_subscribers": 137387, "created_utc": 1698800401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.", "author_fullname": "t2_ymrlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do organisations use abbreviations for table and field names that don't save much space and reduce clarity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l1crr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698803337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l1crr", "is_robot_indexable": true, "report_reasons": null, "author": "NightflowerFade", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "subreddit_subscribers": 137387, "created_utc": 1698803337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks, I'm on a team of \"full-stack\" analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp; analysis.\n\nWe don't have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We've had to constantly  push our infrastructure and modelling projects month after month because there's a constant influx of request from stakeholders.\n\nIs this a problem for you guys? What are you doing to address it?", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how many analytics engineers here work on ad-hoc SQL requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfb8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698854219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks, I&amp;#39;m on a team of &amp;quot;full-stack&amp;quot; analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp;amp; analysis.&lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We&amp;#39;ve had to constantly  push our infrastructure and modelling projects month after month because there&amp;#39;s a constant influx of request from stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Is this a problem for you guys? What are you doing to address it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfb8v", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "subreddit_subscribers": 137387, "created_utc": 1698854219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nIn my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.\n\nWe don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. \n\nI\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? \n\ni turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.\n\nThank you in advance :)", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8eu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;In my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.&lt;/p&gt;\n\n&lt;p&gt;We don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? &lt;/p&gt;\n\n&lt;p&gt;i turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l8eu6", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "subreddit_subscribers": 137387, "created_utc": 1698831740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was just hired as a data engineer but my boss won't let me automate or develop anything.  I feel like my hands are tied, and even when I come up with great and logical solutions that should be compliant, my ideas are shot down.\n\nDid anyone else ever work for a company like this?  I worked with other companies with very strict by-the-book protocols and PHI, but nothing like this.  I feel like my boss won't give approval for anything because she's not tech-savvy and doesn't understand, and even when I take the time to explain things to her, she still never agrees or approves anything.\n\n&amp;#x200B;\n\n**My boss won't let me:**\n\n* Create automated processes using Python because \"it uses a username and password to connect to SQL Server and we're only allowed to use Windows Authentication\" (even though everyone uses Windows Authentication with SSMS and other applications every day.)\n* Then I switch to Selenium in Python as an alternative which doesn't use any credentials but am not allowed to use it because it \"needs to run from a different server and not my VPN\" but we don't have a server to run it on.\n* Not allowed to use Windows Authentication with Visual Studio within SSIS because \"the data contains PHI\" (even though everyone accesses PHI all day every day and saves it to their VPN's PC).\n* Before I started, no one maintained our prod server and doesn't have the correct data anymore, so we're not allowed to use it.  Instead, we must use our test server as prod.\n* Not allowed to backup our test server and restore to prod so we can actually use prod again because \"we need to wait until next year to make sure that the numbers are correct.\"\n* Not allowed to compare data from our test server to prod and make the changes manually for the same reason.\n* Not allowed to use SSIS to develop or test packages because \"we haven't done that in years\". (even though I can see in the pipeline that SSIS packages were deployed in last year.)\n* Not allowed to backup our test server and restore it to dev because \"that creates a backup of the data that contains PHI\". (our current dev server is not in use)  I asked the same question last month and was told that we couldn't do that because \"I don't know if we have enough space\" (our current dev sever is empty LOL)\n* Not allowed to create a new database on dev with EMPTY tables and no PHI to do SSIS development work because \"we have never done that in the past.\"\n* Not allowed to do any development work because \"our previous employee did all development work on our test server\" (our test server is now our ONLY server that we're allowed to use)\n\nThings I can do as a data engineer:\n\n* Run a query manually in SSMS, copy the data, paste it into Excel, and email the Excel file.\n* Develop read-only t-sql queries and run in SSMS.\n* Go to our SSRS server's website, manually choose all of the filters, wait for the report to load 2 times, wait for the report to download, rename the Excel report, and email the report.\n\n&amp;#x200B;\n\nI can automate our entire process in a week and it would then automatically complete each month instead of spending 60 hours manually doing the process.  Our SSIS project broke each month over the last 3 months but I can't even get permission to troubleshoot it within Visual Studio.  Right now, all of our important reports are past due without any solution in sight except for the many solutions that I pitched to get everything fixed, but she won't approve anything, yet she told us that we \"need to be more proactive\".\n\nDuring my first month there, modifying an Excel report that I personally used to use parameters to create links using Excel formulas to automatically download SSRS reports took a week to get approval across many heated conversations and she made me meet with others to get their approval as well.  I already created the Excel report and she saw it when I was sharing my screen, and then I wasn't allowed to use it for a week+ until everyone approved it.\n\nEDIT:  Thanks everyone for talking it through! It helped me figure out what to do. First, I'm going to continue to self-study to learn Spark and SSAS to further my career.  Then I'm going to use the company's existing SSAS, spark, devops, and pipelines to get better at these skills while kind of ignoring the other half of the sinking ship.  Then will finish up the SQL Server to cloud migration project by the 6 month mark. In the meantime, I'm going to take the bullet point list above, clean it up a bit, and review it during a meeting with my boss and a few IT and security folks. This should help my boss understand that all of this work can be done and can be compliant at the same time. To try to get her to allow me to restore a copy of test to the Dev and prod servers, I think I'll pull a couple of million records that don't match in both test and prod and tell her that someone would have to manually update all of these records individually unless she let's me click the button to restore the databases and make everything correct.", "author_fullname": "t2_ipzgsi9u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Boss Won't Let me Automate or Develop Anything as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17llxya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698880254.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698871898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just hired as a data engineer but my boss won&amp;#39;t let me automate or develop anything.  I feel like my hands are tied, and even when I come up with great and logical solutions that should be compliant, my ideas are shot down.&lt;/p&gt;\n\n&lt;p&gt;Did anyone else ever work for a company like this?  I worked with other companies with very strict by-the-book protocols and PHI, but nothing like this.  I feel like my boss won&amp;#39;t give approval for anything because she&amp;#39;s not tech-savvy and doesn&amp;#39;t understand, and even when I take the time to explain things to her, she still never agrees or approves anything.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My boss won&amp;#39;t let me:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create automated processes using Python because &amp;quot;it uses a username and password to connect to SQL Server and we&amp;#39;re only allowed to use Windows Authentication&amp;quot; (even though everyone uses Windows Authentication with SSMS and other applications every day.)&lt;/li&gt;\n&lt;li&gt;Then I switch to Selenium in Python as an alternative which doesn&amp;#39;t use any credentials but am not allowed to use it because it &amp;quot;needs to run from a different server and not my VPN&amp;quot; but we don&amp;#39;t have a server to run it on.&lt;/li&gt;\n&lt;li&gt;Not allowed to use Windows Authentication with Visual Studio within SSIS because &amp;quot;the data contains PHI&amp;quot; (even though everyone accesses PHI all day every day and saves it to their VPN&amp;#39;s PC).&lt;/li&gt;\n&lt;li&gt;Before I started, no one maintained our prod server and doesn&amp;#39;t have the correct data anymore, so we&amp;#39;re not allowed to use it.  Instead, we must use our test server as prod.&lt;/li&gt;\n&lt;li&gt;Not allowed to backup our test server and restore to prod so we can actually use prod again because &amp;quot;we need to wait until next year to make sure that the numbers are correct.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Not allowed to compare data from our test server to prod and make the changes manually for the same reason.&lt;/li&gt;\n&lt;li&gt;Not allowed to use SSIS to develop or test packages because &amp;quot;we haven&amp;#39;t done that in years&amp;quot;. (even though I can see in the pipeline that SSIS packages were deployed in last year.)&lt;/li&gt;\n&lt;li&gt;Not allowed to backup our test server and restore it to dev because &amp;quot;that creates a backup of the data that contains PHI&amp;quot;. (our current dev server is not in use)  I asked the same question last month and was told that we couldn&amp;#39;t do that because &amp;quot;I don&amp;#39;t know if we have enough space&amp;quot; (our current dev sever is empty LOL)&lt;/li&gt;\n&lt;li&gt;Not allowed to create a new database on dev with EMPTY tables and no PHI to do SSIS development work because &amp;quot;we have never done that in the past.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Not allowed to do any development work because &amp;quot;our previous employee did all development work on our test server&amp;quot; (our test server is now our ONLY server that we&amp;#39;re allowed to use)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Things I can do as a data engineer:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run a query manually in SSMS, copy the data, paste it into Excel, and email the Excel file.&lt;/li&gt;\n&lt;li&gt;Develop read-only t-sql queries and run in SSMS.&lt;/li&gt;\n&lt;li&gt;Go to our SSRS server&amp;#39;s website, manually choose all of the filters, wait for the report to load 2 times, wait for the report to download, rename the Excel report, and email the report.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can automate our entire process in a week and it would then automatically complete each month instead of spending 60 hours manually doing the process.  Our SSIS project broke each month over the last 3 months but I can&amp;#39;t even get permission to troubleshoot it within Visual Studio.  Right now, all of our important reports are past due without any solution in sight except for the many solutions that I pitched to get everything fixed, but she won&amp;#39;t approve anything, yet she told us that we &amp;quot;need to be more proactive&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;During my first month there, modifying an Excel report that I personally used to use parameters to create links using Excel formulas to automatically download SSRS reports took a week to get approval across many heated conversations and she made me meet with others to get their approval as well.  I already created the Excel report and she saw it when I was sharing my screen, and then I wasn&amp;#39;t allowed to use it for a week+ until everyone approved it.&lt;/p&gt;\n\n&lt;p&gt;EDIT:  Thanks everyone for talking it through! It helped me figure out what to do. First, I&amp;#39;m going to continue to self-study to learn Spark and SSAS to further my career.  Then I&amp;#39;m going to use the company&amp;#39;s existing SSAS, spark, devops, and pipelines to get better at these skills while kind of ignoring the other half of the sinking ship.  Then will finish up the SQL Server to cloud migration project by the 6 month mark. In the meantime, I&amp;#39;m going to take the bullet point list above, clean it up a bit, and review it during a meeting with my boss and a few IT and security folks. This should help my boss understand that all of this work can be done and can be compliant at the same time. To try to get her to allow me to restore a copy of test to the Dev and prod servers, I think I&amp;#39;ll pull a couple of million records that don&amp;#39;t match in both test and prod and tell her that someone would have to manually update all of these records individually unless she let&amp;#39;s me click the button to restore the databases and make everything correct.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17llxya", "is_robot_indexable": true, "report_reasons": null, "author": "DesignedIt", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17llxya/boss_wont_let_me_automate_or_develop_anything_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17llxya/boss_wont_let_me_automate_or_develop_anything_as/", "subreddit_subscribers": 137387, "created_utc": 1698871898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title.\n\nAt work, the non-coding people are telling me it's redundant to save the data first to a .csv, and I should just load it from there.\n\nI'm not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.\n\nIt's not as if exctracting data and saving it to a .csv is an Herculean task...", "author_fullname": "t2_mnoei525n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using an API, should I load the data directly to a database, or should I just clean the data, save it as .csvs in blob storage and then load my data from the .csvs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ld440", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698848144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title.&lt;/p&gt;\n\n&lt;p&gt;At work, the non-coding people are telling me it&amp;#39;s redundant to save the data first to a .csv, and I should just load it from there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not as if exctracting data and saving it to a .csv is an Herculean task...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ld440", "is_robot_indexable": true, "report_reasons": null, "author": "peroqueteniaquever", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "subreddit_subscribers": 137387, "created_utc": 1698848144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering community,\n\nI'm in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I'm feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.\n\nFor those who have been through this journey, I have a few questions:\n\n1. To what extent should I be practicing Python problems on Leetcode for a data engineering role?\n2. What specific topics or areas should be my primary focus?\n3. During your interviews, which Python-related topics were emphasized the most?\n\nAny insights or guidance would be greatly appreciated! Thanks in advance.", "author_fullname": "t2_5u73tpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How deep or advanced should my Python knowledge be when practicing on Leetcode for a Data Engineering role? Which difficulty levels of problems are most relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3hjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I&amp;#39;m feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.&lt;/p&gt;\n\n&lt;p&gt;For those who have been through this journey, I have a few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To what extent should I be practicing Python problems on Leetcode for a data engineering role?&lt;/li&gt;\n&lt;li&gt;What specific topics or areas should be my primary focus?&lt;/li&gt;\n&lt;li&gt;During your interviews, which Python-related topics were emphasized the most?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any insights or guidance would be greatly appreciated! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3hjb", "is_robot_indexable": true, "report_reasons": null, "author": "arcofiero", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "subreddit_subscribers": 137387, "created_utc": 1698810142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.\n\nThese guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.\n\nNowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d\n\nSomething like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.\n\nSo that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?\n\n\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you do when you joined an organization with some serious data problems, and you needed to introduce structure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kztbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698799438.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698798618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.&lt;/p&gt;\n\n&lt;p&gt;These guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.&lt;/p&gt;\n\n&lt;p&gt;Nowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d&lt;/p&gt;\n\n&lt;p&gt;Something like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.&lt;/p&gt;\n\n&lt;p&gt;So that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?&lt;/p&gt;\n\n&lt;p&gt;\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kztbm", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "subreddit_subscribers": 137387, "created_utc": 1698798618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!", "author_fullname": "t2_c85rlf9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Meta Virtual Onsite interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3nzl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3nzl", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle_Restaurant_35", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "subreddit_subscribers": 137387, "created_utc": 1698810819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its **free** for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  \n\n\n[https://www.amazon.com/dp/B0CM85Q7YJ](https://www.amazon.com/dp/B0CM85Q7YJ)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free eBook on Acing the Data Engineering Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17le6tc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698851150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its &lt;strong&gt;free&lt;/strong&gt; for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0CM85Q7YJ\"&gt;https://www.amazon.com/dp/B0CM85Q7YJ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17le6tc", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "subreddit_subscribers": 137387, "created_utc": 1698851150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. \n\nNow the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. \n\nI am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. \n\nI was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. \n\nAnyone have any advice or thoughts?", "author_fullname": "t2_bbmo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GIT and environments in a data context", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l4v87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698830665.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698815394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. &lt;/p&gt;\n\n&lt;p&gt;Now the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. &lt;/p&gt;\n\n&lt;p&gt;I am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. &lt;/p&gt;\n\n&lt;p&gt;I was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any advice or thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l4v87", "is_robot_indexable": true, "report_reasons": null, "author": "cursedbartender", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "subreddit_subscribers": 137387, "created_utc": 1698815394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE's\n\nI am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.\n\nNo I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.\n\n1. I need to check if I can join tables on some join key and every record match:\n2. I need to check if every column values in source are exactly the same as in target column\n\nSo my idea is to do something like this:\n\n1. Read DWH table with Spark (source table)\n2. Read DataLake table with Spark (target table)\n3. Add prefix to source table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n4. Add prefix to target table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n5. Use join\\_key to left join table:  e.g:   source\\_table\\['source\\_join\\_key'\\] == target\\_table\\['target\\_join\\_key'\\]\n6. Use this combined table to run great expectations\n   1. check if tables properly joined: expect\\_column\\_values\\_to\\_not\\_be\\_null(column='target\\_join\\_key')\n   2. check if column in source is the same as column in target  \nfor every column pair from source and target do the check:  \nexpect\\_column\\_pair\\_values\\_to\\_be\\_equal(  \n column\\_A=source\\_column\\_a, column\\_B=target\\_column\\_b)  \n\n\nGreat expectations is something new to me. Do you think my ideas is good or is there a better way ?  \nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.\n\n  \n", "author_fullname": "t2_2llofc3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great expectations -&gt; how to compare 2 dafarames", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l89wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE&amp;#39;s&lt;/p&gt;\n\n&lt;p&gt;I am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.&lt;/p&gt;\n\n&lt;p&gt;No I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I need to check if I can join tables on some join key and every record match:&lt;/li&gt;\n&lt;li&gt;I need to check if every column values in source are exactly the same as in target column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So my idea is to do something like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read DWH table with Spark (source table)&lt;/li&gt;\n&lt;li&gt;Read DataLake table with Spark (target table)&lt;/li&gt;\n&lt;li&gt;Add prefix to source table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Add prefix to target table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Use join_key to left join table:  e.g:   source_table[&amp;#39;source_join_key&amp;#39;] == target_table[&amp;#39;target_join_key&amp;#39;]&lt;/li&gt;\n&lt;li&gt;Use this combined table to run great expectations\n\n&lt;ol&gt;\n&lt;li&gt;check if tables properly joined: expect_column_values_to_not_be_null(column=&amp;#39;target_join_key&amp;#39;)&lt;/li&gt;\n&lt;li&gt;check if column in source is the same as column in target&lt;br/&gt;\nfor every column pair from source and target do the check:&lt;br/&gt;\nexpect_column_pair_values_to_be_equal(&lt;br/&gt;\ncolumn_A=source_column_a, column_B=target_column_b)&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Great expectations is something new to me. Do you think my ideas is good or is there a better way ?&lt;br/&gt;\nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l89wn", "is_robot_indexable": true, "report_reasons": null, "author": "masek94", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "subreddit_subscribers": 137387, "created_utc": 1698831087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Nov 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1698854452.916, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfedu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698854452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?auto=webp&amp;s=f31fa9903d75d67fdf7aa466dc59b353580baab5", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d07b02ea6d52e510a89eebac3220c5380d16a142", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ffdf2cc7f4c7114208ab8b1d725d8b597246398", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17088c4844a3ddeb97d8b7a5cbe0f0bb49f04088", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1d617569fa501370336b415c3779b4906b139b24", "width": 640, "height": 333}], "variants": {}, "id": "VINWZoaUoDSGoJqMz7V286sj1fgBznndF5gxkCuKIxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfedu", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "subreddit_subscribers": 137387, "created_utc": 1698854452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for \"full stack\" analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).\n\nI've been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.\n\nThe implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I've worked with some of these people before and they're wicked smart.\n\nBesides my story and any advice you'd provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What other roles would you entertain beyond DE and SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17leyt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698853293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for &amp;quot;full stack&amp;quot; analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.&lt;/p&gt;\n\n&lt;p&gt;The implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I&amp;#39;ve worked with some of these people before and they&amp;#39;re wicked smart.&lt;/p&gt;\n\n&lt;p&gt;Besides my story and any advice you&amp;#39;d provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17leyt8", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "subreddit_subscribers": 137387, "created_utc": 1698853293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipelines for Data Products: Key Components, Recommended Tools, and Fundamental Development Concepts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17l97g9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EIv6gRw0P89sEDCK4NSudJaEodcyodm-X3JW9F6OKvM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698835195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?auto=webp&amp;s=b25f887df718c4bb01b0cfed6817176eb521e590", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4bfdb31befcbbe7483e6f726d778f8e9b313d06", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac59763b5c2e199b7f0510593e9b60059274698f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd9cccbfff8962388ed92c9415979a31979db949", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79e68330249124713e23b85e86d0d373585ca011", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b0c6d1642261a80c5cdc619f6c5c8085d93dccb6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ebabeea51e10cd32fcbcd0e82e32fda98459aade", "width": 1080, "height": 540}], "variants": {}, "id": "08ytc-6p-5bmF7Vj6nq-fUR0LEM5son5wQBs-pHIOBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17l97g9", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l97g9/data_pipelines_for_data_products_key_components/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "subreddit_subscribers": 137387, "created_utc": 1698835195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working with an insecure bully who wants to appear smart and be seen as a savant . However he is a pain to work with because he wants us to implement solutions he thinks is best and is usually something he read up on or found out a few weeks back . I and the other senior engineer voice concerns and he then becomes nasty and belittling making comments like \u201chave you ever done this before\u201d or \u201cdo you even know anything about data architecture or xyz technology\u201d", "author_fullname": "t2_imxcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with an insecure manager who throws a lot of buzz words and wants to implement his way of doing things because he found a new tech or process a few weeks back?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17loju3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698878733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working with an insecure bully who wants to appear smart and be seen as a savant . However he is a pain to work with because he wants us to implement solutions he thinks is best and is usually something he read up on or found out a few weeks back . I and the other senior engineer voice concerns and he then becomes nasty and belittling making comments like \u201chave you ever done this before\u201d or \u201cdo you even know anything about data architecture or xyz technology\u201d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17loju3", "is_robot_indexable": true, "report_reasons": null, "author": "nus07", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17loju3/how_do_you_deal_with_an_insecure_manager_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17loju3/how_do_you_deal_with_an_insecure_manager_who/", "subreddit_subscribers": 137387, "created_utc": 1698878733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Whats a Data Product per your definition and how does it differ from a Data Asset?", "author_fullname": "t2_c45r2mfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Product Definition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8vv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698833808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whats a Data Product per your definition and how does it differ from a Data Asset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l8vv3", "is_robot_indexable": true, "report_reasons": null, "author": "Head_Ad_5511", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8vv3/data_product_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8vv3/data_product_definition/", "subreddit_subscribers": 137387, "created_utc": 1698833808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand that is not always as specific or resources catered to data engineering specific interviews so open to more general ideas that would serve me well on how to best perform but also if you have advice specific to a de system design interview, interested as well", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good tips or tricks on design prep for a system engineer interview for data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17loys6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698879815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand that is not always as specific or resources catered to data engineering specific interviews so open to more general ideas that would serve me well on how to best perform but also if you have advice specific to a de system design interview, interested as well&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17loys6", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17loys6/any_good_tips_or_tricks_on_design_prep_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17loys6/any_good_tips_or_tricks_on_design_prep_for_a/", "subreddit_subscribers": 137387, "created_utc": 1698879815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of hadoop tables on a server. Our enterprise is using cloudera and impala to help with the administration. What is the easiest way to get an entity diagram of all the tables that exist in the system? Ideally it will generate the entities and then I can add the relationships in after as they are not explicitly defined. ", "author_fullname": "t2_ea0rdldy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with hadoop vizualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lnv2i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698876907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of hadoop tables on a server. Our enterprise is using cloudera and impala to help with the administration. What is the easiest way to get an entity diagram of all the tables that exist in the system? Ideally it will generate the entities and then I can add the relationships in after as they are not explicitly defined. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lnv2i", "is_robot_indexable": true, "report_reasons": null, "author": "saf34w0rk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lnv2i/help_with_hadoop_vizualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lnv2i/help_with_hadoop_vizualization/", "subreddit_subscribers": 137387, "created_utc": 1698876907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not a data engineer.\n\nI work as a Data analyst (SQL, PowerBI, Power Platform, some Python proficiency) and applications support at my org.\n\nI have been given an Azure SQL DB.  I will have full run of the DB.  I have an idea of what the table structures should be and I have SQL statements ready-to-go to retrieve the necessary data.\n\nI may need to do some pivotting and transformation before writing to the DB, but I need a scheduled \"pipeline\" with ETL activities/capablities.  I do not have ADF access.\n\nWhat are the easiest and \"cheapest\" (in terms of reducing the amount of \"new\" tools, compute, etc) solutions for me?  Let me know if I am not providing enough context.   Any help is appreciated.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_26ealf6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "recommendation on a basic \"pipeline\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lmnxc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698873804.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not a data engineer.&lt;/p&gt;\n\n&lt;p&gt;I work as a Data analyst (SQL, PowerBI, Power Platform, some Python proficiency) and applications support at my org.&lt;/p&gt;\n\n&lt;p&gt;I have been given an Azure SQL DB.  I will have full run of the DB.  I have an idea of what the table structures should be and I have SQL statements ready-to-go to retrieve the necessary data.&lt;/p&gt;\n\n&lt;p&gt;I may need to do some pivotting and transformation before writing to the DB, but I need a scheduled &amp;quot;pipeline&amp;quot; with ETL activities/capablities.  I do not have ADF access.&lt;/p&gt;\n\n&lt;p&gt;What are the easiest and &amp;quot;cheapest&amp;quot; (in terms of reducing the amount of &amp;quot;new&amp;quot; tools, compute, etc) solutions for me?  Let me know if I am not providing enough context.   Any help is appreciated.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lmnxc", "is_robot_indexable": true, "report_reasons": null, "author": "Mgmt049", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lmnxc/recommendation_on_a_basic_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lmnxc/recommendation_on_a_basic_pipeline/", "subreddit_subscribers": 137387, "created_utc": 1698873804.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team wrote this article with some context on what a data catalog is, how to create and deploy one as well as a delightful template: [https://www.castordoc.com/blog/what-is-a-data-dictionary](https://www.castordoc.com/blog/what-is-a-data-dictionary)\n\n&amp;#x200B;\n\n[Free Data Catalog Excel Template To Build your First Data Dictionary](https://preview.redd.it/ashiq483zsxb1.png?width=2844&amp;format=png&amp;auto=webp&amp;s=68d0003003666b640e978778a504b36bf26c8233)\n\nIt might interest some of you looking to better organize your data", "author_fullname": "t2_bu8cw718", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Template - How to create a data catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ashiq483zsxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b651f5f02187fe426af2107d75f4b31aa19ef73"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=607462faff610ef9e5b80162bab825336c481067"}, {"y": 165, "x": 320, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b7551d28ceffaca0b49d8dc4e86281bf73090151"}, {"y": 331, "x": 640, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=70809cb8a7ffde14b6e2e287e6d0c7fbce775c28"}, {"y": 496, "x": 960, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8213b182e7c0f60603def2d2d877a2928d253800"}, {"y": 558, "x": 1080, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b57cd09cdb17c1074a8b428f48141c3063e13e22"}], "s": {"y": 1472, "x": 2844, "u": "https://preview.redd.it/ashiq483zsxb1.png?width=2844&amp;format=png&amp;auto=webp&amp;s=68d0003003666b640e978778a504b36bf26c8233"}, "id": "ashiq483zsxb1"}}, "name": "t3_17lmjs3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Tx5MFTlTnRCgiHz5ymt9w18vx76zItHnxqzB-cdQQeo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698873504.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team wrote this article with some context on what a data catalog is, how to create and deploy one as well as a delightful template: &lt;a href=\"https://www.castordoc.com/blog/what-is-a-data-dictionary\"&gt;https://www.castordoc.com/blog/what-is-a-data-dictionary&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ashiq483zsxb1.png?width=2844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68d0003003666b640e978778a504b36bf26c8233\"&gt;Free Data Catalog Excel Template To Build your First Data Dictionary&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It might interest some of you looking to better organize your data&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?auto=webp&amp;s=96966f3b3cbfc687b0d07b6bbb184da63ce019d3", "width": 1320, "height": 622}, "resolutions": [{"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=931aa5c20d82e391603aafad075a18bcec885362", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e25af9a88d0460a891b256f3846e848881b2f66", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=49f987a42bb680889b30c921fa8bcbfcc79e8986", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a93ed850ce6c4014ffe321a8a624343441eaca6", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=67225ce3d7f17a1551407044f7da1146f6635b03", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/m3MVfz6xqqPIg8YK6b2uT6DTV7SAwtd8kltFGTAQ54g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=41baf2ab6c614f0ad298b3a2fa99e290a6f47740", "width": 1080, "height": 508}], "variants": {}, "id": "vp67-BvElJrbu9gU4uR5R-Md7d5wdv5YPNiHbWZkGqI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17lmjs3", "is_robot_indexable": true, "report_reasons": null, "author": "castor-metadata", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lmjs3/template_how_to_create_a_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lmjs3/template_how_to_create_a_data_catalog/", "subreddit_subscribers": 137387, "created_utc": 1698873504.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Preface:**\n\n* I am going to use termonology wrong, and I apologize. My career has been primarily on the business side but I have a minor in comp sci and I did 4 years of database in Uni 15 years ago haha. I've been a business resource on a snowflake implementation recently and done some work doing Data science using SSIS, SSRS on prem days. So I know a little but i also not ignorant to all the stuff i dont know.\n* We are a big company and have lagged behind the times in leveraging our data\n* We have limited IS skills available and no budget to hire external\n   * We have a solid Infrastructure architect, but no true data architect/engineer.\n* We are an AWS shop with S3 datalake mostly implemented but nothing robust or enterprise beyond that\n* We want to serve up, modelled trusted data from multiple data sources to our customers\n\n&amp;#x200B;\n\n**Proposed solution**\n\n* Ingestions into the lake via AWS Glue\n* Implement a medallion architecture within AWS S3 buckets\n* Utilize Glue for transformations between layers orchestrated via step functions\n* Store files in Silver and Gold layer as Deltalake Parquet\n* Bring gold layer into PowerBI data marts and serve up star schemas to customers\n\n&amp;#x200B;\n\n**Other considerations**\n\n* Utilize glue crawlers on Silver and Gold layers to populate glue catalog to be used as data catalog.\n* If we get approval for fabric, utilize S3 Shortcuts (hence deltalake format earlier) to model Gold layer in Synapse\n* No I cant go buy Databricks sadly (or snowflake/BQ)\n* We could standup a redshift warehouse but we'll be limited technically (no data arcitect) and I feel like we won't be able to support it over the medium to long term\n\nWe are trying to balance what we can accomplish we a few smart people learning on the fly and basically no real data engineers.  We know we won't build the best product, we want to build it good enough to drive business value and prove to senior leadership that it's worth investing $$ into for a real, enterprise product.", "author_fullname": "t2_kgtd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about our Lake housing Strategy and Technology Stack - Be Brutal, please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lm9s9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698872785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Preface:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I am going to use termonology wrong, and I apologize. My career has been primarily on the business side but I have a minor in comp sci and I did 4 years of database in Uni 15 years ago haha. I&amp;#39;ve been a business resource on a snowflake implementation recently and done some work doing Data science using SSIS, SSRS on prem days. So I know a little but i also not ignorant to all the stuff i dont know.&lt;/li&gt;\n&lt;li&gt;We are a big company and have lagged behind the times in leveraging our data&lt;/li&gt;\n&lt;li&gt;We have limited IS skills available and no budget to hire external\n\n&lt;ul&gt;\n&lt;li&gt;We have a solid Infrastructure architect, but no true data architect/engineer.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;We are an AWS shop with S3 datalake mostly implemented but nothing robust or enterprise beyond that&lt;/li&gt;\n&lt;li&gt;We want to serve up, modelled trusted data from multiple data sources to our customers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Proposed solution&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ingestions into the lake via AWS Glue&lt;/li&gt;\n&lt;li&gt;Implement a medallion architecture within AWS S3 buckets&lt;/li&gt;\n&lt;li&gt;Utilize Glue for transformations between layers orchestrated via step functions&lt;/li&gt;\n&lt;li&gt;Store files in Silver and Gold layer as Deltalake Parquet&lt;/li&gt;\n&lt;li&gt;Bring gold layer into PowerBI data marts and serve up star schemas to customers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Other considerations&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Utilize glue crawlers on Silver and Gold layers to populate glue catalog to be used as data catalog.&lt;/li&gt;\n&lt;li&gt;If we get approval for fabric, utilize S3 Shortcuts (hence deltalake format earlier) to model Gold layer in Synapse&lt;/li&gt;\n&lt;li&gt;No I cant go buy Databricks sadly (or snowflake/BQ)&lt;/li&gt;\n&lt;li&gt;We could standup a redshift warehouse but we&amp;#39;ll be limited technically (no data arcitect) and I feel like we won&amp;#39;t be able to support it over the medium to long term&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We are trying to balance what we can accomplish we a few smart people learning on the fly and basically no real data engineers.  We know we won&amp;#39;t build the best product, we want to build it good enough to drive business value and prove to senior leadership that it&amp;#39;s worth investing $$ into for a real, enterprise product.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lm9s9", "is_robot_indexable": true, "report_reasons": null, "author": "haigins", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lm9s9/question_about_our_lake_housing_strategy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lm9s9/question_about_our_lake_housing_strategy_and/", "subreddit_subscribers": 137387, "created_utc": 1698872785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I have a grid example (below, taken from [https://covjson.org/playground/](https://covjson.org/playground/) ) in which an XYZt array is specified.\n\nThe axes are specified in the domain, the values are stored in a 1 dimensional array with a given shape of the axes.\n\nI need to write a function that gets the Sea Ice Concentration (ICEC) parameter at a specific location at a specific time.\n\nHowever my brain cannot comprehend how to extract the correct value using the \"shape\", \"axisNames\" and  \"values\" from the \"ranges\" object. On the web I can only find examples for non-CoverageJSON files.\n\nThe (pseudo) code:\n\n    float result = getICECValue(x: -5, y: 40, z: 5, t: \"2010-01-01T00:12:20Z\");\n    \n    func getICECValue(x: float, y: float, z: float, t: DateTime) {\n       // what goes here?\n    }\n\nAny help is greatly appreciated.\n\nThe data:\n\n    {\n      \"type\" : \"Coverage\",\n      \"domain\" : {\n        \"type\" : \"Domain\",\n        \"domainType\" : \"Grid\",\n        \"axes\": {\n          \"x\" : { \"values\": [-10,-5,0] },\n          \"y\" : { \"values\": [40,50] },\n          \"z\" : { \"values\": [ 5] },\n          \"t\" : { \"values\": [\"2010-01-01T00:12:20Z\"] }\n        },\n        \"referencing\": [{\n          \"coordinates\": [\"y\",\"x\",\"z\"],\n          \"system\": {\n            \"type\": \"GeographicCRS\",\n            \"id\": \"http://www.opengis.net/def/crs/EPSG/0/4979\"\n          }\n        }, {\n          \"coordinates\": [\"t\"],\n          \"system\": {\n            \"type\": \"TemporalRS\",\n            \"calendar\": \"Gregorian\"\n          }\n        }]\n      },\n      \"parameters\" : {\n        \"ICEC\": {\n          \"type\" : \"Parameter\",\n          \"description\": {\n          \t\"en\": \"Sea Ice concentration (ice=1;no ice=0)\"\n          },\n          \"unit\" : {\n            \"label\": {\n              \"en\": \"Ratio\"\n            },\n            \"symbol\": {\n              \"value\": \"1\",\n              \"type\": \"http://www.opengis.net/def/uom/UCUM/\"\n            }\n          },\n          \"observedProperty\" : {\n            \"id\" : \"http://vocab.nerc.ac.uk/standard_name/sea_ice_area_fraction/\",\n            \"label\" : {\n              \"en\": \"Sea Ice Concentration\"\n            }\n          }\n        }\n      },\n      \"ranges\" : {\n        \"ICEC\" : {\n          \"type\" : \"NdArray\",\n          \"dataType\": \"float\",\n          \"axisNames\": [\"t\",\"z\",\"y\",\"x\"],\n          \"shape\": [1, 1, 2, 3],\n          \"values\" : [ 0.5, 0.6, 0.4, 0.6, 0.2, null ]\n        }\n      }\n    }\n\n&amp;#x200B;", "author_fullname": "t2_knlbfd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CoverageJSON: How to get values from an XYZt NdArray?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ljxh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698866446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a grid example (below, taken from &lt;a href=\"https://covjson.org/playground/\"&gt;https://covjson.org/playground/&lt;/a&gt; ) in which an XYZt array is specified.&lt;/p&gt;\n\n&lt;p&gt;The axes are specified in the domain, the values are stored in a 1 dimensional array with a given shape of the axes.&lt;/p&gt;\n\n&lt;p&gt;I need to write a function that gets the Sea Ice Concentration (ICEC) parameter at a specific location at a specific time.&lt;/p&gt;\n\n&lt;p&gt;However my brain cannot comprehend how to extract the correct value using the &amp;quot;shape&amp;quot;, &amp;quot;axisNames&amp;quot; and  &amp;quot;values&amp;quot; from the &amp;quot;ranges&amp;quot; object. On the web I can only find examples for non-CoverageJSON files.&lt;/p&gt;\n\n&lt;p&gt;The (pseudo) code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;float result = getICECValue(x: -5, y: 40, z: 5, t: &amp;quot;2010-01-01T00:12:20Z&amp;quot;);\n\nfunc getICECValue(x: float, y: float, z: float, t: DateTime) {\n   // what goes here?\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Any help is greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;The data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;type&amp;quot; : &amp;quot;Coverage&amp;quot;,\n  &amp;quot;domain&amp;quot; : {\n    &amp;quot;type&amp;quot; : &amp;quot;Domain&amp;quot;,\n    &amp;quot;domainType&amp;quot; : &amp;quot;Grid&amp;quot;,\n    &amp;quot;axes&amp;quot;: {\n      &amp;quot;x&amp;quot; : { &amp;quot;values&amp;quot;: [-10,-5,0] },\n      &amp;quot;y&amp;quot; : { &amp;quot;values&amp;quot;: [40,50] },\n      &amp;quot;z&amp;quot; : { &amp;quot;values&amp;quot;: [ 5] },\n      &amp;quot;t&amp;quot; : { &amp;quot;values&amp;quot;: [&amp;quot;2010-01-01T00:12:20Z&amp;quot;] }\n    },\n    &amp;quot;referencing&amp;quot;: [{\n      &amp;quot;coordinates&amp;quot;: [&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;,&amp;quot;z&amp;quot;],\n      &amp;quot;system&amp;quot;: {\n        &amp;quot;type&amp;quot;: &amp;quot;GeographicCRS&amp;quot;,\n        &amp;quot;id&amp;quot;: &amp;quot;http://www.opengis.net/def/crs/EPSG/0/4979&amp;quot;\n      }\n    }, {\n      &amp;quot;coordinates&amp;quot;: [&amp;quot;t&amp;quot;],\n      &amp;quot;system&amp;quot;: {\n        &amp;quot;type&amp;quot;: &amp;quot;TemporalRS&amp;quot;,\n        &amp;quot;calendar&amp;quot;: &amp;quot;Gregorian&amp;quot;\n      }\n    }]\n  },\n  &amp;quot;parameters&amp;quot; : {\n    &amp;quot;ICEC&amp;quot;: {\n      &amp;quot;type&amp;quot; : &amp;quot;Parameter&amp;quot;,\n      &amp;quot;description&amp;quot;: {\n        &amp;quot;en&amp;quot;: &amp;quot;Sea Ice concentration (ice=1;no ice=0)&amp;quot;\n      },\n      &amp;quot;unit&amp;quot; : {\n        &amp;quot;label&amp;quot;: {\n          &amp;quot;en&amp;quot;: &amp;quot;Ratio&amp;quot;\n        },\n        &amp;quot;symbol&amp;quot;: {\n          &amp;quot;value&amp;quot;: &amp;quot;1&amp;quot;,\n          &amp;quot;type&amp;quot;: &amp;quot;http://www.opengis.net/def/uom/UCUM/&amp;quot;\n        }\n      },\n      &amp;quot;observedProperty&amp;quot; : {\n        &amp;quot;id&amp;quot; : &amp;quot;http://vocab.nerc.ac.uk/standard_name/sea_ice_area_fraction/&amp;quot;,\n        &amp;quot;label&amp;quot; : {\n          &amp;quot;en&amp;quot;: &amp;quot;Sea Ice Concentration&amp;quot;\n        }\n      }\n    }\n  },\n  &amp;quot;ranges&amp;quot; : {\n    &amp;quot;ICEC&amp;quot; : {\n      &amp;quot;type&amp;quot; : &amp;quot;NdArray&amp;quot;,\n      &amp;quot;dataType&amp;quot;: &amp;quot;float&amp;quot;,\n      &amp;quot;axisNames&amp;quot;: [&amp;quot;t&amp;quot;,&amp;quot;z&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;],\n      &amp;quot;shape&amp;quot;: [1, 1, 2, 3],\n      &amp;quot;values&amp;quot; : [ 0.5, 0.6, 0.4, 0.6, 0.2, null ]\n    }\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ljxh5", "is_robot_indexable": true, "report_reasons": null, "author": "hotdogsoup_nl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ljxh5/coveragejson_how_to_get_values_from_an_xyzt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ljxh5/coveragejson_how_to_get_values_from_an_xyzt/", "subreddit_subscribers": 137387, "created_utc": 1698866446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2 Postgres databases and need to synchronize a few tables between them, with requirements:\n\n1. Do a few transformations (all are simple, select subset of columns mostly)\n2. Do this real-time or very near real-time (e.g. every 5 minutes is already not acceptable)\n3. Synchronize table schema changes\n4. Solution needs to be open source (we have a large volume of data, with variable loads, and are running highly cost-optimized Kubernetes, both DBs are self-hosted)\n5. Solution needs to be reasonably popular (we've had bad time with new software which died out due to lack of popularity)\n\nSolutions I considered:\n\n1. Logical replication - doesn't propagate schema changes, and would require quite complicated CI/CD (app that manages source DB would have to do transactional change of synchronization in target DB, which is managed by another app)\n2. Airbyte - highest possible frequency is 5 minutes\n3. Meltano - seems to be able to work quite frequently, even every minute, but is still not real time\n4. Most other solutions is only commercially available.\n\nDo you know of any solutions that satisfy those requirements? From my perspective (with limited experience) it sounds like a reasonably typical problem.", "author_fullname": "t2_wounm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres to Postgres real time data + schema sync solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lj8fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698864613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 Postgres databases and need to synchronize a few tables between them, with requirements:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do a few transformations (all are simple, select subset of columns mostly)&lt;/li&gt;\n&lt;li&gt;Do this real-time or very near real-time (e.g. every 5 minutes is already not acceptable)&lt;/li&gt;\n&lt;li&gt;Synchronize table schema changes&lt;/li&gt;\n&lt;li&gt;Solution needs to be open source (we have a large volume of data, with variable loads, and are running highly cost-optimized Kubernetes, both DBs are self-hosted)&lt;/li&gt;\n&lt;li&gt;Solution needs to be reasonably popular (we&amp;#39;ve had bad time with new software which died out due to lack of popularity)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Solutions I considered:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Logical replication - doesn&amp;#39;t propagate schema changes, and would require quite complicated CI/CD (app that manages source DB would have to do transactional change of synchronization in target DB, which is managed by another app)&lt;/li&gt;\n&lt;li&gt;Airbyte - highest possible frequency is 5 minutes&lt;/li&gt;\n&lt;li&gt;Meltano - seems to be able to work quite frequently, even every minute, but is still not real time&lt;/li&gt;\n&lt;li&gt;Most other solutions is only commercially available.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you know of any solutions that satisfy those requirements? From my perspective (with limited experience) it sounds like a reasonably typical problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lj8fq", "is_robot_indexable": true, "report_reasons": null, "author": "qalis", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lj8fq/postgres_to_postgres_real_time_data_schema_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lj8fq/postgres_to_postgres_real_time_data_schema_sync/", "subreddit_subscribers": 137387, "created_utc": 1698864613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my boss asks me if we are secure, I said yes, but I am 100% confident. So I am curious to know where any gaps might be if any.\n\nOur DW and PBI are behind okta for all users, we only have a few service accounts with full access to the data that we use to transform with. We house our source creds in AWS secrets manager. Access secrets manager via STS. We rotate PW once a year for mostly everything, and outside of snowflake nothing is exposed publicly.\n\nI use airflow to s3 to snowflake to DBT to power bi.\n\nWould love and out side perspective.", "author_fullname": "t2_v6u6a9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Think about security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lhumb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698860905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my boss asks me if we are secure, I said yes, but I am 100% confident. So I am curious to know where any gaps might be if any.&lt;/p&gt;\n\n&lt;p&gt;Our DW and PBI are behind okta for all users, we only have a few service accounts with full access to the data that we use to transform with. We house our source creds in AWS secrets manager. Access secrets manager via STS. We rotate PW once a year for mostly everything, and outside of snowflake nothing is exposed publicly.&lt;/p&gt;\n\n&lt;p&gt;I use airflow to s3 to snowflake to DBT to power bi.&lt;/p&gt;\n\n&lt;p&gt;Would love and out side perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lhumb", "is_robot_indexable": true, "report_reasons": null, "author": "NexusIO", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lhumb/think_about_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lhumb/think_about_security/", "subreddit_subscribers": 137387, "created_utc": 1698860905.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}