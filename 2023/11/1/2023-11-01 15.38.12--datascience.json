{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.\n\nI received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.\n\nSomeone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.\n\nThe day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.\n\nBefore the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.\n\nI was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.\n\nThere were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.\n\nAfter a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.\n\nNext I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.\n\nFinally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.\n\nAfter this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.\n\nI also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).\n\nSo, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this.", "author_fullname": "t2_7q2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why some data science interviews suck, as an interviewer...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kvjmp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 153, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 153, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698786767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I&amp;#39;d give my experience from the other side of the desk which may go some way to showing why it can be so bad.&lt;/p&gt;\n\n&lt;p&gt;I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.&lt;/p&gt;\n\n&lt;p&gt;Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.&lt;/p&gt;\n\n&lt;p&gt;The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some &amp;#39;calibration&amp;#39; briefing before the interviews; it was too late to speak to HR.&lt;/p&gt;\n\n&lt;p&gt;Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no &amp;#39;calibration&amp;#39; brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.&lt;/p&gt;\n\n&lt;p&gt;I was dropped straight into a &amp;#39;technical&amp;#39; interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.&lt;/p&gt;\n\n&lt;p&gt;There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be &amp;#39;The candidate readily accepts new ideas&amp;#39;. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.&lt;/p&gt;\n\n&lt;p&gt;After a few of these there was the &amp;#39;technical&amp;#39; section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.&lt;/p&gt;\n\n&lt;p&gt;Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.&lt;/p&gt;\n\n&lt;p&gt;Finally there was a group activity and we were supposed to observe the &amp;#39;teamwork&amp;#39; but the team just split the tasks and got on with them individually so there was hardly anything to observe.&lt;/p&gt;\n\n&lt;p&gt;After this the HR bod asked us to complete all the assessments and submit them. Then we&amp;#39;d have a &amp;#39;wash up&amp;#39;. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.&lt;/p&gt;\n\n&lt;p&gt;I also asked about the inappropriate technical questions and they said they didn&amp;#39;t get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).&lt;/p&gt;\n\n&lt;p&gt;So, as you can see, HR ruin everything they touch and hiring is a HR process so it&amp;#39;s terrible. Sorry if you had to go through this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17kvjmp", "is_robot_indexable": true, "report_reasons": null, "author": "nth_citizen", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/", "subreddit_subscribers": 1108337, "created_utc": 1698786767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. \n\nTime series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. \n\nIt also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. \n\nAnyone else find time series somewhat uninteresting? What can I do to get more interested it in?", "author_fullname": "t2_g7jmnu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else find time series work a little dull?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17koo01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698768668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. &lt;/p&gt;\n\n&lt;p&gt;Time series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. &lt;/p&gt;\n\n&lt;p&gt;It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. &lt;/p&gt;\n\n&lt;p&gt;Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17koo01", "is_robot_indexable": true, "report_reasons": null, "author": "_hairyberry_", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "subreddit_subscribers": 1108337, "created_utc": 1698768668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. \n\nI always assumed that it was 'bad form' to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use \"42\" or \"365\" or \"1234\" all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? ", "author_fullname": "t2_ghxga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data folks of Reddit: How do you choose a random seed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kxd5s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698791634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From classwork, it seems like a lot of people choose the same number for input into a sample() or set.seed() function. &lt;/p&gt;\n\n&lt;p&gt;I always assumed that it was &amp;#39;bad form&amp;#39; to use the same number for multiple applications of a random seed.  So I actually use dice to generate random seeds, just to be over-detailed.  But is that necessary?  If I just use &amp;quot;42&amp;quot; or &amp;quot;365&amp;quot; or &amp;quot;1234&amp;quot; all the time, am I missing something?  Is there a cultural issue or tradition in communities to use a given number? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17kxd5s", "is_robot_indexable": true, "report_reasons": null, "author": "CatOfGrey", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kxd5s/data_folks_of_reddit_how_do_you_choose_a_random/", "subreddit_subscribers": 1108337, "created_utc": 1698791634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If I don\u2019t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..", "author_fullname": "t2_ayqufd5k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I learn LangChain? It\u2019s like learning a whole new tool set on top of LLM/Transformer models\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l11nx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698802357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I don\u2019t use LangChain or HuggingFace how can I build a chat box trained on my local data but using LLM like turbo etc..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17l11nx", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent_Mushroom98", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17l11nx/why_should_i_learn_langchain_its_like_learning_a/", "subreddit_subscribers": 1108337, "created_utc": 1698802357.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? \n\nMy coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. \n\nSo how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.", "author_fullname": "t2_5akq1mi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you analyze your models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kp0nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698769598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? &lt;/p&gt;\n\n&lt;p&gt;My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. &lt;/p&gt;\n\n&lt;p&gt;So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17kp0nu", "is_robot_indexable": true, "report_reasons": null, "author": "Dapper-Economy", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "subreddit_subscribers": 1108337, "created_utc": 1698769598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods &amp; neural networks in particular. \n\nI'm thinking of the Georgia Tech one but would be curious to hear about others.", "author_fullname": "t2_89ar1fajx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you did an online MSc in Stats and/or DS or something in that area &amp; liked it, what program was it and what did you like about it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ktlc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698781586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company offers tuition assistance and I&amp;#39;m thinking about going back for a formal degree, but it&amp;#39;d need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there&amp;#39;s gaps in my math and experience with some of the newer ML methods &amp;amp; neural networks in particular. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of the Georgia Tech one but would be curious to hear about others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17ktlc5", "is_robot_indexable": true, "report_reasons": null, "author": "AnxiousEgg6284", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/", "subreddit_subscribers": 1108337, "created_utc": 1698781586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.\n\nSo I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.\n\nIn the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served\n\nDM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automating ad-hoc SQL requests from stakeholders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kpxml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698772053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, I made a &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; here last month about my team spending too much time on ad-hoc SQL requests.&lt;/p&gt;\n\n&lt;p&gt;So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It&amp;#39;s basically a text to SQL interface for your users. We&amp;#39;re looking for a design partner to use our product for free in exchange for feedback.&lt;/p&gt;\n\n&lt;p&gt;In the original &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; there were concerns with trusting an LLM to produce accurate queries. We think there are too, it&amp;#39;s not perfect yet. That&amp;#39;s why we&amp;#39;d love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served&lt;/p&gt;\n\n&lt;p&gt;DM or comment if you&amp;#39;re interested and we&amp;#39;ll set something up! Would love to hear some feedback, positive or negative, from y&amp;#39;all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kpxml", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "subreddit_subscribers": 1108337, "created_utc": 1698772053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?", "author_fullname": "t2_dc8euqz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for technical interviews with focus on cleaning unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kvm37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698786949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17kvm37", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Bed5587", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/", "subreddit_subscribers": 1108337, "created_utc": 1698786949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I'm targeting appeared geared towards product data science. I'd like to hear from data scientists currently working in product roles:\n\n\\- How to stand out in terms of past experience, projects, resume, interview, etc?\n\n\\- What does a \"product\" data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?\n\n\\- What type of specific skills are you looking for outside of the core data science skillset?\n\nI was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a \"product\", but I'm not sure if it's directly applicable, especially with regards to customer behavior.", "author_fullname": "t2_1ns77nex", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to be Competitive for a Product Data Scientist Role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17le04v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "seniorflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698850684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a mid level data scientist with 3 yoe as a data scientist for the US Air Force and 1 yoe of prior experience as a data analyst at a major bank. I have a MS in Data Science from a Top 10 program and MBA in Business Analytics from Top 50. A lot of the roles at tech companies/large startups that I&amp;#39;m targeting appeared geared towards product data science. I&amp;#39;d like to hear from data scientists currently working in product roles:&lt;/p&gt;\n\n&lt;p&gt;- How to stand out in terms of past experience, projects, resume, interview, etc?&lt;/p&gt;\n\n&lt;p&gt;- What does a &amp;quot;product&amp;quot; data scientist do day to day? Is this customer analytics, pricing, A/B testing, forecasting, data mining, etc?&lt;/p&gt;\n\n&lt;p&gt;- What type of specific skills are you looking for outside of the core data science skillset?&lt;/p&gt;\n\n&lt;p&gt;I was think of trying to leverage my MBA and experience working with modelling costs for fighter jets as a &amp;quot;product&amp;quot;, but I&amp;#39;m not sure if it&amp;#39;s directly applicable, especially with regards to customer behavior.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist MS|MBA ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17le04v", "is_robot_indexable": true, "report_reasons": null, "author": "DJAlaskaAndrew", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17le04v/how_to_be_competitive_for_a_product_data/", "subreddit_subscribers": 1108337, "created_utc": 1698850684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks\n\nFor the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work\n\n[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)\n\nhope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metabase, PowerBI and Gooddata capabilities: A comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8xdt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698833994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks&lt;/p&gt;\n\n&lt;p&gt;For the ones of you who manage dashboards or semantic models in UI tools, here&amp;#39;s an article describing 3 popular tools and their capabilities at doing this work&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dlthub.com/docs/blog/semantic-modeling-tools-comparison\"&gt;https://dlthub.com/docs/blog/semantic-modeling-tools-comparison&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;hope you enjoy the read and if you&amp;#39;d like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?auto=webp&amp;s=baf5edae6ead07395e7b0f4f43b416bb4f7d2663", "width": 1017, "height": 502}, "resolutions": [{"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aad7f0d66da3e4f493a2e586874be97a7eef7ef2", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8721a71c23b0248f369ee7e7bb3470111e9c6c2", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d45554e342882523cb3df4a37ebe617641870400", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2114b9c84fbc85f25e822d69742996f6aca22f1e", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7699e43df6a105dd859147cd6d4e730ee0deb64", "width": 960, "height": 473}], "variants": {}, "id": "8jYk58ZKnFHJb47ZtO42qbrIKmGGyqQijmsQllfJlw4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17l8xdt", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17l8xdt/metabase_powerbi_and_gooddata_capabilities_a/", "subreddit_subscribers": 1108337, "created_utc": 1698833994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks! I\u2019m building a classification model using LSTM many-to-one because my data is sequential in nature. My input dimensions are (50000, 12, 100) to encompass 50000 users, 12 months, and 100 features. So far it\u2019s performing super poorly. How do I ensure that each input individually reads each user\u2019s 12 months data separate from the other. Meaning that 1:50000 are treated independently and ensure non-overlapping in model training.", "author_fullname": "t2_9nb63fwi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSTM many-to-one classification question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l0xaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698801978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks! I\u2019m building a classification model using LSTM many-to-one because my data is sequential in nature. My input dimensions are (50000, 12, 100) to encompass 50000 users, 12 months, and 100 features. So far it\u2019s performing super poorly. How do I ensure that each input individually reads each user\u2019s 12 months data separate from the other. Meaning that 1:50000 are treated independently and ensure non-overlapping in model training.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17l0xaq", "is_robot_indexable": true, "report_reasons": null, "author": "dogsdogsdogsdogswooo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17l0xaq/lstm_manytoone_classification_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17l0xaq/lstm_manytoone_classification_question/", "subreddit_subscribers": 1108337, "created_utc": 1698801978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ll compile answers and write an article with the summary", "author_fullname": "t2_dif6b393", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Describe the analytics tool of your dreams\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kvn2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698787019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll compile answers and write an article with the summary&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kvn2f", "is_robot_indexable": true, "report_reasons": null, "author": "ExpressOcelot8977", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/", "subreddit_subscribers": 1108337, "created_utc": 1698787019.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been watching his videos for a while now and being a beginner, I assumed he was pretty good.\n\nHowever, I've seen a few people criticise him for not knowing what he's talking about, and that he's only good for absolute beginners.", "author_fullname": "t2_cs54hyd66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Krish Naik?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3gak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been watching his videos for a while now and being a beginner, I assumed he was pretty good.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve seen a few people criticise him for not knowing what he&amp;#39;s talking about, and that he&amp;#39;s only good for absolute beginners.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17l3gak", "is_robot_indexable": true, "report_reasons": null, "author": "Mission-Language8789", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17l3gak/thoughts_on_krish_naik/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17l3gak/thoughts_on_krish_naik/", "subreddit_subscribers": 1108337, "created_utc": 1698810020.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}