{"kind": "Listing", "data": {"after": "t3_17kyfng", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4axt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "House Speaker deleted his podcast. Hoarders to the rescue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17krv41", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 1905, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 1905, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uvTH9T91fGpH0ezEYyJiofKRjFdA-3IdaXllbRIhq9M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698777103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jo7at0rg0lxb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jo7at0rg0lxb1.jpg?auto=webp&amp;s=4602c332cf9034751b0d8f19c8eb3bab8fe6b090", "width": 535, "height": 767}, "resolutions": [{"url": "https://preview.redd.it/jo7at0rg0lxb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=465345bc3f725d4f06d8d86cf23550e448181673", "width": 108, "height": 154}, {"url": "https://preview.redd.it/jo7at0rg0lxb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b6bc686085d9403fd096bf7a7d03b00b5bac791", "width": 216, "height": 309}, {"url": "https://preview.redd.it/jo7at0rg0lxb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2b798e51e51d372bd8cd6b462fca2a99e0bca14", "width": 320, "height": 458}], "variants": {}, "id": "r0WGUPjd0FhehKIcUOJIb3YTx1NdTYp90vaOq7txZXg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": true, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17krv41", "is_robot_indexable": true, "report_reasons": null, "author": "harrro", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17krv41/house_speaker_deleted_his_podcast_hoarders_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jo7at0rg0lxb1.jpg", "subreddit_subscribers": 709801, "created_utc": 1698777103.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.reddit.com/r/DataHoarder/comments/n2w3dr/how\\_to\\_get\\_wd\\_firmware\\_updates/](https://www.reddit.com/r/DataHoarder/comments/n2w3dr/how_to_get_wd_firmware_updates/)\n\nThere was a thread about this, and besides what was said there, I wanted to add something relevant for this subreddit, because only after contacting WD I was able to solve it. After I received their 2 TB NVME SSD, DASHBOARD (their software) updated the firmware, it was an easy process, and after that, random BSODs stopped for good, with Windows 11. Also, the drive is said to be fine with CrystalDiskINFO.\n\nBut, after recent updates, DASHBOARD stopped detecting the SSD. Then, the ticket sent me a few steps which solved the issue:\n\n[https://community.wd.com/t/wd-dashboard-no-longer-recognizes-sn850x-2-tb-nvme-drive/286317/14](https://community.wd.com/t/wd-dashboard-no-longer-recognizes-sn850x-2-tb-nvme-drive/286317/14)\n\nIt's important to post this here, because updating these SSDs is really needed to avoid further problems. Also, if you own a Samsung SSD (like the 980 or 990 Pro), check this ASAP because a few of these will DIE soon if you don't update the FW:\n\n[https://www.tomshardware.com/news/samsung-980-pro-ssd-failures-firmware-update](https://www.tomshardware.com/news/samsung-980-pro-ssd-failures-firmware-update)\n\nI avoided buying NVME from Samsung for that reason. The 990 Pro was said here in DATAHOARDER to experience performance issues:\n\n[https://www.reddit.com/r/buildapc/comments/11p9svz/samsung\\_990\\_pro\\_2tb\\_performance\\_is\\_slow/](https://www.reddit.com/r/buildapc/comments/11p9svz/samsung_990_pro_2tb_performance_is_slow/)\n\nFor Samsung, install their MAGICIAN software.\n\nHere is a link for WD DASHBOARD:  \n[https://support-en.wd.com/app/answers/detailweb/a\\_id/31759/initiator/user](https://support-en.wd.com/app/answers/detailweb/a_id/31759/initiator/user)\n\nAnd MAGICIAN: [https://semiconductor.samsung.com/consumer-storage/magician/](https://semiconductor.samsung.com/consumer-storage/magician/)\n\nI also updated my motherboard (BIOS), in my case it's the MSI Z590-A Pro.\n\nFrom Samsung I only purchased their 4 TB regular SSD. The reason I didn't get the 4 TB NVME from WD was because the price was/still is more than twice what they are asking for the 2 TB version.", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Important: How to get Western Digital firmware updates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17krvhp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698777130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/n2w3dr/how_to_get_wd_firmware_updates/\"&gt;https://www.reddit.com/r/DataHoarder/comments/n2w3dr/how_to_get_wd_firmware_updates/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There was a thread about this, and besides what was said there, I wanted to add something relevant for this subreddit, because only after contacting WD I was able to solve it. After I received their 2 TB NVME SSD, DASHBOARD (their software) updated the firmware, it was an easy process, and after that, random BSODs stopped for good, with Windows 11. Also, the drive is said to be fine with CrystalDiskINFO.&lt;/p&gt;\n\n&lt;p&gt;But, after recent updates, DASHBOARD stopped detecting the SSD. Then, the ticket sent me a few steps which solved the issue:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://community.wd.com/t/wd-dashboard-no-longer-recognizes-sn850x-2-tb-nvme-drive/286317/14\"&gt;https://community.wd.com/t/wd-dashboard-no-longer-recognizes-sn850x-2-tb-nvme-drive/286317/14&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s important to post this here, because updating these SSDs is really needed to avoid further problems. Also, if you own a Samsung SSD (like the 980 or 990 Pro), check this ASAP because a few of these will DIE soon if you don&amp;#39;t update the FW:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.tomshardware.com/news/samsung-980-pro-ssd-failures-firmware-update\"&gt;https://www.tomshardware.com/news/samsung-980-pro-ssd-failures-firmware-update&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I avoided buying NVME from Samsung for that reason. The 990 Pro was said here in DATAHOARDER to experience performance issues:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/buildapc/comments/11p9svz/samsung_990_pro_2tb_performance_is_slow/\"&gt;https://www.reddit.com/r/buildapc/comments/11p9svz/samsung_990_pro_2tb_performance_is_slow/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For Samsung, install their MAGICIAN software.&lt;/p&gt;\n\n&lt;p&gt;Here is a link for WD DASHBOARD:&lt;br/&gt;\n&lt;a href=\"https://support-en.wd.com/app/answers/detailweb/a_id/31759/initiator/user\"&gt;https://support-en.wd.com/app/answers/detailweb/a_id/31759/initiator/user&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And MAGICIAN: &lt;a href=\"https://semiconductor.samsung.com/consumer-storage/magician/\"&gt;https://semiconductor.samsung.com/consumer-storage/magician/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I also updated my motherboard (BIOS), in my case it&amp;#39;s the MSI Z590-A Pro.&lt;/p&gt;\n\n&lt;p&gt;From Samsung I only purchased their 4 TB regular SSD. The reason I didn&amp;#39;t get the 4 TB NVME from WD was because the price was/still is more than twice what they are asking for the 2 TB version.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17krvhp", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17krvhp/important_how_to_get_western_digital_firmware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17krvhp/important_how_to_get_western_digital_firmware/", "subreddit_subscribers": 709801, "created_utc": 1698777130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found this list: https://github.com/meichthys/foss_photo_libraries/tree/main\n\nWhich seems to be only a year old. I've also installed PhotoPrism and the jury is still out because there's gaping holes and issues I don't know if I can resolve.\n\nMy focus is not on storage or I'd just do NextCloud. I want all the bells and whistles. Good face detection, scene and object detection / TensorFlow, reverse geocoding with an API like MapBox, automatic album and filenames using machine learning.\n\nI was really hoping there would be one obvious front-runner.", "author_fullname": "t2_nv9mx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bleeding-edge Self-Hosted Photo software in 2023? I'm talking AI-powered, Docker-friendly, open source, etc...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l7230", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698825271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found this list: &lt;a href=\"https://github.com/meichthys/foss_photo_libraries/tree/main\"&gt;https://github.com/meichthys/foss_photo_libraries/tree/main&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Which seems to be only a year old. I&amp;#39;ve also installed PhotoPrism and the jury is still out because there&amp;#39;s gaping holes and issues I don&amp;#39;t know if I can resolve.&lt;/p&gt;\n\n&lt;p&gt;My focus is not on storage or I&amp;#39;d just do NextCloud. I want all the bells and whistles. Good face detection, scene and object detection / TensorFlow, reverse geocoding with an API like MapBox, automatic album and filenames using machine learning.&lt;/p&gt;\n\n&lt;p&gt;I was really hoping there would be one obvious front-runner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17l7230", "is_robot_indexable": true, "report_reasons": null, "author": "malachi347", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l7230/bleedingedge_selfhosted_photo_software_in_2023_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l7230/bleedingedge_selfhosted_photo_software_in_2023_im/", "subreddit_subscribers": 709801, "created_utc": 1698825271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "SSDs self-encrypting drives can be bought with two sorts of Opal standard: Opalite and Pyrite. The further is obvious: it implies the data is encrypted but Pyrite has no such requirement.\n\nWhat is your practice? Is the data actually at least partially \u201esafe\u201d from people trying to breach the local stuff by a screwdriver?", "author_fullname": "t2_2wyahov1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD Opalite vs. Pyrite", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17krmeh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698776490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SSDs self-encrypting drives can be bought with two sorts of Opal standard: Opalite and Pyrite. The further is obvious: it implies the data is encrypted but Pyrite has no such requirement.&lt;/p&gt;\n\n&lt;p&gt;What is your practice? Is the data actually at least partially \u201esafe\u201d from people trying to breach the local stuff by a screwdriver?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17krmeh", "is_robot_indexable": true, "report_reasons": null, "author": "eRIZpl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17krmeh/ssd_opalite_vs_pyrite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17krmeh/ssd_opalite_vs_pyrite/", "subreddit_subscribers": 709801, "created_utc": 1698776490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am switching from a Synology with 8 drive bays to a server with 24 drive bays to up my data hoarding game. [This](https://www.servercase.co.uk/shop/server-cases/rackmount/4u-chassis/4u-server-case-w-24x-35-hot-swappable-satasas-drive-bays-12g-backplane-sc-4324/) is the chassis I will be using. There appear to be 6 backplanes, each of which drive 4 drives. What I am unsure of is how to connect that to my system. I understand I should probably be using an HBA card, I see a lot of recommendations for the LSI 9211-8i, but I only see 2 ports on that, is that sufficient? If not which hba card should I be going for? Also which cables will I need to connect it to the backplanes? Oh also I am using the [Gigabyte Z790 Aorus Elite AX, Intel Z790 Motherboard](https://www.amazon.co.uk/dp/B0BH28M64J?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details) if that matters for this question. Thanks in advance!", "author_fullname": "t2_417t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some advice with HBA card and cables.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l92dm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698834941.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698834598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am switching from a Synology with 8 drive bays to a server with 24 drive bays to up my data hoarding game. &lt;a href=\"https://www.servercase.co.uk/shop/server-cases/rackmount/4u-chassis/4u-server-case-w-24x-35-hot-swappable-satasas-drive-bays-12g-backplane-sc-4324/\"&gt;This&lt;/a&gt; is the chassis I will be using. There appear to be 6 backplanes, each of which drive 4 drives. What I am unsure of is how to connect that to my system. I understand I should probably be using an HBA card, I see a lot of recommendations for the LSI 9211-8i, but I only see 2 ports on that, is that sufficient? If not which hba card should I be going for? Also which cables will I need to connect it to the backplanes? Oh also I am using the &lt;a href=\"https://www.amazon.co.uk/dp/B0BH28M64J?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details\"&gt;Gigabyte Z790 Aorus Elite AX, Intel Z790 Motherboard&lt;/a&gt; if that matters for this question. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?auto=webp&amp;s=cc1290301fa7f3bd493ccc284409c3e5f30ab017", "width": 1024, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6fdfbe029bf8446131197eabcc9b2ac7fa3f13b7", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd493e717e05880dc5683f5c2545724752620188", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b437b86b3d759167b06eec0bd7852d5c99252f5f", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fe7c3d62562f65eb4b0fa3c37011aa9970ad68e", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5a2f43b6d3bae8d99be957d758ddafa61eeb5c86", "width": 960, "height": 720}], "variants": {}, "id": "KycaFLy5iFQEXScOKN6TrtxSMGr4MVNhNdnzL2-2lRE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l92dm", "is_robot_indexable": true, "report_reasons": null, "author": "Spaztic_monkey", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l92dm/need_some_advice_with_hba_card_and_cables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l92dm/need_some_advice_with_hba_card_and_cables/", "subreddit_subscribers": 709801, "created_utc": 1698834598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey so, I just passed the 30TB mark but I need more storage. Can anyone reccomend me a SATA hub or docking bay for more HDDs? I already maxed out the slots in my server case. And specifically NOT USB 3.0 bays. I want them to act like actual drives and I feel like USB would slow them down way too much for my liking.", "author_fullname": "t2_g14at", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone reccomend me a SATA HDD HUB/BAY?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l88yp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698830981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so, I just passed the 30TB mark but I need more storage. Can anyone reccomend me a SATA hub or docking bay for more HDDs? I already maxed out the slots in my server case. And specifically NOT USB 3.0 bays. I want them to act like actual drives and I feel like USB would slow them down way too much for my liking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l88yp", "is_robot_indexable": true, "report_reasons": null, "author": "Firefoxray", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l88yp/can_someone_reccomend_me_a_sata_hdd_hubbay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l88yp/can_someone_reccomend_me_a_sata_hdd_hubbay/", "subreddit_subscribers": 709801, "created_utc": 1698830981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone.  Figured this would be the best place for this seemingly simple question.  I have a home arcade and I was wondering where best to store my ROMs?  I find myself constantly trying new OS\u2019s and don\u2019t mind spending a weekend going all in, but eventually I will find exactly what I want and will settle.  So my question is, in terms of just ROM storage, does it matter between an SSD or a USB?", "author_fullname": "t2_m3v42azt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD vs. USB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kx4cl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698790963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.  Figured this would be the best place for this seemingly simple question.  I have a home arcade and I was wondering where best to store my ROMs?  I find myself constantly trying new OS\u2019s and don\u2019t mind spending a weekend going all in, but eventually I will find exactly what I want and will settle.  So my question is, in terms of just ROM storage, does it matter between an SSD or a USB?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17kx4cl", "is_robot_indexable": true, "report_reasons": null, "author": "Meechiemon76", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17kx4cl/ssd_vs_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17kx4cl/ssd_vs_usb/", "subreddit_subscribers": 709801, "created_utc": 1698790963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Where can i learn facts about HDD head movement?\n\nMost information I get is clueless consumers scaring each other and telling stories of failing drives (which could very well be the case i'm in)\n\nWe just moved offices and our main NAS (RAID1 of WD 10TB gold drives) started to display constant head movement that i can hear easily. Almost like clicking of death, but more \"contained\".  not so loud and just under 1s interval.\n\nWe do have daily/biweekly backup besides the RAID1. But since we were semi-offline for the office move we have some data there that is not on the (paused) daily snapshots. Which i don't want to tell users they lost. This sound very amateur, because it is :) non-profit and all.\n\nThe host is linux 6.5. I'm using only two disks in read-only mode for now.\n\nEach disk is 10TB but only have 2TB partitions for the linux soft raid (mdadm). In the raid there's a LUKS volume with encryption and inside that a single ext4 partition.\n\neverything shows up perfect. SMART pass with flying colors on short tests. RAID shows healthy status. kernel complains of nothing. But the head movement is driving me crazy scared!\n\nThe drives are mostly idle, but vmstat does show some IO happening. Which i suspect is journal being checked? Is there anyway i can tell the kernel to pause all journal activity to make sure the noise goes away? Or maybe it is a firmware thing?\n\nThe drives are not too old. They are exact same model but different lots. always lived in that raid1. And they were transported in different methods for the move. They are both connected to the same PSU (can this be bad power? would it not show up anywhere?). Data reading bandwidth seems the same as before the move (i.e. during the time without the weird head movement sound).\n\nWhat i'm trying to understand now is if I can take my time getting data out of the drivers which are offline, threat it as a imminent failure case, or don't even bother buying new drives for now and use them as regular till they die as they all do and just keep dropping in new spares in the raid. it's only the fact that all of them started the sound at the same time that leads me to believe it might be something in software/firmware/journal thanks to the time offline instead of hardware failure.", "author_fullname": "t2_vjutt7ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD head movement information", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ldhba", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698849188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where can i learn facts about HDD head movement?&lt;/p&gt;\n\n&lt;p&gt;Most information I get is clueless consumers scaring each other and telling stories of failing drives (which could very well be the case i&amp;#39;m in)&lt;/p&gt;\n\n&lt;p&gt;We just moved offices and our main NAS (RAID1 of WD 10TB gold drives) started to display constant head movement that i can hear easily. Almost like clicking of death, but more &amp;quot;contained&amp;quot;.  not so loud and just under 1s interval.&lt;/p&gt;\n\n&lt;p&gt;We do have daily/biweekly backup besides the RAID1. But since we were semi-offline for the office move we have some data there that is not on the (paused) daily snapshots. Which i don&amp;#39;t want to tell users they lost. This sound very amateur, because it is :) non-profit and all.&lt;/p&gt;\n\n&lt;p&gt;The host is linux 6.5. I&amp;#39;m using only two disks in read-only mode for now.&lt;/p&gt;\n\n&lt;p&gt;Each disk is 10TB but only have 2TB partitions for the linux soft raid (mdadm). In the raid there&amp;#39;s a LUKS volume with encryption and inside that a single ext4 partition.&lt;/p&gt;\n\n&lt;p&gt;everything shows up perfect. SMART pass with flying colors on short tests. RAID shows healthy status. kernel complains of nothing. But the head movement is driving me crazy scared!&lt;/p&gt;\n\n&lt;p&gt;The drives are mostly idle, but vmstat does show some IO happening. Which i suspect is journal being checked? Is there anyway i can tell the kernel to pause all journal activity to make sure the noise goes away? Or maybe it is a firmware thing?&lt;/p&gt;\n\n&lt;p&gt;The drives are not too old. They are exact same model but different lots. always lived in that raid1. And they were transported in different methods for the move. They are both connected to the same PSU (can this be bad power? would it not show up anywhere?). Data reading bandwidth seems the same as before the move (i.e. during the time without the weird head movement sound).&lt;/p&gt;\n\n&lt;p&gt;What i&amp;#39;m trying to understand now is if I can take my time getting data out of the drivers which are offline, threat it as a imminent failure case, or don&amp;#39;t even bother buying new drives for now and use them as regular till they die as they all do and just keep dropping in new spares in the raid. it&amp;#39;s only the fact that all of them started the sound at the same time that leads me to believe it might be something in software/firmware/journal thanks to the time offline instead of hardware failure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ldhba", "is_robot_indexable": true, "report_reasons": null, "author": "DecentTone876", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ldhba/hdd_head_movement_information/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ldhba/hdd_head_movement_information/", "subreddit_subscribers": 709801, "created_utc": 1698849188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I say \"large\" because it's probably crumbs to folks on here but I have roughly 2-3TB of movies and tv shows for my Plex server. Problem is, I have copies of mainly movies scattered between 3-4 computers and I'm finally setting up a dedicated server to consolidate everything. Once I have everything on a single computer, I want to be able to find duplicate movies and shows and keep the higher quality ones. I guess the simplest way would be to toss everything into the same folder and when Windows notifies me of a duplicate, I would just keep which ever file size is bigger which would assume higher quality. I'm hoping to find an application that lets me export video metadata so I can see sizes, bitrate, and resolution so I can 1. delete low quality version then 2. see which of my favorite movies/shows are of low quality so I can eventually get higher quality replacements.  \n  \nI came across MediaInfo but can't tell if it only lets you view video data individually or if it can do a mass export to a csv or something of the like.", "author_fullname": "t2_ceda1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting video metadata of \"large\" collection of movies and tv shows.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lbwxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698844631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I say &amp;quot;large&amp;quot; because it&amp;#39;s probably crumbs to folks on here but I have roughly 2-3TB of movies and tv shows for my Plex server. Problem is, I have copies of mainly movies scattered between 3-4 computers and I&amp;#39;m finally setting up a dedicated server to consolidate everything. Once I have everything on a single computer, I want to be able to find duplicate movies and shows and keep the higher quality ones. I guess the simplest way would be to toss everything into the same folder and when Windows notifies me of a duplicate, I would just keep which ever file size is bigger which would assume higher quality. I&amp;#39;m hoping to find an application that lets me export video metadata so I can see sizes, bitrate, and resolution so I can 1. delete low quality version then 2. see which of my favorite movies/shows are of low quality so I can eventually get higher quality replacements.  &lt;/p&gt;\n\n&lt;p&gt;I came across MediaInfo but can&amp;#39;t tell if it only lets you view video data individually or if it can do a mass export to a csv or something of the like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lbwxz", "is_robot_indexable": true, "report_reasons": null, "author": "inthemix8080", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lbwxz/exporting_video_metadata_of_large_collection_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lbwxz/exporting_video_metadata_of_large_collection_of/", "subreddit_subscribers": 709801, "created_utc": 1698844631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI just flashed a 9300-8i to IT mode, but it only shows one disk properly (sda), and one disk as 0B (sdb) (in proxmox).  This is the same/similar regardless of which combination of 8 drives, 2 cables, 2 ports I use - always only one disk reporting a size, up to three additional disks reporting 0B, and no disks ever showing under sas3ircu.\n\nAnyone have any ideas what's going on?\n\n\\# lsblk:\n\n    NAME               MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\n    sda                  8:0    0   1.5T  0 disk\n    \u251c\u2500sda1               8:1    0   1.5T  0 part\n    \u2514\u2500sda9               8:9    0     8M  0 part\n    sdb                  8:16   0     0B  0 disk\n    nvme3n1            259:0    0 931.5G  0 disk\n    \u251c\u2500nvme3n1p1        259:1    0  1007K  0 part\n    \u251c\u2500nvme3n1p2        259:2    0     1G  0 part /boot/efi\n    \u2514\u2500nvme3n1p3        259:3    0 930.5G  0 part\n      \u251c\u2500pve-swap       253:0    0     8G  0 lvm  [SWAP]\n      \u251c\u2500pve-root       253:1    0    96G  0 lvm  /\n      \u251c\u2500pve-data_tmeta 253:2    0   8.1G  0 lvm \n      \u2502 \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n      \u2514\u2500pve-data_tdata 253:3    0 794.3G  0 lvm \n        \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n    nvme0n1            259:4    0 931.5G  0 disk\n    \u251c\u2500nvme0n1p1        259:5    0 931.5G  0 part\n    \u2514\u2500nvme0n1p9        259:6    0     8M  0 part\n    nvme1n1            259:7    0 931.5G  0 disk\n    \u251c\u2500nvme1n1p1        259:8    0 931.5G  0 part\n    \u2514\u2500nvme1n1p9        259:9    0     8M  0 part\n    nvme2n1            259:10   0   1.5T  0 disk\n\n\\# sas3ircu 0 display\n\n    Avago Technologies SAS3 IR Configuration Utility.\n    Version 17.00.00.00 (2018.04.02)\n    Copyright (c) 2009-2018 Avago Technologies. All rights reserved.\n    \n    Read configuration has been initiated for controller 0\n    ------------------------------------------------------------------------\n    Controller information\n    ------------------------------------------------------------------------\n      Controller type                         : SAS3008\n      BIOS version                            : 8.37.00.00\n      Firmware version                        : 16.00.10.00\n      Channel description                     : 1 Serial Attached SCSI\n      Initiator ID                            : 0\n      Maximum physical devices                : 1023\n      Concurrent commands supported           : 9856\n      Slot                                    : 24\n      Segment                                 : 0\n      Bus                                     : 3\n      Device                                  : 0\n      Function                                : 0\n      RAID Support                            : No\n    ------------------------------------------------------------------------\n    IR Volume information\n    ------------------------------------------------------------------------\n    ------------------------------------------------------------------------\n    Physical device information\n    ------------------------------------------------------------------------\n    ------------------------------------------------------------------------\n    Enclosure information\n    ------------------------------------------------------------------------\n      Enclosure#                              : 1\n      Logical ID                              : 500605b0:0b2c9b80\n      Numslots                                : 8\n      StartSlot                               : 0\n    ------------------------------------------------------------------------\n    SAS3IRCU: Command DISPLAY Completed Successfully.\n    SAS3IRCU: Utility Completed Successfully.\n\n\\# sas3flash -c 0 -list\n\n    Avago Technologies SAS3 Flash Utility\n    Version 16.00.00.00 (2017.05.02) \n    Copyright 2008-2017 Avago Technologies. All rights reserved.\n    \n            Adapter Selected is a Avago SAS: SAS3008(C0)\n    \n            Controller Number              : 0\n            Controller                     : SAS3008(C0)\n            PCI Address                    : 00:03:00:00\n            SAS Address                    : 500605b-0-0b2c-9b80\n            NVDATA Version (Default)       : 0e.01.00.07\n            NVDATA Version (Persistent)    : 0e.01.00.07\n            Firmware Product ID            : 0x2221 (IT)\n            Firmware Version               : 16.00.10.00\n            NVDATA Vendor                  : LSI\n            NVDATA Product ID              : SAS9300-8i\n            BIOS Version                   : 08.37.00.00\n            UEFI BSD Version               : 18.00.00.00\n            FCODE Version                  : N/A\n            Board Name                     : SAS9300-8i\n            Board Assembly                 : N/A\n            Board Tracer Number            : N/A\n    \n            Finished Processing Commands Successfully.\n            Exiting SAS3Flash.\n\n\\# lspci\n\n    03:00.0 Serial Attached SCSI controller: Broadcom / LSI SAS3008 PCI-Express Fusion-MPT SAS-3 (rev 02)\n\n&amp;#x200B;", "author_fullname": "t2_qz8xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17la0xl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698840023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698838408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I just flashed a 9300-8i to IT mode, but it only shows one disk properly (sda), and one disk as 0B (sdb) (in proxmox).  This is the same/similar regardless of which combination of 8 drives, 2 cables, 2 ports I use - always only one disk reporting a size, up to three additional disks reporting 0B, and no disks ever showing under sas3ircu.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any ideas what&amp;#39;s going on?&lt;/p&gt;\n\n&lt;p&gt;# lsblk:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;NAME               MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nsda                  8:0    0   1.5T  0 disk\n\u251c\u2500sda1               8:1    0   1.5T  0 part\n\u2514\u2500sda9               8:9    0     8M  0 part\nsdb                  8:16   0     0B  0 disk\nnvme3n1            259:0    0 931.5G  0 disk\n\u251c\u2500nvme3n1p1        259:1    0  1007K  0 part\n\u251c\u2500nvme3n1p2        259:2    0     1G  0 part /boot/efi\n\u2514\u2500nvme3n1p3        259:3    0 930.5G  0 part\n  \u251c\u2500pve-swap       253:0    0     8G  0 lvm  [SWAP]\n  \u251c\u2500pve-root       253:1    0    96G  0 lvm  /\n  \u251c\u2500pve-data_tmeta 253:2    0   8.1G  0 lvm \n  \u2502 \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n  \u2514\u2500pve-data_tdata 253:3    0 794.3G  0 lvm \n    \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \nnvme0n1            259:4    0 931.5G  0 disk\n\u251c\u2500nvme0n1p1        259:5    0 931.5G  0 part\n\u2514\u2500nvme0n1p9        259:6    0     8M  0 part\nnvme1n1            259:7    0 931.5G  0 disk\n\u251c\u2500nvme1n1p1        259:8    0 931.5G  0 part\n\u2514\u2500nvme1n1p9        259:9    0     8M  0 part\nnvme2n1            259:10   0   1.5T  0 disk\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# sas3ircu 0 display&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avago Technologies SAS3 IR Configuration Utility.\nVersion 17.00.00.00 (2018.04.02)\nCopyright (c) 2009-2018 Avago Technologies. All rights reserved.\n\nRead configuration has been initiated for controller 0\n------------------------------------------------------------------------\nController information\n------------------------------------------------------------------------\n  Controller type                         : SAS3008\n  BIOS version                            : 8.37.00.00\n  Firmware version                        : 16.00.10.00\n  Channel description                     : 1 Serial Attached SCSI\n  Initiator ID                            : 0\n  Maximum physical devices                : 1023\n  Concurrent commands supported           : 9856\n  Slot                                    : 24\n  Segment                                 : 0\n  Bus                                     : 3\n  Device                                  : 0\n  Function                                : 0\n  RAID Support                            : No\n------------------------------------------------------------------------\nIR Volume information\n------------------------------------------------------------------------\n------------------------------------------------------------------------\nPhysical device information\n------------------------------------------------------------------------\n------------------------------------------------------------------------\nEnclosure information\n------------------------------------------------------------------------\n  Enclosure#                              : 1\n  Logical ID                              : 500605b0:0b2c9b80\n  Numslots                                : 8\n  StartSlot                               : 0\n------------------------------------------------------------------------\nSAS3IRCU: Command DISPLAY Completed Successfully.\nSAS3IRCU: Utility Completed Successfully.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# sas3flash -c 0 -list&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avago Technologies SAS3 Flash Utility\nVersion 16.00.00.00 (2017.05.02) \nCopyright 2008-2017 Avago Technologies. All rights reserved.\n\n        Adapter Selected is a Avago SAS: SAS3008(C0)\n\n        Controller Number              : 0\n        Controller                     : SAS3008(C0)\n        PCI Address                    : 00:03:00:00\n        SAS Address                    : 500605b-0-0b2c-9b80\n        NVDATA Version (Default)       : 0e.01.00.07\n        NVDATA Version (Persistent)    : 0e.01.00.07\n        Firmware Product ID            : 0x2221 (IT)\n        Firmware Version               : 16.00.10.00\n        NVDATA Vendor                  : LSI\n        NVDATA Product ID              : SAS9300-8i\n        BIOS Version                   : 08.37.00.00\n        UEFI BSD Version               : 18.00.00.00\n        FCODE Version                  : N/A\n        Board Name                     : SAS9300-8i\n        Board Assembly                 : N/A\n        Board Tracer Number            : N/A\n\n        Finished Processing Commands Successfully.\n        Exiting SAS3Flash.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# lspci&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;03:00.0 Serial Attached SCSI controller: Broadcom / LSI SAS3008 PCI-Express Fusion-MPT SAS-3 (rev 02)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17la0xl", "is_robot_indexable": true, "report_reasons": null, "author": "SunRoyal", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17la0xl/help_with_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17la0xl/help_with_hba/", "subreddit_subscribers": 709801, "created_utc": 1698838408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nWhats your experience with the Samsung 870 QVO 8TB drive? I plan to buy an Intel NUC tall version, install Jellyfin and use this drive as main storage for my media. I don't expect I will write and delete data too much off of it in this context ...\n\nThanks", "author_fullname": "t2_155ml1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung 870 QVO 8TB - What's your experience with this drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l9nzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698837011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Whats your experience with the Samsung 870 QVO 8TB drive? I plan to buy an Intel NUC tall version, install Jellyfin and use this drive as main storage for my media. I don&amp;#39;t expect I will write and delete data too much off of it in this context ...&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17l9nzl", "is_robot_indexable": true, "report_reasons": null, "author": "mariusmoga_2005", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l9nzl/samsung_870_qvo_8tb_whats_your_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l9nzl/samsung_870_qvo_8tb_whats_your_experience_with/", "subreddit_subscribers": 709801, "created_utc": 1698837011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dear members,\n\nI have a collection of low to medium capacity HDDs (int. &amp; ext.) and SSDs (ext) between 480 GB and 4 TB. Currently, I'm considering building a NAS with those components that does not need to perform exceptionally. Thus, I was considering a RPi 5 with a Quad SATA HAT (currently available only for RPi 4) and a powered USB Hub for powering the HDDs and as a temporary solution for the SATA drives, until a SATA HAT is released for the RPi 5.\n\nMy goal is to have the lowest idle consumption possible and even turn the NAS off for the most part of the day, make use of the components, invest less than 350 bucks and fit it under my bookshelf with a height constraint of 9cm.\n\nWould this be viable at all, or have I not considered some solutions that are less advertised than the RPi articles i.e. DIY solutions?\n\nMuch appreciated!", "author_fullname": "t2_z560y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4x 2.5 SATA HDD, 4x 2.5 USB HDD, 2x 2.5 SATA SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l7rha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698836894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698828709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear members,&lt;/p&gt;\n\n&lt;p&gt;I have a collection of low to medium capacity HDDs (int. &amp;amp; ext.) and SSDs (ext) between 480 GB and 4 TB. Currently, I&amp;#39;m considering building a NAS with those components that does not need to perform exceptionally. Thus, I was considering a RPi 5 with a Quad SATA HAT (currently available only for RPi 4) and a powered USB Hub for powering the HDDs and as a temporary solution for the SATA drives, until a SATA HAT is released for the RPi 5.&lt;/p&gt;\n\n&lt;p&gt;My goal is to have the lowest idle consumption possible and even turn the NAS off for the most part of the day, make use of the components, invest less than 350 bucks and fit it under my bookshelf with a height constraint of 9cm.&lt;/p&gt;\n\n&lt;p&gt;Would this be viable at all, or have I not considered some solutions that are less advertised than the RPi articles i.e. DIY solutions?&lt;/p&gt;\n\n&lt;p&gt;Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l7rha", "is_robot_indexable": true, "report_reasons": null, "author": "mhmilo24", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l7rha/4x_25_sata_hdd_4x_25_usb_hdd_2x_25_sata_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l7rha/4x_25_sata_hdd_4x_25_usb_hdd_2x_25_sata_ssd/", "subreddit_subscribers": 709801, "created_utc": 1698828709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to up my unraid array. Do they usually do good Black Friday deals. How many of you are satisfied with their refurb drives?", "author_fullname": "t2_5j15m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ServerPartsDeals good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kypgv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698795388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to up my unraid array. Do they usually do good Black Friday deals. How many of you are satisfied with their refurb drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17kypgv", "is_robot_indexable": true, "report_reasons": null, "author": "halfam", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17kypgv/serverpartsdeals_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17kypgv/serverpartsdeals_good/", "subreddit_subscribers": 709801, "created_utc": 1698795388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've read that changing the name of data disks in Snapraid is tolerated. However to my understanding changing the order of data drives in the Snapraid config will cause issues with parity.\n\nFor example when replacing two smaller disks for one larger 18TB HDD, I run into the issue:\n\nData Disks:\n\n&gt;*d1-Exos10tb (this drive to be replaced with larger HDD)*  \n&gt;  \n&gt;*d2-Exos-8tb  (drive also to be replaced with same large HDD from above)*  \n&gt;  \n&gt;*d3-Exos20tb*  \n&gt;  \n&gt;*d4-Exos16tb*  \n&gt;  \n&gt;*d5-Exos14tb*\n\nI wish to replace d1 and d2 with one large HDD. How would I go about this operation?\n\nIf I just assign the new larger data disk as d1, what would happen to d2 and the the drives listed after it? Should I comment out the d2 line until I utilize that position with another drive, preserving the following disk's order? Or is there a better way to go about this?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reordering Data Drives in Snapraid config?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kv0ov", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698785409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read that changing the name of data disks in Snapraid is tolerated. However to my understanding changing the order of data drives in the Snapraid config will cause issues with parity.&lt;/p&gt;\n\n&lt;p&gt;For example when replacing two smaller disks for one larger 18TB HDD, I run into the issue:&lt;/p&gt;\n\n&lt;p&gt;Data Disks:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;d1-Exos10tb (this drive to be replaced with larger HDD)&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;d2-Exos-8tb  (drive also to be replaced with same large HDD from above)&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;d3-Exos20tb&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;d4-Exos16tb&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;d5-Exos14tb&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I wish to replace d1 and d2 with one large HDD. How would I go about this operation?&lt;/p&gt;\n\n&lt;p&gt;If I just assign the new larger data disk as d1, what would happen to d2 and the the drives listed after it? Should I comment out the d2 line until I utilize that position with another drive, preserving the following disk&amp;#39;s order? Or is there a better way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17kv0ov", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17kv0ov/reordering_data_drives_in_snapraid_config/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17kv0ov/reordering_data_drives_in_snapraid_config/", "subreddit_subscribers": 709801, "created_utc": 1698785409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "this might be a silly question, but during the twitter link search, am i able to click confirm and start downloading before it's done, or will that cut off any of the posts that haven't been grabbed yet? \n\ni saw a post about manual crawling that said it's fine to do and that it'll add the rest of the media into a second batch later - but i've never used this before and i don't wanna waste the last half hour i've spent waiting for the search to be over just to have to do it all over again lol", "author_fullname": "t2_121h3iip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confirming WFDownloader Link Search Before Complete?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kzxxr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698798997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;this might be a silly question, but during the twitter link search, am i able to click confirm and start downloading before it&amp;#39;s done, or will that cut off any of the posts that haven&amp;#39;t been grabbed yet? &lt;/p&gt;\n\n&lt;p&gt;i saw a post about manual crawling that said it&amp;#39;s fine to do and that it&amp;#39;ll add the rest of the media into a second batch later - but i&amp;#39;ve never used this before and i don&amp;#39;t wanna waste the last half hour i&amp;#39;ve spent waiting for the search to be over just to have to do it all over again lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17kzxxr", "is_robot_indexable": true, "report_reasons": null, "author": "food_WHOREder", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17kzxxr/confirming_wfdownloader_link_search_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17kzxxr/confirming_wfdownloader_link_search_before/", "subreddit_subscribers": 709801, "created_utc": 1698798997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All\n\nHope you're all doing great.\n\nI have an existing array of 8 x 3TB (RAID 6) giving me 17TB. \n\nI just got 10 refurbished but tested 8TB SAS drives cheap as hell on Ebay so this gives quite an increase in array size (although still tiny compared to some of you lot!). :-)\n\nI would go 8 x 8TB RAID 6, with the final two drives sitting on a shelf, just in case.\n\nI've toyed with `ZFS` in the past but it seemed overkill for me. When I retired my old ReadyNAS, I found that they were using `mdam`, `lvm` and `btrfs`. So, I copied this setup thinking that if it was good enough for them, it would be fine for me. So, `mdadm` handles the raw RAID part, `lvm` to make things flexible and then `btrfs` as the filesystem.\n\nIn the 5 years I've had the existing array, I have had no problems. Maybe one failed drive but changing and updating was straightforward.\n\nShould I stick with what works?\n\nOr is it time to change it up? I guess I will be using this for the next 5 years or so.\n\nI am hosting the array on a Proxmox install on an `Intel X10SDV` platform with 64GB ECC RAM, `Qlogic dual SFP+ nic`, an `LSI SAS2008  HBA` and an HBA Expander to give me plenty of internal ports (which will help with the data migration which I guess will be a weekend or so of rsync). I'm using a PCIE splitter taking my single PCIE 3 x8 to two PCIE 3 x 4, which seems to be working well. So, I get 5GT/S and x4 for each of the cards (Qlogic 10G NIC and HBA).\n\nMy performance requirements are modest - just some video streaming to probably no more than a couple of concurrent users.  I also use the storage as a dump for my homelab.\n\nI don't really care if I lose any data beyond the protection of RAID 6. My precious stuff like photos etc  is backed up in multiple places in the cloud.\n\n\nOpinions are welcome!\n\nThanks in advance", "author_fullname": "t2_3g5lg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sanity check please? Migrating to a new array. Should I stick with mdadm, lvm and btrfs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17knbst", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698765793.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698765210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All&lt;/p&gt;\n\n&lt;p&gt;Hope you&amp;#39;re all doing great.&lt;/p&gt;\n\n&lt;p&gt;I have an existing array of 8 x 3TB (RAID 6) giving me 17TB. &lt;/p&gt;\n\n&lt;p&gt;I just got 10 refurbished but tested 8TB SAS drives cheap as hell on Ebay so this gives quite an increase in array size (although still tiny compared to some of you lot!). :-)&lt;/p&gt;\n\n&lt;p&gt;I would go 8 x 8TB RAID 6, with the final two drives sitting on a shelf, just in case.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve toyed with &lt;code&gt;ZFS&lt;/code&gt; in the past but it seemed overkill for me. When I retired my old ReadyNAS, I found that they were using &lt;code&gt;mdam&lt;/code&gt;, &lt;code&gt;lvm&lt;/code&gt; and &lt;code&gt;btrfs&lt;/code&gt;. So, I copied this setup thinking that if it was good enough for them, it would be fine for me. So, &lt;code&gt;mdadm&lt;/code&gt; handles the raw RAID part, &lt;code&gt;lvm&lt;/code&gt; to make things flexible and then &lt;code&gt;btrfs&lt;/code&gt; as the filesystem.&lt;/p&gt;\n\n&lt;p&gt;In the 5 years I&amp;#39;ve had the existing array, I have had no problems. Maybe one failed drive but changing and updating was straightforward.&lt;/p&gt;\n\n&lt;p&gt;Should I stick with what works?&lt;/p&gt;\n\n&lt;p&gt;Or is it time to change it up? I guess I will be using this for the next 5 years or so.&lt;/p&gt;\n\n&lt;p&gt;I am hosting the array on a Proxmox install on an &lt;code&gt;Intel X10SDV&lt;/code&gt; platform with 64GB ECC RAM, &lt;code&gt;Qlogic dual SFP+ nic&lt;/code&gt;, an &lt;code&gt;LSI SAS2008  HBA&lt;/code&gt; and an HBA Expander to give me plenty of internal ports (which will help with the data migration which I guess will be a weekend or so of rsync). I&amp;#39;m using a PCIE splitter taking my single PCIE 3 x8 to two PCIE 3 x 4, which seems to be working well. So, I get 5GT/S and x4 for each of the cards (Qlogic 10G NIC and HBA).&lt;/p&gt;\n\n&lt;p&gt;My performance requirements are modest - just some video streaming to probably no more than a couple of concurrent users.  I also use the storage as a dump for my homelab.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really care if I lose any data beyond the protection of RAID 6. My precious stuff like photos etc  is backed up in multiple places in the cloud.&lt;/p&gt;\n\n&lt;p&gt;Opinions are welcome!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17knbst", "is_robot_indexable": true, "report_reasons": null, "author": "wawawawa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17knbst/sanity_check_please_migrating_to_a_new_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17knbst/sanity_check_please_migrating_to_a_new_array/", "subreddit_subscribers": 709801, "created_utc": 1698765210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI started building my own media server about two months ago. By now, I've amassed around 600 movies, mostly ripped DVDs and Blu-rays from my collection. I'm currently using Jellyfin.\n\nUnfortunately, I wasn't very experienced with video encoding before, so I had to learn about it along the way.\n\nRegrettably, I converted a large portion of the .mkv files to .mp4 using Handbrake, using H.265 for encoding.\n\n&amp;#x200B;\n\nNow, I've realized that my server starts live transcoding every time I stream these movies. I didn't realize that seemingly very few devices support H.265. This issue doesn't occur with H.264.\n\n&amp;#x200B;\n\nIf I had known this beforehand, I would have encoded the files directly in H.264.\n\n&amp;#x200B;\n\nNow I'm considering re-transcoding all the files that are encoded in H.265. Is there a significant loss of quality in doing so?\n\n&amp;#x200B;\n\nOf course, I've organized all the files in the folder structure recommended by Jellyfin. Is there a quick method to sort out the 600 movies that are encoded in H.265?\n\n&amp;#x200B;\n\nIs what I'm planning to do perhaps unnecessary? In that case, I'll leave the files as they are. If so, I could also forego transcoding in the future and simply remux the .mkv files to .mp4 without transcoding, even though they'd use MPEG codecs for DVDs. Or I might just leave them as they are in the .mkv format.", "author_fullname": "t2_a24rhwsb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing My Media Server: H.265 to H.264 Conversion Dilemma", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ldtp6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698850188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I started building my own media server about two months ago. By now, I&amp;#39;ve amassed around 600 movies, mostly ripped DVDs and Blu-rays from my collection. I&amp;#39;m currently using Jellyfin.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, I wasn&amp;#39;t very experienced with video encoding before, so I had to learn about it along the way.&lt;/p&gt;\n\n&lt;p&gt;Regrettably, I converted a large portion of the .mkv files to .mp4 using Handbrake, using H.265 for encoding.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;ve realized that my server starts live transcoding every time I stream these movies. I didn&amp;#39;t realize that seemingly very few devices support H.265. This issue doesn&amp;#39;t occur with H.264.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I had known this beforehand, I would have encoded the files directly in H.264.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m considering re-transcoding all the files that are encoded in H.265. Is there a significant loss of quality in doing so?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Of course, I&amp;#39;ve organized all the files in the folder structure recommended by Jellyfin. Is there a quick method to sort out the 600 movies that are encoded in H.265?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is what I&amp;#39;m planning to do perhaps unnecessary? In that case, I&amp;#39;ll leave the files as they are. If so, I could also forego transcoding in the future and simply remux the .mkv files to .mp4 without transcoding, even though they&amp;#39;d use MPEG codecs for DVDs. Or I might just leave them as they are in the .mkv format.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ldtp6", "is_robot_indexable": true, "report_reasons": null, "author": "Mikrogeophagus-rami", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ldtp6/optimizing_my_media_server_h265_to_h264/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ldtp6/optimizing_my_media_server_h265_to_h264/", "subreddit_subscribers": 709801, "created_utc": 1698850188.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just received notice that iDrive is \"upgrading\" my plan and bumping my price yet again. I just saw there is a promotion in place for new users of 5$/10TB for the first year. I am tempted of not renewing my plan, setting up a new account (different name and credit card), and take advantage of this promotion, or for reasons I don't foresee it won't work. Opinions?", "author_fullname": "t2_p3757", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "create a new iDrive account to take advantage of promotions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lb9rv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698842663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just received notice that iDrive is &amp;quot;upgrading&amp;quot; my plan and bumping my price yet again. I just saw there is a promotion in place for new users of 5$/10TB for the first year. I am tempted of not renewing my plan, setting up a new account (different name and credit card), and take advantage of this promotion, or for reasons I don&amp;#39;t foresee it won&amp;#39;t work. Opinions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lb9rv", "is_robot_indexable": true, "report_reasons": null, "author": "Bib_fortune", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lb9rv/create_a_new_idrive_account_to_take_advantage_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lb9rv/create_a_new_idrive_account_to_take_advantage_of/", "subreddit_subscribers": 709801, "created_utc": 1698842663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there. \nI'm thinking of getting/making a home NAS/Server/Jellyfin. \nI already have an old pc with a i5-6600k, GTX1060, 550w PSU just laying around and I'm trying to understand if it will be enough for it. \nThe other options I saw was getting a Synology or making a Pi_NAS. \nI'm afraid that the PC will consume much more energy than the other 2 options. \nWhat do you guys think?", "author_fullname": "t2_5syc5zdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old PC vs NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17labiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698839483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. \nI&amp;#39;m thinking of getting/making a home NAS/Server/Jellyfin. \nI already have an old pc with a i5-6600k, GTX1060, 550w PSU just laying around and I&amp;#39;m trying to understand if it will be enough for it. \nThe other options I saw was getting a Synology or making a Pi_NAS. \nI&amp;#39;m afraid that the PC will consume much more energy than the other 2 options. \nWhat do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17labiv", "is_robot_indexable": true, "report_reasons": null, "author": "Serigaita", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17labiv/old_pc_vs_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17labiv/old_pc_vs_nas/", "subreddit_subscribers": 709801, "created_utc": 1698839483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to download all data, or at least just the videos from a particular Twitter account. Anyone know of ways of doing this?", "author_fullname": "t2_6gi594yt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help Downloading all Data from a Twitter Account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17la5vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698838924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to download all data, or at least just the videos from a particular Twitter account. Anyone know of ways of doing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17la5vr", "is_robot_indexable": true, "report_reasons": null, "author": "Radiant_Help", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17la5vr/need_help_downloading_all_data_from_a_twitter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17la5vr/need_help_downloading_all_data_from_a_twitter/", "subreddit_subscribers": 709801, "created_utc": 1698838924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there! I just recently added a few more drives to my array in Windows Storage Spaces. I re-formatted the volume with 128KB cluster size to get around the 14.4TB volume limit, and then it let me expand it to the new capacity. Afterwards, it's showing my partition size correctly but is still showing a capacity of 14.4TB in Disk Management as well as Explorer. Any ideas?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2yvzfhs0xnxb1.png?width=673&amp;format=png&amp;auto=webp&amp;s=c7b48de5379ad5a4663f9d6a5adbeffc55d130aa\n\n&amp;#x200B;\n\nhttps://preview.redd.it/p8g1jrxzwnxb1.png?width=743&amp;format=png&amp;auto=webp&amp;s=9a1c64e7178a05b06f3eda5b552acd48a0e27f88\n\nhttps://preview.redd.it/nefufwmewnxb1.png?width=1822&amp;format=png&amp;auto=webp&amp;s=80d978c429ccced233e360687ba710648b15e081", "author_fullname": "t2_vhzy2v09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Volume Storage doesn't add up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 29, "top_awarded_type": null, "hide_score": false, "media_metadata": {"p8g1jrxzwnxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/p8g1jrxzwnxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aaa3f15d59a94f5078f7ae6f52f61fcfea749727"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/p8g1jrxzwnxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=17008aa99c82309a2e581edb7ad0808cbf2572aa"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/p8g1jrxzwnxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=027270e30e3d9363ef3791313180c7ab8cf8702c"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/p8g1jrxzwnxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e70e8658f43bb3bf4a394581bc961b70d3986295"}], "s": {"y": 524, "x": 743, "u": "https://preview.redd.it/p8g1jrxzwnxb1.png?width=743&amp;format=png&amp;auto=webp&amp;s=9a1c64e7178a05b06f3eda5b552acd48a0e27f88"}, "id": "p8g1jrxzwnxb1"}, "nefufwmewnxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=205125c7b98fe75d5608b6186a3ed75940eb7a54"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6dc46a8874a436614b5d1b8c225c5e76f1045d3a"}, {"y": 139, "x": 320, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1211c5a5ec7d4d45f6cbf7d58f5a6daa82d2471"}, {"y": 279, "x": 640, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6e07bcaebed55da9eef87c726748989f36dfd73"}, {"y": 419, "x": 960, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d40670d9477444e162cb3bd423e8750d8ea1fdbb"}, {"y": 471, "x": 1080, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7a0acd24943bbc9c98d4654d658791ed645fbe36"}], "s": {"y": 796, "x": 1822, "u": "https://preview.redd.it/nefufwmewnxb1.png?width=1822&amp;format=png&amp;auto=webp&amp;s=80d978c429ccced233e360687ba710648b15e081"}, "id": "nefufwmewnxb1"}, "2yvzfhs0xnxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 22, "x": 108, "u": "https://preview.redd.it/2yvzfhs0xnxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7becd83834435ff46cd9be6cecea20ec9dd6d6c1"}, {"y": 45, "x": 216, "u": "https://preview.redd.it/2yvzfhs0xnxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=14414c1d3584873fad87c2c9590c568ef418a27e"}, {"y": 67, "x": 320, "u": "https://preview.redd.it/2yvzfhs0xnxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b5103d4918c1e8269207b2804a88125034110244"}, {"y": 134, "x": 640, "u": "https://preview.redd.it/2yvzfhs0xnxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=929a177e1a488eda84ad56c4612419b16c20f8f2"}], "s": {"y": 141, "x": 673, "u": "https://preview.redd.it/2yvzfhs0xnxb1.png?width=673&amp;format=png&amp;auto=webp&amp;s=c7b48de5379ad5a4663f9d6a5adbeffc55d130aa"}, "id": "2yvzfhs0xnxb1"}}, "name": "t3_17l42hr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JjAlbwkS-BFWGrRGQRWMNOUZP1LZwQ-XzQIYyq_k0Ac.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698812271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I just recently added a few more drives to my array in Windows Storage Spaces. I re-formatted the volume with 128KB cluster size to get around the 14.4TB volume limit, and then it let me expand it to the new capacity. Afterwards, it&amp;#39;s showing my partition size correctly but is still showing a capacity of 14.4TB in Disk Management as well as Explorer. Any ideas?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2yvzfhs0xnxb1.png?width=673&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7b48de5379ad5a4663f9d6a5adbeffc55d130aa\"&gt;https://preview.redd.it/2yvzfhs0xnxb1.png?width=673&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7b48de5379ad5a4663f9d6a5adbeffc55d130aa&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/p8g1jrxzwnxb1.png?width=743&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a1c64e7178a05b06f3eda5b552acd48a0e27f88\"&gt;https://preview.redd.it/p8g1jrxzwnxb1.png?width=743&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9a1c64e7178a05b06f3eda5b552acd48a0e27f88&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nefufwmewnxb1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d978c429ccced233e360687ba710648b15e081\"&gt;https://preview.redd.it/nefufwmewnxb1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80d978c429ccced233e360687ba710648b15e081&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l42hr", "is_robot_indexable": true, "report_reasons": null, "author": "EmiSkyye", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l42hr/volume_storage_doesnt_add_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l42hr/volume_storage_doesnt_add_up/", "subreddit_subscribers": 709801, "created_utc": 1698812271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have to check a lot of photo's DPI and it would be easier to do if the photos dpi could be seen in the window folder bottom horizontal bar. Right clicking to check in Properties is too tedious.  Anyone know of a software that can do this?", "author_fullname": "t2_3cakgqxg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm looking for software that can show the dpi of photos in the windows folder bottom horizontal bar.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l4k56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698814191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to check a lot of photo&amp;#39;s DPI and it would be easier to do if the photos dpi could be seen in the window folder bottom horizontal bar. Right clicking to check in Properties is too tedious.  Anyone know of a software that can do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l4k56", "is_robot_indexable": true, "report_reasons": null, "author": "lobster455", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l4k56/im_looking_for_software_that_can_show_the_dpi_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l4k56/im_looking_for_software_that_can_show_the_dpi_of/", "subreddit_subscribers": 709801, "created_utc": 1698814191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know of a tool that downloads from Usenet with prowlarr or jackett and then provides the files as a download from your own server? Preferably with automatic deletion after a few days? ", "author_fullname": "t2_88u1dju4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "*arr interated downloader", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ks6um", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698777940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know of a tool that downloads from Usenet with prowlarr or jackett and then provides the files as a download from your own server? Preferably with automatic deletion after a few days? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ks6um", "is_robot_indexable": true, "report_reasons": null, "author": "Shwunce", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ks6um/arr_interated_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ks6um/arr_interated_downloader/", "subreddit_subscribers": 709801, "created_utc": 1698777940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to follow a blogger www.aordisco.com - It seems inactive in its original form, and a few years ago it vanished due to a copywrite stake or legal action, I just checked to see if I could recover any content and found to my surprise it has reappeared. It features a wealth of info regarding 70-80s music and as I followed the weekly posts I built an iTunes playlist - which I later lost.\n\nI\u2019m currently rebuilding the playlist from info on every page, it\u2019s rather tedious.  I archived the whole site with sitesucker as html.\n\nTLDR is there a way to extract the text from html archive to a single text file or similar.", "author_fullname": "t2_e2qbpp4j5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HTML to Word (Sitesucker)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l4qn5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698814906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to follow a blogger &lt;a href=\"http://www.aordisco.com\"&gt;www.aordisco.com&lt;/a&gt; - It seems inactive in its original form, and a few years ago it vanished due to a copywrite stake or legal action, I just checked to see if I could recover any content and found to my surprise it has reappeared. It features a wealth of info regarding 70-80s music and as I followed the weekly posts I built an iTunes playlist - which I later lost.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently rebuilding the playlist from info on every page, it\u2019s rather tedious.  I archived the whole site with sitesucker as html.&lt;/p&gt;\n\n&lt;p&gt;TLDR is there a way to extract the text from html archive to a single text file or similar.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pL83ETuQ753jTdC2ucaLrUODjbxwRbMKVSlAj4vxMms.jpg?auto=webp&amp;s=60c69b3b474140fa8021af42d38f982e1e4eb7ab", "width": 283, "height": 291}, "resolutions": [{"url": "https://external-preview.redd.it/pL83ETuQ753jTdC2ucaLrUODjbxwRbMKVSlAj4vxMms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b03381ba30876afcd01ac5deedcefc654809f80b", "width": 108, "height": 111}, {"url": "https://external-preview.redd.it/pL83ETuQ753jTdC2ucaLrUODjbxwRbMKVSlAj4vxMms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=627a7c06d5f00877f359a861f90f119b46acad09", "width": 216, "height": 222}], "variants": {}, "id": "HZA4U9Fp30On0HfLnPisfqsfofhkaCRYwlfKd4E0qdY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l4qn5", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded-Cold495", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l4qn5/html_to_word_sitesucker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l4qn5/html_to_word_sitesucker/", "subreddit_subscribers": 709801, "created_utc": 1698814906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I saw a good offer for a used ssd, and I wonder if the SMART data can be spoofed.", "author_fullname": "t2_bcn2i6g6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to manipulate SSD SMART data ( like resetting the TBW value)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kyfng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698794625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw a good offer for a used ssd, and I wonder if the SMART data can be spoofed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17kyfng", "is_robot_indexable": true, "report_reasons": null, "author": "A5623", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17kyfng/is_it_possible_to_manipulate_ssd_smart_data_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17kyfng/is_it_possible_to_manipulate_ssd_smart_data_like/", "subreddit_subscribers": 709801, "created_utc": 1698794625.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}