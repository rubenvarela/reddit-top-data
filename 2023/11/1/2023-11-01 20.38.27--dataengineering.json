{"kind": "Listing", "data": {"after": "t3_17la7ao", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For 25 years, I never fired anyone.  And yet, this is the third guy I've fired in the last 18 months.  Granted, I wasn't the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made *zero* effort to integrate into the organisation.\n\nAre we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don't need to make any kind of effort anymore?  Do they think they can just \"wing it\"?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?\n\nI feel like shit, because as much as this guy only has himself to blame, I'm still turfing him out in November, in a shitty, shitty job market.", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So I had to fire a guy today...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l0elt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 86, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 86, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698800401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For 25 years, I never fired anyone.  And yet, this is the third guy I&amp;#39;ve fired in the last 18 months.  Granted, I wasn&amp;#39;t the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made &lt;em&gt;zero&lt;/em&gt; effort to integrate into the organisation.&lt;/p&gt;\n\n&lt;p&gt;Are we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don&amp;#39;t need to make any kind of effort anymore?  Do they think they can just &amp;quot;wing it&amp;quot;?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?&lt;/p&gt;\n\n&lt;p&gt;I feel like shit, because as much as this guy only has himself to blame, I&amp;#39;m still turfing him out in November, in a shitty, shitty job market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l0elt", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 93, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "subreddit_subscribers": 137350, "created_utc": 1698800401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.", "author_fullname": "t2_ymrlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do organisations use abbreviations for table and field names that don't save much space and reduce clarity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l1crr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698803337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l1crr", "is_robot_indexable": true, "report_reasons": null, "author": "NightflowerFade", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "subreddit_subscribers": 137350, "created_utc": 1698803337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nIn my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.\n\nWe don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. \n\nI\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? \n\ni turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.\n\nThank you in advance :)", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8eu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;In my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.&lt;/p&gt;\n\n&lt;p&gt;We don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? &lt;/p&gt;\n\n&lt;p&gt;i turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l8eu6", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "subreddit_subscribers": 137350, "created_utc": 1698831740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a Sr DE, but basically I\u2019m a SWE/dev ops/DE in reality, got 10+ YOE. My main current focus at work is creation of DE infrastructure and custom ETL frameworks that make other engineers life\u2019s easier and solve incredible large scale problems of infrastructure (the last one for example was how to filter data sets 700 billion records in a couple of seconds with high concurrency). I also have what I think are good SA skills focused on cost reduction on AWS.\n\nMy day to day is mostly CDK (typescript), Python (vanilla and spark) and googling weird stuff that happens at our scale. Manager great, team is great, I actually really like my job.\n\nHowever\u2026 I still work for someone and I\u2019m subject to dumb corporate decisions. Just a number to anyone above my manager. I am very seriously thinking about going into consulting and make my own business focused on AWS security, cost reduction and data engineering automations.\n\nIs this a stupid thought? Has anyone gone successfully into consulting? How tough is it out there? Is it more profitable?", "author_fullname": "t2_dt2eqjvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kwk0b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698789416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a Sr DE, but basically I\u2019m a SWE/dev ops/DE in reality, got 10+ YOE. My main current focus at work is creation of DE infrastructure and custom ETL frameworks that make other engineers life\u2019s easier and solve incredible large scale problems of infrastructure (the last one for example was how to filter data sets 700 billion records in a couple of seconds with high concurrency). I also have what I think are good SA skills focused on cost reduction on AWS.&lt;/p&gt;\n\n&lt;p&gt;My day to day is mostly CDK (typescript), Python (vanilla and spark) and googling weird stuff that happens at our scale. Manager great, team is great, I actually really like my job.&lt;/p&gt;\n\n&lt;p&gt;However\u2026 I still work for someone and I\u2019m subject to dumb corporate decisions. Just a number to anyone above my manager. I am very seriously thinking about going into consulting and make my own business focused on AWS security, cost reduction and data engineering automations.&lt;/p&gt;\n\n&lt;p&gt;Is this a stupid thought? Has anyone gone successfully into consulting? How tough is it out there? Is it more profitable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17kwk0b", "is_robot_indexable": true, "report_reasons": null, "author": "ksco92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kwk0b/going_into_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kwk0b/going_into_consulting/", "subreddit_subscribers": 137350, "created_utc": 1698789416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks, I'm on a team of \"full-stack\" analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp; analysis.\n\nWe don't have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We've had to constantly  push our infrastructure and modelling projects month after month because there's a constant influx of request from stakeholders.\n\nIs this a problem for you guys? What are you doing to address it?", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how many analytics engineers here work on ad-hoc SQL requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfb8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698854219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks, I&amp;#39;m on a team of &amp;quot;full-stack&amp;quot; analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp;amp; analysis.&lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We&amp;#39;ve had to constantly  push our infrastructure and modelling projects month after month because there&amp;#39;s a constant influx of request from stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Is this a problem for you guys? What are you doing to address it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfb8v", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "subreddit_subscribers": 137350, "created_utc": 1698854219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title.\n\nAt work, the non-coding people are telling me it's redundant to save the data first to a .csv, and I should just load it from there.\n\nI'm not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.\n\nIt's not as if exctracting data and saving it to a .csv is an Herculean task...", "author_fullname": "t2_mnoei525n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using an API, should I load the data directly to a database, or should I just clean the data, save it as .csvs in blob storage and then load my data from the .csvs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ld440", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698848144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title.&lt;/p&gt;\n\n&lt;p&gt;At work, the non-coding people are telling me it&amp;#39;s redundant to save the data first to a .csv, and I should just load it from there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not as if exctracting data and saving it to a .csv is an Herculean task...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ld440", "is_robot_indexable": true, "report_reasons": null, "author": "peroqueteniaquever", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "subreddit_subscribers": 137350, "created_utc": 1698848144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!", "author_fullname": "t2_c85rlf9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Meta Virtual Onsite interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3nzl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3nzl", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle_Restaurant_35", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "subreddit_subscribers": 137350, "created_utc": 1698810819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering community,\n\nI'm in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I'm feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.\n\nFor those who have been through this journey, I have a few questions:\n\n1. To what extent should I be practicing Python problems on Leetcode for a data engineering role?\n2. What specific topics or areas should be my primary focus?\n3. During your interviews, which Python-related topics were emphasized the most?\n\nAny insights or guidance would be greatly appreciated! Thanks in advance.", "author_fullname": "t2_5u73tpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How deep or advanced should my Python knowledge be when practicing on Leetcode for a Data Engineering role? Which difficulty levels of problems are most relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3hjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I&amp;#39;m feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.&lt;/p&gt;\n\n&lt;p&gt;For those who have been through this journey, I have a few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To what extent should I be practicing Python problems on Leetcode for a data engineering role?&lt;/li&gt;\n&lt;li&gt;What specific topics or areas should be my primary focus?&lt;/li&gt;\n&lt;li&gt;During your interviews, which Python-related topics were emphasized the most?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any insights or guidance would be greatly appreciated! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3hjb", "is_robot_indexable": true, "report_reasons": null, "author": "arcofiero", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "subreddit_subscribers": 137350, "created_utc": 1698810142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.\n\nThese guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.\n\nNowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d\n\nSomething like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.\n\nSo that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?\n\n\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you do when you joined an organization with some serious data problems, and you needed to introduce structure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kztbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698799438.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698798618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.&lt;/p&gt;\n\n&lt;p&gt;These guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.&lt;/p&gt;\n\n&lt;p&gt;Nowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d&lt;/p&gt;\n\n&lt;p&gt;Something like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.&lt;/p&gt;\n\n&lt;p&gt;So that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?&lt;/p&gt;\n\n&lt;p&gt;\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kztbm", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "subreddit_subscribers": 137350, "created_utc": 1698798618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. \n\nNow the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. \n\nI am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. \n\nI was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. \n\nAnyone have any advice or thoughts?", "author_fullname": "t2_bbmo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GIT and environments in a data context", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l4v87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698830665.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698815394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. &lt;/p&gt;\n\n&lt;p&gt;Now the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. &lt;/p&gt;\n\n&lt;p&gt;I am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. &lt;/p&gt;\n\n&lt;p&gt;I was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any advice or thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l4v87", "is_robot_indexable": true, "report_reasons": null, "author": "cursedbartender", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "subreddit_subscribers": 137350, "created_utc": 1698815394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its **free** for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  \n\n\n[https://www.amazon.com/dp/B0CM85Q7YJ](https://www.amazon.com/dp/B0CM85Q7YJ)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free eBook on Acing the Data Engineering Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17le6tc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698851150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its &lt;strong&gt;free&lt;/strong&gt; for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0CM85Q7YJ\"&gt;https://www.amazon.com/dp/B0CM85Q7YJ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17le6tc", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "subreddit_subscribers": 137350, "created_utc": 1698851150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE's\n\nI am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.\n\nNo I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.\n\n1. I need to check if I can join tables on some join key and every record match:\n2. I need to check if every column values in source are exactly the same as in target column\n\nSo my idea is to do something like this:\n\n1. Read DWH table with Spark (source table)\n2. Read DataLake table with Spark (target table)\n3. Add prefix to source table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n4. Add prefix to target table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n5. Use join\\_key to left join table:  e.g:   source\\_table\\['source\\_join\\_key'\\] == target\\_table\\['target\\_join\\_key'\\]\n6. Use this combined table to run great expectations\n   1. check if tables properly joined: expect\\_column\\_values\\_to\\_not\\_be\\_null(column='target\\_join\\_key')\n   2. check if column in source is the same as column in target  \nfor every column pair from source and target do the check:  \nexpect\\_column\\_pair\\_values\\_to\\_be\\_equal(  \n column\\_A=source\\_column\\_a, column\\_B=target\\_column\\_b)  \n\n\nGreat expectations is something new to me. Do you think my ideas is good or is there a better way ?  \nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.\n\n  \n", "author_fullname": "t2_2llofc3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great expectations -&gt; how to compare 2 dafarames", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l89wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE&amp;#39;s&lt;/p&gt;\n\n&lt;p&gt;I am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.&lt;/p&gt;\n\n&lt;p&gt;No I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I need to check if I can join tables on some join key and every record match:&lt;/li&gt;\n&lt;li&gt;I need to check if every column values in source are exactly the same as in target column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So my idea is to do something like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read DWH table with Spark (source table)&lt;/li&gt;\n&lt;li&gt;Read DataLake table with Spark (target table)&lt;/li&gt;\n&lt;li&gt;Add prefix to source table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Add prefix to target table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Use join_key to left join table:  e.g:   source_table[&amp;#39;source_join_key&amp;#39;] == target_table[&amp;#39;target_join_key&amp;#39;]&lt;/li&gt;\n&lt;li&gt;Use this combined table to run great expectations\n\n&lt;ol&gt;\n&lt;li&gt;check if tables properly joined: expect_column_values_to_not_be_null(column=&amp;#39;target_join_key&amp;#39;)&lt;/li&gt;\n&lt;li&gt;check if column in source is the same as column in target&lt;br/&gt;\nfor every column pair from source and target do the check:&lt;br/&gt;\nexpect_column_pair_values_to_be_equal(&lt;br/&gt;\ncolumn_A=source_column_a, column_B=target_column_b)&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Great expectations is something new to me. Do you think my ideas is good or is there a better way ?&lt;br/&gt;\nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l89wn", "is_robot_indexable": true, "report_reasons": null, "author": "masek94", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "subreddit_subscribers": 137350, "created_utc": 1698831087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Nov 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1698854452.916, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfedu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698854452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?auto=webp&amp;s=f31fa9903d75d67fdf7aa466dc59b353580baab5", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d07b02ea6d52e510a89eebac3220c5380d16a142", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ffdf2cc7f4c7114208ab8b1d725d8b597246398", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17088c4844a3ddeb97d8b7a5cbe0f0bb49f04088", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1d617569fa501370336b415c3779b4906b139b24", "width": 640, "height": 333}], "variants": {}, "id": "VINWZoaUoDSGoJqMz7V286sj1fgBznndF5gxkCuKIxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfedu", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "subreddit_subscribers": 137350, "created_utc": 1698854452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for \"full stack\" analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).\n\nI've been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.\n\nThe implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I've worked with some of these people before and they're wicked smart.\n\nBesides my story and any advice you'd provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What other roles would you entertain beyond DE and SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17leyt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698853293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for &amp;quot;full stack&amp;quot; analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.&lt;/p&gt;\n\n&lt;p&gt;The implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I&amp;#39;ve worked with some of these people before and they&amp;#39;re wicked smart.&lt;/p&gt;\n\n&lt;p&gt;Besides my story and any advice you&amp;#39;d provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17leyt8", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "subreddit_subscribers": 137350, "created_utc": 1698853293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipelines for Data Products: Key Components, Recommended Tools, and Fundamental Development Concepts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17l97g9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EIv6gRw0P89sEDCK4NSudJaEodcyodm-X3JW9F6OKvM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698835195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?auto=webp&amp;s=b25f887df718c4bb01b0cfed6817176eb521e590", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4bfdb31befcbbe7483e6f726d778f8e9b313d06", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac59763b5c2e199b7f0510593e9b60059274698f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd9cccbfff8962388ed92c9415979a31979db949", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79e68330249124713e23b85e86d0d373585ca011", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b0c6d1642261a80c5cdc619f6c5c8085d93dccb6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ebabeea51e10cd32fcbcd0e82e32fda98459aade", "width": 1080, "height": 540}], "variants": {}, "id": "08ytc-6p-5bmF7Vj6nq-fUR0LEM5son5wQBs-pHIOBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17l97g9", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l97g9/data_pipelines_for_data_products_key_components/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "subreddit_subscribers": 137350, "created_utc": 1698835195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, We have some requirements to move transaction data(10's of Billions of rows/day and 24/7 streaming, majority would be INSERT and few of them will be Updates/deletes too), which gets generated from on-premise Oracle database. This data needs to be moved to AWS snowflake data lake(which going to serve our reporting and analytics need). And we want this to happen as real time streaming i.e kind of real time data replication from on-premise to the cloud. And team is planning to use below data pipeline model\n\nOracle GGS(Golden gate replicats) --&gt; Kafka--&gt; Event extractor--&gt; S3 Raw --&gt; Delta lake curation+ refiner--&gt; Snowflake\n\nBut from the test this seems going to take lot of time i.e. 3-4hrs lag between the generation of data at source and reaching the snowflake. So wanted to understand , what other possible strategies we can follow to skip all these hops and move data to snowflake efficiently in quick time without so many hops? \n\njust to note- \"Event extractor\" is used because there is another application which is based on cloud and is based on micro-services/event based architecture , and that sends events to the snowflake in same route. So at snowflake basically we consolidate data from both the on-premise and the cloud native app.", "author_fullname": "t2_awgfwfxot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Continuous data streaming from on premise to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kwzt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698790613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, We have some requirements to move transaction data(10&amp;#39;s of Billions of rows/day and 24/7 streaming, majority would be INSERT and few of them will be Updates/deletes too), which gets generated from on-premise Oracle database. This data needs to be moved to AWS snowflake data lake(which going to serve our reporting and analytics need). And we want this to happen as real time streaming i.e kind of real time data replication from on-premise to the cloud. And team is planning to use below data pipeline model&lt;/p&gt;\n\n&lt;p&gt;Oracle GGS(Golden gate replicats) --&amp;gt; Kafka--&amp;gt; Event extractor--&amp;gt; S3 Raw --&amp;gt; Delta lake curation+ refiner--&amp;gt; Snowflake&lt;/p&gt;\n\n&lt;p&gt;But from the test this seems going to take lot of time i.e. 3-4hrs lag between the generation of data at source and reaching the snowflake. So wanted to understand , what other possible strategies we can follow to skip all these hops and move data to snowflake efficiently in quick time without so many hops? &lt;/p&gt;\n\n&lt;p&gt;just to note- &amp;quot;Event extractor&amp;quot; is used because there is another application which is based on cloud and is based on micro-services/event based architecture , and that sends events to the snowflake in same route. So at snowflake basically we consolidate data from both the on-premise and the cloud native app.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kwzt1", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Length9755", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kwzt1/continuous_data_streaming_from_on_premise_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kwzt1/continuous_data_streaming_from_on_premise_to_cloud/", "subreddit_subscribers": 137350, "created_utc": 1698790613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if anyone has done the Meta Infra DE Onsite in the last year or so. There\u2019s tons of info on Reddit and Blind about the Product Analytics onsite and even which questions are asked but haven\u2019t seen any about the Infra one. And if there are any about Infra, they are 2+ years old. If anyone has gone through the onsite, could you give guidance on the Python/Coding portion as well as a the System Design/End to End portion? These are the two I\u2019m most concerned about and hoping someone could help give info on the topics/questions/how to prepare. Thanks in advance :)", "author_fullname": "t2_ghqh5w6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta Infra DE Onsite Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lc9um", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698845704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if anyone has done the Meta Infra DE Onsite in the last year or so. There\u2019s tons of info on Reddit and Blind about the Product Analytics onsite and even which questions are asked but haven\u2019t seen any about the Infra one. And if there are any about Infra, they are 2+ years old. If anyone has gone through the onsite, could you give guidance on the Python/Coding portion as well as a the System Design/End to End portion? These are the two I\u2019m most concerned about and hoping someone could help give info on the topics/questions/how to prepare. Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17lc9um", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Sprinkles8216", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lc9um/meta_infra_de_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lc9um/meta_infra_de_onsite_interview/", "subreddit_subscribers": 137350, "created_utc": 1698845704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Whats a Data Product per your definition and how does it differ from a Data Asset?", "author_fullname": "t2_c45r2mfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Product Definition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8vv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698833808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whats a Data Product per your definition and how does it differ from a Data Asset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l8vv3", "is_robot_indexable": true, "report_reasons": null, "author": "Head_Ad_5511", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8vv3/data_product_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8vv3/data_product_definition/", "subreddit_subscribers": 137350, "created_utc": 1698833808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I have a grid example (below, taken from [https://covjson.org/playground/](https://covjson.org/playground/) ) in which an XYZt array is specified.\n\nThe axes are specified in the domain, the values are stored in a 1 dimensional array with a given shape of the axes.\n\nI need to write a function that gets the Sea Ice Concentration (ICEC) parameter at a specific location at a specific time.\n\nHowever my brain cannot comprehend how to extract the correct value using the \"shape\", \"axisNames\" and  \"values\" from the \"ranges\" object. On the web I can only find examples for non-CoverageJSON files.\n\nThe (pseudo) code:\n\n    float result = getICECValue(x: -5, y: 40, z: 5, t: \"2010-01-01T00:12:20Z\");\n    \n    func getICECValue(x: float, y: float, z: float, t: DateTime) {\n       // what goes here?\n    }\n\nAny help is greatly appreciated.\n\nThe data:\n\n    {\n      \"type\" : \"Coverage\",\n      \"domain\" : {\n        \"type\" : \"Domain\",\n        \"domainType\" : \"Grid\",\n        \"axes\": {\n          \"x\" : { \"values\": [-10,-5,0] },\n          \"y\" : { \"values\": [40,50] },\n          \"z\" : { \"values\": [ 5] },\n          \"t\" : { \"values\": [\"2010-01-01T00:12:20Z\"] }\n        },\n        \"referencing\": [{\n          \"coordinates\": [\"y\",\"x\",\"z\"],\n          \"system\": {\n            \"type\": \"GeographicCRS\",\n            \"id\": \"http://www.opengis.net/def/crs/EPSG/0/4979\"\n          }\n        }, {\n          \"coordinates\": [\"t\"],\n          \"system\": {\n            \"type\": \"TemporalRS\",\n            \"calendar\": \"Gregorian\"\n          }\n        }]\n      },\n      \"parameters\" : {\n        \"ICEC\": {\n          \"type\" : \"Parameter\",\n          \"description\": {\n          \t\"en\": \"Sea Ice concentration (ice=1;no ice=0)\"\n          },\n          \"unit\" : {\n            \"label\": {\n              \"en\": \"Ratio\"\n            },\n            \"symbol\": {\n              \"value\": \"1\",\n              \"type\": \"http://www.opengis.net/def/uom/UCUM/\"\n            }\n          },\n          \"observedProperty\" : {\n            \"id\" : \"http://vocab.nerc.ac.uk/standard_name/sea_ice_area_fraction/\",\n            \"label\" : {\n              \"en\": \"Sea Ice Concentration\"\n            }\n          }\n        }\n      },\n      \"ranges\" : {\n        \"ICEC\" : {\n          \"type\" : \"NdArray\",\n          \"dataType\": \"float\",\n          \"axisNames\": [\"t\",\"z\",\"y\",\"x\"],\n          \"shape\": [1, 1, 2, 3],\n          \"values\" : [ 0.5, 0.6, 0.4, 0.6, 0.2, null ]\n        }\n      }\n    }\n\n&amp;#x200B;", "author_fullname": "t2_knlbfd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CoverageJSON: How to get values from an XYZt NdArray?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ljxh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698866446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a grid example (below, taken from &lt;a href=\"https://covjson.org/playground/\"&gt;https://covjson.org/playground/&lt;/a&gt; ) in which an XYZt array is specified.&lt;/p&gt;\n\n&lt;p&gt;The axes are specified in the domain, the values are stored in a 1 dimensional array with a given shape of the axes.&lt;/p&gt;\n\n&lt;p&gt;I need to write a function that gets the Sea Ice Concentration (ICEC) parameter at a specific location at a specific time.&lt;/p&gt;\n\n&lt;p&gt;However my brain cannot comprehend how to extract the correct value using the &amp;quot;shape&amp;quot;, &amp;quot;axisNames&amp;quot; and  &amp;quot;values&amp;quot; from the &amp;quot;ranges&amp;quot; object. On the web I can only find examples for non-CoverageJSON files.&lt;/p&gt;\n\n&lt;p&gt;The (pseudo) code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;float result = getICECValue(x: -5, y: 40, z: 5, t: &amp;quot;2010-01-01T00:12:20Z&amp;quot;);\n\nfunc getICECValue(x: float, y: float, z: float, t: DateTime) {\n   // what goes here?\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Any help is greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;The data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;type&amp;quot; : &amp;quot;Coverage&amp;quot;,\n  &amp;quot;domain&amp;quot; : {\n    &amp;quot;type&amp;quot; : &amp;quot;Domain&amp;quot;,\n    &amp;quot;domainType&amp;quot; : &amp;quot;Grid&amp;quot;,\n    &amp;quot;axes&amp;quot;: {\n      &amp;quot;x&amp;quot; : { &amp;quot;values&amp;quot;: [-10,-5,0] },\n      &amp;quot;y&amp;quot; : { &amp;quot;values&amp;quot;: [40,50] },\n      &amp;quot;z&amp;quot; : { &amp;quot;values&amp;quot;: [ 5] },\n      &amp;quot;t&amp;quot; : { &amp;quot;values&amp;quot;: [&amp;quot;2010-01-01T00:12:20Z&amp;quot;] }\n    },\n    &amp;quot;referencing&amp;quot;: [{\n      &amp;quot;coordinates&amp;quot;: [&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;,&amp;quot;z&amp;quot;],\n      &amp;quot;system&amp;quot;: {\n        &amp;quot;type&amp;quot;: &amp;quot;GeographicCRS&amp;quot;,\n        &amp;quot;id&amp;quot;: &amp;quot;http://www.opengis.net/def/crs/EPSG/0/4979&amp;quot;\n      }\n    }, {\n      &amp;quot;coordinates&amp;quot;: [&amp;quot;t&amp;quot;],\n      &amp;quot;system&amp;quot;: {\n        &amp;quot;type&amp;quot;: &amp;quot;TemporalRS&amp;quot;,\n        &amp;quot;calendar&amp;quot;: &amp;quot;Gregorian&amp;quot;\n      }\n    }]\n  },\n  &amp;quot;parameters&amp;quot; : {\n    &amp;quot;ICEC&amp;quot;: {\n      &amp;quot;type&amp;quot; : &amp;quot;Parameter&amp;quot;,\n      &amp;quot;description&amp;quot;: {\n        &amp;quot;en&amp;quot;: &amp;quot;Sea Ice concentration (ice=1;no ice=0)&amp;quot;\n      },\n      &amp;quot;unit&amp;quot; : {\n        &amp;quot;label&amp;quot;: {\n          &amp;quot;en&amp;quot;: &amp;quot;Ratio&amp;quot;\n        },\n        &amp;quot;symbol&amp;quot;: {\n          &amp;quot;value&amp;quot;: &amp;quot;1&amp;quot;,\n          &amp;quot;type&amp;quot;: &amp;quot;http://www.opengis.net/def/uom/UCUM/&amp;quot;\n        }\n      },\n      &amp;quot;observedProperty&amp;quot; : {\n        &amp;quot;id&amp;quot; : &amp;quot;http://vocab.nerc.ac.uk/standard_name/sea_ice_area_fraction/&amp;quot;,\n        &amp;quot;label&amp;quot; : {\n          &amp;quot;en&amp;quot;: &amp;quot;Sea Ice Concentration&amp;quot;\n        }\n      }\n    }\n  },\n  &amp;quot;ranges&amp;quot; : {\n    &amp;quot;ICEC&amp;quot; : {\n      &amp;quot;type&amp;quot; : &amp;quot;NdArray&amp;quot;,\n      &amp;quot;dataType&amp;quot;: &amp;quot;float&amp;quot;,\n      &amp;quot;axisNames&amp;quot;: [&amp;quot;t&amp;quot;,&amp;quot;z&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;x&amp;quot;],\n      &amp;quot;shape&amp;quot;: [1, 1, 2, 3],\n      &amp;quot;values&amp;quot; : [ 0.5, 0.6, 0.4, 0.6, 0.2, null ]\n    }\n  }\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ljxh5", "is_robot_indexable": true, "report_reasons": null, "author": "hotdogsoup_nl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ljxh5/coveragejson_how_to_get_values_from_an_xyzt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ljxh5/coveragejson_how_to_get_values_from_an_xyzt/", "subreddit_subscribers": 137350, "created_utc": 1698866446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 2 Postgres databases and need to synchronize a few tables between them, with requirements:\n\n1. Do a few transformations (all are simple, select subset of columns mostly)\n2. Do this real-time or very near real-time (e.g. every 5 minutes is already not acceptable)\n3. Synchronize table schema changes\n4. Solution needs to be open source (we have a large volume of data, with variable loads, and are running highly cost-optimized Kubernetes, both DBs are self-hosted)\n5. Solution needs to be reasonably popular (we've had bad time with new software which died out due to lack of popularity)\n\nSolutions I considered:\n\n1. Logical replication - doesn't propagate schema changes, and would require quite complicated CI/CD (app that manages source DB would have to do transactional change of synchronization in target DB, which is managed by another app)\n2. Airbyte - highest possible frequency is 5 minutes\n3. Meltano - seems to be able to work quite frequently, even every minute, but is still not real time\n4. Most other solutions is only commercially available.\n\nDo you know of any solutions that satisfy those requirements? From my perspective (with limited experience) it sounds like a reasonably typical problem.", "author_fullname": "t2_wounm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Postgres to Postgres real time data + schema sync solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lj8fq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698864613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 Postgres databases and need to synchronize a few tables between them, with requirements:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do a few transformations (all are simple, select subset of columns mostly)&lt;/li&gt;\n&lt;li&gt;Do this real-time or very near real-time (e.g. every 5 minutes is already not acceptable)&lt;/li&gt;\n&lt;li&gt;Synchronize table schema changes&lt;/li&gt;\n&lt;li&gt;Solution needs to be open source (we have a large volume of data, with variable loads, and are running highly cost-optimized Kubernetes, both DBs are self-hosted)&lt;/li&gt;\n&lt;li&gt;Solution needs to be reasonably popular (we&amp;#39;ve had bad time with new software which died out due to lack of popularity)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Solutions I considered:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Logical replication - doesn&amp;#39;t propagate schema changes, and would require quite complicated CI/CD (app that manages source DB would have to do transactional change of synchronization in target DB, which is managed by another app)&lt;/li&gt;\n&lt;li&gt;Airbyte - highest possible frequency is 5 minutes&lt;/li&gt;\n&lt;li&gt;Meltano - seems to be able to work quite frequently, even every minute, but is still not real time&lt;/li&gt;\n&lt;li&gt;Most other solutions is only commercially available.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you know of any solutions that satisfy those requirements? From my perspective (with limited experience) it sounds like a reasonably typical problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lj8fq", "is_robot_indexable": true, "report_reasons": null, "author": "qalis", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lj8fq/postgres_to_postgres_real_time_data_schema_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lj8fq/postgres_to_postgres_real_time_data_schema_sync/", "subreddit_subscribers": 137350, "created_utc": 1698864613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my boss asks me if we are secure, I said yes, but I am 100% confident. So I am curious to know where any gaps might be if any.\n\nOur DW and PBI are behind okta for all users, we only have a few service accounts with full access to the data that we use to transform with. We house our source creds in AWS secrets manager. Access secrets manager via STS. We rotate PW once a year for mostly everything, and outside of snowflake nothing is exposed publicly.\n\nI use airflow to s3 to snowflake to DBT to power bi.\n\nWould love and out side perspective.", "author_fullname": "t2_v6u6a9c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Think about security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lhumb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698860905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my boss asks me if we are secure, I said yes, but I am 100% confident. So I am curious to know where any gaps might be if any.&lt;/p&gt;\n\n&lt;p&gt;Our DW and PBI are behind okta for all users, we only have a few service accounts with full access to the data that we use to transform with. We house our source creds in AWS secrets manager. Access secrets manager via STS. We rotate PW once a year for mostly everything, and outside of snowflake nothing is exposed publicly.&lt;/p&gt;\n\n&lt;p&gt;I use airflow to s3 to snowflake to DBT to power bi.&lt;/p&gt;\n\n&lt;p&gt;Would love and out side perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lhumb", "is_robot_indexable": true, "report_reasons": null, "author": "NexusIO", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lhumb/think_about_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lhumb/think_about_security/", "subreddit_subscribers": 137350, "created_utc": 1698860905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit Community!\n\nI\u2019m a 25-year-old Data Engineer and I would love to get your advice on future career growth and progression.\n\n**Background (During Studies)**\n\n* **Education:** I have a degree in Industrial Engineering and Management. This broad education introduced me to logistics, ergonomics, work safety, statistics, maths, project management, maintenance, programming and many other areas. It has been incredibly useful in enabling me to communicate across people with different engineering fields and provides me with a macro view of business processes.\n* **Entrepreneurial Stint:** I co-founded an association in my hometown and served as its vice president. We managed to secure funding from the local municipality and organized various events, underlining my entrepreneurial spirit.\n* **Internships (2 Years in multiple companies):** While studying, I completed 3 internships focusing on project implementations mostly in logistics, ergonomics assessments, and process mapping with BPMN, and used a lot of Excel.\n\n**Background (After Studies)**\n\n* **Logistics Specialist (1 Year in Company 1):** My role was multifaceted and included leading a project to implement SAP EWM in 2 warehouses. I was responsible for creating user processes, instructions, and conducting training sessions. Additionally, I developed automated workflows using Microsoft Automate and created SharePoint lists and permissions. Data visualization was another strong suit, and I extensively used Power BI for this.\n* **Business Analyst (4-5 Months in Company 2):** In this position, I generated reports for store owners with varying frequencies\u2014daily, weekly, and monthly. My toolbox included Excel, Power Pivot, SSIS, and SSRS.\n* **Data Engineering (8 Months in Company - Currert Role):** I\u2019ve found my niche here as a Data Engineer. Beyond my proficiency in Talend Studio and SQL, I\u2019ve also been responsible for creating a data warehouse and establishing data quality checks. This includes deleting irrelevant data, which has had an impact on reducing monthly costs by 20%. I also created a data cube for customers and automated several tasks using Python. Project management and tracking are handled through Jira. Additionally, my effectiveness in handling projects led my team to cease its collaboration with an external data engineering developer, as I was able to deliver projects faster and with higher quality.\n\n**Future Ambitions**\n\n* **Short-Term (1-2 Years)**: I plan to tackle more complex projects with significant business impact. Leadership of technical teams, potentially starting with interns, is also on my agenda.\n* **Long-Term (5 Years):** A transition into people management roles, overseeing full teams, is what I envision for myself in the long run.\n\nGiven that I currently work in Portugal and have already laid out my short-term and long-term goals, what should be my next steps? What areas should I focus on to make a significant leap in my career? Any advice tailored to the local job market here would also be highly appreciated.\n\n**Would love any advice or insights on achieving these ambitions and considerations for promotion opportunities.**\n\nThank you for reading!", "author_fullname": "t2_imnwscg17", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landed a Data Engineering role, now what? Future Ambitions - Need Career Progression Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lg8xa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698862167.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698856695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit Community!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a 25-year-old Data Engineer and I would love to get your advice on future career growth and progression.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background (During Studies)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Education:&lt;/strong&gt; I have a degree in Industrial Engineering and Management. This broad education introduced me to logistics, ergonomics, work safety, statistics, maths, project management, maintenance, programming and many other areas. It has been incredibly useful in enabling me to communicate across people with different engineering fields and provides me with a macro view of business processes.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Entrepreneurial Stint:&lt;/strong&gt; I co-founded an association in my hometown and served as its vice president. We managed to secure funding from the local municipality and organized various events, underlining my entrepreneurial spirit.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internships (2 Years in multiple companies):&lt;/strong&gt; While studying, I completed 3 internships focusing on project implementations mostly in logistics, ergonomics assessments, and process mapping with BPMN, and used a lot of Excel.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Background (After Studies)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Logistics Specialist (1 Year in Company 1):&lt;/strong&gt; My role was multifaceted and included leading a project to implement SAP EWM in 2 warehouses. I was responsible for creating user processes, instructions, and conducting training sessions. Additionally, I developed automated workflows using Microsoft Automate and created SharePoint lists and permissions. Data visualization was another strong suit, and I extensively used Power BI for this.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Business Analyst (4-5 Months in Company 2):&lt;/strong&gt; In this position, I generated reports for store owners with varying frequencies\u2014daily, weekly, and monthly. My toolbox included Excel, Power Pivot, SSIS, and SSRS.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Engineering (8 Months in Company - Currert Role):&lt;/strong&gt; I\u2019ve found my niche here as a Data Engineer. Beyond my proficiency in Talend Studio and SQL, I\u2019ve also been responsible for creating a data warehouse and establishing data quality checks. This includes deleting irrelevant data, which has had an impact on reducing monthly costs by 20%. I also created a data cube for customers and automated several tasks using Python. Project management and tracking are handled through Jira. Additionally, my effectiveness in handling projects led my team to cease its collaboration with an external data engineering developer, as I was able to deliver projects faster and with higher quality.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Future Ambitions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Short-Term (1-2 Years)&lt;/strong&gt;: I plan to tackle more complex projects with significant business impact. Leadership of technical teams, potentially starting with interns, is also on my agenda.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Long-Term (5 Years):&lt;/strong&gt; A transition into people management roles, overseeing full teams, is what I envision for myself in the long run.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Given that I currently work in Portugal and have already laid out my short-term and long-term goals, what should be my next steps? What areas should I focus on to make a significant leap in my career? Any advice tailored to the local job market here would also be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would love any advice or insights on achieving these ambitions and considerations for promotion opportunities.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lg8xa", "is_robot_indexable": true, "report_reasons": null, "author": "ByteAutomator", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17lg8xa/landed_a_data_engineering_role_now_what_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lg8xa/landed_a_data_engineering_role_now_what_future/", "subreddit_subscribers": 137350, "created_utc": 1698856695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are best options for Pyspark on databricks training? I\u2019m not familiar with Pyspark but am solid on python and pandas. (I just got my first data engineering job and need to learn these)", "author_fullname": "t2_74v59rzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark on Databricks training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lg547", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698856667.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698856423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are best options for Pyspark on databricks training? I\u2019m not familiar with Pyspark but am solid on python and pandas. (I just got my first data engineering job and need to learn these)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lg547", "is_robot_indexable": true, "report_reasons": null, "author": "codeslp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lg547/pyspark_on_databricks_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lg547/pyspark_on_databricks_training/", "subreddit_subscribers": 137350, "created_utc": 1698856423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.\n\nI have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.\n\nBut it seens my initial ideas of contribution were already done...\n\nFirst i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much that they havent done already lol\n\nI have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.\n\nDo you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfgsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698854617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.&lt;/p&gt;\n\n&lt;p&gt;But it seens my initial ideas of contribution were already done...&lt;/p&gt;\n\n&lt;p&gt;First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much that they havent done already lol&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfgsp", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfgsp/working_on_improving_the_process_of_converting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lfgsp/working_on_improving_the_process_of_converting/", "subreddit_subscribers": 137350, "created_utc": 1698854617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone.\n\nWe have website with GA4 tracking, CRM tracking, Email tool tracking etc. All the tools needs specific data structure, so they are little bit different, but we are tracking same things many times - like visit of item product page, adding to cart and many more.\n\nI would like to make an tracker (js), which will send data to API, where they are distributed/modeled to many destinations. I code in Python and JS, mainly rest APIs in Flask. Can you give me the best solution how to prepare it? What tools or services are best for this? I dont know if it will be quick enough for real-time tracking with just standard python ETL/middleware for tracking.\n\nI want to be really as simple as possible and cost efficient, but do you have any experience/ideas? Thank you.", "author_fullname": "t2_31exp9bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple question about data collection / tracking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17la7ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698839068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;\n\n&lt;p&gt;We have website with GA4 tracking, CRM tracking, Email tool tracking etc. All the tools needs specific data structure, so they are little bit different, but we are tracking same things many times - like visit of item product page, adding to cart and many more.&lt;/p&gt;\n\n&lt;p&gt;I would like to make an tracker (js), which will send data to API, where they are distributed/modeled to many destinations. I code in Python and JS, mainly rest APIs in Flask. Can you give me the best solution how to prepare it? What tools or services are best for this? I dont know if it will be quick enough for real-time tracking with just standard python ETL/middleware for tracking.&lt;/p&gt;\n\n&lt;p&gt;I want to be really as simple as possible and cost efficient, but do you have any experience/ideas? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17la7ao", "is_robot_indexable": true, "report_reasons": null, "author": "Sonny-Orkidea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17la7ao/simple_question_about_data_collection_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17la7ao/simple_question_about_data_collection_tracking/", "subreddit_subscribers": 137350, "created_utc": 1698839068.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}