{"kind": "Listing", "data": {"after": "t3_17l8u58", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For 25 years, I never fired anyone.  And yet, this is the third guy I've fired in the last 18 months.  Granted, I wasn't the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made *zero* effort to integrate into the organisation.\n\nAre we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don't need to make any kind of effort anymore?  Do they think they can just \"wing it\"?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?\n\nI feel like shit, because as much as this guy only has himself to blame, I'm still turfing him out in November, in a shitty, shitty job market.", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So I had to fire a guy today...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l0elt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698800401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For 25 years, I never fired anyone.  And yet, this is the third guy I&amp;#39;ve fired in the last 18 months.  Granted, I wasn&amp;#39;t the hiring manager for any of them... I just inherited them via org restructures.  But at least two were allegedly skilled and very experienced.  But all of them were unmotivated, lacked any initiative and were reluctant to learn new skills and embrace our stack.  All three made &lt;em&gt;zero&lt;/em&gt; effort to integrate into the organisation.&lt;/p&gt;\n\n&lt;p&gt;Are we going through a particularly bad time?  eg, has WFH left some staff complacent?  Do they think they don&amp;#39;t need to make any kind of effort anymore?  Do they think they can just &amp;quot;wing it&amp;quot;?   IMHO, at least two of the guys I fired had significantly oversold their technical skills.  Is DE particularly prone to fakes and fraudsters?&lt;/p&gt;\n\n&lt;p&gt;I feel like shit, because as much as this guy only has himself to blame, I&amp;#39;m still turfing him out in November, in a shitty, shitty job market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l0elt", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l0elt/so_i_had_to_fire_a_guy_today/", "subreddit_subscribers": 137327, "created_utc": 1698800401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.", "author_fullname": "t2_ymrlz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do organisations use abbreviations for table and field names that don't save much space and reduce clarity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l1crr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698803337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To give some examples,  I see table names such as applctn, prmtn, cstmr, thrshld. Is there any legitimate reason for doing this? To me, it reduces clarity and conversely makes typing and understanding them more difficult since one is not used to such abbreviations.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l1crr", "is_robot_indexable": true, "report_reasons": null, "author": "NightflowerFade", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l1crr/why_do_organisations_use_abbreviations_for_table/", "subreddit_subscribers": 137327, "created_utc": 1698803337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a Sr DE, but basically I\u2019m a SWE/dev ops/DE in reality, got 10+ YOE. My main current focus at work is creation of DE infrastructure and custom ETL frameworks that make other engineers life\u2019s easier and solve incredible large scale problems of infrastructure (the last one for example was how to filter data sets 700 billion records in a couple of seconds with high concurrency). I also have what I think are good SA skills focused on cost reduction on AWS.\n\nMy day to day is mostly CDK (typescript), Python (vanilla and spark) and googling weird stuff that happens at our scale. Manager great, team is great, I actually really like my job.\n\nHowever\u2026 I still work for someone and I\u2019m subject to dumb corporate decisions. Just a number to anyone above my manager. I am very seriously thinking about going into consulting and make my own business focused on AWS security, cost reduction and data engineering automations.\n\nIs this a stupid thought? Has anyone gone successfully into consulting? How tough is it out there? Is it more profitable?", "author_fullname": "t2_dt2eqjvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kwk0b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698789416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a Sr DE, but basically I\u2019m a SWE/dev ops/DE in reality, got 10+ YOE. My main current focus at work is creation of DE infrastructure and custom ETL frameworks that make other engineers life\u2019s easier and solve incredible large scale problems of infrastructure (the last one for example was how to filter data sets 700 billion records in a couple of seconds with high concurrency). I also have what I think are good SA skills focused on cost reduction on AWS.&lt;/p&gt;\n\n&lt;p&gt;My day to day is mostly CDK (typescript), Python (vanilla and spark) and googling weird stuff that happens at our scale. Manager great, team is great, I actually really like my job.&lt;/p&gt;\n\n&lt;p&gt;However\u2026 I still work for someone and I\u2019m subject to dumb corporate decisions. Just a number to anyone above my manager. I am very seriously thinking about going into consulting and make my own business focused on AWS security, cost reduction and data engineering automations.&lt;/p&gt;\n\n&lt;p&gt;Is this a stupid thought? Has anyone gone successfully into consulting? How tough is it out there? Is it more profitable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17kwk0b", "is_robot_indexable": true, "report_reasons": null, "author": "ksco92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kwk0b/going_into_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kwk0b/going_into_consulting/", "subreddit_subscribers": 137327, "created_utc": 1698789416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nIn my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.\n\nWe don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. \n\nI\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? \n\ni turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.\n\nThank you in advance :)", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8eu6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;In my company we\u2019re about to build our first data warehouse, and we\u2019re currently in the process of evaluating potential providers.&lt;/p&gt;\n\n&lt;p&gt;We don\u2019t have a huge amount of data (yet) and we\u2019re not planning to run heavy queries/ analysis. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious to hear from experienced people, will you recommend Snowflake or BigQuery and why? &lt;/p&gt;\n\n&lt;p&gt;i turned a blind eye on amazon redshift because i heard it needs regular maintenance and someone really skilled in AWS.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l8eu6", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8eu6/snowflake_vs_bigquery/", "subreddit_subscribers": 137327, "created_utc": 1698831740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!", "author_fullname": "t2_c85rlf9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Meta Virtual Onsite interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3nzl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all :) I have an onsite loop for meta product analytics data engineer coming up, the interviews cover product sense, data modeling and Python/SQL coding. Wanna know if anyone has any prep material or resources you can share (websites you used prep, practice questions, articles, case studies etc.)? Any tips and experience on the interviews are welcome too!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3nzl", "is_robot_indexable": true, "report_reasons": null, "author": "Fickle_Restaurant_35", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3nzl/data_engineer_meta_virtual_onsite_interview/", "subreddit_subscribers": 137327, "created_utc": 1698810819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello r/dataengineering community,\n\nI'm in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I'm feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.\n\nFor those who have been through this journey, I have a few questions:\n\n1. To what extent should I be practicing Python problems on Leetcode for a data engineering role?\n2. What specific topics or areas should be my primary focus?\n3. During your interviews, which Python-related topics were emphasized the most?\n\nAny insights or guidance would be greatly appreciated! Thanks in advance.", "author_fullname": "t2_5u73tpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How deep or advanced should my Python knowledge be when practicing on Leetcode for a Data Engineering role? Which difficulty levels of problems are most relevant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l3hjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698810142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the midst of preparing for interviews with two FAANG companies for a data engineer role, and I&amp;#39;m feeling slightly overwhelmed by the breadth of knowledge required. From mastering Python and SQL to delving into Big Data technologies like Kafka, Hadoop, Spark, and Airflow, the list seems endless.&lt;/p&gt;\n\n&lt;p&gt;For those who have been through this journey, I have a few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;To what extent should I be practicing Python problems on Leetcode for a data engineering role?&lt;/li&gt;\n&lt;li&gt;What specific topics or areas should be my primary focus?&lt;/li&gt;\n&lt;li&gt;During your interviews, which Python-related topics were emphasized the most?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any insights or guidance would be greatly appreciated! Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17l3hjb", "is_robot_indexable": true, "report_reasons": null, "author": "arcofiero", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l3hjb/how_deep_or_advanced_should_my_python_knowledge/", "subreddit_subscribers": 137327, "created_utc": 1698810142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.\n\nThese guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.\n\nNowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d\n\nSomething like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.\n\nSo that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?\n\n\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did you do when you joined an organization with some serious data problems, and you needed to introduce structure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kztbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698799438.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698798618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve joined this organization and they\u2019re big enough financially that I\u2019m surprised they would be in this situation. I\u2019m finding that the company has been run by geniuses in the engineering industry, but novices in the data industry.&lt;/p&gt;\n\n&lt;p&gt;These guys build giant ships, trains, you name it, They get a project idea, work out its dependancies (expenses), use prior projects to estimate the value of each expense, and roll everything up into a final estimated cost. It\u2019s awesome. The problem: they\u2019ve been doing it for nearly 30 years with Excel.&lt;/p&gt;\n\n&lt;p&gt;Nowadays the projects are massive and very complicated. The estimators eventually need to present their estimated budget to the C-Suite, and the C-Suite has questions like \u201cwell, how\u2019d/why\u2019d you figure $n/square_foot for metal sheeting?\u201d&lt;/p&gt;\n\n&lt;p&gt;Something like metal sheeting is very granular. It\u2019s an individual price point that could trace back to an average of a few projects with an estimators addition of n% for market changes. Since we have thousands of expenses, tracing that back during meeting time is very difficult. Again, they\u2019re in excel.&lt;/p&gt;\n\n&lt;p&gt;So that is one problem I\u2019m dealing with, among many. I\u2019m excited though\u2026 just curious for those who I\u2019ve been in similar positions, how\u2019d you handle all of it?&lt;/p&gt;\n\n&lt;p&gt;\u2014 I will be doing infrastructure management, data engineering, and analytics all wrapped up in a bow, I guess. I am fine with this, as they are quite lenient with project time. I want to run departments doing all of this one day, so the experience doing all of it myself should be good \u2014 right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kztbm", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kztbm/what_did_you_do_when_you_joined_an_organization/", "subreddit_subscribers": 137327, "created_utc": 1698798618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the following commands, it prompts you which snapshot to display, and then [you have this](https://app.data-drift.io/41231518/samox/local-datadrift-repo/overview?snapshotDate=2023-10-25&amp;commitSha=105c05f0d9b418cf86e223d59cc4a686b298935f) \ud83d\ude07\n\n&amp;#x200B;\n\n    pip install driftdb==0.0.1a12\n    driftdb dbt snapshot\n\nThe lib: [https://pypi.org/project/driftdb/](https://pypi.org/project/driftdb/)\n\nAll the data stays on your host !\n\n[Example of drift](https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6)", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a tool to visualize dbt-snapshots with a git like display", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tfve1f4ekkxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3381aa5d6cdc6023c7559e6cafa5f9874949c0a6"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccde4aa990cb7d15f7af363f07e38df1b2b8113d"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c024dc99c72dc3457887c326bcf3739ddf2d1ae0"}, {"y": 442, "x": 640, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f465caf5dd2157396caad0a4073fa26341a22a41"}, {"y": 663, "x": 960, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc697f3963cff63421c52a7d79486fe6f7c243df"}, {"y": 746, "x": 1080, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f0a934a13fdfcddd408c3e4b5b6f771540eb980"}], "s": {"y": 1664, "x": 2406, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6"}, "id": "tfve1f4ekkxb1"}}, "name": "t3_17kpvp6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/M-Ib3fRg5MfaoZgm7lp_0dl2nRgC5wcT2mWawn50IP8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698771914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the following commands, it prompts you which snapshot to display, and then &lt;a href=\"https://app.data-drift.io/41231518/samox/local-datadrift-repo/overview?snapshotDate=2023-10-25&amp;amp;commitSha=105c05f0d9b418cf86e223d59cc4a686b298935f\"&gt;you have this&lt;/a&gt; \ud83d\ude07&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install driftdb==0.0.1a12\ndriftdb dbt snapshot\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The lib: &lt;a href=\"https://pypi.org/project/driftdb/\"&gt;https://pypi.org/project/driftdb/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All the data stays on your host !&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6\"&gt;Example of drift&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17kpvp6", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kpvp6/i_created_a_tool_to_visualize_dbtsnapshots_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kpvp6/i_created_a_tool_to_visualize_dbtsnapshots_with_a/", "subreddit_subscribers": 137327, "created_utc": 1698771914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey folks, I'm on a team of \"full-stack\" analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp; analysis.\n\nWe don't have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We've had to constantly  push our infrastructure and modelling projects month after month because there's a constant influx of request from stakeholders.\n\nIs this a problem for you guys? What are you doing to address it?", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how many analytics engineers here work on ad-hoc SQL requests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lfb8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698854219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey folks, I&amp;#39;m on a team of &amp;quot;full-stack&amp;quot; analytics folks. Our scope is the entire modern data stack: ETL, warehouse, data modelling, BI, reverse ETL, reporting &amp;amp; analysis.&lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t have budgets this year or next to hire data or BI analysts so just wondering how many other folks here just get rammed with ad-hoc requests? Many of us just want to focus on data modelling and not having to deal with stakeholders. We&amp;#39;ve had to constantly  push our infrastructure and modelling projects month after month because there&amp;#39;s a constant influx of request from stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Is this a problem for you guys? What are you doing to address it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfb8v", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lfb8v/how_many_analytics_engineers_here_work_on_adhoc/", "subreddit_subscribers": 137327, "created_utc": 1698854219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. \n\nNow the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. \n\nI am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. \n\nI was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. \n\nAnyone have any advice or thoughts?", "author_fullname": "t2_bbmo0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GIT and environments in a data context", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l4v87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698830665.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698815394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you guys approaching git branching and releases within a data context? I have inherited a large code base of DAGs that uses branches for each data environment prod testing staging and develop. Staging test and prod all have distinct data lineage. &lt;/p&gt;\n\n&lt;p&gt;Now the way it has been happening is the developers work off of develop and when ready to release had opened an issue for a \u201crelease manager\u201d to literally checkout the files to a long life release branch and then cherry pick the commits onto each relevant branch. &lt;/p&gt;\n\n&lt;p&gt;I am currently adjusting this to a more \u201cstandard\u201d approach where the developer should see there commit move all the way through into production. I\u2019m pretty stuck with the environmental branches short term till we align a few more things. &lt;/p&gt;\n\n&lt;p&gt;I was thinking I would simply reset the develop branch to the release branch and then set all merges to trigger a short lived release branch that opens a pr into a higher environment. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any advice or thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l4v87", "is_robot_indexable": true, "report_reasons": null, "author": "cursedbartender", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l4v87/git_and_environments_in_a_data_context/", "subreddit_subscribers": 137327, "created_utc": 1698815394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipelines for Data Products: Key Components, Recommended Tools, and Fundamental Development Concepts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17l97g9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EIv6gRw0P89sEDCK4NSudJaEodcyodm-X3JW9F6OKvM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698835195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?auto=webp&amp;s=b25f887df718c4bb01b0cfed6817176eb521e590", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4bfdb31befcbbe7483e6f726d778f8e9b313d06", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac59763b5c2e199b7f0510593e9b60059274698f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd9cccbfff8962388ed92c9415979a31979db949", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79e68330249124713e23b85e86d0d373585ca011", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b0c6d1642261a80c5cdc619f6c5c8085d93dccb6", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Ml3zWL16mQgmRvtVEJZvn6SNuC0-nwUTc4_DLWDWTXs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ebabeea51e10cd32fcbcd0e82e32fda98459aade", "width": 1080, "height": 540}], "variants": {}, "id": "08ytc-6p-5bmF7Vj6nq-fUR0LEM5son5wQBs-pHIOBc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17l97g9", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l97g9/data_pipelines_for_data_products_key_components/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/data-pipelines-for-data-products", "subreddit_subscribers": 137327, "created_utc": 1698835195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE's\n\nI am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.\n\nNo I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.\n\n1. I need to check if I can join tables on some join key and every record match:\n2. I need to check if every column values in source are exactly the same as in target column\n\nSo my idea is to do something like this:\n\n1. Read DWH table with Spark (source table)\n2. Read DataLake table with Spark (target table)\n3. Add prefix to source table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n4. Add prefix to target table columns: e.g source\\_column\\_a, source\\_column\\_b ...\n5. Use join\\_key to left join table:  e.g:   source\\_table\\['source\\_join\\_key'\\] == target\\_table\\['target\\_join\\_key'\\]\n6. Use this combined table to run great expectations\n   1. check if tables properly joined: expect\\_column\\_values\\_to\\_not\\_be\\_null(column='target\\_join\\_key')\n   2. check if column in source is the same as column in target  \nfor every column pair from source and target do the check:  \nexpect\\_column\\_pair\\_values\\_to\\_be\\_equal(  \n column\\_A=source\\_column\\_a, column\\_B=target\\_column\\_b)  \n\n\nGreat expectations is something new to me. Do you think my ideas is good or is there a better way ?  \nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.\n\n  \n", "author_fullname": "t2_2llofc3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great expectations -&gt; how to compare 2 dafarames", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l89wn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698831087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE&amp;#39;s&lt;/p&gt;\n\n&lt;p&gt;I am working on project where I am migrating data warehouse table to datalake. And I am using for this PySpark jobs and Airflow as scheduler.&lt;/p&gt;\n\n&lt;p&gt;No I need to develop some tool with the usage of Greate Expectations framework to do some checks if table was properly migrated. Source table needs to be exactly the same as target table.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I need to check if I can join tables on some join key and every record match:&lt;/li&gt;\n&lt;li&gt;I need to check if every column values in source are exactly the same as in target column&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So my idea is to do something like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read DWH table with Spark (source table)&lt;/li&gt;\n&lt;li&gt;Read DataLake table with Spark (target table)&lt;/li&gt;\n&lt;li&gt;Add prefix to source table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Add prefix to target table columns: e.g source_column_a, source_column_b ...&lt;/li&gt;\n&lt;li&gt;Use join_key to left join table:  e.g:   source_table[&amp;#39;source_join_key&amp;#39;] == target_table[&amp;#39;target_join_key&amp;#39;]&lt;/li&gt;\n&lt;li&gt;Use this combined table to run great expectations\n\n&lt;ol&gt;\n&lt;li&gt;check if tables properly joined: expect_column_values_to_not_be_null(column=&amp;#39;target_join_key&amp;#39;)&lt;/li&gt;\n&lt;li&gt;check if column in source is the same as column in target&lt;br/&gt;\nfor every column pair from source and target do the check:&lt;br/&gt;\nexpect_column_pair_values_to_be_equal(&lt;br/&gt;\ncolumn_A=source_column_a, column_B=target_column_b)&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Great expectations is something new to me. Do you think my ideas is good or is there a better way ?&lt;br/&gt;\nIn the end the goal is to check if source table from DWH is exactly the same like Data Lake table. With row level granurality and generate some nice docs, report which will contain differences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17l89wn", "is_robot_indexable": true, "report_reasons": null, "author": "masek94", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l89wn/great_expectations_how_to_compare_2_dafarames/", "subreddit_subscribers": 137327, "created_utc": 1698831087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, We have some requirements to move transaction data(10's of Billions of rows/day and 24/7 streaming, majority would be INSERT and few of them will be Updates/deletes too), which gets generated from on-premise Oracle database. This data needs to be moved to AWS snowflake data lake(which going to serve our reporting and analytics need). And we want this to happen as real time streaming i.e kind of real time data replication from on-premise to the cloud. And team is planning to use below data pipeline model\n\nOracle GGS(Golden gate replicats) --&gt; Kafka--&gt; Event extractor--&gt; S3 Raw --&gt; Delta lake curation+ refiner--&gt; Snowflake\n\nBut from the test this seems going to take lot of time i.e. 3-4hrs lag between the generation of data at source and reaching the snowflake. So wanted to understand , what other possible strategies we can follow to skip all these hops and move data to snowflake efficiently in quick time without so many hops? \n\njust to note- \"Event extractor\" is used because there is another application which is based on cloud and is based on micro-services/event based architecture , and that sends events to the snowflake in same route. So at snowflake basically we consolidate data from both the on-premise and the cloud native app.", "author_fullname": "t2_awgfwfxot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Continuous data streaming from on premise to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kwzt1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698790613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, We have some requirements to move transaction data(10&amp;#39;s of Billions of rows/day and 24/7 streaming, majority would be INSERT and few of them will be Updates/deletes too), which gets generated from on-premise Oracle database. This data needs to be moved to AWS snowflake data lake(which going to serve our reporting and analytics need). And we want this to happen as real time streaming i.e kind of real time data replication from on-premise to the cloud. And team is planning to use below data pipeline model&lt;/p&gt;\n\n&lt;p&gt;Oracle GGS(Golden gate replicats) --&amp;gt; Kafka--&amp;gt; Event extractor--&amp;gt; S3 Raw --&amp;gt; Delta lake curation+ refiner--&amp;gt; Snowflake&lt;/p&gt;\n\n&lt;p&gt;But from the test this seems going to take lot of time i.e. 3-4hrs lag between the generation of data at source and reaching the snowflake. So wanted to understand , what other possible strategies we can follow to skip all these hops and move data to snowflake efficiently in quick time without so many hops? &lt;/p&gt;\n\n&lt;p&gt;just to note- &amp;quot;Event extractor&amp;quot; is used because there is another application which is based on cloud and is based on micro-services/event based architecture , and that sends events to the snowflake in same route. So at snowflake basically we consolidate data from both the on-premise and the cloud native app.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kwzt1", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Length9755", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kwzt1/continuous_data_streaming_from_on_premise_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kwzt1/continuous_data_streaming_from_on_premise_to_cloud/", "subreddit_subscribers": 137327, "created_utc": 1698790613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Nov 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c", "t3_17lfedu"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1698854452.916, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lfedu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698854452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?auto=webp&amp;s=f31fa9903d75d67fdf7aa466dc59b353580baab5", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d07b02ea6d52e510a89eebac3220c5380d16a142", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ffdf2cc7f4c7114208ab8b1d725d8b597246398", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=17088c4844a3ddeb97d8b7a5cbe0f0bb49f04088", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/rxvvbbkij7qY9RjTudT9hRKqZsTVBC3s9sUKA54HJcI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1d617569fa501370336b415c3779b4906b139b24", "width": 640, "height": 333}], "variants": {}, "id": "VINWZoaUoDSGoJqMz7V286sj1fgBznndF5gxkCuKIxs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfedu", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/17lfedu/monthly_general_discussion_nov_2023/", "subreddit_subscribers": 137327, "created_utc": 1698854452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for \"full stack\" analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).\n\nI've been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.\n\nThe implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I've worked with some of these people before and they're wicked smart.\n\nBesides my story and any advice you'd provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What other roles would you entertain beyond DE and SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17leyt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698853293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analytics engineer who is pretending to be a data architect at a start-up company. Basically a one man show for &amp;quot;full stack&amp;quot; analytics in a GCP/Looker environment. Most of my day is directly supporting a data warehouse and ELT pipelines (both through an onboarding tool and custom cloud function scripts).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been asked if I am interested in a director of implementation and solution architecture for another startup given my database and accounting background. The company I am currently at is running into cash issues, so the longevity is starting to be concerning.&lt;/p&gt;\n\n&lt;p&gt;The implementation part of the role would be managing migrations from one competitor system into the new one, which is in AWS. The second part of this role would be helping product solution through either data or billing/accounting issues. I&amp;#39;ve worked with some of these people before and they&amp;#39;re wicked smart.&lt;/p&gt;\n\n&lt;p&gt;Besides my story and any advice you&amp;#39;d provide, what other DE adjacent roles would you be willing to take? Data science? Analytics? Product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17leyt8", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17leyt8/what_other_roles_would_you_entertain_beyond_de/", "subreddit_subscribers": 137327, "created_utc": 1698853293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Whats a Data Product per your definition and how does it differ from a Data Asset?", "author_fullname": "t2_c45r2mfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Product Definition?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8vv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698833808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Whats a Data Product per your definition and how does it differ from a Data Asset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17l8vv3", "is_robot_indexable": true, "report_reasons": null, "author": "Head_Ad_5511", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8vv3/data_product_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8vv3/data_product_definition/", "subreddit_subscribers": 137327, "created_utc": 1698833808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI know questions like this get asked a lot, but I was unable to find a discussion relating to my exact situation so I wanted to reach out to get you guys' opinion. \n\nI have been working as a financial analyst with a healthcare company for 3 years. During my time at this role, I have quickly learned that I have far less of an interest doing the analytics of company data to make business decisions and am far more passionate about solving efficiency and data problems with code. I really have grown to love Python and SQL and really enjoy making tools to make processes easier for our teams. Because of this, I have begun to think that a career in DE is more related to my interests. \n\nSome of the work I've done here have included: \n\n - transitioning SAS projections into Python notebooks and automating Excel read-ins to speed up the projection process saving hours weekly. \n\n- Optimizing SQL queries and improving database structure, reducing redundancies and transactions to the servers\n\n- Using Git hooks and Python to automate versioning incrementation of Excel reporting tool versions and prevent out of date versions of reports from being used\n\n- Managing data deployments to PROD servers during the insurance bid season and creating a Python tool that connects to a Git repo to execute queries and loads such data into new/existing tables, as well as copying tables from one server to another. \n\n\nI know that none of these projects have been too advanced DE type projects, but I feel like they are getting me on the right path.  I, unfortunately, have no real experience with cloud systems, formal ETL tools, data lake/warehousing, some deeper coding stuff like linux systems etc. \n\nI am looking to move soon to get closer to family, and am looking to find something that is completely remote (current role is hybrid). I have applying heavily to largely Data Engineer jobs, but have been applying to lots of other adjacent roles as well including data analyst, ETL Developer, Analytics Engineer, Business Intelligence Engineer, Database Developer, ETL Analyst, and on and on. I can't seem to get any offers. I'm not applying only to FAANG, I'm applying to hundreds of roles. I've submitted my resume to r/resumes (check my post history) and have received other online help and I believe that it shouldn't be bad *enough* to be getting no offers and hardly any interviews. I know that now is apparently a bad time for the job market, but I can not fathom how if I were to lose my job for whatever reason, that it would take months to get a single offer as even a data analyst (which is how long I've been applying for positions). \n\nWhat I'm asking is for suggestions. Should I just focus on trying to find a Data Analyst role that focuses on ETL and data pipelines before looking for strictly DE roles? I've received feedback that I could land a DE role, but I have yet to get a single interview for  DE position. Is the job market really that bad right now? \n\nDoes anyone have any suggestions on how someone with some DE-like experience could transition into a DE role? Do you have any suggestions on job titles I could look into that could be essentially a stepping stone to a DE position? Any suggestions on how/where to find job listings that I would be a decent fit in? \n\nfor context: I have a degree in Mathematics and am in the US. I work for a large insurance company doing lots of DE-like tasks using Python, SQL, Git, Excel, VBA, Power BI \n\nedit: I forgot to add, I am looking to move very soon if possible, so I really don't have time to complete a certification like one for AWS or time to learn Databricks or Snowflake unfortunately. I definitely would like to learn stuff like this, I just don't think I can get familiar with them while looking for a job/packing\n\n\ntl;dr: \nBeen working for an insurance company for 3 years doing DE type projects, but can't get a DE interview. I've received feedback saying my resume is decent. Are there any adjacent jobs that could help me transition into DE? Is the market just really bad for someone with 3 years of experience right now?", "author_fullname": "t2_gy2be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyst with a focus in DE projects -&gt; DE transition/job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kt7e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698780546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I know questions like this get asked a lot, but I was unable to find a discussion relating to my exact situation so I wanted to reach out to get you guys&amp;#39; opinion. &lt;/p&gt;\n\n&lt;p&gt;I have been working as a financial analyst with a healthcare company for 3 years. During my time at this role, I have quickly learned that I have far less of an interest doing the analytics of company data to make business decisions and am far more passionate about solving efficiency and data problems with code. I really have grown to love Python and SQL and really enjoy making tools to make processes easier for our teams. Because of this, I have begun to think that a career in DE is more related to my interests. &lt;/p&gt;\n\n&lt;p&gt;Some of the work I&amp;#39;ve done here have included: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;transitioning SAS projections into Python notebooks and automating Excel read-ins to speed up the projection process saving hours weekly. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Optimizing SQL queries and improving database structure, reducing redundancies and transactions to the servers&lt;/li&gt;\n&lt;li&gt;Using Git hooks and Python to automate versioning incrementation of Excel reporting tool versions and prevent out of date versions of reports from being used&lt;/li&gt;\n&lt;li&gt;Managing data deployments to PROD servers during the insurance bid season and creating a Python tool that connects to a Git repo to execute queries and loads such data into new/existing tables, as well as copying tables from one server to another. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I know that none of these projects have been too advanced DE type projects, but I feel like they are getting me on the right path.  I, unfortunately, have no real experience with cloud systems, formal ETL tools, data lake/warehousing, some deeper coding stuff like linux systems etc. &lt;/p&gt;\n\n&lt;p&gt;I am looking to move soon to get closer to family, and am looking to find something that is completely remote (current role is hybrid). I have applying heavily to largely Data Engineer jobs, but have been applying to lots of other adjacent roles as well including data analyst, ETL Developer, Analytics Engineer, Business Intelligence Engineer, Database Developer, ETL Analyst, and on and on. I can&amp;#39;t seem to get any offers. I&amp;#39;m not applying only to FAANG, I&amp;#39;m applying to hundreds of roles. I&amp;#39;ve submitted my resume to &lt;a href=\"/r/resumes\"&gt;r/resumes&lt;/a&gt; (check my post history) and have received other online help and I believe that it shouldn&amp;#39;t be bad &lt;em&gt;enough&lt;/em&gt; to be getting no offers and hardly any interviews. I know that now is apparently a bad time for the job market, but I can not fathom how if I were to lose my job for whatever reason, that it would take months to get a single offer as even a data analyst (which is how long I&amp;#39;ve been applying for positions). &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m asking is for suggestions. Should I just focus on trying to find a Data Analyst role that focuses on ETL and data pipelines before looking for strictly DE roles? I&amp;#39;ve received feedback that I could land a DE role, but I have yet to get a single interview for  DE position. Is the job market really that bad right now? &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions on how someone with some DE-like experience could transition into a DE role? Do you have any suggestions on job titles I could look into that could be essentially a stepping stone to a DE position? Any suggestions on how/where to find job listings that I would be a decent fit in? &lt;/p&gt;\n\n&lt;p&gt;for context: I have a degree in Mathematics and am in the US. I work for a large insurance company doing lots of DE-like tasks using Python, SQL, Git, Excel, VBA, Power BI &lt;/p&gt;\n\n&lt;p&gt;edit: I forgot to add, I am looking to move very soon if possible, so I really don&amp;#39;t have time to complete a certification like one for AWS or time to learn Databricks or Snowflake unfortunately. I definitely would like to learn stuff like this, I just don&amp;#39;t think I can get familiar with them while looking for a job/packing&lt;/p&gt;\n\n&lt;p&gt;tl;dr: \nBeen working for an insurance company for 3 years doing DE type projects, but can&amp;#39;t get a DE interview. I&amp;#39;ve received feedback saying my resume is decent. Are there any adjacent jobs that could help me transition into DE? Is the market just really bad for someone with 3 years of experience right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17kt7e3", "is_robot_indexable": true, "report_reasons": null, "author": "iSeeXenuInYou", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17kt7e3/analyst_with_a_focus_in_de_projects_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kt7e3/analyst_with_a_focus_in_de_projects_de/", "subreddit_subscribers": 137327, "created_utc": 1698780546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Reddit Community!\n\nI\u2019m a 25-year-old Data Engineer and I would love to get your advice on future career growth and progression.\n\n**Background (During Studies)**\n\n* **Education:** I have a degree in Industrial Engineering and Management. This broad education introduced me to logistics, ergonomics, work safety, statistics, maths, project management, maintenance, programming and many other areas. It has been incredibly useful in enabling me to communicate across people with different engineering fields and provides me with a macro view of business processes.\n* **Entrepreneurial Stint:** I co-founded an association in my hometown and served as its vice president. We managed to secure funding from the local municipality and organized various events, underlining my entrepreneurial spirit.\n* **Internships (2 Years in multiple companies):** While studying, I completed 3 internships focusing on project implementations mostly in logistics, ergonomics assessments, and process mapping with BPMN, and used a lot of Excel.\n\n**Background (After Studies)**\n\n* **Logistics Specialist (1 Year in Company 1):** My role was multifaceted and included leading a project to implement SAP EWM in 2 warehouses. I was responsible for creating user processes, instructions, and conducting training sessions. Additionally, I developed automated workflows using Microsoft Automate and created SharePoint lists and permissions. Data visualization was another strong suit, and I extensively used Power BI for this.\n* **Business Analyst (4-5 Months in Company 2):** In this position, I generated reports for store owners with varying frequencies\u2014daily, weekly, and monthly. My toolbox included Excel, Power Pivot, SSIS, and SSRS.\n* **Data Engineering (8 Months in Company - Currert Role):** I\u2019ve found my niche here as a Data Engineer. Beyond my proficiency in Talend Studio and SQL, I\u2019ve also been responsible for creating a data warehouse and establishing data quality checks. This includes deleting irrelevant data, which has had an impact on reducing monthly costs by 20%. I also created a data cube for customers and automated several tasks using Python. Project management and tracking are handled through Jira. Additionally, my effectiveness in handling projects led my team to cease its collaboration with an external data engineering developer, as I was able to deliver projects faster and with higher quality.\n\n**Future Ambitions**\n\n* **Short-Term (1-2 Years)**: I plan to tackle more complex projects with significant business impact. Leadership of technical teams, potentially starting with interns, is also on my agenda.\n* **Long-Term (5 Years):** A transition into people management roles, overseeing full teams, is what I envision for myself in the long run.\n\n**From Logistics to Analytics**\n\nInterestingly, I started my post-academic career in logistics, but quickly realized that my passion lies in the analytical field. Making the transition wasn\u2019t easy, but I\u2019ve managed to find my footing, and I\u2019m now excelling in data engineering.\n\nGiven that I currently work in Portugal and have already laid out my short-term and long-term goals, what should be my next steps? What areas should I focus on to make a significant leap in my career? Any advice tailored to the local job market here would also be highly appreciated.\n\n**Would love any advice or insights on achieving these ambitions and considerations for promotion opportunities.**\n\nThank you for reading!", "author_fullname": "t2_imnwscg17", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landed a Data Engineering role, now what? Future Ambitions - Need Career Progression Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lg8xa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698857240.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698856695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Reddit Community!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m a 25-year-old Data Engineer and I would love to get your advice on future career growth and progression.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background (During Studies)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Education:&lt;/strong&gt; I have a degree in Industrial Engineering and Management. This broad education introduced me to logistics, ergonomics, work safety, statistics, maths, project management, maintenance, programming and many other areas. It has been incredibly useful in enabling me to communicate across people with different engineering fields and provides me with a macro view of business processes.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Entrepreneurial Stint:&lt;/strong&gt; I co-founded an association in my hometown and served as its vice president. We managed to secure funding from the local municipality and organized various events, underlining my entrepreneurial spirit.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internships (2 Years in multiple companies):&lt;/strong&gt; While studying, I completed 3 internships focusing on project implementations mostly in logistics, ergonomics assessments, and process mapping with BPMN, and used a lot of Excel.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Background (After Studies)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Logistics Specialist (1 Year in Company 1):&lt;/strong&gt; My role was multifaceted and included leading a project to implement SAP EWM in 2 warehouses. I was responsible for creating user processes, instructions, and conducting training sessions. Additionally, I developed automated workflows using Microsoft Automate and created SharePoint lists and permissions. Data visualization was another strong suit, and I extensively used Power BI for this.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Business Analyst (4-5 Months in Company 2):&lt;/strong&gt; In this position, I generated reports for store owners with varying frequencies\u2014daily, weekly, and monthly. My toolbox included Excel, Power Pivot, SSIS, and SSRS.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Engineering (8 Months in Company - Currert Role):&lt;/strong&gt; I\u2019ve found my niche here as a Data Engineer. Beyond my proficiency in Talend Studio and SQL, I\u2019ve also been responsible for creating a data warehouse and establishing data quality checks. This includes deleting irrelevant data, which has had an impact on reducing monthly costs by 20%. I also created a data cube for customers and automated several tasks using Python. Project management and tracking are handled through Jira. Additionally, my effectiveness in handling projects led my team to cease its collaboration with an external data engineering developer, as I was able to deliver projects faster and with higher quality.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Future Ambitions&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Short-Term (1-2 Years)&lt;/strong&gt;: I plan to tackle more complex projects with significant business impact. Leadership of technical teams, potentially starting with interns, is also on my agenda.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Long-Term (5 Years):&lt;/strong&gt; A transition into people management roles, overseeing full teams, is what I envision for myself in the long run.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;From Logistics to Analytics&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Interestingly, I started my post-academic career in logistics, but quickly realized that my passion lies in the analytical field. Making the transition wasn\u2019t easy, but I\u2019ve managed to find my footing, and I\u2019m now excelling in data engineering.&lt;/p&gt;\n\n&lt;p&gt;Given that I currently work in Portugal and have already laid out my short-term and long-term goals, what should be my next steps? What areas should I focus on to make a significant leap in my career? Any advice tailored to the local job market here would also be highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would love any advice or insights on achieving these ambitions and considerations for promotion opportunities.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lg8xa", "is_robot_indexable": true, "report_reasons": null, "author": "ByteAutomator", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17lg8xa/landed_a_data_engineering_role_now_what_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lg8xa/landed_a_data_engineering_role_now_what_future/", "subreddit_subscribers": 137327, "created_utc": 1698856695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are best options for Pyspark on databricks training? I\u2019m not familiar with Pyspark but am solid on python and pandas. (I just got my first data engineering job and need to learn these)", "author_fullname": "t2_74v59rzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark on Databricks training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lg547", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698856667.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698856423.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are best options for Pyspark on databricks training? I\u2019m not familiar with Pyspark but am solid on python and pandas. (I just got my first data engineering job and need to learn these)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lg547", "is_robot_indexable": true, "report_reasons": null, "author": "codeslp", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lg547/pyspark_on_databricks_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lg547/pyspark_on_databricks_training/", "subreddit_subscribers": 137327, "created_utc": 1698856423.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.\n\nI have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.\n\nBut it seens my initial ideas of contribution were already done...\n\nFirst i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much that they havent done already lol\n\nI have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.\n\nDo you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working on improving the process of converting documents into Embeddings (for vectorStores) for LLM applications but i need some ideas and complaints from you!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lfgsp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698854617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am CS undergrad interested in NLP, building LLM applications and uses of embeddings in professional settings.&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about researching better ways to extract, transform and load (ETL pipelines) data from several formats into text embeddings for the aforementioned applications.&lt;/p&gt;\n\n&lt;p&gt;But it seens my initial ideas of contribution were already done...&lt;/p&gt;\n\n&lt;p&gt;First i thought about a better way to load CSV and tabular data files into embeddings, but PostGresVector DB was launched a month or so ago, so i guess i cant really do much that they havent done already lol&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about other data types such as JSON or XML and how to treat them and load them into vectorDBs but i am not sure.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have more ideas? Maybe one complaint you have when using such tools and data sources? I am curious and excited to hear these problems so maybe i could work on them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lfgsp", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lfgsp/working_on_improving_the_process_of_converting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lfgsp/working_on_improving_the_process_of_converting/", "subreddit_subscribers": 137327, "created_utc": 1698854617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its **free** for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  \n\n\n[https://www.amazon.com/dp/B0CM85Q7YJ](https://www.amazon.com/dp/B0CM85Q7YJ)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free eBook on Acing the Data Engineering Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17le6tc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698851150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a huge gap in interview-prep content for data engineers, so I wrote a book about it. It went live in Amazon Kindle, and its &lt;strong&gt;free&lt;/strong&gt; for the next 5 days. If you are preparing for the data engineering interview and looking for a step by step guide, this is a great place to start.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.com/dp/B0CM85Q7YJ\"&gt;https://www.amazon.com/dp/B0CM85Q7YJ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17le6tc", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17le6tc/free_ebook_on_acing_the_data_engineering_interview/", "subreddit_subscribers": 137327, "created_utc": 1698851150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty much the title.\n\nAt work, the non-coding people are telling me it's redundant to save the data first to a .csv, and I should just load it from there.\n\nI'm not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.\n\nIt's not as if exctracting data and saving it to a .csv is an Herculean task...", "author_fullname": "t2_mnoei525n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using an API, should I load the data directly to a database, or should I just clean the data, save it as .csvs in blob storage and then load my data from the .csvs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ld440", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698848144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much the title.&lt;/p&gt;\n\n&lt;p&gt;At work, the non-coding people are telling me it&amp;#39;s redundant to save the data first to a .csv, and I should just load it from there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not convinced by this, the first problem I see is not having the .csvs on hand if I need them. There has already been issues with cloud and API providers with their systems failing and making the data irretrievable. That alone is enough for me to save as .csv first and then load the data, along other reasons like data continuity, being able to log errors easily, and having a standard way to load data from multiple clients and data sources.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not as if exctracting data and saving it to a .csv is an Herculean task...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ld440", "is_robot_indexable": true, "report_reasons": null, "author": "peroqueteniaquever", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ld440/using_an_api_should_i_load_the_data_directly_to_a/", "subreddit_subscribers": 137327, "created_utc": 1698848144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if anyone has done the Meta Infra DE Onsite in the last year or so. There\u2019s tons of info on Reddit and Blind about the Product Analytics onsite and even which questions are asked but haven\u2019t seen any about the Infra one. And if there are any about Infra, they are 2+ years old. If anyone has gone through the onsite, could you give guidance on the Python/Coding portion as well as a the System Design/End to End portion? These are the two I\u2019m most concerned about and hoping someone could help give info on the topics/questions/how to prepare. Thanks in advance :)", "author_fullname": "t2_ghqh5w6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meta Infra DE Onsite Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lc9um", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698845704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if anyone has done the Meta Infra DE Onsite in the last year or so. There\u2019s tons of info on Reddit and Blind about the Product Analytics onsite and even which questions are asked but haven\u2019t seen any about the Infra one. And if there are any about Infra, they are 2+ years old. If anyone has gone through the onsite, could you give guidance on the Python/Coding portion as well as a the System Design/End to End portion? These are the two I\u2019m most concerned about and hoping someone could help give info on the topics/questions/how to prepare. Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17lc9um", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Sprinkles8216", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lc9um/meta_infra_de_onsite_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lc9um/meta_infra_de_onsite_interview/", "subreddit_subscribers": 137327, "created_utc": 1698845704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone.\n\nWe have website with GA4 tracking, CRM tracking, Email tool tracking etc. All the tools needs specific data structure, so they are little bit different, but we are tracking same things many times - like visit of item product page, adding to cart and many more.\n\nI would like to make an tracker (js), which will send data to API, where they are distributed/modeled to many destinations. I code in Python and JS, mainly rest APIs in Flask. Can you give me the best solution how to prepare it? What tools or services are best for this? I dont know if it will be quick enough for real-time tracking with just standard python ETL/middleware for tracking.\n\nI want to be really as simple as possible and cost efficient, but do you have any experience/ideas? Thank you.", "author_fullname": "t2_31exp9bt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simple question about data collection / tracking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17la7ao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698839068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.&lt;/p&gt;\n\n&lt;p&gt;We have website with GA4 tracking, CRM tracking, Email tool tracking etc. All the tools needs specific data structure, so they are little bit different, but we are tracking same things many times - like visit of item product page, adding to cart and many more.&lt;/p&gt;\n\n&lt;p&gt;I would like to make an tracker (js), which will send data to API, where they are distributed/modeled to many destinations. I code in Python and JS, mainly rest APIs in Flask. Can you give me the best solution how to prepare it? What tools or services are best for this? I dont know if it will be quick enough for real-time tracking with just standard python ETL/middleware for tracking.&lt;/p&gt;\n\n&lt;p&gt;I want to be really as simple as possible and cost efficient, but do you have any experience/ideas? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17la7ao", "is_robot_indexable": true, "report_reasons": null, "author": "Sonny-Orkidea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17la7ao/simple_question_about_data_collection_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17la7ao/simple_question_about_data_collection_tracking/", "subreddit_subscribers": 137327, "created_utc": 1698839068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks\n\nFor the ones of you who manage dashboards or semantic models in UI tools, here's an article describing 3 popular tools and their capabilities at doing this work\n\n[https://dlthub.com/docs/blog/semantic-modeling-tools-comparison](https://dlthub.com/docs/blog/semantic-modeling-tools-comparison)\n\nhope you enjoy the read and if you'd like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metabase, PowerBI and Gooddata capabilities: A comparison", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l8u58", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698833585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks&lt;/p&gt;\n\n&lt;p&gt;For the ones of you who manage dashboards or semantic models in UI tools, here&amp;#39;s an article describing 3 popular tools and their capabilities at doing this work&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dlthub.com/docs/blog/semantic-modeling-tools-comparison\"&gt;https://dlthub.com/docs/blog/semantic-modeling-tools-comparison&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;hope you enjoy the read and if you&amp;#39;d like to see more comparisons, other tools or verticals, or to focus on particular aspects, then let us know which!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?auto=webp&amp;s=baf5edae6ead07395e7b0f4f43b416bb4f7d2663", "width": 1017, "height": 502}, "resolutions": [{"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aad7f0d66da3e4f493a2e586874be97a7eef7ef2", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8721a71c23b0248f369ee7e7bb3470111e9c6c2", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d45554e342882523cb3df4a37ebe617641870400", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2114b9c84fbc85f25e822d69742996f6aca22f1e", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/gmKY5bc-UmvHHk_sU5NjGpiL8Y7NOyIUTnDdiiPPlYU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7699e43df6a105dd859147cd6d4e730ee0deb64", "width": 960, "height": 473}], "variants": {}, "id": "8jYk58ZKnFHJb47ZtO42qbrIKmGGyqQijmsQllfJlw4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17l8u58", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17l8u58/metabase_powerbi_and_gooddata_capabilities_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17l8u58/metabase_powerbi_and_gooddata_capabilities_a/", "subreddit_subscribers": 137327, "created_utc": 1698833585.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}