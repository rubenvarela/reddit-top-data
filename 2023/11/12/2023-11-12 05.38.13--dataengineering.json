{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious on some of the biggest costs of time/money that holds back the ability for your team to do their jobs effectively. For example,  things that are huge pain daily.", "author_fullname": "t2_kj229pv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the biggest obstacles/painpoints in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17so76t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699682230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious on some of the biggest costs of time/money that holds back the ability for your team to do their jobs effectively. For example,  things that are huge pain daily.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17so76t", "is_robot_indexable": true, "report_reasons": null, "author": "snailspeed25", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17so76t/what_are_the_biggest_obstaclespainpoints_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17so76t/what_are_the_biggest_obstaclespainpoints_in_data/", "subreddit_subscribers": 139208, "created_utc": 1699682230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's a rant really about some of our airflow jobs having more lines of code than the actual code and also more effort in writing airflow code than the real work.\n\nI tried building airflow factory models etc but it did not help. Hope something like autosys or control m comes up as open source for big data job scheduling.", "author_fullname": "t2_kfvc08j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hate the idea of writing code for job scheduling like airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t0d2p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699726999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a rant really about some of our airflow jobs having more lines of code than the actual code and also more effort in writing airflow code than the real work.&lt;/p&gt;\n\n&lt;p&gt;I tried building airflow factory models etc but it did not help. Hope something like autosys or control m comes up as open source for big data job scheduling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t0d2p", "is_robot_indexable": true, "report_reasons": null, "author": "RepulsiveCry8412", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t0d2p/does_anyone_else_hate_the_idea_of_writing_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t0d2p/does_anyone_else_hate_the_idea_of_writing_code/", "subreddit_subscribers": 139208, "created_utc": 1699726999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Give me perspective, oh wise Reddit collective!\n\nWe are on-prem Oracle ERP and DWHS and management wants to move DWHS to MS Fabric (when GA) and Purview. DWHS is ~200 end-reporting-tables/20 models for Cognos (storage of reporting data in Oracle tops out around 1TB).\n\nPowerBI certainly seems more capable/supported/forward-thinking than Cognos, and we\u2019re mostly an MS shop, so I see the allure:\n\n1) Moving to \u201cthe cloud\u201d as a measure of maturity (DE Manifesto)\n2 ADF/AzureDevOps touts ease-of-CI/CD and rapid pipeline development\n3) OneLake inclusion of User-Supplied data in modeling\n4) Sensitivity Labeling preventive exfiltration\n5) Reverse engineering with Power Automate\n\nHowever, I\u2019m concerned this move, while likely an improvement from our current architecture, would be a mistake, given the plethora of outstanding decoupled open-source components out there for orgs with sufficient on-prem experience and resources such as ours.\n\nI\u2019m thinking something like getting off Oracle for our DWHS, using on-prem PostGres (maybe one dedicated for perpetual ETL-oading into another for consumption), using Airbyte for the ingestion, Dagster for the Orchestration, Git/DBT for the \u2018T\u2019, while moving the needle in the DataMesh direction by taking the dozen-or-so external domain analysts with current direct access, to using DBT and developing locally with DuckDB, maybe even SQLMesh.\n\nI feel like the amount of time it would take us to move and acclimate to Azure would be on par with the time to go down this \u201cfree\u201d route.\n\nAnyone else have experience with these quandaries?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why pay for worse when better is free?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17sq4zz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699690931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Give me perspective, oh wise Reddit collective!&lt;/p&gt;\n\n&lt;p&gt;We are on-prem Oracle ERP and DWHS and management wants to move DWHS to MS Fabric (when GA) and Purview. DWHS is ~200 end-reporting-tables/20 models for Cognos (storage of reporting data in Oracle tops out around 1TB).&lt;/p&gt;\n\n&lt;p&gt;PowerBI certainly seems more capable/supported/forward-thinking than Cognos, and we\u2019re mostly an MS shop, so I see the allure:&lt;/p&gt;\n\n&lt;p&gt;1) Moving to \u201cthe cloud\u201d as a measure of maturity (DE Manifesto)\n2 ADF/AzureDevOps touts ease-of-CI/CD and rapid pipeline development\n3) OneLake inclusion of User-Supplied data in modeling\n4) Sensitivity Labeling preventive exfiltration\n5) Reverse engineering with Power Automate&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m concerned this move, while likely an improvement from our current architecture, would be a mistake, given the plethora of outstanding decoupled open-source components out there for orgs with sufficient on-prem experience and resources such as ours.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking something like getting off Oracle for our DWHS, using on-prem PostGres (maybe one dedicated for perpetual ETL-oading into another for consumption), using Airbyte for the ingestion, Dagster for the Orchestration, Git/DBT for the \u2018T\u2019, while moving the needle in the DataMesh direction by taking the dozen-or-so external domain analysts with current direct access, to using DBT and developing locally with DuckDB, maybe even SQLMesh.&lt;/p&gt;\n\n&lt;p&gt;I feel like the amount of time it would take us to move and acclimate to Azure would be on par with the time to go down this \u201cfree\u201d route.&lt;/p&gt;\n\n&lt;p&gt;Anyone else have experience with these quandaries?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17sq4zz", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17sq4zz/why_pay_for_worse_when_better_is_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17sq4zz/why_pay_for_worse_when_better_is_free/", "subreddit_subscribers": 139208, "created_utc": 1699690931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title basically. \n\nWhat do you do on a daily/weekly basis to keep your interview skills sharp and stay job-ready?", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you always stay job-ready?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t87s3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699748828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title basically. &lt;/p&gt;\n\n&lt;p&gt;What do you do on a daily/weekly basis to keep your interview skills sharp and stay job-ready?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t87s3", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t87s3/how_do_you_always_stay_jobready/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t87s3/how_do_you_always_stay_jobready/", "subreddit_subscribers": 139208, "created_utc": 1699748828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience using Dremio and Starburst?  When should I consider using one over the other?  They seem very similar. \n\nThey both query Iceberg. Which one is faster?", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dremio vs Starburst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17svlvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699713182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience using Dremio and Starburst?  When should I consider using one over the other?  They seem very similar. &lt;/p&gt;\n\n&lt;p&gt;They both query Iceberg. Which one is faster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17svlvl", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17svlvl/dremio_vs_starburst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17svlvl/dremio_vs_starburst/", "subreddit_subscribers": 139208, "created_utc": 1699713182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm setting up a data warehouse in Oracle and could use some advice. At a previous job, a colleague of mine used a T-SQL stored procedure for SCD dimension tables in SQL Server.\n\nNow in Oracle, I'm wondering:\n1. What's the best way to handle SCD Type 2? Any specific Oracle ways?\n2. For scheduling these \u201cjobs\u201d, what's the Oracle equivalent of SQL Server Agent?\n\nPS: A colleague of mine proposed using Talend to handle this, but I think a more SQL native solution would be better - easier to understand and maintain.\n\nWould love to hear your opinions on this. Thanks!", "author_fullname": "t2_imnwscg17", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle Ninjas: How should I handle SCDs? (Data Warehouse)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t4r8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699739988.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699739086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m setting up a data warehouse in Oracle and could use some advice. At a previous job, a colleague of mine used a T-SQL stored procedure for SCD dimension tables in SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Now in Oracle, I&amp;#39;m wondering:\n1. What&amp;#39;s the best way to handle SCD Type 2? Any specific Oracle ways?\n2. For scheduling these \u201cjobs\u201d, what&amp;#39;s the Oracle equivalent of SQL Server Agent?&lt;/p&gt;\n\n&lt;p&gt;PS: A colleague of mine proposed using Talend to handle this, but I think a more SQL native solution would be better - easier to understand and maintain.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your opinions on this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t4r8q", "is_robot_indexable": true, "report_reasons": null, "author": "ByteAutomator", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17t4r8q/oracle_ninjas_how_should_i_handle_scds_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t4r8q/oracle_ninjas_how_should_i_handle_scds_data/", "subreddit_subscribers": 139208, "created_utc": 1699739086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: design pattern for loading / maintaining a conformed dimension.\n\nCan anyone reference a best practice for loading and then referencing conformed dimensions?Example: you have multiple systems that all reference \"location/financial location\" of work, though they identify it in different ways (Department, Profit Center, Account)Ultimately, what you want is all of your schemas to use the SAME \"location/financial location\" dimension (conformed dimension). There must be a recommended pattern/approach for building this with ETL/ETL?I'd guess its something like  \n\n\n1. maintain a link table that connects the business key from each source system to the conformed dimension key\n2. load all of the \"new\" data from each of the sources into some sort of staging area (lake, whatever)\n3. merge/match the data to generate new dimension rows\n4. etc.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load/Maintain Pattern for Conformed Dimension", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t3gfz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699735592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: design pattern for loading / maintaining a conformed dimension.&lt;/p&gt;\n\n&lt;p&gt;Can anyone reference a best practice for loading and then referencing conformed dimensions?Example: you have multiple systems that all reference &amp;quot;location/financial location&amp;quot; of work, though they identify it in different ways (Department, Profit Center, Account)Ultimately, what you want is all of your schemas to use the SAME &amp;quot;location/financial location&amp;quot; dimension (conformed dimension). There must be a recommended pattern/approach for building this with ETL/ETL?I&amp;#39;d guess its something like  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;maintain a link table that connects the business key from each source system to the conformed dimension key&lt;/li&gt;\n&lt;li&gt;load all of the &amp;quot;new&amp;quot; data from each of the sources into some sort of staging area (lake, whatever)&lt;/li&gt;\n&lt;li&gt;merge/match the data to generate new dimension rows&lt;/li&gt;\n&lt;li&gt;etc.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t3gfz", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t3gfz/loadmaintain_pattern_for_conformed_dimension/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t3gfz/loadmaintain_pattern_for_conformed_dimension/", "subreddit_subscribers": 139208, "created_utc": 1699735592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bxjjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seven Ways to Put CDC to Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_17sxiv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p-1bMdQlEO9XyREMAnnasGKtIVdM7SG1f6xPt3fJG8s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699718761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decodable.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decodable.co/blog/seven-ways-to-put-cdc-to-work", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?auto=webp&amp;s=6e1b24a0e3e5f942e335d40f22bbbeae2e09ede3", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3946929800677f18be110ad2d5337e3b5f99392", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4c41d292d9dfe6734617e03c8fc08207379fc048", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f98209135993d551d293acbf30e0b49def8351e", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8df7eb665b1cbbad290ae34d4f92684428e1dcc", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa00aa6abf8e7ec30d7dd778e450033135db2e9c", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1940b19737a954a031744950ae2aeaa47547ad8", "width": 1080, "height": 720}], "variants": {}, "id": "CwSgzNv0p-XF2ms2horJA6xnC8Sn8GyHtIhwC5LmGsA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17sxiv3", "is_robot_indexable": true, "report_reasons": null, "author": "gunnarmorling", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17sxiv3/seven_ways_to_put_cdc_to_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decodable.co/blog/seven-ways-to-put-cdc-to-work", "subreddit_subscribers": 139208, "created_utc": 1699718761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to hear what's worked for others!", "author_fullname": "t2_b0v8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your typical study/practice regime like when preparing for interviews? What resources proved to be the most helpful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ta1ga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699754623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to hear what&amp;#39;s worked for others!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17ta1ga", "is_robot_indexable": true, "report_reasons": null, "author": "thetalkingrock", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ta1ga/what_is_your_typical_studypractice_regime_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ta1ga/what_is_your_typical_studypractice_regime_like/", "subreddit_subscribers": 139208, "created_utc": 1699754623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I completed the DataTalksClub Data Engineering course months ago but wanted to share the project I worked on at the end of the course. The purpose of my project was to monitor the discussion regarding the Solana blockchain especially after the FTX Scandal and numerous outages. I wrote a pipeline using Prefect to extract data using Reddit\u2019s PRAW API from the Solana subreddit, a community devoted to discussing news regarding Solana. The data was then moved to a google cloud bucket as a staging area, cleaned and then moved to respective BigQuery tables. DBT was used to transform and merge tables for proper visualization into Google Looker Studio. \n\nLink to GitHub Repo: https://github.com/seacevedo/Solana-Pipeline\n\nObviously still learning and would like some input on how this project can be improved and what was done well, in order to apply to new projects in the future.", "author_fullname": "t2_3iljgzjo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Data Engineering Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17tcya9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699766538.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699764977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I completed the DataTalksClub Data Engineering course months ago but wanted to share the project I worked on at the end of the course. The purpose of my project was to monitor the discussion regarding the Solana blockchain especially after the FTX Scandal and numerous outages. I wrote a pipeline using Prefect to extract data using Reddit\u2019s PRAW API from the Solana subreddit, a community devoted to discussing news regarding Solana. The data was then moved to a google cloud bucket as a staging area, cleaned and then moved to respective BigQuery tables. DBT was used to transform and merge tables for proper visualization into Google Looker Studio. &lt;/p&gt;\n\n&lt;p&gt;Link to GitHub Repo: &lt;a href=\"https://github.com/seacevedo/Solana-Pipeline\"&gt;https://github.com/seacevedo/Solana-Pipeline&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Obviously still learning and would like some input on how this project can be improved and what was done well, in order to apply to new projects in the future.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?auto=webp&amp;s=023190404138d25a5a68ffb7c5e29a596c8dfb59", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5064b116703e5a163ecad944685aa1104411340a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cf5ff212df2c13ff3b522606931711d53e6f1e3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=21686ede1caa34ea3d6422912f06e02fb51348fe", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c3f308adb8ccedc3385edcbe1dc5120e6218df4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a97c633e1dc690b3c7ded51c6ba258a2fa5a1363", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-pOjLQtUH6z7yDeNZJvwUjqwo9mZ3kqRhHbdSLwponc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4bf8c0d4e866d95ad8e78bc1270a68f6aa7c311e", "width": 1080, "height": 540}], "variants": {}, "id": "b1WW75HQN8qfzQiYg8zxdZtnUyDbw0_T2cF5UoBGGWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17tcya9", "is_robot_indexable": true, "report_reasons": null, "author": "bass581", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17tcya9/first_data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17tcya9/first_data_engineering_project/", "subreddit_subscribers": 139208, "created_utc": 1699764977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, trying to play around with some personal projects and I'd like to build connections between my banking accounts and a SQL server. First off, just want to make sure this is possible as a consumer (main account is with Bank of America) and secondly, what tools should I use?\n\nI found a few youtube vids that were accessing banking transactions using Postman and the Open Banking API. once I manage to gain access to my bank's portal, is it just a manner of loading the data onto something like MySQL? Thanks!", "author_fullname": "t2_3k4h7uai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal Finance Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tbd16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699759069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, trying to play around with some personal projects and I&amp;#39;d like to build connections between my banking accounts and a SQL server. First off, just want to make sure this is possible as a consumer (main account is with Bank of America) and secondly, what tools should I use?&lt;/p&gt;\n\n&lt;p&gt;I found a few youtube vids that were accessing banking transactions using Postman and the Open Banking API. once I manage to gain access to my bank&amp;#39;s portal, is it just a manner of loading the data onto something like MySQL? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17tbd16", "is_robot_indexable": true, "report_reasons": null, "author": "peepoo123", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17tbd16/personal_finance_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17tbd16/personal_finance_dashboard/", "subreddit_subscribers": 139208, "created_utc": 1699759069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \nI have been in data engineering for not so long. I am using airbyte and fivetran for past few days to build some connections. \nOut of curiosity , i wanna understand how have they build these platforms, if I need to build something like airbyte , atleast like one one connection support in start, how should I go about?\nBasically, i wanna provide a front end tool like airbyte where people can make their connection without any coding. \nAny article, blog, repos will be appreciated.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No code etl tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17st2zb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699704453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, \nI have been in data engineering for not so long. I am using airbyte and fivetran for past few days to build some connections. \nOut of curiosity , i wanna understand how have they build these platforms, if I need to build something like airbyte , atleast like one one connection support in start, how should I go about?\nBasically, i wanna provide a front end tool like airbyte where people can make their connection without any coding. \nAny article, blog, repos will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17st2zb", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17st2zb/no_code_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17st2zb/no_code_etl_tool/", "subreddit_subscribers": 139208, "created_utc": 1699704453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hear me out with this one- it might be a bad idea that\u2019s going to cause more harm than good in the long run. However, maybe a proper implementation can mean this *could* be quite beneficial\u2026 I\u2019m not sure.\n\nI\u2019m in a scenario where I\u2019m building a data warehouse for my organization. At the moment, several departments have outsourced their storage needs to various companies. This causes issues and we want a single source for some data that gets used in some critical operations to our business. In theory, this is just going to make a painful process better, save the CEO (C-suit really) a bunch of time in meetings, you get the idea.\n\nThis project has become bottlenecked by another project: a webapp that needs to be smart enough for my users to input denormalized fields, and it can store the normalized records. I\u2019m not quite experienced with webapps, but seeing as this is going to require some logic I went with Django.\n\nLet me explain a little about my schema. My users want to store the historic rates for building materials. The source metrics are a quantity and cost_total. Unfortunately, because this has been tracked in Excel for decades, there\u2019s a bit of missing data.\n\nNow, a rate might be determined by dividing the item by a unit of measure, like square foot. Alternatively, a rate might be determined per instance of something in the project, like the number of Floors in the project (assuming we\u2019re building a house). E.g., you might measure the cost of Fire Sprinkler Systems per floor in the building, but Flooring costs per Square Foot of Flooring.\n\nSo I created a table to store costs for items, a table for quantities of project attributes, and a table for rates. The values for items and project attributes are NULLable, so in theory a rate can be stored with missing data.\n\nMy webapp has to be smart enough that users can select the fundamental components (project_name, item, \u2026) and it\u2019ll automatically find records for Quantity and Cost_Total, and allow users to create those records if needed or change them, while just submitting a rate. No problem, but it\u2019s going to take me awhile as I\u2019m no JavaScript guru.\n\nIn the meantime, I have business users who just want higher quality data sources now. They\u2019ve got deadlines and I don\u2019t know if I can finish the webapp + get my business users to input all their data quick enough. My business users do NOT (for some reason) want to take the quick start and make me an Excel/ CSV upload file.\n\nSo, I\u2019m wondering if there would be any sense at all in designing my other colleagues a file level database they can use as a single source of truth for the time being. I haven\u2019t brainstormed all the answers yet, but in theory maybe a temporary solution with SQLite3 and an ODBC driver can work for now. I could fill this much more quickly with basic data they\u2019d need and it could be a \u201csingle source of truth.\u201d \n\nRight now, an Excel file isn\u2019t a \u201csingle source of truth\u201d because of various nuances in how the existing workflow works\u2026 needing to copy data here and there\u2026. We\u2019ve got a long way ahead of us.\n\nIs this a bad idea guys? I\u2019m kind of curious what all of this makes you think about.\n\nThanks.", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of quick and dirty SQLite3 solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t3ryj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699747344.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699736490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hear me out with this one- it might be a bad idea that\u2019s going to cause more harm than good in the long run. However, maybe a proper implementation can mean this &lt;em&gt;could&lt;/em&gt; be quite beneficial\u2026 I\u2019m not sure.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m in a scenario where I\u2019m building a data warehouse for my organization. At the moment, several departments have outsourced their storage needs to various companies. This causes issues and we want a single source for some data that gets used in some critical operations to our business. In theory, this is just going to make a painful process better, save the CEO (C-suit really) a bunch of time in meetings, you get the idea.&lt;/p&gt;\n\n&lt;p&gt;This project has become bottlenecked by another project: a webapp that needs to be smart enough for my users to input denormalized fields, and it can store the normalized records. I\u2019m not quite experienced with webapps, but seeing as this is going to require some logic I went with Django.&lt;/p&gt;\n\n&lt;p&gt;Let me explain a little about my schema. My users want to store the historic rates for building materials. The source metrics are a quantity and cost_total. Unfortunately, because this has been tracked in Excel for decades, there\u2019s a bit of missing data.&lt;/p&gt;\n\n&lt;p&gt;Now, a rate might be determined by dividing the item by a unit of measure, like square foot. Alternatively, a rate might be determined per instance of something in the project, like the number of Floors in the project (assuming we\u2019re building a house). E.g., you might measure the cost of Fire Sprinkler Systems per floor in the building, but Flooring costs per Square Foot of Flooring.&lt;/p&gt;\n\n&lt;p&gt;So I created a table to store costs for items, a table for quantities of project attributes, and a table for rates. The values for items and project attributes are NULLable, so in theory a rate can be stored with missing data.&lt;/p&gt;\n\n&lt;p&gt;My webapp has to be smart enough that users can select the fundamental components (project_name, item, \u2026) and it\u2019ll automatically find records for Quantity and Cost_Total, and allow users to create those records if needed or change them, while just submitting a rate. No problem, but it\u2019s going to take me awhile as I\u2019m no JavaScript guru.&lt;/p&gt;\n\n&lt;p&gt;In the meantime, I have business users who just want higher quality data sources now. They\u2019ve got deadlines and I don\u2019t know if I can finish the webapp + get my business users to input all their data quick enough. My business users do NOT (for some reason) want to take the quick start and make me an Excel/ CSV upload file.&lt;/p&gt;\n\n&lt;p&gt;So, I\u2019m wondering if there would be any sense at all in designing my other colleagues a file level database they can use as a single source of truth for the time being. I haven\u2019t brainstormed all the answers yet, but in theory maybe a temporary solution with SQLite3 and an ODBC driver can work for now. I could fill this much more quickly with basic data they\u2019d need and it could be a \u201csingle source of truth.\u201d &lt;/p&gt;\n\n&lt;p&gt;Right now, an Excel file isn\u2019t a \u201csingle source of truth\u201d because of various nuances in how the existing workflow works\u2026 needing to copy data here and there\u2026. We\u2019ve got a long way ahead of us.&lt;/p&gt;\n\n&lt;p&gt;Is this a bad idea guys? I\u2019m kind of curious what all of this makes you think about.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17t3ryj", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t3ryj/what_do_you_think_of_quick_and_dirty_sqlite3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t3ryj/what_do_you_think_of_quick_and_dirty_sqlite3/", "subreddit_subscribers": 139208, "created_utc": 1699736490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm 27, working in the automotive industry in Brazil since 2018, when I joined a major company as an intern. While I  enjoy the engineering challenges, it's not where I see my future. The  salary progression in my field is slow, and growth opportunities are  scarce. \n\nI've been studying to transition into a technical role in data,  working on projects with Python and SQL. However, considering the skills  expected from a data engineer, it seems I have a long way to go. \n\nShould  I bridge the gap by transitioning to data analysis before becoming a  data engineer? Is it possible to jump straight ahead in data engineering? ", "author_fullname": "t2_83641vot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice for carrer transition coming from Mechanical Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t6l0u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699744037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m 27, working in the automotive industry in Brazil since 2018, when I joined a major company as an intern. While I  enjoy the engineering challenges, it&amp;#39;s not where I see my future. The  salary progression in my field is slow, and growth opportunities are  scarce. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been studying to transition into a technical role in data,  working on projects with Python and SQL. However, considering the skills  expected from a data engineer, it seems I have a long way to go. &lt;/p&gt;\n\n&lt;p&gt;Should  I bridge the gap by transitioning to data analysis before becoming a  data engineer? Is it possible to jump straight ahead in data engineering? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17t6l0u", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious-Cat-7016", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t6l0u/seeking_advice_for_carrer_transition_coming_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t6l0u/seeking_advice_for_carrer_transition_coming_from/", "subreddit_subscribers": 139208, "created_utc": 1699744037.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}