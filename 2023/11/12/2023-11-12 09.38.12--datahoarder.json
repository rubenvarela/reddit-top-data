{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've seen many archiving projects of old versions of popular games (the best example is [Omniarchive](https://omniarchive.uk/) that's archiving old Minecraft versions), except Fortnite. When I see Fortnite Archiving projects, they're dead or very small.\n\nMore than 50% of old Fortnite versions are lost. Which is so unreal to me. Some of the lost versions we're talking about were released during when Fortnite was **very popular**. (For example: 4.4 build, released in 2018.) \"Most wanted\" builds are before Battle Royale.\n\nSo, I am asking here. If you have any build that isn't listed [here](https://github.com/simplyblk/Fortnitebuilds), please DM me here.", "author_fullname": "t2_t6ightw1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archiving old Fortnite Builds/Versions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17sxb8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699718162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen many archiving projects of old versions of popular games (the best example is &lt;a href=\"https://omniarchive.uk/\"&gt;Omniarchive&lt;/a&gt; that&amp;#39;s archiving old Minecraft versions), except Fortnite. When I see Fortnite Archiving projects, they&amp;#39;re dead or very small.&lt;/p&gt;\n\n&lt;p&gt;More than 50% of old Fortnite versions are lost. Which is so unreal to me. Some of the lost versions we&amp;#39;re talking about were released during when Fortnite was &lt;strong&gt;very popular&lt;/strong&gt;. (For example: 4.4 build, released in 2018.) &amp;quot;Most wanted&amp;quot; builds are before Battle Royale.&lt;/p&gt;\n\n&lt;p&gt;So, I am asking here. If you have any build that isn&amp;#39;t listed &lt;a href=\"https://github.com/simplyblk/Fortnitebuilds\"&gt;here&lt;/a&gt;, please DM me here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p7eYqjFaW_nyebDDVoJ_pUlZqErNiJmyFluJiZ6G38g.jpg?auto=webp&amp;s=ef65892b6d243ef61dfc7ff2aa54ec56a9c83659", "width": 128, "height": 128}, "resolutions": [{"url": "https://external-preview.redd.it/p7eYqjFaW_nyebDDVoJ_pUlZqErNiJmyFluJiZ6G38g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=42d10f00467df9786bc222da7512eb9efcb9381a", "width": 108, "height": 108}], "variants": {}, "id": "qmaQ5xBLoURVxRDUic9pTp-AskE4yQLfOXVpKpgRqiw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17sxb8h", "is_robot_indexable": true, "report_reasons": null, "author": "plvqr", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17sxb8h/archiving_old_fortnite_buildsversions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17sxb8h/archiving_old_fortnite_buildsversions/", "subreddit_subscribers": 711665, "created_utc": 1699718162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently had an indicdent where I discovered that some image folders on the drive that I did a backup of were damaged which resulted in an incomplete/broken backup. Fortunately I managed to recover the damaged pictures from an old computer. \n\n**old computer and other devices** (no damaged files ) **--&gt; backup** (had some damaged files) **--&gt; backup of backup** (also got the damaged files)\n\nI know that the drive shouldn't had been used the state where files got damaged in the first place, but I'd like to know if there's a tool that can scan for inconsistencies among the files and identify if there are any damaged ones? Preferably without having to compare with the original files. \n\nI discovered the broken images by pure luck (it was only a couple of folders), and the thought of not doing this and continuing to backup broken files scares me at night when I try to sleep. ", "author_fullname": "t2_r76xkp0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unknown damaged files in backups scares me at night, is there a solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t8bop", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699749162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had an indicdent where I discovered that some image folders on the drive that I did a backup of were damaged which resulted in an incomplete/broken backup. Fortunately I managed to recover the damaged pictures from an old computer. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;old computer and other devices&lt;/strong&gt; (no damaged files ) &lt;strong&gt;--&amp;gt; backup&lt;/strong&gt; (had some damaged files) &lt;strong&gt;--&amp;gt; backup of backup&lt;/strong&gt; (also got the damaged files)&lt;/p&gt;\n\n&lt;p&gt;I know that the drive shouldn&amp;#39;t had been used the state where files got damaged in the first place, but I&amp;#39;d like to know if there&amp;#39;s a tool that can scan for inconsistencies among the files and identify if there are any damaged ones? Preferably without having to compare with the original files. &lt;/p&gt;\n\n&lt;p&gt;I discovered the broken images by pure luck (it was only a couple of folders), and the thought of not doing this and continuing to backup broken files scares me at night when I try to sleep. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t8bop", "is_robot_indexable": true, "report_reasons": null, "author": "mediamystery", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t8bop/unknown_damaged_files_in_backups_scares_me_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t8bop/unknown_damaged_files_in_backups_scares_me_at/", "subreddit_subscribers": 711665, "created_utc": 1699749162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I will digitize a couple of thousand pictures for my family and some of them range from 40-50 years ago, which means they are discolored and blurred.\n\nThe scanner I have doesn't have a good auto processing software (Canon Imageformula R40), it increases the contrast way too much and doesn't seem to understand that old photos get red with time.\n\nSo I was looking at ways to bulk process these images. It doesn't need to be perfect, it just need to improve a little bit. Does anyone has any tip?", "author_fullname": "t2_eg24o7dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips on how to bulk process digitized photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tc9gy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699762286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will digitize a couple of thousand pictures for my family and some of them range from 40-50 years ago, which means they are discolored and blurred.&lt;/p&gt;\n\n&lt;p&gt;The scanner I have doesn&amp;#39;t have a good auto processing software (Canon Imageformula R40), it increases the contrast way too much and doesn&amp;#39;t seem to understand that old photos get red with time.&lt;/p&gt;\n\n&lt;p&gt;So I was looking at ways to bulk process these images. It doesn&amp;#39;t need to be perfect, it just need to improve a little bit. Does anyone has any tip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tc9gy", "is_robot_indexable": true, "report_reasons": null, "author": "backwards_watch", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tc9gy/any_tips_on_how_to_bulk_process_digitized_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tc9gy/any_tips_on_how_to_bulk_process_digitized_photos/", "subreddit_subscribers": 711665, "created_utc": 1699762286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,I'm looking for some input into if I'm looking at the best options for an HBA card to expand my storage capacity for my Windows 10 machine.  Right now I've got 4 drives in my tower, and two drives externally hooked up via USB, as I don't have enough SATA ports on my motherboard to put everything internal.\n\nI have two PCIE x16 slots open, one with an x8 data lane and one with an x4 (as well as 3 x1 slots, but those I'm assuming are too slow to use for multiple HDDs).  I have a Fractal Design Define 7XL, so I can fit a lot of HDDs it into for my future needs, I just need to be sure that I'm set for at least 8 new HDDs before I consider adding either a second HBA card or upgrading to one with more ports.\n\nThe below table are the cards I've looked at that MIGHT work for me, but I'm honestly not certain on how good the brands are (aside from StarTech and LSI), or whether there are better options out there.\n\n|Manufacturer|PCIE Type|Speed|Architecture|\\# of Ports|Price|\n|:-|:-|:-|:-|:-|:-|\n|[BEYIMEI](https://www.amazon.com/BEYIMEI-Splitter-Profile-Controller-Expansion/dp/B09K5GLJ8D/ref=sr_1_19?crid=24FEGOPRRRXQR&amp;keywords=sas%2B3200&amp;qid=1699648061&amp;refinements=p_85%3A2470955011&amp;rnid=2470954011&amp;rps=1&amp;sprefix=sas%2B3200%2Caps%2C122&amp;sr=8-19&amp;th=1) |x16|6Gbps|6x ASM1064 - 1x ASM1812|24|$169.98|\n|[StarTech](https://www.amazon.com/StarTech-com-Port-SATA-PCIe-8P6G-PCIE-SATA-CARD/dp/B09KDLKYRN/ref=psdc_3012291011_t3_B0BVVDT4F1?th=1)|x4|6Gbps|ASM1062|10|$111.80|\n|[10GTek](https://www.amazon.com/dp/B07VV91L61/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=xbit-20&amp;linkId=80524adb8573cebbfb5fcc10b46f18fd&amp;language=en_US&amp;th=1)|x3|12Gbps|9300-8i|8|$112.99|\n|[LSI](https://www.amazon.com/dp/B0B23S57ZS?tag=apcstart-20&amp;linkCode=ogi&amp;th=1&amp;psc=1)||12Gbps|9300-16i|16|$149.00|\n|[LSI Broadcom](https://www.amazon.com/LSI-Broadcom-9300-8i-PCI-Express-Profile/dp/B00DSURZYS/ref=sr_1_4?crid=HPZ2IMJ8HVQL&amp;keywords=LSI+SAS9207-8i+8-Port+Internal+HBA+PCIe&amp;qid=1699716834&amp;sprefix=lsi+sas9207-8i+8-port+internal+hba+pcie%2Caps%2C174&amp;sr=8-4&amp;ufe=app_do%3Aamzn1.fos.d977788f-1483-4f76-90a3-786e4cdc8f10)|x3|12Gbps|9300-8i|8|$80.00|\n|[LSI Logic](https://www.amazon.com/SAS9211-8I-8PORT-Int-Sata-Pcie/dp/B002RL8I7M/ref=sr_1_2?crid=HPZ2IMJ8HVQL&amp;keywords=LSI+SAS9207-8i+8-Port+Internal+HBA+PCIe&amp;qid=1699716834&amp;sprefix=lsi+sas9207-8i+8-port+internal+hba+pcie%2Caps%2C174&amp;sr=8-2&amp;ufe=app_do%3Aamzn1.fos.d977788f-1483-4f76-90a3-786e4cdc8f10)|x2|6Gbps|9211-8i|8|$64.90|\n\nI know that there is a lot of knowledge in this subreddit, and I really appreciate if anyone can steer me in the right/better direction on this.\n\nThanks in advance for any help!", "author_fullname": "t2_d8cma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Proper HBA card for Windows 10 server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t3t10", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699736558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,I&amp;#39;m looking for some input into if I&amp;#39;m looking at the best options for an HBA card to expand my storage capacity for my Windows 10 machine.  Right now I&amp;#39;ve got 4 drives in my tower, and two drives externally hooked up via USB, as I don&amp;#39;t have enough SATA ports on my motherboard to put everything internal.&lt;/p&gt;\n\n&lt;p&gt;I have two PCIE x16 slots open, one with an x8 data lane and one with an x4 (as well as 3 x1 slots, but those I&amp;#39;m assuming are too slow to use for multiple HDDs).  I have a Fractal Design Define 7XL, so I can fit a lot of HDDs it into for my future needs, I just need to be sure that I&amp;#39;m set for at least 8 new HDDs before I consider adding either a second HBA card or upgrading to one with more ports.&lt;/p&gt;\n\n&lt;p&gt;The below table are the cards I&amp;#39;ve looked at that MIGHT work for me, but I&amp;#39;m honestly not certain on how good the brands are (aside from StarTech and LSI), or whether there are better options out there.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Manufacturer&lt;/th&gt;\n&lt;th align=\"left\"&gt;PCIE Type&lt;/th&gt;\n&lt;th align=\"left\"&gt;Speed&lt;/th&gt;\n&lt;th align=\"left\"&gt;Architecture&lt;/th&gt;\n&lt;th align=\"left\"&gt;# of Ports&lt;/th&gt;\n&lt;th align=\"left\"&gt;Price&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/BEYIMEI-Splitter-Profile-Controller-Expansion/dp/B09K5GLJ8D/ref=sr_1_19?crid=24FEGOPRRRXQR&amp;amp;keywords=sas%2B3200&amp;amp;qid=1699648061&amp;amp;refinements=p_85%3A2470955011&amp;amp;rnid=2470954011&amp;amp;rps=1&amp;amp;sprefix=sas%2B3200%2Caps%2C122&amp;amp;sr=8-19&amp;amp;th=1\"&gt;BEYIMEI&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;x16&lt;/td&gt;\n&lt;td align=\"left\"&gt;6Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;6x ASM1064 - 1x ASM1812&lt;/td&gt;\n&lt;td align=\"left\"&gt;24&lt;/td&gt;\n&lt;td align=\"left\"&gt;$169.98&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/StarTech-com-Port-SATA-PCIe-8P6G-PCIE-SATA-CARD/dp/B09KDLKYRN/ref=psdc_3012291011_t3_B0BVVDT4F1?th=1\"&gt;StarTech&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;x4&lt;/td&gt;\n&lt;td align=\"left\"&gt;6Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;ASM1062&lt;/td&gt;\n&lt;td align=\"left\"&gt;10&lt;/td&gt;\n&lt;td align=\"left\"&gt;$111.80&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/dp/B07VV91L61/ref=as_li_ss_tl?ie=UTF8&amp;amp;linkCode=ll1&amp;amp;tag=xbit-20&amp;amp;linkId=80524adb8573cebbfb5fcc10b46f18fd&amp;amp;language=en_US&amp;amp;th=1\"&gt;10GTek&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;x3&lt;/td&gt;\n&lt;td align=\"left\"&gt;12Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;9300-8i&lt;/td&gt;\n&lt;td align=\"left\"&gt;8&lt;/td&gt;\n&lt;td align=\"left\"&gt;$112.99&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/dp/B0B23S57ZS?tag=apcstart-20&amp;amp;linkCode=ogi&amp;amp;th=1&amp;amp;psc=1\"&gt;LSI&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;12Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;9300-16i&lt;/td&gt;\n&lt;td align=\"left\"&gt;16&lt;/td&gt;\n&lt;td align=\"left\"&gt;$149.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/LSI-Broadcom-9300-8i-PCI-Express-Profile/dp/B00DSURZYS/ref=sr_1_4?crid=HPZ2IMJ8HVQL&amp;amp;keywords=LSI+SAS9207-8i+8-Port+Internal+HBA+PCIe&amp;amp;qid=1699716834&amp;amp;sprefix=lsi+sas9207-8i+8-port+internal+hba+pcie%2Caps%2C174&amp;amp;sr=8-4&amp;amp;ufe=app_do%3Aamzn1.fos.d977788f-1483-4f76-90a3-786e4cdc8f10\"&gt;LSI Broadcom&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;x3&lt;/td&gt;\n&lt;td align=\"left\"&gt;12Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;9300-8i&lt;/td&gt;\n&lt;td align=\"left\"&gt;8&lt;/td&gt;\n&lt;td align=\"left\"&gt;$80.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://www.amazon.com/SAS9211-8I-8PORT-Int-Sata-Pcie/dp/B002RL8I7M/ref=sr_1_2?crid=HPZ2IMJ8HVQL&amp;amp;keywords=LSI+SAS9207-8i+8-Port+Internal+HBA+PCIe&amp;amp;qid=1699716834&amp;amp;sprefix=lsi+sas9207-8i+8-port+internal+hba+pcie%2Caps%2C174&amp;amp;sr=8-2&amp;amp;ufe=app_do%3Aamzn1.fos.d977788f-1483-4f76-90a3-786e4cdc8f10\"&gt;LSI Logic&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;x2&lt;/td&gt;\n&lt;td align=\"left\"&gt;6Gbps&lt;/td&gt;\n&lt;td align=\"left\"&gt;9211-8i&lt;/td&gt;\n&lt;td align=\"left\"&gt;8&lt;/td&gt;\n&lt;td align=\"left\"&gt;$64.90&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;I know that there is a lot of knowledge in this subreddit, and I really appreciate if anyone can steer me in the right/better direction on this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t3t10", "is_robot_indexable": true, "report_reasons": null, "author": "dakar82", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t3t10/proper_hba_card_for_windows_10_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t3t10/proper_hba_card_for_windows_10_server/", "subreddit_subscribers": 711665, "created_utc": 1699736558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nCurrently have 2 x 16TB hard drives containing movie files plugged directly into my router to share across my network. Works flawlessly. This is in a cupboard under the stairs.\n\nOne of the drives is full and the other is close to being full so I\u2019m going to have to think about a different arrangement once I buy a third 16TB HDD (router only has 2 x USB ports).\n\nThe setup will have to remain in the cupboard under the stairs so space is limited. Initial thought is to buy a Surface Pro and a multi HDD dock to go into the SP and then gigabit into the router.\n\nInterested to hear any other possible ideas.\n\nTIA \ud83d\ude42", "author_fullname": "t2_aupjndba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best solution for my storage problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17suats", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699709030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Currently have 2 x 16TB hard drives containing movie files plugged directly into my router to share across my network. Works flawlessly. This is in a cupboard under the stairs.&lt;/p&gt;\n\n&lt;p&gt;One of the drives is full and the other is close to being full so I\u2019m going to have to think about a different arrangement once I buy a third 16TB HDD (router only has 2 x USB ports).&lt;/p&gt;\n\n&lt;p&gt;The setup will have to remain in the cupboard under the stairs so space is limited. Initial thought is to buy a Surface Pro and a multi HDD dock to go into the SP and then gigabit into the router.&lt;/p&gt;\n\n&lt;p&gt;Interested to hear any other possible ideas.&lt;/p&gt;\n\n&lt;p&gt;TIA \ud83d\ude42&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17suats", "is_robot_indexable": true, "report_reasons": null, "author": "Low-Office8421", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17suats/best_solution_for_my_storage_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17suats/best_solution_for_my_storage_problem/", "subreddit_subscribers": 711665, "created_utc": 1699709030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\ni found a offering on Ebay for refurbished seagate enterprise capacity harddrives with a good price (12tb/120\u20ac).\n\nHas anyone experience using these drives in a nas and would recommend them ? Or should I stay away?\n\nI\u2019m running a 4 bay nas with raid5.\n\nThanks.", "author_fullname": "t2_18d60sm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Refurbished Seagate Enterprise Capacity for Nas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_17tg4ul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i53F1Hnz0SHAvA6GsiwkP9Vu8oAZADbATdfixHZUe8M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699778560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\ni found a offering on Ebay for refurbished seagate enterprise capacity harddrives with a good price (12tb/120\u20ac).&lt;/p&gt;\n\n&lt;p&gt;Has anyone experience using these drives in a nas and would recommend them ? Or should I stay away?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m running a 4 bay nas with raid5.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4e9lshqcqvzb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?auto=webp&amp;s=746162479822935741d51396cb1e9168f08ed7a2", "width": 1125, "height": 1637}, "resolutions": [{"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27f91d59bab9bb41057dabb4fd965489477f7291", "width": 108, "height": 157}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47458dc7a2c8d8207d3cebb6e6eb2ab9803747f6", "width": 216, "height": 314}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1f1f6664bc6389786529e606d40533a8fe4bbf7", "width": 320, "height": 465}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c333f31de9209635cda4e8174ffe5874008a1a1", "width": 640, "height": 931}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2632bf64cbfa9747aa157dee01ba798cbe2706a4", "width": 960, "height": 1396}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01decaae033b33c1c4711a47c89a316fddd470", "width": 1080, "height": 1571}], "variants": {}, "id": "XYYwksRwZfPHxHbKXeBYXQwy5RGyXQ5W-RMNNxD6pXI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tg4ul", "is_robot_indexable": true, "report_reasons": null, "author": "chaosys", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tg4ul/has_anyone_used_refurbished_seagate_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4e9lshqcqvzb1.jpg", "subreddit_subscribers": 711665, "created_utc": 1699778560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to start data hoarding ebooks and other educational media, this drive will live off the grid most of the time as my area gets a lot of storms and I've lost a previous setup to a surge (surge protectors did not help).\nThe drive will not see much reading, mainly writing so I was thinking maybe a surveillance drive might be best.\nI'm looking at around ~2tb of calculated storage I'll be needing so maybe a 4tb or 8tb or higher(if possible with my budget) might be better in order to have some more space for future data needs. What are my best options below 150 euro?", "author_fullname": "t2_69j5jfgc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best 4tb to 8tb drive below 150 euros", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17tflov", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699776634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699776089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to start data hoarding ebooks and other educational media, this drive will live off the grid most of the time as my area gets a lot of storms and I&amp;#39;ve lost a previous setup to a surge (surge protectors did not help).\nThe drive will not see much reading, mainly writing so I was thinking maybe a surveillance drive might be best.\nI&amp;#39;m looking at around ~2tb of calculated storage I&amp;#39;ll be needing so maybe a 4tb or 8tb or higher(if possible with my budget) might be better in order to have some more space for future data needs. What are my best options below 150 euro?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tflov", "is_robot_indexable": true, "report_reasons": null, "author": "ComfyCore", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tflov/best_4tb_to_8tb_drive_below_150_euros/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tflov/best_4tb_to_8tb_drive_below_150_euros/", "subreddit_subscribers": 711665, "created_utc": 1699776089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my old PC my secondary HDD would keep spinning when I restarted my PC, but on my new one it spins down and spins back up on restart which I don't want as it's not good for the drive.\n\nI have the B650 Tomahawk Motherboard - Is there perhaps some sort of setting I can change? Thanks.", "author_fullname": "t2_ag5e2mic0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to stop secondary HDD from spinning down on restart?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tf2la", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699773728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my old PC my secondary HDD would keep spinning when I restarted my PC, but on my new one it spins down and spins back up on restart which I don&amp;#39;t want as it&amp;#39;s not good for the drive.&lt;/p&gt;\n\n&lt;p&gt;I have the B650 Tomahawk Motherboard - Is there perhaps some sort of setting I can change? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tf2la", "is_robot_indexable": true, "report_reasons": null, "author": "ArmorOfAltair", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tf2la/any_way_to_stop_secondary_hdd_from_spinning_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tf2la/any_way_to_stop_secondary_hdd_from_spinning_down/", "subreddit_subscribers": 711665, "created_utc": 1699773728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Running Seatools on a job lot of used disks, a WD Blue 2 TB came up as 0 power-on hours. It has Windows 10 installed (but no user files), so should be a few hours at least. The other SMART data looks plausible. I have used Seatools on WD drives before, and it always showed many hours for those.", "author_fullname": "t2_3bw5dt30", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seatools showing zero hours on old drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ta17h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699754603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Running Seatools on a job lot of used disks, a WD Blue 2 TB came up as 0 power-on hours. It has Windows 10 installed (but no user files), so should be a few hours at least. The other SMART data looks plausible. I have used Seatools on WD drives before, and it always showed many hours for those.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ta17h", "is_robot_indexable": true, "report_reasons": null, "author": "VS2ute", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ta17h/seatools_showing_zero_hours_on_old_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ta17h/seatools_showing_zero_hours_on_old_drive/", "subreddit_subscribers": 711665, "created_utc": 1699754603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI recently got a Synology DS923+ for someone as a gift, and installed the drives/ran initial setup so that it will be good to go when they open it.\n\nMy question is - i**s it safe to repackage the unit in the box that it arrived in now that the drives are installed?** It is almost all cardboard while the NAS itself came wrapped in a light cloth material \n\nI don't see why it wouldn't be , but I wanted to make sure before I bricked some 20 TB drives\n\nThank you in advance!", "author_fullname": "t2_kqraiwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it safe to store a NAS with installed HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t4g5r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699738266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I recently got a Synology DS923+ for someone as a gift, and installed the drives/ran initial setup so that it will be good to go when they open it.&lt;/p&gt;\n\n&lt;p&gt;My question is - i&lt;strong&gt;s it safe to repackage the unit in the box that it arrived in now that the drives are installed?&lt;/strong&gt; It is almost all cardboard while the NAS itself came wrapped in a light cloth material &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see why it wouldn&amp;#39;t be , but I wanted to make sure before I bricked some 20 TB drives&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t4g5r", "is_robot_indexable": true, "report_reasons": null, "author": "FiziksMayMays", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t4g5r/is_it_safe_to_store_a_nas_with_installed_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t4g5r/is_it_safe_to_store_a_nas_with_installed_hdds/", "subreddit_subscribers": 711665, "created_utc": 1699738266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey Everyone,\nI was just wondering what the most efficient and/or cost efficient way to transfer data from smaller external hard drives into a much larger external hard drive. I've definitely connected both to my pc but to be honest, that can take hours and days. What are some faster or just more efficient processes for doing so? \nThanks", "author_fullname": "t2_i7183", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best method or transferring multiple external HDDs to single external HDD (or SSD)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t2chu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699732508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,\nI was just wondering what the most efficient and/or cost efficient way to transfer data from smaller external hard drives into a much larger external hard drive. I&amp;#39;ve definitely connected both to my pc but to be honest, that can take hours and days. What are some faster or just more efficient processes for doing so? \nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t2chu", "is_robot_indexable": true, "report_reasons": null, "author": "OutlawJournalist", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t2chu/best_method_or_transferring_multiple_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t2chu/best_method_or_transferring_multiple_external/", "subreddit_subscribers": 711665, "created_utc": 1699732508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone, new to this whole world and haven\u2019t jumped in on purchasing an NAS yet, but had a question. With the synology units I notice they have a USB port and an Ethernet port as well. I\u2019m wondering if I have the device connected to my home network via the Ethernet port, can I also have it connected to my PC with the USB port?\n\nBy doing this I\u2019m wondering if I can have the computer recognize it as an external attached storage device (therefore it will sync to Backblaze as an attached hard drive), but I would still be able to access files over the network from my laptop if the desktop computer its attached to (by usb) is turned off. Do you know if this is possible?", "author_fullname": "t2_a2ekvhrw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about synology USB port &amp; Ethernet ports\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t1if6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699730191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, new to this whole world and haven\u2019t jumped in on purchasing an NAS yet, but had a question. With the synology units I notice they have a USB port and an Ethernet port as well. I\u2019m wondering if I have the device connected to my home network via the Ethernet port, can I also have it connected to my PC with the USB port?&lt;/p&gt;\n\n&lt;p&gt;By doing this I\u2019m wondering if I can have the computer recognize it as an external attached storage device (therefore it will sync to Backblaze as an attached hard drive), but I would still be able to access files over the network from my laptop if the desktop computer its attached to (by usb) is turned off. Do you know if this is possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t1if6", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Abrocoma7460", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t1if6/question_about_synology_usb_port_ethernet_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t1if6/question_about_synology_usb_port_ethernet_ports/", "subreddit_subscribers": 711665, "created_utc": 1699730191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nI know there are various tools that are supposed to make this easy, but I couldn't find anything that did everything I wanted, so I made this today for fun. The web-based offerings all take forever and seem flaky, and you need to process one video at a time, with no control over the transcription settings. In contrast, my script lets you convert a whole playlist in bulk with full control over everything.\n\nIt's truly easy to use-- you can clone the repo, install to a venv, and be generating a folder full of high quality transcript text files in under 5 minutes. All you need to do is supply the URL to a YouTube playlist or to an individual video file and this tool does the rest automatically. It uses faster-whisper with a high beam_size, so it's a bit slower than you might expect, but this does result in higher accuracy. The best way to use this is to take an existing playlist, or create a new one on YouTube, start this script up, and come back the next morning with all your finished transcripts. It attempts to \"upgrade\" the output of whisper by taking all the transcript segments, gluing them together, and then splitting them back into sentences (it uses Spacy for this, or a simpler regex-based function). You end up with a single text file with the full transcript all ready to go for each video in the playlist, with a sensible file name based on the title of the video.\n\nIf you have CUDA installed, it will try to use it, but as with all things CUDA, it's annoyingly fragile and picky, so don't be surprised if you get a CUDA error even if you know for a fact CUDA is installed on your system. If you're looking for reliability, disable CUDA. But if you need to transcribe a LOT of transcripts, it does go much, much faster on a GPU.\n\nEven if you don't have a GPU, if you have a powerful machine with a lot of RAM and cores, this script will fully saturate them and can download and process multiple videos at the same time. The default settings are pretty good for that situation. But if you have a slower machine, you might want to use a smaller Whisper model (like `base.en` or even `tiny.en`) and dial down the beam_size to 2.", "author_fullname": "t2_aod18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Creation of Transcripts from YouTube Playlists with Whisper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17t9njk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/D-XXy6YrNXiUtVtN5bMxWdMP4sgukGjnQ30cIIMRo5A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699753392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are various tools that are supposed to make this easy, but I couldn&amp;#39;t find anything that did everything I wanted, so I made this today for fun. The web-based offerings all take forever and seem flaky, and you need to process one video at a time, with no control over the transcription settings. In contrast, my script lets you convert a whole playlist in bulk with full control over everything.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s truly easy to use-- you can clone the repo, install to a venv, and be generating a folder full of high quality transcript text files in under 5 minutes. All you need to do is supply the URL to a YouTube playlist or to an individual video file and this tool does the rest automatically. It uses faster-whisper with a high beam_size, so it&amp;#39;s a bit slower than you might expect, but this does result in higher accuracy. The best way to use this is to take an existing playlist, or create a new one on YouTube, start this script up, and come back the next morning with all your finished transcripts. It attempts to &amp;quot;upgrade&amp;quot; the output of whisper by taking all the transcript segments, gluing them together, and then splitting them back into sentences (it uses Spacy for this, or a simpler regex-based function). You end up with a single text file with the full transcript all ready to go for each video in the playlist, with a sensible file name based on the title of the video.&lt;/p&gt;\n\n&lt;p&gt;If you have CUDA installed, it will try to use it, but as with all things CUDA, it&amp;#39;s annoyingly fragile and picky, so don&amp;#39;t be surprised if you get a CUDA error even if you know for a fact CUDA is installed on your system. If you&amp;#39;re looking for reliability, disable CUDA. But if you need to transcribe a LOT of transcripts, it does go much, much faster on a GPU.&lt;/p&gt;\n\n&lt;p&gt;Even if you don&amp;#39;t have a GPU, if you have a powerful machine with a lot of RAM and cores, this script will fully saturate them and can download and process multiple videos at the same time. The default settings are pretty good for that situation. But if you have a slower machine, you might want to use a smaller Whisper model (like &lt;code&gt;base.en&lt;/code&gt; or even &lt;code&gt;tiny.en&lt;/code&gt;) and dial down the beam_size to 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Dicklesworthstone/bulk_transcribe_youtube_videos_from_playlist", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?auto=webp&amp;s=a5c47fe51bbccf0042e5be1ac685c7e1ada6785b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d74027886f21186594414c9e5442db3302b84319", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a68965eaa4d977135a9db6348742ecbf14ccb39", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=224f1d15fe382d62897ece3d3b0cbca3dc4ddc8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=12d4c43e9677640dd45453e7571e526344042af1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6458c4abe5f18282bdf72aae5e0bc6c2acd79ca9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96b0dc841672059c889a1b90c380b65ab5d9cb37", "width": 1080, "height": 540}], "variants": {}, "id": "v-Wj3rAYmAz36GP-eHRThTYuIed01ANmkIAj0Pls8HQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t9njk", "is_robot_indexable": true, "report_reasons": null, "author": "dicklesworth", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t9njk/bulk_creation_of_transcripts_from_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Dicklesworthstone/bulk_transcribe_youtube_videos_from_playlist", "subreddit_subscribers": 711665, "created_utc": 1699753392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI've got two drives connected to a mini pc that's powered 24/7: a 6TB WD Blue (it's actually a WD Elements but the serial number is the same, guess it is SMR btw) and a 2TB WD Purple (this one is CMR I think).\n\nThese are the tasks I want to perform:\n\n- Back up my desktop computer (pictures, music, documents, etc.).\n- Store videos and music to be streamed through Navidrome and Jellyfin.\n- Back up those videos and music.\n- Download torrents.\n- Store and seed torrent files.\n- Back up those torrent files just in case (private trackers are hard).\n\nSo, the question is, how would you distribute this tasks between both drives?\n\nI'm thinking about keeping both plugged in and using the purple for backing up and leeching torrents, and the blue for storing music and video and seeding torrents (also making an additional desktop backup if there's free space); OR using the Purple to leech&amp;seed torrents and store the music and movies, and leaving the blue offline for backing up everything.\n\nNot planning to torrent more than 1.5tb in the next 5 years though.\n\nThanks!", "author_fullname": "t2_i70y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Assigning roles to my HDD drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t2kgj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699733112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got two drives connected to a mini pc that&amp;#39;s powered 24/7: a 6TB WD Blue (it&amp;#39;s actually a WD Elements but the serial number is the same, guess it is SMR btw) and a 2TB WD Purple (this one is CMR I think).&lt;/p&gt;\n\n&lt;p&gt;These are the tasks I want to perform:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Back up my desktop computer (pictures, music, documents, etc.).&lt;/li&gt;\n&lt;li&gt;Store videos and music to be streamed through Navidrome and Jellyfin.&lt;/li&gt;\n&lt;li&gt;Back up those videos and music.&lt;/li&gt;\n&lt;li&gt;Download torrents.&lt;/li&gt;\n&lt;li&gt;Store and seed torrent files.&lt;/li&gt;\n&lt;li&gt;Back up those torrent files just in case (private trackers are hard).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So, the question is, how would you distribute this tasks between both drives?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking about keeping both plugged in and using the purple for backing up and leeching torrents, and the blue for storing music and video and seeding torrents (also making an additional desktop backup if there&amp;#39;s free space); OR using the Purple to leech&amp;amp;seed torrents and store the music and movies, and leaving the blue offline for backing up everything.&lt;/p&gt;\n\n&lt;p&gt;Not planning to torrent more than 1.5tb in the next 5 years though.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t2kgj", "is_robot_indexable": true, "report_reasons": null, "author": "alvarodel8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t2kgj/assigning_roles_to_my_hdd_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t2kgj/assigning_roles_to_my_hdd_drives/", "subreddit_subscribers": 711665, "created_utc": 1699733112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hoping someone here has a better understanding of these tools than I do and might be willing to help me out - or perhaps can point me to an existing example.\n\nI have Macrium on my Win11 computer set up to backup my Windows drive (`C:\\`, 2TB) and my VMs drive (`D:\\` 2TB) to my onboard backups drive (`E:\\`, 8TB) using the default Grandfather, Father, Son strategy for both sets of backups. I also have two external SSDs (`A:\\` and `B:\\`, 4TB) which I would like to keep backups on as well. I can plug either (or both) in once a day, but I was thinking of rotating one offsite weekly and have them unplugged most of the time for some additional protection.\n\nAt the moment, I am thinking a reasonable strategy would be to automatically sync backup images to either of two USB SSD drives when plugged in. I have this sort of working with SyncFolder from the Microsoft Store, but I want to protect the drive with MacriumImageGuardian, which would I think would prevent SyncFolder from deleting files, and eventually the external drives will run out of space which will require a different retention strategy for `A:\\` and `B:\\` (external backups) than for `E:\\` (onboard backups).\n\n[This discussion](https://forum.macrium.com/38582/Sync-Options?PageIndex=1) explains how to make a powershell script within macrium to sync to two destinations *when a backup is completed*.\n\n[This discussion](https://forum.macrium.com/Topic332.aspx) explains how to make a powershell script that detects when a drive has been mounted and *copy* files over, but it also seems like it is doing a lot of other stuff  which I'm not sure I need - also not sure how \"the script is started at user logon\".\n\n[This discussion](https://forum.macrium.com/Topic42020.aspx) includes a link to a description of how to set up backups to run when a drive is plugged in, but it relies on another piece of software to trigger the script, which I would like to avoid. [Here's](https://techcommunity.microsoft.com/t5/windows-powershell/automaticlly-running-a-ps-script-when-the-usb-drive-is-plugged/m-p/3663653) an example of running a script automatically using just windows event log.\n\n**Questions:**\n\n1. Is there a smarter way to keep backups on the two external drives than what I'm asking for?\n2. if not... then is there a straightforward way to combine the script ideas from those two links to sync backups from `E:\\Macrium Reflect\\C Drive` to `A|B:\\Macrium Reflect\\C Drive` when `A:\\` or `B:\\` is plugged in and have it unmount `A:\\` or `B:\\`when the sync is completed?\n3. Is there a way to add a different retention strategy to `A:\\` and `B:\\` to keep this from breaking as they fill up, but while `E:\\` still has space?\n\n&amp;#x200B;", "author_fullname": "t2_4yuut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Macrium sync images to USB SSDs when plugged in, or other strategy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t1n2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699757208.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699730561.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping someone here has a better understanding of these tools than I do and might be willing to help me out - or perhaps can point me to an existing example.&lt;/p&gt;\n\n&lt;p&gt;I have Macrium on my Win11 computer set up to backup my Windows drive (&lt;code&gt;C:\\&lt;/code&gt;, 2TB) and my VMs drive (&lt;code&gt;D:\\&lt;/code&gt; 2TB) to my onboard backups drive (&lt;code&gt;E:\\&lt;/code&gt;, 8TB) using the default Grandfather, Father, Son strategy for both sets of backups. I also have two external SSDs (&lt;code&gt;A:\\&lt;/code&gt; and &lt;code&gt;B:\\&lt;/code&gt;, 4TB) which I would like to keep backups on as well. I can plug either (or both) in once a day, but I was thinking of rotating one offsite weekly and have them unplugged most of the time for some additional protection.&lt;/p&gt;\n\n&lt;p&gt;At the moment, I am thinking a reasonable strategy would be to automatically sync backup images to either of two USB SSD drives when plugged in. I have this sort of working with SyncFolder from the Microsoft Store, but I want to protect the drive with MacriumImageGuardian, which would I think would prevent SyncFolder from deleting files, and eventually the external drives will run out of space which will require a different retention strategy for &lt;code&gt;A:\\&lt;/code&gt; and &lt;code&gt;B:\\&lt;/code&gt; (external backups) than for &lt;code&gt;E:\\&lt;/code&gt; (onboard backups).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forum.macrium.com/38582/Sync-Options?PageIndex=1\"&gt;This discussion&lt;/a&gt; explains how to make a powershell script within macrium to sync to two destinations &lt;em&gt;when a backup is completed&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forum.macrium.com/Topic332.aspx\"&gt;This discussion&lt;/a&gt; explains how to make a powershell script that detects when a drive has been mounted and &lt;em&gt;copy&lt;/em&gt; files over, but it also seems like it is doing a lot of other stuff  which I&amp;#39;m not sure I need - also not sure how &amp;quot;the script is started at user logon&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://forum.macrium.com/Topic42020.aspx\"&gt;This discussion&lt;/a&gt; includes a link to a description of how to set up backups to run when a drive is plugged in, but it relies on another piece of software to trigger the script, which I would like to avoid. &lt;a href=\"https://techcommunity.microsoft.com/t5/windows-powershell/automaticlly-running-a-ps-script-when-the-usb-drive-is-plugged/m-p/3663653\"&gt;Here&amp;#39;s&lt;/a&gt; an example of running a script automatically using just windows event log.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a smarter way to keep backups on the two external drives than what I&amp;#39;m asking for?&lt;/li&gt;\n&lt;li&gt;if not... then is there a straightforward way to combine the script ideas from those two links to sync backups from &lt;code&gt;E:\\Macrium Reflect\\C Drive&lt;/code&gt; to &lt;code&gt;A|B:\\Macrium Reflect\\C Drive&lt;/code&gt; when &lt;code&gt;A:\\&lt;/code&gt; or &lt;code&gt;B:\\&lt;/code&gt; is plugged in and have it unmount &lt;code&gt;A:\\&lt;/code&gt; or &lt;code&gt;B:\\&lt;/code&gt;when the sync is completed?&lt;/li&gt;\n&lt;li&gt;Is there a way to add a different retention strategy to &lt;code&gt;A:\\&lt;/code&gt; and &lt;code&gt;B:\\&lt;/code&gt; to keep this from breaking as they fill up, but while &lt;code&gt;E:\\&lt;/code&gt; still has space?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t1n2x", "is_robot_indexable": true, "report_reasons": null, "author": "verticalfuzz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t1n2x/macrium_sync_images_to_usb_ssds_when_plugged_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t1n2x/macrium_sync_images_to_usb_ssds_when_plugged_in/", "subreddit_subscribers": 711665, "created_utc": 1699730561.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a library of images, each organized into folders by the author of the image. I've been using [Stash](https://github.com/stashapp/stash) to easily view these images in chronological order which works great, but it lacks the ability to pull EXIF information out of jpgs automatically, and drilling down to find the author of an image requires a few clicks. It has a good image tagging system, but there again you need to click through a bunch of times to get to the edit functions, which is time consuming when needing to process a lot of images.\n\nThe only other image viewer that I've found come close to Stash's functionality is [Damselfly](https://github.com/Webreaper/Damselfly), which automatically pulls EXIF data out of images and offers a few different view styles (thumbnail size/chronological/by date etc). However, it seems more geared towards image editing and not image viewing.\n\nWhat other options are out there that I'm not aware of? My image library is stored locally, and I'm interested in a web-based solution that runs in docker for ease of use. \n\nThank you for your suggestions!", "author_fullname": "t2_4af0sxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image viewer/organizers like stash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17svmr0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699713253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a library of images, each organized into folders by the author of the image. I&amp;#39;ve been using &lt;a href=\"https://github.com/stashapp/stash\"&gt;Stash&lt;/a&gt; to easily view these images in chronological order which works great, but it lacks the ability to pull EXIF information out of jpgs automatically, and drilling down to find the author of an image requires a few clicks. It has a good image tagging system, but there again you need to click through a bunch of times to get to the edit functions, which is time consuming when needing to process a lot of images.&lt;/p&gt;\n\n&lt;p&gt;The only other image viewer that I&amp;#39;ve found come close to Stash&amp;#39;s functionality is &lt;a href=\"https://github.com/Webreaper/Damselfly\"&gt;Damselfly&lt;/a&gt;, which automatically pulls EXIF data out of images and offers a few different view styles (thumbnail size/chronological/by date etc). However, it seems more geared towards image editing and not image viewing.&lt;/p&gt;\n\n&lt;p&gt;What other options are out there that I&amp;#39;m not aware of? My image library is stored locally, and I&amp;#39;m interested in a web-based solution that runs in docker for ease of use. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?auto=webp&amp;s=1cae3af43990ba418a9a44c609139991e2f7d92c", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e573726d938f0f322a4f588b212489fc16a4339", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=18f1409e9417ca5b6545fdb73d50b9f864c19564", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d7695d7caaa13db2bc65fafad0c45b3b330b4445", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2448102bc241a6dc148a6e5556490140b803d69", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=505e9b86f2a8bf38c181fb7c6b1fbfbd3c624dad", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/IzifGDL5n1QPJlXWlVRc-W1EYdjTv_3enjKCM5zhCHo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eda30debe7e87f797519229edc3f7862797409de", "width": 1080, "height": 540}], "variants": {}, "id": "L3ie0F02t5Q86Iy5PepA7ppCsWnIQj-pX6lu8tD7388"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17svmr0", "is_robot_indexable": true, "report_reasons": null, "author": "roadgeek77", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17svmr0/image_viewerorganizers_like_stash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17svmr0/image_viewerorganizers_like_stash/", "subreddit_subscribers": 711665, "created_utc": 1699713253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I've seen a few posts on how it can be done with FFMPEG, but I have zero clue on how to use it (And when I've tried it won't work) And I'm wondering if there's any other way to save these videos. These 2 videos are the only remaining snippets of these music videos anywhere on the internet, and I'd like to preserve them as [archive.org](https://archive.org) can't seem to archive them properly. Any help is very appreciated. \n\n[Video 1](https://players.brightcove.net/4838167534001/HJ6my7pN_default/index.html?videoId=ref:75000267_ESCL-2349_01VFL)\n\n[Video 2](https://players.brightcove.net/4838167534001/HJ6my7pN_default/index.html?videoId=ref:75000267_ESCL-2326_01VFL)", "author_fullname": "t2_2wu5lee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help downloading brightcove videos.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t80em", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699748211.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;ve seen a few posts on how it can be done with FFMPEG, but I have zero clue on how to use it (And when I&amp;#39;ve tried it won&amp;#39;t work) And I&amp;#39;m wondering if there&amp;#39;s any other way to save these videos. These 2 videos are the only remaining snippets of these music videos anywhere on the internet, and I&amp;#39;d like to preserve them as &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt; can&amp;#39;t seem to archive them properly. Any help is very appreciated. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://players.brightcove.net/4838167534001/HJ6my7pN_default/index.html?videoId=ref:75000267_ESCL-2349_01VFL\"&gt;Video 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://players.brightcove.net/4838167534001/HJ6my7pN_default/index.html?videoId=ref:75000267_ESCL-2326_01VFL\"&gt;Video 2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t80em", "is_robot_indexable": true, "report_reasons": null, "author": "Lunah05", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t80em/need_help_downloading_brightcove_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t80em/need_help_downloading_brightcove_videos/", "subreddit_subscribers": 711665, "created_utc": 1699748211.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was recently gifted on old computer that I'm hoping to turn in to a NAS. The MOBO has 4 SATA 2.0 ports. I'm needing more ports than that, and also hoping to get some SATA 3.0 ports for the faster speed. The issue is the computer only has PCI (not express) and PCIe 1.0 slots on it. Does anyone know of any SATA cards that will work in these slots? And is SATA 3.0 even that much faster for hard drives over SATA 2.0?", "author_fullname": "t2_6obd67l2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old computer SATA 3.0 card", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t4j2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699738469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was recently gifted on old computer that I&amp;#39;m hoping to turn in to a NAS. The MOBO has 4 SATA 2.0 ports. I&amp;#39;m needing more ports than that, and also hoping to get some SATA 3.0 ports for the faster speed. The issue is the computer only has PCI (not express) and PCIe 1.0 slots on it. Does anyone know of any SATA cards that will work in these slots? And is SATA 3.0 even that much faster for hard drives over SATA 2.0?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t4j2s", "is_robot_indexable": true, "report_reasons": null, "author": "spaghettigoedde", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t4j2s/old_computer_sata_30_card/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t4j2s/old_computer_sata_30_card/", "subreddit_subscribers": 711665, "created_utc": 1699738469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just swapped some bigger drives into my Synology NAS and now have a spare 8TB and 4TB drive. I'd like to use them as an offsite backup. I tried to access the drives on my Windows 10 PC with a SATA reader and WinBTRFS, but apparently WinBTRFS can't access Synology drives because they use LVM.\n\nNew plan is to reformat the drives to NTFS so Windows can access them natively (I have multiple backups so I'm fine if they get wiped). Anyone have experience with reformatting BTRFS to NTFS?", "author_fullname": "t2_5vffa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reformat BTRFS drives to NTFS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t1ipp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699730214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just swapped some bigger drives into my Synology NAS and now have a spare 8TB and 4TB drive. I&amp;#39;d like to use them as an offsite backup. I tried to access the drives on my Windows 10 PC with a SATA reader and WinBTRFS, but apparently WinBTRFS can&amp;#39;t access Synology drives because they use LVM.&lt;/p&gt;\n\n&lt;p&gt;New plan is to reformat the drives to NTFS so Windows can access them natively (I have multiple backups so I&amp;#39;m fine if they get wiped). Anyone have experience with reformatting BTRFS to NTFS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t1ipp", "is_robot_indexable": true, "report_reasons": null, "author": "One_Eyed_Man", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t1ipp/reformat_btrfs_drives_to_ntfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t1ipp/reformat_btrfs_drives_to_ntfs/", "subreddit_subscribers": 711665, "created_utc": 1699730214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I'm looking to add some large Enterprise HDD's to my array and was wondering if a Long Smart Test would be sufficient before putting the drive into service?\n\nI use Windows/Snapraid and have/use HDD Sentinel and also could run Read and/or write tests.\n\nI'm curious what others testing methods are after a drive is shipped to them before putting it into service?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your test method for new HDDs before adding to array?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t4ozw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699738915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to add some large Enterprise HDD&amp;#39;s to my array and was wondering if a Long Smart Test would be sufficient before putting the drive into service?&lt;/p&gt;\n\n&lt;p&gt;I use Windows/Snapraid and have/use HDD Sentinel and also could run Read and/or write tests.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious what others testing methods are after a drive is shipped to them before putting it into service?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t4ozw", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17t4ozw/what_is_your_test_method_for_new_hdds_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17t4ozw/what_is_your_test_method_for_new_hdds_before/", "subreddit_subscribers": 711665, "created_utc": 1699738915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nJust planning to get a new drive for torrenting. I actually download everything to a usb-stick and then copy it to my drive for seeding. \n\nI know seeding destroys disks but, the question is, if I seed mostly for a private tracker, where usually there's no data upload for most of the day, will the drive be constantly reading too?\n\nI can get a 1TB SDD for 55\u20ac, or and 7200rpm 1TB WD Blue (refurbished) + enclosure for about 25\u20ac, or a WD My Book 3TB for about 35\u20ac (refurbished), what would you recommend? \n\nI've been searching for 2nd hand disks because I don't mind it breaking (will make a backup just in case), I just want the cheapest option considering the next 5 years or so. The drive is meant to work 24/7.\n\nThanks!!", "author_fullname": "t2_i70y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help getting a SSD or HDD for torrenting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17stelk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.23, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699705795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Just planning to get a new drive for torrenting. I actually download everything to a usb-stick and then copy it to my drive for seeding. &lt;/p&gt;\n\n&lt;p&gt;I know seeding destroys disks but, the question is, if I seed mostly for a private tracker, where usually there&amp;#39;s no data upload for most of the day, will the drive be constantly reading too?&lt;/p&gt;\n\n&lt;p&gt;I can get a 1TB SDD for 55\u20ac, or and 7200rpm 1TB WD Blue (refurbished) + enclosure for about 25\u20ac, or a WD My Book 3TB for about 35\u20ac (refurbished), what would you recommend? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been searching for 2nd hand disks because I don&amp;#39;t mind it breaking (will make a backup just in case), I just want the cheapest option considering the next 5 years or so. The drive is meant to work 24/7.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17stelk", "is_robot_indexable": true, "report_reasons": null, "author": "alvarodel8", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17stelk/need_help_getting_a_ssd_or_hdd_for_torrenting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17stelk/need_help_getting_a_ssd_or_hdd_for_torrenting/", "subreddit_subscribers": 711665, "created_utc": 1699705795.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}