{"kind": "Listing", "data": {"after": "t3_181vtdv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_c4gff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Heads up for a data corruption bug in ZFS, few versions affected, might have started at 2.1.x, but many reports on 2.2.x", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1821mpr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/593qtb3dHwI0ViAkWS8yjVaKJtsekhPBzPs1gFsi_B4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700747503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/openzfs/zfs/issues/15526", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?auto=webp&amp;s=3d75edbf9d4374ef534a321594c3b5b3c63a4d45", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7220162628377636e38962e9e58d1f58468c3455", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b73d47e8fa1d526fe4f2c477ea8721a8aabdd41", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa9c7fb0177ed9c025427cb72595149f26e1dccb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ab386af01f72e6ea5187bf53081da90623ea4dc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d58ca2b0c12431f6cd47655d775cc8e7d822b7df", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3d2833479980bb5b2f3efb25acc54426bbd41084", "width": 1080, "height": 540}], "variants": {}, "id": "OI58A6yzSBQ2nmfk0t6nJlBsRz8Hv6FTc1BQ-SNIOE0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1821mpr", "is_robot_indexable": true, "report_reasons": null, "author": "vitzli-mmc", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1821mpr/heads_up_for_a_data_corruption_bug_in_zfs_few/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://github.com/openzfs/zfs/issues/15526", "subreddit_subscribers": 713867, "created_utc": 1700747503.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cchf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Costco - 14TB for $150", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_181uqfh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p8Vt6YZEHJT_5M8vvGp00F37vzs44YX1qirb1GgBOcw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700720523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cobi7fkaj12c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?auto=webp&amp;s=ac7b8b897f8879bdd35bf186b03199b9084748cf", "width": 1422, "height": 4271}, "resolutions": [{"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44ed802c9d3e2a16e937bbbf5bf47b0c2478745e", "width": 108, "height": 216}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07080cc81937293c80f4443033bea2ee094ed203", "width": 216, "height": 432}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=012da5e26ae75fb3b15e38d839a08c83dd2a703d", "width": 320, "height": 640}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bae8c5d3466f11353bd084b5f7a041cd1943c586", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d45806a8cb8d991bd3a140bd6d5f26b087fce09", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c12ee3423d83af5dcbc2c3b55100937c6c7a3df2", "width": 1080, "height": 2160}], "variants": {}, "id": "JlVSP5fs4CmPFCBIQvyLeKlBP87Sc-eHoX0LLw7vkkU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "181uqfh", "is_robot_indexable": true, "report_reasons": null, "author": "Atanzarian", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181uqfh/costco_14tb_for_150/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cobi7fkaj12c1.jpg", "subreddit_subscribers": 713867, "created_utc": 1700720523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have recently thought about burning some data to Blu-ray and therefore looked for some cheap blank discs. To my surprise, higher density Blu-rays seem to be much more expensive than lower density ones. In my country (Germany) for example, I could buy a 25 GB BD for 0,44\u20ac. A 100 GB BD would cost me 8,77\u20ac! At that price, it would be more efficient to store 100 GB on four 25 GB discs instead of one 100 GB disc (1,76\u20ac vs. 8,77\u20ac). Sure, if it is one file I would have to split it first and combine it again when I want to access the data, but that effort seems to be worth it.\n\nWhy are high capacity Blu-rays so much more expensive, especially compared to HDDs or SSDs where the price per GB/TB usually drops with higher capacity?", "author_fullname": "t2_2toymaqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are 100 GB Blu-rays so much more expensive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181q19n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700704486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently thought about burning some data to Blu-ray and therefore looked for some cheap blank discs. To my surprise, higher density Blu-rays seem to be much more expensive than lower density ones. In my country (Germany) for example, I could buy a 25 GB BD for 0,44\u20ac. A 100 GB BD would cost me 8,77\u20ac! At that price, it would be more efficient to store 100 GB on four 25 GB discs instead of one 100 GB disc (1,76\u20ac vs. 8,77\u20ac). Sure, if it is one file I would have to split it first and combine it again when I want to access the data, but that effort seems to be worth it.&lt;/p&gt;\n\n&lt;p&gt;Why are high capacity Blu-rays so much more expensive, especially compared to HDDs or SSDs where the price per GB/TB usually drops with higher capacity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181q19n", "is_robot_indexable": true, "report_reasons": null, "author": "KingKevin-23", "discussion_type": null, "num_comments": 44, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181q19n/why_are_100_gb_blurays_so_much_more_expensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181q19n/why_are_100_gb_blurays_so_much_more_expensive/", "subreddit_subscribers": 713867, "created_utc": 1700704486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am 99% of the way to pulling the trigger on a custom NAS build for backup and a home server. \n\nThen I see this thing. 4 Ethernet, 2 nvme, celadon with quicksync. Honestly I would never be able to build something this clean. \n\nHas anyone ever heard of this?", "author_fullname": "t2_11dcf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Has anyone ever seen this thing? No trace on the internet.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"acil8be4852c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 149, "x": 108, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=22ddb27eb47cb7036458bfc203f951e4a0ef852d"}, {"y": 299, "x": 216, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1f1dca6047d434c9222620d41e1c760598ac69a"}, {"y": 444, "x": 320, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1ca2580010b20282fdc19f10b33a2b3c8b49122"}, {"y": 888, "x": 640, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0d506e41c1fa9ff09aa7261a6cfdac55b688c19b"}, {"y": 1332, "x": 960, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ee6281e2c0e047b3940da2805cde26bbea690e1"}, {"y": 1499, "x": 1080, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c0c507cbe622f40013d0ebc52d8779088626d9f9"}], "s": {"y": 1624, "x": 1170, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=0a452fa2bb57e8ab982b9d94f5918603da36fbec"}, "id": "acil8be4852c1"}, "cokroae4852c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99700f838746cd6de7d4776226bd9989bc918153"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=981e3941d2c13e5ae318ad659a5d86e60933cf74"}, {"y": 427, "x": 320, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eeb0aee5de4287d04bb1845ea0148f87a5c0733d"}, {"y": 855, "x": 640, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20fcb9ba395ea8cebffdac69d749b9fed954dcee"}, {"y": 1283, "x": 960, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7ffc927d917682645b7d1f15d6a80c65074ba13d"}, {"y": 1443, "x": 1080, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06210b0cb8b908dcf500ff3aaa16aad11ead6d94"}], "s": {"y": 1564, "x": 1170, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=2426913794c29753d95af6f6f1b7b1b1a207513a"}, "id": "cokroae4852c1"}}, "name": "t3_18281b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 37, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "acil8be4852c1", "id": 364351604}, {"media_id": "cokroae4852c1", "id": 364351605}]}, "link_flair_text": "Backup", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NUYBYS8BxlMAT44eoUQRQfrJRXovbOnwDTW-KQ-v1-c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700765195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 99% of the way to pulling the trigger on a custom NAS build for backup and a home server. &lt;/p&gt;\n\n&lt;p&gt;Then I see this thing. 4 Ethernet, 2 nvme, celadon with quicksync. Honestly I would never be able to build something this clean. &lt;/p&gt;\n\n&lt;p&gt;Has anyone ever heard of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18281b0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18281b0", "is_robot_indexable": true, "report_reasons": null, "author": "wonka88", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18281b0/has_anyone_ever_seen_this_thing_no_trace_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18281b0", "subreddit_subscribers": 713867, "created_utc": 1700765195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It is time keep hoarding AI models as Chinese censorship hits NYC based Huggingface the biggest AI library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1826g5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mbyapud7", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/83Pjn1hvGrzkjzGLZtyTKqE_xeq19q0zX-PPAmVoxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "", "author_fullname": "t2_4ulrx5xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hugging Face Removes Singing AI Models of Xi Jinping But Not of Biden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_181rdx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "#bbbdbf", "ups": 292, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "03eba0e8-72f2-11ee-96eb-9a14648159ce", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 292, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/83Pjn1hvGrzkjzGLZtyTKqE_xeq19q0zX-PPAmVoxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700708677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "404media.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?auto=webp&amp;s=eaf93a4eae394d3bb7ab438b35ed6a6b867cf024", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9f22c5d5af4f3eea3937d08d55243e02544135", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a43b73bfef0509aec0c56fe0cd47b47f4558ce5e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a7d7c348e9e004288d6c37becc67621076e67eb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d4467326c54cdcd7445385f748f4b80ea5f5945", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4055ff6de501a27f6d30ff67f794aa2d992b939b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae41a6ac0d38f5e2ab302970c0c049639d461f98", "width": 1080, "height": 607}], "variants": {}, "id": "39UkKvxDztZ4DlgRPndfQMepqR5cLM0-u2ZmLf6husw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "koboldcpp", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "181rdx3", "is_robot_indexable": true, "report_reasons": null, "author": "Merchant_Lawrence", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/LocalLLaMA/comments/181rdx3/hugging_face_removes_singing_ai_models_of_xi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "subreddit_subscribers": 78882, "created_utc": 1700708677.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1700760924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "404media.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?auto=webp&amp;s=eaf93a4eae394d3bb7ab438b35ed6a6b867cf024", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9f22c5d5af4f3eea3937d08d55243e02544135", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a43b73bfef0509aec0c56fe0cd47b47f4558ce5e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a7d7c348e9e004288d6c37becc67621076e67eb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d4467326c54cdcd7445385f748f4b80ea5f5945", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4055ff6de501a27f6d30ff67f794aa2d992b939b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae41a6ac0d38f5e2ab302970c0c049639d461f98", "width": 1080, "height": 607}], "variants": {}, "id": "39UkKvxDztZ4DlgRPndfQMepqR5cLM0-u2ZmLf6husw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1826g5l", "is_robot_indexable": true, "report_reasons": null, "author": "ihmoguy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_181rdx3", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1826g5l/it_is_time_keep_hoarding_ai_models_as_chinese/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "subreddit_subscribers": 713867, "created_utc": 1700760924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title says it all. Most of the stuff I had no backup for. It sucks but I'm trying to take it in stride. Time will tell if I actually needed any of that data or if I was just hoarding it with no actual use. \n\nI'm still trying to recover the data with pros, and in any case I'll find a cost-efficient way to keep backups from now (any suggestions? One drive? External SSD?)\n\nHave any of you experienced this? How do you feel or how would you feel? Is this your worst nightmare? Let's discuss", "author_fullname": "t2_afzguhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My 8 year old HDD died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1824mrv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700756072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title says it all. Most of the stuff I had no backup for. It sucks but I&amp;#39;m trying to take it in stride. Time will tell if I actually needed any of that data or if I was just hoarding it with no actual use. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still trying to recover the data with pros, and in any case I&amp;#39;ll find a cost-efficient way to keep backups from now (any suggestions? One drive? External SSD?)&lt;/p&gt;\n\n&lt;p&gt;Have any of you experienced this? How do you feel or how would you feel? Is this your worst nightmare? Let&amp;#39;s discuss&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1824mrv", "is_robot_indexable": true, "report_reasons": null, "author": "M3M3-", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1824mrv/my_8_year_old_hdd_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1824mrv/my_8_year_old_hdd_died/", "subreddit_subscribers": 713867, "created_utc": 1700756072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking at this one 4TB drive I got recently that has a manufacturing date in 2013, total written amount of 12 TB, restart count ~500, but total power-on only around 1,000h. I was wondering what happened there, why a restart every 2h, and was it really used intensely for only 1 month in 10 years...\n\nWhat are some weird ones you've seen?\n\nI'm assuming SMART attributes can't be set selectively can they? AFAIK SMART reset is an all-or-nothing deal that wipes the whole thing.", "author_fullname": "t2_4o56qcsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some strange stories that the SMART of used drives has told you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181y9fh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700735001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at this one 4TB drive I got recently that has a manufacturing date in 2013, total written amount of 12 TB, restart count ~500, but total power-on only around 1,000h. I was wondering what happened there, why a restart every 2h, and was it really used intensely for only 1 month in 10 years...&lt;/p&gt;\n\n&lt;p&gt;What are some weird ones you&amp;#39;ve seen?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m assuming SMART attributes can&amp;#39;t be set selectively can they? AFAIK SMART reset is an all-or-nothing deal that wipes the whole thing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "181y9fh", "is_robot_indexable": true, "report_reasons": null, "author": "GolemancerVekk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/181y9fh/what_are_some_strange_stories_that_the_smart_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181y9fh/what_are_some_strange_stories_that_the_smart_of/", "subreddit_subscribers": 713867, "created_utc": 1700735001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey friends, looking for advice on how I can possibly get the best of both worlds out of this situation...\n\nSome Background:\n\nI've been running a Plex server for about 2 years now. 2018 Mac Mini, DAS: Pegasus R4 with 4x 12TB drives configured in RAID5.  It's worked great, no complaints.  I'm nearing the 36TB capacity of my array and have been researching the best course to upgrade for a couple months.  Very interested in the idea of building a proper server and moving to Proxmox so I can start doing some other homelab stuff with the machine as well.\n\nYesterday, I got a new job which starts in February, so I have a little bit of time to figure things out.\n\nFor the new job, I will need to build a RAID with 70-100TB of usable space.  I'll be offloading 1TB and 2TB NVMe's to 2 destinations.  Destinations are the HDD RAID I'm building as well as to a 4TB NVMe external drive.  Everything must be run through an xxhash64 checksum.  One downside, is I'm required to use MacOs for the job.  The offload has to be pretty fast, without breaking the bank.\n\n&amp;#x200B;\n\nThe cheapest/easiest solution I've come up with is:\n\n\\- Buy Mac Studio M1 Max ($1,579 refurbished from Apple)\n\n\\- Buy OWC Thunderbay 8 enclosure ($899.99)\n\n\\-Fill the Thunderbay with 20TB IronWolf Pro drives ($1800 for 6x 20TB)\n\nPros to this setup:  Relatively cheap given the parameters.  No building anything or relying on my (lack-of) skill in building a DAS/NAS.  Good warranties on the computer and enclosure if something goes wrong and needs replaced fast.\n\nDownsides to this setup: I really don't like the idea of using Softraid. I would much prefer a hardware raid.  The Thunderbay is big and power hungry, and I'd prefer something rack mounted.\n\nI considered the idea of building a NAS...But then to move files from the source drives to the NAS, would I just need a 10Gb switch to establish a local network on my work truck? (I've never done this, only used DAS for work)  I also have no idea what kind of read/write speeds I could expect from a NAS spinning the IronWolf Pros.\n\nWhat I'm looking for is advice on possibly building a DAS or NAS that I could use for the job and, when the job is over, reuse as much of it as possible in my new Plex server / Homelab build.  Ideally, it would be compatible with both MacOS and Linux, have hardware RAID control, minimum 8 bays, be rack mounted and power efficient.  \n\nBased on the price of the above setup, I'll say my budget is $2,500 excluding the cost of HDDs.\n\nThings I already own that may or may not be helpful: 2018 Mac Mini i7 w/ 16GB DDR4 RAM, Pegasus R4 with 4x 14TB IronWolf Pro Drives\n\n&amp;#x200B;\n\nThanks for your time and I appreciate any feedback you can give!", "author_fullname": "t2_13ewcj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm trying to Hannah Montana this Situation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181mz79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700695493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey friends, looking for advice on how I can possibly get the best of both worlds out of this situation...&lt;/p&gt;\n\n&lt;p&gt;Some Background:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been running a Plex server for about 2 years now. 2018 Mac Mini, DAS: Pegasus R4 with 4x 12TB drives configured in RAID5.  It&amp;#39;s worked great, no complaints.  I&amp;#39;m nearing the 36TB capacity of my array and have been researching the best course to upgrade for a couple months.  Very interested in the idea of building a proper server and moving to Proxmox so I can start doing some other homelab stuff with the machine as well.&lt;/p&gt;\n\n&lt;p&gt;Yesterday, I got a new job which starts in February, so I have a little bit of time to figure things out.&lt;/p&gt;\n\n&lt;p&gt;For the new job, I will need to build a RAID with 70-100TB of usable space.  I&amp;#39;ll be offloading 1TB and 2TB NVMe&amp;#39;s to 2 destinations.  Destinations are the HDD RAID I&amp;#39;m building as well as to a 4TB NVMe external drive.  Everything must be run through an xxhash64 checksum.  One downside, is I&amp;#39;m required to use MacOs for the job.  The offload has to be pretty fast, without breaking the bank.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The cheapest/easiest solution I&amp;#39;ve come up with is:&lt;/p&gt;\n\n&lt;p&gt;- Buy Mac Studio M1 Max ($1,579 refurbished from Apple)&lt;/p&gt;\n\n&lt;p&gt;- Buy OWC Thunderbay 8 enclosure ($899.99)&lt;/p&gt;\n\n&lt;p&gt;-Fill the Thunderbay with 20TB IronWolf Pro drives ($1800 for 6x 20TB)&lt;/p&gt;\n\n&lt;p&gt;Pros to this setup:  Relatively cheap given the parameters.  No building anything or relying on my (lack-of) skill in building a DAS/NAS.  Good warranties on the computer and enclosure if something goes wrong and needs replaced fast.&lt;/p&gt;\n\n&lt;p&gt;Downsides to this setup: I really don&amp;#39;t like the idea of using Softraid. I would much prefer a hardware raid.  The Thunderbay is big and power hungry, and I&amp;#39;d prefer something rack mounted.&lt;/p&gt;\n\n&lt;p&gt;I considered the idea of building a NAS...But then to move files from the source drives to the NAS, would I just need a 10Gb switch to establish a local network on my work truck? (I&amp;#39;ve never done this, only used DAS for work)  I also have no idea what kind of read/write speeds I could expect from a NAS spinning the IronWolf Pros.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is advice on possibly building a DAS or NAS that I could use for the job and, when the job is over, reuse as much of it as possible in my new Plex server / Homelab build.  Ideally, it would be compatible with both MacOS and Linux, have hardware RAID control, minimum 8 bays, be rack mounted and power efficient.  &lt;/p&gt;\n\n&lt;p&gt;Based on the price of the above setup, I&amp;#39;ll say my budget is $2,500 excluding the cost of HDDs.&lt;/p&gt;\n\n&lt;p&gt;Things I already own that may or may not be helpful: 2018 Mac Mini i7 w/ 16GB DDR4 RAM, Pegasus R4 with 4x 14TB IronWolf Pro Drives&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time and I appreciate any feedback you can give!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181mz79", "is_robot_indexable": true, "report_reasons": null, "author": "BagOfTStops", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181mz79/im_trying_to_hannah_montana_this_situation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181mz79/im_trying_to_hannah_montana_this_situation/", "subreddit_subscribers": 713867, "created_utc": 1700695493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_hjrjb1zca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For anyone with a Brothers Scanner, or if you use IPrint&amp;Scan, is there a way to select which pages get saved together? I scanned in 10 pages but I don't want them all saved as one document", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1823lez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rpQJ6MJmYp79o_ozpxrx9vXbER33XNrXopVMR8qbI6Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700753253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/myog3f8l842c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/myog3f8l842c1.png?auto=webp&amp;s=be42f3a3bc4d719e175572464ca54d63b9fafbac", "width": 1528, "height": 952}, "resolutions": [{"url": "https://preview.redd.it/myog3f8l842c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f7a24cae3e9c12048fc1bb799de100deb5712c0", "width": 108, "height": 67}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fedc1e916d550a373e4ed616b504605656644617", "width": 216, "height": 134}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=58374691cd09298a048bc75583ac8efef381b5b7", "width": 320, "height": 199}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1af5ec5f61fc78ceaff67e8a1a772996de56ba5", "width": 640, "height": 398}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5fea0fafb96861d1b881a1742d9a639a3cc706e", "width": 960, "height": 598}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e41919f80a01374e7177d1dea9cc0c1c0f50952", "width": 1080, "height": 672}], "variants": {}, "id": "Tz7Xdv6d3a5UNQZpKMMcCAyYxzKy4DwUs_WxL58xFOM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1823lez", "is_robot_indexable": true, "report_reasons": null, "author": "Teachmetofishplease", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1823lez/for_anyone_with_a_brothers_scanner_or_if_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/myog3f8l842c1.png", "subreddit_subscribers": 713867, "created_utc": 1700753253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The drive had nothing essential (that I can think of yet :D) and I've yet to try salvaging data via ddrescue/testdisk/etc when the new drive arrives. But it was a motivator to finally do a robust backup system for most of my data, rather than just the essential stuff. I was supposed to do that till the end of the year ... for the last several years. Here's what I've come up with so far:\n\nWish list for the setup:\n\n1. Have versioned backups for some of the data (e.g. projects/documents)\n2. Have a copy of all personal/work/system config data by the 3-2-1 \"rule\" (3 copies, 2 media, 1 remote location)\n3. Be able to restore a machine easily enough if the drive of the root fails (not necessarily instantly), possibly without keeping whole copies for the root around\n4. No port forwarding/VPN/reverse proxy, etc for the remote communication between machines. \n5. And in general keep things as simple as possible.\n\nThe plan (using Borg and Syncthing):\n\nI have a laptop (but say I have N laptops), a (mostly) headless server locally and a remote RaspberryPi with a large HDD attached. \n\n1. Setup periodic Borg backups and staggered versioning for the folders which warrant that.\n2. Create a /backups folder on all devices. In it have /backups/&lt;device\\_id&gt; subfolders in which each machine will place its data for backup (i have some feeling the path compatibility will matter). The idea is to keep the Borg repos here, as well as symlinks to folders I want to have replicated to the two backup locations (but for which I don't need versioned backups).\n3. Configure Syncthing on all three machines so the local server and remote RPi keep read only copies of all /backups/&lt;device\\_id&gt; folders. ST can be setup to do scans on a smaller period and has been pretty stable with numerous files AFAIK.\n4. Regarding system configs (and if a root partition fails) - I'm thinking of keeping backups of /etc and \\~/.config (as well as some other app folders and files like .bashrc from /home). I'll also periodically dump the list of installed packages. In theory I should be able to do a fresh install, install the same packages, transplant /etc and the /home/&lt;user&gt; folder and ... be happy? I'm pretty sure I'm missing something here. I'll also backup systemd logs wherever they are (to trace failures potentially). I don't have any databases or services that keep data outside /home .. I think. \n5. I would optimally setup some kind of monitoring and recovery testing (thanks, chatgpt for reminding me of the latter). If you have some specific advice for some simple tools/approaches that would be nice. Otherwise I'll have to conjure some mini app/script that I'll run when I have ssh access to the machines. Or have a diagnostics folder, where each machine will write their own and have that synced with ST to asses on the laptop. I really have to not overengineer it, because I want to be done with the whole thing sooner rather than later.\n\nWhat I'm still not sure about:\n\n1. Should I keep a copy of my essential data at a cloud provider regardless of the triple copy? Yes, it's always nice to have redundancy, but is it a significantly needed measure in your experience?\n2. Should I fear encryption and being locked out of my data? Also how hard and how needed is it to change encryption keys at some point? I guess it's very much specific on their usage, etc., but I guess I'm looking for some examples from your experience.\n\nAnd in general - roast my planned setup before I've invested significant effort in implementing it.", "author_fullname": "t2_11g6s46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A 4TB WD Blue blew up and now I'm finally contemplating a more methodical backup strategy. Roast me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182bfw5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700774985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The drive had nothing essential (that I can think of yet :D) and I&amp;#39;ve yet to try salvaging data via ddrescue/testdisk/etc when the new drive arrives. But it was a motivator to finally do a robust backup system for most of my data, rather than just the essential stuff. I was supposed to do that till the end of the year ... for the last several years. Here&amp;#39;s what I&amp;#39;ve come up with so far:&lt;/p&gt;\n\n&lt;p&gt;Wish list for the setup:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have versioned backups for some of the data (e.g. projects/documents)&lt;/li&gt;\n&lt;li&gt;Have a copy of all personal/work/system config data by the 3-2-1 &amp;quot;rule&amp;quot; (3 copies, 2 media, 1 remote location)&lt;/li&gt;\n&lt;li&gt;Be able to restore a machine easily enough if the drive of the root fails (not necessarily instantly), possibly without keeping whole copies for the root around&lt;/li&gt;\n&lt;li&gt;No port forwarding/VPN/reverse proxy, etc for the remote communication between machines. &lt;/li&gt;\n&lt;li&gt;And in general keep things as simple as possible.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The plan (using Borg and Syncthing):&lt;/p&gt;\n\n&lt;p&gt;I have a laptop (but say I have N laptops), a (mostly) headless server locally and a remote RaspberryPi with a large HDD attached. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Setup periodic Borg backups and staggered versioning for the folders which warrant that.&lt;/li&gt;\n&lt;li&gt;Create a /backups folder on all devices. In it have /backups/&amp;lt;device\\_id&amp;gt; subfolders in which each machine will place its data for backup (i have some feeling the path compatibility will matter). The idea is to keep the Borg repos here, as well as symlinks to folders I want to have replicated to the two backup locations (but for which I don&amp;#39;t need versioned backups).&lt;/li&gt;\n&lt;li&gt;Configure Syncthing on all three machines so the local server and remote RPi keep read only copies of all /backups/&amp;lt;device\\_id&amp;gt; folders. ST can be setup to do scans on a smaller period and has been pretty stable with numerous files AFAIK.&lt;/li&gt;\n&lt;li&gt;Regarding system configs (and if a root partition fails) - I&amp;#39;m thinking of keeping backups of /etc and ~/.config (as well as some other app folders and files like .bashrc from /home). I&amp;#39;ll also periodically dump the list of installed packages. In theory I should be able to do a fresh install, install the same packages, transplant /etc and the /home/&amp;lt;user&amp;gt; folder and ... be happy? I&amp;#39;m pretty sure I&amp;#39;m missing something here. I&amp;#39;ll also backup systemd logs wherever they are (to trace failures potentially). I don&amp;#39;t have any databases or services that keep data outside /home .. I think. &lt;/li&gt;\n&lt;li&gt;I would optimally setup some kind of monitoring and recovery testing (thanks, chatgpt for reminding me of the latter). If you have some specific advice for some simple tools/approaches that would be nice. Otherwise I&amp;#39;ll have to conjure some mini app/script that I&amp;#39;ll run when I have ssh access to the machines. Or have a diagnostics folder, where each machine will write their own and have that synced with ST to asses on the laptop. I really have to not overengineer it, because I want to be done with the whole thing sooner rather than later.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What I&amp;#39;m still not sure about:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I keep a copy of my essential data at a cloud provider regardless of the triple copy? Yes, it&amp;#39;s always nice to have redundancy, but is it a significantly needed measure in your experience?&lt;/li&gt;\n&lt;li&gt;Should I fear encryption and being locked out of my data? Also how hard and how needed is it to change encryption keys at some point? I guess it&amp;#39;s very much specific on their usage, etc., but I guess I&amp;#39;m looking for some examples from your experience.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;And in general - roast my planned setup before I&amp;#39;ve invested significant effort in implementing it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182bfw5", "is_robot_indexable": true, "report_reasons": null, "author": "stargazer_w", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182bfw5/a_4tb_wd_blue_blew_up_and_now_im_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182bfw5/a_4tb_wd_blue_blew_up_and_now_im_finally/", "subreddit_subscribers": 713867, "created_utc": 1700774985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a WD 10 TB HDD. It never used to make noise (from the half year I got it) until recently, it got below 700 GB and *only* while torrenting.\n\nI deleted a bunch of data and it got above 700 GB. I don't want to jinx it, but I opened qBittorrent up for a minute again, and there was no noise coming from the HDD.\n\nIs this normal? It means I don't have to worry about my HDD, right? Also, what causes it to make noise below a certain level while torrenting, if anyone knows.", "author_fullname": "t2_8010p0pl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD noise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182atih", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700773276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a WD 10 TB HDD. It never used to make noise (from the half year I got it) until recently, it got below 700 GB and &lt;em&gt;only&lt;/em&gt; while torrenting.&lt;/p&gt;\n\n&lt;p&gt;I deleted a bunch of data and it got above 700 GB. I don&amp;#39;t want to jinx it, but I opened qBittorrent up for a minute again, and there was no noise coming from the HDD.&lt;/p&gt;\n\n&lt;p&gt;Is this normal? It means I don&amp;#39;t have to worry about my HDD, right? Also, what causes it to make noise below a certain level while torrenting, if anyone knows.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182atih", "is_robot_indexable": true, "report_reasons": null, "author": "Simple-Maximum-7736", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182atih/hdd_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182atih/hdd_noise/", "subreddit_subscribers": 713867, "created_utc": 1700773276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\nI was wondering if there was a way I could save all of my Reddit account\u2019s saved photos and videos after the api change. I have seen a lot of posts on this subreddit however most seem to only do one subreddit or were broken by the api changes.\nThank you", "author_fullname": "t2_2m8vh58l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download all my Reddit saves", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1828vy6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700767614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI was wondering if there was a way I could save all of my Reddit account\u2019s saved photos and videos after the api change. I have seen a lot of posts on this subreddit however most seem to only do one subreddit or were broken by the api changes.\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1828vy6", "is_robot_indexable": true, "report_reasons": null, "author": "oZeppy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1828vy6/how_to_download_all_my_reddit_saves/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1828vy6/how_to_download_all_my_reddit_saves/", "subreddit_subscribers": 713867, "created_utc": 1700767614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wanted some advice from you storage fellas! I decided that I am going to be using m-disks to long term archive videos and photos. Got some very important videos from when I was a kid and I don't want to risk losing them (I have backups on other media but not long term) I am looking for a good quality Blu-Ray \"M-Disk\" drive that is internal - but I am planning on making it external with adapters and what not! I don't particularly want to use an enclosure as it's too expensive for my budget.\n\nBeen looking on amazon for some, specifically the Hitachi-LG BH16, but I'd rather check here if you guys know if it's good etc...\n\nCan you guys kindly recommend me a good drive that supports m-disk? Been looking for a few weeks now. Budget around \u00a360 - \u00a390 :)", "author_fullname": "t2_4a2bccmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of buying an internal Blu-Ray \"M-Disk\" compatible drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18226uh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700749194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted some advice from you storage fellas! I decided that I am going to be using m-disks to long term archive videos and photos. Got some very important videos from when I was a kid and I don&amp;#39;t want to risk losing them (I have backups on other media but not long term) I am looking for a good quality Blu-Ray &amp;quot;M-Disk&amp;quot; drive that is internal - but I am planning on making it external with adapters and what not! I don&amp;#39;t particularly want to use an enclosure as it&amp;#39;s too expensive for my budget.&lt;/p&gt;\n\n&lt;p&gt;Been looking on amazon for some, specifically the Hitachi-LG BH16, but I&amp;#39;d rather check here if you guys know if it&amp;#39;s good etc...&lt;/p&gt;\n\n&lt;p&gt;Can you guys kindly recommend me a good drive that supports m-disk? Been looking for a few weeks now. Budget around \u00a360 - \u00a390 :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18226uh", "is_robot_indexable": true, "report_reasons": null, "author": "oxendaleliam", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18226uh/thinking_of_buying_an_internal_bluray_mdisk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18226uh/thinking_of_buying_an_internal_bluray_mdisk/", "subreddit_subscribers": 713867, "created_utc": 1700749194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, how are you? Please excuse my lack of knowledge, but I need some advice.\n\nI currently have around 5TB of data scattered between my OneDrive account and 2 separate SSDs. I want to create a reliable backup solution for all of my personal and work data.\n\nI recently learned about the 3-2-1 backup strategy, which involves creating 3 copies of your data on 2 different types of storage, with 1 copy being kept off-site (correct me if I'm wrong).\n\nHowever, in my situation, I work on a laptop that only has 1TB of internal storage and I don't rely on it for anything other than my active projects. Everything else is either on OneDrive or on the SSD.\n\nSo, my question is: how can I benefit from a 3-2-1 backup strategy? Should I invest in a NAS drive and store everything on it, while also using a cloud backup service like Backblaze to keep one copy off-site? Or any 8TB HDD desktop drive is enough.   \nAnd what about a 3rd copy?", "author_fullname": "t2_12pg2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on implementing 3-2-1 backup strategy with scattered data - Need suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181yf5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700735854.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700735672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, how are you? Please excuse my lack of knowledge, but I need some advice.&lt;/p&gt;\n\n&lt;p&gt;I currently have around 5TB of data scattered between my OneDrive account and 2 separate SSDs. I want to create a reliable backup solution for all of my personal and work data.&lt;/p&gt;\n\n&lt;p&gt;I recently learned about the 3-2-1 backup strategy, which involves creating 3 copies of your data on 2 different types of storage, with 1 copy being kept off-site (correct me if I&amp;#39;m wrong).&lt;/p&gt;\n\n&lt;p&gt;However, in my situation, I work on a laptop that only has 1TB of internal storage and I don&amp;#39;t rely on it for anything other than my active projects. Everything else is either on OneDrive or on the SSD.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: how can I benefit from a 3-2-1 backup strategy? Should I invest in a NAS drive and store everything on it, while also using a cloud backup service like Backblaze to keep one copy off-site? Or any 8TB HDD desktop drive is enough.&lt;br/&gt;\nAnd what about a 3rd copy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181yf5k", "is_robot_indexable": true, "report_reasons": null, "author": "zizo999", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181yf5k/looking_for_advice_on_implementing_321_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181yf5k/looking_for_advice_on_implementing_321_backup/", "subreddit_subscribers": 713867, "created_utc": 1700735672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u3i8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AnandTech releases his list of best internal HDDs for Holidays 2023. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_181ybft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/dbzbVUXmcM9WUfo2Gox7T04ADa6GqhtUH6I8ZIW1GM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700735227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "anandtech.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.anandtech.com/show/12075/best-consumer-hdds", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?auto=webp&amp;s=dcfc48f99463b92411285312b77e47db51a33c41", "width": 678, "height": 454}, "resolutions": [{"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a3024febe75e06bc864da2ba4a3533e08b7fae4", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae3378a97fab4b4f30d6dabf296ed31af937999b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f9d1453a3c883e82c5e1a9376187b0c4efec31e", "width": 320, "height": 214}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=52b9acf42fa8e9dd338582fdcd213eab95ee5a55", "width": 640, "height": 428}], "variants": {}, "id": "oeJpaXt0sftyq2FczsNaxKPVlTzfVxEV44O06vXK1wg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "181ybft", "is_robot_indexable": true, "report_reasons": null, "author": "javipas", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181ybft/anandtech_releases_his_list_of_best_internal_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.anandtech.com/show/12075/best-consumer-hdds", "subreddit_subscribers": 713867, "created_utc": 1700735227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "if its an photograph thats black and white, it will tag it as a black and white photo, if its a graphic design logo it will tag it as a graphic design image, and if its a image of a painting it will tag it as a painting \n\nI've heard of MAGIX photo manager and digicam, can these programs do this? any better suggestions would be great ", "author_fullname": "t2_e67xpbe9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a software that can automatically analyze images and add relevant tags based on the content in the image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181tckh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700715450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;if its an photograph thats black and white, it will tag it as a black and white photo, if its a graphic design logo it will tag it as a graphic design image, and if its a image of a painting it will tag it as a painting &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of MAGIX photo manager and digicam, can these programs do this? any better suggestions would be great &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181tckh", "is_robot_indexable": true, "report_reasons": null, "author": "Moneydamjan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181tckh/is_there_a_software_that_can_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181tckh/is_there_a_software_that_can_automatically/", "subreddit_subscribers": 713867, "created_utc": 1700715450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm going to be setting up my first NAS soon and want to be sure that I have a backup solution in place as well.  I'd like to store all of my files locally rather than using a cloud service for backups.  I could either buy a premade backup drive (WD Elements, Seagate Expansion, etc.) or a large hard disk and an enclosure and assemble one myself.  Can those of you with experience in this area please guide me?  I'd appreciate learning about the pros and cons from expert data hoarders :)  Thank you!", "author_fullname": "t2_91n9kswm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buy large capacity off the shelf backup drive or assemble one myself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181m018", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700692926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going to be setting up my first NAS soon and want to be sure that I have a backup solution in place as well.  I&amp;#39;d like to store all of my files locally rather than using a cloud service for backups.  I could either buy a premade backup drive (WD Elements, Seagate Expansion, etc.) or a large hard disk and an enclosure and assemble one myself.  Can those of you with experience in this area please guide me?  I&amp;#39;d appreciate learning about the pros and cons from expert data hoarders :)  Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181m018", "is_robot_indexable": true, "report_reasons": null, "author": "S7Jordan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181m018/buy_large_capacity_off_the_shelf_backup_drive_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181m018/buy_large_capacity_off_the_shelf_backup_drive_or/", "subreddit_subscribers": 713867, "created_utc": 1700692926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_npmomnoyz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "$230 - WD 18TB Elements Desktop External Hard Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181lp1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1700692144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "amazon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.amazon.com/dp/B08KTRBHP1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "181lp1o", "is_robot_indexable": true, "report_reasons": null, "author": "Bruceshadow", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181lp1o/230_wd_18tb_elements_desktop_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.amazon.com/dp/B08KTRBHP1", "subreddit_subscribers": 713867, "created_utc": 1700692144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, looking this Black Friday to get some WD Red Pro's if they drop in price (buying from Canada) -- we have two at home, one is a 5 bay and one a 3 -- we might eventually switch the 4 bay which is a newer 918+, the older one is a 1513+ which we would like to keep, but upgrade at some point with more space --- for now before we buy more space in a couple days, we nabbed an 18 TB WD Elements to use as an off-site backup solution since we wanted to free some of the space used for redundancy in our RAID configuration on that Synology (not sure if this is what's referred to as \"off-site\" -- kind of a noob lol)\n\n&amp;#x200B;\n\nMy question is at this point is there a way to safely free the redundancy space, and it won't affect my data, or should I wait to get the WD HDD in a couple days and copy everything to that, then I re-format or wipe the drives? Just in case we pass on buying new internal HDD's this Thanksgiving, I did want to at least free some extra space\n\n&amp;#x200B;\n\nLooks like the 1513+ I'm trying to free are five 4TB Seagate st4000dm000 in a 'Synology Hybrid Raid (SHR) (With data protection with 1-drive fault tolerance)\n\n&amp;#x200B;\n\nThank you for any and all help", "author_fullname": "t2_u1wga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Change Synology Configuration and Other Redundancy Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182bvws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700777664.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700776256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, looking this Black Friday to get some WD Red Pro&amp;#39;s if they drop in price (buying from Canada) -- we have two at home, one is a 5 bay and one a 3 -- we might eventually switch the 4 bay which is a newer 918+, the older one is a 1513+ which we would like to keep, but upgrade at some point with more space --- for now before we buy more space in a couple days, we nabbed an 18 TB WD Elements to use as an off-site backup solution since we wanted to free some of the space used for redundancy in our RAID configuration on that Synology (not sure if this is what&amp;#39;s referred to as &amp;quot;off-site&amp;quot; -- kind of a noob lol)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is at this point is there a way to safely free the redundancy space, and it won&amp;#39;t affect my data, or should I wait to get the WD HDD in a couple days and copy everything to that, then I re-format or wipe the drives? Just in case we pass on buying new internal HDD&amp;#39;s this Thanksgiving, I did want to at least free some extra space&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Looks like the 1513+ I&amp;#39;m trying to free are five 4TB Seagate st4000dm000 in a &amp;#39;Synology Hybrid Raid (SHR) (With data protection with 1-drive fault tolerance)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any and all help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182bvws", "is_robot_indexable": true, "report_reasons": null, "author": "NoirYorkCity", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182bvws/how_to_change_synology_configuration_and_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182bvws/how_to_change_synology_configuration_and_other/", "subreddit_subscribers": 713867, "created_utc": 1700776256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Happy Thanksgiving! \n\nWeird question, but do 9600-24i eHBA give a BIOS splash screen? I've updated the firmware ROM to latest using the Windows LSA (couldn't get sas3flash to work) and I see it showing in lspci, but haven't gotten drives detecting yet. But I'm used to seeing the initial splash on boot with my old 3008 card and the drives listed. Is that no longer a thing or should it also be doing a splash config screen?\n\nTIA", "author_fullname": "t2_jcdv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "9600-24i Bios Interface", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182b0ar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700773792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy Thanksgiving! &lt;/p&gt;\n\n&lt;p&gt;Weird question, but do 9600-24i eHBA give a BIOS splash screen? I&amp;#39;ve updated the firmware ROM to latest using the Windows LSA (couldn&amp;#39;t get sas3flash to work) and I see it showing in lspci, but haven&amp;#39;t gotten drives detecting yet. But I&amp;#39;m used to seeing the initial splash on boot with my old 3008 card and the drives listed. Is that no longer a thing or should it also be doing a splash config screen?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182b0ar", "is_robot_indexable": true, "report_reasons": null, "author": "researchallthethings", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182b0ar/960024i_bios_interface/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182b0ar/960024i_bios_interface/", "subreddit_subscribers": 713867, "created_utc": 1700773792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is such a random and basic question, but I wonder if anyone can help. \n\nI'm a videographer whose footage has been double backed up on HDDs for the past 8 years. I label each individual drive by taping a piece of paper to it which helps me identify it at a glance - (1-A, 1-B, 2-A, 2-B, etc)  \n\nNow I've bought a couple of SAMSUNG T7 Shield 4TB SSD's as they're currently on sale and infinitely better than my old cheap drives. \n\nThe problem is the Shields have this rubber coating to keep them rugged, but I can't find a way to label them. Tape and stickers slide right off. I even tried writing with a white out pen and it also doesn't hold to the surface lol. Anyone have any creative ideas? \n\n&amp;#x200B;", "author_fullname": "t2_1790yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to label a Samsung Shield SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182axed", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700773566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is such a random and basic question, but I wonder if anyone can help. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a videographer whose footage has been double backed up on HDDs for the past 8 years. I label each individual drive by taping a piece of paper to it which helps me identify it at a glance - (1-A, 1-B, 2-A, 2-B, etc)  &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve bought a couple of SAMSUNG T7 Shield 4TB SSD&amp;#39;s as they&amp;#39;re currently on sale and infinitely better than my old cheap drives. &lt;/p&gt;\n\n&lt;p&gt;The problem is the Shields have this rubber coating to keep them rugged, but I can&amp;#39;t find a way to label them. Tape and stickers slide right off. I even tried writing with a white out pen and it also doesn&amp;#39;t hold to the surface lol. Anyone have any creative ideas? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182axed", "is_robot_indexable": true, "report_reasons": null, "author": "the_long_bridge", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182axed/how_to_label_a_samsung_shield_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182axed/how_to_label_a_samsung_shield_ssd/", "subreddit_subscribers": 713867, "created_utc": 1700773566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is asked every now and then, but then there are occasional new tools, so I wanted to check again.\n\nI am planning to add a few more sites to my archives, and am open to suggestion.\n\n1. `wget` \"works\" of course. I have used it in the past. But does not know anything about multiple versions, or other structural parts of the web archive. \n\n2. [https://github.com/internetarchive/dweb-mirror](https://github.com/internetarchive/dweb-mirror). The \"official\" mirroring tool. I might give it a try. But could not find a way to restrict to my selected list of web pages.\n\nWhat is the current best strategy to get this done?", "author_fullname": "t2_17g3q9fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The best advice for wayback machine (web.archive.org) mirroring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18280gk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700765133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is asked every now and then, but then there are occasional new tools, so I wanted to check again.&lt;/p&gt;\n\n&lt;p&gt;I am planning to add a few more sites to my archives, and am open to suggestion.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;code&gt;wget&lt;/code&gt; &amp;quot;works&amp;quot; of course. I have used it in the past. But does not know anything about multiple versions, or other structural parts of the web archive. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://github.com/internetarchive/dweb-mirror\"&gt;https://github.com/internetarchive/dweb-mirror&lt;/a&gt;. The &amp;quot;official&amp;quot; mirroring tool. I might give it a try. But could not find a way to restrict to my selected list of web pages.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What is the current best strategy to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?auto=webp&amp;s=ce67ac4eaf4a6fded058d4d9c5becae87234c2ea", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67f929495243a3bfa30b4a64140cea9b59d4cf26", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=057122bd90ef79a94809253a383e43fb9c52d4ca", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e156f4acf34640c3b320cf3cded989751874a52", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b046817895c7bff6ec28669e6a1a5c7f68735b7b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=98ef71a501cfb81f177051ebc4d32af8ec705fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ade59ef0f9b3bf868b5ee95ea675c0d4a1c4ca8", "width": 1080, "height": 540}], "variants": {}, "id": "H9vrkJn5vS3p-i7AmG7Hi0KwD8pcxC2iybrn7JJSkBI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18280gk", "is_robot_indexable": true, "report_reasons": null, "author": "stikves", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18280gk/the_best_advice_for_wayback_machine_webarchiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18280gk/the_best_advice_for_wayback_machine_webarchiveorg/", "subreddit_subscribers": 713867, "created_utc": 1700765133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have many public download links to files.\nAnd I dont want to have a download manager to download many links at once. I want to share it with just one click to one person. So you just need to download the files at once\n\nIn cloud storage services you can put many files into one folder and download just one folder. You know what I mean?\n\nIt would be so cool, if you could make a virtual file system just with public links and download it trough one link all the files. Becouse its more comfort. You know what I mean? Is that possible?", "author_fullname": "t2_oq2e3f8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create an virtual file system only with links? Is that possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1824e8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700755445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have many public download links to files.\nAnd I dont want to have a download manager to download many links at once. I want to share it with just one click to one person. So you just need to download the files at once&lt;/p&gt;\n\n&lt;p&gt;In cloud storage services you can put many files into one folder and download just one folder. You know what I mean?&lt;/p&gt;\n\n&lt;p&gt;It would be so cool, if you could make a virtual file system just with public links and download it trough one link all the files. Becouse its more comfort. You know what I mean? Is that possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1824e8o", "is_robot_indexable": true, "report_reasons": null, "author": "Sorita_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1824e8o/create_an_virtual_file_system_only_with_links_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1824e8o/create_an_virtual_file_system_only_with_links_is/", "subreddit_subscribers": 713867, "created_utc": 1700755445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Me and a friend want to build a plexserver and need help for finding the right hdd. It needs to be a quiet one because it's standing in my bedroom. Do you guys have any recommendations for 14tb+ HDD's that are as quiet as possible?", "author_fullname": "t2_uaony", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quiet(isch) HDD for HTPC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18200a7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700742023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Me and a friend want to build a plexserver and need help for finding the right hdd. It needs to be a quiet one because it&amp;#39;s standing in my bedroom. Do you guys have any recommendations for 14tb+ HDD&amp;#39;s that are as quiet as possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18200a7", "is_robot_indexable": true, "report_reasons": null, "author": "druvanti", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18200a7/quietisch_hdd_for_htpc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18200a7/quietisch_hdd_for_htpc/", "subreddit_subscribers": 713867, "created_utc": 1700742023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Had a storage machine carrying some important data that's been in cold storage for a year. Not too worried about the hdds, but thinking the SSDs could use a good once over to make sure none of the files have decayed. Not really sure how to do that though, was thinking of maybe running a virus scanner over the whole thing as that should force the system to look at every file, and maybe the ssd/hdd error correction will make sure everything is up to snuff. Any advice? Is there a better way?\n\nSystem is running windows so some Linux tools are trickier to fire up without creating some kind of live disc or something.", "author_fullname": "t2_vivjs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a storage machine in cold storage and unpowered for almost an entire year. Advice on insuring data integrity on startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181vtdv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700724751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a storage machine carrying some important data that&amp;#39;s been in cold storage for a year. Not too worried about the hdds, but thinking the SSDs could use a good once over to make sure none of the files have decayed. Not really sure how to do that though, was thinking of maybe running a virus scanner over the whole thing as that should force the system to look at every file, and maybe the ssd/hdd error correction will make sure everything is up to snuff. Any advice? Is there a better way?&lt;/p&gt;\n\n&lt;p&gt;System is running windows so some Linux tools are trickier to fire up without creating some kind of live disc or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181vtdv", "is_robot_indexable": true, "report_reasons": null, "author": "Captain_Starkiller", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181vtdv/had_a_storage_machine_in_cold_storage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181vtdv/had_a_storage_machine_in_cold_storage_and/", "subreddit_subscribers": 713867, "created_utc": 1700724751.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}