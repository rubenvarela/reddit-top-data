{"kind": "Listing", "data": {"after": "t3_17lksdo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The single biggest factor in SSD performance is the presence and quantity of DRAM cache.  A drive with a GB or two of DRAM will write at several hundred MB/s all day long, while a DRAM-less drive will slow to a crawl after the first couple GB written.  \n\nThis being the case, why does nobody list this spec?  Neither amazon nor newegg have cache as a filterable item.  95% of drives don't even mention it one way or the other in the product description.  It's fucking maddening.\n\nAre there any web shops that will let me search for drives with DRAM cache specifically, or am I going to have to resort to googling full reviews of each model individually?", "author_fullname": "t2_4wc8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD shopping - how to find drives with DRAM cache?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lgjrj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698857499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The single biggest factor in SSD performance is the presence and quantity of DRAM cache.  A drive with a GB or two of DRAM will write at several hundred MB/s all day long, while a DRAM-less drive will slow to a crawl after the first couple GB written.  &lt;/p&gt;\n\n&lt;p&gt;This being the case, why does nobody list this spec?  Neither amazon nor newegg have cache as a filterable item.  95% of drives don&amp;#39;t even mention it one way or the other in the product description.  It&amp;#39;s fucking maddening.&lt;/p&gt;\n\n&lt;p&gt;Are there any web shops that will let me search for drives with DRAM cache specifically, or am I going to have to resort to googling full reviews of each model individually?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "190TB Drivepool/Snapraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17lgjrj", "is_robot_indexable": true, "report_reasons": null, "author": "candre23", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17lgjrj/ssd_shopping_how_to_find_drives_with_dram_cache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lgjrj/ssd_shopping_how_to_find_drives_with_dram_cache/", "subreddit_subscribers": 709913, "created_utc": 1698857499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning a Christmas gift for someone who loves having physical media.  She likes the packaging and knowing that she owns the movie without having to pay any type of subscription or logging into an account.  \n\nWe have a PS5 that can play the Blu-ray discs, but I worry about them getting scratched up after continual use.  We have an LG TV that runs webOS which has a USB port so if I can rip the Blu-ray to USB in a supported format, we can play them that way.  She also likes to watch the movies on her iPad while away from home so I am hoping the rip can also be played on it.  \n\nI have a [full-size desktop computer](https://psref.lenovo.com/Product/Legion/Lenovo_Legion_T7_34IMZ5) (i9-11900K / 64GB DDR4 / RTX 3080 4.0 GB) but it doesn't have a Blu-ray player.  I don't see an internal bay to add one so I imagine my options are to either use a USB Blu-ray reader (probably extremely slow) or just temporarily open the case and have an internal SATA Blu-ray player connected while I rip them.  Are there any models people recommend that will do the job quickly?\n\nIt looks like [MakeMKV](https://www.makemkv.com/) is the gold standard for converting a physical Blu-ray to digital media.  Is the digital file compatible with iOS and webOS?  If not, what converters would you recommend? \n\nThe end goal is to have a USB drive with all of the movies digitally on it which can be plugged into the LG TV to play directly.  The files will also be copied to the iPad preferably through iTunes but I could also install the VLC app and copy them that way if iTunes doesn't support it.", "author_fullname": "t2_a4gfzgya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to purchase ~20 Blu-ray musicals and rip them to a format playable on iOS and webOS. What do I need?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lgn0a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698857740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning a Christmas gift for someone who loves having physical media.  She likes the packaging and knowing that she owns the movie without having to pay any type of subscription or logging into an account.  &lt;/p&gt;\n\n&lt;p&gt;We have a PS5 that can play the Blu-ray discs, but I worry about them getting scratched up after continual use.  We have an LG TV that runs webOS which has a USB port so if I can rip the Blu-ray to USB in a supported format, we can play them that way.  She also likes to watch the movies on her iPad while away from home so I am hoping the rip can also be played on it.  &lt;/p&gt;\n\n&lt;p&gt;I have a &lt;a href=\"https://psref.lenovo.com/Product/Legion/Lenovo_Legion_T7_34IMZ5\"&gt;full-size desktop computer&lt;/a&gt; (i9-11900K / 64GB DDR4 / RTX 3080 4.0 GB) but it doesn&amp;#39;t have a Blu-ray player.  I don&amp;#39;t see an internal bay to add one so I imagine my options are to either use a USB Blu-ray reader (probably extremely slow) or just temporarily open the case and have an internal SATA Blu-ray player connected while I rip them.  Are there any models people recommend that will do the job quickly?&lt;/p&gt;\n\n&lt;p&gt;It looks like &lt;a href=\"https://www.makemkv.com/\"&gt;MakeMKV&lt;/a&gt; is the gold standard for converting a physical Blu-ray to digital media.  Is the digital file compatible with iOS and webOS?  If not, what converters would you recommend? &lt;/p&gt;\n\n&lt;p&gt;The end goal is to have a USB drive with all of the movies digitally on it which can be plugged into the LG TV to play directly.  The files will also be copied to the iPad preferably through iTunes but I could also install the VLC app and copy them that way if iTunes doesn&amp;#39;t support it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lgn0a", "is_robot_indexable": true, "report_reasons": null, "author": "FatherLiamFinnegan", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lgn0a/wanting_to_purchase_20_bluray_musicals_and_rip/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lgn0a/wanting_to_purchase_20_bluray_musicals_and_rip/", "subreddit_subscribers": 709913, "created_utc": 1698857740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, first time posting on this subreddit. \n\nSo currently I have over 200,000 bookmarks on my Windows laptop split across these browsers - Chrome, Brave, Edge, Firefox, Opera, Vivaldi and Chrome Beta (Chrome Dev seems to be quite unstable).\n\nDue to privacy and security reasons, I DON'T want to use ANY online/cloud service, and I use all browsers on my laptop SIGNED OUT so there is NO online/cloud syncing, NO multiple profiles, and ALL the bookmarks are stored LOCALLY on the laptop's hard drive. I also keep exporting them from time-to-time in HTML formats as backups. \n\nI have NO duplicates or waste bookmarks, they are well organized into dozens of different folders and it has been my habit to collect various links, websites and URLs since nearly a decade now. \n\nGenuinely curious about whether or not this process can scale to potentially MILLIONS of bookmarks in the future, because its part of my habit to store bookmarks while browsing the web. ", "author_fullname": "t2_986czkvnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can web browsers on computers store and manage millions of bookmarks offline and still be functional without lagging if there are NO online/cloud syncing at all?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lejtu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698852140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, first time posting on this subreddit. &lt;/p&gt;\n\n&lt;p&gt;So currently I have over 200,000 bookmarks on my Windows laptop split across these browsers - Chrome, Brave, Edge, Firefox, Opera, Vivaldi and Chrome Beta (Chrome Dev seems to be quite unstable).&lt;/p&gt;\n\n&lt;p&gt;Due to privacy and security reasons, I DON&amp;#39;T want to use ANY online/cloud service, and I use all browsers on my laptop SIGNED OUT so there is NO online/cloud syncing, NO multiple profiles, and ALL the bookmarks are stored LOCALLY on the laptop&amp;#39;s hard drive. I also keep exporting them from time-to-time in HTML formats as backups. &lt;/p&gt;\n\n&lt;p&gt;I have NO duplicates or waste bookmarks, they are well organized into dozens of different folders and it has been my habit to collect various links, websites and URLs since nearly a decade now. &lt;/p&gt;\n\n&lt;p&gt;Genuinely curious about whether or not this process can scale to potentially MILLIONS of bookmarks in the future, because its part of my habit to store bookmarks while browsing the web. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lejtu", "is_robot_indexable": true, "report_reasons": null, "author": "ZyxWvuO", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lejtu/can_web_browsers_on_computers_store_and_manage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lejtu/can_web_browsers_on_computers_store_and_manage/", "subreddit_subscribers": 709913, "created_utc": 1698852140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to store a backup of recordings we've been making for the past three years. It's currently at less than 3 TB and these are 5 - 9 GB files each, as mp4s. It will continue to grow, as we generate 6 recordings a month. I don't need to access the backup frequently, as the files are also on my local machine, on archival M-discs, and on a separate HDD that I keep as a physical backup and sync two regularly. I also have Backblaze in the background. So when I go back to edit the recordings, I'll be using the local files rather than the ones in the cloud.\n\nHowever I really want someplace to drop a recording immediately after it's done that's off-site in the cloud, just in case of an immediate disaster.\n\nThey are currently on [Sync.com](https://sync.com/), which offers unlimited space for $30/mo, but the service's stopped providing support *of any kind* recently (despite advertising phone support for their higher tiers) so I'm worried they're about to go under or that something is up with their company.\n\nI had considered AWS Deep Archive, but their egress cost seems insane as the service is really meant for \"archives\" as far as I understand it, not as a backup I might very infrequently access. \n\nWhat other options are out there to consider?", "author_fullname": "t2_7r7o3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use case for my long term video storage and potential cloud options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lh46i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698858960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to store a backup of recordings we&amp;#39;ve been making for the past three years. It&amp;#39;s currently at less than 3 TB and these are 5 - 9 GB files each, as mp4s. It will continue to grow, as we generate 6 recordings a month. I don&amp;#39;t need to access the backup frequently, as the files are also on my local machine, on archival M-discs, and on a separate HDD that I keep as a physical backup and sync two regularly. I also have Backblaze in the background. So when I go back to edit the recordings, I&amp;#39;ll be using the local files rather than the ones in the cloud.&lt;/p&gt;\n\n&lt;p&gt;However I really want someplace to drop a recording immediately after it&amp;#39;s done that&amp;#39;s off-site in the cloud, just in case of an immediate disaster.&lt;/p&gt;\n\n&lt;p&gt;They are currently on &lt;a href=\"https://sync.com/\"&gt;Sync.com&lt;/a&gt;, which offers unlimited space for $30/mo, but the service&amp;#39;s stopped providing support &lt;em&gt;of any kind&lt;/em&gt; recently (despite advertising phone support for their higher tiers) so I&amp;#39;m worried they&amp;#39;re about to go under or that something is up with their company.&lt;/p&gt;\n\n&lt;p&gt;I had considered AWS Deep Archive, but their egress cost seems insane as the service is really meant for &amp;quot;archives&amp;quot; as far as I understand it, not as a backup I might very infrequently access. &lt;/p&gt;\n\n&lt;p&gt;What other options are out there to consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lh46i", "is_robot_indexable": true, "report_reasons": null, "author": "mccoypauley", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lh46i/use_case_for_my_long_term_video_storage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lh46i/use_case_for_my_long_term_video_storage_and/", "subreddit_subscribers": 709913, "created_utc": 1698858960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The drive in question is a Samsung 500 GB Samsung EVO 850. Samsung Magician says the drive is good. There have been 354 TB written. I believe the drive is at least 8 years old.\n\nLately HD Sentinel has been reporting consistent sectors being reallocated. For the month of October 80 sectors were reallocated for a total of 145 that have been reallocated.\n\n(Sorry about the line breaks creating the extra space. I am not sure how to get rid of that.)\n\nHere is a brief history from the log.\n\n11/1/2023 10:45:34 AM,#5   Reallocated Sectors Count  144 -&gt; 145\n\n11/1/2023 1:15:11 AM,#5   Reallocated Sectors Count  143 -&gt; 144\n\n10/31/2023 7:28:19 PM,#5   Reallocated Sectors Count  142 -&gt; 143\n\n10/31/2023 7:46:46 AM,#5   Reallocated Sectors Count  141 -&gt; 142\n\n10/31/2023 3:40:42 AM,#5   Reallocated Sectors Count  140 -&gt; 141\n\n10/31/2023 3:30:40 AM,#5   Reallocated Sectors Count  139 -&gt; 140\n\n10/31/2023 1:45:16 AM,#5   Reallocated Sectors Count  138 -&gt; 139\n\n10/31/2023 1:40:16 AM,#5   Reallocated Sectors Count  137 -&gt; 138\n\n10/30/2023 8:13:11 PM,#5   Reallocated Sectors Count  136 -&gt; 137\n\n10/30/2023 10:31:28 AM,#5   Reallocated Sectors Count  135 -&gt; 136\n\n10/29/2023 11:32:55 PM,#5   Reallocated Sectors Count  134 -&gt; 135\n\n10/29/2023 3:01:36 PM,#5   Reallocated Sectors Count  133 -&gt; 134\n\n10/29/2023 11:20:46 AM,#5   Reallocated Sectors Count  132 -&gt; 133\n\n10/28/2023 12:42:09 PM,#5   Reallocated Sectors Count  130 -&gt; 132\n\n10/28/2023 8:31:29 AM,#5   Reallocated Sectors Count  129 -&gt; 130\n\n10/28/2023 8:21:27 AM,#5   Reallocated Sectors Count  128 -&gt; 129\n\n10/27/2023 5:22:07 PM,#5   Reallocated Sectors Count  127 -&gt; 128\n\n10/27/2023 2:26:43 PM,#5   Reallocated Sectors Count  126 -&gt; 127\n\n10/26/2023 10:34:41 PM,#5   Reallocated Sectors Count  125 -&gt; 126\n\n10/26/2023 7:39:15 PM,#5   Reallocated Sectors Count  124 -&gt; 125\n\n10/26/2023 5:48:58 PM,#5   Reallocated Sectors Count  123 -&gt; 124\n\n10/26/2023 12:48:08 PM,#5   Reallocated Sectors Count  122 -&gt; 123\n\n10/26/2023 9:23:56 AM,#5   Reallocated Sectors Count  121 -&gt; 122\n\n10/26/2023 9:18:53 AM,#5   Reallocated Sectors Count  120 -&gt; 121", "author_fullname": "t2_hxgex", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When Do Reallocated Sectors Become a Problem on an SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17le5f1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698851046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The drive in question is a Samsung 500 GB Samsung EVO 850. Samsung Magician says the drive is good. There have been 354 TB written. I believe the drive is at least 8 years old.&lt;/p&gt;\n\n&lt;p&gt;Lately HD Sentinel has been reporting consistent sectors being reallocated. For the month of October 80 sectors were reallocated for a total of 145 that have been reallocated.&lt;/p&gt;\n\n&lt;p&gt;(Sorry about the line breaks creating the extra space. I am not sure how to get rid of that.)&lt;/p&gt;\n\n&lt;p&gt;Here is a brief history from the log.&lt;/p&gt;\n\n&lt;p&gt;11/1/2023 10:45:34 AM,#5   Reallocated Sectors Count  144 -&amp;gt; 145&lt;/p&gt;\n\n&lt;p&gt;11/1/2023 1:15:11 AM,#5   Reallocated Sectors Count  143 -&amp;gt; 144&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 7:28:19 PM,#5   Reallocated Sectors Count  142 -&amp;gt; 143&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 7:46:46 AM,#5   Reallocated Sectors Count  141 -&amp;gt; 142&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 3:40:42 AM,#5   Reallocated Sectors Count  140 -&amp;gt; 141&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 3:30:40 AM,#5   Reallocated Sectors Count  139 -&amp;gt; 140&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 1:45:16 AM,#5   Reallocated Sectors Count  138 -&amp;gt; 139&lt;/p&gt;\n\n&lt;p&gt;10/31/2023 1:40:16 AM,#5   Reallocated Sectors Count  137 -&amp;gt; 138&lt;/p&gt;\n\n&lt;p&gt;10/30/2023 8:13:11 PM,#5   Reallocated Sectors Count  136 -&amp;gt; 137&lt;/p&gt;\n\n&lt;p&gt;10/30/2023 10:31:28 AM,#5   Reallocated Sectors Count  135 -&amp;gt; 136&lt;/p&gt;\n\n&lt;p&gt;10/29/2023 11:32:55 PM,#5   Reallocated Sectors Count  134 -&amp;gt; 135&lt;/p&gt;\n\n&lt;p&gt;10/29/2023 3:01:36 PM,#5   Reallocated Sectors Count  133 -&amp;gt; 134&lt;/p&gt;\n\n&lt;p&gt;10/29/2023 11:20:46 AM,#5   Reallocated Sectors Count  132 -&amp;gt; 133&lt;/p&gt;\n\n&lt;p&gt;10/28/2023 12:42:09 PM,#5   Reallocated Sectors Count  130 -&amp;gt; 132&lt;/p&gt;\n\n&lt;p&gt;10/28/2023 8:31:29 AM,#5   Reallocated Sectors Count  129 -&amp;gt; 130&lt;/p&gt;\n\n&lt;p&gt;10/28/2023 8:21:27 AM,#5   Reallocated Sectors Count  128 -&amp;gt; 129&lt;/p&gt;\n\n&lt;p&gt;10/27/2023 5:22:07 PM,#5   Reallocated Sectors Count  127 -&amp;gt; 128&lt;/p&gt;\n\n&lt;p&gt;10/27/2023 2:26:43 PM,#5   Reallocated Sectors Count  126 -&amp;gt; 127&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 10:34:41 PM,#5   Reallocated Sectors Count  125 -&amp;gt; 126&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 7:39:15 PM,#5   Reallocated Sectors Count  124 -&amp;gt; 125&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 5:48:58 PM,#5   Reallocated Sectors Count  123 -&amp;gt; 124&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 12:48:08 PM,#5   Reallocated Sectors Count  122 -&amp;gt; 123&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 9:23:56 AM,#5   Reallocated Sectors Count  121 -&amp;gt; 122&lt;/p&gt;\n\n&lt;p&gt;10/26/2023 9:18:53 AM,#5   Reallocated Sectors Count  120 -&amp;gt; 121&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17le5f1", "is_robot_indexable": true, "report_reasons": null, "author": "waynomo", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17le5f1/when_do_reallocated_sectors_become_a_problem_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17le5f1/when_do_reallocated_sectors_become_a_problem_on/", "subreddit_subscribers": 709913, "created_utc": 1698851046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found this list: https://github.com/meichthys/foss_photo_libraries/tree/main\n\nWhich seems to be only a year old. I've also installed PhotoPrism and the jury is still out because there's gaping holes and issues I don't know if I can resolve.\n\nMy focus is not on storage or I'd just do NextCloud. I want all the bells and whistles. Good face detection, scene and object detection / TensorFlow, reverse geocoding with an API like MapBox, automatic album and filenames using machine learning.\n\nI was really hoping there would be one obvious front-runner.", "author_fullname": "t2_nv9mx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bleeding-edge Self-Hosted Photo software in 2023? I'm talking AI-powered, Docker-friendly, open source, etc...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l7230", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698825271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found this list: &lt;a href=\"https://github.com/meichthys/foss_photo_libraries/tree/main\"&gt;https://github.com/meichthys/foss_photo_libraries/tree/main&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Which seems to be only a year old. I&amp;#39;ve also installed PhotoPrism and the jury is still out because there&amp;#39;s gaping holes and issues I don&amp;#39;t know if I can resolve.&lt;/p&gt;\n\n&lt;p&gt;My focus is not on storage or I&amp;#39;d just do NextCloud. I want all the bells and whistles. Good face detection, scene and object detection / TensorFlow, reverse geocoding with an API like MapBox, automatic album and filenames using machine learning.&lt;/p&gt;\n\n&lt;p&gt;I was really hoping there would be one obvious front-runner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17l7230", "is_robot_indexable": true, "report_reasons": null, "author": "malachi347", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l7230/bleedingedge_selfhosted_photo_software_in_2023_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l7230/bleedingedge_selfhosted_photo_software_in_2023_im/", "subreddit_subscribers": 709913, "created_utc": 1698825271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've noted that sometime in the last week, it appears that the Internet Archive has not been archiving, automatically, many (any?) reddit posts on their own. Is there a recent technical issue that is causing this, is the reddit-archive-team bot down, or something else?", "author_fullname": "t2_ydy1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the Internet Archive having technical issues crawling reddit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lmnqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698873791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noted that sometime in the last week, it appears that the Internet Archive has not been archiving, automatically, many (any?) reddit posts on their own. Is there a recent technical issue that is causing this, is the reddit-archive-team bot down, or something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lmnqt", "is_robot_indexable": true, "report_reasons": null, "author": "Justausername1234", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lmnqt/is_the_internet_archive_having_technical_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lmnqt/is_the_internet_archive_having_technical_issues/", "subreddit_subscribers": 709913, "created_utc": 1698873791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone, \n\nMy parents have a bunch of data just sitting on external drives, and that data is not copied anywhere. They have lost family photos to a failing drive before, and I want to prevent something like that from happening again.\n\nIn this vein, **I want to get them a complete NAS solution** for a Christmas present. I work in technology, although not in IT, so I am competent at understanding things of this nature but do not have the knowledge myself currently.\n\nIdeally, **this is my target system**:\n- an easy-to-use NAS that they will find intuitive (and cannot easily break)\n- a automated backup solution (ideally one on-site and one in the cloud, I use Backblaze B2 personally)\n- perhaps a UPS to really mitigate the possibility of error (do you all think this is necessary?)\n\n**I will provide**\n- a budget to get this done (I am comfortable spending between 1-2k USD)\n- the initial setup for them\n- support in the future should something go wrong\n\n**Any advice is greatly appreciated!** I'm not currently aware of how much storage will actually be required, but I think 5 or so TB to start would be sufficient.\n\nI've been looking at synology NAS options and am really just looking for advice on whether I've made some sort of mistake in reasoning, companies/products to avoid (or use), and any other advice you all would think is valuable :) Thanks again!", "author_fullname": "t2_kqraiwk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete NAS solution for parents for Christmas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ls9w0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698888964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, &lt;/p&gt;\n\n&lt;p&gt;My parents have a bunch of data just sitting on external drives, and that data is not copied anywhere. They have lost family photos to a failing drive before, and I want to prevent something like that from happening again.&lt;/p&gt;\n\n&lt;p&gt;In this vein, &lt;strong&gt;I want to get them a complete NAS solution&lt;/strong&gt; for a Christmas present. I work in technology, although not in IT, so I am competent at understanding things of this nature but do not have the knowledge myself currently.&lt;/p&gt;\n\n&lt;p&gt;Ideally, &lt;strong&gt;this is my target system&lt;/strong&gt;:\n- an easy-to-use NAS that they will find intuitive (and cannot easily break)\n- a automated backup solution (ideally one on-site and one in the cloud, I use Backblaze B2 personally)\n- perhaps a UPS to really mitigate the possibility of error (do you all think this is necessary?)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I will provide&lt;/strong&gt;\n- a budget to get this done (I am comfortable spending between 1-2k USD)\n- the initial setup for them\n- support in the future should something go wrong&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Any advice is greatly appreciated!&lt;/strong&gt; I&amp;#39;m not currently aware of how much storage will actually be required, but I think 5 or so TB to start would be sufficient.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at synology NAS options and am really just looking for advice on whether I&amp;#39;ve made some sort of mistake in reasoning, companies/products to avoid (or use), and any other advice you all would think is valuable :) Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ls9w0", "is_robot_indexable": true, "report_reasons": null, "author": "FiziksMayMays", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ls9w0/complete_nas_solution_for_parents_for_christmas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ls9w0/complete_nas_solution_for_parents_for_christmas/", "subreddit_subscribers": 709913, "created_utc": 1698888964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I\u2019m having an issue with an external HDD I use as a backup drive. It\u2019s starting to fail and I am wondering if I should use an SSD for a backup instead (I have a spare SATA one from Micron).\n\nI have seen people mention that SSDs are not good for long-term storage when they are left powered off. If I power on the SSD once a month when I do my backups will I be fine or should I just use an HDD?", "author_fullname": "t2_13bt8084", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD for External Backup Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lm1ya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698872718.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698872219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I\u2019m having an issue with an external HDD I use as a backup drive. It\u2019s starting to fail and I am wondering if I should use an SSD for a backup instead (I have a spare SATA one from Micron).&lt;/p&gt;\n\n&lt;p&gt;I have seen people mention that SSDs are not good for long-term storage when they are left powered off. If I power on the SSD once a month when I do my backups will I be fine or should I just use an HDD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lm1ya", "is_robot_indexable": true, "report_reasons": null, "author": "xxBLVCKMVGICxx", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lm1ya/ssd_for_external_backup_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lm1ya/ssd_for_external_backup_drive/", "subreddit_subscribers": 709913, "created_utc": 1698872219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I want to completely mirror a website, but only get a specific level of length when accessing external websites. How can I do this in wget? The help section isn't so clear about this", "author_fullname": "t2_ld87l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Only getting a specific depth of an external link with wget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lk835", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698867232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I want to completely mirror a website, but only get a specific level of length when accessing external websites. How can I do this in wget? The help section isn&amp;#39;t so clear about this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "37 TB local + 2.1 TB cloud", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lk835", "is_robot_indexable": true, "report_reasons": null, "author": "Sai22", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17lk835/only_getting_a_specific_depth_of_an_external_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lk835/only_getting_a_specific_depth_of_an_external_link/", "subreddit_subscribers": 709913, "created_utc": 1698867232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I wanted to do it with an excel file and just do it manually. Every session is recorded with OBS, uploaded to YT, and then redownloaded so it's compressed. You may disagree with that method, but I just care about the moments and such, so the quality is irrelevant as long as it's 720+ and you can tell what's going on, and Youtube does the compression for me so I don't gotta be running handbrake 24/7.\n\nI have over a thousand sessions since 2017, probably way more than that, just know that it's a lot. I mostly play League and mostly with the same people, and it's almost all organized with dates and time. Some sessions (moreso edited stuff) don't have dates. Some stuff is not gaming related.\n\nNow the reason I'm making this post is that I'm wondering what data you'd include. You know how excel has those columns, well I thought the first would be some sort of hex id just in case I needed it for something in the future, the second would be the date, and third would be title. I'd like to include file path and YT url/id. Maybe YT upload date as well. File size and upload date of course.\n\nNow the more annoying stuff that I'd like to include: People I played with, what games I played, how long I played each game, the scorelines or lengths of said games. Timestamps to funny or notable moments. Now I'm not sure how I'd include that if every session only has a single row. Maybe a second sheet? Idk.\n\nI'm not asking you for nitty gritty details, but just suggestions and such if you have any.", "author_fullname": "t2_bede0mtsb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wanna create a database for all my gaming sessions. Asking for some ideas, as it's a long term project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lld37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698870311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I wanted to do it with an excel file and just do it manually. Every session is recorded with OBS, uploaded to YT, and then redownloaded so it&amp;#39;s compressed. You may disagree with that method, but I just care about the moments and such, so the quality is irrelevant as long as it&amp;#39;s 720+ and you can tell what&amp;#39;s going on, and Youtube does the compression for me so I don&amp;#39;t gotta be running handbrake 24/7.&lt;/p&gt;\n\n&lt;p&gt;I have over a thousand sessions since 2017, probably way more than that, just know that it&amp;#39;s a lot. I mostly play League and mostly with the same people, and it&amp;#39;s almost all organized with dates and time. Some sessions (moreso edited stuff) don&amp;#39;t have dates. Some stuff is not gaming related.&lt;/p&gt;\n\n&lt;p&gt;Now the reason I&amp;#39;m making this post is that I&amp;#39;m wondering what data you&amp;#39;d include. You know how excel has those columns, well I thought the first would be some sort of hex id just in case I needed it for something in the future, the second would be the date, and third would be title. I&amp;#39;d like to include file path and YT url/id. Maybe YT upload date as well. File size and upload date of course.&lt;/p&gt;\n\n&lt;p&gt;Now the more annoying stuff that I&amp;#39;d like to include: People I played with, what games I played, how long I played each game, the scorelines or lengths of said games. Timestamps to funny or notable moments. Now I&amp;#39;m not sure how I&amp;#39;d include that if every session only has a single row. Maybe a second sheet? Idk.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not asking you for nitty gritty details, but just suggestions and such if you have any.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lld37", "is_robot_indexable": true, "report_reasons": null, "author": "spanspan3213", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lld37/i_wanna_create_a_database_for_all_my_gaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lld37/i_wanna_create_a_database_for_all_my_gaming/", "subreddit_subscribers": 709913, "created_utc": 1698870311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I say \"large\" because it's probably crumbs to folks on here but I have roughly 2-3TB of movies and tv shows for my Plex server. Problem is, I have copies of mainly movies scattered between 3-4 computers and I'm finally setting up a dedicated server to consolidate everything. Once I have everything on a single computer, I want to be able to find duplicate movies and shows and keep the higher quality ones. I guess the simplest way would be to toss everything into the same folder and when Windows notifies me of a duplicate, I would just keep which ever file size is bigger which would assume higher quality. I'm hoping to find an application that lets me export video metadata so I can see sizes, bitrate, and resolution so I can 1. delete low quality version then 2. see which of my favorite movies/shows are of low quality so I can eventually get higher quality replacements.  \n  \nI came across MediaInfo but can't tell if it only lets you view video data individually or if it can do a mass export to a csv or something of the like.", "author_fullname": "t2_ceda1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting video metadata of \"large\" collection of movies and tv shows.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lbwxz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698844631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I say &amp;quot;large&amp;quot; because it&amp;#39;s probably crumbs to folks on here but I have roughly 2-3TB of movies and tv shows for my Plex server. Problem is, I have copies of mainly movies scattered between 3-4 computers and I&amp;#39;m finally setting up a dedicated server to consolidate everything. Once I have everything on a single computer, I want to be able to find duplicate movies and shows and keep the higher quality ones. I guess the simplest way would be to toss everything into the same folder and when Windows notifies me of a duplicate, I would just keep which ever file size is bigger which would assume higher quality. I&amp;#39;m hoping to find an application that lets me export video metadata so I can see sizes, bitrate, and resolution so I can 1. delete low quality version then 2. see which of my favorite movies/shows are of low quality so I can eventually get higher quality replacements.  &lt;/p&gt;\n\n&lt;p&gt;I came across MediaInfo but can&amp;#39;t tell if it only lets you view video data individually or if it can do a mass export to a csv or something of the like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lbwxz", "is_robot_indexable": true, "report_reasons": null, "author": "inthemix8080", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lbwxz/exporting_video_metadata_of_large_collection_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lbwxz/exporting_video_metadata_of_large_collection_of/", "subreddit_subscribers": 709913, "created_utc": 1698844631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI just flashed a 9300-8i to IT mode, but it only shows one disk properly (sda), and one disk as 0B (sdb) (in proxmox).  This is the same/similar regardless of which combination of 8 drives, 2 cables, 2 ports I use - always only one disk reporting a size, up to three additional disks reporting 0B, and no disks ever showing under sas3ircu.\n\nAnyone have any ideas what's going on?\n\n\\# lsblk:\n\n    NAME               MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\n    sda                  8:0    0   1.5T  0 disk\n    \u251c\u2500sda1               8:1    0   1.5T  0 part\n    \u2514\u2500sda9               8:9    0     8M  0 part\n    sdb                  8:16   0     0B  0 disk\n    nvme3n1            259:0    0 931.5G  0 disk\n    \u251c\u2500nvme3n1p1        259:1    0  1007K  0 part\n    \u251c\u2500nvme3n1p2        259:2    0     1G  0 part /boot/efi\n    \u2514\u2500nvme3n1p3        259:3    0 930.5G  0 part\n      \u251c\u2500pve-swap       253:0    0     8G  0 lvm  [SWAP]\n      \u251c\u2500pve-root       253:1    0    96G  0 lvm  /\n      \u251c\u2500pve-data_tmeta 253:2    0   8.1G  0 lvm \n      \u2502 \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n      \u2514\u2500pve-data_tdata 253:3    0 794.3G  0 lvm \n        \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n    nvme0n1            259:4    0 931.5G  0 disk\n    \u251c\u2500nvme0n1p1        259:5    0 931.5G  0 part\n    \u2514\u2500nvme0n1p9        259:6    0     8M  0 part\n    nvme1n1            259:7    0 931.5G  0 disk\n    \u251c\u2500nvme1n1p1        259:8    0 931.5G  0 part\n    \u2514\u2500nvme1n1p9        259:9    0     8M  0 part\n    nvme2n1            259:10   0   1.5T  0 disk\n\n\\# sas3ircu 0 display\n\n    Avago Technologies SAS3 IR Configuration Utility.\n    Version 17.00.00.00 (2018.04.02)\n    Copyright (c) 2009-2018 Avago Technologies. All rights reserved.\n    \n    Read configuration has been initiated for controller 0\n    ------------------------------------------------------------------------\n    Controller information\n    ------------------------------------------------------------------------\n      Controller type                         : SAS3008\n      BIOS version                            : 8.37.00.00\n      Firmware version                        : 16.00.10.00\n      Channel description                     : 1 Serial Attached SCSI\n      Initiator ID                            : 0\n      Maximum physical devices                : 1023\n      Concurrent commands supported           : 9856\n      Slot                                    : 24\n      Segment                                 : 0\n      Bus                                     : 3\n      Device                                  : 0\n      Function                                : 0\n      RAID Support                            : No\n    ------------------------------------------------------------------------\n    IR Volume information\n    ------------------------------------------------------------------------\n    ------------------------------------------------------------------------\n    Physical device information\n    ------------------------------------------------------------------------\n    ------------------------------------------------------------------------\n    Enclosure information\n    ------------------------------------------------------------------------\n      Enclosure#                              : 1\n      Logical ID                              : 500605b0:0b2c9b80\n      Numslots                                : 8\n      StartSlot                               : 0\n    ------------------------------------------------------------------------\n    SAS3IRCU: Command DISPLAY Completed Successfully.\n    SAS3IRCU: Utility Completed Successfully.\n\n\\# sas3flash -c 0 -list\n\n    Avago Technologies SAS3 Flash Utility\n    Version 16.00.00.00 (2017.05.02) \n    Copyright 2008-2017 Avago Technologies. All rights reserved.\n    \n            Adapter Selected is a Avago SAS: SAS3008(C0)\n    \n            Controller Number              : 0\n            Controller                     : SAS3008(C0)\n            PCI Address                    : 00:03:00:00\n            SAS Address                    : 500605b-0-0b2c-9b80\n            NVDATA Version (Default)       : 0e.01.00.07\n            NVDATA Version (Persistent)    : 0e.01.00.07\n            Firmware Product ID            : 0x2221 (IT)\n            Firmware Version               : 16.00.10.00\n            NVDATA Vendor                  : LSI\n            NVDATA Product ID              : SAS9300-8i\n            BIOS Version                   : 08.37.00.00\n            UEFI BSD Version               : 18.00.00.00\n            FCODE Version                  : N/A\n            Board Name                     : SAS9300-8i\n            Board Assembly                 : N/A\n            Board Tracer Number            : N/A\n    \n            Finished Processing Commands Successfully.\n            Exiting SAS3Flash.\n\n\\# lspci\n\n    03:00.0 Serial Attached SCSI controller: Broadcom / LSI SAS3008 PCI-Express Fusion-MPT SAS-3 (rev 02)\n\n&amp;#x200B;", "author_fullname": "t2_qz8xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17la0xl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698840023.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698838408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I just flashed a 9300-8i to IT mode, but it only shows one disk properly (sda), and one disk as 0B (sdb) (in proxmox).  This is the same/similar regardless of which combination of 8 drives, 2 cables, 2 ports I use - always only one disk reporting a size, up to three additional disks reporting 0B, and no disks ever showing under sas3ircu.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any ideas what&amp;#39;s going on?&lt;/p&gt;\n\n&lt;p&gt;# lsblk:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;NAME               MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nsda                  8:0    0   1.5T  0 disk\n\u251c\u2500sda1               8:1    0   1.5T  0 part\n\u2514\u2500sda9               8:9    0     8M  0 part\nsdb                  8:16   0     0B  0 disk\nnvme3n1            259:0    0 931.5G  0 disk\n\u251c\u2500nvme3n1p1        259:1    0  1007K  0 part\n\u251c\u2500nvme3n1p2        259:2    0     1G  0 part /boot/efi\n\u2514\u2500nvme3n1p3        259:3    0 930.5G  0 part\n  \u251c\u2500pve-swap       253:0    0     8G  0 lvm  [SWAP]\n  \u251c\u2500pve-root       253:1    0    96G  0 lvm  /\n  \u251c\u2500pve-data_tmeta 253:2    0   8.1G  0 lvm \n  \u2502 \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \n  \u2514\u2500pve-data_tdata 253:3    0 794.3G  0 lvm \n    \u2514\u2500pve-data     253:4    0 794.3G  0 lvm \nnvme0n1            259:4    0 931.5G  0 disk\n\u251c\u2500nvme0n1p1        259:5    0 931.5G  0 part\n\u2514\u2500nvme0n1p9        259:6    0     8M  0 part\nnvme1n1            259:7    0 931.5G  0 disk\n\u251c\u2500nvme1n1p1        259:8    0 931.5G  0 part\n\u2514\u2500nvme1n1p9        259:9    0     8M  0 part\nnvme2n1            259:10   0   1.5T  0 disk\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# sas3ircu 0 display&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avago Technologies SAS3 IR Configuration Utility.\nVersion 17.00.00.00 (2018.04.02)\nCopyright (c) 2009-2018 Avago Technologies. All rights reserved.\n\nRead configuration has been initiated for controller 0\n------------------------------------------------------------------------\nController information\n------------------------------------------------------------------------\n  Controller type                         : SAS3008\n  BIOS version                            : 8.37.00.00\n  Firmware version                        : 16.00.10.00\n  Channel description                     : 1 Serial Attached SCSI\n  Initiator ID                            : 0\n  Maximum physical devices                : 1023\n  Concurrent commands supported           : 9856\n  Slot                                    : 24\n  Segment                                 : 0\n  Bus                                     : 3\n  Device                                  : 0\n  Function                                : 0\n  RAID Support                            : No\n------------------------------------------------------------------------\nIR Volume information\n------------------------------------------------------------------------\n------------------------------------------------------------------------\nPhysical device information\n------------------------------------------------------------------------\n------------------------------------------------------------------------\nEnclosure information\n------------------------------------------------------------------------\n  Enclosure#                              : 1\n  Logical ID                              : 500605b0:0b2c9b80\n  Numslots                                : 8\n  StartSlot                               : 0\n------------------------------------------------------------------------\nSAS3IRCU: Command DISPLAY Completed Successfully.\nSAS3IRCU: Utility Completed Successfully.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# sas3flash -c 0 -list&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Avago Technologies SAS3 Flash Utility\nVersion 16.00.00.00 (2017.05.02) \nCopyright 2008-2017 Avago Technologies. All rights reserved.\n\n        Adapter Selected is a Avago SAS: SAS3008(C0)\n\n        Controller Number              : 0\n        Controller                     : SAS3008(C0)\n        PCI Address                    : 00:03:00:00\n        SAS Address                    : 500605b-0-0b2c-9b80\n        NVDATA Version (Default)       : 0e.01.00.07\n        NVDATA Version (Persistent)    : 0e.01.00.07\n        Firmware Product ID            : 0x2221 (IT)\n        Firmware Version               : 16.00.10.00\n        NVDATA Vendor                  : LSI\n        NVDATA Product ID              : SAS9300-8i\n        BIOS Version                   : 08.37.00.00\n        UEFI BSD Version               : 18.00.00.00\n        FCODE Version                  : N/A\n        Board Name                     : SAS9300-8i\n        Board Assembly                 : N/A\n        Board Tracer Number            : N/A\n\n        Finished Processing Commands Successfully.\n        Exiting SAS3Flash.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;# lspci&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;03:00.0 Serial Attached SCSI controller: Broadcom / LSI SAS3008 PCI-Express Fusion-MPT SAS-3 (rev 02)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17la0xl", "is_robot_indexable": true, "report_reasons": null, "author": "SunRoyal", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17la0xl/help_with_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17la0xl/help_with_hba/", "subreddit_subscribers": 709913, "created_utc": 1698838408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am switching from a Synology with 8 drive bays to a server with 24 drive bays to up my data hoarding game. [This](https://www.servercase.co.uk/shop/server-cases/rackmount/4u-chassis/4u-server-case-w-24x-35-hot-swappable-satasas-drive-bays-12g-backplane-sc-4324/) is the chassis I will be using. There appear to be 6 backplanes, each of which drive 4 drives. What I am unsure of is how to connect that to my system. I understand I should probably be using an HBA card, I see a lot of recommendations for the LSI 9211-8i, but I only see 2 ports on that, is that sufficient? If not which hba card should I be going for? Also which cables will I need to connect it to the backplanes? Oh also I am using the [Gigabyte Z790 Aorus Elite AX, Intel Z790 Motherboard](https://www.amazon.co.uk/dp/B0BH28M64J?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details) if that matters for this question. Thanks in advance!", "author_fullname": "t2_417t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some advice with HBA card and cables.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l92dm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698834941.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698834598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am switching from a Synology with 8 drive bays to a server with 24 drive bays to up my data hoarding game. &lt;a href=\"https://www.servercase.co.uk/shop/server-cases/rackmount/4u-chassis/4u-server-case-w-24x-35-hot-swappable-satasas-drive-bays-12g-backplane-sc-4324/\"&gt;This&lt;/a&gt; is the chassis I will be using. There appear to be 6 backplanes, each of which drive 4 drives. What I am unsure of is how to connect that to my system. I understand I should probably be using an HBA card, I see a lot of recommendations for the LSI 9211-8i, but I only see 2 ports on that, is that sufficient? If not which hba card should I be going for? Also which cables will I need to connect it to the backplanes? Oh also I am using the &lt;a href=\"https://www.amazon.co.uk/dp/B0BH28M64J?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details\"&gt;Gigabyte Z790 Aorus Elite AX, Intel Z790 Motherboard&lt;/a&gt; if that matters for this question. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?auto=webp&amp;s=cc1290301fa7f3bd493ccc284409c3e5f30ab017", "width": 1024, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6fdfbe029bf8446131197eabcc9b2ac7fa3f13b7", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cd493e717e05880dc5683f5c2545724752620188", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b437b86b3d759167b06eec0bd7852d5c99252f5f", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3fe7c3d62562f65eb4b0fa3c37011aa9970ad68e", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/S15efRRRd-wxIoPCijhJ4k6KZo8xMwCP4mq1uTf_DAc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5a2f43b6d3bae8d99be957d758ddafa61eeb5c86", "width": 960, "height": 720}], "variants": {}, "id": "KycaFLy5iFQEXScOKN6TrtxSMGr4MVNhNdnzL2-2lRE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l92dm", "is_robot_indexable": true, "report_reasons": null, "author": "Spaztic_monkey", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l92dm/need_some_advice_with_hba_card_and_cables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l92dm/need_some_advice_with_hba_card_and_cables/", "subreddit_subscribers": 709913, "created_utc": 1698834598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey so, I just passed the 30TB mark but I need more storage. Can anyone reccomend me a SATA hub or docking bay for more HDDs? I already maxed out the slots in my server case. And specifically NOT USB 3.0 bays. I want them to act like actual drives and I feel like USB would slow them down way too much for my liking.", "author_fullname": "t2_g14at", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone reccomend me a SATA HDD HUB/BAY?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l88yp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698830981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey so, I just passed the 30TB mark but I need more storage. Can anyone reccomend me a SATA hub or docking bay for more HDDs? I already maxed out the slots in my server case. And specifically NOT USB 3.0 bays. I want them to act like actual drives and I feel like USB would slow them down way too much for my liking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l88yp", "is_robot_indexable": true, "report_reasons": null, "author": "Firefoxray", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l88yp/can_someone_reccomend_me_a_sata_hdd_hubbay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l88yp/can_someone_reccomend_me_a_sata_hdd_hubbay/", "subreddit_subscribers": 709913, "created_utc": 1698830981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dear members,\n\nI have a collection of low to medium capacity HDDs (int. &amp; ext.) and SSDs (ext) between 480 GB and 4 TB. Currently, I'm considering building a NAS with those components that does not need to perform exceptionally. Thus, I was considering a RPi 5 with a Quad SATA HAT (currently available only for RPi 4) and a powered USB Hub for powering the HDDs and as a temporary solution for the SATA drives, until a SATA HAT is released for the RPi 5.\n\nMy goal is to have the lowest idle consumption possible and even turn the NAS off for the most part of the day, make use of the components, invest less than 350 bucks and fit it under my bookshelf with a height constraint of 9cm.\n\nWould this be viable at all, or have I not considered some solutions that are less advertised than the RPi articles i.e. DIY solutions?\n\nMuch appreciated!", "author_fullname": "t2_z560y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4x 2.5 SATA HDD, 4x 2.5 USB HDD, 2x 2.5 SATA SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l7rha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698836894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698828709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear members,&lt;/p&gt;\n\n&lt;p&gt;I have a collection of low to medium capacity HDDs (int. &amp;amp; ext.) and SSDs (ext) between 480 GB and 4 TB. Currently, I&amp;#39;m considering building a NAS with those components that does not need to perform exceptionally. Thus, I was considering a RPi 5 with a Quad SATA HAT (currently available only for RPi 4) and a powered USB Hub for powering the HDDs and as a temporary solution for the SATA drives, until a SATA HAT is released for the RPi 5.&lt;/p&gt;\n\n&lt;p&gt;My goal is to have the lowest idle consumption possible and even turn the NAS off for the most part of the day, make use of the components, invest less than 350 bucks and fit it under my bookshelf with a height constraint of 9cm.&lt;/p&gt;\n\n&lt;p&gt;Would this be viable at all, or have I not considered some solutions that are less advertised than the RPi articles i.e. DIY solutions?&lt;/p&gt;\n\n&lt;p&gt;Much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17l7rha", "is_robot_indexable": true, "report_reasons": null, "author": "mhmilo24", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l7rha/4x_25_sata_hdd_4x_25_usb_hdd_2x_25_sata_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l7rha/4x_25_sata_hdd_4x_25_usb_hdd_2x_25_sata_ssd/", "subreddit_subscribers": 709913, "created_utc": 1698828709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there,\n\nI bought two WD RED 14 TB drives (7200 RPM) recently for mass storage, and added all of my data to both of them which are now synced via 'rsync'.\n\nMy issue is this:\n\n\\- Every 5 secs, I can hear like a 'data read' type noise --&gt; Not necessarily as bad as a hard drive failure click, but something noticeable. Its kind of slight loud, and hard to ignore. It doesn't sound awful, but I can't like 'not hear it' which is getting annoying.\n\nI notice them in tandem since they are the same drive aka as soon as 5 secs go by --&gt; one makes the read noise, and the other makes a read noise shortly there after.\n\nI am using Linux so I observed this issue on the same machine via Ubuntu Server, and Linux Mint.\n\n&amp;#x200B;\n\nAnyone else notice this? Is this normal? Asking since I can probably just zero out the drives and return them, but would need to know if I can maybe force it to do this kind of idle read every few minutes or something.\n\n&amp;#x200B;\n\nFigured I would ask you guys, thanks.", "author_fullname": "t2_9kx87h0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question Regarding Default 'Read' Click For WD RED 14 TB Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lt0kf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698891101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I bought two WD RED 14 TB drives (7200 RPM) recently for mass storage, and added all of my data to both of them which are now synced via &amp;#39;rsync&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;My issue is this:&lt;/p&gt;\n\n&lt;p&gt;- Every 5 secs, I can hear like a &amp;#39;data read&amp;#39; type noise --&amp;gt; Not necessarily as bad as a hard drive failure click, but something noticeable. Its kind of slight loud, and hard to ignore. It doesn&amp;#39;t sound awful, but I can&amp;#39;t like &amp;#39;not hear it&amp;#39; which is getting annoying.&lt;/p&gt;\n\n&lt;p&gt;I notice them in tandem since they are the same drive aka as soon as 5 secs go by --&amp;gt; one makes the read noise, and the other makes a read noise shortly there after.&lt;/p&gt;\n\n&lt;p&gt;I am using Linux so I observed this issue on the same machine via Ubuntu Server, and Linux Mint.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone else notice this? Is this normal? Asking since I can probably just zero out the drives and return them, but would need to know if I can maybe force it to do this kind of idle read every few minutes or something.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Figured I would ask you guys, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lt0kf", "is_robot_indexable": true, "report_reasons": null, "author": "BackToPlebbit69", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lt0kf/question_regarding_default_read_click_for_wd_red/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lt0kf/question_regarding_default_read_click_for_wd_red/", "subreddit_subscribers": 709913, "created_utc": 1698891101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just installed a ssd on my pc and installed windows on the it. my old hdd still have windows on it and I'm planning to completely remove the windows. my hdd has 2 partitions. C for windows and D for personal data. After formatting the C drive(system drive on hdd) i want to merge it with other D drive. I want to know if I can merge them as one single drive and if yes then how. thank you.\nedit: I also would like to do this without any data loss so let me know if the merger will lead to data loss on the personal drive (of old hdd)", "author_fullname": "t2_17eahs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about disk partition.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lk470", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698867413.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698866955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just installed a ssd on my pc and installed windows on the it. my old hdd still have windows on it and I&amp;#39;m planning to completely remove the windows. my hdd has 2 partitions. C for windows and D for personal data. After formatting the C drive(system drive on hdd) i want to merge it with other D drive. I want to know if I can merge them as one single drive and if yes then how. thank you.\nedit: I also would like to do this without any data loss so let me know if the merger will lead to data loss on the personal drive (of old hdd)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lk470", "is_robot_indexable": true, "report_reasons": null, "author": "thetushar7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lk470/question_about_disk_partition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lk470/question_about_disk_partition/", "subreddit_subscribers": 709913, "created_utc": 1698866955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "title, need to download multiple  youtube channels and have them download any new videos uploaded", "author_fullname": "t2_4av7osji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how can i download a whole youtube channel and have it automatically download new videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ljq1t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698865895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title, need to download multiple  youtube channels and have them download any new videos uploaded&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ljq1t", "is_robot_indexable": true, "report_reasons": null, "author": "alex_square6", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ljq1t/how_can_i_download_a_whole_youtube_channel_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ljq1t/how_can_i_download_a_whole_youtube_channel_and/", "subreddit_subscribers": 709913, "created_utc": 1698865895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I know I can write a script for this, but I was wondering if there is some sort of solution that is already made for this.\n\nThanks!", "author_fullname": "t2_uy2zp43z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool to automatically archive a folder, transfer via scp/rsync and decompress on the other side automatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lfukx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698855651.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I know I can write a script for this, but I was wondering if there is some sort of solution that is already made for this.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lfukx", "is_robot_indexable": true, "report_reasons": null, "author": "angel__-__-", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lfukx/is_there_a_tool_to_automatically_archive_a_folder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lfukx/is_there_a_tool_to_automatically_archive_a_folder/", "subreddit_subscribers": 709913, "created_utc": 1698855651.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Where can i learn facts about HDD head movement?\n\nMost information I get is clueless consumers scaring each other and telling stories of failing drives (which could very well be the case i'm in)\n\nWe just moved offices and our main NAS (RAID1 of WD 10TB gold drives) started to display constant head movement that i can hear easily. Almost like clicking of death, but more \"contained\".  not so loud and just under 1s interval.\n\nWe do have daily/biweekly backup besides the RAID1. But since we were semi-offline for the office move we have some data there that is not on the (paused) daily snapshots. Which i don't want to tell users they lost. This sound very amateur, because it is :) non-profit and all.\n\nThe host is linux 6.5. I'm using only two disks in read-only mode for now.\n\nEach disk is 10TB but only have 2TB partitions for the linux soft raid (mdadm). In the raid there's a LUKS volume with encryption and inside that a single ext4 partition.\n\neverything shows up perfect. SMART pass with flying colors on short tests. RAID shows healthy status. kernel complains of nothing. But the head movement is driving me crazy scared!\n\nThe drives are mostly idle, but vmstat does show some IO happening. Which i suspect is journal being checked? Is there anyway i can tell the kernel to pause all journal activity to make sure the noise goes away? Or maybe it is a firmware thing?\n\nThe drives are not too old. They are exact same model but different lots. always lived in that raid1. And they were transported in different methods for the move. They are both connected to the same PSU (can this be bad power? would it not show up anywhere?). Data reading bandwidth seems the same as before the move (i.e. during the time without the weird head movement sound).\n\nWhat i'm trying to understand now is if I can take my time getting data out of the drivers which are offline, threat it as a imminent failure case, or don't even bother buying new drives for now and use them as regular till they die as they all do and just keep dropping in new spares in the raid. it's only the fact that all of them started the sound at the same time that leads me to believe it might be something in software/firmware/journal thanks to the time offline instead of hardware failure.", "author_fullname": "t2_vjutt7ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD head movement information", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ldhba", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698849188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where can i learn facts about HDD head movement?&lt;/p&gt;\n\n&lt;p&gt;Most information I get is clueless consumers scaring each other and telling stories of failing drives (which could very well be the case i&amp;#39;m in)&lt;/p&gt;\n\n&lt;p&gt;We just moved offices and our main NAS (RAID1 of WD 10TB gold drives) started to display constant head movement that i can hear easily. Almost like clicking of death, but more &amp;quot;contained&amp;quot;.  not so loud and just under 1s interval.&lt;/p&gt;\n\n&lt;p&gt;We do have daily/biweekly backup besides the RAID1. But since we were semi-offline for the office move we have some data there that is not on the (paused) daily snapshots. Which i don&amp;#39;t want to tell users they lost. This sound very amateur, because it is :) non-profit and all.&lt;/p&gt;\n\n&lt;p&gt;The host is linux 6.5. I&amp;#39;m using only two disks in read-only mode for now.&lt;/p&gt;\n\n&lt;p&gt;Each disk is 10TB but only have 2TB partitions for the linux soft raid (mdadm). In the raid there&amp;#39;s a LUKS volume with encryption and inside that a single ext4 partition.&lt;/p&gt;\n\n&lt;p&gt;everything shows up perfect. SMART pass with flying colors on short tests. RAID shows healthy status. kernel complains of nothing. But the head movement is driving me crazy scared!&lt;/p&gt;\n\n&lt;p&gt;The drives are mostly idle, but vmstat does show some IO happening. Which i suspect is journal being checked? Is there anyway i can tell the kernel to pause all journal activity to make sure the noise goes away? Or maybe it is a firmware thing?&lt;/p&gt;\n\n&lt;p&gt;The drives are not too old. They are exact same model but different lots. always lived in that raid1. And they were transported in different methods for the move. They are both connected to the same PSU (can this be bad power? would it not show up anywhere?). Data reading bandwidth seems the same as before the move (i.e. during the time without the weird head movement sound).&lt;/p&gt;\n\n&lt;p&gt;What i&amp;#39;m trying to understand now is if I can take my time getting data out of the drivers which are offline, threat it as a imminent failure case, or don&amp;#39;t even bother buying new drives for now and use them as regular till they die as they all do and just keep dropping in new spares in the raid. it&amp;#39;s only the fact that all of them started the sound at the same time that leads me to believe it might be something in software/firmware/journal thanks to the time offline instead of hardware failure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ldhba", "is_robot_indexable": true, "report_reasons": null, "author": "DecentTone876", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ldhba/hdd_head_movement_information/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ldhba/hdd_head_movement_information/", "subreddit_subscribers": 709913, "created_utc": 1698849188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello there. \nI'm thinking of getting/making a home NAS/Server/Jellyfin. \nI already have an old pc with a i5-6600k, GTX1060, 550w PSU just laying around and I'm trying to understand if it will be enough for it. \nThe other options I saw was getting a Synology or making a Pi_NAS. \nI'm afraid that the PC will consume much more energy than the other 2 options. \nWhat do you guys think?", "author_fullname": "t2_5syc5zdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old PC vs NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17labiv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698839483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there. \nI&amp;#39;m thinking of getting/making a home NAS/Server/Jellyfin. \nI already have an old pc with a i5-6600k, GTX1060, 550w PSU just laying around and I&amp;#39;m trying to understand if it will be enough for it. \nThe other options I saw was getting a Synology or making a Pi_NAS. \nI&amp;#39;m afraid that the PC will consume much more energy than the other 2 options. \nWhat do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17labiv", "is_robot_indexable": true, "report_reasons": null, "author": "Serigaita", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17labiv/old_pc_vs_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17labiv/old_pc_vs_nas/", "subreddit_subscribers": 709913, "created_utc": 1698839483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nWhats your experience with the Samsung 870 QVO 8TB drive? I plan to buy an Intel NUC tall version, install Jellyfin and use this drive as main storage for my media. I don't expect I will write and delete data too much off of it in this context ...\n\nThanks", "author_fullname": "t2_155ml1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Samsung 870 QVO 8TB - What's your experience with this drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17l9nzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698837011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Whats your experience with the Samsung 870 QVO 8TB drive? I plan to buy an Intel NUC tall version, install Jellyfin and use this drive as main storage for my media. I don&amp;#39;t expect I will write and delete data too much off of it in this context ...&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17l9nzl", "is_robot_indexable": true, "report_reasons": null, "author": "mariusmoga_2005", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17l9nzl/samsung_870_qvo_8tb_whats_your_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17l9nzl/samsung_870_qvo_8tb_whats_your_experience_with/", "subreddit_subscribers": 709913, "created_utc": 1698837011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking to repurpose 4x 6tb drives and will only use for archiving backup. No hosting. I don't want this accessed remotely. I'm aware that terramaster has terrible os and TOS4 was bad. My questionis, do i still get their nas (wont run TOS5)? Or am i better off repurposing my i5 6th gen mini-itx pc by replacing the case and psu woth a mini itx case and sfx psu? (Current case is a mid tower).\n\n[View Poll](https://www.reddit.com/poll/17lw1rc)", "author_fullname": "t2_57pge7h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terramaster F4-210 or custom NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17lw1rc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698901162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to repurpose 4x 6tb drives and will only use for archiving backup. No hosting. I don&amp;#39;t want this accessed remotely. I&amp;#39;m aware that terramaster has terrible os and TOS4 was bad. My questionis, do i still get their nas (wont run TOS5)? Or am i better off repurposing my i5 6th gen mini-itx pc by replacing the case and psu woth a mini itx case and sfx psu? (Current case is a mid tower).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17lw1rc\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lw1rc", "is_robot_indexable": true, "report_reasons": null, "author": "Fantastic_Bookkeeper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1699073962313, "options": [{"text": "Terramaster F4-210", "id": "25532489"}, {"text": "Use existing mini itx pc and add case and sfx psu", "id": "25532490"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 3, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lw1rc/terramaster_f4210_or_custom_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/DataHoarder/comments/17lw1rc/terramaster_f4210_or_custom_nas/", "subreddit_subscribers": 709913, "created_utc": 1698901162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been a pretty faithful with backups for decades, changing tools and services with the flow, and I'm in the process of reviewing my current practices to see if they are a good fit for my needs. Would love to hear suggestions. I'm running an M1 Macbook Pro with 1TB internal drive.\n\nCurrent strategy:\n\n1. Time Machine for local backup of laptop\n2. iDrive for remote backup of laptop plus a couple of external drives (currently have 5TB storage plan)\n\nMy goals:\n\n1. Have a good local backup in case of drive failure\n2. Have a good remote backup of laptop\n3. Long-term archival storage of photos, videos, documents, etc., both local and remote. These are not working files and are not stored on the laptop. Current volume is in the 2TB range.\n4. Backup including iPhone stuff (photos and whatnot)\n\nTools I have on hand:\n\n1. Various external hard drives, mostly USB3, in the 2-5 TB range\n2. Chronosync, Carbon Copy Cloner\n\nI'm not willing to put in the time and energy to build a NAS.\n\nI used to store my archive files on Amazon Drive but that's going away and Amazon Photos is HORRIBLE so I don't even consider it an option, plus I have a lot of files that aren't photo/video.\n\nUsed to have Crashplan for years until they got rid of personal accounts back when. Switched to iDrive. I've played with Backblaze a bit but am alarmed by what I've read here about the viability of the company.\n\nShould I look into some type of cloud storage (not backup) for the archive stuff? Or try to hobble along with it as part of a personal backup service (having it back up as an external drive)? Or just get cloud storage and use something like Chronosync to back up to disk images and upload those to the cloud?\n\nThanks for your suggestions.", "author_fullname": "t2_d7hme", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for suggestions to create a good backup plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lksdo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698868775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a pretty faithful with backups for decades, changing tools and services with the flow, and I&amp;#39;m in the process of reviewing my current practices to see if they are a good fit for my needs. Would love to hear suggestions. I&amp;#39;m running an M1 Macbook Pro with 1TB internal drive.&lt;/p&gt;\n\n&lt;p&gt;Current strategy:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Time Machine for local backup of laptop&lt;/li&gt;\n&lt;li&gt;iDrive for remote backup of laptop plus a couple of external drives (currently have 5TB storage plan)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My goals:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have a good local backup in case of drive failure&lt;/li&gt;\n&lt;li&gt;Have a good remote backup of laptop&lt;/li&gt;\n&lt;li&gt;Long-term archival storage of photos, videos, documents, etc., both local and remote. These are not working files and are not stored on the laptop. Current volume is in the 2TB range.&lt;/li&gt;\n&lt;li&gt;Backup including iPhone stuff (photos and whatnot)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Tools I have on hand:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Various external hard drives, mostly USB3, in the 2-5 TB range&lt;/li&gt;\n&lt;li&gt;Chronosync, Carbon Copy Cloner&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m not willing to put in the time and energy to build a NAS.&lt;/p&gt;\n\n&lt;p&gt;I used to store my archive files on Amazon Drive but that&amp;#39;s going away and Amazon Photos is HORRIBLE so I don&amp;#39;t even consider it an option, plus I have a lot of files that aren&amp;#39;t photo/video.&lt;/p&gt;\n\n&lt;p&gt;Used to have Crashplan for years until they got rid of personal accounts back when. Switched to iDrive. I&amp;#39;ve played with Backblaze a bit but am alarmed by what I&amp;#39;ve read here about the viability of the company.&lt;/p&gt;\n\n&lt;p&gt;Should I look into some type of cloud storage (not backup) for the archive stuff? Or try to hobble along with it as part of a personal backup service (having it back up as an external drive)? Or just get cloud storage and use something like Chronosync to back up to disk images and upload those to the cloud?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17lksdo", "is_robot_indexable": true, "report_reasons": null, "author": "debit72", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17lksdo/looking_for_suggestions_to_create_a_good_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17lksdo/looking_for_suggestions_to_create_a_good_backup/", "subreddit_subscribers": 709913, "created_utc": 1698868775.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}