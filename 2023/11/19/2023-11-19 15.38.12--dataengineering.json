{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seeking insights: \n\nI manage a data analytics department and a group of data engineers. We report up through Business Strategy. IT is proposing that the Data Engineers should reside in IT.\n\nWhat are the key advantages or disadvantages of keeping data engineering within the business versus integrating it into the IT department?\n\nYour thoughts and experiences are highly appreciated!", "author_fullname": "t2_jih20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Strategy vs. IT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ye6xm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700336435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seeking insights: &lt;/p&gt;\n\n&lt;p&gt;I manage a data analytics department and a group of data engineers. We report up through Business Strategy. IT is proposing that the Data Engineers should reside in IT.&lt;/p&gt;\n\n&lt;p&gt;What are the key advantages or disadvantages of keeping data engineering within the business versus integrating it into the IT department?&lt;/p&gt;\n\n&lt;p&gt;Your thoughts and experiences are highly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ye6xm", "is_robot_indexable": true, "report_reasons": null, "author": "genghiskhanh", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ye6xm/business_strategy_vs_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ye6xm/business_strategy_vs_it/", "subreddit_subscribers": 140475, "created_utc": 1700336435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://delta-io.github.io/delta-rs/\n\nThis is the documentation for the native Python implementation of Delta Lake. It is based on the delta-rs Rust library and requires no Spark or JVM dependencies. For the PySpark implementation, see delta-spark instead.", "author_fullname": "t2_4da3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Native Python Delta Lake package - No Spark or JVM Dependencies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ymsf4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700360824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://delta-io.github.io/delta-rs/\"&gt;https://delta-io.github.io/delta-rs/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is the documentation for the native Python implementation of Delta Lake. It is based on the delta-rs Rust library and requires no Spark or JVM dependencies. For the PySpark implementation, see delta-spark instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17ymsf4", "is_robot_indexable": true, "report_reasons": null, "author": "keseykid", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ymsf4/native_python_delta_lake_package_no_spark_or_jvm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ymsf4/native_python_delta_lake_package_no_spark_or_jvm/", "subreddit_subscribers": 140475, "created_utc": 1700360824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title is the question, how would you change the mind of someone who is ambivalent?", "author_fullname": "t2_eanzp1mp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you sell the value of Data Engineering at your org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17yy1wp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700403187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title is the question, how would you change the mind of someone who is ambivalent?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17yy1wp", "is_robot_indexable": true, "report_reasons": null, "author": "DesperateForAnalysex", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yy1wp/how_do_you_sell_the_value_of_data_engineering_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yy1wp/how_do_you_sell_the_value_of_data_engineering_at/", "subreddit_subscribers": 140475, "created_utc": 1700403187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this is a bit outside the normal DE domain but I was just wondering if anyone has put together any fun or interesting use cases with Neo4j? I was thinking about putting together a proof-of-concept around SAP materials management but otherwise Neo4j seems quite niche. Thoughts?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any fun / interesting use cases for Neo4j?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yo16g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700364839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is a bit outside the normal DE domain but I was just wondering if anyone has put together any fun or interesting use cases with Neo4j? I was thinking about putting together a proof-of-concept around SAP materials management but otherwise Neo4j seems quite niche. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17yo16g", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yo16g/any_fun_interesting_use_cases_for_neo4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yo16g/any_fun_interesting_use_cases_for_neo4j/", "subreddit_subscribers": 140475, "created_utc": 1700364839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you're trying to get sales data from a third-party sales-tracking tool, and want to populate your own SQL database with it at regular intervals. You want your SQL db to match the third-party tool's database exactly. Maybe you update data that was updated after a certain time-stamp, however that won't help you remove records that were deleted. Some API endpoints have a \"deleted\" table which gives IDs to delete, however some don't and I'm wondering how some of you handle getting rid of deleted records.", "author_fullname": "t2_4ywya5oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strategies for syncing your local database with data fed by a third party API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yi9vf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700347587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you&amp;#39;re trying to get sales data from a third-party sales-tracking tool, and want to populate your own SQL database with it at regular intervals. You want your SQL db to match the third-party tool&amp;#39;s database exactly. Maybe you update data that was updated after a certain time-stamp, however that won&amp;#39;t help you remove records that were deleted. Some API endpoints have a &amp;quot;deleted&amp;quot; table which gives IDs to delete, however some don&amp;#39;t and I&amp;#39;m wondering how some of you handle getting rid of deleted records.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17yi9vf", "is_robot_indexable": true, "report_reasons": null, "author": "LibertyDay", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yi9vf/strategies_for_syncing_your_local_database_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yi9vf/strategies_for_syncing_your_local_database_with/", "subreddit_subscribers": 140475, "created_utc": 1700347587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi, \n\nis it possible to validate the schema when reading json files?\n\n\nschema = StructType([  \n\u00a0 StructField(\"name\", StringType(), False),  \n\u00a0 StructField(\"city\", StringType(), False),  \n])  \ndf = spark.read.format(\"json\").option(\"header\", True).schema(schema).load(\"dbfs:/FileStore/tmp2/part-00000-tid-6160476532014978736-a578e6fa-09e0-4488-a895-93e86779384f-32-1-c000.json\")  \ndf.show()\n\n\n \\+-----+----+ | \n\nname|city| \n\n\\+-----+----+ \n\n|claus|  ny| \n\n\\+-----+----+   \n\n\nThis works as expected. \n\nHowever its still possible to read the json when I remove one field from the schema. When reading the file again it is just ignored. Can I force to check if any additional fields are included in the json file?  \n\n\nschema = StructType([  \n\u00a0 StructField(\"name\", StringType(), False),  \n])  \ndf = spark.read.format(\"json\").option(\"header\", True).schema(schema).load(\"dbfs:/FileStore/tmp2/part-00000-tid-6160476532014978736-a578e6fa-09e0-4488-a895-93e86779384f-32-1-c000.json\")  \ndf.show()\n\n\\`\\`\\`\n\n \\+-----+ \n\n| name| \n\n\\+-----+ |\n\nclaus| \n\n\\+-----+", "author_fullname": "t2_rydqu8m3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validate json on read with pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yeb27", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700336762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;is it possible to validate the schema when reading json files?&lt;/p&gt;\n\n&lt;p&gt;schema = StructType([&lt;br/&gt;\n\u00a0 StructField(&amp;quot;name&amp;quot;, StringType(), False),&lt;br/&gt;\n\u00a0 StructField(&amp;quot;city&amp;quot;, StringType(), False),&lt;br/&gt;\n])&lt;br/&gt;\ndf = spark.read.format(&amp;quot;json&amp;quot;).option(&amp;quot;header&amp;quot;, True).schema(schema).load(&amp;quot;dbfs:/FileStore/tmp2/part-00000-tid-6160476532014978736-a578e6fa-09e0-4488-a895-93e86779384f-32-1-c000.json&amp;quot;)&lt;br/&gt;\ndf.show()&lt;/p&gt;\n\n&lt;p&gt;+-----+----+ | &lt;/p&gt;\n\n&lt;p&gt;name|city| &lt;/p&gt;\n\n&lt;p&gt;+-----+----+ &lt;/p&gt;\n\n&lt;p&gt;|claus|  ny| &lt;/p&gt;\n\n&lt;p&gt;+-----+----+   &lt;/p&gt;\n\n&lt;p&gt;This works as expected. &lt;/p&gt;\n\n&lt;p&gt;However its still possible to read the json when I remove one field from the schema. When reading the file again it is just ignored. Can I force to check if any additional fields are included in the json file?  &lt;/p&gt;\n\n&lt;p&gt;schema = StructType([&lt;br/&gt;\n\u00a0 StructField(&amp;quot;name&amp;quot;, StringType(), False),&lt;br/&gt;\n])&lt;br/&gt;\ndf = spark.read.format(&amp;quot;json&amp;quot;).option(&amp;quot;header&amp;quot;, True).schema(schema).load(&amp;quot;dbfs:/FileStore/tmp2/part-00000-tid-6160476532014978736-a578e6fa-09e0-4488-a895-93e86779384f-32-1-c000.json&amp;quot;)&lt;br/&gt;\ndf.show()&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;+-----+ &lt;/p&gt;\n\n&lt;p&gt;| name| &lt;/p&gt;\n\n&lt;p&gt;+-----+ |&lt;/p&gt;\n\n&lt;p&gt;claus| &lt;/p&gt;\n\n&lt;p&gt;+-----+&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yeb27", "is_robot_indexable": true, "report_reasons": null, "author": "DecisionAgile7326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17yeb27/validate_json_on_read_with_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yeb27/validate_json_on_read_with_pyspark/", "subreddit_subscribers": 140475, "created_utc": 1700336762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, like to ask about the potential and the pitfall for using both the DataFrame method and Spark SQL method (with dbt) simultaneously.\n\nOur current setup is getting the data through streaming (through Kafka; with Hudi streaming solution) and processing it with PySpark. The team built all this with the traditional PySpark DataFrame method for processing transactional records. \n\nNow, we are considering implementing dbt in the process for the new analytics models (and for better governance/lineage, allowing analysts to develop models for BI later on). It sounds good in theory but personally, I have never heard of anyone combining both methods in this way, so I wonder:\n\n1. Is there a best method to include dbt in our current process (My thought is not touching the established pipelines and just adding new dbt actions for BI after the original pipelines finish; basically building a dbt project in the current repo and triggering it after the spark job finishes)\n2. Is there a way to \"include\" the established DataFrame pipeline in the dbt framework without rewriting the whole thing in SQL (for the data lineage and catalog purposes)? I am not sure how UDFs in PySpark work in the dbt framework so don't like to commit to rewriting the whole thing\n\nI would appreciate any suggestions or even examples of similar solutions. Thanks!", "author_fullname": "t2_23fqgpxi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark ETL with both DataFrames and SQL (with dbt)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17yy9d4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700403815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, like to ask about the potential and the pitfall for using both the DataFrame method and Spark SQL method (with dbt) simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Our current setup is getting the data through streaming (through Kafka; with Hudi streaming solution) and processing it with PySpark. The team built all this with the traditional PySpark DataFrame method for processing transactional records. &lt;/p&gt;\n\n&lt;p&gt;Now, we are considering implementing dbt in the process for the new analytics models (and for better governance/lineage, allowing analysts to develop models for BI later on). It sounds good in theory but personally, I have never heard of anyone combining both methods in this way, so I wonder:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a best method to include dbt in our current process (My thought is not touching the established pipelines and just adding new dbt actions for BI after the original pipelines finish; basically building a dbt project in the current repo and triggering it after the spark job finishes)&lt;/li&gt;\n&lt;li&gt;Is there a way to &amp;quot;include&amp;quot; the established DataFrame pipeline in the dbt framework without rewriting the whole thing in SQL (for the data lineage and catalog purposes)? I am not sure how UDFs in PySpark work in the dbt framework so don&amp;#39;t like to commit to rewriting the whole thing&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would appreciate any suggestions or even examples of similar solutions. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yy9d4", "is_robot_indexable": true, "report_reasons": null, "author": "HiIamGeoff", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yy9d4/pyspark_etl_with_both_dataframes_and_sql_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yy9d4/pyspark_etl_with_both_dataframes_and_sql_with_dbt/", "subreddit_subscribers": 140475, "created_utc": 1700403815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As it implies, I'm actually curious here for Data engineers that are in those type of roles that was a college student and applied overseas.\n\n1. Is it actually possible\n2. How hard it is to gain job overseas as your first job as a DE\n3. Is college degree a must?\n4. What learning curve did you use? \n\nso to disclose I'm actually a student from a state university at my second year, I have some development that I created particularly in Mobile and web development, I used java and js, html, css when I was on my senior high school days and currently working for a freelance job using react and nodejs, so web development ain't really my thing, but would do it anyways, I wouldn't say I like nor hate it but I can tell that in developing stuffs it would be the last thing I'd do.\n\nPeople tend to say that having an experience in the role itself is 10x better than having a college degree (tho I won't drop college, it'll still be my edge to land a role better than having none), I want to have a real experience to it, I have been doing some web crawling with an integrated map (Idk if this helps but I suppose it is, in a sense)\n\nI know this could be a subjective topic since not everyone here lives in the same place, I just want some insight about it, and it is better to talk to those people who had actual experience and share it to some people like me who maybe is finding things like this.", "author_fullname": "t2_4zj54s5s0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Job overseas as DE in college?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yct9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700332542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As it implies, I&amp;#39;m actually curious here for Data engineers that are in those type of roles that was a college student and applied overseas.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is it actually possible&lt;/li&gt;\n&lt;li&gt;How hard it is to gain job overseas as your first job as a DE&lt;/li&gt;\n&lt;li&gt;Is college degree a must?&lt;/li&gt;\n&lt;li&gt;What learning curve did you use? &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;so to disclose I&amp;#39;m actually a student from a state university at my second year, I have some development that I created particularly in Mobile and web development, I used java and js, html, css when I was on my senior high school days and currently working for a freelance job using react and nodejs, so web development ain&amp;#39;t really my thing, but would do it anyways, I wouldn&amp;#39;t say I like nor hate it but I can tell that in developing stuffs it would be the last thing I&amp;#39;d do.&lt;/p&gt;\n\n&lt;p&gt;People tend to say that having an experience in the role itself is 10x better than having a college degree (tho I won&amp;#39;t drop college, it&amp;#39;ll still be my edge to land a role better than having none), I want to have a real experience to it, I have been doing some web crawling with an integrated map (Idk if this helps but I suppose it is, in a sense)&lt;/p&gt;\n\n&lt;p&gt;I know this could be a subjective topic since not everyone here lives in the same place, I just want some insight about it, and it is better to talk to those people who had actual experience and share it to some people like me who maybe is finding things like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17yct9c", "is_robot_indexable": true, "report_reasons": null, "author": "AuimiArreis", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yct9c/looking_for_a_job_overseas_as_de_in_college/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yct9c/looking_for_a_job_overseas_as_de_in_college/", "subreddit_subscribers": 140475, "created_utc": 1700332542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Particularly looking at extracting data from Netsuite into EDW.", "author_fullname": "t2_legyu6zou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have any opinions on either Informatica or CData?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yayai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700327359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Particularly looking at extracting data from Netsuite into EDW.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17yayai", "is_robot_indexable": true, "report_reasons": null, "author": "anotherwetsock", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yayai/does_anyone_have_any_opinions_on_either/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yayai/does_anyone_have_any_opinions_on_either/", "subreddit_subscribers": 140475, "created_utc": 1700327359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI just started at a new company using Databricks and I'm kinda new to it. They asked me to define a nomenclature for Catalogs, Databases and Tables given one single use case :/  \n\n\nThe use case is quite simple :\n\nWe have a single raw data source coming from Azure Event Hub, let's call it TRUTH.\n\nUsing this single raw data, we're gonna create multiple silver layer tables which will serve multiple gold layer tables.\n\nBasically it looks like this:\n\nhttps://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;format=png&amp;auto=webp&amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf\n\nGiven the description of Unity Catalog in the official doc :\n\n&gt; Unity Catalog provides centralized access control, auditing, lineage, and data discovery capabilities across Databricks workspaces. \n\nDoes it means that each of the \"Bunch of Gold tables\" should be a Separate Unity Catalog. \n\n* \"Team 1\" for Red\n* \"Team 2\" for Green\n* \"Team 3\" for Blue\n\nIf doing so, I don't see what kind of nomenclature I would have for Databases, I mean each Team's Golden uses multiple silver data, so I can't really have like a silver database and golden database on each unity catalog.\n\nOr should I make like one single unity catalog for the whole use case then make :\n\n1. One Database for the Raw Data, with a single table\n2. One database for the Silver Data, with n silver tables\n3. X databases for the Gold Data, one per team, each database will have Y number of gold tables\n\nCan you let me know what do you think of this two approaches, or maybe suggest some other ?  \nI hope I've explained the problem properly, If not, please don't hesitate to ask me any questions. Thanks !", "author_fullname": "t2_a6b9szlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Design Unity Catalog, Databases and Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": true, "media_metadata": {"5zlj8kmmfb1c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8f7daf248c35146d3cd9b60240f8ab7861287871"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=37e3e940a43786004989a06064679cbc51b802b8"}, {"y": 173, "x": 320, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=87faca5a7f6b0cfcb4940cd16b992db184b2ce55"}, {"y": 346, "x": 640, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=77254c6330af9881644a7920746bf3601090e772"}], "s": {"y": 401, "x": 741, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;format=png&amp;auto=webp&amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf"}, "id": "5zlj8kmmfb1c1"}}, "name": "t3_17yyrio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TSsaipfCcVUB-8gDwmbIBrroO0pBxX9bzbnbSIX2fe0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700405296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I just started at a new company using Databricks and I&amp;#39;m kinda new to it. They asked me to define a nomenclature for Catalogs, Databases and Tables given one single use case :/  &lt;/p&gt;\n\n&lt;p&gt;The use case is quite simple :&lt;/p&gt;\n\n&lt;p&gt;We have a single raw data source coming from Azure Event Hub, let&amp;#39;s call it TRUTH.&lt;/p&gt;\n\n&lt;p&gt;Using this single raw data, we&amp;#39;re gonna create multiple silver layer tables which will serve multiple gold layer tables.&lt;/p&gt;\n\n&lt;p&gt;Basically it looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf\"&gt;https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Given the description of Unity Catalog in the official doc :&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Unity Catalog provides centralized access control, auditing, lineage, and data discovery capabilities across Databricks workspaces. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Does it means that each of the &amp;quot;Bunch of Gold tables&amp;quot; should be a Separate Unity Catalog. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Team 1&amp;quot; for Red&lt;/li&gt;\n&lt;li&gt;&amp;quot;Team 2&amp;quot; for Green&lt;/li&gt;\n&lt;li&gt;&amp;quot;Team 3&amp;quot; for Blue&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If doing so, I don&amp;#39;t see what kind of nomenclature I would have for Databases, I mean each Team&amp;#39;s Golden uses multiple silver data, so I can&amp;#39;t really have like a silver database and golden database on each unity catalog.&lt;/p&gt;\n\n&lt;p&gt;Or should I make like one single unity catalog for the whole use case then make :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;One Database for the Raw Data, with a single table&lt;/li&gt;\n&lt;li&gt;One database for the Silver Data, with n silver tables&lt;/li&gt;\n&lt;li&gt;X databases for the Gold Data, one per team, each database will have Y number of gold tables&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Can you let me know what do you think of this two approaches, or maybe suggest some other ?&lt;br/&gt;\nI hope I&amp;#39;ve explained the problem properly, If not, please don&amp;#39;t hesitate to ask me any questions. Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yyrio", "is_robot_indexable": true, "report_reasons": null, "author": "TheFragan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yyrio/databricks_design_unity_catalog_databases_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yyrio/databricks_design_unity_catalog_databases_and/", "subreddit_subscribers": 140475, "created_utc": 1700405296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm a data scientist who does some contracting on the side.\n\nI'm currently contracting as a credit risk manager at a fintech startup (4m revenue) and I now have the opportunity to review and help develop the data and system architecture of the company, under the guidance of a senior architect.\n\nWhat career opportunities would this open up for me? I heard architects are normally senior devs or data engineers with experience - but I am a data scientist.", "author_fullname": "t2_3w4t0q25", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Architecture as a data scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ykr4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700354587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data scientist who does some contracting on the side.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently contracting as a credit risk manager at a fintech startup (4m revenue) and I now have the opportunity to review and help develop the data and system architecture of the company, under the guidance of a senior architect.&lt;/p&gt;\n\n&lt;p&gt;What career opportunities would this open up for me? I heard architects are normally senior devs or data engineers with experience - but I am a data scientist.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ykr4k", "is_robot_indexable": true, "report_reasons": null, "author": "undecidedx10", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ykr4k/architecture_as_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ykr4k/architecture_as_a_data_scientist/", "subreddit_subscribers": 140475, "created_utc": 1700354587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nDo you have any online course recommendations about : Data lifecycle management?\n\nThank you!", "author_fullname": "t2_9gm8piae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Courses Data lifecycle management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yeyl1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700338640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Do you have any online course recommendations about : Data lifecycle management?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yeyl1", "is_robot_indexable": true, "report_reasons": null, "author": "Mya123456", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yeyl1/courses_data_lifecycle_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yeyl1/courses_data_lifecycle_management/", "subreddit_subscribers": 140475, "created_utc": 1700338640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All!\n\nI am an upcoming data engineer trying to set up Airflow for my team. Our objective is mainly to orchestrate already on going pipelines, containerize them and have visibility on what is going on. \n\nI have looked at a couple of options, and to avoid having to do any docker-to-docker conflicts, I decided to go for the kubernetes route. But I want to avoid having to spend 70$+ per month on setting up a system for small tasks. \n\nHence my question, would minikube be alright for those small tasks? Our loads are small. There is no mission-critical tasks that cannot be run some time later if they fail. \n\nAny experiences with hosting your own small prod environments in minikube?", "author_fullname": "t2_o5sdswgng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minikube + Airflow for small production environment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y9jx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700323327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All!&lt;/p&gt;\n\n&lt;p&gt;I am an upcoming data engineer trying to set up Airflow for my team. Our objective is mainly to orchestrate already on going pipelines, containerize them and have visibility on what is going on. &lt;/p&gt;\n\n&lt;p&gt;I have looked at a couple of options, and to avoid having to do any docker-to-docker conflicts, I decided to go for the kubernetes route. But I want to avoid having to spend 70$+ per month on setting up a system for small tasks. &lt;/p&gt;\n\n&lt;p&gt;Hence my question, would minikube be alright for those small tasks? Our loads are small. There is no mission-critical tasks that cannot be run some time later if they fail. &lt;/p&gt;\n\n&lt;p&gt;Any experiences with hosting your own small prod environments in minikube?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y9jx3", "is_robot_indexable": true, "report_reasons": null, "author": "TostGushMuts", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y9jx3/minikube_airflow_for_small_production_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y9jx3/minikube_airflow_for_small_production_environment/", "subreddit_subscribers": 140475, "created_utc": 1700323327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been data engineering adjacent for years, primarily working with Oracle and programming data conversions and analytics for a sought out fintech platform. I have a couple of employment opportunities right now. The one I\u2019m in now wants to extend my contract and when the bulk of the project work winds down hire me as a data engineer. I\u2019m getting hands on experience in databricks, python, ADF, Azure, etc. I currently have very strong pl/sql and sql skills. I\u2019m also good at optimizing db code.\n\nThere is a big 3 firm that wants to contract with me doing my old data programming job at 2x my previous pay rate (I\u2019m currently in the middle right now) but it\u2019s doing what I always done - oracle, 2nd Gen Core, limited. After that contract ends I should have enough money to take a few months off and focus on training, but something is telling me staying put leaning to tools I\u2019m learning now would be better for the long run.\n\nWhat is better, staying put getting hands on experience with cloud and data engineering tools or moving, having a big 3 on my resume, getting paid over $100 an hour, but staying in old school oracle land?", "author_fullname": "t2_4dl7aahw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s better Self Study or Hands on Exp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y9i1u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700323200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been data engineering adjacent for years, primarily working with Oracle and programming data conversions and analytics for a sought out fintech platform. I have a couple of employment opportunities right now. The one I\u2019m in now wants to extend my contract and when the bulk of the project work winds down hire me as a data engineer. I\u2019m getting hands on experience in databricks, python, ADF, Azure, etc. I currently have very strong pl/sql and sql skills. I\u2019m also good at optimizing db code.&lt;/p&gt;\n\n&lt;p&gt;There is a big 3 firm that wants to contract with me doing my old data programming job at 2x my previous pay rate (I\u2019m currently in the middle right now) but it\u2019s doing what I always done - oracle, 2nd Gen Core, limited. After that contract ends I should have enough money to take a few months off and focus on training, but something is telling me staying put leaning to tools I\u2019m learning now would be better for the long run.&lt;/p&gt;\n\n&lt;p&gt;What is better, staying put getting hands on experience with cloud and data engineering tools or moving, having a big 3 on my resume, getting paid over $100 an hour, but staying in old school oracle land?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17y9i1u", "is_robot_indexable": true, "report_reasons": null, "author": "Zestyclose-Height-59", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y9i1u/whats_better_self_study_or_hands_on_exp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y9i1u/whats_better_self_study_or_hands_on_exp/", "subreddit_subscribers": 140475, "created_utc": 1700323200.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}