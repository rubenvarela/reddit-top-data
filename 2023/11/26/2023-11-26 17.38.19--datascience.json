{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "REMOTE Data Scientist Requirements/Responsibilities \n\n*MUST be a USC or Green Card Holder. NO C2C* \n\n- Exploring new analytical technologies and evaluate their technical and commercial viability. \n\n- Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools. \n\n- Working across various data mediums: text, audio, imagery, sensory, and structured data. \n\n- Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients. \n\n- Testing and rejecting hypotheses around data processing and ML model building. \n\n- Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task. \n\n- Building ML pipelines that ingest, clean data, and make predictions. \n\n- Focusing on AI and ML techniques that are broadly applicable across all industries. \n\n- Staying abreast of new AI research from leading labs by reading papers and experimenting with code. \n\n- Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients. \n\n- Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.). \n\n- Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique. \n\n- Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow). \n\n- Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application. \n\n- Building ML models and systems, interpreting their output, and communicating the results. \n\n- Moving models from development to production; conducting lab research and publishing work. \n\n- Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:\n\n- Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix. \n\n- Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.). \n\n- Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow. \n\n- Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy. \n\n- Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots &amp; Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS. \n\n- Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio). \n\n- Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS. \n\n- Minimum Degree Required: Bachelor Degree. \n\n- Additional Educational Requirements: Bachelor's degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college. \n\n- Degree Preferred: Master Degree. \n\n- Preferred Fields of Study: Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research. \n\n- Additional Educational Preferences: PhD highly preferred.\n\n&amp;nbsp;\n\nI found this on Linkedin, I don't understand how something like this is even remotely okay", "author_fullname": "t2_fb4ll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worst JD of the year", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183p9u1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700934703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;REMOTE Data Scientist Requirements/Responsibilities &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;MUST be a USC or Green Card Holder. NO C2C&lt;/em&gt; &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Exploring new analytical technologies and evaluate their technical and commercial viability. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Working across entire pipeline: data ingestion, feature engineering, ML model development, visualization of results, and packaging solutions into applications/production ready tools. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Working across various data mediums: text, audio, imagery, sensory, and structured data. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Working in (6) 2-week sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Testing and rejecting hypotheses around data processing and ML model building. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Experimenting, fail quickly, and recognize when you need assistance vs. concluding a technology is not suitable for the task. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Building ML pipelines that ingest, clean data, and make predictions. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Focusing on AI and ML techniques that are broadly applicable across all industries. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Staying abreast of new AI research from leading labs by reading papers and experimenting with code. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Developing innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Applying ML techniques to address a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.). &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Understanding ML algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Understanding open-source deep learning frameworks (PyTorch, Keras, Tensorflow). &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Understanding text pre-processing and normalization techniques, such as tokenization, POS tagging and knowledge of Named Entity Extraction, Document Classification, Topic Modeling, Text summarization and concepts behind application. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Building ML models and systems, interpreting their output, and communicating the results. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Moving models from development to production; conducting lab research and publishing work. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrates thorough abilities and/or a proven record of success in the Essential 8: AI, Blockchain, Augmented Reality, Drones, IoT, Robotics, Virtual Reality and 3D printing in addition to:&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Programming languages: Python, R, Java, JavaScript, C++, Unix. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Data Storage Technologies: SQL, NoSQL, Postgres, Neo4j, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.). &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Data Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Machine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in NLU/NLP domain: Sentiment Analysis, Chatbots &amp;amp; Virtual Assistants, Text Classification, Text Extraction, Machine Translation, Text Summarization, Intent Classification, Speech Recognition, STT, TTS. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in Visualization tools: Python (Matplotlib, Seaborn, bokeh, etc.), JavaScript (d3), third party libraries (Power BI, Tableau, Data Studio). &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Demonstrating knowledge in productionization and containerization technologies: GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Minimum Degree Required: Bachelor Degree. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Additional Educational Requirements: Bachelor&amp;#39;s degree or in lieu of a degree, demonstrating, in addition to the minimum years of experience required for the role, three years of specialized training and/or progressively responsible work experience in technology for each missing year of college. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Degree Preferred: Master Degree. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Preferred Fields of Study: Computer and Information Science, Mathematics, Computer Engineering, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Economics, Operations Management/Research. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Additional Educational Preferences: PhD highly preferred.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I found this on Linkedin, I don&amp;#39;t understand how something like this is even remotely okay&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "183p9u1", "is_robot_indexable": true, "report_reasons": null, "author": "PLxFTW", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183p9u1/worst_jd_of_the_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183p9u1/worst_jd_of_the_year/", "subreddit_subscribers": 1149532, "created_utc": 1700934703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.  \n\nBut the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I'm sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn't really build the thing yourself.  \n\n\nLooking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!", "author_fullname": "t2_9bow4eln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change my mind: AI is inherently public domain knowledge and should not be commercialized", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183uo20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700949444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.  &lt;/p&gt;\n\n&lt;p&gt;But the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I&amp;#39;m sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn&amp;#39;t really build the thing yourself.  &lt;/p&gt;\n\n&lt;p&gt;Looking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "183uo20", "is_robot_indexable": true, "report_reasons": null, "author": "Unhappy_Technician68", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/", "subreddit_subscribers": 1149532, "created_utc": 1700949444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! \n\nCurious as to what industry has the best (work-life balance)/(compensation) ratio. \n\n1. Work hours/week\n2. Compensation\n3. Job security", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working in which industry has a better work-life balance/pay ratio: Finance or Big Tech?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183vc1k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700955599.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700951243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;Curious as to what industry has the best (work-life balance)/(compensation) ratio. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Work hours/week&lt;/li&gt;\n&lt;li&gt;Compensation&lt;/li&gt;\n&lt;li&gt;Job security&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "183vc1k", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/", "subreddit_subscribers": 1149532, "created_utc": 1700951243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven\u2019t use it before, is it viable?", "author_fullname": "t2_t4026fbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP for dirty data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1843m38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700976808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven\u2019t use it before, is it viable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1843m38", "is_robot_indexable": true, "report_reasons": null, "author": "chris_813", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1843m38/nlp_for_dirty_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1843m38/nlp_for_dirty_data/", "subreddit_subscribers": 1149532, "created_utc": 1700976808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.\n\nThe way the model is set up is the following:\n\nFirstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven't come back in a while rather than those that are buying stuff regularly. However, I haven't given this issue much thought, yet, because I focusing on other aspects.\n\nSecondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn't really improve the model and hence, I decided to not include it for now.\n\nThirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn't really think of much on how to deal with that issue and would like to hear how you would approach this.\n\nLastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. \n\nSo, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?\n\nMany thanks in advance and I am curious to hear what you guys think about this project.", "author_fullname": "t2_8xlmglbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail based recommendation system - Setup and how to deal with severe class imbalance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18488s8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700996066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.&lt;/p&gt;\n\n&lt;p&gt;The way the model is set up is the following:&lt;/p&gt;\n\n&lt;p&gt;Firstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven&amp;#39;t come back in a while rather than those that are buying stuff regularly. However, I haven&amp;#39;t given this issue much thought, yet, because I focusing on other aspects.&lt;/p&gt;\n\n&lt;p&gt;Secondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn&amp;#39;t really improve the model and hence, I decided to not include it for now.&lt;/p&gt;\n\n&lt;p&gt;Thirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn&amp;#39;t really think of much on how to deal with that issue and would like to hear how you would approach this.&lt;/p&gt;\n\n&lt;p&gt;Lastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. &lt;/p&gt;\n\n&lt;p&gt;So, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance and I am curious to hear what you guys think about this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "18488s8", "is_robot_indexable": true, "report_reasons": null, "author": "vossiplayz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/", "subreddit_subscribers": 1149532, "created_utc": 1700996066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been asked by my boss to submit a budget for learning. \n\nI am looking for course ideas that actually add value. \n\nI am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :\n\n1) telling better stories (how I feedback analyse to the business )\n2) insight in operational parts of the business especially product managers and product marketing managers\n3) strategic insights (why is what I present important to the business ) \n\nI feel these are linked but curious on this communities experience. \n\nI am looking at doing an MBA but will only do that in a few years.", "author_fullname": "t2_2sbgb66v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1847uj1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700994395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been asked by my boss to submit a budget for learning. &lt;/p&gt;\n\n&lt;p&gt;I am looking for course ideas that actually add value. &lt;/p&gt;\n\n&lt;p&gt;I am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :&lt;/p&gt;\n\n&lt;p&gt;1) telling better stories (how I feedback analyse to the business )\n2) insight in operational parts of the business especially product managers and product marketing managers\n3) strategic insights (why is what I present important to the business ) &lt;/p&gt;\n\n&lt;p&gt;I feel these are linked but curious on this communities experience. &lt;/p&gt;\n\n&lt;p&gt;I am looking at doing an MBA but will only do that in a few years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1847uj1", "is_robot_indexable": true, "report_reasons": null, "author": "oryx_za", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1847uj1/learning_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1847uj1/learning_opportunities/", "subreddit_subscribers": 1149532, "created_utc": 1700994395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I\u2019m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you had to list a \u201ctier list\u201d of software that data scientists should be competent with prior to their first job, what would it be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_184ezlq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701017549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I\u2019m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "184ezlq", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/", "subreddit_subscribers": 1149532, "created_utc": 1701017549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there!\n\nLast year I tried running a large BERT model on my notebook. It only has a Nvidia GTX 1050 4GB so naturally I was expecting the poor guy to struggle with it. However, I couldn't even run the thing because it didn't had enough VRAM to do it.\n\nSo I just used google colab and in the ocasions I had to use an LLM I went straight there, never worrying about VRAM. I remember reading that at least 12GB of VRAM was necessary to run the large BERT model, ideally much more than that.\n\nHowever, time has passed, we have LLAMA 2 now, GPUs got more advanced etc etc. I was wondering what is the state of the art on this right now. Is it possible to run a good model on a RTX 4070 (8GB)? Or does the 12gb threshold still persists? I know there are notebooks out there with 12\\~16GB VRAM, but they are crazy expensive so I was wondering most about the intermediate ones.\n\nThanks!", "author_fullname": "t2_91ysx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are modern notebooks able to easily run LLMs locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1843i05", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700976403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;Last year I tried running a large BERT model on my notebook. It only has a Nvidia GTX 1050 4GB so naturally I was expecting the poor guy to struggle with it. However, I couldn&amp;#39;t even run the thing because it didn&amp;#39;t had enough VRAM to do it.&lt;/p&gt;\n\n&lt;p&gt;So I just used google colab and in the ocasions I had to use an LLM I went straight there, never worrying about VRAM. I remember reading that at least 12GB of VRAM was necessary to run the large BERT model, ideally much more than that.&lt;/p&gt;\n\n&lt;p&gt;However, time has passed, we have LLAMA 2 now, GPUs got more advanced etc etc. I was wondering what is the state of the art on this right now. Is it possible to run a good model on a RTX 4070 (8GB)? Or does the 12gb threshold still persists? I know there are notebooks out there with 12~16GB VRAM, but they are crazy expensive so I was wondering most about the intermediate ones.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1843i05", "is_robot_indexable": true, "report_reasons": null, "author": "JCoelho", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1843i05/are_modern_notebooks_able_to_easily_run_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1843i05/are_modern_notebooks_able_to_easily_run_llms/", "subreddit_subscribers": 1149532, "created_utc": 1700976403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I ran across this reel in Instagram of a one of those \"finance gurus\" that said something like:\n\n&gt; If you invest $1,500 per month with this bond scheme, after 20 years, you end up with $1,000,000.\n\nwhich I thought \"meh, it's not that much\", just the principal or capital is $360K ($1,500 for 240 months).\n\nBut then I thought, it doesn't seem like A HUGE return, but what is it?\n\n**What is the monthly return in that case?**\n\n(Assuming you reinvest all the proceedings and consistently add $1,500 on top every month).\n\nCan you solve it? It's not that hard, and it's not that \"Data Science\" (although I did end up using some Python and Fortran to solve it), but it's a fun brain teaser. I can post the solution later if you want.\n\nEDIT: I\u2019m getting downvoted into oblivion. I thought you guys would enjoy a fun challenge \ud83e\udd72.\n\nEDIT: there\u2019s a perfectly reasonable way to come up with the correct answer using math and without brute force.", "author_fullname": "t2_782al", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Silly problem I ran into today in an Instagram reel, can you solve it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183qz8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.23, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Challenges", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700950177.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700939333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran across this reel in Instagram of a one of those &amp;quot;finance gurus&amp;quot; that said something like:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If you invest $1,500 per month with this bond scheme, after 20 years, you end up with $1,000,000.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;which I thought &amp;quot;meh, it&amp;#39;s not that much&amp;quot;, just the principal or capital is $360K ($1,500 for 240 months).&lt;/p&gt;\n\n&lt;p&gt;But then I thought, it doesn&amp;#39;t seem like A HUGE return, but what is it?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is the monthly return in that case?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;(Assuming you reinvest all the proceedings and consistently add $1,500 on top every month).&lt;/p&gt;\n\n&lt;p&gt;Can you solve it? It&amp;#39;s not that hard, and it&amp;#39;s not that &amp;quot;Data Science&amp;quot; (although I did end up using some Python and Fortran to solve it), but it&amp;#39;s a fun brain teaser. I can post the solution later if you want.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I\u2019m getting downvoted into oblivion. I thought you guys would enjoy a fun challenge \ud83e\udd72.&lt;/p&gt;\n\n&lt;p&gt;EDIT: there\u2019s a perfectly reasonable way to come up with the correct answer using math and without brute force.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "417296a0-70eb-11ee-8c58-122e95e91c4c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffd635", "id": "183qz8o", "is_robot_indexable": true, "report_reasons": null, "author": "santiagobasulto", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183qz8o/silly_problem_i_ran_into_today_in_an_instagram/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183qz8o/silly_problem_i_ran_into_today_in_an_instagram/", "subreddit_subscribers": 1149532, "created_utc": 1700939333.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}