{"kind": "Listing", "data": {"after": null, "dist": 7, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.  \n\nBut the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I'm sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn't really build the thing yourself.  \n\n\nLooking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!", "author_fullname": "t2_9bow4eln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Change my mind: AI is inherently public domain knowledge and should not be commercialized", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183uo20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700949444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want to start out by saying that AI is an incredibly useful, arguably fundamental tool.  LLMs have an amazing potential to aid in productivity, I really feel that AI is going to make personalized healthcare a possibility and there are of course many as of yet undiscovered applications.  We need AI in our lives and it can make the world a better place.  &lt;/p&gt;\n\n&lt;p&gt;But the scale of data required to train these things necessitates using publicly available data which no one can claim to have developed or collected themselves.  If a company has sales data and it trains AI on that data which they colected and organized, then yes they can claim this is an IP they themselves made and developed.  But we all know these models are of limited generalizability.  And when we think of training say an AI to predict which drug is going to treat a person cancer based on the genotyping of a tumor sample there is simply no way an private enterprise would be able to collect and collate the data needed for that sort of discovery.  It needs to be open access, you can commercialize certain aspects and applications I&amp;#39;m sure.  Like compounds discovered using the model, if you used it to develop those compounds.  But the core model needs to be not for profit and withholding that model past a certain point is harmful to society at large and unjust considering you didn&amp;#39;t really build the thing yourself.  &lt;/p&gt;\n\n&lt;p&gt;Looking forward to counter arguments, refinement of my logic, and healthy discussion.  Be civil lets have a fun talk if you have any thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "183uo20", "is_robot_indexable": true, "report_reasons": null, "author": "Unhappy_Technician68", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183uo20/change_my_mind_ai_is_inherently_public_domain/", "subreddit_subscribers": 1149798, "created_utc": 1700949444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! \n\nCurious as to what industry has the best (work-life balance)/(compensation) ratio. \n\n1. Work hours/week\n2. Compensation\n3. Job security", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working in which industry has a better work-life balance/pay ratio: Finance or Big Tech?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183vc1k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700955599.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700951243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;Curious as to what industry has the best (work-life balance)/(compensation) ratio. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Work hours/week&lt;/li&gt;\n&lt;li&gt;Compensation&lt;/li&gt;\n&lt;li&gt;Job security&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "183vc1k", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/183vc1k/working_in_which_industry_has_a_better_worklife/", "subreddit_subscribers": 1149798, "created_utc": 1700951243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I\u2019m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you had to list a \u201ctier list\u201d of software that data scientists should be competent with prior to their first job, what would it be?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184ezlq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701017549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;May or may not be asking this so I can aggregate courses for me to learn/upskill. But basically I feel like being the R/SQL/Python guy I\u2019m missing out on a lot of other tools and tech. Give me a list of more tools I should know as an incoming data scientist. Cloud platforms? Git? Docker? List anything and everything you would hope a data scientist should be good to pickup or know before starting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "184ezlq", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/184ezlq/if_you_had_to_list_a_tier_list_of_software_that/", "subreddit_subscribers": 1149798, "created_utc": 1701017549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven\u2019t use it before, is it viable?", "author_fullname": "t2_t4026fbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP for dirty data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1843m38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700976808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have tons of addresses from clients, I want to use geo coding to get all those clients mapped, but addresses are dirty with incomplete words so I was wondering if NLP could improve this. I haven\u2019t use it before, is it viable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "1843m38", "is_robot_indexable": true, "report_reasons": null, "author": "chris_813", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1843m38/nlp_for_dirty_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1843m38/nlp_for_dirty_data/", "subreddit_subscribers": 1149798, "created_utc": 1700976808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.\n\nThe way the model is set up is the following:\n\nFirstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven't come back in a while rather than those that are buying stuff regularly. However, I haven't given this issue much thought, yet, because I focusing on other aspects.\n\nSecondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn't really improve the model and hence, I decided to not include it for now.\n\nThirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn't really think of much on how to deal with that issue and would like to hear how you would approach this.\n\nLastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. \n\nSo, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?\n\nMany thanks in advance and I am curious to hear what you guys think about this project.", "author_fullname": "t2_8xlmglbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retail based recommendation system - Setup and how to deal with severe class imbalance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18488s8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700996066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently took on a project where I am supposed to build a recommendation system which recommends clothes/shoes to customers based on their purchase history. I am relatively new to this field and would like to get some feedback regarding the choices made, learn how others would have approached this, and how to deal with severe class imbalance.&lt;/p&gt;\n\n&lt;p&gt;The way the model is set up is the following:&lt;/p&gt;\n\n&lt;p&gt;Firstly, I decided to only concentrate on customers who made one or most purchases in the past 90 days to reduce complexity and respect seasonality. In the future I would like to include more customers, as this reduces the customers a prediction is provided for by 2/3 and I think there is probably great value in trying to reach customers that haven&amp;#39;t come back in a while rather than those that are buying stuff regularly. However, I haven&amp;#39;t given this issue much thought, yet, because I focusing on other aspects.&lt;/p&gt;\n\n&lt;p&gt;Secondly, I generate possible candidates per customers by checking what they have previously purchased, bestsellers by gender and type of product, and similarities between users/product characteristics. Additionally, I tried the Tensorflow Recommenders library, but it didn&amp;#39;t really improve the model and hence, I decided to not include it for now.&lt;/p&gt;\n\n&lt;p&gt;Thirdly, I use a LightGBM Ranker to sort these lists by customer. Moreover, the data is split into train and test sets. Each set consists of 4 months, where the most recent month provides the ground truth and the previous three months are used for the retrieval generation. However, this is where the biggest issues arise. There is extremely severe class imbalance because relevance is evaluated solely based on customers who made at least one purchase in the three months, where the retrieval is based on, and who made at least one purchase in the most recent month. This leads to the model overemphasising on very very few articles that appear to be relevant. Due to the class imbalance most products appear not to be relevant given that simply not enough customers purchase items frequently. Additionally, the performance metrics such as MAP@k are also highly skewed because they are based on such few people. I couldn&amp;#39;t really think of much on how to deal with that issue and would like to hear how you would approach this.&lt;/p&gt;\n\n&lt;p&gt;Lastly, I apply several filters to remedy some minor issues. For example, the model focuses more on quantity rather than revenue generated from an item. Therefore, socks and underwear are suggested often by the model because they are simply purchased a bunch. Currently, I am just removing items of category socks/underwear in excess of a given threshold. For the future, I am thinking about fixing this by including weights that are inversely related to the quantity purchased and directly to the price. &lt;/p&gt;\n\n&lt;p&gt;So, what do you think about my general approach? Do you see any major flaws in my thinking? And how do you think I should deal with the enormous class imbalance that leads to overemphasising on very few products?&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance and I am curious to hear what you guys think about this project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "18488s8", "is_robot_indexable": true, "report_reasons": null, "author": "vossiplayz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18488s8/retail_based_recommendation_system_setup_and_how/", "subreddit_subscribers": 1149798, "created_utc": 1700996066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been asked by my boss to submit a budget for learning. \n\nI am looking for course ideas that actually add value. \n\nI am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :\n\n1) telling better stories (how I feedback analyse to the business )\n2) insight in operational parts of the business especially product managers and product marketing managers\n3) strategic insights (why is what I present important to the business ) \n\nI feel these are linked but curious on this communities experience. \n\nI am looking at doing an MBA but will only do that in a few years.", "author_fullname": "t2_2sbgb66v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1847uj1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700994395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been asked by my boss to submit a budget for learning. &lt;/p&gt;\n\n&lt;p&gt;I am looking for course ideas that actually add value. &lt;/p&gt;\n\n&lt;p&gt;I am ok on the technical side. There is plenty on the stack we work with. I am thinking more regarding the soft and/or business side. The areas I think I need to improve in are :&lt;/p&gt;\n\n&lt;p&gt;1) telling better stories (how I feedback analyse to the business )\n2) insight in operational parts of the business especially product managers and product marketing managers\n3) strategic insights (why is what I present important to the business ) &lt;/p&gt;\n\n&lt;p&gt;I feel these are linked but curious on this communities experience. &lt;/p&gt;\n\n&lt;p&gt;I am looking at doing an MBA but will only do that in a few years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1847uj1", "is_robot_indexable": true, "report_reasons": null, "author": "oryx_za", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1847uj1/learning_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1847uj1/learning_opportunities/", "subreddit_subscribers": 1149798, "created_utc": 1700994395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there!\n\nLast year I tried running a large BERT model on my notebook. It only has a Nvidia GTX 1050 4GB so naturally I was expecting the poor guy to struggle with it. However, I couldn't even run the thing because it didn't had enough VRAM to do it.\n\nSo I just used google colab and in the ocasions I had to use an LLM I went straight there, never worrying about VRAM. I remember reading that at least 12GB of VRAM was necessary to run the large BERT model, ideally much more than that.\n\nHowever, time has passed, we have LLAMA 2 now, GPUs got more advanced etc etc. I was wondering what is the state of the art on this right now. Is it possible to run a good model on a RTX 4070 (8GB)? Or does the 12gb threshold still persists? I know there are notebooks out there with 12\\~16GB VRAM, but they are crazy expensive so I was wondering most about the intermediate ones.\n\nThanks!", "author_fullname": "t2_91ysx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are modern notebooks able to easily run LLMs locally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1843i05", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700976403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there!&lt;/p&gt;\n\n&lt;p&gt;Last year I tried running a large BERT model on my notebook. It only has a Nvidia GTX 1050 4GB so naturally I was expecting the poor guy to struggle with it. However, I couldn&amp;#39;t even run the thing because it didn&amp;#39;t had enough VRAM to do it.&lt;/p&gt;\n\n&lt;p&gt;So I just used google colab and in the ocasions I had to use an LLM I went straight there, never worrying about VRAM. I remember reading that at least 12GB of VRAM was necessary to run the large BERT model, ideally much more than that.&lt;/p&gt;\n\n&lt;p&gt;However, time has passed, we have LLAMA 2 now, GPUs got more advanced etc etc. I was wondering what is the state of the art on this right now. Is it possible to run a good model on a RTX 4070 (8GB)? Or does the 12gb threshold still persists? I know there are notebooks out there with 12~16GB VRAM, but they are crazy expensive so I was wondering most about the intermediate ones.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "1843i05", "is_robot_indexable": true, "report_reasons": null, "author": "JCoelho", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1843i05/are_modern_notebooks_able_to_easily_run_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1843i05/are_modern_notebooks_able_to_easily_run_llms/", "subreddit_subscribers": 1149798, "created_utc": 1700976403.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}