{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dnf1ebcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oldcoderguy - The World\u2019s Most Secure Data Warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_183hgs2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 41, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFNB-Y1-bLs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The World&amp;#39;s Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The World's Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFNB-Y1-bLs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The World&amp;#39;s Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from\"&gt;&lt;/iframe&gt;", "author_name": "OldCoderGuy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zFNB-Y1-bLs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@oldcoderguy"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFNB-Y1-bLs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The World&amp;#39;s Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/183hgs2", "height": 200}, "link_flair_text": "Meme", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rl9MTYsoyoBU1z-I0GkQ7y-WrqnAL8c11Ofod8Fpkts.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700910320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/zFNB-Y1-bLs?si=8klUbx516LZQzfqa", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vot8pxO0tcvBBYYSfV9R2z9dWtKPU-LNa-E1C0xxqjo.jpg?auto=webp&amp;s=fec6c542511f7bfd49fbbf136d139917cdc8e4a9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/vot8pxO0tcvBBYYSfV9R2z9dWtKPU-LNa-E1C0xxqjo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0b81bcc9a0324b726808c3c2a8be9d8d8ca474ec", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/vot8pxO0tcvBBYYSfV9R2z9dWtKPU-LNa-E1C0xxqjo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=abd7121cd83acf81a021a964aee426c0ae8bfddc", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/vot8pxO0tcvBBYYSfV9R2z9dWtKPU-LNa-E1C0xxqjo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f51b0ed31a9e49e295ecd775349d68bb7c75c7b", "width": 320, "height": 240}], "variants": {}, "id": "Z5EYsiMJGCt_8vHttO6ALjOo5E0IB4n8ojbmTxS4MfM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "183hgs2", "is_robot_indexable": true, "report_reasons": null, "author": "Background-Head9233", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/183hgs2/oldcoderguy_the_worlds_most_secure_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/zFNB-Y1-bLs?si=8klUbx516LZQzfqa", "subreddit_subscribers": 141727, "created_utc": 1700910320.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The World's Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFNB-Y1-bLs?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The World&amp;#39;s Most Secure Data Warehouse. #sql #dataengineer #programmerhumor #from\"&gt;&lt;/iframe&gt;", "author_name": "OldCoderGuy", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zFNB-Y1-bLs/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@oldcoderguy"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The process of purchasing software sucks. It feels like the vendors do everything in their power to make it difficult to find honest opinions/information/benchmarks about their products, and once you do narrow down your options, dealing with sales teams is miserable. \n\nI want to do something about it. I'd like to create a product that simplifies the process for purchasing data/analytics software, and I'm in need of your help to determine where to start.\n\nI think that the buying process breaks down into the following steps. I'd love to hear your thoughts on which are the most frustrating and why.\n\n1. Pre-purchase: Identifying software needs\n2. Pre-purchase: Narrowing options down from many to few (usually done via online research)\n3. Pre-purchase: Narrowing options down from few to one (usually done via hands-on evaluation)\n4. Pre-purchase: Negotiating favorable contracts\n5. Post-purchase: Ensuring seamless integration\n6. Post-purchase: Continuous monitoring and evaluation of software performance\n7. Post-purchase: Vendor contract management (spending trends, renewals, etc)\n8. Post-purchase: Vendor product management (new product announcements, new use cases)\n\nIf you'd like to contribute to a solution anonymously or just not on this thread, you can also submit your opinion [here](https://app.opinionx.co/9ce9b84f-8acf-4192-9970-fd0a395f1a5b).\n\nThank you for your help!", "author_fullname": "t2_hq4hf0y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Does Buying Software Suck So Much?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183rcpc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700940354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The process of purchasing software sucks. It feels like the vendors do everything in their power to make it difficult to find honest opinions/information/benchmarks about their products, and once you do narrow down your options, dealing with sales teams is miserable. &lt;/p&gt;\n\n&lt;p&gt;I want to do something about it. I&amp;#39;d like to create a product that simplifies the process for purchasing data/analytics software, and I&amp;#39;m in need of your help to determine where to start.&lt;/p&gt;\n\n&lt;p&gt;I think that the buying process breaks down into the following steps. I&amp;#39;d love to hear your thoughts on which are the most frustrating and why.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Pre-purchase: Identifying software needs&lt;/li&gt;\n&lt;li&gt;Pre-purchase: Narrowing options down from many to few (usually done via online research)&lt;/li&gt;\n&lt;li&gt;Pre-purchase: Narrowing options down from few to one (usually done via hands-on evaluation)&lt;/li&gt;\n&lt;li&gt;Pre-purchase: Negotiating favorable contracts&lt;/li&gt;\n&lt;li&gt;Post-purchase: Ensuring seamless integration&lt;/li&gt;\n&lt;li&gt;Post-purchase: Continuous monitoring and evaluation of software performance&lt;/li&gt;\n&lt;li&gt;Post-purchase: Vendor contract management (spending trends, renewals, etc)&lt;/li&gt;\n&lt;li&gt;Post-purchase: Vendor product management (new product announcements, new use cases)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If you&amp;#39;d like to contribute to a solution anonymously or just not on this thread, you can also submit your opinion &lt;a href=\"https://app.opinionx.co/9ce9b84f-8acf-4192-9970-fd0a395f1a5b\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?auto=webp&amp;s=a0093b74d2331520919904fa0854dfa6d7294848", "width": 4000, "height": 2250}, "resolutions": [{"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc137392f3433bf65ca44348e576ac9e6f97ee3d", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d50faf599b6a31ae115080056db4f22c222c618", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca8c01abd9d0843176890da3251ef1775734e9fb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8187c3d6e2cc7ca7dec8c53cd73196cd4c6ec899", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9c483a3bdf05d307b7cb9856e58a9eb679b86996", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/rDnzrkh8TJi0BFObICODhHJ9QZ6jPfSixlkTjtNvTEE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14e95129553aafe7543c738f46054c68b77c644c", "width": 1080, "height": 607}], "variants": {}, "id": "5T8E-gRyPMVj6I0Ovk5cza07au56LoGbvCjSZR9FQXw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "183rcpc", "is_robot_indexable": true, "report_reasons": null, "author": "Dizzy_Fruit5948", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/183rcpc/why_does_buying_software_suck_so_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/183rcpc/why_does_buying_software_suck_so_much/", "subreddit_subscribers": 141727, "created_utc": 1700940354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As per post title. Anything from macros to project config. Keen to hear and learn.", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What DBT hacks do you wish you knew sooner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18420vg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700971236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As per post title. Anything from macros to project config. Keen to hear and learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18420vg", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18420vg/what_dbt_hacks_do_you_wish_you_knew_sooner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18420vg/what_dbt_hacks_do_you_wish_you_knew_sooner/", "subreddit_subscribers": 141727, "created_utc": 1700971236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I uploaded a Python Pandas course on YouTube. I covered the introduction and installation of pandas, series and series operations, dataframes and basic dataframe creation, creating dataframes from various file formats, dataframe operations, identifying and handling missing data, data manipulation using loc and iloc, sorting and ranking data, combining and merging dataframes, data cleaning techniques, handling categorical data, data transformation techniques, handling date and time data, group by operations, aggregating data using functions, time series data visualization, advanced data manipulation techniques (apply, map, and apply map), data visualization with pandas tools, working with multi-index dataframes and text manipulation methods topics. I am leaving the course link below, have a great day!\n\n[https://www.youtube.com/watch?v=KvFZf3cL\\_IY](https://www.youtube.com/watch?v=KvFZf3cL_IY)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I shared a Python Pandas course (1.5 Hrs) on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183qx2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700939168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I uploaded a Python Pandas course on YouTube. I covered the introduction and installation of pandas, series and series operations, dataframes and basic dataframe creation, creating dataframes from various file formats, dataframe operations, identifying and handling missing data, data manipulation using loc and iloc, sorting and ranking data, combining and merging dataframes, data cleaning techniques, handling categorical data, data transformation techniques, handling date and time data, group by operations, aggregating data using functions, time series data visualization, advanced data manipulation techniques (apply, map, and apply map), data visualization with pandas tools, working with multi-index dataframes and text manipulation methods topics. I am leaving the course link below, have a great day!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=KvFZf3cL_IY\"&gt;https://www.youtube.com/watch?v=KvFZf3cL_IY&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a28REiz-i6TCSSJNCPEQznulRVVwAHDlJtNk-k1JGWE.jpg?auto=webp&amp;s=3974ce5358d6edda0ff613b79bb686a237084a98", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/a28REiz-i6TCSSJNCPEQznulRVVwAHDlJtNk-k1JGWE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63125c8e2954f6fd620743240dca75911cfd4464", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/a28REiz-i6TCSSJNCPEQznulRVVwAHDlJtNk-k1JGWE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f45309685173cd001cf3cbf6a20e4ff4f73cf022", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/a28REiz-i6TCSSJNCPEQznulRVVwAHDlJtNk-k1JGWE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=01a52c93555af6397da89e0a1081b8923438bc55", "width": 320, "height": 240}], "variants": {}, "id": "NhttvYj22tJS8xcXpty-_Hsoshs5MBcQWs3ai4XNACM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "183qx2q", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/183qx2q/i_shared_a_python_pandas_course_15_hrs_on_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/183qx2q/i_shared_a_python_pandas_course_15_hrs_on_youtube/", "subreddit_subscribers": 141727, "created_utc": 1700939168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Shopping around for experiences. In the past have obviously used Airflow since it was the only game in town. Of course I was also bitten by the numerous issues that Airflow has experienced with Schedulers falling over, deadlocks between worker threads and schedulers, etc. Now I have never run Airflow with a HA Scheduler environment and supposedly since the 2.6 update they have fixed some deadlocking issues. But will this scale to 1000s of DAGs scheduled at an hourly cadence?\n\nI have also poked around the edges of Dagster and Prefect but never used them in a production environment before, so I don't know how far those technologies scale in a real world environment.\n\nOr maybe there is another tool I am unaware of that better meets this usecase?\n\nEdit: I am specifically asking about scalability here", "author_fullname": "t2_dxegl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling to N DAGs: Airflow vs. Prefect vs. Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183jgps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700939352.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700917920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Shopping around for experiences. In the past have obviously used Airflow since it was the only game in town. Of course I was also bitten by the numerous issues that Airflow has experienced with Schedulers falling over, deadlocks between worker threads and schedulers, etc. Now I have never run Airflow with a HA Scheduler environment and supposedly since the 2.6 update they have fixed some deadlocking issues. But will this scale to 1000s of DAGs scheduled at an hourly cadence?&lt;/p&gt;\n\n&lt;p&gt;I have also poked around the edges of Dagster and Prefect but never used them in a production environment before, so I don&amp;#39;t know how far those technologies scale in a real world environment.&lt;/p&gt;\n\n&lt;p&gt;Or maybe there is another tool I am unaware of that better meets this usecase?&lt;/p&gt;\n\n&lt;p&gt;Edit: I am specifically asking about scalability here&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "183jgps", "is_robot_indexable": true, "report_reasons": null, "author": "nutso_muzz", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/183jgps/scaling_to_n_dags_airflow_vs_prefect_vs_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/183jgps/scaling_to_n_dags_airflow_vs_prefect_vs_dagster/", "subreddit_subscribers": 141727, "created_utc": 1700917920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "EMR is old 5.x and the spark installed in it is 2.4.x but I need to use the newer spark version to be compatible with certain libs, newer hudi. Is there anyway to run newer Spark [3.5.x] on the older cluster. Any help would be appreciated.\n\nP.S: Older MR jobs and spark jobs are running in the cluster, so the option of upgrading the cluster won't be possible.", "author_fullname": "t2_76srr1mpd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there anyway to run newer Spark version on EMR [older spark version]?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183j7yn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700917133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;EMR is old 5.x and the spark installed in it is 2.4.x but I need to use the newer spark version to be compatible with certain libs, newer hudi. Is there anyway to run newer Spark [3.5.x] on the older cluster. Any help would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;P.S: Older MR jobs and spark jobs are running in the cluster, so the option of upgrading the cluster won&amp;#39;t be possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "183j7yn", "is_robot_indexable": true, "report_reasons": null, "author": "pr6g_head", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/183j7yn/is_there_anyway_to_run_newer_spark_version_on_emr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/183j7yn/is_there_anyway_to_run_newer_spark_version_on_emr/", "subreddit_subscribers": 141727, "created_utc": 1700917133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve hit a scaling issue in my pipeline which processes receipts (strings which could be quite short or very long):\n\nAt the moment the affected task for-loops over all receipts available at that time. I\u2019m now expecting this to scale to hundreds of receipts at a time which would result in very long task completion time and might give me memory issues. That\u2019s why I\u2019mconsidering fanning out the processing bit for scalability. \n\nMy first question is by what principles to decide how much fanning out is sensible? I could do one process per receipt or alternatively per receipt batch and loop over each batch. Because many receipts are tiny the latter seems sensible to me but I\u2019m not sure how to back it up with numbers. That\u2019s a general question independent of tooling.\n\nMy second question concerns the actual\nimplementation: I use Flyte which fans out to Kubernetes pods which are more resource-intensive than just a process. So again not sure how to decide the batch size that\u2019s sensible per pod.", "author_fullname": "t2_2k05c87o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design question: Serial vs fan-out (on k8s)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_18464aw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700986745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve hit a scaling issue in my pipeline which processes receipts (strings which could be quite short or very long):&lt;/p&gt;\n\n&lt;p&gt;At the moment the affected task for-loops over all receipts available at that time. I\u2019m now expecting this to scale to hundreds of receipts at a time which would result in very long task completion time and might give me memory issues. That\u2019s why I\u2019mconsidering fanning out the processing bit for scalability. &lt;/p&gt;\n\n&lt;p&gt;My first question is by what principles to decide how much fanning out is sensible? I could do one process per receipt or alternatively per receipt batch and loop over each batch. Because many receipts are tiny the latter seems sensible to me but I\u2019m not sure how to back it up with numbers. That\u2019s a general question independent of tooling.&lt;/p&gt;\n\n&lt;p&gt;My second question concerns the actual\nimplementation: I use Flyte which fans out to Kubernetes pods which are more resource-intensive than just a process. So again not sure how to decide the batch size that\u2019s sensible per pod.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18464aw", "is_robot_indexable": true, "report_reasons": null, "author": "ephif", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18464aw/design_question_serial_vs_fanout_on_k8s/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18464aw/design_question_serial_vs_fanout_on_k8s/", "subreddit_subscribers": 141727, "created_utc": 1700986745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Oddly enough, I have a passion for data quality. Are there any jobs that focus specifically on data quality and solving data quality problems with statistics and programming? If so, what job titles should I look for and what concepts, data quality tools, languages, etc should I learn? I have a bachelors in statistics.", "author_fullname": "t2_b3uyjy3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on a career in data quality - possible careers and what I should learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1843kr1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700976673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Oddly enough, I have a passion for data quality. Are there any jobs that focus specifically on data quality and solving data quality problems with statistics and programming? If so, what job titles should I look for and what concepts, data quality tools, languages, etc should I learn? I have a bachelors in statistics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1843kr1", "is_robot_indexable": true, "report_reasons": null, "author": "Cold_Ad_2230", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1843kr1/seeking_advice_on_a_career_in_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1843kr1/seeking_advice_on_a_career_in_data_quality/", "subreddit_subscribers": 141727, "created_utc": 1700976673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nCan you recommend any materials that helped you prepare for the certifications beyond Core? Especially the Architect version.\n\nThanks", "author_fullname": "t2_gejetxj65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowpro advanced architect - tips for preparation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_183mr6u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700927857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Can you recommend any materials that helped you prepare for the certifications beyond Core? Especially the Architect version.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "183mr6u", "is_robot_indexable": true, "report_reasons": null, "author": "Visual-Exercise8031", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/183mr6u/snowpro_advanced_architect_tips_for_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/183mr6u/snowpro_advanced_architect_tips_for_preparation/", "subreddit_subscribers": 141727, "created_utc": 1700927857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://graflinger.medium.com/bring-your-py-spark-code-to-the-next-level-with-user-defined-functions-udfs-and-the-native-c7623d2e76f7", "author_fullname": "t2_aqzwz9ec", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different types of UDFs within pyspark and when to use them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1846cvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700987812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://graflinger.medium.com/bring-your-py-spark-code-to-the-next-level-with-user-defined-functions-udfs-and-the-native-c7623d2e76f7\"&gt;https://graflinger.medium.com/bring-your-py-spark-code-to-the-next-level-with-user-defined-functions-udfs-and-the-native-c7623d2e76f7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?auto=webp&amp;s=5a208d5e928652fe103f3767f8c6aa8b670c749e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dbd6512ab2117bb850f6737f75b1a2e60251f54", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4012ea3e8b9ac89f6776d9ff4ada73f78e5d1f57", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=164df234486bec1ef20547a6871a271c33d6efc4", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2e5b57f80eb73567b2dd2aca7411ef96baccd47", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6049e04e0ca0272c9e9b46f6daaabadf7d562249", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/kOc_TKom6tdiNVUfg5Ikxws7IF7Blt-rIKyCZU6TuKE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ca4670dacfd5cc07ac73200ca9925d80b8e32cae", "width": 1080, "height": 720}], "variants": {}, "id": "1OLVE5Gb_cQ6rMYsBpDxvEJr6UafO1Ca-KByLsKpK7M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1846cvd", "is_robot_indexable": true, "report_reasons": null, "author": "Sensitive-Noise-3261", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1846cvd/different_types_of_udfs_within_pyspark_and_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1846cvd/different_types_of_udfs_within_pyspark_and_when/", "subreddit_subscribers": 141727, "created_utc": 1700987812.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}