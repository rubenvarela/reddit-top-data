{"kind": "Listing", "data": {"after": "t3_17p08gq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "During my time in data engineering, I've noticed a lot of data engineers discount their own experience compared to software engineers who do not work in data.  Do a lot of data engineers not consider themselves a type of software engineer?\n\n\n\nI find that strange, because during my career I was able to do a lot of work in python, java, SQL, and Terraform.  I also have a lot of experience setting up CI/CD pipelines and building cloud infrastructure.  In many cases, I feel like our field overlaps a lot with backend engineering.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why don't a lot of data engineers consider themselves software engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p20y6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699275064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During my time in data engineering, I&amp;#39;ve noticed a lot of data engineers discount their own experience compared to software engineers who do not work in data.  Do a lot of data engineers not consider themselves a type of software engineer?&lt;/p&gt;\n\n&lt;p&gt;I find that strange, because during my career I was able to do a lot of work in python, java, SQL, and Terraform.  I also have a lot of experience setting up CI/CD pipelines and building cloud infrastructure.  In many cases, I feel like our field overlaps a lot with backend engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p20y6", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17p20y6/why_dont_a_lot_of_data_engineers_consider/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p20y6/why_dont_a_lot_of_data_engineers_consider/", "subreddit_subscribers": 138229, "created_utc": 1699275064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.\n\n1. Talend - I hear is open source and easy to use. It's made as a low code/no code solution for ETL.\n\n2. Pyspark - I'm kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.\n\n3. Informatica - I heard this one is ancient, should I just avoid?\n\n4. Fivetran - I heard is relatively new but don't know much about it, pros and cons?\n\nAny others you would consider and for what use case?", "author_fullname": "t2_bpr9freq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ETL tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oljhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699217931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Talend - I hear is open source and easy to use. It&amp;#39;s made as a low code/no code solution for ETL.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Pyspark - I&amp;#39;m kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Informatica - I heard this one is ancient, should I just avoid?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Fivetran - I heard is relatively new but don&amp;#39;t know much about it, pros and cons?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any others you would consider and for what use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oljhd", "is_robot_indexable": true, "report_reasons": null, "author": "BuyHigh_S3llLow", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oljhd/best_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oljhd/best_etl_tool/", "subreddit_subscribers": 138229, "created_utc": 1699217931.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty often while browsing this sub I see people put down 'low code/no code' data engineering solutions, and promoting ETL processes running on engines like Spark as opposed to transforming data in SQL. The reasons stated are usually for being easier to follow software engineering practices with 'real' code.\n\nHowever, it's undeniable that there exist cloud-based analytics warehouses that significantly outperform the traditional 'real code' frameworks when it comes to data transformation. I have transformations running in BigQuery where my testing has shown the costs of running on BQ to be about four or five times cheaper than with PySpark. I've read articles that back up this performance gap and it seems to be well accepted that tools like BigQuery significantly outperform traditional batch processing frameworks.\n\nOn a personal level I would prefer to be writing these transformations in Python - it's easier, it's cleaner, it's more versatile. With functions written in BigQuery we're usually ending up with long queries featuring a mess of joins that are hard to troubleshoot when things start going wrong.\n\nBut if I go to my manager and say \"I would rather write these transformations in Spark - it will be significantly more expensive but I will find it easier\" then I don't think it's going to go down well.\n\nSo I'd like to put it to this sub - if we have transformation processes that perform extremely well in BigQuery and our evidence shows that it would be significantly more expensive to move to other technologies, how could we justify moving away from a 'low code/no code' stack when it comes to transformations?", "author_fullname": "t2_2jmvd5bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shunning 'low code/no code' solutions in a world where analytics warehouses provide great performance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ow2ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699249969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty often while browsing this sub I see people put down &amp;#39;low code/no code&amp;#39; data engineering solutions, and promoting ETL processes running on engines like Spark as opposed to transforming data in SQL. The reasons stated are usually for being easier to follow software engineering practices with &amp;#39;real&amp;#39; code.&lt;/p&gt;\n\n&lt;p&gt;However, it&amp;#39;s undeniable that there exist cloud-based analytics warehouses that significantly outperform the traditional &amp;#39;real code&amp;#39; frameworks when it comes to data transformation. I have transformations running in BigQuery where my testing has shown the costs of running on BQ to be about four or five times cheaper than with PySpark. I&amp;#39;ve read articles that back up this performance gap and it seems to be well accepted that tools like BigQuery significantly outperform traditional batch processing frameworks.&lt;/p&gt;\n\n&lt;p&gt;On a personal level I would prefer to be writing these transformations in Python - it&amp;#39;s easier, it&amp;#39;s cleaner, it&amp;#39;s more versatile. With functions written in BigQuery we&amp;#39;re usually ending up with long queries featuring a mess of joins that are hard to troubleshoot when things start going wrong.&lt;/p&gt;\n\n&lt;p&gt;But if I go to my manager and say &amp;quot;I would rather write these transformations in Spark - it will be significantly more expensive but I will find it easier&amp;quot; then I don&amp;#39;t think it&amp;#39;s going to go down well.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;d like to put it to this sub - if we have transformation processes that perform extremely well in BigQuery and our evidence shows that it would be significantly more expensive to move to other technologies, how could we justify moving away from a &amp;#39;low code/no code&amp;#39; stack when it comes to transformations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ow2ku", "is_robot_indexable": true, "report_reasons": null, "author": "Objectionne", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ow2ku/shunning_low_codeno_code_solutions_in_a_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ow2ku/shunning_low_codeno_code_solutions_in_a_world/", "subreddit_subscribers": 138229, "created_utc": 1699249969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I am a business analyst and planning to have an initiative to have the business glossary and data dictionary, mostly my target audience will be the stakeholders, customers and non technical people.\n\nTo give you a background, my current project is a web based application, coded in java. So mostly the data validation is configured through java. In line with that, I want that to translate by creating the DD.\n\nData Dictionary that I'm planning to do is kind of web based application that connects to the git/java code, so every time that there are changes in field validations it automatically reflects in the DD.\n\nFor example;\nPersonal name : Varchar (20), minimum 10\n\nDo you have any recommendation tools that I can use?", "author_fullname": "t2_4z8wla8ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool for creating Business Glossary and Data Dictionary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oygw9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699260371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a business analyst and planning to have an initiative to have the business glossary and data dictionary, mostly my target audience will be the stakeholders, customers and non technical people.&lt;/p&gt;\n\n&lt;p&gt;To give you a background, my current project is a web based application, coded in java. So mostly the data validation is configured through java. In line with that, I want that to translate by creating the DD.&lt;/p&gt;\n\n&lt;p&gt;Data Dictionary that I&amp;#39;m planning to do is kind of web based application that connects to the git/java code, so every time that there are changes in field validations it automatically reflects in the DD.&lt;/p&gt;\n\n&lt;p&gt;For example;\nPersonal name : Varchar (20), minimum 10&lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendation tools that I can use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oygw9", "is_robot_indexable": true, "report_reasons": null, "author": "Kizzmexoxo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oygw9/best_tool_for_creating_business_glossary_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oygw9/best_tool_for_creating_business_glossary_and_data/", "subreddit_subscribers": 138229, "created_utc": 1699260371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to learn about the landscape of data engineering certifications in 2023/24. \n\nIf you don't mind sharing your insights, I have some questions:\n\n1. In your opinion, which DE/ML certifications are highly regarded or considered valuable in the industry right now or will be in near future?\n2. What is your perspective on certifications from major cloud service providers like AWS, GCP, and Azure, in terms of their relevance and impact on a DE career? Which one would you recommend?\n3. Do niche-specific certifications (e.g., CDMP, Airflow, Snowflake, Databricks, etc) hold significant weight?\n4. Are there any other certifications or training programs you think are worth mentioning for those looking to advance in the field?\n\nThanks in advance for sharing your knowledge and experience!", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are useful data engineering certifications in 2023/24?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17paeyc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699297910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to learn about the landscape of data engineering certifications in 2023/24. &lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t mind sharing your insights, I have some questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In your opinion, which DE/ML certifications are highly regarded or considered valuable in the industry right now or will be in near future?&lt;/li&gt;\n&lt;li&gt;What is your perspective on certifications from major cloud service providers like AWS, GCP, and Azure, in terms of their relevance and impact on a DE career? Which one would you recommend?&lt;/li&gt;\n&lt;li&gt;Do niche-specific certifications (e.g., CDMP, Airflow, Snowflake, Databricks, etc) hold significant weight?&lt;/li&gt;\n&lt;li&gt;Are there any other certifications or training programs you think are worth mentioning for those looking to advance in the field?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance for sharing your knowledge and experience!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17paeyc", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17paeyc/what_are_useful_data_engineering_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17paeyc/what_are_useful_data_engineering_certifications/", "subreddit_subscribers": 138229, "created_utc": 1699297910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've joined a small org as a BI analyst but have been asked to build a data platform with support from an external consultant.  \n\nConsultant wants to use Fabric for everything, I raised a concern (as advised by many here on r/DEng) that Fabric is not yet ready too use as a primary system. \n\nHe responded that only some of the components are new, and as many are rebranded (eg PowerBI is now under the fabric banner) and I shouldn't worry.\n\nSo which components of fabric (other than powerBI) are deployment ready?", "author_fullname": "t2_2s6myxsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Fabric components are stable and deployment ready?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oyhgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699260450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve joined a small org as a BI analyst but have been asked to build a data platform with support from an external consultant.  &lt;/p&gt;\n\n&lt;p&gt;Consultant wants to use Fabric for everything, I raised a concern (as advised by many here on &lt;a href=\"/r/DEng\"&gt;r/DEng&lt;/a&gt;) that Fabric is not yet ready too use as a primary system. &lt;/p&gt;\n\n&lt;p&gt;He responded that only some of the components are new, and as many are rebranded (eg PowerBI is now under the fabric banner) and I shouldn&amp;#39;t worry.&lt;/p&gt;\n\n&lt;p&gt;So which components of fabric (other than powerBI) are deployment ready?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oyhgt", "is_robot_indexable": true, "report_reasons": null, "author": "Dog_In_A_Human_Suit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oyhgt/which_fabric_components_are_stable_and_deployment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oyhgt/which_fabric_components_are_stable_and_deployment/", "subreddit_subscribers": 138229, "created_utc": 1699260450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working as a data engineer for about 3 years now mainly with snowflake, azure ecosystem (azure sql and data factory), and databricks mostly building pipelines and ELTs. The companies I worked for were big enough to justify and afford these tools.\n\nI have a side business that offers parcel services. We use AWS lightsale to host our web app as well as our posgreSQL database. Some operational reporting is done directly through the app. So far the database is working with no issue. The biggest table we have has around 123k records.\n\nI have some experience with power bi and wanted to build some more strategic reports with more functionality and to also lift some weight from the developers having to develop all the reports. My idea was to create a new star schema within the same database. Power bi would point to this schema and it would refresh daily at a point in time where it's barely being used to avoid performance issues.\n\nI'm debating whether to just use views pointing to the existing tables or to create and load new tables. I've seen that this subreddit talks very well of dbt and I'm thinking of using it in this project to learn the tool and to maintain good practices.\n\nWhat are your thoughts on views vs tables?\n\nWould you recommend sharing the database for both transactional and analytical workloads if the business is small?\n\n At what point do you decide to separate the data warehouse?", "author_fullname": "t2_177meuof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what point do you need a data warehouse for a small business?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17pahfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699298103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working as a data engineer for about 3 years now mainly with snowflake, azure ecosystem (azure sql and data factory), and databricks mostly building pipelines and ELTs. The companies I worked for were big enough to justify and afford these tools.&lt;/p&gt;\n\n&lt;p&gt;I have a side business that offers parcel services. We use AWS lightsale to host our web app as well as our posgreSQL database. Some operational reporting is done directly through the app. So far the database is working with no issue. The biggest table we have has around 123k records.&lt;/p&gt;\n\n&lt;p&gt;I have some experience with power bi and wanted to build some more strategic reports with more functionality and to also lift some weight from the developers having to develop all the reports. My idea was to create a new star schema within the same database. Power bi would point to this schema and it would refresh daily at a point in time where it&amp;#39;s barely being used to avoid performance issues.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m debating whether to just use views pointing to the existing tables or to create and load new tables. I&amp;#39;ve seen that this subreddit talks very well of dbt and I&amp;#39;m thinking of using it in this project to learn the tool and to maintain good practices.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on views vs tables?&lt;/p&gt;\n\n&lt;p&gt;Would you recommend sharing the database for both transactional and analytical workloads if the business is small?&lt;/p&gt;\n\n&lt;p&gt;At what point do you decide to separate the data warehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17pahfg", "is_robot_indexable": true, "report_reasons": null, "author": "hershy08", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pahfg/at_what_point_do_you_need_a_data_warehouse_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pahfg/at_what_point_do_you_need_a_data_warehouse_for_a/", "subreddit_subscribers": 138229, "created_utc": 1699298103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 years of experience in data engineering and soon going to start a job as a solutions architect.\n\nI know this is less experience and I see most of the jobs in solutions architecture require 7-8+ years of work experience. With that considered, what are some great books that I can read to increase my knowledge about solution architecture concepts?  \nAlso please feel free to post some things that I need to keep in mind to succeed.\n\n&amp;#x200B;\n\nThank you in advance", "author_fullname": "t2_8gpfnv45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for solutions architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p90ns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699294316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 years of experience in data engineering and soon going to start a job as a solutions architect.&lt;/p&gt;\n\n&lt;p&gt;I know this is less experience and I see most of the jobs in solutions architecture require 7-8+ years of work experience. With that considered, what are some great books that I can read to increase my knowledge about solution architecture concepts?&lt;br/&gt;\nAlso please feel free to post some things that I need to keep in mind to succeed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p90ns", "is_robot_indexable": true, "report_reasons": null, "author": "ameya_b", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p90ns/resources_for_solutions_architect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p90ns/resources_for_solutions_architect/", "subreddit_subscribers": 138229, "created_utc": 1699294316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior data engineer and i perform an automated ETL system that extract data from multiple excel sheets, transform them and then load them into a destination database table, my problem is the excel sheets have different column names and different column orders from each other and from the destination database table, so i want to make the mapping process automated (not to create a mapping dictionary that specify the old column name with the new column name)", "author_fullname": "t2_g2wxrrado", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oxw83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699257790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior data engineer and i perform an automated ETL system that extract data from multiple excel sheets, transform them and then load them into a destination database table, my problem is the excel sheets have different column names and different column orders from each other and from the destination database table, so i want to make the mapping process automated (not to create a mapping dictionary that specify the old column name with the new column name)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oxw83", "is_robot_indexable": true, "report_reasons": null, "author": "OtherCan6354", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oxw83/need_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oxw83/need_solution/", "subreddit_subscribers": 138229, "created_utc": 1699257790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE transition into MLE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ooyfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699226980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ooyfj", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "subreddit_subscribers": 138229, "created_utc": 1699226980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.peerdb.io/building-a-streaming-platform-in-go-for-postgres](https://blog.peerdb.io/building-a-streaming-platform-in-go-for-postgres)  \n[PeerDB's](https://www.peerdb.io/) recent engineering blog on a design change that reduces replication latency/lag while streaming data from Postgres  from 30s to less than 5s.\n\nIf you are a Go u/golang developer you would find this intriguing. Would love to hear your feedback.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Streaming Platform in Go for Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17papeg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699298679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.peerdb.io/building-a-streaming-platform-in-go-for-postgres\"&gt;https://blog.peerdb.io/building-a-streaming-platform-in-go-for-postgres&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://www.peerdb.io/\"&gt;PeerDB&amp;#39;s&lt;/a&gt; recent engineering blog on a design change that reduces replication latency/lag while streaming data from Postgres  from 30s to less than 5s.&lt;/p&gt;\n\n&lt;p&gt;If you are a Go &lt;a href=\"/u/golang\"&gt;u/golang&lt;/a&gt; developer you would find this intriguing. Would love to hear your feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?auto=webp&amp;s=51e136315e28eae2332c64f9794907f59192e89a", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=013570b5f4313cd4e20708bd8e6ff743d645a35d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8195282656de899f495044c52af47a835299b3ea", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=673beea3ef9d37b60709058fcc5b155096a9bb29", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4bed1027ebb57891852ebc59bfffcd58f7db8477", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5337009152e44970850c78d69c1817b2ee0e8f2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/DDjncTXWggiNzdVYG9e0CLj8gWIQqqkxXUTaR5rozTo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b82655640d39f01746c8924e49e16db89a4f2c0f", "width": 1080, "height": 720}], "variants": {}, "id": "jLylNeqzjTc-QQvl96AqP5DuMQdHOnWYRo1GHxGz9Ls"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17papeg", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17papeg/building_a_streaming_platform_in_go_for_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17papeg/building_a_streaming_platform_in_go_for_postgres/", "subreddit_subscribers": 138229, "created_utc": 1699298679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I was tasked with a certain requirement as the title suggests, I need to push/export the bigquery tables via API so the client can fetch the data via same API calls. I tried checking via official documentation but except granting permissions or exporting to GCS buckets I couldn\u2019t come up with anything. \n\nPlease guide me if I\u2019ve missed out something. Open to suggestions on the same.\n\nThank you", "author_fullname": "t2_3qc9b4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting BigQuery Tables via API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17owput", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699252592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was tasked with a certain requirement as the title suggests, I need to push/export the bigquery tables via API so the client can fetch the data via same API calls. I tried checking via official documentation but except granting permissions or exporting to GCS buckets I couldn\u2019t come up with anything. &lt;/p&gt;\n\n&lt;p&gt;Please guide me if I\u2019ve missed out something. Open to suggestions on the same.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17owput", "is_robot_indexable": true, "report_reasons": null, "author": "apache444", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17owput/exporting_bigquery_tables_via_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17owput/exporting_bigquery_tables_via_api/", "subreddit_subscribers": 138229, "created_utc": 1699252592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\n**TL;DR**\n\n*Looking for an ETL tool that bridges the gap between no-code prototyping and established engineering practices. Want it to auto-generate code from visual steps and run in a serverless context. Seeking input and opinions from the community* \n\nI've searched all over the internet but couldn't find a tool of the following kind (dagster + dbt is close though).\n\n**Problem**:\n\nI work with various clients that start in a no-code environment (Alteryx, Informatica, Knime, etc.), but then they want to move to something else, either because the data has grown in size or they want a more stable and customizable workflow. This could involve building a Python library with testable components hosted on their side or at least sql scripts.\n\nI was wondering if there is an ETL tool that could bridge the gap between quick prototyping and clicking around, and established engineering practices. For example, an analyst starts a project as a no-code one, but behind every click on a step (filter, group by, etc.), the platform generates actual .py files or .sql files and prepares/structures the project so that when a more technical person takes over, they can switch to seeing the generated files, folders, connections instead of the visual aspect of the project. The technical team can then work alongside the analyst and adding new files/folders will automatically render the steps, tables, and so on.\n\nIdeally, this service would be sold as a managed service on the customer's cloud (similar to Databricks) rather than on a separate platform. Each table would be one file executed in a serverless context with the following flow: send the code to the cloud container service, execute it, save the table on the blob, and proceed to the next step.\n\n**Issues with current tools**:\n\n* Dagster + dbt seem to be close to what I envision because of the simplicity of syntax and autogeneration of DAGs. The only issues are that it lacks the visual no-code part, and to set it up with serverless execution, you would need some configuring and self-host it on a K8s cluster or create your own step launcher.\n* Databricks covers the ease of getting started: add your service, create your workflow, choose your cluster, and run it. I understand that it's intended for big data, but I'm adding it as a perspective on the end-user experience. I would like, in addition to VM provisioning, to also be able to spin up bare containers without the Spark overhead.\n\nDoes this concept resonate with anyone and can recommend something on the market? Also, what are your personal thoughts on this idea? Am I overthinking it or do you think it may be useful? ", "author_fullname": "t2_4l3aonbn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless ETL tool as managed service on Azure/AWS/GCP - combination of no code solution, Dagster and Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17p9nba", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699295942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Looking for an ETL tool that bridges the gap between no-code prototyping and established engineering practices. Want it to auto-generate code from visual steps and run in a serverless context. Seeking input and opinions from the community&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve searched all over the internet but couldn&amp;#39;t find a tool of the following kind (dagster + dbt is close though).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;p&gt;I work with various clients that start in a no-code environment (Alteryx, Informatica, Knime, etc.), but then they want to move to something else, either because the data has grown in size or they want a more stable and customizable workflow. This could involve building a Python library with testable components hosted on their side or at least sql scripts.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there is an ETL tool that could bridge the gap between quick prototyping and clicking around, and established engineering practices. For example, an analyst starts a project as a no-code one, but behind every click on a step (filter, group by, etc.), the platform generates actual .py files or .sql files and prepares/structures the project so that when a more technical person takes over, they can switch to seeing the generated files, folders, connections instead of the visual aspect of the project. The technical team can then work alongside the analyst and adding new files/folders will automatically render the steps, tables, and so on.&lt;/p&gt;\n\n&lt;p&gt;Ideally, this service would be sold as a managed service on the customer&amp;#39;s cloud (similar to Databricks) rather than on a separate platform. Each table would be one file executed in a serverless context with the following flow: send the code to the cloud container service, execute it, save the table on the blob, and proceed to the next step.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issues with current tools&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dagster + dbt seem to be close to what I envision because of the simplicity of syntax and autogeneration of DAGs. The only issues are that it lacks the visual no-code part, and to set it up with serverless execution, you would need some configuring and self-host it on a K8s cluster or create your own step launcher.&lt;/li&gt;\n&lt;li&gt;Databricks covers the ease of getting started: add your service, create your workflow, choose your cluster, and run it. I understand that it&amp;#39;s intended for big data, but I&amp;#39;m adding it as a perspective on the end-user experience. I would like, in addition to VM provisioning, to also be able to spin up bare containers without the Spark overhead.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Does this concept resonate with anyone and can recommend something on the market? Also, what are your personal thoughts on this idea? Am I overthinking it or do you think it may be useful? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p9nba", "is_robot_indexable": true, "report_reasons": null, "author": "_randomymous_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p9nba/serverless_etl_tool_as_managed_service_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p9nba/serverless_etl_tool_as_managed_service_on/", "subreddit_subscribers": 138229, "created_utc": 1699295942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everybody, I'm enrolled in a Data Science Master In Paris, with two internship experiences, 6 months as an Azure Data Engineer and 3 months as a Data Scientist. I am actively seeking an end-of-studies data engineer Internship in Paris or Europe starting in March 2024. I have applied many times and had very little feedback. Is it normal due to the high competition? or there is a problem with my Resume? Should I be worried or it's too early?\n\nPlease check my resume here, I would be super grateful for any advice regarding my resume or any opportunities that I can apply for.\n\nresume : [https://drive.google.com/file/d/1fh2V8aqDMnMXcI\\_Frr4UjTbxbEM1uVUh/view?usp=drive\\_link](https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link)", "author_fullname": "t2_g0flbs20b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Resume for an End-of-studies Internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p7yg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699294802.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699291599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody, I&amp;#39;m enrolled in a Data Science Master In Paris, with two internship experiences, 6 months as an Azure Data Engineer and 3 months as a Data Scientist. I am actively seeking an end-of-studies data engineer Internship in Paris or Europe starting in March 2024. I have applied many times and had very little feedback. Is it normal due to the high competition? or there is a problem with my Resume? Should I be worried or it&amp;#39;s too early?&lt;/p&gt;\n\n&lt;p&gt;Please check my resume here, I would be super grateful for any advice regarding my resume or any opportunities that I can apply for.&lt;/p&gt;\n\n&lt;p&gt;resume : &lt;a href=\"https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link\"&gt;https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p7yg5", "is_robot_indexable": true, "report_reasons": null, "author": "med_maz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p7yg5/data_engineering_resume_for_an_endofstudies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p7yg5/data_engineering_resume_for_an_endofstudies/", "subreddit_subscribers": 138229, "created_utc": 1699291599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products | Evolve: Part 4/4 Advanced SLOs, Feedback Loops, Optimised Data Product, and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17p21jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CPo-qUNcpXogigmEZh7oJ4UqfS2IXKs7kEMtJFETld0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699275121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/evolving-data-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?auto=webp&amp;s=1221a1dce31f3afe76700003ecc0b1ddb6be9b66", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65be0a310cfc5f7368c888c1638e9db48dc08a1f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84058159ac22b55a3f202ff5dc450404dbb2c6b3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b88b81f6bd64d16a333eaa562695fb58dd2d057", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6d6bfb73a928498e52dc9fa0684118e28d75f4c2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8de6d0063f9da38114ffd20967e62af2a6f8111a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c6b4f396c1c77a4b36e6b36f63fb6a313090f653", "width": 1080, "height": 540}], "variants": {}, "id": "XJZ-DYAnwfbcnEScRfgAlIRNXlSes7wfrL03G0CXFcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17p21jc", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p21jc/how_to_build_data_products_evolve_part_44/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/evolving-data-products", "subreddit_subscribers": 138229, "created_utc": 1699275121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Howdy y'all \ud83e\udd20\ud83d\udc4b  \n\n\nI'm an aspiring data engineer and have been self-teaching a number of skills such as SQL, python, and dbt. One of my main goals now is to build a custom ETL pipeline using python.   \n\n\nWhat are your recommendations for an orchestration tool? Looking for a package that can be used directly from python - trying to avoid a pre-package tool like Fivetran as my goal is to develop useful core DE skills.  \n\n\nI see Airflow mentioned frequently. I know there is a web-based GUI, but can it also be used entirely via python?", "author_fullname": "t2_y2dhb7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Recommendation for Orchestration Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17pbgyn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699300662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Howdy y&amp;#39;all \ud83e\udd20\ud83d\udc4b  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an aspiring data engineer and have been self-teaching a number of skills such as SQL, python, and dbt. One of my main goals now is to build a custom ETL pipeline using python.   &lt;/p&gt;\n\n&lt;p&gt;What are your recommendations for an orchestration tool? Looking for a package that can be used directly from python - trying to avoid a pre-package tool like Fivetran as my goal is to develop useful core DE skills.  &lt;/p&gt;\n\n&lt;p&gt;I see Airflow mentioned frequently. I know there is a web-based GUI, but can it also be used entirely via python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17pbgyn", "is_robot_indexable": true, "report_reasons": null, "author": "creamycolslaw", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pbgyn/looking_for_recommendation_for_orchestration_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pbgyn/looking_for_recommendation_for_orchestration_tool/", "subreddit_subscribers": 138229, "created_utc": 1699300662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c75e0hjg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RevenueCat's data-caching techniques for 1.2 billion daily API requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_17pb8v6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zI2UAjcgjgXOnusnkYi3B4iriAw8k5_pb89HFqhubcs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699300066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "revenuecat.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?auto=webp&amp;s=43eab23811acd15223d93996fd35633e2fbede08", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd59eb2ec39c278d82b7ed31c8fbbb8056ae1ed8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=08b662c261dc255ff76779cca5853eb5bb50b9fd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=71261122fba8653aa61fcba55218e728e7a57b0b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51f542c45d65577603a894b246f2a71c5246349f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cd661d2bac40c183fbc2fa97fbcf4b67c4a0356d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fTpx0SpHtgvUWceCFNqdjsCzD4U9nnFSSAPJwUbl7xc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b6c9eff7b95ec4134311407d4d018811e2e4d039", "width": 1080, "height": 567}], "variants": {}, "id": "YgEOOqqwm_nMXategwITapc1-ybJGxYTttj9Te9eN3k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17pb8v6", "is_robot_indexable": true, "report_reasons": null, "author": "PoolOpening6090", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pb8v6/revenuecats_datacaching_techniques_for_12_billion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/", "subreddit_subscribers": 138229, "created_utc": 1699300066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s3s2xpr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automatic database change tracking with Bemi", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_17paw3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xMyrMOtivegnpi9uXU43_U-Oy9_g12YdZEqf5mBnLuA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699299156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bemi.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bemi.io", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?auto=webp&amp;s=7c6ab18148ce84fe336720c19f5ef4b9f5cc2aa5", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dd96790cf3fa2dff690037fe557eb3b37f4be69b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=90657527360b975cbea4f78cd951dd6920d075ae", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e7d8bfac4fd1d40e243b5d78bc0a6cc582ef06b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93a8f5b4d74f31a3de081d0a32e6963ddde365b6", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a0faaf624d123e05106e09e396d43bafaeedcd44", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/x8ukifSZdRByod-RJi3daE-L2Vnl3zeVJNjo3YkP_20.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9c9d7da04c8b8cfbce79a94cb15835e0eeb8c51", "width": 1080, "height": 567}], "variants": {}, "id": "9fzOuHSY0Ha5CBeS5O60tfgpNBCxukJVuCqR1TP0ZlU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17paw3d", "is_robot_indexable": true, "report_reasons": null, "author": "More_Champion_7731", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17paw3d/automatic_database_change_tracking_with_bemi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bemi.io", "subreddit_subscribers": 138229, "created_utc": 1699299156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning pyspark and would be great to know if I can optimise this even more further.\n\nI have followed this [S/O post](https://stackoverflow.com/questions/69002085/populate-a-column-based-on-previous-value-and-row-pyspark) and was able to optimize one of the process but still Im struggling to figure out is there a better way to solve the below scenario.  \n\n\nThe dataframe will be like this \n\n&amp;#x200B;\n\n|Date|Date 2|Partition|\n|:-|:-|:-|\n| 6 Nov   |6 Nov  |1|\n|6 Nov|7 Nov|2|\n|7 Nov|7 Nov|2|\n|6 Nov|8 Nov|3|\n|7 Nov|8 Nov|3|\n|8 Nov|8 Nov|3|\n\n&amp;#x200B;\n\nPartition here is just a group of data and whatever the calculation that is required to generate the columns will be based on from those current partition.\n\n&gt;while (!threshold) {  \n&gt;  \n&gt;price =+ 25;  \n&gt;  \n&gt;result = // consider an operation like the one mentioned in the previous S/O link is happening here  \n&gt;  \n&gt;// few more calculations which will generate few columns  \n&gt;  \n&gt;if (result &lt; someValue) {   \n&gt;  \n&gt;populate one column here          \n&gt;  \n&gt;} else {  \n&gt;  \n&gt;flips the threshold  \n}\n\nFrom the above while loop we are interested in the final price and the aggregated values and the generated values in the final iteration of the while loop all intermediate results are overwritten or not used.\n\nRight now I have implemented this with while loop in spark and used \\`\\`\\`\\`when / otherwise\\`\\`\\`\\` to do all those if conditions\n\n&amp;#x200B;\n\nI want to know is there any other better spark way to do this, since before knowing the attached S/O implementation my other operation was taking few minutes to complete but now its a breeze.\n\n&amp;#x200B;\n\nAn idea or some reference links to look or concepts to learn would be even more appreciated.\n\nThanks in advance.", "author_fullname": "t2_6oj5b6d9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a better way to write / optimize this loop in pyspark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17pa515", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699297203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning pyspark and would be great to know if I can optimise this even more further.&lt;/p&gt;\n\n&lt;p&gt;I have followed this &lt;a href=\"https://stackoverflow.com/questions/69002085/populate-a-column-based-on-previous-value-and-row-pyspark\"&gt;S/O post&lt;/a&gt; and was able to optimize one of the process but still Im struggling to figure out is there a better way to solve the below scenario.  &lt;/p&gt;\n\n&lt;p&gt;The dataframe will be like this &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Date&lt;/th&gt;\n&lt;th align=\"left\"&gt;Date 2&lt;/th&gt;\n&lt;th align=\"left\"&gt;Partition&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;6 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;7 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;7 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;7 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;8 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;7 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;8 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;8 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;8 Nov&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Partition here is just a group of data and whatever the calculation that is required to generate the columns will be based on from those current partition.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;while (!threshold) {  &lt;/p&gt;\n\n&lt;p&gt;price =+ 25;  &lt;/p&gt;\n\n&lt;p&gt;result = // consider an operation like the one mentioned in the previous S/O link is happening here  &lt;/p&gt;\n\n&lt;p&gt;// few more calculations which will generate few columns  &lt;/p&gt;\n\n&lt;p&gt;if (result &amp;lt; someValue) {   &lt;/p&gt;\n\n&lt;p&gt;populate one column here          &lt;/p&gt;\n\n&lt;p&gt;} else {  &lt;/p&gt;\n\n&lt;p&gt;flips the threshold&lt;br/&gt;\n}&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;From the above while loop we are interested in the final price and the aggregated values and the generated values in the final iteration of the while loop all intermediate results are overwritten or not used.&lt;/p&gt;\n\n&lt;p&gt;Right now I have implemented this with while loop in spark and used ````when / otherwise```` to do all those if conditions&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to know is there any other better spark way to do this, since before knowing the attached S/O implementation my other operation was taking few minutes to complete but now its a breeze.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;An idea or some reference links to look or concepts to learn would be even more appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17pa515", "is_robot_indexable": true, "report_reasons": null, "author": "zee_wild_runner", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pa515/is_there_a_better_way_to_write_optimize_this_loop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pa515/is_there_a_better_way_to_write_optimize_this_loop/", "subreddit_subscribers": 138229, "created_utc": 1699297203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody, just wanted to know what would be your go to orchestrator based on set up time and complexity. I feel, that for some simpel projects, let's say just a few apis +dbt for example, a setup with dagster, prefect etc. Is overkill and a simple bash script might be better? The only down side is the non existing/custom notification possibility.\nWhat do you think? Do you have any preferences for orchestration?", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low effort orchestrator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17p9z80", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699296779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, just wanted to know what would be your go to orchestrator based on set up time and complexity. I feel, that for some simpel projects, let&amp;#39;s say just a few apis +dbt for example, a setup with dagster, prefect etc. Is overkill and a simple bash script might be better? The only down side is the non existing/custom notification possibility.\nWhat do you think? Do you have any preferences for orchestration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p9z80", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p9z80/low_effort_orchestrator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p9z80/low_effort_orchestrator/", "subreddit_subscribers": 138229, "created_utc": 1699296779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, \n\nI have a system I'm looking to first \"batch\" then stream data to conditionally. Essentially the data has dates associated with it and the target system I want to deliver the data to can't accept the data too far before its associated date, but the data can be generated for any date in the future. So I'm looking to design a system that X days before a date will deliver all previously received data for that date then begin to stream (kafka) any new records or changes near real time once within the window. \n\nDoes this pattern/design have a name? Or are there any established patterns that would work well for this use case? It's a surprisingly hard thing to Google... \n\nThanks!", "author_fullname": "t2_pgfxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to best approach a conditional datastream? Is there an established design for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p713g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699289237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;I have a system I&amp;#39;m looking to first &amp;quot;batch&amp;quot; then stream data to conditionally. Essentially the data has dates associated with it and the target system I want to deliver the data to can&amp;#39;t accept the data too far before its associated date, but the data can be generated for any date in the future. So I&amp;#39;m looking to design a system that X days before a date will deliver all previously received data for that date then begin to stream (kafka) any new records or changes near real time once within the window. &lt;/p&gt;\n\n&lt;p&gt;Does this pattern/design have a name? Or are there any established patterns that would work well for this use case? It&amp;#39;s a surprisingly hard thing to Google... &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p713g", "is_robot_indexable": true, "report_reasons": null, "author": "Sanity__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p713g/how_to_best_approach_a_conditional_datastream_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p713g/how_to_best_approach_a_conditional_datastream_is/", "subreddit_subscribers": 138229, "created_utc": 1699289237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Requirement is to write data in RDS Postgre tables to Hive Tables in  Databricks. Databricks environment is externally hosted, can either be on AWS or Azure. How to do the same securely?", "author_fullname": "t2_9rp533dt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write AWS RDS Postgres tables to Hive tables in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p5vnv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699286159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Requirement is to write data in RDS Postgre tables to Hive Tables in  Databricks. Databricks environment is externally hosted, can either be on AWS or Azure. How to do the same securely?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p5vnv", "is_robot_indexable": true, "report_reasons": null, "author": "prasanna_aatma", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p5vnv/write_aws_rds_postgres_tables_to_hive_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p5vnv/write_aws_rds_postgres_tables_to_hive_tables_in/", "subreddit_subscribers": 138229, "created_utc": 1699286159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,  \n\n\nI am working on a Pipeline in Azure Data Factory which gets the last modified date data from ADLG2 &amp; On-prem storage.  I have a situation where multiple files are uploaded to the container with a difference of seconds and minutes.  \n\n\nThe issue is all these files are meant to arrive at the same time so with the issue of different time upload and want to create a function that ignores the Timestamp usually generate from \"Last Modified\" date and just consider only the Date (yyyy-MM-dd).\n\nI would love if anyone can help me because this is really a big issue for me. Also links to materials will help.  \n\n\nAlso in a scenario where let say 5-10 files enters the same time using the Last Modified Date activity in ADF will it pick all files.  \n\n\nThanks SOS.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get Date only using the Azure Data Factory Get Meta Data (Last Modified)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p52e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699283946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,  &lt;/p&gt;\n\n&lt;p&gt;I am working on a Pipeline in Azure Data Factory which gets the last modified date data from ADLG2 &amp;amp; On-prem storage.  I have a situation where multiple files are uploaded to the container with a difference of seconds and minutes.  &lt;/p&gt;\n\n&lt;p&gt;The issue is all these files are meant to arrive at the same time so with the issue of different time upload and want to create a function that ignores the Timestamp usually generate from &amp;quot;Last Modified&amp;quot; date and just consider only the Date (yyyy-MM-dd).&lt;/p&gt;\n\n&lt;p&gt;I would love if anyone can help me because this is really a big issue for me. Also links to materials will help.  &lt;/p&gt;\n\n&lt;p&gt;Also in a scenario where let say 5-10 files enters the same time using the Last Modified Date activity in ADF will it pick all files.  &lt;/p&gt;\n\n&lt;p&gt;Thanks SOS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p52e3", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p52e3/how_to_get_date_only_using_the_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p52e3/how_to_get_date_only_using_the_azure_data_factory/", "subreddit_subscribers": 138229, "created_utc": 1699283946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With my team, we're testing out our framework (Versatile Data Kit) and Jupyter notebooks, and as part of it, we're organizing a free workshop on ingestion and anonymization.   \n\n\nThe workshop covers the basics of DE with Python and SQL, is very easy to follow, hands-on, 1 h, ask-any-questions experience in a small group.   \n\n\nThis is the second workshop we're organizing on the topic, and if there are any suggestions or requests on other topics we could demo, I'm also open to hear! ", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE workshop - Ingestion and Anonymization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p1vju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699274538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With my team, we&amp;#39;re testing out our framework (Versatile Data Kit) and Jupyter notebooks, and as part of it, we&amp;#39;re organizing a free workshop on ingestion and anonymization.   &lt;/p&gt;\n\n&lt;p&gt;The workshop covers the basics of DE with Python and SQL, is very easy to follow, hands-on, 1 h, ask-any-questions experience in a small group.   &lt;/p&gt;\n\n&lt;p&gt;This is the second workshop we&amp;#39;re organizing on the topic, and if there are any suggestions or requests on other topics we could demo, I&amp;#39;m also open to hear! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17p1vju", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p1vju/de_workshop_ingestion_and_anonymization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p1vju/de_workshop_ingestion_and_anonymization/", "subreddit_subscribers": 138229, "created_utc": 1699274538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone had any luck replicating and/or extracting data from Netsuite ERP database?\n\nWhat tool did you use ?\n\nCheers", "author_fullname": "t2_legyu6zou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting data from Netsuite?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p08gq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699268494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone had any luck replicating and/or extracting data from Netsuite ERP database?&lt;/p&gt;\n\n&lt;p&gt;What tool did you use ?&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p08gq", "is_robot_indexable": true, "report_reasons": null, "author": "anotherwetsock", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p08gq/extracting_data_from_netsuite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p08gq/extracting_data_from_netsuite/", "subreddit_subscribers": 138229, "created_utc": 1699268494.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}