{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After working in this industry for 10+ years, I strongly feel like the data engineering space has a title problem. Data Science also has this issue, but I believe in Data Engineering it is even worse. Companies release vacancies for \"data engineer\" when the role can mean so many different things.\n\nI feel like a new set of titles is required to make the industry more mature. Such as:\n\n1. **Analytics Engineer (AE)**: Previously the data warehouse developer. Mainly works with SQL, Airflow, Python to transform data within the data warehouse. Person building analytics pipelines. A lot of DE work falls here.\n2. **Data Platform Engineer (DPE)**: An engineer who works on the platform, but not the pipelines. Cross-over with cloud engineer and dev/ops.\n3. **Data Streaming Engineer (DSE):** Specialized in data streaming, specifically; coding and patterns here are an entirely different ballgame from all of the above.\n\nToo many times I see companies ask for \"Data Engineer\" - expecting an analytics engineer with enough experience to do what the DPE does. Or companies who mainly to DSE, and end up with too many AEs in the pipeline.\n\nSome companies get this right by specifying that there is a \"focus\" area for a DE role. For example, Data Engineers with a heavy cloud focus, or Data Engineers focused on streaming (sometimes also called Big Data Engineer).\n\nMore specific DE roles would help both candidates and companies. Ideally the DE title should disappear completely and have several different roles falling under it.\n\n&amp;#x200B;\n\nWhat is your opinion? What titles would you propose?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Data Engineering has a title problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oe4z2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699197627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After working in this industry for 10+ years, I strongly feel like the data engineering space has a title problem. Data Science also has this issue, but I believe in Data Engineering it is even worse. Companies release vacancies for &amp;quot;data engineer&amp;quot; when the role can mean so many different things.&lt;/p&gt;\n\n&lt;p&gt;I feel like a new set of titles is required to make the industry more mature. Such as:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Analytics Engineer (AE)&lt;/strong&gt;: Previously the data warehouse developer. Mainly works with SQL, Airflow, Python to transform data within the data warehouse. Person building analytics pipelines. A lot of DE work falls here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Platform Engineer (DPE)&lt;/strong&gt;: An engineer who works on the platform, but not the pipelines. Cross-over with cloud engineer and dev/ops.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Streaming Engineer (DSE):&lt;/strong&gt; Specialized in data streaming, specifically; coding and patterns here are an entirely different ballgame from all of the above.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Too many times I see companies ask for &amp;quot;Data Engineer&amp;quot; - expecting an analytics engineer with enough experience to do what the DPE does. Or companies who mainly to DSE, and end up with too many AEs in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;Some companies get this right by specifying that there is a &amp;quot;focus&amp;quot; area for a DE role. For example, Data Engineers with a heavy cloud focus, or Data Engineers focused on streaming (sometimes also called Big Data Engineer).&lt;/p&gt;\n\n&lt;p&gt;More specific DE roles would help both candidates and companies. Ideally the DE title should disappear completely and have several different roles falling under it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is your opinion? What titles would you propose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oe4z2", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oe4z2/discussion_data_engineering_has_a_title_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oe4z2/discussion_data_engineering_has_a_title_problem/", "subreddit_subscribers": 138105, "created_utc": 1699197627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was tasked with finding a solution to the following problem:\n\nThe company uses excel for everything and each department has its own set of excel files with data that might overlap. I need to put everything \"into a database\" and the end users are of course supposed to still be able to input data, but none of them know sql. There also needs to be some data validation before the data is persisted.\n\nLater only I need to be able to get that data out into a datalake.\n\nI am considering using airtables for this, but I wanted to hear whether somebody here has a different idea, be that another tool that does the same or a completely different approach.\n\nThanks!", "author_fullname": "t2_f3x6oc10q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to get rid of excel sheets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o83kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699175550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was tasked with finding a solution to the following problem:&lt;/p&gt;\n\n&lt;p&gt;The company uses excel for everything and each department has its own set of excel files with data that might overlap. I need to put everything &amp;quot;into a database&amp;quot; and the end users are of course supposed to still be able to input data, but none of them know sql. There also needs to be some data validation before the data is persisted.&lt;/p&gt;\n\n&lt;p&gt;Later only I need to be able to get that data out into a datalake.&lt;/p&gt;\n\n&lt;p&gt;I am considering using airtables for this, but I wanted to hear whether somebody here has a different idea, be that another tool that does the same or a completely different approach.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17o83kd", "is_robot_indexable": true, "report_reasons": null, "author": "RydRychards", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o83kd/tool_to_get_rid_of_excel_sheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o83kd/tool_to_get_rid_of_excel_sheets/", "subreddit_subscribers": 138105, "created_utc": 1699175550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi everyone,\n\nI'm working with a large dataset (around 20GB) and need to perform data wrangling, transformation, and hypothesis testing using Python. However, the dataset is too large to load into memory all at once.\n\nI'm looking for a straightforward way to host this dataset in the cloud and run Python analysis without having to download anything, as I can't install software on my laptop. Ideally, I'd like to manage and analyze the data entirely through a browser-based interface.\n\nI thought hosting it as a database and connecting via Python would be simple, but I'm finding the multitude of cloud services to be quite overwhelming. Does anyone have experience with a similar situation or know of the best approach for this kind of task? I'm not tied to any specific technology as long as it gets the job done.\n\nAdditionally, if anyone has tutorials or resources on handling and analyzing big datasets in the cloud using Python, I would greatly appreciate it.\n\nThanks in advance for your guidance!", "author_fullname": "t2_34i32fyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help: How to work with large datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o9xo5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699183857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with a large dataset (around 20GB) and need to perform data wrangling, transformation, and hypothesis testing using Python. However, the dataset is too large to load into memory all at once.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a straightforward way to host this dataset in the cloud and run Python analysis without having to download anything, as I can&amp;#39;t install software on my laptop. Ideally, I&amp;#39;d like to manage and analyze the data entirely through a browser-based interface.&lt;/p&gt;\n\n&lt;p&gt;I thought hosting it as a database and connecting via Python would be simple, but I&amp;#39;m finding the multitude of cloud services to be quite overwhelming. Does anyone have experience with a similar situation or know of the best approach for this kind of task? I&amp;#39;m not tied to any specific technology as long as it gets the job done.&lt;/p&gt;\n\n&lt;p&gt;Additionally, if anyone has tutorials or resources on handling and analyzing big datasets in the cloud using Python, I would greatly appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17o9xo5", "is_robot_indexable": true, "report_reasons": null, "author": "SaluteOrbis", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o9xo5/help_how_to_work_with_large_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o9xo5/help_how_to_work_with_large_datasets/", "subreddit_subscribers": 138105, "created_utc": 1699183857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, relatively new to data engineering and our orgs data maturity is still pretty low. We use Snowflake and have views set up for our use case. We\u2019re not mature enough to use anything like dbt, spark or airflow so we handle all transformations in the view (it\u2019s not a ton of data). These are usually maintained by shared worksheets, but I\u2019ve been reading here that we should really version control these and introduce git into our workflow.\n\nMy question is how do we really get started with this? I understand git, but what should an ideal workflow look like?", "author_fullname": "t2_6pkcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you version control Snowflake queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o9yss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699183987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, relatively new to data engineering and our orgs data maturity is still pretty low. We use Snowflake and have views set up for our use case. We\u2019re not mature enough to use anything like dbt, spark or airflow so we handle all transformations in the view (it\u2019s not a ton of data). These are usually maintained by shared worksheets, but I\u2019ve been reading here that we should really version control these and introduce git into our workflow.&lt;/p&gt;\n\n&lt;p&gt;My question is how do we really get started with this? I understand git, but what should an ideal workflow look like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17o9yss", "is_robot_indexable": true, "report_reasons": null, "author": "PablanoPato", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o9yss/how_do_you_version_control_snowflake_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o9yss/how_do_you_version_control_snowflake_queries/", "subreddit_subscribers": 138105, "created_utc": 1699183987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.\n\n1. Talend - I hear is open source and easy to use. It's made as a low code/no code solution for ETL.\n\n2. Pyspark - I'm kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.\n\n3. Informatica - I heard this one is ancient, should I just avoid?\n\n4. Fivetran - I heard is relatively new but don't know much about it, pros and cons?\n\nAny others you would consider and for what use case?", "author_fullname": "t2_bpr9freq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ETL tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oljhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699217931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Talend - I hear is open source and easy to use. It&amp;#39;s made as a low code/no code solution for ETL.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Pyspark - I&amp;#39;m kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Informatica - I heard this one is ancient, should I just avoid?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Fivetran - I heard is relatively new but don&amp;#39;t know much about it, pros and cons?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any others you would consider and for what use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oljhd", "is_robot_indexable": true, "report_reasons": null, "author": "BuyHigh_S3llLow", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oljhd/best_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oljhd/best_etl_tool/", "subreddit_subscribers": 138105, "created_utc": 1699217931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need solution architectures for Cloudera / Databricks / Pure Cloud Services on MSFT AZ/AWS that include:\n\n\\- staging environments\n\n\\- CI/CD components and processes, also with respect to staging. (Usually its never the same in all stages)\n\n&amp;#x200B;\n\nI can only find solution architectures that show which core service components are stichted together. Sometimes CI/CD is included when serverless Cloud tools are used, but that not comprehensive enough (I.e. [https://aws.amazon.com/solutions/implementations/data-lake-solution/](https://aws.amazon.com/solutions/implementations/data-lake-solution/)) Staging environments are also rarely considered, especially \n\n&amp;#x200B;\n\nDo you know any sources?", "author_fullname": "t2_ag17bkmz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lakehouse Solution architectures that include CI/CD and staging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17og29m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699203063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need solution architectures for Cloudera / Databricks / Pure Cloud Services on MSFT AZ/AWS that include:&lt;/p&gt;\n\n&lt;p&gt;- staging environments&lt;/p&gt;\n\n&lt;p&gt;- CI/CD components and processes, also with respect to staging. (Usually its never the same in all stages)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can only find solution architectures that show which core service components are stichted together. Sometimes CI/CD is included when serverless Cloud tools are used, but that not comprehensive enough (I.e. &lt;a href=\"https://aws.amazon.com/solutions/implementations/data-lake-solution/\"&gt;https://aws.amazon.com/solutions/implementations/data-lake-solution/&lt;/a&gt;) Staging environments are also rarely considered, especially &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you know any sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?auto=webp&amp;s=8afacfc14dfed09cec0415cac7d36db9c3374c61", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=64a1b1322ed94c559cb213e6a08f3eb426a3fb0b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9edddfdb28bb0e92ceb041859aacef81ab9ed42e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de73cdc9da2d0b04938bb7d051ab1a3ceb783323", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60037829d2ce04de0705a2b45123d8ab7c12d41c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5a8f0da08b9281c578a8ab6f49a5b3f577ec9b8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a9a9c1c38bd543a7ea6b718e139a9c1e6b62d18", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17og29m", "is_robot_indexable": true, "report_reasons": null, "author": "Velocity911911", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17og29m/data_lakehouse_solution_architectures_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17og29m/data_lakehouse_solution_architectures_that/", "subreddit_subscribers": 138105, "created_utc": 1699203063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE transition into MLE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ooyfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699226980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ooyfj", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "subreddit_subscribers": 138105, "created_utc": 1699226980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been working in the data analysis field for a while. I enjoy creating automations that make things easier for others. Examples: Reports, calculations, programs.\n\nWondering, do DEs do any sort of automation? If so, what is there as a data engineer?", "author_fullname": "t2_7x2alm42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automations in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o6cx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699167426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working in the data analysis field for a while. I enjoy creating automations that make things easier for others. Examples: Reports, calculations, programs.&lt;/p&gt;\n\n&lt;p&gt;Wondering, do DEs do any sort of automation? If so, what is there as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17o6cx1", "is_robot_indexable": true, "report_reasons": null, "author": "InstaMastery", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o6cx1/automations_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o6cx1/automations_in_data_engineering/", "subreddit_subscribers": 138105, "created_utc": 1699167426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm writing a pipeline to download and process some data. The data are monthly and I need to process them from 1980-now on a frequent basis.\n\nCurrently, I fan out the download tasks per month from 1980 to now, so the graph looks like this the following image: [https://i.stack.imgur.com/iWRxh.png](https://i.stack.imgur.com/iWRxh.png). \n\nBasically, a many-to-one graph. I'm generating all of the download tasks inside of a for loop in airflow with the code below (the code is just an example that reads and writes files, simulating the real behavior so I can run it locally). I'm relying on airflow's parallel process limits to keep from overloading the download APIs.\n\nI was wondering if the extreme fan-out of API calls is a common airflow design pattern. Are there different better design patterns?\n\nExample code for reference (the multiple\\_outputs tasks replicate the actual functionality even though there's only one output)\n\n    with DAG(\n            'download_and_transform_data',\n            default_args=default_args,\n            description='Download monthly data from JRA and ERA',\n            schedule=timedelta(days=30),\n            catchup=False,\n    ) as dag:\n    @task(multiple_outputs=True,\n              retries=3)\n        def download_jra_data_task(month, year, output_directory):\n            outf = os.path.join(output_directory, f\"jra_{month}_{year}\")\n            with open(outf, \"w\") as dst:\n                dst.write(f\"{month}, {year} {time.time()}\")\n            return {\"file\": outf}\n    \n    \n    \n        @task(\n            multiple_outputs=True,\n            retries=3,\n        )\n        def download_era_data_task(month, year, output_directory):\n            outf = os.path.join(output_directory, f\"era_{month}_{year}\")\n            with open(outf, \"w\") as dst:\n                dst.write(f\"{month}, {year} {time.time()}\")\n            return {\"file\": outf}\n    \n        @task\n        def transform_task(file, output_dir):\n            print(f\"processing {file}\")\n            file = file[\"file\"]\n            with open(file, \"r\") as src:\n                buf = src.read()\n    \n            with open(os.path.join(output_dir, os.path.basename(file)), \"w\") as dst:\n                dst.write(f\"{buf} {time.time()}\\n\")\n    \n            return file\n    \n    \n        @task\n        def merge_and_remap_file(filelist, output_dir):\n            with open(os.path.join(output_dir, os.path.basename(filelist[0]) + \"_merged\"), \"w\") as dst:\n                for f in filelist:\n                    with open(f, \"r\") as src:\n                        buf = src.read()\n                    dst.write(f\"{buf} \\n\")\n    era_files = []\n        jra_files = []\n        for year in range(1980, 2022):\n            for month in range(1, 13):\n                jra_files.append(download_jra_data_task(month, year, os.path.join(STAGING_DIR, \"jra\")))\n                era_files.append(download_era_data_task(month, year, os.path.join(STAGING_DIR, \"era\")))\n    \n        jra_transform = []\n        for jra_file in jra_files:\n            # transform task also checks the data\n            f = transform_task(jra_file, os.path.join(WAREHOUSE_DIR, \"jra\"))\n            jra_transform.append(f)\n    \n        era_transform = []\n        for era_file in era_files:\n            # transform task also checks the data\n            transform_task(era_file, os.path.join(WAREHOUSE_DIR, \"era\"))\n            era_transform.append(f)\n    \n        merged_era = merge_and_remap_file(era_transform, os.path.join(PROD_DIR, \"era\"))\n        merged_jra = merge_and_remap_file(jra_transform, os.path.join(PROD_DIR, \"jra\"))\n\n&amp;#x200B;", "author_fullname": "t2_80aq2vu3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow design advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17of7x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699200704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m writing a pipeline to download and process some data. The data are monthly and I need to process them from 1980-now on a frequent basis.&lt;/p&gt;\n\n&lt;p&gt;Currently, I fan out the download tasks per month from 1980 to now, so the graph looks like this the following image: &lt;a href=\"https://i.stack.imgur.com/iWRxh.png\"&gt;https://i.stack.imgur.com/iWRxh.png&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;Basically, a many-to-one graph. I&amp;#39;m generating all of the download tasks inside of a for loop in airflow with the code below (the code is just an example that reads and writes files, simulating the real behavior so I can run it locally). I&amp;#39;m relying on airflow&amp;#39;s parallel process limits to keep from overloading the download APIs.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if the extreme fan-out of API calls is a common airflow design pattern. Are there different better design patterns?&lt;/p&gt;\n\n&lt;p&gt;Example code for reference (the multiple_outputs tasks replicate the actual functionality even though there&amp;#39;s only one output)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with DAG(\n        &amp;#39;download_and_transform_data&amp;#39;,\n        default_args=default_args,\n        description=&amp;#39;Download monthly data from JRA and ERA&amp;#39;,\n        schedule=timedelta(days=30),\n        catchup=False,\n) as dag:\n@task(multiple_outputs=True,\n          retries=3)\n    def download_jra_data_task(month, year, output_directory):\n        outf = os.path.join(output_directory, f&amp;quot;jra_{month}_{year}&amp;quot;)\n        with open(outf, &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{month}, {year} {time.time()}&amp;quot;)\n        return {&amp;quot;file&amp;quot;: outf}\n\n\n\n    @task(\n        multiple_outputs=True,\n        retries=3,\n    )\n    def download_era_data_task(month, year, output_directory):\n        outf = os.path.join(output_directory, f&amp;quot;era_{month}_{year}&amp;quot;)\n        with open(outf, &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{month}, {year} {time.time()}&amp;quot;)\n        return {&amp;quot;file&amp;quot;: outf}\n\n    @task\n    def transform_task(file, output_dir):\n        print(f&amp;quot;processing {file}&amp;quot;)\n        file = file[&amp;quot;file&amp;quot;]\n        with open(file, &amp;quot;r&amp;quot;) as src:\n            buf = src.read()\n\n        with open(os.path.join(output_dir, os.path.basename(file)), &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{buf} {time.time()}\\n&amp;quot;)\n\n        return file\n\n\n    @task\n    def merge_and_remap_file(filelist, output_dir):\n        with open(os.path.join(output_dir, os.path.basename(filelist[0]) + &amp;quot;_merged&amp;quot;), &amp;quot;w&amp;quot;) as dst:\n            for f in filelist:\n                with open(f, &amp;quot;r&amp;quot;) as src:\n                    buf = src.read()\n                dst.write(f&amp;quot;{buf} \\n&amp;quot;)\nera_files = []\n    jra_files = []\n    for year in range(1980, 2022):\n        for month in range(1, 13):\n            jra_files.append(download_jra_data_task(month, year, os.path.join(STAGING_DIR, &amp;quot;jra&amp;quot;)))\n            era_files.append(download_era_data_task(month, year, os.path.join(STAGING_DIR, &amp;quot;era&amp;quot;)))\n\n    jra_transform = []\n    for jra_file in jra_files:\n        # transform task also checks the data\n        f = transform_task(jra_file, os.path.join(WAREHOUSE_DIR, &amp;quot;jra&amp;quot;))\n        jra_transform.append(f)\n\n    era_transform = []\n    for era_file in era_files:\n        # transform task also checks the data\n        transform_task(era_file, os.path.join(WAREHOUSE_DIR, &amp;quot;era&amp;quot;))\n        era_transform.append(f)\n\n    merged_era = merge_and_remap_file(era_transform, os.path.join(PROD_DIR, &amp;quot;era&amp;quot;))\n    merged_jra = merge_and_remap_file(jra_transform, os.path.join(PROD_DIR, &amp;quot;jra&amp;quot;))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?auto=webp&amp;s=6cc3016f5696949bff654c85174e62630dd7f171", "width": 503, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c0193b7765a80eb2ed5f3b55ac981f6f017c01c", "width": 108, "height": 175}, {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f819052b32b0156730c2c2ff9cee9cbb367013b", "width": 216, "height": 351}, {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5c8979935001824e02a136d136b309c45bf97ec", "width": 320, "height": 520}], "variants": {}, "id": "8lBmeB85vuRIh8VU2soN7B9xheCfiYfJuAKjQdZi9O4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17of7x7", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous_Spring_7708", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17of7x7/airflow_design_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17of7x7/airflow_design_advice/", "subreddit_subscribers": 138105, "created_utc": 1699200704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm trying to get through the onboarding steps in Databricks and I'm essentially stuck at the beginning. I was able to get my aws credentials linked and a workspace created, however I'm not having any luck starting the sample SQL warehouse. I keep getting the error message \" **Cluster Start-up Delayed. Please wait while we continue to try and start the cluster. No action is required from you.**\"\n\nI've tried creating a separate SQL warehouse of a different size, and I've also tried creating a workspace in a different aws region (us-west-2 at first, then us-east-1) but I'm still not having any success.\n\nHas anyone experienced anything similar?", "author_fullname": "t2_4bn2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "databricks SQL warehouses won't start. Able to create workspaces, unsure if AWS permissions issue. Has anyone experienced this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oj25k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699211117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get through the onboarding steps in Databricks and I&amp;#39;m essentially stuck at the beginning. I was able to get my aws credentials linked and a workspace created, however I&amp;#39;m not having any luck starting the sample SQL warehouse. I keep getting the error message &amp;quot; &lt;strong&gt;Cluster Start-up Delayed. Please wait while we continue to try and start the cluster. No action is required from you.&lt;/strong&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried creating a separate SQL warehouse of a different size, and I&amp;#39;ve also tried creating a workspace in a different aws region (us-west-2 at first, then us-east-1) but I&amp;#39;m still not having any success.&lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced anything similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oj25k", "is_robot_indexable": true, "report_reasons": null, "author": "chronosphere", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oj25k/databricks_sql_warehouses_wont_start_able_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oj25k/databricks_sql_warehouses_wont_start_able_to/", "subreddit_subscribers": 138105, "created_utc": 1699211117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nOne of our vendors has an ancient database using SQL Anywhere 17. This is currently connected through an Integration Runtime via ODBC and queried from Azure Data Factory.\n\nI am trying to migrate us away from this setup and move it into Databricks, but cannot for the life of me figure out how to get the JDBC driver up and running in a notebook / cluster.\n\nHas anyone had to do this?", "author_fullname": "t2_v85tqybf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to Connect to a SQL Anywhere 17 Database From Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oj27s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699211122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;One of our vendors has an ancient database using SQL Anywhere 17. This is currently connected through an Integration Runtime via ODBC and queried from Azure Data Factory.&lt;/p&gt;\n\n&lt;p&gt;I am trying to migrate us away from this setup and move it into Databricks, but cannot for the life of me figure out how to get the JDBC driver up and running in a notebook / cluster.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oj27s", "is_robot_indexable": true, "report_reasons": null, "author": "YHJTC", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oj27s/struggling_to_connect_to_a_sql_anywhere_17/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oj27s/struggling_to_connect_to_a_sql_anywhere_17/", "subreddit_subscribers": 138105, "created_utc": 1699211122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\n\nI'm a data engineer in a startup for more than 2 years. I have some questions and your feedback are much appreciated:\n1. Best tips for landing a Data Engineer job at big companies (not necessarily tech, TC more than 120k)\n2. What kind of sources you use for interview preparation? \n\nThanks,", "author_fullname": "t2_bfz4zq58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Canada Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o309a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699153840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineer in a startup for more than 2 years. I have some questions and your feedback are much appreciated:\n1. Best tips for landing a Data Engineer job at big companies (not necessarily tech, TC more than 120k)\n2. What kind of sources you use for interview preparation? &lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17o309a", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Ad_8085", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o309a/canada_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o309a/canada_job_market/", "subreddit_subscribers": 138105, "created_utc": 1699153840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About me:\n\n\\- 5 years experience as a data analyst, heavily used Power BI and relational DBs.\n\n\\- Have really sharpened my SQL and Python skills lately. Have a data scraping project on my resume.\n\nI'm going to start applying for BI Engineer/Analytics Engineer roles. What should. I try to focus on next? dbt and Snowflake certs? Cloud cert? Airflow project? Any feedback is greatly appreciated.", "author_fullname": "t2_15g1bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About to start applying for jobs, what do I need to focus on next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17olilb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699217858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About me:&lt;/p&gt;\n\n&lt;p&gt;- 5 years experience as a data analyst, heavily used Power BI and relational DBs.&lt;/p&gt;\n\n&lt;p&gt;- Have really sharpened my SQL and Python skills lately. Have a data scraping project on my resume.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to start applying for BI Engineer/Analytics Engineer roles. What should. I try to focus on next? dbt and Snowflake certs? Cloud cert? Airflow project? Any feedback is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17olilb", "is_robot_indexable": true, "report_reasons": null, "author": "ImTedsBestFriend", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17olilb/about_to_start_applying_for_jobs_what_do_i_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17olilb/about_to_start_applying_for_jobs_what_do_i_need/", "subreddit_subscribers": 138105, "created_utc": 1699217858.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}