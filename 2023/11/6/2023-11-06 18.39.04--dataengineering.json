{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "During my time in data engineering, I've noticed a lot of data engineers discount their own experience compared to software engineers who do not work in data.  Do a lot of data engineers not consider themselves a type of software engineer?\n\n\n\nI find that strange, because during my career I was able to do a lot of work in python, java, SQL, and Terraform.  I also have a lot of experience setting up CI/CD pipelines and building cloud infrastructure.  In many cases, I feel like our field overlaps a lot with backend engineering.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why don't a lot of data engineers consider themselves software engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p20y6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699275064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During my time in data engineering, I&amp;#39;ve noticed a lot of data engineers discount their own experience compared to software engineers who do not work in data.  Do a lot of data engineers not consider themselves a type of software engineer?&lt;/p&gt;\n\n&lt;p&gt;I find that strange, because during my career I was able to do a lot of work in python, java, SQL, and Terraform.  I also have a lot of experience setting up CI/CD pipelines and building cloud infrastructure.  In many cases, I feel like our field overlaps a lot with backend engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p20y6", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17p20y6/why_dont_a_lot_of_data_engineers_consider/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p20y6/why_dont_a_lot_of_data_engineers_consider/", "subreddit_subscribers": 138209, "created_utc": 1699275064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pretty often while browsing this sub I see people put down 'low code/no code' data engineering solutions, and promoting ETL processes running on engines like Spark as opposed to transforming data in SQL. The reasons stated are usually for being easier to follow software engineering practices with 'real' code.\n\nHowever, it's undeniable that there exist cloud-based analytics warehouses that significantly outperform the traditional 'real code' frameworks when it comes to data transformation. I have transformations running in BigQuery where my testing has shown the costs of running on BQ to be about four or five times cheaper than with PySpark. I've read articles that back up this performance gap and it seems to be well accepted that tools like BigQuery significantly outperform traditional batch processing frameworks.\n\nOn a personal level I would prefer to be writing these transformations in Python - it's easier, it's cleaner, it's more versatile. With functions written in BigQuery we're usually ending up with long queries featuring a mess of joins that are hard to troubleshoot when things start going wrong.\n\nBut if I go to my manager and say \"I would rather write these transformations in Spark - it will be significantly more expensive but I will find it easier\" then I don't think it's going to go down well.\n\nSo I'd like to put it to this sub - if we have transformation processes that perform extremely well in BigQuery and our evidence shows that it would be significantly more expensive to move to other technologies, how could we justify moving away from a 'low code/no code' stack when it comes to transformations?", "author_fullname": "t2_2jmvd5bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shunning 'low code/no code' solutions in a world where analytics warehouses provide great performance.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ow2ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699249969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty often while browsing this sub I see people put down &amp;#39;low code/no code&amp;#39; data engineering solutions, and promoting ETL processes running on engines like Spark as opposed to transforming data in SQL. The reasons stated are usually for being easier to follow software engineering practices with &amp;#39;real&amp;#39; code.&lt;/p&gt;\n\n&lt;p&gt;However, it&amp;#39;s undeniable that there exist cloud-based analytics warehouses that significantly outperform the traditional &amp;#39;real code&amp;#39; frameworks when it comes to data transformation. I have transformations running in BigQuery where my testing has shown the costs of running on BQ to be about four or five times cheaper than with PySpark. I&amp;#39;ve read articles that back up this performance gap and it seems to be well accepted that tools like BigQuery significantly outperform traditional batch processing frameworks.&lt;/p&gt;\n\n&lt;p&gt;On a personal level I would prefer to be writing these transformations in Python - it&amp;#39;s easier, it&amp;#39;s cleaner, it&amp;#39;s more versatile. With functions written in BigQuery we&amp;#39;re usually ending up with long queries featuring a mess of joins that are hard to troubleshoot when things start going wrong.&lt;/p&gt;\n\n&lt;p&gt;But if I go to my manager and say &amp;quot;I would rather write these transformations in Spark - it will be significantly more expensive but I will find it easier&amp;quot; then I don&amp;#39;t think it&amp;#39;s going to go down well.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;d like to put it to this sub - if we have transformation processes that perform extremely well in BigQuery and our evidence shows that it would be significantly more expensive to move to other technologies, how could we justify moving away from a &amp;#39;low code/no code&amp;#39; stack when it comes to transformations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ow2ku", "is_robot_indexable": true, "report_reasons": null, "author": "Objectionne", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ow2ku/shunning_low_codeno_code_solutions_in_a_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ow2ku/shunning_low_codeno_code_solutions_in_a_world/", "subreddit_subscribers": 138209, "created_utc": 1699249969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.\n\n1. Talend - I hear is open source and easy to use. It's made as a low code/no code solution for ETL.\n\n2. Pyspark - I'm kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.\n\n3. Informatica - I heard this one is ancient, should I just avoid?\n\n4. Fivetran - I heard is relatively new but don't know much about it, pros and cons?\n\nAny others you would consider and for what use case?", "author_fullname": "t2_bpr9freq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ETL tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oljhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699217931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been researching different ETL tools to get an idea or when to use each but thought I can drop in here to see what others think.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Talend - I hear is open source and easy to use. It&amp;#39;s made as a low code/no code solution for ETL.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Pyspark - I&amp;#39;m kinda learning this one already on my own already as I already know python/pandas and my tech stack kinda aligns with learning this eventually anyways.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Informatica - I heard this one is ancient, should I just avoid?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Fivetran - I heard is relatively new but don&amp;#39;t know much about it, pros and cons?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any others you would consider and for what use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oljhd", "is_robot_indexable": true, "report_reasons": null, "author": "BuyHigh_S3llLow", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oljhd/best_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oljhd/best_etl_tool/", "subreddit_subscribers": 138209, "created_utc": 1699217931.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've joined a small org as a BI analyst but have been asked to build a data platform with support from an external consultant.  \n\nConsultant wants to use Fabric for everything, I raised a concern (as advised by many here on r/DEng) that Fabric is not yet ready too use as a primary system. \n\nHe responded that only some of the components are new, and as many are rebranded (eg PowerBI is now under the fabric banner) and I shouldn't worry.\n\nSo which components of fabric (other than powerBI) are deployment ready?", "author_fullname": "t2_2s6myxsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Fabric components are stable and deployment ready?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oyhgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699260450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve joined a small org as a BI analyst but have been asked to build a data platform with support from an external consultant.  &lt;/p&gt;\n\n&lt;p&gt;Consultant wants to use Fabric for everything, I raised a concern (as advised by many here on &lt;a href=\"/r/DEng\"&gt;r/DEng&lt;/a&gt;) that Fabric is not yet ready too use as a primary system. &lt;/p&gt;\n\n&lt;p&gt;He responded that only some of the components are new, and as many are rebranded (eg PowerBI is now under the fabric banner) and I shouldn&amp;#39;t worry.&lt;/p&gt;\n\n&lt;p&gt;So which components of fabric (other than powerBI) are deployment ready?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oyhgt", "is_robot_indexable": true, "report_reasons": null, "author": "Dog_In_A_Human_Suit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oyhgt/which_fabric_components_are_stable_and_deployment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oyhgt/which_fabric_components_are_stable_and_deployment/", "subreddit_subscribers": 138209, "created_utc": 1699260450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I am a business analyst and planning to have an initiative to have the business glossary and data dictionary, mostly my target audience will be the stakeholders, customers and non technical people.\n\nTo give you a background, my current project is a web based application, coded in java. So mostly the data validation is configured through java. In line with that, I want that to translate by creating the DD.\n\nData Dictionary that I'm planning to do is kind of web based application that connects to the git/java code, so every time that there are changes in field validations it automatically reflects in the DD.\n\nFor example;\nPersonal name : Varchar (20), minimum 10\n\nDo you have any recommendation tools that I can use?", "author_fullname": "t2_4z8wla8ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool for creating Business Glossary and Data Dictionary", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oygw9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699260371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a business analyst and planning to have an initiative to have the business glossary and data dictionary, mostly my target audience will be the stakeholders, customers and non technical people.&lt;/p&gt;\n\n&lt;p&gt;To give you a background, my current project is a web based application, coded in java. So mostly the data validation is configured through java. In line with that, I want that to translate by creating the DD.&lt;/p&gt;\n\n&lt;p&gt;Data Dictionary that I&amp;#39;m planning to do is kind of web based application that connects to the git/java code, so every time that there are changes in field validations it automatically reflects in the DD.&lt;/p&gt;\n\n&lt;p&gt;For example;\nPersonal name : Varchar (20), minimum 10&lt;/p&gt;\n\n&lt;p&gt;Do you have any recommendation tools that I can use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oygw9", "is_robot_indexable": true, "report_reasons": null, "author": "Kizzmexoxo", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oygw9/best_tool_for_creating_business_glossary_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oygw9/best_tool_for_creating_business_glossary_and_data/", "subreddit_subscribers": 138209, "created_utc": 1699260371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a junior data engineer and i perform an automated ETL system that extract data from multiple excel sheets, transform them and then load them into a destination database table, my problem is the excel sheets have different column names and different column orders from each other and from the destination database table, so i want to make the mapping process automated (not to create a mapping dictionary that specify the old column name with the new column name)", "author_fullname": "t2_g2wxrrado", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oxw83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699257790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a junior data engineer and i perform an automated ETL system that extract data from multiple excel sheets, transform them and then load them into a destination database table, my problem is the excel sheets have different column names and different column orders from each other and from the destination database table, so i want to make the mapping process automated (not to create a mapping dictionary that specify the old column name with the new column name)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oxw83", "is_robot_indexable": true, "report_reasons": null, "author": "OtherCan6354", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oxw83/need_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oxw83/need_solution/", "subreddit_subscribers": 138209, "created_utc": 1699257790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE transition into MLE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ooyfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699226980.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible for a DE to transition into MLE? I have been learning about NLP and it\u2019s been so interesting, and I would really want to learn more about MLE works. Given that it\u2019s possible for a DE to transition into MLE, what topics should I study to get a shot?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ooyfj", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ooyfj/de_transition_into_mle/", "subreddit_subscribers": 138209, "created_utc": 1699226980.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Requirement is to write data in RDS Postgre tables to Hive Tables in  Databricks. Databricks environment is externally hosted, can either be on AWS or Azure. How to do the same securely?", "author_fullname": "t2_9rp533dt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write AWS RDS Postgres tables to Hive tables in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p5vnv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699286159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Requirement is to write data in RDS Postgre tables to Hive Tables in  Databricks. Databricks environment is externally hosted, can either be on AWS or Azure. How to do the same securely?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p5vnv", "is_robot_indexable": true, "report_reasons": null, "author": "prasanna_aatma", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p5vnv/write_aws_rds_postgres_tables_to_hive_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p5vnv/write_aws_rds_postgres_tables_to_hive_tables_in/", "subreddit_subscribers": 138209, "created_utc": 1699286159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products | Evolve: Part 4/4 Advanced SLOs, Feedback Loops, Optimised Data Product, and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17p21jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CPo-qUNcpXogigmEZh7oJ4UqfS2IXKs7kEMtJFETld0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699275121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/evolving-data-products", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?auto=webp&amp;s=1221a1dce31f3afe76700003ecc0b1ddb6be9b66", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65be0a310cfc5f7368c888c1638e9db48dc08a1f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=84058159ac22b55a3f202ff5dc450404dbb2c6b3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b88b81f6bd64d16a333eaa562695fb58dd2d057", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6d6bfb73a928498e52dc9fa0684118e28d75f4c2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8de6d0063f9da38114ffd20967e62af2a6f8111a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Rop2sdhd_CVzU2H4lV1I2lzz8cC_jk7A9wp3KZeZnkc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c6b4f396c1c77a4b36e6b36f63fb6a313090f653", "width": 1080, "height": 540}], "variants": {}, "id": "XJZ-DYAnwfbcnEScRfgAlIRNXlSes7wfrL03G0CXFcI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17p21jc", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p21jc/how_to_build_data_products_evolve_part_44/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/evolving-data-products", "subreddit_subscribers": 138209, "created_utc": 1699275121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I was tasked with a certain requirement as the title suggests, I need to push/export the bigquery tables via API so the client can fetch the data via same API calls. I tried checking via official documentation but except granting permissions or exporting to GCS buckets I couldn\u2019t come up with anything. \n\nPlease guide me if I\u2019ve missed out something. Open to suggestions on the same.\n\nThank you", "author_fullname": "t2_3qc9b4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exporting BigQuery Tables via API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17owput", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699252592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I was tasked with a certain requirement as the title suggests, I need to push/export the bigquery tables via API so the client can fetch the data via same API calls. I tried checking via official documentation but except granting permissions or exporting to GCS buckets I couldn\u2019t come up with anything. &lt;/p&gt;\n\n&lt;p&gt;Please guide me if I\u2019ve missed out something. Open to suggestions on the same.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17owput", "is_robot_indexable": true, "report_reasons": null, "author": "apache444", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17owput/exporting_bigquery_tables_via_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17owput/exporting_bigquery_tables_via_api/", "subreddit_subscribers": 138209, "created_utc": 1699252592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everybody, I'm enrolled in a Data Science Master In Paris, with two internship experiences, 6 months as an Azure Data Engineer and 3 months as a Data Scientist. I am actively seeking an end-of-studies data engineer Internship in Paris or Europe starting in March 2024. I have applied many times and had very little feedback. Is it normal due to the high competition? or there is a problem with my Resume? Should I be worried or it's too early?\n\nPlease check my resume here, I would be super grateful for any advice regarding my resume or any opportunities that I can apply for.\n\nresume : [https://drive.google.com/file/d/1fh2V8aqDMnMXcI\\_Frr4UjTbxbEM1uVUh/view?usp=drive\\_link](https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link)", "author_fullname": "t2_g0flbs20b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Resume for an End-of-studies Internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17p7yg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699294802.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699291599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody, I&amp;#39;m enrolled in a Data Science Master In Paris, with two internship experiences, 6 months as an Azure Data Engineer and 3 months as a Data Scientist. I am actively seeking an end-of-studies data engineer Internship in Paris or Europe starting in March 2024. I have applied many times and had very little feedback. Is it normal due to the high competition? or there is a problem with my Resume? Should I be worried or it&amp;#39;s too early?&lt;/p&gt;\n\n&lt;p&gt;Please check my resume here, I would be super grateful for any advice regarding my resume or any opportunities that I can apply for.&lt;/p&gt;\n\n&lt;p&gt;resume : &lt;a href=\"https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link\"&gt;https://drive.google.com/file/d/1fh2V8aqDMnMXcI_Frr4UjTbxbEM1uVUh/view?usp=drive_link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p7yg5", "is_robot_indexable": true, "report_reasons": null, "author": "med_maz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p7yg5/data_engineering_resume_for_an_endofstudies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p7yg5/data_engineering_resume_for_an_endofstudies/", "subreddit_subscribers": 138209, "created_utc": 1699291599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, \n\nI have a system I'm looking to first \"batch\" then stream data to conditionally. Essentially the data has dates associated with it and the target system I want to deliver the data to can't accept the data too far before its associated date, but the data can be generated for any date in the future. So I'm looking to design a system that X days before a date will deliver all previously received data for that date then begin to stream (kafka) any new records or changes near real time once within the window. \n\nDoes this pattern/design have a name? Or are there any established patterns that would work well for this use case? It's a surprisingly hard thing to Google... \n\nThanks!", "author_fullname": "t2_pgfxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to best approach a conditional datastream? Is there an established design for this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17p713g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699289237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, &lt;/p&gt;\n\n&lt;p&gt;I have a system I&amp;#39;m looking to first &amp;quot;batch&amp;quot; then stream data to conditionally. Essentially the data has dates associated with it and the target system I want to deliver the data to can&amp;#39;t accept the data too far before its associated date, but the data can be generated for any date in the future. So I&amp;#39;m looking to design a system that X days before a date will deliver all previously received data for that date then begin to stream (kafka) any new records or changes near real time once within the window. &lt;/p&gt;\n\n&lt;p&gt;Does this pattern/design have a name? Or are there any established patterns that would work well for this use case? It&amp;#39;s a surprisingly hard thing to Google... &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p713g", "is_robot_indexable": true, "report_reasons": null, "author": "Sanity__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p713g/how_to_best_approach_a_conditional_datastream_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p713g/how_to_best_approach_a_conditional_datastream_is/", "subreddit_subscribers": 138209, "created_utc": 1699289237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,  \n\n\nI am working on a Pipeline in Azure Data Factory which gets the last modified date data from ADLG2 &amp; On-prem storage.  I have a situation where multiple files are uploaded to the container with a difference of seconds and minutes.  \n\n\nThe issue is all these files are meant to arrive at the same time so with the issue of different time upload and want to create a function that ignores the Timestamp usually generate from \"Last Modified\" date and just consider only the Date (yyyy-MM-dd).\n\nI would love if anyone can help me because this is really a big issue for me. Also links to materials will help.  \n\n\nAlso in a scenario where let say 5-10 files enters the same time using the Last Modified Date activity in ADF will it pick all files.  \n\n\nThanks SOS.", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get Date only using the Azure Data Factory Get Meta Data (Last Modified)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p52e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699283946.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,  &lt;/p&gt;\n\n&lt;p&gt;I am working on a Pipeline in Azure Data Factory which gets the last modified date data from ADLG2 &amp;amp; On-prem storage.  I have a situation where multiple files are uploaded to the container with a difference of seconds and minutes.  &lt;/p&gt;\n\n&lt;p&gt;The issue is all these files are meant to arrive at the same time so with the issue of different time upload and want to create a function that ignores the Timestamp usually generate from &amp;quot;Last Modified&amp;quot; date and just consider only the Date (yyyy-MM-dd).&lt;/p&gt;\n\n&lt;p&gt;I would love if anyone can help me because this is really a big issue for me. Also links to materials will help.  &lt;/p&gt;\n\n&lt;p&gt;Also in a scenario where let say 5-10 files enters the same time using the Last Modified Date activity in ADF will it pick all files.  &lt;/p&gt;\n\n&lt;p&gt;Thanks SOS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17p52e3", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p52e3/how_to_get_date_only_using_the_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p52e3/how_to_get_date_only_using_the_azure_data_factory/", "subreddit_subscribers": 138209, "created_utc": 1699283946.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With my team, we're testing out our framework (Versatile Data Kit) and Jupyter notebooks, and as part of it, we're organizing a free workshop on ingestion and anonymization.   \n\n\nThe workshop covers the basics of DE with Python and SQL, is very easy to follow, hands-on, 1 h, ask-any-questions experience in a small group.   \n\n\nThis is the second workshop we're organizing on the topic, and if there are any suggestions or requests on other topics we could demo, I'm also open to hear! ", "author_fullname": "t2_49cfbl1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE workshop - Ingestion and Anonymization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p1vju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699274538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With my team, we&amp;#39;re testing out our framework (Versatile Data Kit) and Jupyter notebooks, and as part of it, we&amp;#39;re organizing a free workshop on ingestion and anonymization.   &lt;/p&gt;\n\n&lt;p&gt;The workshop covers the basics of DE with Python and SQL, is very easy to follow, hands-on, 1 h, ask-any-questions experience in a small group.   &lt;/p&gt;\n\n&lt;p&gt;This is the second workshop we&amp;#39;re organizing on the topic, and if there are any suggestions or requests on other topics we could demo, I&amp;#39;m also open to hear! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17p1vju", "is_robot_indexable": true, "report_reasons": null, "author": "zverulacis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p1vju/de_workshop_ingestion_and_anonymization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p1vju/de_workshop_ingestion_and_anonymization/", "subreddit_subscribers": 138209, "created_utc": 1699274538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone had any luck replicating and/or extracting data from Netsuite ERP database?\n\nWhat tool did you use ?\n\nCheers", "author_fullname": "t2_legyu6zou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting data from Netsuite?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p08gq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699268494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone had any luck replicating and/or extracting data from Netsuite ERP database?&lt;/p&gt;\n\n&lt;p&gt;What tool did you use ?&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17p08gq", "is_robot_indexable": true, "report_reasons": null, "author": "anotherwetsock", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17p08gq/extracting_data_from_netsuite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17p08gq/extracting_data_from_netsuite/", "subreddit_subscribers": 138209, "created_utc": 1699268494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked to built an entire kind of lakehouse for a company, but they are trying to save as much money as possible in managed solutions and rather run everything they can in their own kubernetes clusters.\n\n&amp;#x200B;\n\nI have been googling around and the best seems to be [this google spark operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator). Now I am somewhat worried of running this in production as it's on beta and I am afraid they might stop supporting it anytime soon.\n\n&amp;#x200B;\n\nI would appreciate if someone can explain, if they are running their own Spark on k8s and a little bit of information of how they are doing it.", "author_fullname": "t2_c8ep1w3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone here self-hosting/managing Spark in kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ozw2w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699267034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked to built an entire kind of lakehouse for a company, but they are trying to save as much money as possible in managed solutions and rather run everything they can in their own kubernetes clusters.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been googling around and the best seems to be &lt;a href=\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator\"&gt;this google spark operator&lt;/a&gt;. Now I am somewhat worried of running this in production as it&amp;#39;s on beta and I am afraid they might stop supporting it anytime soon.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would appreciate if someone can explain, if they are running their own Spark on k8s and a little bit of information of how they are doing it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?auto=webp&amp;s=93a8620a9fb756bb2d41d73313aff9ec40dbfb7e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d31b4e8127587dba4d34473a4c8562cf1e8ef066", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86da0aa24a3ed0982c3ba8bfce238ff0e26c26be", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59e656cb25b331832ae037e2216b1e4d11140c20", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1d48e5729a4afae65915db1a16e6bf0547d1587e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ccd3395b466cba9ae37c3616bdf313330a3ada67", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZkS_30QD3G71FeERL3QPxQ_z3CYyQgZs5I-n1GXFZFo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8cc0cbd2953e85786defb3c91f9834ee898272f2", "width": 1080, "height": 540}], "variants": {}, "id": "-6TotB3PDankL33Um5RtT2CE60CraQgTYWZDRJ6I66U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ozw2w", "is_robot_indexable": true, "report_reasons": null, "author": "Dataeng92", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ozw2w/is_anyone_here_selfhostingmanaging_spark_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ozw2w/is_anyone_here_selfhostingmanaging_spark_in/", "subreddit_subscribers": 138209, "created_utc": 1699267034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I'm trying to get through the onboarding steps in Databricks and I'm essentially stuck at the beginning. I was able to get my aws credentials linked and a workspace created, however I'm not having any luck starting the sample SQL warehouse. I keep getting the error message \" **Cluster Start-up Delayed. Please wait while we continue to try and start the cluster. No action is required from you.**\"\n\nI've tried creating a separate SQL warehouse of a different size, and I've also tried creating a workspace in a different aws region (us-west-2 at first, then us-east-1) but I'm still not having any success.\n\nHas anyone experienced anything similar?", "author_fullname": "t2_4bn2b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "databricks SQL warehouses won't start. Able to create workspaces, unsure if AWS permissions issue. Has anyone experienced this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oj25k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699211117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to get through the onboarding steps in Databricks and I&amp;#39;m essentially stuck at the beginning. I was able to get my aws credentials linked and a workspace created, however I&amp;#39;m not having any luck starting the sample SQL warehouse. I keep getting the error message &amp;quot; &lt;strong&gt;Cluster Start-up Delayed. Please wait while we continue to try and start the cluster. No action is required from you.&lt;/strong&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried creating a separate SQL warehouse of a different size, and I&amp;#39;ve also tried creating a workspace in a different aws region (us-west-2 at first, then us-east-1) but I&amp;#39;m still not having any success.&lt;/p&gt;\n\n&lt;p&gt;Has anyone experienced anything similar?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oj25k", "is_robot_indexable": true, "report_reasons": null, "author": "chronosphere", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oj25k/databricks_sql_warehouses_wont_start_able_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oj25k/databricks_sql_warehouses_wont_start_able_to/", "subreddit_subscribers": 138209, "created_utc": 1699211117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nOne of our vendors has an ancient database using SQL Anywhere 17. This is currently connected through an Integration Runtime via ODBC and queried from Azure Data Factory.\n\nI am trying to migrate us away from this setup and move it into Databricks, but cannot for the life of me figure out how to get the JDBC driver up and running in a notebook / cluster.\n\nHas anyone had to do this?", "author_fullname": "t2_v85tqybf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to Connect to a SQL Anywhere 17 Database From Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oj27s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699211122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;One of our vendors has an ancient database using SQL Anywhere 17. This is currently connected through an Integration Runtime via ODBC and queried from Azure Data Factory.&lt;/p&gt;\n\n&lt;p&gt;I am trying to migrate us away from this setup and move it into Databricks, but cannot for the life of me figure out how to get the JDBC driver up and running in a notebook / cluster.&lt;/p&gt;\n\n&lt;p&gt;Has anyone had to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17oj27s", "is_robot_indexable": true, "report_reasons": null, "author": "YHJTC", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oj27s/struggling_to_connect_to_a_sql_anywhere_17/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oj27s/struggling_to_connect_to_a_sql_anywhere_17/", "subreddit_subscribers": 138209, "created_utc": 1699211122.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}