{"kind": "Listing", "data": {"after": "t3_181pvl5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_c4gff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Heads up for a data corruption bug in ZFS, few versions affected, might have started at 2.1.x, but many reports on 2.2.x", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_1821mpr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/593qtb3dHwI0ViAkWS8yjVaKJtsekhPBzPs1gFsi_B4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700747503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/openzfs/zfs/issues/15526", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?auto=webp&amp;s=3d75edbf9d4374ef534a321594c3b5b3c63a4d45", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7220162628377636e38962e9e58d1f58468c3455", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b73d47e8fa1d526fe4f2c477ea8721a8aabdd41", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa9c7fb0177ed9c025427cb72595149f26e1dccb", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5ab386af01f72e6ea5187bf53081da90623ea4dc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d58ca2b0c12431f6cd47655d775cc8e7d822b7df", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/5tgxp9vJsEE6NG2RoxEQzIEPUXUn4LU-f1y58Go7n-U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3d2833479980bb5b2f3efb25acc54426bbd41084", "width": 1080, "height": 540}], "variants": {}, "id": "OI58A6yzSBQ2nmfk0t6nJlBsRz8Hv6FTc1BQ-SNIOE0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1821mpr", "is_robot_indexable": true, "report_reasons": null, "author": "vitzli-mmc", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1821mpr/heads_up_for_a_data_corruption_bug_in_zfs_few/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://github.com/openzfs/zfs/issues/15526", "subreddit_subscribers": 713885, "created_utc": 1700747503.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_cchf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Costco - 14TB for $150", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_181uqfh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p8Vt6YZEHJT_5M8vvGp00F37vzs44YX1qirb1GgBOcw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700720523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cobi7fkaj12c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?auto=webp&amp;s=ac7b8b897f8879bdd35bf186b03199b9084748cf", "width": 1422, "height": 4271}, "resolutions": [{"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44ed802c9d3e2a16e937bbbf5bf47b0c2478745e", "width": 108, "height": 216}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07080cc81937293c80f4443033bea2ee094ed203", "width": 216, "height": 432}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=012da5e26ae75fb3b15e38d839a08c83dd2a703d", "width": 320, "height": 640}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bae8c5d3466f11353bd084b5f7a041cd1943c586", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5d45806a8cb8d991bd3a140bd6d5f26b087fce09", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/cobi7fkaj12c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c12ee3423d83af5dcbc2c3b55100937c6c7a3df2", "width": 1080, "height": 2160}], "variants": {}, "id": "JlVSP5fs4CmPFCBIQvyLeKlBP87Sc-eHoX0LLw7vkkU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "181uqfh", "is_robot_indexable": true, "report_reasons": null, "author": "Atanzarian", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181uqfh/costco_14tb_for_150/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cobi7fkaj12c1.jpg", "subreddit_subscribers": 713885, "created_utc": 1700720523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have recently thought about burning some data to Blu-ray and therefore looked for some cheap blank discs. To my surprise, higher density Blu-rays seem to be much more expensive than lower density ones. In my country (Germany) for example, I could buy a 25 GB BD for 0,44\u20ac. A 100 GB BD would cost me 8,77\u20ac! At that price, it would be more efficient to store 100 GB on four 25 GB discs instead of one 100 GB disc (1,76\u20ac vs. 8,77\u20ac). Sure, if it is one file I would have to split it first and combine it again when I want to access the data, but that effort seems to be worth it.\n\nWhy are high capacity Blu-rays so much more expensive, especially compared to HDDs or SSDs where the price per GB/TB usually drops with higher capacity?", "author_fullname": "t2_2toymaqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are 100 GB Blu-rays so much more expensive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181q19n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700704486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have recently thought about burning some data to Blu-ray and therefore looked for some cheap blank discs. To my surprise, higher density Blu-rays seem to be much more expensive than lower density ones. In my country (Germany) for example, I could buy a 25 GB BD for 0,44\u20ac. A 100 GB BD would cost me 8,77\u20ac! At that price, it would be more efficient to store 100 GB on four 25 GB discs instead of one 100 GB disc (1,76\u20ac vs. 8,77\u20ac). Sure, if it is one file I would have to split it first and combine it again when I want to access the data, but that effort seems to be worth it.&lt;/p&gt;\n\n&lt;p&gt;Why are high capacity Blu-rays so much more expensive, especially compared to HDDs or SSDs where the price per GB/TB usually drops with higher capacity?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181q19n", "is_robot_indexable": true, "report_reasons": null, "author": "KingKevin-23", "discussion_type": null, "num_comments": 48, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181q19n/why_are_100_gb_blurays_so_much_more_expensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181q19n/why_are_100_gb_blurays_so_much_more_expensive/", "subreddit_subscribers": 713885, "created_utc": 1700704486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am 99% of the way to pulling the trigger on a custom NAS build for backup and a home server. \n\nThen I see this thing. 4 Ethernet, 2 nvme, celadon with quicksync. Honestly I would never be able to build something this clean. \n\nHas anyone ever heard of this?", "author_fullname": "t2_11dcf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Has anyone ever seen this thing? No trace on the internet.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"acil8be4852c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 149, "x": 108, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=22ddb27eb47cb7036458bfc203f951e4a0ef852d"}, {"y": 299, "x": 216, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1f1dca6047d434c9222620d41e1c760598ac69a"}, {"y": 444, "x": 320, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1ca2580010b20282fdc19f10b33a2b3c8b49122"}, {"y": 888, "x": 640, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0d506e41c1fa9ff09aa7261a6cfdac55b688c19b"}, {"y": 1332, "x": 960, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ee6281e2c0e047b3940da2805cde26bbea690e1"}, {"y": 1499, "x": 1080, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c0c507cbe622f40013d0ebc52d8779088626d9f9"}], "s": {"y": 1624, "x": 1170, "u": "https://preview.redd.it/acil8be4852c1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=0a452fa2bb57e8ab982b9d94f5918603da36fbec"}, "id": "acil8be4852c1"}, "cokroae4852c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99700f838746cd6de7d4776226bd9989bc918153"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=981e3941d2c13e5ae318ad659a5d86e60933cf74"}, {"y": 427, "x": 320, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eeb0aee5de4287d04bb1845ea0148f87a5c0733d"}, {"y": 855, "x": 640, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20fcb9ba395ea8cebffdac69d749b9fed954dcee"}, {"y": 1283, "x": 960, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7ffc927d917682645b7d1f15d6a80c65074ba13d"}, {"y": 1443, "x": 1080, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=06210b0cb8b908dcf500ff3aaa16aad11ead6d94"}], "s": {"y": 1564, "x": 1170, "u": "https://preview.redd.it/cokroae4852c1.jpg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=2426913794c29753d95af6f6f1b7b1b1a207513a"}, "id": "cokroae4852c1"}}, "name": "t3_18281b0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 90, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "acil8be4852c1", "id": 364351604}, {"media_id": "cokroae4852c1", "id": 364351605}]}, "link_flair_text": "Backup", "can_mod_post": false, "score": 90, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NUYBYS8BxlMAT44eoUQRQfrJRXovbOnwDTW-KQ-v1-c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700765195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 99% of the way to pulling the trigger on a custom NAS build for backup and a home server. &lt;/p&gt;\n\n&lt;p&gt;Then I see this thing. 4 Ethernet, 2 nvme, celadon with quicksync. Honestly I would never be able to build something this clean. &lt;/p&gt;\n\n&lt;p&gt;Has anyone ever heard of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/18281b0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18281b0", "is_robot_indexable": true, "report_reasons": null, "author": "wonka88", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18281b0/has_anyone_ever_seen_this_thing_no_trace_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/18281b0", "subreddit_subscribers": 713885, "created_utc": 1700765195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It is time keep hoarding AI models as Chinese censorship hits NYC based Huggingface the biggest AI library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1826g5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_mbyapud7", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/83Pjn1hvGrzkjzGLZtyTKqE_xeq19q0zX-PPAmVoxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "LocalLLaMA", "selftext": "", "author_fullname": "t2_4ulrx5xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hugging Face Removes Singing AI Models of Xi Jinping But Not of Biden", "link_flair_richtext": [], "subreddit_name_prefixed": "r/LocalLLaMA", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_181rdx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": "#bbbdbf", "ups": 300, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "03eba0e8-72f2-11ee-96eb-9a14648159ce", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 300, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/83Pjn1hvGrzkjzGLZtyTKqE_xeq19q0zX-PPAmVoxPI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700708677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "404media.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?auto=webp&amp;s=eaf93a4eae394d3bb7ab438b35ed6a6b867cf024", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9f22c5d5af4f3eea3937d08d55243e02544135", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a43b73bfef0509aec0c56fe0cd47b47f4558ce5e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a7d7c348e9e004288d6c37becc67621076e67eb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d4467326c54cdcd7445385f748f4b80ea5f5945", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4055ff6de501a27f6d30ff67f794aa2d992b939b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae41a6ac0d38f5e2ab302970c0c049639d461f98", "width": 1080, "height": 607}], "variants": {}, "id": "39UkKvxDztZ4DlgRPndfQMepqR5cLM0-u2ZmLf6husw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "koboldcpp", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_81eyvm", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "181rdx3", "is_robot_indexable": true, "report_reasons": null, "author": "Merchant_Lawrence", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/LocalLLaMA/comments/181rdx3/hugging_face_removes_singing_ai_models_of_xi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "subreddit_subscribers": 78949, "created_utc": 1700708677.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1700760924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "404media.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?auto=webp&amp;s=eaf93a4eae394d3bb7ab438b35ed6a6b867cf024", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e9f22c5d5af4f3eea3937d08d55243e02544135", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a43b73bfef0509aec0c56fe0cd47b47f4558ce5e", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a7d7c348e9e004288d6c37becc67621076e67eb", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d4467326c54cdcd7445385f748f4b80ea5f5945", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4055ff6de501a27f6d30ff67f794aa2d992b939b", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Yne6dJLfSnATEUSkcOXSk7wj7WdU13fuJEGR2iNwkpU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae41a6ac0d38f5e2ab302970c0c049639d461f98", "width": 1080, "height": 607}], "variants": {}, "id": "39UkKvxDztZ4DlgRPndfQMepqR5cLM0-u2ZmLf6husw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1826g5l", "is_robot_indexable": true, "report_reasons": null, "author": "ihmoguy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_181rdx3", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1826g5l/it_is_time_keep_hoarding_ai_models_as_chinese/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.404media.co/hugging-face-removes-singing-ai-models-of-xi-but-not-of-biden/", "subreddit_subscribers": 713885, "created_utc": 1700760924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title says it all. Most of the stuff I had no backup for. It sucks but I'm trying to take it in stride. Time will tell if I actually needed any of that data or if I was just hoarding it with no actual use. \n\nI'm still trying to recover the data with pros, and in any case I'll find a cost-efficient way to keep backups from now (any suggestions? One drive? External SSD?)\n\nHave any of you experienced this? How do you feel or how would you feel? Is this your worst nightmare? Let's discuss", "author_fullname": "t2_afzguhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My 8 year old HDD died", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1824mrv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700756072.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title says it all. Most of the stuff I had no backup for. It sucks but I&amp;#39;m trying to take it in stride. Time will tell if I actually needed any of that data or if I was just hoarding it with no actual use. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still trying to recover the data with pros, and in any case I&amp;#39;ll find a cost-efficient way to keep backups from now (any suggestions? One drive? External SSD?)&lt;/p&gt;\n\n&lt;p&gt;Have any of you experienced this? How do you feel or how would you feel? Is this your worst nightmare? Let&amp;#39;s discuss&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1824mrv", "is_robot_indexable": true, "report_reasons": null, "author": "M3M3-", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1824mrv/my_8_year_old_hdd_died/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1824mrv/my_8_year_old_hdd_died/", "subreddit_subscribers": 713885, "created_utc": 1700756072.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A week ago, a former Rockstar Games employee who worked on the company since 1995 created a blog that detailed very important and rare information about the development of various GTA games and unreleased R* projects, within just a few hours ago, Rockstar told him to shut the blog down.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182eupf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": "", "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2pju4k0w", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "lostmedia", "selftext": "Obee Vermeij is a developer who worked on Rockstar Games from 1995 until 2009, like a week ago, he created a blog named https://insiderockstarnorth.blogspot.com/, which detailed a lot of very interesting information about the development of the original GTA trilogy, GTA 4, their cancelled Cold War spy-action game Agent, and even stuff like a never-before-publicly-revealed Zombie Survival game set in Scotland that was being developed around the same time as Vice City (2002), and many more.\n\nLike, how can I describe it? this blog is every GTA fan dream, it even revealed 20-year-old unexplained mysteries in the GTA trilogy, like explaining the easter egg of why the moon in the original GTA games enlarges when you shoot it with a sniper rifle.\n\nVery awesome stuff for GTA and video game fans in general!, a ton of GTA-centric YouTube channels have made videos about this blog in various languages, but unfortunately, since this topic is related to a multi-billion dollar media empire like Rockstar Games, the company that constantly shuts down fan mods, Obee's last post was about how he received an e-mail from Rockstar North telling him to stop, and so it did, the blogspot was deleted.\n\n# However....\n\n[The blog and apparently all of its contents were archived on the Wayback Machine](https://web.archive.org/web/20231123011845/https://insiderockstarnorth.blogspot.com/), but again, since this is Rockstar Games that we are talking about, **I recommend everyone in the Lost Media and GTA/Rockstar Games community to archive all of its content on the WayBack Machine in case Rockstar goes against the Wayback Machine too!**", "author_fullname": "t2_2pju4k0w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[ARCHIVAL] A week ago, a former Rockstar Games employee who worked on the company since 1995 created a blog that detailed very important and rare information about the development of various GTA games and unreleased R* projects, within just a few hours ago, Rockstar told him to shut the blog down.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/lostmedia", "hidden": false, "pwls": null, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182elo4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Internet Media", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700785755.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700784150.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.lostmedia", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Obee Vermeij is a developer who worked on Rockstar Games from 1995 until 2009, like a week ago, he created a blog named &lt;a href=\"https://insiderockstarnorth.blogspot.com/\"&gt;https://insiderockstarnorth.blogspot.com/&lt;/a&gt;, which detailed a lot of very interesting information about the development of the original GTA trilogy, GTA 4, their cancelled Cold War spy-action game Agent, and even stuff like a never-before-publicly-revealed Zombie Survival game set in Scotland that was being developed around the same time as Vice City (2002), and many more.&lt;/p&gt;\n\n&lt;p&gt;Like, how can I describe it? this blog is every GTA fan dream, it even revealed 20-year-old unexplained mysteries in the GTA trilogy, like explaining the easter egg of why the moon in the original GTA games enlarges when you shoot it with a sniper rifle.&lt;/p&gt;\n\n&lt;p&gt;Very awesome stuff for GTA and video game fans in general!, a ton of GTA-centric YouTube channels have made videos about this blog in various languages, but unfortunately, since this topic is related to a multi-billion dollar media empire like Rockstar Games, the company that constantly shuts down fan mods, Obee&amp;#39;s last post was about how he received an e-mail from Rockstar North telling him to stop, and so it did, the blogspot was deleted.&lt;/p&gt;\n\n&lt;h1&gt;However....&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.archive.org/web/20231123011845/https://insiderockstarnorth.blogspot.com/\"&gt;The blog and apparently all of its contents were archived on the Wayback Machine&lt;/a&gt;, but again, since this is Rockstar Games that we are talking about, &lt;strong&gt;I recommend everyone in the Lost Media and GTA/Rockstar Games community to archive all of its content on the WayBack Machine in case Rockstar goes against the Wayback Machine too!&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5803acd6-0db4-11ea-a19a-0e1e11b0db07", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_38s0f", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "182elo4", "is_robot_indexable": true, "report_reasons": null, "author": "2zo2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/lostmedia/comments/182elo4/archival_a_week_ago_a_former_rockstar_games/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/lostmedia/comments/182elo4/archival_a_week_ago_a_former_rockstar_games/", "subreddit_subscribers": 180211, "created_utc": 1700784150.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1700784912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.lostmedia", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/lostmedia/comments/182elo4/archival_a_week_ago_a_former_rockstar_games/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182eupf", "is_robot_indexable": true, "report_reasons": null, "author": "2zo2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_182elo4", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182eupf/a_week_ago_a_former_rockstar_games_employee_who/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/lostmedia/comments/182elo4/archival_a_week_ago_a_former_rockstar_games/", "subreddit_subscribers": 713885, "created_utc": 1700784912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking at this one 4TB drive I got recently that has a manufacturing date in 2013, total written amount of 12 TB, restart count ~500, but total power-on only around 1,000h. I was wondering what happened there, why a restart every 2h, and was it really used intensely for only 1 month in 10 years...\n\nWhat are some weird ones you've seen?\n\nI'm assuming SMART attributes can't be set selectively can they? AFAIK SMART reset is an all-or-nothing deal that wipes the whole thing.", "author_fullname": "t2_4o56qcsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some strange stories that the SMART of used drives has told you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181y9fh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700735001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at this one 4TB drive I got recently that has a manufacturing date in 2013, total written amount of 12 TB, restart count ~500, but total power-on only around 1,000h. I was wondering what happened there, why a restart every 2h, and was it really used intensely for only 1 month in 10 years...&lt;/p&gt;\n\n&lt;p&gt;What are some weird ones you&amp;#39;ve seen?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m assuming SMART attributes can&amp;#39;t be set selectively can they? AFAIK SMART reset is an all-or-nothing deal that wipes the whole thing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "181y9fh", "is_robot_indexable": true, "report_reasons": null, "author": "GolemancerVekk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/181y9fh/what_are_some_strange_stories_that_the_smart_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181y9fh/what_are_some_strange_stories_that_the_smart_of/", "subreddit_subscribers": 713885, "created_utc": 1700735001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_hjrjb1zca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For anyone with a Brothers Scanner, or if you use IPrint&amp;Scan, is there a way to select which pages get saved together? I scanned in 10 pages but I don't want them all saved as one document", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_1823lez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rpQJ6MJmYp79o_ozpxrx9vXbER33XNrXopVMR8qbI6Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700753253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/myog3f8l842c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/myog3f8l842c1.png?auto=webp&amp;s=be42f3a3bc4d719e175572464ca54d63b9fafbac", "width": 1528, "height": 952}, "resolutions": [{"url": "https://preview.redd.it/myog3f8l842c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f7a24cae3e9c12048fc1bb799de100deb5712c0", "width": 108, "height": 67}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fedc1e916d550a373e4ed616b504605656644617", "width": 216, "height": 134}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=58374691cd09298a048bc75583ac8efef381b5b7", "width": 320, "height": 199}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1af5ec5f61fc78ceaff67e8a1a772996de56ba5", "width": 640, "height": 398}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c5fea0fafb96861d1b881a1742d9a639a3cc706e", "width": 960, "height": 598}, {"url": "https://preview.redd.it/myog3f8l842c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e41919f80a01374e7177d1dea9cc0c1c0f50952", "width": 1080, "height": 672}], "variants": {}, "id": "Tz7Xdv6d3a5UNQZpKMMcCAyYxzKy4DwUs_WxL58xFOM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1823lez", "is_robot_indexable": true, "report_reasons": null, "author": "Teachmetofishplease", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1823lez/for_anyone_with_a_brothers_scanner_or_if_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/myog3f8l842c1.png", "subreddit_subscribers": 713885, "created_utc": 1700753253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The drive had nothing essential (that I can think of yet :D) and I've yet to try salvaging data via ddrescue/testdisk/etc when the new drive arrives. But it was a motivator to finally do a robust backup system for most of my data, rather than just the essential stuff. I was supposed to do that till the end of the year ... for the last several years. Here's what I've come up with so far:\n\nWish list for the setup:\n\n1. Have versioned backups for some of the data (e.g. projects/documents)\n2. Have a copy of all personal/work/system config data by the 3-2-1 \"rule\" (3 copies, 2 media, 1 remote location)\n3. Be able to restore a machine easily enough if the drive of the root fails (not necessarily instantly), possibly without keeping whole copies for the root around\n4. No port forwarding/VPN/reverse proxy, etc for the remote communication between machines. \n5. And in general keep things as simple as possible.\n\nThe plan (using Borg and Syncthing):\n\nI have a laptop (but say I have N laptops), a (mostly) headless server locally and a remote RaspberryPi with a large HDD attached. \n\n1. Setup periodic Borg backups and staggered versioning for the folders which warrant that.\n2. Create a /backups folder on all devices. In it have /backups/&lt;device\\_id&gt; subfolders in which each machine will place its data for backup (i have some feeling the path compatibility will matter). The idea is to keep the Borg repos here, as well as symlinks to folders I want to have replicated to the two backup locations (but for which I don't need versioned backups).\n3. Configure Syncthing on all three machines so the local server and remote RPi keep read only copies of all /backups/&lt;device\\_id&gt; folders. ST can be setup to do scans on a smaller period and has been pretty stable with numerous files AFAIK.\n4. Regarding system configs (and if a root partition fails) - I'm thinking of keeping backups of /etc and \\~/.config (as well as some other app folders and files like .bashrc from /home). I'll also periodically dump the list of installed packages. In theory I should be able to do a fresh install, install the same packages, transplant /etc and the /home/&lt;user&gt; folder and ... be happy? I'm pretty sure I'm missing something here. I'll also backup systemd logs wherever they are (to trace failures potentially). I don't have any databases or services that keep data outside /home .. I think. \n5. I would optimally setup some kind of monitoring and recovery testing (thanks, chatgpt for reminding me of the latter). If you have some specific advice for some simple tools/approaches that would be nice. Otherwise I'll have to conjure some mini app/script that I'll run when I have ssh access to the machines. Or have a diagnostics folder, where each machine will write their own and have that synced with ST to asses on the laptop. I really have to not overengineer it, because I want to be done with the whole thing sooner rather than later.\n\nWhat I'm still not sure about:\n\n1. Should I keep a copy of my essential data at a cloud provider regardless of the triple copy? Yes, it's always nice to have redundancy, but is it a significantly needed measure in your experience?\n2. Should I fear encryption and being locked out of my data? Also how hard and how needed is it to change encryption keys at some point? I guess it's very much specific on their usage, etc., but I guess I'm looking for some examples from your experience.\n\nAnd in general - roast my planned setup before I've invested significant effort in implementing it.", "author_fullname": "t2_11g6s46", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A 4TB WD Blue blew up and now I'm finally contemplating a more methodical backup strategy. Roast me.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182bfw5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700774985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The drive had nothing essential (that I can think of yet :D) and I&amp;#39;ve yet to try salvaging data via ddrescue/testdisk/etc when the new drive arrives. But it was a motivator to finally do a robust backup system for most of my data, rather than just the essential stuff. I was supposed to do that till the end of the year ... for the last several years. Here&amp;#39;s what I&amp;#39;ve come up with so far:&lt;/p&gt;\n\n&lt;p&gt;Wish list for the setup:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have versioned backups for some of the data (e.g. projects/documents)&lt;/li&gt;\n&lt;li&gt;Have a copy of all personal/work/system config data by the 3-2-1 &amp;quot;rule&amp;quot; (3 copies, 2 media, 1 remote location)&lt;/li&gt;\n&lt;li&gt;Be able to restore a machine easily enough if the drive of the root fails (not necessarily instantly), possibly without keeping whole copies for the root around&lt;/li&gt;\n&lt;li&gt;No port forwarding/VPN/reverse proxy, etc for the remote communication between machines. &lt;/li&gt;\n&lt;li&gt;And in general keep things as simple as possible.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The plan (using Borg and Syncthing):&lt;/p&gt;\n\n&lt;p&gt;I have a laptop (but say I have N laptops), a (mostly) headless server locally and a remote RaspberryPi with a large HDD attached. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Setup periodic Borg backups and staggered versioning for the folders which warrant that.&lt;/li&gt;\n&lt;li&gt;Create a /backups folder on all devices. In it have /backups/&amp;lt;device\\_id&amp;gt; subfolders in which each machine will place its data for backup (i have some feeling the path compatibility will matter). The idea is to keep the Borg repos here, as well as symlinks to folders I want to have replicated to the two backup locations (but for which I don&amp;#39;t need versioned backups).&lt;/li&gt;\n&lt;li&gt;Configure Syncthing on all three machines so the local server and remote RPi keep read only copies of all /backups/&amp;lt;device\\_id&amp;gt; folders. ST can be setup to do scans on a smaller period and has been pretty stable with numerous files AFAIK.&lt;/li&gt;\n&lt;li&gt;Regarding system configs (and if a root partition fails) - I&amp;#39;m thinking of keeping backups of /etc and ~/.config (as well as some other app folders and files like .bashrc from /home). I&amp;#39;ll also periodically dump the list of installed packages. In theory I should be able to do a fresh install, install the same packages, transplant /etc and the /home/&amp;lt;user&amp;gt; folder and ... be happy? I&amp;#39;m pretty sure I&amp;#39;m missing something here. I&amp;#39;ll also backup systemd logs wherever they are (to trace failures potentially). I don&amp;#39;t have any databases or services that keep data outside /home .. I think. &lt;/li&gt;\n&lt;li&gt;I would optimally setup some kind of monitoring and recovery testing (thanks, chatgpt for reminding me of the latter). If you have some specific advice for some simple tools/approaches that would be nice. Otherwise I&amp;#39;ll have to conjure some mini app/script that I&amp;#39;ll run when I have ssh access to the machines. Or have a diagnostics folder, where each machine will write their own and have that synced with ST to asses on the laptop. I really have to not overengineer it, because I want to be done with the whole thing sooner rather than later.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What I&amp;#39;m still not sure about:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I keep a copy of my essential data at a cloud provider regardless of the triple copy? Yes, it&amp;#39;s always nice to have redundancy, but is it a significantly needed measure in your experience?&lt;/li&gt;\n&lt;li&gt;Should I fear encryption and being locked out of my data? Also how hard and how needed is it to change encryption keys at some point? I guess it&amp;#39;s very much specific on their usage, etc., but I guess I&amp;#39;m looking for some examples from your experience.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;And in general - roast my planned setup before I&amp;#39;ve invested significant effort in implementing it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182bfw5", "is_robot_indexable": true, "report_reasons": null, "author": "stargazer_w", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182bfw5/a_4tb_wd_blue_blew_up_and_now_im_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182bfw5/a_4tb_wd_blue_blew_up_and_now_im_finally/", "subreddit_subscribers": 713885, "created_utc": 1700774985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wanted some advice from you storage fellas! I decided that I am going to be using m-disks to long term archive videos and photos. Got some very important videos from when I was a kid and I don't want to risk losing them (I have backups on other media but not long term) I am looking for a good quality Blu-Ray \"M-Disk\" drive that is internal - but I am planning on making it external with adapters and what not! I don't particularly want to use an enclosure as it's too expensive for my budget.\n\nBeen looking on amazon for some, specifically the Hitachi-LG BH16, but I'd rather check here if you guys know if it's good etc...\n\nCan you guys kindly recommend me a good drive that supports m-disk? Been looking for a few weeks now. Budget around \u00a360 - \u00a390 :)", "author_fullname": "t2_4a2bccmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of buying an internal Blu-Ray \"M-Disk\" compatible drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18226uh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700749194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted some advice from you storage fellas! I decided that I am going to be using m-disks to long term archive videos and photos. Got some very important videos from when I was a kid and I don&amp;#39;t want to risk losing them (I have backups on other media but not long term) I am looking for a good quality Blu-Ray &amp;quot;M-Disk&amp;quot; drive that is internal - but I am planning on making it external with adapters and what not! I don&amp;#39;t particularly want to use an enclosure as it&amp;#39;s too expensive for my budget.&lt;/p&gt;\n\n&lt;p&gt;Been looking on amazon for some, specifically the Hitachi-LG BH16, but I&amp;#39;d rather check here if you guys know if it&amp;#39;s good etc...&lt;/p&gt;\n\n&lt;p&gt;Can you guys kindly recommend me a good drive that supports m-disk? Been looking for a few weeks now. Budget around \u00a360 - \u00a390 :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18226uh", "is_robot_indexable": true, "report_reasons": null, "author": "oxendaleliam", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18226uh/thinking_of_buying_an_internal_bluray_mdisk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18226uh/thinking_of_buying_an_internal_bluray_mdisk/", "subreddit_subscribers": 713885, "created_utc": 1700749194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, how are you? Please excuse my lack of knowledge, but I need some advice.\n\nI currently have around 5TB of data scattered between my OneDrive account and 2 separate SSDs. I want to create a reliable backup solution for all of my personal and work data.\n\nI recently learned about the 3-2-1 backup strategy, which involves creating 3 copies of your data on 2 different types of storage, with 1 copy being kept off-site (correct me if I'm wrong).\n\nHowever, in my situation, I work on a laptop that only has 1TB of internal storage and I don't rely on it for anything other than my active projects. Everything else is either on OneDrive or on the SSD.\n\nSo, my question is: how can I benefit from a 3-2-1 backup strategy? Should I invest in a NAS drive and store everything on it, while also using a cloud backup service like Backblaze to keep one copy off-site? Or any 8TB HDD desktop drive is enough.   \nAnd what about a 3rd copy?", "author_fullname": "t2_12pg2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on implementing 3-2-1 backup strategy with scattered data - Need suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181yf5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700735854.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700735672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, how are you? Please excuse my lack of knowledge, but I need some advice.&lt;/p&gt;\n\n&lt;p&gt;I currently have around 5TB of data scattered between my OneDrive account and 2 separate SSDs. I want to create a reliable backup solution for all of my personal and work data.&lt;/p&gt;\n\n&lt;p&gt;I recently learned about the 3-2-1 backup strategy, which involves creating 3 copies of your data on 2 different types of storage, with 1 copy being kept off-site (correct me if I&amp;#39;m wrong).&lt;/p&gt;\n\n&lt;p&gt;However, in my situation, I work on a laptop that only has 1TB of internal storage and I don&amp;#39;t rely on it for anything other than my active projects. Everything else is either on OneDrive or on the SSD.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: how can I benefit from a 3-2-1 backup strategy? Should I invest in a NAS drive and store everything on it, while also using a cloud backup service like Backblaze to keep one copy off-site? Or any 8TB HDD desktop drive is enough.&lt;br/&gt;\nAnd what about a 3rd copy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181yf5k", "is_robot_indexable": true, "report_reasons": null, "author": "zizo999", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181yf5k/looking_for_advice_on_implementing_321_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181yf5k/looking_for_advice_on_implementing_321_backup/", "subreddit_subscribers": 713885, "created_utc": 1700735672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u3i8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AnandTech releases his list of best internal HDDs for Holidays 2023. Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_181ybft", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/dbzbVUXmcM9WUfo2Gox7T04ADa6GqhtUH6I8ZIW1GM8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700735227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "anandtech.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.anandtech.com/show/12075/best-consumer-hdds", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?auto=webp&amp;s=dcfc48f99463b92411285312b77e47db51a33c41", "width": 678, "height": 454}, "resolutions": [{"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a3024febe75e06bc864da2ba4a3533e08b7fae4", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ae3378a97fab4b4f30d6dabf296ed31af937999b", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f9d1453a3c883e82c5e1a9376187b0c4efec31e", "width": 320, "height": 214}, {"url": "https://external-preview.redd.it/YQH9Q2-KDBKkDO-CTlSBJCOaEScrHQMPhSaBNWl-Myo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=52b9acf42fa8e9dd338582fdcd213eab95ee5a55", "width": 640, "height": 428}], "variants": {}, "id": "oeJpaXt0sftyq2FczsNaxKPVlTzfVxEV44O06vXK1wg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "181ybft", "is_robot_indexable": true, "report_reasons": null, "author": "javipas", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181ybft/anandtech_releases_his_list_of_best_internal_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.anandtech.com/show/12075/best-consumer-hdds", "subreddit_subscribers": 713885, "created_utc": 1700735227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Had a storage machine carrying some important data that's been in cold storage for a year. Not too worried about the hdds, but thinking the SSDs could use a good once over to make sure none of the files have decayed. Not really sure how to do that though, was thinking of maybe running a virus scanner over the whole thing as that should force the system to look at every file, and maybe the ssd/hdd error correction will make sure everything is up to snuff. Any advice? Is there a better way?\n\nSystem is running windows so some Linux tools are trickier to fire up without creating some kind of live disc or something.", "author_fullname": "t2_vivjs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had a storage machine in cold storage and unpowered for almost an entire year. Advice on insuring data integrity on startup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181vtdv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700724751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had a storage machine carrying some important data that&amp;#39;s been in cold storage for a year. Not too worried about the hdds, but thinking the SSDs could use a good once over to make sure none of the files have decayed. Not really sure how to do that though, was thinking of maybe running a virus scanner over the whole thing as that should force the system to look at every file, and maybe the ssd/hdd error correction will make sure everything is up to snuff. Any advice? Is there a better way?&lt;/p&gt;\n\n&lt;p&gt;System is running windows so some Linux tools are trickier to fire up without creating some kind of live disc or something.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181vtdv", "is_robot_indexable": true, "report_reasons": null, "author": "Captain_Starkiller", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181vtdv/had_a_storage_machine_in_cold_storage_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181vtdv/had_a_storage_machine_in_cold_storage_and/", "subreddit_subscribers": 713885, "created_utc": 1700724751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "if its an photograph thats black and white, it will tag it as a black and white photo, if its a graphic design logo it will tag it as a graphic design image, and if its a image of a painting it will tag it as a painting \n\nI've heard of MAGIX photo manager and digicam, can these programs do this? any better suggestions would be great ", "author_fullname": "t2_e67xpbe9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is there a software that can automatically analyze images and add relevant tags based on the content in the image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181tckh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700715450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;if its an photograph thats black and white, it will tag it as a black and white photo, if its a graphic design logo it will tag it as a graphic design image, and if its a image of a painting it will tag it as a painting &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard of MAGIX photo manager and digicam, can these programs do this? any better suggestions would be great &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181tckh", "is_robot_indexable": true, "report_reasons": null, "author": "Moneydamjan", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181tckh/is_there_a_software_that_can_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181tckh/is_there_a_software_that_can_automatically/", "subreddit_subscribers": 713885, "created_utc": 1700715450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m looking to update one of my data drives without having to re-sync the whole parity via snapraid. Last time I updated a data drive, when I connected the new hard drive, Stablebit created its own \u2018PoolPart\u2019 sub folder with a unique set of numbers in the subfolder name. I couldn\u2019t copy over the PoolPart subfolder from the old drive to the new drive and just use that subfolder. I needed to put the files into the new subfolder. This forced me to re-run/re-sync the entire parity essentially because the directory where the files were stored changed. \n\nI plan on updating another data drive, and I would like to make it as seamless as possible. What\u2019s the best way to update a data drive when I am using Stablebit in general? Is there a way to copy over the PoolPart subfolder so StableBit doesn\u2019t create a new subfolder on its own? Is there a way to change the new PoolPart subfolder name to match the name of the old one? From my memory, it wouldn\u2019t let me change the name.", "author_fullname": "t2_k1lso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stablebit + SnapRaid question (upgrading data drive)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182ec8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700783370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to update one of my data drives without having to re-sync the whole parity via snapraid. Last time I updated a data drive, when I connected the new hard drive, Stablebit created its own \u2018PoolPart\u2019 sub folder with a unique set of numbers in the subfolder name. I couldn\u2019t copy over the PoolPart subfolder from the old drive to the new drive and just use that subfolder. I needed to put the files into the new subfolder. This forced me to re-run/re-sync the entire parity essentially because the directory where the files were stored changed. &lt;/p&gt;\n\n&lt;p&gt;I plan on updating another data drive, and I would like to make it as seamless as possible. What\u2019s the best way to update a data drive when I am using Stablebit in general? Is there a way to copy over the PoolPart subfolder so StableBit doesn\u2019t create a new subfolder on its own? Is there a way to change the new PoolPart subfolder name to match the name of the old one? From my memory, it wouldn\u2019t let me change the name.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182ec8t", "is_robot_indexable": true, "report_reasons": null, "author": "darkazcura", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182ec8t/stablebit_snapraid_question_upgrading_data_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182ec8t/stablebit_snapraid_question_upgrading_data_drive/", "subreddit_subscribers": 713885, "created_utc": 1700783370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you don\u2019t have the money for the most amount of terabytes there is but you can find it in your budget if you buy it pre-owned.", "author_fullname": "t2_pzcs0b20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are used hard drives ok?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182cz93", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700779374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you don\u2019t have the money for the most amount of terabytes there is but you can find it in your budget if you buy it pre-owned.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182cz93", "is_robot_indexable": true, "report_reasons": null, "author": "ImHidingtheRealMe", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182cz93/are_used_hard_drives_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182cz93/are_used_hard_drives_ok/", "subreddit_subscribers": 713885, "created_utc": 1700779374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I plan on building my first home server primarily to function as a NAS.  I'd love to video edit from it.  Ultimately, I may stream home videos from it and may look at utilizing it in other ways as I learn to a home servers capabilities.\n\nI've had the i3-12100 recommended a number of times. However, for the sake of power efficiency and upfront cost, however, I've been looking at i3-7100T.  Would this be good enough for the needs I've outlined?  I understand it would be significantly less powerful, but I want honest thoughts on whether it'd be sufficient for a video editing NAS?", "author_fullname": "t2_ebnpzr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intel Core i3-7100T for a home server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182cbuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700777485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on building my first home server primarily to function as a NAS.  I&amp;#39;d love to video edit from it.  Ultimately, I may stream home videos from it and may look at utilizing it in other ways as I learn to a home servers capabilities.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had the i3-12100 recommended a number of times. However, for the sake of power efficiency and upfront cost, however, I&amp;#39;ve been looking at i3-7100T.  Would this be good enough for the needs I&amp;#39;ve outlined?  I understand it would be significantly less powerful, but I want honest thoughts on whether it&amp;#39;d be sufficient for a video editing NAS?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182cbuq", "is_robot_indexable": true, "report_reasons": null, "author": "-ThatGingerKid-", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182cbuq/intel_core_i37100t_for_a_home_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182cbuq/intel_core_i37100t_for_a_home_server/", "subreddit_subscribers": 713885, "created_utc": 1700777485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, looking this Black Friday to get some WD Red Pro's if they drop in price (buying from Canada) -- we have two at home, one is a 5 bay and one a 3 -- we might eventually switch the 4 bay which is a newer 918+, the older one is a 1513+ which we would like to keep, but upgrade at some point with more space --- for now before we buy more space in a couple days, we nabbed an 18 TB WD Elements to use as an off-site backup solution since we wanted to free some of the space used for redundancy in our RAID configuration on that Synology (not sure if this is what's referred to as \"off-site\" -- kind of a noob lol)\n\n&amp;#x200B;\n\nMy question is at this point is there a way to safely free the redundancy space, and it won't affect my data, or should I wait to get the WD HDD in a couple days and copy everything to that, then I re-format or wipe the drives? Just in case we pass on buying new internal HDD's this Thanksgiving, I did want to at least free some extra space\n\n&amp;#x200B;\n\nLooks like the 1513+ I'm trying to free are five 4TB Seagate st4000dm000 in a 'Synology Hybrid Raid (SHR) (With data protection with 1-drive fault tolerance)\n\n&amp;#x200B;\n\nThank you for any and all help", "author_fullname": "t2_u1wga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Change Synology Configuration and Other Redundancy Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182bvws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700777664.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700776256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, looking this Black Friday to get some WD Red Pro&amp;#39;s if they drop in price (buying from Canada) -- we have two at home, one is a 5 bay and one a 3 -- we might eventually switch the 4 bay which is a newer 918+, the older one is a 1513+ which we would like to keep, but upgrade at some point with more space --- for now before we buy more space in a couple days, we nabbed an 18 TB WD Elements to use as an off-site backup solution since we wanted to free some of the space used for redundancy in our RAID configuration on that Synology (not sure if this is what&amp;#39;s referred to as &amp;quot;off-site&amp;quot; -- kind of a noob lol)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is at this point is there a way to safely free the redundancy space, and it won&amp;#39;t affect my data, or should I wait to get the WD HDD in a couple days and copy everything to that, then I re-format or wipe the drives? Just in case we pass on buying new internal HDD&amp;#39;s this Thanksgiving, I did want to at least free some extra space&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Looks like the 1513+ I&amp;#39;m trying to free are five 4TB Seagate st4000dm000 in a &amp;#39;Synology Hybrid Raid (SHR) (With data protection with 1-drive fault tolerance)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for any and all help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182bvws", "is_robot_indexable": true, "report_reasons": null, "author": "NoirYorkCity", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182bvws/how_to_change_synology_configuration_and_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182bvws/how_to_change_synology_configuration_and_other/", "subreddit_subscribers": 713885, "created_utc": 1700776256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Happy Thanksgiving! \n\nWeird question, but do 9600-24i eHBA give a BIOS splash screen? I've updated the firmware ROM to latest using the Windows LSA (couldn't get sas3flash to work) and I see it showing in lspci, but haven't gotten drives detecting yet. But I'm used to seeing the initial splash on boot with my old 3008 card and the drives listed. Is that no longer a thing or should it also be doing a splash config screen?\n\nTIA", "author_fullname": "t2_jcdv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "9600-24i Bios Interface", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182b0ar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700773792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happy Thanksgiving! &lt;/p&gt;\n\n&lt;p&gt;Weird question, but do 9600-24i eHBA give a BIOS splash screen? I&amp;#39;ve updated the firmware ROM to latest using the Windows LSA (couldn&amp;#39;t get sas3flash to work) and I see it showing in lspci, but haven&amp;#39;t gotten drives detecting yet. But I&amp;#39;m used to seeing the initial splash on boot with my old 3008 card and the drives listed. Is that no longer a thing or should it also be doing a splash config screen?&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182b0ar", "is_robot_indexable": true, "report_reasons": null, "author": "researchallthethings", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182b0ar/960024i_bios_interface/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182b0ar/960024i_bios_interface/", "subreddit_subscribers": 713885, "created_utc": 1700773792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is such a random and basic question, but I wonder if anyone can help. \n\nI'm a videographer whose footage has been double backed up on HDDs for the past 8 years. I label each individual drive by taping a piece of paper to it which helps me identify it at a glance - (1-A, 1-B, 2-A, 2-B, etc)  \n\nNow I've bought a couple of SAMSUNG T7 Shield 4TB SSD's as they're currently on sale and infinitely better than my old cheap drives. \n\nThe problem is the Shields have this rubber coating to keep them rugged, but I can't find a way to label them. Tape and stickers slide right off. I even tried writing with a white out pen and it also doesn't hold to the surface lol. Anyone have any creative ideas? \n\n&amp;#x200B;", "author_fullname": "t2_1790yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to label a Samsung Shield SSD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182axed", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700773566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is such a random and basic question, but I wonder if anyone can help. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a videographer whose footage has been double backed up on HDDs for the past 8 years. I label each individual drive by taping a piece of paper to it which helps me identify it at a glance - (1-A, 1-B, 2-A, 2-B, etc)  &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;ve bought a couple of SAMSUNG T7 Shield 4TB SSD&amp;#39;s as they&amp;#39;re currently on sale and infinitely better than my old cheap drives. &lt;/p&gt;\n\n&lt;p&gt;The problem is the Shields have this rubber coating to keep them rugged, but I can&amp;#39;t find a way to label them. Tape and stickers slide right off. I even tried writing with a white out pen and it also doesn&amp;#39;t hold to the surface lol. Anyone have any creative ideas? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "182axed", "is_robot_indexable": true, "report_reasons": null, "author": "the_long_bridge", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/182axed/how_to_label_a_samsung_shield_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/182axed/how_to_label_a_samsung_shield_ssd/", "subreddit_subscribers": 713885, "created_utc": 1700773566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is asked every now and then, but then there are occasional new tools, so I wanted to check again.\n\nI am planning to add a few more sites to my archives, and am open to suggestion.\n\n1. `wget` \"works\" of course. I have used it in the past. But does not know anything about multiple versions, or other structural parts of the web archive. \n\n2. [https://github.com/internetarchive/dweb-mirror](https://github.com/internetarchive/dweb-mirror). The \"official\" mirroring tool. I might give it a try. But could not find a way to restrict to my selected list of web pages.\n\nWhat is the current best strategy to get this done?", "author_fullname": "t2_17g3q9fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The best advice for wayback machine (web.archive.org) mirroring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18280gk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700765133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is asked every now and then, but then there are occasional new tools, so I wanted to check again.&lt;/p&gt;\n\n&lt;p&gt;I am planning to add a few more sites to my archives, and am open to suggestion.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;code&gt;wget&lt;/code&gt; &amp;quot;works&amp;quot; of course. I have used it in the past. But does not know anything about multiple versions, or other structural parts of the web archive. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://github.com/internetarchive/dweb-mirror\"&gt;https://github.com/internetarchive/dweb-mirror&lt;/a&gt;. The &amp;quot;official&amp;quot; mirroring tool. I might give it a try. But could not find a way to restrict to my selected list of web pages.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What is the current best strategy to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?auto=webp&amp;s=ce67ac4eaf4a6fded058d4d9c5becae87234c2ea", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67f929495243a3bfa30b4a64140cea9b59d4cf26", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=057122bd90ef79a94809253a383e43fb9c52d4ca", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e156f4acf34640c3b320cf3cded989751874a52", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b046817895c7bff6ec28669e6a1a5c7f68735b7b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=98ef71a501cfb81f177051ebc4d32af8ec705fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Fx7jtZWJ5TziHMATjWIpcv7MeYZFvuJJorFON3-lAF8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ade59ef0f9b3bf868b5ee95ea675c0d4a1c4ca8", "width": 1080, "height": 540}], "variants": {}, "id": "H9vrkJn5vS3p-i7AmG7Hi0KwD8pcxC2iybrn7JJSkBI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18280gk", "is_robot_indexable": true, "report_reasons": null, "author": "stikves", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18280gk/the_best_advice_for_wayback_machine_webarchiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18280gk/the_best_advice_for_wayback_machine_webarchiveorg/", "subreddit_subscribers": 713885, "created_utc": 1700765133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have many public download links to files.\nAnd I dont want to have a download manager to download many links at once. I want to share it with just one click to one person. So you just need to download the files at once\n\nIn cloud storage services you can put many files into one folder and download just one folder. You know what I mean?\n\nIt would be so cool, if you could make a virtual file system just with public links and download it trough one link all the files. Becouse its more comfort. You know what I mean? Is that possible?", "author_fullname": "t2_oq2e3f8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create an virtual file system only with links? Is that possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1824e8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700755445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have many public download links to files.\nAnd I dont want to have a download manager to download many links at once. I want to share it with just one click to one person. So you just need to download the files at once&lt;/p&gt;\n\n&lt;p&gt;In cloud storage services you can put many files into one folder and download just one folder. You know what I mean?&lt;/p&gt;\n\n&lt;p&gt;It would be so cool, if you could make a virtual file system just with public links and download it trough one link all the files. Becouse its more comfort. You know what I mean? Is that possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1824e8o", "is_robot_indexable": true, "report_reasons": null, "author": "Sorita_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1824e8o/create_an_virtual_file_system_only_with_links_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1824e8o/create_an_virtual_file_system_only_with_links_is/", "subreddit_subscribers": 713885, "created_utc": 1700755445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Me and a friend want to build a plexserver and need help for finding the right hdd. It needs to be a quiet one because it's standing in my bedroom. Do you guys have any recommendations for 14tb+ HDD's that are as quiet as possible?", "author_fullname": "t2_uaony", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quiet(isch) HDD for HTPC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18200a7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700742023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Me and a friend want to build a plexserver and need help for finding the right hdd. It needs to be a quiet one because it&amp;#39;s standing in my bedroom. Do you guys have any recommendations for 14tb+ HDD&amp;#39;s that are as quiet as possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18200a7", "is_robot_indexable": true, "report_reasons": null, "author": "druvanti", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18200a7/quietisch_hdd_for_htpc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18200a7/quietisch_hdd_for_htpc/", "subreddit_subscribers": 713885, "created_utc": 1700742023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I'll fully admit this is probably user error and not due to any bugs with the software. But I've been on a bit of a tear lately utilizing YT-DLP to download videos from YouTube. Now I'm not a stranger to this process, I'd used Youtube-DL successfully for years now. But I did recently take advantage of using it in conjunction Aria2c with the understanding that it would give me a bit more of a boost . Well...\n\nI don't know if it's YT-DLP or Aria or my NAS or my Internet connection, but I went through to organize these downloads and found TONS and TONS of video files ending with \".part-frag###.\" There are thousands and thousands, and upon a cursory glance, seems to affect hundreds of video downloads. Each folder has dozens of these files and if it doesn't, it has split mp4/m4a. Rarely does a folder seem to have one clean video file like I would expect. I skimmed through and there *seems* to be finished files amongst the mess that *seem* to play fine, I can't be 100% sure though these files are as complete as they should be (surely the part-frags exist for a reason).\n\nSo firstly, what program or setting is causing this plague of fragments? Secondly, is there anything I can do to resolve theses files at this point? Yes, I can delete all the frags, but that doesn't give me any comfort in the integrity of whatever video file remains (and it won't solve the problem for future downloads). And as I archive to a txt file, I can't just re-download as YT-DLP considers them downloaded (I've tried redownloading to see it forces a re-check and cleans things up, but no dice). Is it just refusing to merge or delete for some reason?", "author_fullname": "t2_cikix", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about YT-DLP and a mess .part-frags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181pvl5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700703997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ll fully admit this is probably user error and not due to any bugs with the software. But I&amp;#39;ve been on a bit of a tear lately utilizing YT-DLP to download videos from YouTube. Now I&amp;#39;m not a stranger to this process, I&amp;#39;d used Youtube-DL successfully for years now. But I did recently take advantage of using it in conjunction Aria2c with the understanding that it would give me a bit more of a boost . Well...&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s YT-DLP or Aria or my NAS or my Internet connection, but I went through to organize these downloads and found TONS and TONS of video files ending with &amp;quot;.part-frag###.&amp;quot; There are thousands and thousands, and upon a cursory glance, seems to affect hundreds of video downloads. Each folder has dozens of these files and if it doesn&amp;#39;t, it has split mp4/m4a. Rarely does a folder seem to have one clean video file like I would expect. I skimmed through and there &lt;em&gt;seems&lt;/em&gt; to be finished files amongst the mess that &lt;em&gt;seem&lt;/em&gt; to play fine, I can&amp;#39;t be 100% sure though these files are as complete as they should be (surely the part-frags exist for a reason).&lt;/p&gt;\n\n&lt;p&gt;So firstly, what program or setting is causing this plague of fragments? Secondly, is there anything I can do to resolve theses files at this point? Yes, I can delete all the frags, but that doesn&amp;#39;t give me any comfort in the integrity of whatever video file remains (and it won&amp;#39;t solve the problem for future downloads). And as I archive to a txt file, I can&amp;#39;t just re-download as YT-DLP considers them downloaded (I&amp;#39;ve tried redownloading to see it forces a re-check and cleans things up, but no dice). Is it just refusing to merge or delete for some reason?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "181pvl5", "is_robot_indexable": true, "report_reasons": null, "author": "TheSoulCages", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/181pvl5/question_about_ytdlp_and_a_mess_partfrags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/181pvl5/question_about_ytdlp_and_a_mess_partfrags/", "subreddit_subscribers": 713885, "created_utc": 1700703997.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}