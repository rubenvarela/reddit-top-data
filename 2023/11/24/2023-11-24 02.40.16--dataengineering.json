{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a rant.\nI've talked with manager and He told me that at end of january I've to do PL-300.\n\nI work since two years as Data Consultant(mainly DE/ DA / PBI /PMO/ dwh)for one of big 4 consultancy, 6 role in 1.\n\nMy feedback are extremely good, deadlines are meet, numbers do match and since I started pipelines only crash few times during year thanks to my fixes, working on 5-6 project as same time,\nProposed new innovations, projects that has been accepted and made the company earn.\n\nI've done PL-300 twice and did not pass it both for lack of time in studying and because I was forced to do it because my manager was like \"try it, if you pass, it's less pain\".\nI'm more strong in DE and we agreed to go for DE certification but they want PL-300.\n\nIn my team I'm the only one doing PowerBi and DE / SA / PM while I build like 5-6 dashboard for the same client and sometimes I do finish late but is hard for me to find time to study as\n\nI'm always fighting for good data quality, messy data model and all dirty hell of data made by multiple people working on customer.\n\nClient doesn't require it but my company does as it has partnerships.\n\nI told my manager that I hate certifications due to memory and the thought of passing hours after work and during holidays studying it's a no for me\nAs they're important for me as I De-stress.\nAlso I've added \"if I take the certification, you take it too. It is not fair and you'll understand what it will mean to study for it, why since you're tech manager and you work with me, I'm the only one forced to take certs but you are not?\"\n\nI've met a lot of people with senior experience working in big companies that hates certifications.\nI do like studying but not to sacrifice my holidays.\n\n1. Should I start a plan B?\n2. Have you been in same shoes?", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant about certifications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181zzgt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700741938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a rant.\nI&amp;#39;ve talked with manager and He told me that at end of january I&amp;#39;ve to do PL-300.&lt;/p&gt;\n\n&lt;p&gt;I work since two years as Data Consultant(mainly DE/ DA / PBI /PMO/ dwh)for one of big 4 consultancy, 6 role in 1.&lt;/p&gt;\n\n&lt;p&gt;My feedback are extremely good, deadlines are meet, numbers do match and since I started pipelines only crash few times during year thanks to my fixes, working on 5-6 project as same time,\nProposed new innovations, projects that has been accepted and made the company earn.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done PL-300 twice and did not pass it both for lack of time in studying and because I was forced to do it because my manager was like &amp;quot;try it, if you pass, it&amp;#39;s less pain&amp;quot;.\nI&amp;#39;m more strong in DE and we agreed to go for DE certification but they want PL-300.&lt;/p&gt;\n\n&lt;p&gt;In my team I&amp;#39;m the only one doing PowerBi and DE / SA / PM while I build like 5-6 dashboard for the same client and sometimes I do finish late but is hard for me to find time to study as&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m always fighting for good data quality, messy data model and all dirty hell of data made by multiple people working on customer.&lt;/p&gt;\n\n&lt;p&gt;Client doesn&amp;#39;t require it but my company does as it has partnerships.&lt;/p&gt;\n\n&lt;p&gt;I told my manager that I hate certifications due to memory and the thought of passing hours after work and during holidays studying it&amp;#39;s a no for me\nAs they&amp;#39;re important for me as I De-stress.\nAlso I&amp;#39;ve added &amp;quot;if I take the certification, you take it too. It is not fair and you&amp;#39;ll understand what it will mean to study for it, why since you&amp;#39;re tech manager and you work with me, I&amp;#39;m the only one forced to take certs but you are not?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve met a lot of people with senior experience working in big companies that hates certifications.\nI do like studying but not to sacrifice my holidays.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I start a plan B?&lt;/li&gt;\n&lt;li&gt;Have you been in same shoes?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181zzgt", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181zzgt/rant_about_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181zzgt/rant_about_certifications/", "subreddit_subscribers": 141357, "created_utc": 1700741938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a cross platform (android + iOS + web) marketplace with many users and several user journeys and use many 3rd party tools. We need to totally refine our data layer and tagging. \n\nIs it really possible to exchange many SDK-s (e.g: CRM, Facebook ads, etc..) with the segment's and re-use segment events in our 3rd party tools? \n\nAny experience? What is possible what is not? ", "author_fullname": "t2_599d1gmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with Segment or Rudderstack? Does it really worth to use it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181wome", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700728395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a cross platform (android + iOS + web) marketplace with many users and several user journeys and use many 3rd party tools. We need to totally refine our data layer and tagging. &lt;/p&gt;\n\n&lt;p&gt;Is it really possible to exchange many SDK-s (e.g: CRM, Facebook ads, etc..) with the segment&amp;#39;s and re-use segment events in our 3rd party tools? &lt;/p&gt;\n\n&lt;p&gt;Any experience? What is possible what is not? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "181wome", "is_robot_indexable": true, "report_reasons": null, "author": "kozakdavid07", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181wome/experience_with_segment_or_rudderstack_does_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181wome/experience_with_segment_or_rudderstack_does_it/", "subreddit_subscribers": 141357, "created_utc": 1700728395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Who should do the dimensional modelling? By that I mean who is responsible for creating a logic layer in the warehouse  from a transactional system. The data engineer says its not their job and the data scientist seems not capable. \n\nCurrently we just have a massive dump of data , not really a warehouse IMO and there is no single schema whatsoever . I am new in this company but not new to data and never saw something like this before.\n\nAny pointers appreciated.", "author_fullname": "t2_ndvkq3ghs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling ownership", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181vzlj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700725475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Who should do the dimensional modelling? By that I mean who is responsible for creating a logic layer in the warehouse  from a transactional system. The data engineer says its not their job and the data scientist seems not capable. &lt;/p&gt;\n\n&lt;p&gt;Currently we just have a massive dump of data , not really a warehouse IMO and there is no single schema whatsoever . I am new in this company but not new to data and never saw something like this before.&lt;/p&gt;\n\n&lt;p&gt;Any pointers appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "181vzlj", "is_robot_indexable": true, "report_reasons": null, "author": "Special_Bid_3176", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181vzlj/data_modelling_ownership/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181vzlj/data_modelling_ownership/", "subreddit_subscribers": 141357, "created_utc": 1700725475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example \n\nOne input is \n\n    {\"id\": \"abc\", \"users\": [{\"user_id\": 1}]}\n\nAnd another is \n\n    {\"id\": \"def\", \"users\": [{\"user_id\": 1}, {\"user_id\": 2}]}\n\nI'd like the flattened table to be something like (not necessarily this)\n\n| id  | user_1_id | user_2_id |\n|-----|-----------|-----------|\n| abc | 1         | null      |\n| def | 1         | 2         |\n|     |           |           |\n\n\nBut you don't know the max number of users an item/row might have. And it's unwieldy to have user_n_id for n columns.\n\nI know in big query there are nested arrays that could help here but I'm looking for a more tech-agnostic method of dealing with this. Something from the data modeling world I imagine.\n\nI imagine it means separating the latter into 2 rows to yield something like below\n\n| id  | user_id |\n|-----|---------|\n| abc | 1       |\n| def | 1       |\n| def | 2       |\n\nAppreciate any pointers", "author_fullname": "t2_gua18k7sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle json -&gt; tabular format when an array field has a variable number of objects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1828nvo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700766956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example &lt;/p&gt;\n\n&lt;p&gt;One input is &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;abc&amp;quot;, &amp;quot;users&amp;quot;: [{&amp;quot;user_id&amp;quot;: 1}]}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And another is &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;quot;id&amp;quot;: &amp;quot;def&amp;quot;, &amp;quot;users&amp;quot;: [{&amp;quot;user_id&amp;quot;: 1}, {&amp;quot;user_id&amp;quot;: 2}]}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;d like the flattened table to be something like (not necessarily this)&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;id&lt;/th&gt;\n&lt;th&gt;user_1_id&lt;/th&gt;\n&lt;th&gt;user_2_id&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;abc&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;null&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;def&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;But you don&amp;#39;t know the max number of users an item/row might have. And it&amp;#39;s unwieldy to have user_n_id for n columns.&lt;/p&gt;\n\n&lt;p&gt;I know in big query there are nested arrays that could help here but I&amp;#39;m looking for a more tech-agnostic method of dealing with this. Something from the data modeling world I imagine.&lt;/p&gt;\n\n&lt;p&gt;I imagine it means separating the latter into 2 rows to yield something like below&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;id&lt;/th&gt;\n&lt;th&gt;user_id&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;abc&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;def&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;def&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Appreciate any pointers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1828nvo", "is_robot_indexable": true, "report_reasons": null, "author": "alexcontrerasdppl", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1828nvo/how_to_handle_json_tabular_format_when_an_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1828nvo/how_to_handle_json_tabular_format_when_an_array/", "subreddit_subscribers": 141357, "created_utc": 1700766956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,   \nHas anyone had experience using either of these two operators to set up Spark in K8s? Any preferences or weird things you ran into?\n\n  \n\\- [https://github.com/GoogleCloudPlatform/spark-on-k8s-operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)\n\n\\- [https://github.com/stackabletech/spark-k8s-operator](https://github.com/stackabletech/spark-k8s-operator)  \n\n\n&amp;#x200B;", "author_fullname": "t2_t9ep875j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark Operators for K8s", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181uv84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700721026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nHas anyone had experience using either of these two operators to set up Spark in K8s? Any preferences or weird things you ran into?&lt;/p&gt;\n\n&lt;p&gt;- &lt;a href=\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator\"&gt;https://github.com/GoogleCloudPlatform/spark-on-k8s-operator&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- &lt;a href=\"https://github.com/stackabletech/spark-k8s-operator\"&gt;https://github.com/stackabletech/spark-k8s-operator&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?auto=webp&amp;s=d76e7fe9870e04a56ecb8f1e86b453d8c4c8e715", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b20b492420ba8e3c83dc5315b56d19258ac1c44b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6d47be570ef97c2f9d059ee648965d3c8fa8a2f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ecd9635a589e9f11bbf06eed4f8c3e4eb3bebd8c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ea20c577cd85ad373d8d8aa71b60254e4ad388f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee02da9d2f6d28dc6e5c39f908f71820e925ce1b", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/v1jYKbJQG64j9YIa8o09Nnj386fjD8WmiwjaFOk9J5E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ba7a4f2ef018c543e69ad32c884494bdcadc2543", "width": 1080, "height": 540}], "variants": {}, "id": "a_n2GxAwj_f17W6xqN2FO3Y2b2YmsmfGk05Lw1oNnEc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181uv84", "is_robot_indexable": true, "report_reasons": null, "author": "LoquatAlternative680", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181uv84/apache_spark_operators_for_k8s/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181uv84/apache_spark_operators_for_k8s/", "subreddit_subscribers": 141357, "created_utc": 1700721026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. I work as a Business Analyst in a startup that is about to be funded. I always thought about what should be an ideal data stack for us, since we don't have many resources, such as a DW, and most of the reports/dashboards consume data directly from the source using Power Query. \n\nBut I had a talk with the CEO today and he told me to plan what we need to truly build our data environment. \n\nIn my mind, the first thing we should do is to develop a cloud DW, consuming data from our multiple sources (mostly APIs and relational DBs). I have talked a bit with a couple of AIs to expand my views, but I wanted to hear from more experienced professionals. \n\n\\- What tools do I need to build it from scratch?\n\n\\- What processes need to be done?\n\n\\- What costs should I be aware of?\n\n\\- What knowledge base do you recommend?\n\n\\- What **else** should I be aware of?\n\nFrom an outside view, I can imagine it being built within the Microsoft stack, using Data Factory and Data Warehouse.\n\nThanks in advance!", "author_fullname": "t2_8ss95xyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Analyst got a DE (?) Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182a674", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700771396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I work as a Business Analyst in a startup that is about to be funded. I always thought about what should be an ideal data stack for us, since we don&amp;#39;t have many resources, such as a DW, and most of the reports/dashboards consume data directly from the source using Power Query. &lt;/p&gt;\n\n&lt;p&gt;But I had a talk with the CEO today and he told me to plan what we need to truly build our data environment. &lt;/p&gt;\n\n&lt;p&gt;In my mind, the first thing we should do is to develop a cloud DW, consuming data from our multiple sources (mostly APIs and relational DBs). I have talked a bit with a couple of AIs to expand my views, but I wanted to hear from more experienced professionals. &lt;/p&gt;\n\n&lt;p&gt;- What tools do I need to build it from scratch?&lt;/p&gt;\n\n&lt;p&gt;- What processes need to be done?&lt;/p&gt;\n\n&lt;p&gt;- What costs should I be aware of?&lt;/p&gt;\n\n&lt;p&gt;- What knowledge base do you recommend?&lt;/p&gt;\n\n&lt;p&gt;- What &lt;strong&gt;else&lt;/strong&gt; should I be aware of?&lt;/p&gt;\n\n&lt;p&gt;From an outside view, I can imagine it being built within the Microsoft stack, using Data Factory and Data Warehouse.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182a674", "is_robot_indexable": true, "report_reasons": null, "author": "Practical_Gap_3354", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182a674/business_analyst_got_a_de_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182a674/business_analyst_got_a_de_project/", "subreddit_subscribers": 141357, "created_utc": 1700771396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\n37F \n\nSeeking advice on useful, practical gifts I can get my brother\n\nHe is a beginner coder and is building experience, networking, etc \n\nHe is not yet at the point of searching for jobs, but will be within some months \n\nI have read other threads and found suggestions for books such as three easy pieces and DDIA\n\nSaw a workbook that accompany DDIA and thought maybe that would be practical?\n\nI really want to give him something that will include new and useful information \n\nPlease help!\n\nThank you so much", "author_fullname": "t2_dk413ars", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please advise: Christmas gifts for brother who is beginner coder and programmer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181sldl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700712731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;37F &lt;/p&gt;\n\n&lt;p&gt;Seeking advice on useful, practical gifts I can get my brother&lt;/p&gt;\n\n&lt;p&gt;He is a beginner coder and is building experience, networking, etc &lt;/p&gt;\n\n&lt;p&gt;He is not yet at the point of searching for jobs, but will be within some months &lt;/p&gt;\n\n&lt;p&gt;I have read other threads and found suggestions for books such as three easy pieces and DDIA&lt;/p&gt;\n\n&lt;p&gt;Saw a workbook that accompany DDIA and thought maybe that would be practical?&lt;/p&gt;\n\n&lt;p&gt;I really want to give him something that will include new and useful information &lt;/p&gt;\n\n&lt;p&gt;Please help!&lt;/p&gt;\n\n&lt;p&gt;Thank you so much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181sldl", "is_robot_indexable": true, "report_reasons": null, "author": "Cripkate", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181sldl/please_advise_christmas_gifts_for_brother_who_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181sldl/please_advise_christmas_gifts_for_brother_who_is/", "subreddit_subscribers": 141357, "created_utc": 1700712731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My workplace makes queries to data in Snowflake, from Databricks, but it seems like Snowflake is working hard to develop their own ETL, ML pipelines using NVIDIA Rapids/GPU computing even.\n\nI have been signing up for online seminars on Snowflake data science/data engineering because I have a problem with Databricks.\n\nI want to use OpenZiti on Databricks so only client machines with a Ziti identity can connect to the Databricks.  The Databricks itself needs an OpenZiti identity so it can connect to an Ziti Edge Router which in turn would connect to Ziti Edge Router on Azure that connects to my web app on Azure.  From here I want to use Azure private link to connect to OpenAI services (natural language -&gt; SQL query) and to my Snowflake on Azure.\n\nSo the Snowflake on Azure can be totally cut off from the internet as well as my web app on Azure.  But Databricks does not have this capability, ie. close of all incoming ports, only outbound to Ziti edge router and have a Ziti identity.\n\n&amp;#x200B;", "author_fullname": "t2_7bmygxmk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks becoming redundant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182fuyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700788080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My workplace makes queries to data in Snowflake, from Databricks, but it seems like Snowflake is working hard to develop their own ETL, ML pipelines using NVIDIA Rapids/GPU computing even.&lt;/p&gt;\n\n&lt;p&gt;I have been signing up for online seminars on Snowflake data science/data engineering because I have a problem with Databricks.&lt;/p&gt;\n\n&lt;p&gt;I want to use OpenZiti on Databricks so only client machines with a Ziti identity can connect to the Databricks.  The Databricks itself needs an OpenZiti identity so it can connect to an Ziti Edge Router which in turn would connect to Ziti Edge Router on Azure that connects to my web app on Azure.  From here I want to use Azure private link to connect to OpenAI services (natural language -&amp;gt; SQL query) and to my Snowflake on Azure.&lt;/p&gt;\n\n&lt;p&gt;So the Snowflake on Azure can be totally cut off from the internet as well as my web app on Azure.  But Databricks does not have this capability, ie. close of all incoming ports, only outbound to Ziti edge router and have a Ziti identity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182fuyq", "is_robot_indexable": true, "report_reasons": null, "author": "webNoob13", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182fuyq/is_databricks_becoming_redundant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182fuyq/is_databricks_becoming_redundant/", "subreddit_subscribers": 141357, "created_utc": 1700788080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a question on how you would approach this data model design. \n\nMy data model records Sales Revenue, with the special case that a Sales Transaction can generate Sales Revenue for multiple offices.\n\nAn example of a Sales Transactions worth 10k can generate 3k revenue for Office 1 and 7k revenue for Office 2.\n\nCurrently, my revenue fact table stores the generated revenue like this:\noffice_key, date_key, transaction_key, revenue_amount\n\nI have a reporting requirement where I want to drill through from revenue on a certain day to the transactions that attributed to revenue on that day. \n\nDoes it make sense to link from my revenue fact table to the transaction fact table by transaction_key?", "author_fullname": "t2_75hil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data modelling question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181xfa5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700731517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question on how you would approach this data model design. &lt;/p&gt;\n\n&lt;p&gt;My data model records Sales Revenue, with the special case that a Sales Transaction can generate Sales Revenue for multiple offices.&lt;/p&gt;\n\n&lt;p&gt;An example of a Sales Transactions worth 10k can generate 3k revenue for Office 1 and 7k revenue for Office 2.&lt;/p&gt;\n\n&lt;p&gt;Currently, my revenue fact table stores the generated revenue like this:\noffice_key, date_key, transaction_key, revenue_amount&lt;/p&gt;\n\n&lt;p&gt;I have a reporting requirement where I want to drill through from revenue on a certain day to the transactions that attributed to revenue on that day. &lt;/p&gt;\n\n&lt;p&gt;Does it make sense to link from my revenue fact table to the transaction fact table by transaction_key?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181xfa5", "is_robot_indexable": true, "report_reasons": null, "author": "dezwarteridder", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181xfa5/data_modelling_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181xfa5/data_modelling_question/", "subreddit_subscribers": 141357, "created_utc": 1700731517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_21nis1o2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bytebase 2.11.1: Customizable Masking Algorithms and Semantic Types for Data Masking.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_181wcsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/xnwNlxiy3NEewXf9I3GeJglGBjK-ouKeZwNC4x8PaP0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700726992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytebase.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bytebase.com/changelog/bytebase-2-11-1/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?auto=webp&amp;s=5a0d045c73f3056936040c38b958372d7a8b3b90", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a025e4dc2b64f4e27c3095e2dd5bb691a617f886", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5855fcee9ca13834409984a1c10f7b26d47c6b58", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7476df5b07a773ddbeffb85005820d0106fe224d", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e9479518ee288617b4eb8069328ae130a25ad37f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e45aa6537e51539ae95e464d6d5b0c3c700afc2", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/imRbdfXgVGZpJ8LZ74Lu-CUoFgnchJ3kZ_BRGC13ZEE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91898d2a32ec5b83c3275f62b25a3759b99e1ca9", "width": 1080, "height": 607}], "variants": {}, "id": "Mh3ROjg5Y--EPzTtldGfm0Gm4BDULuaJj3U5jVSs3t8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "181wcsb", "is_robot_indexable": true, "report_reasons": null, "author": "placestamphere_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181wcsb/bytebase_2111_customizable_masking_algorithms_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bytebase.com/changelog/bytebase-2-11-1/", "subreddit_subscribers": 141357, "created_utc": 1700726992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uwe2fsd1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Scrape Walmart Data with Ease: A Step-by-Step Guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_181vwrj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3plBK_xTsipBzZ3dQp_mQ_KCyV2EMnOyF4wqS7k_EUw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700725154.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "plainenglish.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://plainenglish.io/blog/how-to-scrape-walmart-data-with-ease-a-step-by-step-guide", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?auto=webp&amp;s=78ee7a2f14f06e28fa21f1e29273dda95ec16c96", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6831353729e3e9e5a1f112b9c293ee70cf14a525", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=afe587eeb1ff23d291fac7c37a1d17ca2bab83c1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=951b06eaf8e3f3a420df8ceadcb83ad01e2aae07", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=448432bf5f0c4b8ce1b1b0b73efb44569437cb56", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dbf0a3a452f7c87cbe75fc5d057def73fcb7aa61", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/7K6aB6miR_LFO4dTIiQo6en3LJo9zuOn4s2lenKsWno.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a9cc05477d7949381f297e160a3d3f2b74673d5", "width": 1080, "height": 567}], "variants": {}, "id": "9I1SgUFBzx1BX6uI79jcxcfAPoqd3CQW7hWPvc-4lZc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "181vwrj", "is_robot_indexable": true, "report_reasons": null, "author": "TheLostWanderer47", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181vwrj/how_to_scrape_walmart_data_with_ease_a_stepbystep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://plainenglish.io/blog/how-to-scrape-walmart-data-with-ease-a-step-by-step-guide", "subreddit_subscribers": 141357, "created_utc": 1700725154.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "32m here have 5+ years of support engineer experience and currently working as security support engineer with company for 3 years which has no technical background. I want to move into data analyst or data engineering role i have basic sql and python knowledge. I have 2 months spare time planning to learn new skills and land a job with 60+ salary. Please advise on which ones to choose and what skills i need to learn \n(P.s - i do have masters in data analytics)\n\nThanks for the help.", "author_fullname": "t2_ci3pz2nj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_182g2yx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700788811.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;32m here have 5+ years of support engineer experience and currently working as security support engineer with company for 3 years which has no technical background. I want to move into data analyst or data engineering role i have basic sql and python knowledge. I have 2 months spare time planning to learn new skills and land a job with 60+ salary. Please advise on which ones to choose and what skills i need to learn \n(P.s - i do have masters in data analytics)&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182g2yx", "is_robot_indexable": true, "report_reasons": null, "author": "Jumpy_Music_187", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182g2yx/need_advise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182g2yx/need_advise/", "subreddit_subscribers": 141357, "created_utc": 1700788811.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I\u2019m very new to working in Azure and with ADFs. I\u2019m working on a project where I need to transform XML files to a CSV output in a specific format. I\u2019ve managed to implement a data flow to get the transformation working as intended, with a blob container for the source and sink respectively. It works as intended when I have one file in the source blob, but when I try with multiple it starts to act a bit weird and tries pulling data from each file into one csv file I think? Ideally I want it so that a specific csv file is generated for each xml file in the source system. Even better if I could get the ADF to trigger with a new blob created and only process the most recently uploaded files. I\u2019ve tried figuring this out but I\u2019m pretty stuck with this processing source items separately thing, is this a for each I should be using?", "author_fullname": "t2_rrfc2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF data flow, scaling up for multiple file inputs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181yrb3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700737144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m very new to working in Azure and with ADFs. I\u2019m working on a project where I need to transform XML files to a CSV output in a specific format. I\u2019ve managed to implement a data flow to get the transformation working as intended, with a blob container for the source and sink respectively. It works as intended when I have one file in the source blob, but when I try with multiple it starts to act a bit weird and tries pulling data from each file into one csv file I think? Ideally I want it so that a specific csv file is generated for each xml file in the source system. Even better if I could get the ADF to trigger with a new blob created and only process the most recently uploaded files. I\u2019ve tried figuring this out but I\u2019m pretty stuck with this processing source items separately thing, is this a for each I should be using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181yrb3", "is_robot_indexable": true, "report_reasons": null, "author": "EvilDoctorShadex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181yrb3/adf_data_flow_scaling_up_for_multiple_file_inputs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181yrb3/adf_data_flow_scaling_up_for_multiple_file_inputs/", "subreddit_subscribers": 141357, "created_utc": 1700737144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have hands-on work experience in python, SQL and frameoworks like SQL alchemy pandas and Numpy. I know basics of other frameworks such as django, react js and react native. \n\nI need to get a job as fast as possible, orphan will need to leave uncles house in 6 months.  \nI dont have a degree but i have worked with a early stage startup writing some I/O scripts I am confused as on what type of portfolio projects i should work on to land me a job in next 6 months. As i have better hands on backend stuff and i just got to know the work i did is actually part of data engineering(correct me if im wrong)\n\nDo employers in data engineering field even consider guys with no degree? if yes, please suggest some portfolio projects. Thanks.", "author_fullname": "t2_vffigorh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In which field its easier to get jobs through portfolio projects - data eng or web dev?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181qsng", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700706865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hands-on work experience in python, SQL and frameoworks like SQL alchemy pandas and Numpy. I know basics of other frameworks such as django, react js and react native. &lt;/p&gt;\n\n&lt;p&gt;I need to get a job as fast as possible, orphan will need to leave uncles house in 6 months.&lt;br/&gt;\nI dont have a degree but i have worked with a early stage startup writing some I/O scripts I am confused as on what type of portfolio projects i should work on to land me a job in next 6 months. As i have better hands on backend stuff and i just got to know the work i did is actually part of data engineering(correct me if im wrong)&lt;/p&gt;\n\n&lt;p&gt;Do employers in data engineering field even consider guys with no degree? if yes, please suggest some portfolio projects. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "181qsng", "is_robot_indexable": true, "report_reasons": null, "author": "guvavava", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181qsng/in_which_field_its_easier_to_get_jobs_through/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181qsng/in_which_field_its_easier_to_get_jobs_through/", "subreddit_subscribers": 141357, "created_utc": 1700706865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Did anyone here managed it to create a table which has partition projection enabled.\n\nI can manage it via Athena, but i want to create it via Trino. Thats why my catalog is glue and the data on s3.\n\nCouldnt find examples in the docu for that", "author_fullname": "t2_kabee6pi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trino table partition projection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1827e97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700763415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did anyone here managed it to create a table which has partition projection enabled.&lt;/p&gt;\n\n&lt;p&gt;I can manage it via Athena, but i want to create it via Trino. Thats why my catalog is glue and the data on s3.&lt;/p&gt;\n\n&lt;p&gt;Couldnt find examples in the docu for that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1827e97", "is_robot_indexable": true, "report_reasons": null, "author": "WeaknessNecessary657", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1827e97/trino_table_partition_projection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1827e97/trino_table_partition_projection/", "subreddit_subscribers": 141357, "created_utc": 1700763415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have experience orchestrating AKS containers via Airflow? At the moment we are using a kubectl cli command to alert the agent pool to run in a bash operator in airflow, but doing so doesn\u2019t actually wait for the task to finish or provide any indication of if the task succeeded or failed.", "author_fullname": "t2_9d5p6jq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure K8s Service via Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18217zc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700746173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have experience orchestrating AKS containers via Airflow? At the moment we are using a kubectl cli command to alert the agent pool to run in a bash operator in airflow, but doing so doesn\u2019t actually wait for the task to finish or provide any indication of if the task succeeded or failed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18217zc", "is_robot_indexable": true, "report_reasons": null, "author": "avclipavclip", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18217zc/azure_k8s_service_via_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18217zc/azure_k8s_service_via_airflow/", "subreddit_subscribers": 141357, "created_utc": 1700746173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Is adopting this approach advisable? I granted the Cloud Function Service Agent role to the Cloud Function Service Agent Service Account in another project, enabling Cloud Functions to trigger upon the arrival of new files. However, due to the absence of official documentation or troubleshooting specifics for this use case, I remain uncertain. Your assistance would be appreciated. ", "author_fullname": "t2_4cullil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud function storage trigger on bucket of other project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181xqek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700732819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is adopting this approach advisable? I granted the Cloud Function Service Agent role to the Cloud Function Service Agent Service Account in another project, enabling Cloud Functions to trigger upon the arrival of new files. However, due to the absence of official documentation or troubleshooting specifics for this use case, I remain uncertain. Your assistance would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181xqek", "is_robot_indexable": true, "report_reasons": null, "author": "tmanipra", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181xqek/cloud_function_storage_trigger_on_bucket_of_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181xqek/cloud_function_storage_trigger_on_bucket_of_other/", "subreddit_subscribers": 141357, "created_utc": 1700732819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udc4b Hey, check out my latest dagster tutorial video of how to build you first asset graph \ud83d\ude1c.", "author_fullname": "t2_h4j43yry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Tutorial: Building an Asset Graph", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_181wqix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gi3tOjDeMVY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Building an Asset Graph\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Dagster Tutorial: Building an Asset Graph", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gi3tOjDeMVY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Building an Asset Graph\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/gi3tOjDeMVY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gi3tOjDeMVY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Building an Asset Graph\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/181wqix", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JdVuKSIMCHm5yN8UxQ4VD97rzhpQSh4ayGHRAdZL5K0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700728616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udc4b Hey, check out my latest dagster tutorial video of how to build you first asset graph \ud83d\ude1c.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/gi3tOjDeMVY", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lKk_aYdpYV1ji2yTG6DXHUHuVHU9TCt5-S98mjsS_w8.jpg?auto=webp&amp;s=4067ae987c49a2f460061d25e2467f07bf97a515", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/lKk_aYdpYV1ji2yTG6DXHUHuVHU9TCt5-S98mjsS_w8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25d686673dacee5bcd563bf6aaed33da7c67df5d", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/lKk_aYdpYV1ji2yTG6DXHUHuVHU9TCt5-S98mjsS_w8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c008ab0fbc8b45967deafb43286b1c7099e3c951", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/lKk_aYdpYV1ji2yTG6DXHUHuVHU9TCt5-S98mjsS_w8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de322f5e14cce9981f95f044f8cf1fd25fcf307e", "width": 320, "height": 240}], "variants": {}, "id": "0agbsI1_biZWYJATsFgLDkhG0PU3wLlUKsi_wcuH0zA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "181wqix", "is_robot_indexable": true, "report_reasons": null, "author": "Coder2j", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181wqix/dagster_tutorial_building_an_asset_graph/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/gi3tOjDeMVY", "subreddit_subscribers": 141357, "created_utc": 1700728616.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Dagster Tutorial: Building an Asset Graph", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/gi3tOjDeMVY?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Building an Asset Graph\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/gi3tOjDeMVY/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. I'm sorry to ask this but I've been looking everywhere and don't seem to find any source or example. I'm new to a data engineering position in a financial institution, and they asked me how can they establish a risk catalog, meaning which of the data has the highest risk. Since every piece of data is confidential (obviously)  how can they establish higher risk and based on what?? Been reading DAMA book on data security, but it speaks too broadly of this subject. Do you recommend any sources?", "author_fullname": "t2_6c61zfmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sources for risk catalog??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_181s54c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700711192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I&amp;#39;m sorry to ask this but I&amp;#39;ve been looking everywhere and don&amp;#39;t seem to find any source or example. I&amp;#39;m new to a data engineering position in a financial institution, and they asked me how can they establish a risk catalog, meaning which of the data has the highest risk. Since every piece of data is confidential (obviously)  how can they establish higher risk and based on what?? Been reading DAMA book on data security, but it speaks too broadly of this subject. Do you recommend any sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "181s54c", "is_robot_indexable": true, "report_reasons": null, "author": "omar_firestorm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/181s54c/sources_for_risk_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/181s54c/sources_for_risk_catalog/", "subreddit_subscribers": 141357, "created_utc": 1700711192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_h557nj7lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "44 Best Resources to learn Data Engineering (YouTube, Books, Courses, &amp; Tutorials)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_1823qih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CqnD0jXp1zy-FvPpGjVU-Jw9G9sUiC_Xd-9NZ2V_A3c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700753655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mltut.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.mltut.com/best-resources-to-learn-data-engineering/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?auto=webp&amp;s=a500e2d0a55645b45e0cebf7674818a8b1a001ec", "width": 2240, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=846b2e4d36e11dd8b46ba3ae70e61fe3cb2d6be6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=93e59e083e2cd40196a9c0e4ea2783db8f4a95a3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a47b29eae87c633967e98ac37f5cd8052261793", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d441865f1baacfeef03dee52e49abfad9bb30a7e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3fc69de998a7ca3ca810b9446754b56529c75f73", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1NkFMNXwXvVR1OEIDUFJu02P5zdR_ceifYkBd6ehlEc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=efcb52b6d7702e76f91f823e3c4894de7dda24e9", "width": 1080, "height": 607}], "variants": {}, "id": "Dfiy7g_nIo24a7MPAubj8Jy84Wz8r8RZoQE-MJidPWc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1823qih", "is_robot_indexable": true, "report_reasons": null, "author": "Aqsa81", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1823qih/44_best_resources_to_learn_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.mltut.com/best-resources-to-learn-data-engineering/", "subreddit_subscribers": 141357, "created_utc": 1700753655.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}