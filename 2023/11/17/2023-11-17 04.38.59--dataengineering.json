{"kind": "Listing", "data": {"after": "t3_17wncmv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of our ETL jobs are python scripts that hit APIs and write to a blob storage. Data is small, so I don\u2019t need any tools like spark. What are some easier tools to schedule and run these python jobs?\n\nI tried using AWS lambda functions, but there are significant limitations like 15 minute max timeouts or maximum size is for uploading python environments.\n\nAirflow on a server is ideal, but extremely difficult to set up and manage currently. Companies that manage it for you (like astronomer) are pretty expensive.\n\nAnyone used Dagster?", "author_fullname": "t2_50i9ola", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Python Jobs in cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wragh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700152660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of our ETL jobs are python scripts that hit APIs and write to a blob storage. Data is small, so I don\u2019t need any tools like spark. What are some easier tools to schedule and run these python jobs?&lt;/p&gt;\n\n&lt;p&gt;I tried using AWS lambda functions, but there are significant limitations like 15 minute max timeouts or maximum size is for uploading python environments.&lt;/p&gt;\n\n&lt;p&gt;Airflow on a server is ideal, but extremely difficult to set up and manage currently. Companies that manage it for you (like astronomer) are pretty expensive.&lt;/p&gt;\n\n&lt;p&gt;Anyone used Dagster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wragh", "is_robot_indexable": true, "report_reasons": null, "author": "D-2-The-Ave", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wragh/running_python_jobs_in_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wragh/running_python_jobs_in_cloud/", "subreddit_subscribers": 140069, "created_utc": 1700152660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at an SME and am building out our DBT infra. Currently a full DBT run on 60 models takes about 12 minutes without any incremental models. Interested to hear just how big these projects get, and potentially some ways to optimise as it grows in size.", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long are your DBT Runs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wdvh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700108467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at an SME and am building out our DBT infra. Currently a full DBT run on 60 models takes about 12 minutes without any incremental models. Interested to hear just how big these projects get, and potentially some ways to optimise as it grows in size.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wdvh8", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wdvh8/how_long_are_your_dbt_runs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wdvh8/how_long_are_your_dbt_runs/", "subreddit_subscribers": 140069, "created_utc": 1700108467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking at Datahub, Amundsen and Atlan.\nEach looks great and Im looking to get some reviews from personal experience. \nIf you have experience with more than one tool - even better! \nMy end goal here is to let new employees a great head start and lower dependancy on power users and other sources. \nMainly an holistic view of the data stream", "author_fullname": "t2_9wdo6orq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data catalog tool - reviews needed!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wj6dc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700128430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking at Datahub, Amundsen and Atlan.\nEach looks great and Im looking to get some reviews from personal experience. \nIf you have experience with more than one tool - even better! \nMy end goal here is to let new employees a great head start and lower dependancy on power users and other sources. \nMainly an holistic view of the data stream&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wj6dc", "is_robot_indexable": true, "report_reasons": null, "author": "Old-Abalone703", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wj6dc/data_catalog_tool_reviews_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wj6dc/data_catalog_tool_reviews_needed/", "subreddit_subscribers": 140069, "created_utc": 1700128430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, my organization is currently evaluating Foundry to help solve some of our warehouse and supply chain issues. We already have an agreement with google and use that for our cloud services, almost all of our data is migrated into the cloud.\n\nMy understanding after reviewing Foundry is that it is itself a data platform, with a UI and advanced analytics on top. \n\nOur organization has several engineering teams but the org leadership feels this would be too big of a project to homegrow ( I disagree as Palantir just looks like spark jobs under the hood) .\n\nWondering what your experience is about the following items\n\n&amp;#x200B;\n\n* Managing the ontology? Importing data definitions (how manual of a process is this? I am thinking a lot of data would be duplicated with our google data cataloging tool, any integrations?)\n* How many resources on your side keep the system up? Are they technical?\n* Model development: what does that look like? Are there out of the box predictive models or are you developing them from ground up?", "author_fullname": "t2_5par13m8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your experiences with Palantir Foundry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wvf53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700163456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, my organization is currently evaluating Foundry to help solve some of our warehouse and supply chain issues. We already have an agreement with google and use that for our cloud services, almost all of our data is migrated into the cloud.&lt;/p&gt;\n\n&lt;p&gt;My understanding after reviewing Foundry is that it is itself a data platform, with a UI and advanced analytics on top. &lt;/p&gt;\n\n&lt;p&gt;Our organization has several engineering teams but the org leadership feels this would be too big of a project to homegrow ( I disagree as Palantir just looks like spark jobs under the hood) .&lt;/p&gt;\n\n&lt;p&gt;Wondering what your experience is about the following items&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Managing the ontology? Importing data definitions (how manual of a process is this? I am thinking a lot of data would be duplicated with our google data cataloging tool, any integrations?)&lt;/li&gt;\n&lt;li&gt;How many resources on your side keep the system up? Are they technical?&lt;/li&gt;\n&lt;li&gt;Model development: what does that look like? Are there out of the box predictive models or are you developing them from ground up?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wvf53", "is_robot_indexable": true, "report_reasons": null, "author": "rysnotnice", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wvf53/your_experiences_with_palantir_foundry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wvf53/your_experiences_with_palantir_foundry/", "subreddit_subscribers": 140069, "created_utc": 1700163456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is something I hear about very often in media but I know no one who has held down more than one job in this field personally. I only have two years of experience (been extremely fortunate they have been Data Engineer jobs) so maybe I simply haven\u2019t seen enough yet. \n\nIt just feels impossible to me, nor would I ever want to. I\u2019m exploring doing freelancing down the line purely as a side gig and I recognize that as a big commitment. Even with the whole \u201cyou don\u2019t really work 8 hours a day\u201d there\u2019s so much that can go logistically wrong with two jobs.\n\nThis feels like a lot like salary talk where some tech people are bragging about and exaggerating what they\u2019re actually doing, and whole media narratives have been spun from what likely represents an extremely small minority of employees.", "author_fullname": "t2_sz695ecm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here know people who are actually \u201cover employed\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ws3d4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700154674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something I hear about very often in media but I know no one who has held down more than one job in this field personally. I only have two years of experience (been extremely fortunate they have been Data Engineer jobs) so maybe I simply haven\u2019t seen enough yet. &lt;/p&gt;\n\n&lt;p&gt;It just feels impossible to me, nor would I ever want to. I\u2019m exploring doing freelancing down the line purely as a side gig and I recognize that as a big commitment. Even with the whole \u201cyou don\u2019t really work 8 hours a day\u201d there\u2019s so much that can go logistically wrong with two jobs.&lt;/p&gt;\n\n&lt;p&gt;This feels like a lot like salary talk where some tech people are bragging about and exaggerating what they\u2019re actually doing, and whole media narratives have been spun from what likely represents an extremely small minority of employees.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ws3d4", "is_robot_indexable": true, "report_reasons": null, "author": "clark_sterling", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ws3d4/does_anyone_here_know_people_who_are_actually/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ws3d4/does_anyone_here_know_people_who_are_actually/", "subreddit_subscribers": 140069, "created_utc": 1700154674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\nThis is the first time I'm designing a data model for an analytics project. I would love to hear some suggestions and guidance. We are using Snowflake + dbt. \n\nThere are collectors which query source systems using API's and do fresh dumps everyday (There could potentially be no change in records other than arrival timestamps). A simple use case right now is we collect list of instances running across all AWS accounts and check for some tag compliance. From receiving the dumps, how do should I plan it? What does dim and fact look like for this? My biggest struggle has been figuring out how to use the timestamp.   \n\n\n&amp;#x200B;", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modelling Suggestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wguez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700118723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;This is the first time I&amp;#39;m designing a data model for an analytics project. I would love to hear some suggestions and guidance. We are using Snowflake + dbt. &lt;/p&gt;\n\n&lt;p&gt;There are collectors which query source systems using API&amp;#39;s and do fresh dumps everyday (There could potentially be no change in records other than arrival timestamps). A simple use case right now is we collect list of instances running across all AWS accounts and check for some tag compliance. From receiving the dumps, how do should I plan it? What does dim and fact look like for this? My biggest struggle has been figuring out how to use the timestamp.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wguez", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wguez/data_modelling_suggestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wguez/data_modelling_suggestion/", "subreddit_subscribers": 140069, "created_utc": 1700118723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have two completely separate questions but might as well make it as one.  \n\n\nFirst, I just wanted to know if anyone here uses Neovim? It's very straightforward when looking at a Software Engineer proejct but I am not sure if you find it useful or efficiency improving in DE?  If you do what kind of workflow do you have that makes you like it?\n\nSecond is do you use Jupyter Notebooks in your workflow? Not necessarily in production pipelines but any place you use it. Personally, we have a NoSQL database and at times I have to manually insert data into our Warehouse. So I use boto3 in Jupyter Notebook, query the data, experiment with how to transform it with pandas, and finally insert it. It works for now but something about it feels distasteful honestly. Writing one long blob per notebook and having one per boto3 query makes me feel bad.\n\nWanted to know your thoughts?", "author_fullname": "t2_jt4dxcgmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Neovim and Jupyter Notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wtnyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700158859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two completely separate questions but might as well make it as one.  &lt;/p&gt;\n\n&lt;p&gt;First, I just wanted to know if anyone here uses Neovim? It&amp;#39;s very straightforward when looking at a Software Engineer proejct but I am not sure if you find it useful or efficiency improving in DE?  If you do what kind of workflow do you have that makes you like it?&lt;/p&gt;\n\n&lt;p&gt;Second is do you use Jupyter Notebooks in your workflow? Not necessarily in production pipelines but any place you use it. Personally, we have a NoSQL database and at times I have to manually insert data into our Warehouse. So I use boto3 in Jupyter Notebook, query the data, experiment with how to transform it with pandas, and finally insert it. It works for now but something about it feels distasteful honestly. Writing one long blob per notebook and having one per boto3 query makes me feel bad.&lt;/p&gt;\n\n&lt;p&gt;Wanted to know your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wtnyb", "is_robot_indexable": true, "report_reasons": null, "author": "codeejen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wtnyb/thoughts_on_neovim_and_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wtnyb/thoughts_on_neovim_and_jupyter_notebooks/", "subreddit_subscribers": 140069, "created_utc": 1700158859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \nI am working in a start up and we are looking for tools which would help collect data into place from which it could be queried and visualised. \nHowever, when it comes data sources- we have explored a couple of tools such as Grafana and Datadog \n\nOur main sources of data can range from google sheets to salesforce. \n\nI am looking for suggestions which can help with the same. \nThank you!", "author_fullname": "t2_6qhb8q3z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lake- tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wi9kk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700124577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, \nI am working in a start up and we are looking for tools which would help collect data into place from which it could be queried and visualised. \nHowever, when it comes data sources- we have explored a couple of tools such as Grafana and Datadog &lt;/p&gt;\n\n&lt;p&gt;Our main sources of data can range from google sheets to salesforce. &lt;/p&gt;\n\n&lt;p&gt;I am looking for suggestions which can help with the same. \nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wi9kk", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-79605", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wi9kk/data_lake_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wi9kk/data_lake_tools/", "subreddit_subscribers": 140069, "created_utc": 1700124577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, this is my first post here :)\n\nIn the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse\n\nThere is one question, where I don't really find a satisfying answer on the internet though:\n\nHow do I design a good data structure in a data lakehouse?\n\nDo I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.\n\nMaybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  \n", "author_fullname": "t2_36ze7ll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I design a data structure in a data lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wylwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700171706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, this is my first post here :)&lt;/p&gt;\n\n&lt;p&gt;In the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse&lt;/p&gt;\n\n&lt;p&gt;There is one question, where I don&amp;#39;t really find a satisfying answer on the internet though:&lt;/p&gt;\n\n&lt;p&gt;How do I design a good data structure in a data lakehouse?&lt;/p&gt;\n\n&lt;p&gt;Do I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.&lt;/p&gt;\n\n&lt;p&gt;Maybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wylwb", "is_robot_indexable": true, "report_reasons": null, "author": "nilsii27", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "subreddit_subscribers": 140069, "created_utc": 1700171706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nI\u2019m looking for a (preferably all-in-one) solution that covers typical capabilities of a catalog (metadata discovery, lineage, dashboards, governance-my-this-and-that, etc.) as well as functionality for more data user/consumer facing exploration/discovery/search like a data library or registry or whatever is the correct term. \nAny suggestions?\nThanks in advance!", "author_fullname": "t2_vek16rwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog and Library in One Solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ws10m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700154505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI\u2019m looking for a (preferably all-in-one) solution that covers typical capabilities of a catalog (metadata discovery, lineage, dashboards, governance-my-this-and-that, etc.) as well as functionality for more data user/consumer facing exploration/discovery/search like a data library or registry or whatever is the correct term. \nAny suggestions?\nThanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ws10m", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Day_6476", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ws10m/data_catalog_and_library_in_one_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ws10m/data_catalog_and_library_in_one_solution/", "subreddit_subscribers": 140069, "created_utc": 1700154505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm doing an analytisc engineering challenge where I'm supposed to create an MRR data model. I don't actually have real data to work with--I'm just supposed to think about what the source data and analytical model might look like, mock up a sample table and SQL queries to address common KPIs.\n\nPart of the instructions is that I should consider performance issues in the model given that they have thousands of users. But how am I supposed to consider performance issues theoretically if I'm not working with data? At work I usually do \"experiments\"--write two SQL queries and compare how they perform.\n\nIt's just that no matter what kind of model I develop now, there's really no way of telling whether it will be performant or not if there's no real data to work with. Or am I missing something?", "author_fullname": "t2_7m2ues2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Your data model should take into consideration possible performance issues\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wqu3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700151540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing an analytisc engineering challenge where I&amp;#39;m supposed to create an MRR data model. I don&amp;#39;t actually have real data to work with--I&amp;#39;m just supposed to think about what the source data and analytical model might look like, mock up a sample table and SQL queries to address common KPIs.&lt;/p&gt;\n\n&lt;p&gt;Part of the instructions is that I should consider performance issues in the model given that they have thousands of users. But how am I supposed to consider performance issues theoretically if I&amp;#39;m not working with data? At work I usually do &amp;quot;experiments&amp;quot;--write two SQL queries and compare how they perform.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s just that no matter what kind of model I develop now, there&amp;#39;s really no way of telling whether it will be performant or not if there&amp;#39;s no real data to work with. Or am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wqu3u", "is_robot_indexable": true, "report_reasons": null, "author": "DataScienceIsScience", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wqu3u/your_data_model_should_take_into_consideration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wqu3u/your_data_model_should_take_into_consideration/", "subreddit_subscribers": 140069, "created_utc": 1700151540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone!\n\n&amp;#x200B;\n\nI work for a non-profit and we recently built a data management system to support our monitoring and evaluation efforts.\n\n&amp;#x200B;\n\nWe have been using Airtable as our data storage solution as its simplicity is very attractive. However, it starts to struggle when datasets get too large, and more so when there are multiple linkages built in. We are now looking for an alternative data storage solution.\n\n&amp;#x200B;\n\nRequirements for the solution:\n\n\\- Fairly simple to use\n\n\\- Relatively low code\n\n\\- Cost effective\n\n\\- Relational database\n\n\\- Cloud based and secure\n\nWe have looked into Google SQL - any thoughts on this?\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_t1mvr7oy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data storage solutions that are low code, secure, cloud based", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wipt9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700126477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I work for a non-profit and we recently built a data management system to support our monitoring and evaluation efforts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We have been using Airtable as our data storage solution as its simplicity is very attractive. However, it starts to struggle when datasets get too large, and more so when there are multiple linkages built in. We are now looking for an alternative data storage solution.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Requirements for the solution:&lt;/p&gt;\n\n&lt;p&gt;- Fairly simple to use&lt;/p&gt;\n\n&lt;p&gt;- Relatively low code&lt;/p&gt;\n\n&lt;p&gt;- Cost effective&lt;/p&gt;\n\n&lt;p&gt;- Relational database&lt;/p&gt;\n\n&lt;p&gt;- Cloud based and secure&lt;/p&gt;\n\n&lt;p&gt;We have looked into Google SQL - any thoughts on this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wipt9", "is_robot_indexable": true, "report_reasons": null, "author": "yaksurf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wipt9/data_storage_solutions_that_are_low_code_secure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wipt9/data_storage_solutions_that_are_low_code_secure/", "subreddit_subscribers": 140069, "created_utc": 1700126477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nWelcome back to the third episode of our Google Cloud Storage series. Today, I am delving deep into an advanced and vital aspect of storage management on GCP: Retention Policies. Ensure the safety and integrity of your data like never before!\n\n\ud83d\udccc What's Unpacked in this Video:\n\n\u2705 Retention Policy Basics: A brief refresher and deep dive into what retention policies are and why they're crucial.\n\n\u2705 Adding Retention Policies: Learn the step-by-step process of defining and applying retention policies to your data.\n\n\u2705 Locked vs. Unlocked Retention Policies: Understand the differences, benefits, and use cases of both locked and unlocked policies.\n\n\u2705 The Temporary Hold Feature: Grasp the nuances of the temporary hold, its applications, and how it interacts with your set policies.\n\n\u2705 Interactive Demo: A comprehensive hands-on demonstration, making it easier to understand and implement the discussed concepts.\n\n\ud83d\udccc [https://youtu.be/vqlg1gqW9ts](https://youtu.be/vqlg1gqW9ts)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pzw2tn8r3o0c1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=0a0fbba1fe850b525c2dbb74c58da7437d62f67c", "author_fullname": "t2_lbvus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 \ud83d\udd25 Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pzw2tn8r3o0c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2d4ed14974c7e7cadd8807c474a68da9bdb36a0"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8bf4fb40cfb4c2c8a25839c1bbc5dc01710958a"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0d6675f08fd0631eef63ec806e1258f1f149a76"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=428b6debd32ab0ce99bae8734a85840ae02eddcd"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7eec6f0eafe2909341d927c4e88165d3eec256f"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6982827dc89892c0c5d73eedde8bfa4b0999c92a"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=0a0fbba1fe850b525c2dbb74c58da7437d62f67c"}, "id": "pzw2tn8r3o0c1"}}, "name": "t3_17wholn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/vqlg1gqW9ts?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/vqlg1gqW9ts?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!\"&gt;&lt;/iframe&gt;", "author_name": "Technical Potpourri", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/vqlg1gqW9ts/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TechnicalPotpourri"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/vqlg1gqW9ts?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17wholn", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Gcer_uuQphoyKkLywRH9T2pRsIfo5hSMsOqyDitteNY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1700122077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome back to the third episode of our Google Cloud Storage series. Today, I am delving deep into an advanced and vital aspect of storage management on GCP: Retention Policies. Ensure the safety and integrity of your data like never before!&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udccc What&amp;#39;s Unpacked in this Video:&lt;/p&gt;\n\n&lt;p&gt;\u2705 Retention Policy Basics: A brief refresher and deep dive into what retention policies are and why they&amp;#39;re crucial.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Adding Retention Policies: Learn the step-by-step process of defining and applying retention policies to your data.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Locked vs. Unlocked Retention Policies: Understand the differences, benefits, and use cases of both locked and unlocked policies.&lt;/p&gt;\n\n&lt;p&gt;\u2705 The Temporary Hold Feature: Grasp the nuances of the temporary hold, its applications, and how it interacts with your set policies.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Interactive Demo: A comprehensive hands-on demonstration, making it easier to understand and implement the discussed concepts.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udccc &lt;a href=\"https://youtu.be/vqlg1gqW9ts\"&gt;https://youtu.be/vqlg1gqW9ts&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=0a0fbba1fe850b525c2dbb74c58da7437d62f67c\"&gt;https://preview.redd.it/pzw2tn8r3o0c1.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=0a0fbba1fe850b525c2dbb74c58da7437d62f67c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P_Q1RKy0PZJAvDtHfw5-uomHNk8jLrBZSjX57ILA8c4.jpg?auto=webp&amp;s=0652f395b21761011792c98e7816f735c6d457ee", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/P_Q1RKy0PZJAvDtHfw5-uomHNk8jLrBZSjX57ILA8c4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2315685ef4198dc5b2db596fa80fcda3552c30da", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/P_Q1RKy0PZJAvDtHfw5-uomHNk8jLrBZSjX57ILA8c4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a87bf5d5c4be1fe30904b18677f7a93a3770b90", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/P_Q1RKy0PZJAvDtHfw5-uomHNk8jLrBZSjX57ILA8c4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=417bc55067166501f6b7541105d43da187e14984", "width": 320, "height": 240}], "variants": {}, "id": "wBnYNUoDuJjylFRz-RE-mZHu0PX9jAEYqjoauSFqYGg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17wholn", "is_robot_indexable": true, "report_reasons": null, "author": "suddeb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wholn/mastering_google_cloud_storage_part_3_advanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wholn/mastering_google_cloud_storage_part_3_advanced/", "subreddit_subscribers": 140069, "created_utc": 1700122077.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/vqlg1gqW9ts?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Mastering Google Cloud Storage Part 3 - Advanced Concepts - Diving Deep into Retention Policies!\"&gt;&lt;/iframe&gt;", "author_name": "Technical Potpourri", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/vqlg1gqW9ts/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TechnicalPotpourri"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?\n\nMy idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a \"data lake\" in gcs and transform with a spark job in data proc, model this data to answer \"bussines problems\" and put into a datawatehouse (bq)\n\nIn my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a \"real Big data problem\"\n\nAny suggestions for my idea? Or any tips for personal projects?\n\nThanks you", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Places to find large amount of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17x5jun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700190677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?&lt;/p&gt;\n\n&lt;p&gt;My idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a &amp;quot;data lake&amp;quot; in gcs and transform with a spark job in data proc, model this data to answer &amp;quot;bussines problems&amp;quot; and put into a datawatehouse (bq)&lt;/p&gt;\n\n&lt;p&gt;In my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a &amp;quot;real Big data problem&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for my idea? Or any tips for personal projects?&lt;/p&gt;\n\n&lt;p&gt;Thanks you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17x5jun", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "subreddit_subscribers": 140069, "created_utc": 1700190677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?\n\nFew questions:\n\n1. help on how to bring about this transition, if possible.\n  Find a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? \n2. What technology stack is in great demand since I would be learning it from scratch \n3. Any certificate courses or Post Graduate courses that can help with the transition?", "author_fullname": "t2_1kd6shn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBA to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x40h9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700186185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?&lt;/p&gt;\n\n&lt;p&gt;Few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;help on how to bring about this transition, if possible.\nFind a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? &lt;/li&gt;\n&lt;li&gt;What technology stack is in great demand since I would be learning it from scratch &lt;/li&gt;\n&lt;li&gt;Any certificate courses or Post Graduate courses that can help with the transition?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17x40h9", "is_robot_indexable": true, "report_reasons": null, "author": "matados", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "subreddit_subscribers": 140069, "created_utc": 1700186185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I am thinking about developing a data engineering open source Python package and have some ideas, but I would like you to help me generate more ideas. What might be useful for you? I would like to build something that will be used later and hopefully to find additional contributors.", "author_fullname": "t2_2lt1q4pa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering Open Source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wzwni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700174956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I am thinking about developing a data engineering open source Python package and have some ideas, but I would like you to help me generate more ideas. What might be useful for you? I would like to build something that will be used later and hopefully to find additional contributors.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wzwni", "is_robot_indexable": true, "report_reasons": null, "author": "Kairo1004", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wzwni/data_engineering_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wzwni/data_engineering_open_source/", "subreddit_subscribers": 140069, "created_utc": 1700174956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,   \nat my current job I don't really learn a lot, and it's hard to get help too since everyone is busy doing their own thing.   \n\n\nWhat type of companies are good places to learn? I'm seriously thinking of finding a new job, because this place is stunting my growth.\n\n  \n ", "author_fullname": "t2_133hadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies where I can learn more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wxfpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700168752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nat my current job I don&amp;#39;t really learn a lot, and it&amp;#39;s hard to get help too since everyone is busy doing their own thing.   &lt;/p&gt;\n\n&lt;p&gt;What type of companies are good places to learn? I&amp;#39;m seriously thinking of finding a new job, because this place is stunting my growth.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17wxfpq", "is_robot_indexable": true, "report_reasons": null, "author": "generalNomnom", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "subreddit_subscribers": 140069, "created_utc": 1700168752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if anyone has experience with any privacy platforms such as transcend, datagrail, or oneTrust. We\u2019re looking to bring on a tool to help us automate a lot of privacy processes (like deletions and access requests). \n\nAnyone have a platform they really like or don\u2019t like? Also insights on how much a platform like these might cost a smaller company (less than 100 people, and only a 2 person data team). \n\nWe\u2019re wanting to bring on a tool because we may soon be subject to GDPR rules and need help navigating that and getting compliant quickly (and of course staying compliant).", "author_fullname": "t2_82zhjuv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Privacy Platforms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wr5fp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700152320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if anyone has experience with any privacy platforms such as transcend, datagrail, or oneTrust. We\u2019re looking to bring on a tool to help us automate a lot of privacy processes (like deletions and access requests). &lt;/p&gt;\n\n&lt;p&gt;Anyone have a platform they really like or don\u2019t like? Also insights on how much a platform like these might cost a smaller company (less than 100 people, and only a 2 person data team). &lt;/p&gt;\n\n&lt;p&gt;We\u2019re wanting to bring on a tool because we may soon be subject to GDPR rules and need help navigating that and getting compliant quickly (and of course staying compliant).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wr5fp", "is_robot_indexable": true, "report_reasons": null, "author": "Comprehensive-Ant251", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wr5fp/privacy_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wr5fp/privacy_platforms/", "subreddit_subscribers": 140069, "created_utc": 1700152320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a GRPC server(written in Python) that accepts incoming requests, and for each request calculates N features(let's say 100). Each feature is basically some kind of counter from the list of transactions. Currently, we go through every transaction, check specific feature filters(is greater, is between, is equal) and after all transactions are done, we calculate specific feature. This is done for every feature in pure Python(for loop, for each feature for every transactions..) over list of objects. There can be between 10 and 10k transactions.\n\nNow, I am looking for a faster way to do that. Speed is of the highest priority! On average 95% response time with pure Python is 100ms, with polars 400ms.\n\nWhat would be your suggestion to try? using sqlite, duckdb or some other way?", "author_fullname": "t2_83axkiwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast way to iterate over rows and calculate some aggregations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wp7l0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700147549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a GRPC server(written in Python) that accepts incoming requests, and for each request calculates N features(let&amp;#39;s say 100). Each feature is basically some kind of counter from the list of transactions. Currently, we go through every transaction, check specific feature filters(is greater, is between, is equal) and after all transactions are done, we calculate specific feature. This is done for every feature in pure Python(for loop, for each feature for every transactions..) over list of objects. There can be between 10 and 10k transactions.&lt;/p&gt;\n\n&lt;p&gt;Now, I am looking for a faster way to do that. Speed is of the highest priority! On average 95% response time with pure Python is 100ms, with polars 400ms.&lt;/p&gt;\n\n&lt;p&gt;What would be your suggestion to try? using sqlite, duckdb or some other way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wp7l0", "is_robot_indexable": true, "report_reasons": null, "author": "Few-Professional-125", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wp7l0/fast_way_to_iterate_over_rows_and_calculate_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wp7l0/fast_way_to_iterate_over_rows_and_calculate_some/", "subreddit_subscribers": 140069, "created_utc": 1700147549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone, I'm currently working at Amazon as an IC. I recently got an opportunity at Atlan for a managerial position. Wanted to check with the community if the switch is worth it. TIA", "author_fullname": "t2_antrhm7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switch to Atlan worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17woxqc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700146851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone, I&amp;#39;m currently working at Amazon as an IC. I recently got an opportunity at Atlan for a managerial position. Wanted to check with the community if the switch is worth it. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17woxqc", "is_robot_indexable": true, "report_reasons": null, "author": "siddu1221", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17woxqc/switch_to_atlan_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17woxqc/switch_to_atlan_worth_it/", "subreddit_subscribers": 140069, "created_utc": 1700146851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, organizing a free instructor-led workshop about reaching sub-second analytics over TB-scale datasets using Firebolt (which I work for :)). \n\nWe'll cover:\n\n1. Data modeling and ingestion with performance in mind\n2. Reaching fast query performance using indexes and partitions while requiring less compute\n3. Working with semi-structured data efficiently using JSON functions and dealing with arrays\n4. Q&amp;A and knowledge exchange\n\nJoin here: [https://hi.firebolt.io/lp/hands-on-firebolt-workshop](https://hi.firebolt.io/lp/hands-on-firebolt-workshop)", "author_fullname": "t2_jg3w8gbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hands-on workshop for faster query performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wkzcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700135282.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, organizing a free instructor-led workshop about reaching sub-second analytics over TB-scale datasets using Firebolt (which I work for :)). &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll cover:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data modeling and ingestion with performance in mind&lt;/li&gt;\n&lt;li&gt;Reaching fast query performance using indexes and partitions while requiring less compute&lt;/li&gt;\n&lt;li&gt;Working with semi-structured data efficiently using JSON functions and dealing with arrays&lt;/li&gt;\n&lt;li&gt;Q&amp;amp;A and knowledge exchange&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Join here: &lt;a href=\"https://hi.firebolt.io/lp/hands-on-firebolt-workshop\"&gt;https://hi.firebolt.io/lp/hands-on-firebolt-workshop&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?auto=webp&amp;s=a23b766867387c27da7803c1b560fb26497069ff", "width": 1201, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=900d09d18c0c8e887e2bd2354743c171121336b0", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4389f73f49b308fb5522b7bf328dd9ec54bff1f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=264bbb86bb83dfdf4ec23d0c250982da2ffd77d3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2cc73ca604b6705cdbaca8bd0e812d3ddc55f3af", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2855e770901c0620db6b2b3421f8f34a852ae36e", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/wK2crd-bgwiTVOJyn2TfQzruU3yPVpRfNhJfFkHS9gI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dbb165fe39207f969efaca5923eda64ba91f213b", "width": 1080, "height": 563}], "variants": {}, "id": "H6xwU-hA4_-jwlzfwnpWx1y-gbvvBRO7paRxyFbIDps"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17wkzcu", "is_robot_indexable": true, "report_reasons": null, "author": "tamargal91", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wkzcu/handson_workshop_for_faster_query_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wkzcu/handson_workshop_for_faster_query_performance/", "subreddit_subscribers": 140069, "created_utc": 1700135282.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a use case to create hudi table where there is a primary key, but it can have multiple records and all are valid. It's same as - [https://tekionc.medium.com/delta-lake-upserting-without-primary-key-by-adarsh-mudukaplur-nagaraj-engineering-manager-b0673375c402](https://tekionc.medium.com/delta-lake-upserting-without-primary-key-by-adarsh-mudukaplur-nagaraj-engineering-manager-b0673375c402).  \n\n\nThere is also a precombine timestamp field, by which we can identify the latest records. So if in the incoming batch of records, for a key x there are 10 records with different timestamps, then we will pick all records to upsert that have max(timestamp), there could be multiple such records for a key.  \n\n\nAnyone have any solution to this problem? I have not been able to find a way to bypass the uniqueness constraint for key. \nI am using Glue to read data from S3 and then sync to glue catalog.", "author_fullname": "t2_o07qftp9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Hudi table in Glue Catalog without unique key", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wj819", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700128632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case to create hudi table where there is a primary key, but it can have multiple records and all are valid. It&amp;#39;s same as - &lt;a href=\"https://tekionc.medium.com/delta-lake-upserting-without-primary-key-by-adarsh-mudukaplur-nagaraj-engineering-manager-b0673375c402\"&gt;https://tekionc.medium.com/delta-lake-upserting-without-primary-key-by-adarsh-mudukaplur-nagaraj-engineering-manager-b0673375c402&lt;/a&gt;.  &lt;/p&gt;\n\n&lt;p&gt;There is also a precombine timestamp field, by which we can identify the latest records. So if in the incoming batch of records, for a key x there are 10 records with different timestamps, then we will pick all records to upsert that have max(timestamp), there could be multiple such records for a key.  &lt;/p&gt;\n\n&lt;p&gt;Anyone have any solution to this problem? I have not been able to find a way to bypass the uniqueness constraint for key. \nI am using Glue to read data from S3 and then sync to glue catalog.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?auto=webp&amp;s=67f6ff9c238fa9dda3731c00d3e845a19c6c5139", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=836c4ebf6ac35cc4297dca1ffb1ba0a6b3d18d63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=088a08a56280f9fb83c5decad4eefafb39c6909b", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b557b856247defbb9f95cbc853d0deceb1eebe6", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae234b09667b473309f4a3c7dda9209f21e8d823", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ce481be7d14d2f036988c0f106998973cb5a3e3a", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/EjpMUNoMI6ba-inhkjekygvV2AWITywICrbE391VM9s.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4af7b3031168e5fb876eed787250e9a6e1086d17", "width": 1080, "height": 607}], "variants": {}, "id": "6yqwSVBLvTH6O79BGGnUyvBhDIZws2Kc1Mrx3yVM2-k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wj819", "is_robot_indexable": true, "report_reasons": null, "author": "Ambitious-Feature263", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wj819/apache_hudi_table_in_glue_catalog_without_unique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wj819/apache_hudi_table_in_glue_catalog_without_unique/", "subreddit_subscribers": 140069, "created_utc": 1700128632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9x3g2jku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs Databricks: Revisited", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17x0ife", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F7oIaFRptAvFjBwXqGD1OrLyJpawi24Qjvta-Ih6pw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700176499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?auto=webp&amp;s=f4448dc2b5908d839e2c89efd8e2a89a4f4eb50b", "width": 720, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f262c59d38fc92cd5d5cbf1023f607defd336099", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2da0f76c2f854a6985adc6dbe3b0433b9f82a3fa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07a10f185f072395074e13ddeff96f339c4dc40f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7503ff9eba8f7758cbaf82ee9906e4ccef48f41e", "width": 640, "height": 360}], "variants": {}, "id": "wde3DNXjG9PueLXi6hD6k6KBM8idwpDpBKNmmNg4npc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x0ife", "is_robot_indexable": true, "report_reasons": null, "author": "winigo51", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x0ife/snowflake_vs_databricks_revisited/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "subreddit_subscribers": 140069, "created_utc": 1700176499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The modern datalake (or perhaps \"lakehouse,\" as you prefer) is remaking the enterprise data architecture. These modern datalakes have expanded to unprecedented sizes, scaling from petabytes to exabytes, while becoming more performant and multi-engine capable through the adoption of cloud-native principles and open standards. These datalakes don't fit in the public cloud for several reasons, the biggest being economics. This mismatch has led to a surge in the construction and migration of datalakes to private cloud environments and colocation data centers.\n\n[https://blog.min.io/why-the-modern-datalake-is-being-built-privately/?utm\\_source=reddit&amp;utm\\_medium=organic-social+&amp;utm\\_campaign=modern\\_datalake\\_built\\_privately+](https://blog.min.io/why-the-modern-datalake-is-being-built-privately/?utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=modern_datalake_built_privately+)", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why the Modern Datalake is Being Built Privately", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wzxr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700175038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The modern datalake (or perhaps &amp;quot;lakehouse,&amp;quot; as you prefer) is remaking the enterprise data architecture. These modern datalakes have expanded to unprecedented sizes, scaling from petabytes to exabytes, while becoming more performant and multi-engine capable through the adoption of cloud-native principles and open standards. These datalakes don&amp;#39;t fit in the public cloud for several reasons, the biggest being economics. This mismatch has led to a surge in the construction and migration of datalakes to private cloud environments and colocation data centers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://blog.min.io/why-the-modern-datalake-is-being-built-privately/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=modern_datalake_built_privately+\"&gt;https://blog.min.io/why-the-modern-datalake-is-being-built-privately/?utm_source=reddit&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=modern_datalake_built_privately+&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?auto=webp&amp;s=4589ab36a627054cf930cefb3b3df552277db68b", "width": 2000, "height": 822}, "resolutions": [{"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac5915012c506e2267dda2359aa783c1cd289f18", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a0b2fb9986f066f17d0fb44d1b6652f75551e6e", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=49c11c024433151e024f469ed639d892ebd640b8", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a13c847888a33789d74be70e19d83fb9141ce62e", "width": 640, "height": 263}, {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1de55bb5d15582410579688ffdd3f959c6aba5a", "width": 960, "height": 394}, {"url": "https://external-preview.redd.it/VSJLpvNTm1LD0OnRmbdxxs7H5iF9WvchFm_Fm31_PC8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68bee5ea091b2dc73a65a60ecd198c4e50e7a5f1", "width": 1080, "height": 443}], "variants": {}, "id": "aaYNzbXE2jsaKrnFLP3TcrJ_k2krwpe-5H0sMO_0-98"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17wzxr0", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wzxr0/why_the_modern_datalake_is_being_built_privately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wzxr0/why_the_modern_datalake_is_being_built_privately/", "subreddit_subscribers": 140069, "created_utc": 1700175038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nAre you concerned about sending your sensitive data to OpenAI?\n\nThen on-premise AI is the solution: deploy an AI model on your own servers instead of sending your data to the cloud.\n\nHere's an article we just wrote at NLP Cloud, explaining what on-premise AI is about, how to implement it, and what the potential challenges are: [https://nlpcloud.com/on-premise-ai-models-edge-ai-for-sensitive-applications.html](https://nlpcloud.com/on-premise-ai-models-edge-ai-for-sensitive-applications.html?utm_source=reddit&amp;utm_campaign=bbcdw625-3816-81ed-a26450242ac140019)\n\nIf you have questions about an on-premise strategy for your project, please let me know, I'll be happy to advise!\n\nJulien", "author_fullname": "t2_4z4m2qcs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Edge AI / On-Premise AI Models For Sensitive Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wncmv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700142653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Are you concerned about sending your sensitive data to OpenAI?&lt;/p&gt;\n\n&lt;p&gt;Then on-premise AI is the solution: deploy an AI model on your own servers instead of sending your data to the cloud.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an article we just wrote at NLP Cloud, explaining what on-premise AI is about, how to implement it, and what the potential challenges are: &lt;a href=\"https://nlpcloud.com/on-premise-ai-models-edge-ai-for-sensitive-applications.html?utm_source=reddit&amp;amp;utm_campaign=bbcdw625-3816-81ed-a26450242ac140019\"&gt;https://nlpcloud.com/on-premise-ai-models-edge-ai-for-sensitive-applications.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you have questions about an on-premise strategy for your project, please let me know, I&amp;#39;ll be happy to advise!&lt;/p&gt;\n\n&lt;p&gt;Julien&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?auto=webp&amp;s=94dbc709adba202f448112f80e7684c2a9b8d951", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7e7f7ae936b0f2c78ed77797035dd6754d676f3f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d247cf760108bdf102c956885db91c1194f0386d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=42bc9b7771c28245ca98cae88525f0880e7916b4", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d36192afc75e5d61cfddea8ac5b3a6dd0ee9feee", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9ea437a6fe8b792a905aa38cd44659721e971f0", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/oswAZMo60339FwwkD3PK87jRAlNkQxpbGMkEYAVJbcQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02c4d2a70f8302753987bafca20024eb400e4079", "width": 1080, "height": 607}], "variants": {}, "id": "gk9hmYu8E1DwdN3hjKXUKZQXLUM5X-Ut0Oh1pZnW4Nw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17wncmv", "is_robot_indexable": true, "report_reasons": null, "author": "juliensalinas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wncmv/edge_ai_onpremise_ai_models_for_sensitive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wncmv/edge_ai_onpremise_ai_models_for_sensitive/", "subreddit_subscribers": 140069, "created_utc": 1700142653.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}