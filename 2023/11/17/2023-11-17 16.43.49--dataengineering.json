{"kind": "Listing", "data": {"after": "t3_17wr5fp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of our ETL jobs are python scripts that hit APIs and write to a blob storage. Data is small, so I don\u2019t need any tools like spark. What are some easier tools to schedule and run these python jobs?\n\nI tried using AWS lambda functions, but there are significant limitations like 15 minute max timeouts or maximum size is for uploading python environments.\n\nAirflow on a server is ideal, but extremely difficult to set up and manage currently. Companies that manage it for you (like astronomer) are pretty expensive.\n\nAnyone used Dagster?", "author_fullname": "t2_50i9ola", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Python Jobs in cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wragh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700152660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of our ETL jobs are python scripts that hit APIs and write to a blob storage. Data is small, so I don\u2019t need any tools like spark. What are some easier tools to schedule and run these python jobs?&lt;/p&gt;\n\n&lt;p&gt;I tried using AWS lambda functions, but there are significant limitations like 15 minute max timeouts or maximum size is for uploading python environments.&lt;/p&gt;\n\n&lt;p&gt;Airflow on a server is ideal, but extremely difficult to set up and manage currently. Companies that manage it for you (like astronomer) are pretty expensive.&lt;/p&gt;\n\n&lt;p&gt;Anyone used Dagster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wragh", "is_robot_indexable": true, "report_reasons": null, "author": "D-2-The-Ave", "discussion_type": null, "num_comments": 99, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wragh/running_python_jobs_in_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wragh/running_python_jobs_in_cloud/", "subreddit_subscribers": 140149, "created_utc": 1700152660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, my organization is currently evaluating Foundry to help solve some of our warehouse and supply chain issues. We already have an agreement with google and use that for our cloud services, almost all of our data is migrated into the cloud.\n\nMy understanding after reviewing Foundry is that it is itself a data platform, with a UI and advanced analytics on top. \n\nOur organization has several engineering teams but the org leadership feels this would be too big of a project to homegrow ( I disagree as Palantir just looks like spark jobs under the hood) .\n\nWondering what your experience is about the following items\n\n&amp;#x200B;\n\n* Managing the ontology? Importing data definitions (how manual of a process is this? I am thinking a lot of data would be duplicated with our google data cataloging tool, any integrations?)\n* How many resources on your side keep the system up? Are they technical?\n* Model development: what does that look like? Are there out of the box predictive models or are you developing them from ground up?", "author_fullname": "t2_5par13m8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your experiences with Palantir Foundry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wvf53", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700163456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, my organization is currently evaluating Foundry to help solve some of our warehouse and supply chain issues. We already have an agreement with google and use that for our cloud services, almost all of our data is migrated into the cloud.&lt;/p&gt;\n\n&lt;p&gt;My understanding after reviewing Foundry is that it is itself a data platform, with a UI and advanced analytics on top. &lt;/p&gt;\n\n&lt;p&gt;Our organization has several engineering teams but the org leadership feels this would be too big of a project to homegrow ( I disagree as Palantir just looks like spark jobs under the hood) .&lt;/p&gt;\n\n&lt;p&gt;Wondering what your experience is about the following items&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Managing the ontology? Importing data definitions (how manual of a process is this? I am thinking a lot of data would be duplicated with our google data cataloging tool, any integrations?)&lt;/li&gt;\n&lt;li&gt;How many resources on your side keep the system up? Are they technical?&lt;/li&gt;\n&lt;li&gt;Model development: what does that look like? Are there out of the box predictive models or are you developing them from ground up?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wvf53", "is_robot_indexable": true, "report_reasons": null, "author": "rysnotnice", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wvf53/your_experiences_with_palantir_foundry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wvf53/your_experiences_with_palantir_foundry/", "subreddit_subscribers": 140149, "created_utc": 1700163456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Folks,  \nWe have Oracle database as our RDBS and we are facing issues on performance on some complex queries where number of rows are very high. Management wants us to implement big data and do all reporting/visualisation from big data and only transactional data in oracle rdbms. There is no big data expert in our team for now. I am planning to use Hadoop file structure and push the data from Oracle to HDFS using sqoop and then use Impala for querying. On top of we planning to use Qlik Sense ( we already have license for this )which already has impala connector. Do you have any other suggestions or opinion on this. Is there any case study/ documentation of this type of data orchestration", "author_fullname": "t2_cug6y6a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDBS to Big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xbk3s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700214336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks,&lt;br/&gt;\nWe have Oracle database as our RDBS and we are facing issues on performance on some complex queries where number of rows are very high. Management wants us to implement big data and do all reporting/visualisation from big data and only transactional data in oracle rdbms. There is no big data expert in our team for now. I am planning to use Hadoop file structure and push the data from Oracle to HDFS using sqoop and then use Impala for querying. On top of we planning to use Qlik Sense ( we already have license for this )which already has impala connector. Do you have any other suggestions or opinion on this. Is there any case study/ documentation of this type of data orchestration&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xbk3s", "is_robot_indexable": true, "report_reasons": null, "author": "jagdishgg", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xbk3s/rdbs_to_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xbk3s/rdbs_to_big_data/", "subreddit_subscribers": 140149, "created_utc": 1700214336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have two completely separate questions but might as well make it as one.  \n\n\nFirst, I just wanted to know if anyone here uses Neovim? It's very straightforward when looking at a Software Engineer proejct but I am not sure if you find it useful or efficiency improving in DE?  If you do what kind of workflow do you have that makes you like it?\n\nSecond is do you use Jupyter Notebooks in your workflow? Not necessarily in production pipelines but any place you use it. Personally, we have a NoSQL database and at times I have to manually insert data into our Warehouse. So I use boto3 in Jupyter Notebook, query the data, experiment with how to transform it with pandas, and finally insert it. It works for now but something about it feels distasteful honestly. Writing one long blob per notebook and having one per boto3 query makes me feel bad.\n\nWanted to know your thoughts?", "author_fullname": "t2_jt4dxcgmi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Neovim and Jupyter Notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wtnyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700158859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two completely separate questions but might as well make it as one.  &lt;/p&gt;\n\n&lt;p&gt;First, I just wanted to know if anyone here uses Neovim? It&amp;#39;s very straightforward when looking at a Software Engineer proejct but I am not sure if you find it useful or efficiency improving in DE?  If you do what kind of workflow do you have that makes you like it?&lt;/p&gt;\n\n&lt;p&gt;Second is do you use Jupyter Notebooks in your workflow? Not necessarily in production pipelines but any place you use it. Personally, we have a NoSQL database and at times I have to manually insert data into our Warehouse. So I use boto3 in Jupyter Notebook, query the data, experiment with how to transform it with pandas, and finally insert it. It works for now but something about it feels distasteful honestly. Writing one long blob per notebook and having one per boto3 query makes me feel bad.&lt;/p&gt;\n\n&lt;p&gt;Wanted to know your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wtnyb", "is_robot_indexable": true, "report_reasons": null, "author": "codeejen", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wtnyb/thoughts_on_neovim_and_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wtnyb/thoughts_on_neovim_and_jupyter_notebooks/", "subreddit_subscribers": 140149, "created_utc": 1700158859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am pulling down electricity usage from my utility and they give the data in Epoch time in UTC.  But when I convert to local time how do I deal with the issue where in the autumn there are 25 hourly timestamps for the one day - so this year there will be two entries for 2023-11-05-01-00  (at least here in EDT/EST zone) or in the spring when there are only 23 hourly timestamps - there will be a missing hour?\n\nThis isn't anything mission critical so I guess I can just throw away the data, but I was wondering how this is dealt with in data engineering?", "author_fullname": "t2_2c03y5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with hourly data when DST (summer time) starts and (especially) ends?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x730s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700195792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pulling down electricity usage from my utility and they give the data in Epoch time in UTC.  But when I convert to local time how do I deal with the issue where in the autumn there are 25 hourly timestamps for the one day - so this year there will be two entries for 2023-11-05-01-00  (at least here in EDT/EST zone) or in the spring when there are only 23 hourly timestamps - there will be a missing hour?&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t anything mission critical so I guess I can just throw away the data, but I was wondering how this is dealt with in data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17x730s", "is_robot_indexable": true, "report_reasons": null, "author": "shoresy99", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x730s/how_do_you_deal_with_hourly_data_when_dst_summer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x730s/how_do_you_deal_with_hourly_data_when_dst_summer/", "subreddit_subscribers": 140149, "created_utc": 1700195792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?\n\nMy idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a \"data lake\" in gcs and transform with a spark job in data proc, model this data to answer \"bussines problems\" and put into a datawatehouse (bq)\n\nIn my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a \"real Big data problem\"\n\nAny suggestions for my idea? Or any tips for personal projects?\n\nThanks you", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Places to find large amount of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x5jun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700190677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?&lt;/p&gt;\n\n&lt;p&gt;My idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a &amp;quot;data lake&amp;quot; in gcs and transform with a spark job in data proc, model this data to answer &amp;quot;bussines problems&amp;quot; and put into a datawatehouse (bq)&lt;/p&gt;\n\n&lt;p&gt;In my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a &amp;quot;real Big data problem&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for my idea? Or any tips for personal projects?&lt;/p&gt;\n\n&lt;p&gt;Thanks you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17x5jun", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "subreddit_subscribers": 140149, "created_utc": 1700190677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is something I hear about very often in media but I know no one who has held down more than one job in this field personally. I only have two years of experience (been extremely fortunate they have been Data Engineer jobs) so maybe I simply haven\u2019t seen enough yet. \n\nIt just feels impossible to me, nor would I ever want to. I\u2019m exploring doing freelancing down the line purely as a side gig and I recognize that as a big commitment. Even with the whole \u201cyou don\u2019t really work 8 hours a day\u201d there\u2019s so much that can go logistically wrong with two jobs.\n\nThis feels like a lot like salary talk where some tech people are bragging about and exaggerating what they\u2019re actually doing, and whole media narratives have been spun from what likely represents an extremely small minority of employees.", "author_fullname": "t2_sz695ecm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here know people who are actually \u201cover employed\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ws3d4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700154674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something I hear about very often in media but I know no one who has held down more than one job in this field personally. I only have two years of experience (been extremely fortunate they have been Data Engineer jobs) so maybe I simply haven\u2019t seen enough yet. &lt;/p&gt;\n\n&lt;p&gt;It just feels impossible to me, nor would I ever want to. I\u2019m exploring doing freelancing down the line purely as a side gig and I recognize that as a big commitment. Even with the whole \u201cyou don\u2019t really work 8 hours a day\u201d there\u2019s so much that can go logistically wrong with two jobs.&lt;/p&gt;\n\n&lt;p&gt;This feels like a lot like salary talk where some tech people are bragging about and exaggerating what they\u2019re actually doing, and whole media narratives have been spun from what likely represents an extremely small minority of employees.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ws3d4", "is_robot_indexable": true, "report_reasons": null, "author": "clark_sterling", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ws3d4/does_anyone_here_know_people_who_are_actually/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ws3d4/does_anyone_here_know_people_who_are_actually/", "subreddit_subscribers": 140149, "created_utc": 1700154674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, apologies for the very nooby question, but I am brand new to DE and starting work on my first real-life project. \n\nI understand the theory etc behind STAR designs vs OBT but am stuck on how the former is actually put into practice. \n\nIn my example, I receive a CSV file monthly with hotel stays for the previous month. I run a Python script to ingest it and load it to a staging table, and then have a view running off it with some transformations, etc and I'm looking to potentially change this up and use a STAR design. For simplicity I'll just say the file contains the hotel name, country, check-in and checkout date, and the name of the guest; and I'd want to create a hotel dim table.\n\nAm I correct in assuming that the process would look something like the below:\n\n1) Create a \"hotel\" dim table with all the unique records currently in the staging table\n\n2) In future, every month do a \"SELECT DISTINCT\" on it, and compare it with all the rows in the new CSV, insert any that aren't there\n\n3) Somehow do a \"lookup\" against the hotel dim table and insert the recordID of the corresponding hotel\n\n4) Load the rest of the data to the staging table \n\nIt seems like potentially a lot of \"SELECT DISTINCTS\" depending on how many dim tables one has, or is there a more elegant way to do this?\n\nAgain sorry for the silly question. If anyone has any resources/articles even on how this is typically implemented that would also be useful.\n\n&amp;#x200B;", "author_fullname": "t2_az62upwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "STAR design in practise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xd5r7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700233875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700221055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, apologies for the very nooby question, but I am brand new to DE and starting work on my first real-life project. &lt;/p&gt;\n\n&lt;p&gt;I understand the theory etc behind STAR designs vs OBT but am stuck on how the former is actually put into practice. &lt;/p&gt;\n\n&lt;p&gt;In my example, I receive a CSV file monthly with hotel stays for the previous month. I run a Python script to ingest it and load it to a staging table, and then have a view running off it with some transformations, etc and I&amp;#39;m looking to potentially change this up and use a STAR design. For simplicity I&amp;#39;ll just say the file contains the hotel name, country, check-in and checkout date, and the name of the guest; and I&amp;#39;d want to create a hotel dim table.&lt;/p&gt;\n\n&lt;p&gt;Am I correct in assuming that the process would look something like the below:&lt;/p&gt;\n\n&lt;p&gt;1) Create a &amp;quot;hotel&amp;quot; dim table with all the unique records currently in the staging table&lt;/p&gt;\n\n&lt;p&gt;2) In future, every month do a &amp;quot;SELECT DISTINCT&amp;quot; on it, and compare it with all the rows in the new CSV, insert any that aren&amp;#39;t there&lt;/p&gt;\n\n&lt;p&gt;3) Somehow do a &amp;quot;lookup&amp;quot; against the hotel dim table and insert the recordID of the corresponding hotel&lt;/p&gt;\n\n&lt;p&gt;4) Load the rest of the data to the staging table &lt;/p&gt;\n\n&lt;p&gt;It seems like potentially a lot of &amp;quot;SELECT DISTINCTS&amp;quot; depending on how many dim tables one has, or is there a more elegant way to do this?&lt;/p&gt;\n\n&lt;p&gt;Again sorry for the silly question. If anyone has any resources/articles even on how this is typically implemented that would also be useful.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xd5r7", "is_robot_indexable": true, "report_reasons": null, "author": "hektar9987", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xd5r7/star_design_in_practise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xd5r7/star_design_in_practise/", "subreddit_subscribers": 140149, "created_utc": 1700221055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?\n\nFew questions:\n\n1. help on how to bring about this transition, if possible.\n  Find a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? \n2. What technology stack is in great demand since I would be learning it from scratch \n3. Any certificate courses or Post Graduate courses that can help with the transition?", "author_fullname": "t2_1kd6shn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBA to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x40h9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700186185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?&lt;/p&gt;\n\n&lt;p&gt;Few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;help on how to bring about this transition, if possible.\nFind a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? &lt;/li&gt;\n&lt;li&gt;What technology stack is in great demand since I would be learning it from scratch &lt;/li&gt;\n&lt;li&gt;Any certificate courses or Post Graduate courses that can help with the transition?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17x40h9", "is_robot_indexable": true, "report_reasons": null, "author": "matados", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "subreddit_subscribers": 140149, "created_utc": 1700186185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?", "author_fullname": "t2_6fccledv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt incremental models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17xhqj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xhqj2", "is_robot_indexable": true, "report_reasons": null, "author": "deadlypiranha", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "subreddit_subscribers": 140149, "created_utc": 1700235385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, this is my first post here :)\n\nIn the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse\n\nThere is one question, where I don't really find a satisfying answer on the internet though:\n\nHow do I design a good data structure in a data lakehouse?\n\nDo I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.\n\nMaybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  \n", "author_fullname": "t2_36ze7ll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I design a data structure in a data lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wylwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700171706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, this is my first post here :)&lt;/p&gt;\n\n&lt;p&gt;In the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse&lt;/p&gt;\n\n&lt;p&gt;There is one question, where I don&amp;#39;t really find a satisfying answer on the internet though:&lt;/p&gt;\n\n&lt;p&gt;How do I design a good data structure in a data lakehouse?&lt;/p&gt;\n\n&lt;p&gt;Do I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.&lt;/p&gt;\n\n&lt;p&gt;Maybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wylwb", "is_robot_indexable": true, "report_reasons": null, "author": "nilsii27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "subreddit_subscribers": 140149, "created_utc": 1700171706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nI\u2019m looking for a (preferably all-in-one) solution that covers typical capabilities of a catalog (metadata discovery, lineage, dashboards, governance-my-this-and-that, etc.) as well as functionality for more data user/consumer facing exploration/discovery/search like a data library or registry or whatever is the correct term. \nAny suggestions?\nThanks in advance!", "author_fullname": "t2_vek16rwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog and Library in One Solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ws10m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700154505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI\u2019m looking for a (preferably all-in-one) solution that covers typical capabilities of a catalog (metadata discovery, lineage, dashboards, governance-my-this-and-that, etc.) as well as functionality for more data user/consumer facing exploration/discovery/search like a data library or registry or whatever is the correct term. \nAny suggestions?\nThanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ws10m", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Day_6476", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ws10m/data_catalog_and_library_in_one_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ws10m/data_catalog_and_library_in_one_solution/", "subreddit_subscribers": 140149, "created_utc": 1700154505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm doing an analytisc engineering challenge where I'm supposed to create an MRR data model. I don't actually have real data to work with--I'm just supposed to think about what the source data and analytical model might look like, mock up a sample table and SQL queries to address common KPIs.\n\nPart of the instructions is that I should consider performance issues in the model given that they have thousands of users. But how am I supposed to consider performance issues theoretically if I'm not working with data? At work I usually do \"experiments\"--write two SQL queries and compare how they perform.\n\nIt's just that no matter what kind of model I develop now, there's really no way of telling whether it will be performant or not if there's no real data to work with. Or am I missing something?", "author_fullname": "t2_7m2ues2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Your data model should take into consideration possible performance issues\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wqu3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700151540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing an analytisc engineering challenge where I&amp;#39;m supposed to create an MRR data model. I don&amp;#39;t actually have real data to work with--I&amp;#39;m just supposed to think about what the source data and analytical model might look like, mock up a sample table and SQL queries to address common KPIs.&lt;/p&gt;\n\n&lt;p&gt;Part of the instructions is that I should consider performance issues in the model given that they have thousands of users. But how am I supposed to consider performance issues theoretically if I&amp;#39;m not working with data? At work I usually do &amp;quot;experiments&amp;quot;--write two SQL queries and compare how they perform.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s just that no matter what kind of model I develop now, there&amp;#39;s really no way of telling whether it will be performant or not if there&amp;#39;s no real data to work with. Or am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wqu3u", "is_robot_indexable": true, "report_reasons": null, "author": "DataScienceIsScience", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wqu3u/your_data_model_should_take_into_consideration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wqu3u/your_data_model_should_take_into_consideration/", "subreddit_subscribers": 140149, "created_utc": 1700151540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi y\u2019all! \n\nI\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. \n\n1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? \n\n2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) \n\n3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? \n\n\ni\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. \n\nAlso, please if you know any good YT channels that explains this process from the very beginning, share it with me. \n\nThank you in advance,\nBest,", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schemas and data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17xi4ru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700236495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. &lt;/p&gt;\n\n&lt;p&gt;1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? &lt;/p&gt;\n\n&lt;p&gt;2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) &lt;/p&gt;\n\n&lt;p&gt;3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? &lt;/p&gt;\n\n&lt;p&gt;i\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. &lt;/p&gt;\n\n&lt;p&gt;Also, please if you know any good YT channels that explains this process from the very beginning, share it with me. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance,\nBest,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xi4ru", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "subreddit_subscribers": 140149, "created_utc": 1700236495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently did a course and that is making me hate spark, the instructor really didn't taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.\n\nCan anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.\n\nSo if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.", "author_fullname": "t2_3xcrjr5n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please share the course or resource which helped you learned pyspark as a beginner to a professional and how did you practiced spark afterwards outside job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17xhqs4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently did a course and that is making me hate spark, the instructor really didn&amp;#39;t taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.&lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.&lt;/p&gt;\n\n&lt;p&gt;So if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xhqs4", "is_robot_indexable": true, "report_reasons": null, "author": "ImpressionOwn137", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "subreddit_subscribers": 140149, "created_utc": 1700235405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : [https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc](https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc)  \n i could really use your help thank you", "author_fullname": "t2_6lzy3mq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark streaming data from kafka topic to elasticsearch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17xh6lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700233856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : &lt;a href=\"https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc\"&gt;https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc&lt;/a&gt;&lt;br/&gt;\n i could really use your help thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xh6lu", "is_robot_indexable": true, "report_reasons": null, "author": "ekkoogod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "subreddit_subscribers": 140149, "created_utc": 1700233856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit Family, I have a request\u2026\n\nWe\u2019ve just launched Lassoo Headless Analytics to the public.\n\n[Lassoo](https://lassoo.io?ref=reddit_de) Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. \n\nWe\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.\n\nWe\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.\n\nIf you\u2019re interested, please DM me.\n\nP.S. It would be great if you could please share this with any colleagues you think could benefit from this offer", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Headless Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xft3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700229984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit Family, I have a request\u2026&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve just launched Lassoo Headless Analytics to the public.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io?ref=reddit_de\"&gt;Lassoo&lt;/a&gt; Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, please DM me.&lt;/p&gt;\n\n&lt;p&gt;P.S. It would be great if you could please share this with any colleagues you think could benefit from this offer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xft3b", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xft3b/headless_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xft3b/headless_analytics/", "subreddit_subscribers": 140149, "created_utc": 1700229984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Team,  \n\n\nI have been tasked with Migrating databases from SQL Server to Azure PostgreSQL. I know how to Migrate a Database from SQL Server to an Azure SQL Database using the Azure Database Migration Service. However, I am not familiar with how I can do it for other Database services like PostgreSQL or MYSQL.  \n\n\nI have search online but no positive solution. I will appreciate if anyone can guild me or point me to a good resource I can use in achieving this.  \n\n\nThanks", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Database from SQL Server On-premise to Azure PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xeyjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700227369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Team,  &lt;/p&gt;\n\n&lt;p&gt;I have been tasked with Migrating databases from SQL Server to Azure PostgreSQL. I know how to Migrate a Database from SQL Server to an Azure SQL Database using the Azure Database Migration Service. However, I am not familiar with how I can do it for other Database services like PostgreSQL or MYSQL.  &lt;/p&gt;\n\n&lt;p&gt;I have search online but no positive solution. I will appreciate if anyone can guild me or point me to a good resource I can use in achieving this.  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xeyjk", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xeyjk/migrate_database_from_sql_server_onpremise_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xeyjk/migrate_database_from_sql_server_onpremise_to/", "subreddit_subscribers": 140149, "created_utc": 1700227369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,   \nHave you encounter some tutorials, can be udemy or other paid platforms, may be youtube, where one does ADF pipeline end to end with configuration from some SQL server and/or Databricks? Basically, nothing is manipulated in data factory, config comes from different source and is passed to the pipeline, everything is set dynamically. I am struggling with this approach, it works but to some extend and I dont know where I am potentialy stuck. All my search was just basic quick pipelines on couple of csv files or few tables from adventureworks\n\nThank you in advance  \n", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF dynamic setup with configuration video tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xei2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700225900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nHave you encounter some tutorials, can be udemy or other paid platforms, may be youtube, where one does ADF pipeline end to end with configuration from some SQL server and/or Databricks? Basically, nothing is manipulated in data factory, config comes from different source and is passed to the pipeline, everything is set dynamically. I am struggling with this approach, it works but to some extend and I dont know where I am potentialy stuck. All my search was just basic quick pipelines on couple of csv files or few tables from adventureworks&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xei2r", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xei2r/adf_dynamic_setup_with_configuration_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xei2r/adf_dynamic_setup_with_configuration_video/", "subreddit_subscribers": 140149, "created_utc": 1700225900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to design my DAGs like so:\n\n    Parent DAG:\n    start &gt;&gt; notify_start &gt;&gt; notify_complete &gt;&gt; end\n\n&amp;#x200B;\n\n    dag1:\n    sense_start &gt;&gt; run_job_1 &gt;&gt; end\n    \n    dag2:\n    sense_start &gt;&gt; run_job_2 &gt;&gt; end\n    \n    dag3: ... etc.\n\n&amp;#x200B;\n\nEach sense\\_start will be a ExternalTaskSensor sensing the notify\\_start task. \n\nI'd like the parent DAG to **wait** for all the downstream DAGs to complete before notify\\_complete executes, without hardcoding knowledge of the downstream DAGs into it.\n\nIs there a way to do this? I want the flexibility to easily add new DAGs (dag\\_4, dag\\_5 etc.) without having to change code upstream that knows about the new additions.\n\nI thought I could add in ExternalTaskMarker to the Parent DAG, but that needs knowledge of the downstream it seems.", "author_fullname": "t2_6a6ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an Airflow operator that can wait on multiple ExternalTaskSensor that depend on it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xc7ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700217288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to design my DAGs like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Parent DAG:\nstart &amp;gt;&amp;gt; notify_start &amp;gt;&amp;gt; notify_complete &amp;gt;&amp;gt; end\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;dag1:\nsense_start &amp;gt;&amp;gt; run_job_1 &amp;gt;&amp;gt; end\n\ndag2:\nsense_start &amp;gt;&amp;gt; run_job_2 &amp;gt;&amp;gt; end\n\ndag3: ... etc.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Each sense_start will be a ExternalTaskSensor sensing the notify_start task. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like the parent DAG to &lt;strong&gt;wait&lt;/strong&gt; for all the downstream DAGs to complete before notify_complete executes, without hardcoding knowledge of the downstream DAGs into it.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this? I want the flexibility to easily add new DAGs (dag_4, dag_5 etc.) without having to change code upstream that knows about the new additions.&lt;/p&gt;\n\n&lt;p&gt;I thought I could add in ExternalTaskMarker to the Parent DAG, but that needs knowledge of the downstream it seems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xc7ya", "is_robot_indexable": true, "report_reasons": null, "author": "Firepanda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xc7ya/is_there_an_airflow_operator_that_can_wait_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xc7ya/is_there_an_airflow_operator_that_can_wait_on/", "subreddit_subscribers": 140149, "created_utc": 1700217288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_13hqmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curated list of web scraping tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17x9853", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oc-0KG0SwjfRMutDN_Z976x4ca5CoV8bN3m8XQ-nSzY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700203929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pixeljets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pixeljets.com/web-scraping-api/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?auto=webp&amp;s=ef3145f70ea23e3dc86fb6c58a9ddce7f0ee04a2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bcd35647403980e3e32afbf16eb803b4b4576df", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b59efc3a913a5e95affd647f30e592152916fba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb04ba49332e427a2dfb3d5d071d80e72803b14e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbf0d3857ba4366cdd43ba5b3414fa4bacc65dd0", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c453a577b69858a4a44763b7bde1851a638b902", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1847e3438ea3329cfe8268a108e16f4d4176a2b", "width": 1080, "height": 567}], "variants": {}, "id": "CYSzXbp2F9Sd4CWJ3IZAI6mjwvjRIa_YdzHkgER4gfk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x9853", "is_robot_indexable": true, "report_reasons": null, "author": "superjet1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x9853/curated_list_of_web_scraping_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pixeljets.com/web-scraping-api/", "subreddit_subscribers": 140149, "created_utc": 1700203929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, it's been a while.\n\nWe've been hard at work on the Pansynchro framework over the past several months, and recently got around to something we'd been putting off for quite a while: running benchmarks of Pansynchro against some other data synchronization products.  The results were a bit surprising: we knew Pansynchro was fast, but we didn't realize it would even beat SSIS, with its reputation for high performance, by such a wide margin!\n\nResults: [ETL Hello World!](https://pansynchro.tech/etl-hello-world/)", "author_fullname": "t2_otqnx9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Hello World!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x6t1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700194824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, it&amp;#39;s been a while.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been hard at work on the Pansynchro framework over the past several months, and recently got around to something we&amp;#39;d been putting off for quite a while: running benchmarks of Pansynchro against some other data synchronization products.  The results were a bit surprising: we knew Pansynchro was fast, but we didn&amp;#39;t realize it would even beat SSIS, with its reputation for high performance, by such a wide margin!&lt;/p&gt;\n\n&lt;p&gt;Results: &lt;a href=\"https://pansynchro.tech/etl-hello-world/\"&gt;ETL Hello World!&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x6t1p", "is_robot_indexable": true, "report_reasons": null, "author": "Pansynchro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x6t1p/etl_hello_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x6t1p/etl_hello_world/", "subreddit_subscribers": 140149, "created_utc": 1700194824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9x3g2jku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs Databricks: Revisited", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17x0ife", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F7oIaFRptAvFjBwXqGD1OrLyJpawi24Qjvta-Ih6pw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700176499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?auto=webp&amp;s=f4448dc2b5908d839e2c89efd8e2a89a4f4eb50b", "width": 720, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f262c59d38fc92cd5d5cbf1023f607defd336099", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2da0f76c2f854a6985adc6dbe3b0433b9f82a3fa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07a10f185f072395074e13ddeff96f339c4dc40f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7503ff9eba8f7758cbaf82ee9906e4ccef48f41e", "width": 640, "height": 360}], "variants": {}, "id": "wde3DNXjG9PueLXi6hD6k6KBM8idwpDpBKNmmNg4npc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x0ife", "is_robot_indexable": true, "report_reasons": null, "author": "winigo51", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x0ife/snowflake_vs_databricks_revisited/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "subreddit_subscribers": 140149, "created_utc": 1700176499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,   \nat my current job I don't really learn a lot, and it's hard to get help too since everyone is busy doing their own thing.   \n\n\nWhat type of companies are good places to learn? I'm seriously thinking of finding a new job, because this place is stunting my growth.\n\n  \n ", "author_fullname": "t2_133hadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies where I can learn more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wxfpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700168752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nat my current job I don&amp;#39;t really learn a lot, and it&amp;#39;s hard to get help too since everyone is busy doing their own thing.   &lt;/p&gt;\n\n&lt;p&gt;What type of companies are good places to learn? I&amp;#39;m seriously thinking of finding a new job, because this place is stunting my growth.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17wxfpq", "is_robot_indexable": true, "report_reasons": null, "author": "generalNomnom", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "subreddit_subscribers": 140149, "created_utc": 1700168752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if anyone has experience with any privacy platforms such as transcend, datagrail, or oneTrust. We\u2019re looking to bring on a tool to help us automate a lot of privacy processes (like deletions and access requests). \n\nAnyone have a platform they really like or don\u2019t like? Also insights on how much a platform like these might cost a smaller company (less than 100 people, and only a 2 person data team). \n\nWe\u2019re wanting to bring on a tool because we may soon be subject to GDPR rules and need help navigating that and getting compliant quickly (and of course staying compliant).", "author_fullname": "t2_82zhjuv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Privacy Platforms?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wr5fp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700152320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if anyone has experience with any privacy platforms such as transcend, datagrail, or oneTrust. We\u2019re looking to bring on a tool to help us automate a lot of privacy processes (like deletions and access requests). &lt;/p&gt;\n\n&lt;p&gt;Anyone have a platform they really like or don\u2019t like? Also insights on how much a platform like these might cost a smaller company (less than 100 people, and only a 2 person data team). &lt;/p&gt;\n\n&lt;p&gt;We\u2019re wanting to bring on a tool because we may soon be subject to GDPR rules and need help navigating that and getting compliant quickly (and of course staying compliant).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17wr5fp", "is_robot_indexable": true, "report_reasons": null, "author": "Comprehensive-Ant251", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wr5fp/privacy_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wr5fp/privacy_platforms/", "subreddit_subscribers": 140149, "created_utc": 1700152320.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}