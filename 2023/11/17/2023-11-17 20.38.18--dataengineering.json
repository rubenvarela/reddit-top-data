{"kind": "Listing", "data": {"after": "t3_17xgl82", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Folks,  \nWe have Oracle database as our RDBS and we are facing issues on performance on some complex queries where number of rows are very high. Management wants us to implement big data and do all reporting/visualisation from big data and only transactional data in oracle rdbms. There is no big data expert in our team for now. I am planning to use Hadoop file structure and push the data from Oracle to HDFS using sqoop and then use Impala for querying. On top of we planning to use Qlik Sense ( we already have license for this )which already has impala connector. Do you have any other suggestions or opinion on this. Is there any case study/ documentation of this type of data orchestration", "author_fullname": "t2_cug6y6a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDBS to Big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xbk3s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700214336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks,&lt;br/&gt;\nWe have Oracle database as our RDBS and we are facing issues on performance on some complex queries where number of rows are very high. Management wants us to implement big data and do all reporting/visualisation from big data and only transactional data in oracle rdbms. There is no big data expert in our team for now. I am planning to use Hadoop file structure and push the data from Oracle to HDFS using sqoop and then use Impala for querying. On top of we planning to use Qlik Sense ( we already have license for this )which already has impala connector. Do you have any other suggestions or opinion on this. Is there any case study/ documentation of this type of data orchestration&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xbk3s", "is_robot_indexable": true, "report_reasons": null, "author": "jagdishgg", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xbk3s/rdbs_to_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xbk3s/rdbs_to_big_data/", "subreddit_subscribers": 140176, "created_utc": 1700214336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, apologies for the very nooby question, but I am brand new to DE and starting work on my first real-life project. \n\nI understand the theory etc behind STAR designs vs OBT but am stuck on how the former is actually put into practice. \n\nIn my example, I receive a CSV file monthly with hotel stays for the previous month. I run a Python script to ingest it and load it to a staging table, and then have a view running off it with some transformations, etc and I'm looking to potentially change this up and use a STAR design. For simplicity I'll just say the file contains the hotel name, country, check-in and checkout date, and the name of the guest; and I'd want to create a hotel dim table.\n\nAm I correct in assuming that the process would look something like the below:\n\n1) Create a \"hotel\" dim table with all the unique records currently in the staging table\n\n2) In future, every month do a \"SELECT DISTINCT\" on it, and compare it with all the rows in the new CSV, insert any that aren't there\n\n3) Somehow do a \"lookup\" against the hotel dim table and insert the recordID of the corresponding hotel\n\n4) Load the rest of the data to the staging table \n\nIt seems like potentially a lot of \"SELECT DISTINCTS\" depending on how many dim tables one has, or is there a more elegant way to do this?\n\nAgain sorry for the silly question. If anyone has any resources/articles even on how this is typically implemented that would also be useful.\n\n&amp;#x200B;", "author_fullname": "t2_az62upwd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "STAR design in practise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xd5r7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700233875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700221055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, apologies for the very nooby question, but I am brand new to DE and starting work on my first real-life project. &lt;/p&gt;\n\n&lt;p&gt;I understand the theory etc behind STAR designs vs OBT but am stuck on how the former is actually put into practice. &lt;/p&gt;\n\n&lt;p&gt;In my example, I receive a CSV file monthly with hotel stays for the previous month. I run a Python script to ingest it and load it to a staging table, and then have a view running off it with some transformations, etc and I&amp;#39;m looking to potentially change this up and use a STAR design. For simplicity I&amp;#39;ll just say the file contains the hotel name, country, check-in and checkout date, and the name of the guest; and I&amp;#39;d want to create a hotel dim table.&lt;/p&gt;\n\n&lt;p&gt;Am I correct in assuming that the process would look something like the below:&lt;/p&gt;\n\n&lt;p&gt;1) Create a &amp;quot;hotel&amp;quot; dim table with all the unique records currently in the staging table&lt;/p&gt;\n\n&lt;p&gt;2) In future, every month do a &amp;quot;SELECT DISTINCT&amp;quot; on it, and compare it with all the rows in the new CSV, insert any that aren&amp;#39;t there&lt;/p&gt;\n\n&lt;p&gt;3) Somehow do a &amp;quot;lookup&amp;quot; against the hotel dim table and insert the recordID of the corresponding hotel&lt;/p&gt;\n\n&lt;p&gt;4) Load the rest of the data to the staging table &lt;/p&gt;\n\n&lt;p&gt;It seems like potentially a lot of &amp;quot;SELECT DISTINCTS&amp;quot; depending on how many dim tables one has, or is there a more elegant way to do this?&lt;/p&gt;\n\n&lt;p&gt;Again sorry for the silly question. If anyone has any resources/articles even on how this is typically implemented that would also be useful.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xd5r7", "is_robot_indexable": true, "report_reasons": null, "author": "hektar9987", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xd5r7/star_design_in_practise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xd5r7/star_design_in_practise/", "subreddit_subscribers": 140176, "created_utc": 1700221055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?\n\nMy idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a \"data lake\" in gcs and transform with a spark job in data proc, model this data to answer \"bussines problems\" and put into a datawatehouse (bq)\n\nIn my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a \"real Big data problem\"\n\nAny suggestions for my idea? Or any tips for personal projects?\n\nThanks you", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Places to find large amount of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x5jun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700190677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, anyone know some resources where i can find large amount of data (1-10 tb) for personal projects?&lt;/p&gt;\n\n&lt;p&gt;My idea is to make a pipeline that can ingest transform and load the data in a cloud environment (GCP free trial) i think that if i find the data source then i can implement a &amp;quot;data lake&amp;quot; in gcs and transform with a spark job in data proc, model this data to answer &amp;quot;bussines problems&amp;quot; and put into a datawatehouse (bq)&lt;/p&gt;\n\n&lt;p&gt;In my actual job i already make some elt Jobs with dbt and orchestator tools but is like 20 GB/ day and i want to do a &amp;quot;real Big data problem&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for my idea? Or any tips for personal projects?&lt;/p&gt;\n\n&lt;p&gt;Thanks you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17x5jun", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x5jun/places_to_find_large_amount_of_data/", "subreddit_subscribers": 140176, "created_utc": 1700190677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am pulling down electricity usage from my utility and they give the data in Epoch time in UTC.  But when I convert to local time how do I deal with the issue where in the autumn there are 25 hourly timestamps for the one day - so this year there will be two entries for 2023-11-05-01-00  (at least here in EDT/EST zone) or in the spring when there are only 23 hourly timestamps - there will be a missing hour?\n\nThis isn't anything mission critical so I guess I can just throw away the data, but I was wondering how this is dealt with in data engineering?", "author_fullname": "t2_2c03y5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you deal with hourly data when DST (summer time) starts and (especially) ends?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x730s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700195792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am pulling down electricity usage from my utility and they give the data in Epoch time in UTC.  But when I convert to local time how do I deal with the issue where in the autumn there are 25 hourly timestamps for the one day - so this year there will be two entries for 2023-11-05-01-00  (at least here in EDT/EST zone) or in the spring when there are only 23 hourly timestamps - there will be a missing hour?&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t anything mission critical so I guess I can just throw away the data, but I was wondering how this is dealt with in data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17x730s", "is_robot_indexable": true, "report_reasons": null, "author": "shoresy99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x730s/how_do_you_deal_with_hourly_data_when_dst_summer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x730s/how_do_you_deal_with_hourly_data_when_dst_summer/", "subreddit_subscribers": 140176, "created_utc": 1700195792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?\n\nFew questions:\n\n1. help on how to bring about this transition, if possible.\n  Find a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? \n2. What technology stack is in great demand since I would be learning it from scratch \n3. Any certificate courses or Post Graduate courses that can help with the transition?", "author_fullname": "t2_1kd6shn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBA to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x40h9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700186185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have approx. 15 yrs of experience working as a database engineer primarily on the MS Sql Server platform on a managerial capacity  , lately I was thinking about making a switch into data engineering /management role , I am looking for some help and guidance from the community , if you are able to answer few of the below questions that would be helpful in providing a direction . Especially people Who have made a same or similar switch ?&lt;/p&gt;\n\n&lt;p&gt;Few questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;help on how to bring about this transition, if possible.\nFind a gig as a data engineer and get into managerial capacity or would a lateral move from manager of database engineering make more sense ? &lt;/li&gt;\n&lt;li&gt;What technology stack is in great demand since I would be learning it from scratch &lt;/li&gt;\n&lt;li&gt;Any certificate courses or Post Graduate courses that can help with the transition?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17x40h9", "is_robot_indexable": true, "report_reasons": null, "author": "matados", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x40h9/dba_to_data_engineering/", "subreddit_subscribers": 140176, "created_utc": 1700186185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently did a course and that is making me hate spark, the instructor really didn't taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.\n\nCan anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.\n\nSo if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.", "author_fullname": "t2_3xcrjr5n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please share the course or resource which helped you learned pyspark as a beginner to a professional and how did you practiced spark afterwards outside job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xhqs4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently did a course and that is making me hate spark, the instructor really didn&amp;#39;t taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.&lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.&lt;/p&gt;\n\n&lt;p&gt;So if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xhqs4", "is_robot_indexable": true, "report_reasons": null, "author": "ImpressionOwn137", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "subreddit_subscribers": 140176, "created_utc": 1700235405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?", "author_fullname": "t2_i7s0h23q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake pay-as-you-go pricing for the business critical edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xlkql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xlkql", "is_robot_indexable": true, "report_reasons": null, "author": "LA_throwaway_one", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "subreddit_subscribers": 140176, "created_utc": 1700245736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I'm part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn't a part of my daily tasks, I do possess some familiarity with writing SQL queries.\n\nOur team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn't just in running numbers and building models and tools - I came in with a strategic education and strategic experience.\n\nI strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.\n\nMy questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don't want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.\n\nI looked into Coursera for BigQuery courses, there are 100s of courses. I don't know what I should pick.\n\nPlease drop your thoughts/suggestions.", "author_fullname": "t2_p2qjz042", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning to 'Analytics Engineering' by blending my existing Analytics and acquiring Data Engineering skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xl0r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700244249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I&amp;#39;m part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn&amp;#39;t a part of my daily tasks, I do possess some familiarity with writing SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn&amp;#39;t just in running numbers and building models and tools - I came in with a strategic education and strategic experience.&lt;/p&gt;\n\n&lt;p&gt;I strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.&lt;/p&gt;\n\n&lt;p&gt;My questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don&amp;#39;t want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.&lt;/p&gt;\n\n&lt;p&gt;I looked into Coursera for BigQuery courses, there are 100s of courses. I don&amp;#39;t know what I should pick.&lt;/p&gt;\n\n&lt;p&gt;Please drop your thoughts/suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xl0r8", "is_robot_indexable": true, "report_reasons": null, "author": "NumbTheFather", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "subreddit_subscribers": 140176, "created_utc": 1700244249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : [https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc](https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc)  \n i could really use your help thank you", "author_fullname": "t2_6lzy3mq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark streaming data from kafka topic to elasticsearch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xh6lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700233856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : &lt;a href=\"https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc\"&gt;https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc&lt;/a&gt;&lt;br/&gt;\n i could really use your help thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xh6lu", "is_robot_indexable": true, "report_reasons": null, "author": "ekkoogod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "subreddit_subscribers": 140176, "created_utc": 1700233856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit Family, I have a request\u2026\n\nWe\u2019ve just launched Lassoo Headless Analytics to the public.\n\n[Lassoo](https://lassoo.io?ref=reddit_de) Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. \n\nWe\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.\n\nWe\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.\n\nIf you\u2019re interested, please DM me.\n\nP.S. It would be great if you could please share this with any colleagues you think could benefit from this offer", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Headless Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xft3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700229984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit Family, I have a request\u2026&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve just launched Lassoo Headless Analytics to the public.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io?ref=reddit_de\"&gt;Lassoo&lt;/a&gt; Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, please DM me.&lt;/p&gt;\n\n&lt;p&gt;P.S. It would be great if you could please share this with any colleagues you think could benefit from this offer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xft3b", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xft3b/headless_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xft3b/headless_analytics/", "subreddit_subscribers": 140176, "created_utc": 1700229984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to design my DAGs like so:\n\n    Parent DAG:\n    start &gt;&gt; notify_start &gt;&gt; notify_complete &gt;&gt; end\n\n&amp;#x200B;\n\n    dag1:\n    sense_start &gt;&gt; run_job_1 &gt;&gt; end\n    \n    dag2:\n    sense_start &gt;&gt; run_job_2 &gt;&gt; end\n    \n    dag3: ... etc.\n\n&amp;#x200B;\n\nEach sense\\_start will be a ExternalTaskSensor sensing the notify\\_start task. \n\nI'd like the parent DAG to **wait** for all the downstream DAGs to complete before notify\\_complete executes, without hardcoding knowledge of the downstream DAGs into it.\n\nIs there a way to do this? I want the flexibility to easily add new DAGs (dag\\_4, dag\\_5 etc.) without having to change code upstream that knows about the new additions.\n\nI thought I could add in ExternalTaskMarker to the Parent DAG, but that needs knowledge of the downstream it seems.", "author_fullname": "t2_6a6ra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an Airflow operator that can wait on multiple ExternalTaskSensor that depend on it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xc7ya", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700217288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to design my DAGs like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Parent DAG:\nstart &amp;gt;&amp;gt; notify_start &amp;gt;&amp;gt; notify_complete &amp;gt;&amp;gt; end\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;dag1:\nsense_start &amp;gt;&amp;gt; run_job_1 &amp;gt;&amp;gt; end\n\ndag2:\nsense_start &amp;gt;&amp;gt; run_job_2 &amp;gt;&amp;gt; end\n\ndag3: ... etc.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Each sense_start will be a ExternalTaskSensor sensing the notify_start task. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like the parent DAG to &lt;strong&gt;wait&lt;/strong&gt; for all the downstream DAGs to complete before notify_complete executes, without hardcoding knowledge of the downstream DAGs into it.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to do this? I want the flexibility to easily add new DAGs (dag_4, dag_5 etc.) without having to change code upstream that knows about the new additions.&lt;/p&gt;\n\n&lt;p&gt;I thought I could add in ExternalTaskMarker to the Parent DAG, but that needs knowledge of the downstream it seems.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xc7ya", "is_robot_indexable": true, "report_reasons": null, "author": "Firepanda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xc7ya/is_there_an_airflow_operator_that_can_wait_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xc7ya/is_there_an_airflow_operator_that_can_wait_on/", "subreddit_subscribers": 140176, "created_utc": 1700217288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9x3g2jku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake vs Databricks: Revisited", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17x0ife", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7F7oIaFRptAvFjBwXqGD1OrLyJpawi24Qjvta-Ih6pw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700176499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?auto=webp&amp;s=f4448dc2b5908d839e2c89efd8e2a89a4f4eb50b", "width": 720, "height": 405}, "resolutions": [{"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f262c59d38fc92cd5d5cbf1023f607defd336099", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2da0f76c2f854a6985adc6dbe3b0433b9f82a3fa", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07a10f185f072395074e13ddeff96f339c4dc40f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/YQT_B65aFN6oRIHQzkfFEDepTmf0RLToEtL7zRbQPBA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7503ff9eba8f7758cbaf82ee9906e4ccef48f41e", "width": 640, "height": 360}], "variants": {}, "id": "wde3DNXjG9PueLXi6hD6k6KBM8idwpDpBKNmmNg4npc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x0ife", "is_robot_indexable": true, "report_reasons": null, "author": "winigo51", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x0ife/snowflake_vs_databricks_revisited/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@noah.goodrich/snowflake-vs-databricks-revisited-edd8201b5799", "subreddit_subscribers": 140176, "created_utc": 1700176499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, this is my first post here :)\n\nIn the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse\n\nThere is one question, where I don't really find a satisfying answer on the internet though:\n\nHow do I design a good data structure in a data lakehouse?\n\nDo I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.\n\nMaybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  \n", "author_fullname": "t2_36ze7ll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I design a data structure in a data lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wylwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700171706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, this is my first post here :)&lt;/p&gt;\n\n&lt;p&gt;In the last few weeks I am looking into Apache Iceberg to improve the usability of data lakes and turn them into a data lakehouse&lt;/p&gt;\n\n&lt;p&gt;There is one question, where I don&amp;#39;t really find a satisfying answer on the internet though:&lt;/p&gt;\n\n&lt;p&gt;How do I design a good data structure in a data lakehouse?&lt;/p&gt;\n\n&lt;p&gt;Do I use something like OBT, or a classic approch like fact and dimension tables, or even a data vault approach with hub, sattelites and links. What would be pros and cons for that? OBT for example would be to inflexible in general but with schema evolution it might not be a pain point anymore.&lt;/p&gt;\n\n&lt;p&gt;Maybe someone can clear this up for me or tell me from experience using Iceberg, Delta or Hudi  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17wylwb", "is_robot_indexable": true, "report_reasons": null, "author": "nilsii27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wylwb/how_do_i_design_a_data_structure_in_a_data/", "subreddit_subscribers": 140176, "created_utc": 1700171706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nWe have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor's (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor's AWS SQL instance over the VPN using a linked service. \n\nWe are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.\n\nOne suggestion we've received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. \n\nThis is less than ideal because adding another VM adds cost. \n\nCan we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?", "author_fullname": "t2_66hzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble connecting Modmed with Azure. Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xldc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor&amp;#39;s (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor&amp;#39;s AWS SQL instance over the VPN using a linked service. &lt;/p&gt;\n\n&lt;p&gt;We are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.&lt;/p&gt;\n\n&lt;p&gt;One suggestion we&amp;#39;ve received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. &lt;/p&gt;\n\n&lt;p&gt;This is less than ideal because adding another VM adds cost. &lt;/p&gt;\n\n&lt;p&gt;Can we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xldc1", "is_robot_indexable": true, "report_reasons": null, "author": "traft00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "subreddit_subscribers": 140176, "created_utc": 1700245193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll try to keep this short.  I work at a Fortune 100 company with a \"senior engineer consultant\" title, although that doesn't really describe what I do.  I'm a business employee (not IT) and my day-to-day is:\n\n* Run validations to ensure IT data replication worked (Python &amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.\n* Pull tables from disparate data sources and compare to find differences (MS Power Query)\n* Tell IT what changes they need to make to the tables \n* Write adhoc SQL reports\n\nI spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.\n\n* 10 years strong SQL (CTE, multi joins, window/analytic functions)\n* 5 years moderate Python, Java, AppsScript\n* 5 years Tableau, Cognos\n* 5 years Talend (ETL)\n\nAm I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?", "author_fullname": "t2_1e1kvt8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I qualified to jump to a mid/senior data engineer position from a business data analyst role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xj3we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700239638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700239146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try to keep this short.  I work at a Fortune 100 company with a &amp;quot;senior engineer consultant&amp;quot; title, although that doesn&amp;#39;t really describe what I do.  I&amp;#39;m a business employee (not IT) and my day-to-day is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run validations to ensure IT data replication worked (Python &amp;amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.&lt;/li&gt;\n&lt;li&gt;Pull tables from disparate data sources and compare to find differences (MS Power Query)&lt;/li&gt;\n&lt;li&gt;Tell IT what changes they need to make to the tables &lt;/li&gt;\n&lt;li&gt;Write adhoc SQL reports&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;10 years strong SQL (CTE, multi joins, window/analytic functions)&lt;/li&gt;\n&lt;li&gt;5 years moderate Python, Java, AppsScript&lt;/li&gt;\n&lt;li&gt;5 years Tableau, Cognos&lt;/li&gt;\n&lt;li&gt;5 years Talend (ETL)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Am I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xj3we", "is_robot_indexable": true, "report_reasons": null, "author": "IT-Banker", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "subreddit_subscribers": 140176, "created_utc": 1700239146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi y\u2019all! \n\nI\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. \n\n1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? \n\n2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) \n\n3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? \n\n\ni\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. \n\nAlso, please if you know any good YT channels that explains this process from the very beginning, share it with me. \n\nThank you in advance,\nBest,", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schemas and data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xi4ru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700236495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. &lt;/p&gt;\n\n&lt;p&gt;1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? &lt;/p&gt;\n\n&lt;p&gt;2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) &lt;/p&gt;\n\n&lt;p&gt;3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? &lt;/p&gt;\n\n&lt;p&gt;i\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. &lt;/p&gt;\n\n&lt;p&gt;Also, please if you know any good YT channels that explains this process from the very beginning, share it with me. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance,\nBest,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xi4ru", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "subreddit_subscribers": 140176, "created_utc": 1700236495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?", "author_fullname": "t2_6fccledv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt incremental models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xhqj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xhqj2", "is_robot_indexable": true, "report_reasons": null, "author": "deadlypiranha", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "subreddit_subscribers": 140176, "created_utc": 1700235385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Team,  \n\n\nI have been tasked with Migrating databases from SQL Server to Azure PostgreSQL. I know how to Migrate a Database from SQL Server to an Azure SQL Database using the Azure Database Migration Service. However, I am not familiar with how I can do it for other Database services like PostgreSQL or MYSQL.  \n\n\nI have search online but no positive solution. I will appreciate if anyone can guild me or point me to a good resource I can use in achieving this.  \n\n\nThanks", "author_fullname": "t2_6fwa4j9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Database from SQL Server On-premise to Azure PostgreSQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xeyjk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700227369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Team,  &lt;/p&gt;\n\n&lt;p&gt;I have been tasked with Migrating databases from SQL Server to Azure PostgreSQL. I know how to Migrate a Database from SQL Server to an Azure SQL Database using the Azure Database Migration Service. However, I am not familiar with how I can do it for other Database services like PostgreSQL or MYSQL.  &lt;/p&gt;\n\n&lt;p&gt;I have search online but no positive solution. I will appreciate if anyone can guild me or point me to a good resource I can use in achieving this.  &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xeyjk", "is_robot_indexable": true, "report_reasons": null, "author": "kiddojazz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xeyjk/migrate_database_from_sql_server_onpremise_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xeyjk/migrate_database_from_sql_server_onpremise_to/", "subreddit_subscribers": 140176, "created_utc": 1700227369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,   \nHave you encounter some tutorials, can be udemy or other paid platforms, may be youtube, where one does ADF pipeline end to end with configuration from some SQL server and/or Databricks? Basically, nothing is manipulated in data factory, config comes from different source and is passed to the pipeline, everything is set dynamically. I am struggling with this approach, it works but to some extend and I dont know where I am potentialy stuck. All my search was just basic quick pipelines on couple of csv files or few tables from adventureworks\n\nThank you in advance  \n", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF dynamic setup with configuration video tutorials", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xei2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700225900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nHave you encounter some tutorials, can be udemy or other paid platforms, may be youtube, where one does ADF pipeline end to end with configuration from some SQL server and/or Databricks? Basically, nothing is manipulated in data factory, config comes from different source and is passed to the pipeline, everything is set dynamically. I am struggling with this approach, it works but to some extend and I dont know where I am potentialy stuck. All my search was just basic quick pipelines on couple of csv files or few tables from adventureworks&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xei2r", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xei2r/adf_dynamic_setup_with_configuration_video/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xei2r/adf_dynamic_setup_with_configuration_video/", "subreddit_subscribers": 140176, "created_utc": 1700225900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_13hqmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Curated list of web scraping tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17x9853", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oc-0KG0SwjfRMutDN_Z976x4ca5CoV8bN3m8XQ-nSzY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700203929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pixeljets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pixeljets.com/web-scraping-api/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?auto=webp&amp;s=ef3145f70ea23e3dc86fb6c58a9ddce7f0ee04a2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bcd35647403980e3e32afbf16eb803b4b4576df", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b59efc3a913a5e95affd647f30e592152916fba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb04ba49332e427a2dfb3d5d071d80e72803b14e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fbf0d3857ba4366cdd43ba5b3414fa4bacc65dd0", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c453a577b69858a4a44763b7bde1851a638b902", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PVwPJ6an-HNrSpewRmeyrMv8X1Gyyf_91ikRkmVpHjc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1847e3438ea3329cfe8268a108e16f4d4176a2b", "width": 1080, "height": 567}], "variants": {}, "id": "CYSzXbp2F9Sd4CWJ3IZAI6mjwvjRIa_YdzHkgER4gfk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x9853", "is_robot_indexable": true, "report_reasons": null, "author": "superjet1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x9853/curated_list_of_web_scraping_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pixeljets.com/web-scraping-api/", "subreddit_subscribers": 140176, "created_utc": 1700203929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, it's been a while.\n\nWe've been hard at work on the Pansynchro framework over the past several months, and recently got around to something we'd been putting off for quite a while: running benchmarks of Pansynchro against some other data synchronization products.  The results were a bit surprising: we knew Pansynchro was fast, but we didn't realize it would even beat SSIS, with its reputation for high performance, by such a wide margin!\n\nResults: [ETL Hello World!](https://pansynchro.tech/etl-hello-world/)", "author_fullname": "t2_otqnx9sa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Hello World!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17x6t1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700194824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, it&amp;#39;s been a while.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been hard at work on the Pansynchro framework over the past several months, and recently got around to something we&amp;#39;d been putting off for quite a while: running benchmarks of Pansynchro against some other data synchronization products.  The results were a bit surprising: we knew Pansynchro was fast, but we didn&amp;#39;t realize it would even beat SSIS, with its reputation for high performance, by such a wide margin!&lt;/p&gt;\n\n&lt;p&gt;Results: &lt;a href=\"https://pansynchro.tech/etl-hello-world/\"&gt;ETL Hello World!&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17x6t1p", "is_robot_indexable": true, "report_reasons": null, "author": "Pansynchro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17x6t1p/etl_hello_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17x6t1p/etl_hello_world/", "subreddit_subscribers": 140176, "created_utc": 1700194824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,   \nat my current job I don't really learn a lot, and it's hard to get help too since everyone is busy doing their own thing.   \n\n\nWhat type of companies are good places to learn? I'm seriously thinking of finding a new job, because this place is stunting my growth.\n\n  \n ", "author_fullname": "t2_133hadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies where I can learn more", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17wxfpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700168752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nat my current job I don&amp;#39;t really learn a lot, and it&amp;#39;s hard to get help too since everyone is busy doing their own thing.   &lt;/p&gt;\n\n&lt;p&gt;What type of companies are good places to learn? I&amp;#39;m seriously thinking of finding a new job, because this place is stunting my growth.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17wxfpq", "is_robot_indexable": true, "report_reasons": null, "author": "generalNomnom", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17wxfpq/companies_where_i_can_learn_more/", "subreddit_subscribers": 140176, "created_utc": 1700168752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Full disclosure: A contributor to the project here.\n\nI have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.\n\nI'm excited to share that the project is now live and I wanted to thank the project's early contributors. You can learn more by visiting the repo: [https://github.com/onetable-io/onetable](https://github.com/onetable-io/onetable)\n\nI'll keep an eye out on this subreddit and the post to answer any questions you may have.", "author_fullname": "t2_o3fw52ash", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OneTable is now live | Table format interoperability is not a dream anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xjs0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700240920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Full disclosure: A contributor to the project here.&lt;/p&gt;\n\n&lt;p&gt;I have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share that the project is now live and I wanted to thank the project&amp;#39;s early contributors. You can learn more by visiting the repo: &lt;a href=\"https://github.com/onetable-io/onetable\"&gt;https://github.com/onetable-io/onetable&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll keep an eye out on this subreddit and the post to answer any questions you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?auto=webp&amp;s=ca8ca18a4768b89f950527c931e5eaa3395cb2cc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3beadbc1b340de0a682d509c2a7cd53cfeff27f7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=adc48402b2652b6a0c110b20f67388030e9ae6b3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ae1ff18f1579e9d9eb9633cfae7e8ff78557eca", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=78f6366155828de3caab54c68df36f92693b047b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=955fac3869882d57292ae00f401b8e3379d5ae4a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cddba46e668b1955c4ec65830b7cf6ea09642eb7", "width": 1080, "height": 540}], "variants": {}, "id": "ZF0kwxmuX9UVT7upWOjDojrXLQQTrxSIm-50k-mSUxg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17xjs0q", "is_robot_indexable": true, "report_reasons": null, "author": "DataRepeatRinse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "subreddit_subscribers": 140176, "created_utc": 1700240920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know there are lots of Python course available on the internet it teaches only the theoretical part of the python . However I have 15 days time out of work/family. Hence I would want something paid or free to start exercises along with theory part. Once I complete the exercise I should proceed further to next level . By end of this course , I would want to rate myself to create my own programs in data engineering. Is there any paid / free course available to start.\n\nCurrently bought Darshil Parmer course ( looks very basic )", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to Master Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xhbfb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700234230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are lots of Python course available on the internet it teaches only the theoretical part of the python . However I have 15 days time out of work/family. Hence I would want something paid or free to start exercises along with theory part. Once I complete the exercise I should proceed further to next level . By end of this course , I would want to rate myself to create my own programs in data engineering. Is there any paid / free course available to start.&lt;/p&gt;\n\n&lt;p&gt;Currently bought Darshil Parmer course ( looks very basic )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xhbfb", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhbfb/need_to_master_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhbfb/need_to_master_python/", "subreddit_subscribers": 140176, "created_utc": 1700234230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/eylrvc487x0c1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=0bf7866a4fbaddd2503190ec60e0726d0c48b3cc\n\nDevart joins the Black Friday celebrations with its dbForge for SQL Server product family \u2014 a suite of products designed for database development, management, and administration.\n\nThe most significant sales of the year are here! Get 15% to 50% off each Devart product you've had your eye on between November 20 and November 26.\n\nPick the tools and get your discounts right now: [https://www.devart.com/blackfriday.html#sql](https://www.devart.com/blackfriday.html#sql) ", "author_fullname": "t2_l03fko6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Save up to 50% on Devart database tools!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eylrvc487x0c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c04dbd385323d395b0eb8d40acdd4920e8523450"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8843462c4fc5e537bb1430fc2f78c137d82b97ad"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc593eb5c935ba7050b3679d5370c52916c0d4aa"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a848b1f77e9fe01ebb61a51ac1868868139839fd"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e8f35c3fcf0bfca8c9e787a81d950e20317d07e"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=190449f58197f3c7c7e4fbb7286aadedeeaae483"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/eylrvc487x0c1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=0bf7866a4fbaddd2503190ec60e0726d0c48b3cc"}, "id": "eylrvc487x0c1"}}, "name": "t3_17xgl82", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/LT4Su8YNDWIeVkf-dIE736i92A08vDpRO5-hTn_5cC0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1700232200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eylrvc487x0c1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0bf7866a4fbaddd2503190ec60e0726d0c48b3cc\"&gt;https://preview.redd.it/eylrvc487x0c1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0bf7866a4fbaddd2503190ec60e0726d0c48b3cc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Devart joins the Black Friday celebrations with its dbForge for SQL Server product family \u2014 a suite of products designed for database development, management, and administration.&lt;/p&gt;\n\n&lt;p&gt;The most significant sales of the year are here! Get 15% to 50% off each Devart product you&amp;#39;ve had your eye on between November 20 and November 26.&lt;/p&gt;\n\n&lt;p&gt;Pick the tools and get your discounts right now: &lt;a href=\"https://www.devart.com/blackfriday.html#sql\"&gt;https://www.devart.com/blackfriday.html#sql&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K2N8TUPiTmz9zd5ZVDni-jZkijo9Z4H7ZIZXchqEP-k.jpg?auto=webp&amp;s=eb237f9930b3809ef4e0f9b3dc4b565a91b4aac2", "width": 146, "height": 57}, "resolutions": [{"url": "https://external-preview.redd.it/K2N8TUPiTmz9zd5ZVDni-jZkijo9Z4H7ZIZXchqEP-k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=566bcec48eb65ff53e2c70f77becc1dbe3d5936d", "width": 108, "height": 42}], "variants": {}, "id": "y0dxQxalo2eI5xqsrBiW8YC-imuDxBqSTKF-C9qiVyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17xgl82", "is_robot_indexable": true, "report_reasons": null, "author": "WeaknessAlive754", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xgl82/save_up_to_50_on_devart_database_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xgl82/save_up_to_50_on_devart_database_tools/", "subreddit_subscribers": 140176, "created_utc": 1700232200.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}