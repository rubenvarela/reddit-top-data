{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious on some of the biggest costs of time/money that holds back the ability for your team to do their jobs effectively. For example,  things that are huge pain daily.", "author_fullname": "t2_kj229pv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the biggest obstacles/painpoints in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17so76t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699682230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious on some of the biggest costs of time/money that holds back the ability for your team to do their jobs effectively. For example,  things that are huge pain daily.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17so76t", "is_robot_indexable": true, "report_reasons": null, "author": "snailspeed25", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17so76t/what_are_the_biggest_obstaclespainpoints_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17so76t/what_are_the_biggest_obstaclespainpoints_in_data/", "subreddit_subscribers": 139174, "created_utc": 1699682230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's a rant really about some of our airflow jobs having more lines of code than the actual code and also more effort in writing airflow code than the real work.\n\nI tried building airflow factory models etc but it did not help. Hope something like autosys or control m comes up as open source for big data job scheduling.", "author_fullname": "t2_kfvc08j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hate the idea of writing code for job scheduling like airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17t0d2p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699726999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a rant really about some of our airflow jobs having more lines of code than the actual code and also more effort in writing airflow code than the real work.&lt;/p&gt;\n\n&lt;p&gt;I tried building airflow factory models etc but it did not help. Hope something like autosys or control m comes up as open source for big data job scheduling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t0d2p", "is_robot_indexable": true, "report_reasons": null, "author": "RepulsiveCry8412", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t0d2p/does_anyone_else_hate_the_idea_of_writing_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t0d2p/does_anyone_else_hate_the_idea_of_writing_code/", "subreddit_subscribers": 139174, "created_utc": 1699726999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Give me perspective, oh wise Reddit collective!\n\nWe are on-prem Oracle ERP and DWHS and management wants to move DWHS to MS Fabric (when GA) and Purview. DWHS is ~200 end-reporting-tables/20 models for Cognos (storage of reporting data in Oracle tops out around 1TB).\n\nPowerBI certainly seems more capable/supported/forward-thinking than Cognos, and we\u2019re mostly an MS shop, so I see the allure:\n\n1) Moving to \u201cthe cloud\u201d as a measure of maturity (DE Manifesto)\n2 ADF/AzureDevOps touts ease-of-CI/CD and rapid pipeline development\n3) OneLake inclusion of User-Supplied data in modeling\n4) Sensitivity Labeling preventive exfiltration\n5) Reverse engineering with Power Automate\n\nHowever, I\u2019m concerned this move, while likely an improvement from our current architecture, would be a mistake, given the plethora of outstanding decoupled open-source components out there for orgs with sufficient on-prem experience and resources such as ours.\n\nI\u2019m thinking something like getting off Oracle for our DWHS, using on-prem PostGres (maybe one dedicated for perpetual ETL-oading into another for consumption), using Airbyte for the ingestion, Dagster for the Orchestration, Git/DBT for the \u2018T\u2019, while moving the needle in the DataMesh direction by taking the dozen-or-so external domain analysts with current direct access, to using DBT and developing locally with DuckDB, maybe even SQLMesh.\n\nI feel like the amount of time it would take us to move and acclimate to Azure would be on par with the time to go down this \u201cfree\u201d route.\n\nAnyone else have experience with these quandaries?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why pay for worse when better is free?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17sq4zz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699690931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Give me perspective, oh wise Reddit collective!&lt;/p&gt;\n\n&lt;p&gt;We are on-prem Oracle ERP and DWHS and management wants to move DWHS to MS Fabric (when GA) and Purview. DWHS is ~200 end-reporting-tables/20 models for Cognos (storage of reporting data in Oracle tops out around 1TB).&lt;/p&gt;\n\n&lt;p&gt;PowerBI certainly seems more capable/supported/forward-thinking than Cognos, and we\u2019re mostly an MS shop, so I see the allure:&lt;/p&gt;\n\n&lt;p&gt;1) Moving to \u201cthe cloud\u201d as a measure of maturity (DE Manifesto)\n2 ADF/AzureDevOps touts ease-of-CI/CD and rapid pipeline development\n3) OneLake inclusion of User-Supplied data in modeling\n4) Sensitivity Labeling preventive exfiltration\n5) Reverse engineering with Power Automate&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m concerned this move, while likely an improvement from our current architecture, would be a mistake, given the plethora of outstanding decoupled open-source components out there for orgs with sufficient on-prem experience and resources such as ours.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking something like getting off Oracle for our DWHS, using on-prem PostGres (maybe one dedicated for perpetual ETL-oading into another for consumption), using Airbyte for the ingestion, Dagster for the Orchestration, Git/DBT for the \u2018T\u2019, while moving the needle in the DataMesh direction by taking the dozen-or-so external domain analysts with current direct access, to using DBT and developing locally with DuckDB, maybe even SQLMesh.&lt;/p&gt;\n\n&lt;p&gt;I feel like the amount of time it would take us to move and acclimate to Azure would be on par with the time to go down this \u201cfree\u201d route.&lt;/p&gt;\n\n&lt;p&gt;Anyone else have experience with these quandaries?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17sq4zz", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17sq4zz/why_pay_for_worse_when_better_is_free/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17sq4zz/why_pay_for_worse_when_better_is_free/", "subreddit_subscribers": 139174, "created_utc": 1699690931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Having a discussion about what level of data freshness a cloud data warehouse should be having. \n\nWhat do you do? Why?\n\n[View Poll](https://www.reddit.com/poll/17siy7h)", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often does your DWH refresh?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17siy7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699664629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Having a discussion about what level of data freshness a cloud data warehouse should be having. &lt;/p&gt;\n\n&lt;p&gt;What do you do? Why?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17siy7h\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17siy7h", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1699837429985, "options": [{"text": "Once Daily (Night)", "id": "25648725"}, {"text": "Twice Daily (Night+Second Load)", "id": "25648726"}, {"text": "Periodically (Every 2/3/4/6 Hours)", "id": "25648727"}, {"text": "Hourly", "id": "25648728"}, {"text": "Sub-Hour", "id": "25648729"}, {"text": "Realtime", "id": "25648730"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 345, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17siy7h/how_often_does_your_dwh_refresh/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/17siy7h/how_often_does_your_dwh_refresh/", "subreddit_subscribers": 139174, "created_utc": 1699664629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience using Dremio and Starburst?  When should I consider using one over the other?  They seem very similar. \n\nThey both query Iceberg. Which one is faster?", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dremio vs Starburst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17svlvl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699713182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience using Dremio and Starburst?  When should I consider using one over the other?  They seem very similar. &lt;/p&gt;\n\n&lt;p&gt;They both query Iceberg. Which one is faster?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17svlvl", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17svlvl/dremio_vs_starburst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17svlvl/dremio_vs_starburst/", "subreddit_subscribers": 139174, "created_utc": 1699713182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So far I put a docstring at the top with the name of the script, the author, and a description. \n\nI then break up my data validation checks, manipulation, etc. into steps and break up each step using commented out line breaks. Visually and logically this makes sense to me, but I would like to learn how other professionals style their scripts for data conversion to get better and make it easy for anyone to follow what I\u2019m doing. \n\nAre there any best practices or standard scripting methods for SQL? Any resources to learn more in depth?", "author_fullname": "t2_pz85y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you style your SQL scripts for data conversion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17slg7x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699672264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far I put a docstring at the top with the name of the script, the author, and a description. &lt;/p&gt;\n\n&lt;p&gt;I then break up my data validation checks, manipulation, etc. into steps and break up each step using commented out line breaks. Visually and logically this makes sense to me, but I would like to learn how other professionals style their scripts for data conversion to get better and make it easy for anyone to follow what I\u2019m doing. &lt;/p&gt;\n\n&lt;p&gt;Are there any best practices or standard scripting methods for SQL? Any resources to learn more in depth?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17slg7x", "is_robot_indexable": true, "report_reasons": null, "author": "imperialka", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17slg7x/how_do_you_style_your_sql_scripts_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17slg7x/how_do_you_style_your_sql_scripts_for_data/", "subreddit_subscribers": 139174, "created_utc": 1699672264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For my own personal development and also on the job.\n\nI am proficient in Power BI and creating complex SQL queries/views and decent knowledge on stored procedures.\n\nMy workplace is allowing me to slowly get some responsibilities on the Data Engineering side. We are a startup and I would say we are a little primitive.\n\nWe use Azure Data Factory, SSIS on Azure Data Factory, Function Apps, Power Automate to connect to do ETL on cloud and API sources. We will eventually get to streaming data.\n\nWhat do you recommend for resources relating to our tools/stack and data engineering in general outside of those tools and that stack?\n\nThanks!", "author_fullname": "t2_2zvizw9q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a Business Intelligence Developer/Engineer and looking to learn Data Engineering. Where should I start? We use the Microsoft Azure and Power Platform and SQL Server if that matters.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17sz0jv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699723121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For my own personal development and also on the job.&lt;/p&gt;\n\n&lt;p&gt;I am proficient in Power BI and creating complex SQL queries/views and decent knowledge on stored procedures.&lt;/p&gt;\n\n&lt;p&gt;My workplace is allowing me to slowly get some responsibilities on the Data Engineering side. We are a startup and I would say we are a little primitive.&lt;/p&gt;\n\n&lt;p&gt;We use Azure Data Factory, SSIS on Azure Data Factory, Function Apps, Power Automate to connect to do ETL on cloud and API sources. We will eventually get to streaming data.&lt;/p&gt;\n\n&lt;p&gt;What do you recommend for resources relating to our tools/stack and data engineering in general outside of those tools and that stack?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17sz0jv", "is_robot_indexable": true, "report_reasons": null, "author": "pikatruuu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17sz0jv/i_am_a_business_intelligence_developerengineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17sz0jv/i_am_a_business_intelligence_developerengineer/", "subreddit_subscribers": 139174, "created_utc": 1699723121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bxjjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seven Ways to Put CDC to Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_17sxiv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p-1bMdQlEO9XyREMAnnasGKtIVdM7SG1f6xPt3fJG8s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699718761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "decodable.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.decodable.co/blog/seven-ways-to-put-cdc-to-work", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?auto=webp&amp;s=6e1b24a0e3e5f942e335d40f22bbbeae2e09ede3", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e3946929800677f18be110ad2d5337e3b5f99392", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4c41d292d9dfe6734617e03c8fc08207379fc048", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f98209135993d551d293acbf30e0b49def8351e", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8df7eb665b1cbbad290ae34d4f92684428e1dcc", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa00aa6abf8e7ec30d7dd778e450033135db2e9c", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/jmgOk-EJWsdmRp32PX5aUg4roBmz4palilEJTI04yXQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b1940b19737a954a031744950ae2aeaa47547ad8", "width": 1080, "height": 720}], "variants": {}, "id": "CwSgzNv0p-XF2ms2horJA6xnC8Sn8GyHtIhwC5LmGsA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17sxiv3", "is_robot_indexable": true, "report_reasons": null, "author": "gunnarmorling", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17sxiv3/seven_ways_to_put_cdc_to_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.decodable.co/blog/seven-ways-to-put-cdc-to-work", "subreddit_subscribers": 139174, "created_utc": 1699718761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: design pattern for loading / maintaining a conformed dimension.\n\nCan anyone reference a best practice for loading and then referencing conformed dimensions?Example: you have multiple systems that all reference \"location/financial location\" of work, though they identify it in different ways (Department, Profit Center, Account)Ultimately, what you want is all of your schemas to use the SAME \"location/financial location\" dimension (conformed dimension). There must be a recommended pattern/approach for building this with ETL/ETL?I'd guess its something like  \n\n\n1. maintain a link table that connects the business key from each source system to the conformed dimension key\n2. load all of the \"new\" data from each of the sources into some sort of staging area (lake, whatever)\n3. merge/match the data to generate new dimension rows\n4. etc.", "author_fullname": "t2_ahf8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load/Maintain Pattern for Conformed Dimension", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17t3gfz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699735592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: design pattern for loading / maintaining a conformed dimension.&lt;/p&gt;\n\n&lt;p&gt;Can anyone reference a best practice for loading and then referencing conformed dimensions?Example: you have multiple systems that all reference &amp;quot;location/financial location&amp;quot; of work, though they identify it in different ways (Department, Profit Center, Account)Ultimately, what you want is all of your schemas to use the SAME &amp;quot;location/financial location&amp;quot; dimension (conformed dimension). There must be a recommended pattern/approach for building this with ETL/ETL?I&amp;#39;d guess its something like  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;maintain a link table that connects the business key from each source system to the conformed dimension key&lt;/li&gt;\n&lt;li&gt;load all of the &amp;quot;new&amp;quot; data from each of the sources into some sort of staging area (lake, whatever)&lt;/li&gt;\n&lt;li&gt;merge/match the data to generate new dimension rows&lt;/li&gt;\n&lt;li&gt;etc.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t3gfz", "is_robot_indexable": true, "report_reasons": null, "author": "PencilBoy99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t3gfz/loadmaintain_pattern_for_conformed_dimension/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t3gfz/loadmaintain_pattern_for_conformed_dimension/", "subreddit_subscribers": 139174, "created_utc": 1699735592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm setting up a data warehouse in Oracle and could use some advice. At a previous job, a colleague of mine used a T-SQL stored procedure for SCD dimension tables in SQL Server.\n\nNow in Oracle, I'm wondering:\n1. What's the best way to handle SCD Type 2? Any specific Oracle ways?\n2. For scheduling these \u201cjobs\u201d, what's the Oracle equivalent of SQL Server Agent?\n\nPS: A colleague of mine proposed using Talend to handle this, but I think a more SQL native solution would be better - easier to understand and maintain.\n\nWould love to hear your opinions on this. Thanks!", "author_fullname": "t2_imnwscg17", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle Ninjas: How should I handle SCDs? (Data Warehouse)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17t4r8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699739988.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699739086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m setting up a data warehouse in Oracle and could use some advice. At a previous job, a colleague of mine used a T-SQL stored procedure for SCD dimension tables in SQL Server.&lt;/p&gt;\n\n&lt;p&gt;Now in Oracle, I&amp;#39;m wondering:\n1. What&amp;#39;s the best way to handle SCD Type 2? Any specific Oracle ways?\n2. For scheduling these \u201cjobs\u201d, what&amp;#39;s the Oracle equivalent of SQL Server Agent?&lt;/p&gt;\n\n&lt;p&gt;PS: A colleague of mine proposed using Talend to handle this, but I think a more SQL native solution would be better - easier to understand and maintain.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your opinions on this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17t4r8q", "is_robot_indexable": true, "report_reasons": null, "author": "ByteAutomator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17t4r8q/oracle_ninjas_how_should_i_handle_scds_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t4r8q/oracle_ninjas_how_should_i_handle_scds_data/", "subreddit_subscribers": 139174, "created_utc": 1699739086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanted to share our work on [Tarsier](https://github.com/reworkd/tarsier) here, an open source utility library that enables LLMs like GPT-4 and GPT-4 Vision to browse the web. The library helps answer the following questions:\n\n* How do you map LLM responses back into web elements?\n* How can you mark up a page for an LLM to better understand its action space?\n* How do you feed a \"screenshot\" to a text-only LLM?\n\nWe do this by tagging \"*interactable*\" elements on the page with an ID, enabling the LLM to connect actions to an ID which we can then translate back into web elements. We also use OCR to translate a page screenshot to a spatially encoded text string such that even a text only LLM can understand how to navigate the page.\n\nView a demo and read more on GitHub: [https://github.com/reworkd/tarsier](https://github.com/reworkd/tarsier)", "author_fullname": "t2_w08ahc6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GPT-4 vision utilities to translate web page data for web browsing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17t4h0y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699738326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to share our work on &lt;a href=\"https://github.com/reworkd/tarsier\"&gt;Tarsier&lt;/a&gt; here, an open source utility library that enables LLMs like GPT-4 and GPT-4 Vision to browse the web. The library helps answer the following questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you map LLM responses back into web elements?&lt;/li&gt;\n&lt;li&gt;How can you mark up a page for an LLM to better understand its action space?&lt;/li&gt;\n&lt;li&gt;How do you feed a &amp;quot;screenshot&amp;quot; to a text-only LLM?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We do this by tagging &amp;quot;&lt;em&gt;interactable&lt;/em&gt;&amp;quot; elements on the page with an ID, enabling the LLM to connect actions to an ID which we can then translate back into web elements. We also use OCR to translate a page screenshot to a spatially encoded text string such that even a text only LLM can understand how to navigate the page.&lt;/p&gt;\n\n&lt;p&gt;View a demo and read more on GitHub: &lt;a href=\"https://github.com/reworkd/tarsier\"&gt;https://github.com/reworkd/tarsier&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?auto=webp&amp;s=a5f040d28e750df730ec39f670172c604bc41989", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6023b959bb5f016acead3b5165eae4f1ccff2895", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3cd3b4c43cf8adffe01aac66dfaa1870ffc7d94", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9f564ea441a484ef549135bb24896969018459e1", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=54cc08028c73f394c4cc745e30d1f4aa449234c4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=344aa8bf0ab59ed6270df6ef1fec6426a1416dbc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/SQnKOQ2ynhTKR8qig1oE0YFKW4fyTeOsvTu_6udsOf4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a60b4fdb6d37a88fcfd7370f598d2ff44b1d65d", "width": 1080, "height": 540}], "variants": {}, "id": "H7P7mxgoWPXQJip0tdF8bnO0aWwc9vDk0036ITGcIX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17t4h0y", "is_robot_indexable": true, "report_reasons": null, "author": "asim-shrestha", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t4h0y/gpt4_vision_utilities_to_translate_web_page_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t4h0y/gpt4_vision_utilities_to_translate_web_page_data/", "subreddit_subscribers": 139174, "created_utc": 1699738326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hear me out with this one- it might be a stupid idea that\u2019s going to cause more harm than good in the long run. However, maybe a proper implementation can mean this *could* be quite beneficial\u2026 I\u2019m not sure.\n\nI\u2019m in a scenario where I\u2019m building a data warehouse for my organization. At the moment, several departments have outsourced their storage needs to various companies. This causes issues and we want a single source for some data that gets used in some critical operations to our business. In theory, this is just going to make a painful process better, save the CEO (C-suit really) a bunch of time in meetings, you get the idea.\n\nThis project has become bottlenecked by another project: a webapp that needs to be smart enough for my users to input denormalized fields, and it can store the normalized records. I\u2019m not quite experienced with webapps, but seeing as this is going to require some logic I went with Django.\n\nLet me explain a little about my schema. My users want to store the historic rates for building materials. The source metrics are a quantity and cost_total. Unfortunately, because this has been tracked in Excel for decades, there\u2019s a bit of missing data.\n\nNow, a rate might be determined by dividing the item by a unit of measure, like square foot. Alternatively, a rate might be determined per instance of something in the project, like the number of Floors in the project (assuming we\u2019re building a house). Think how you might rate Fire Extinguisher costs per floor, but Flooring costs per Square Foot of Flooring.\n\nSo I created a table to store costs for items, a table for quantities of project attributes, and a table for rates. The values for items and project attributes are NULLable, so in theory a rate can be stored with missing data.\n\nMy webapp has to be smart enough that users can select the fundamental components (project_name, item, \u2026) and it\u2019ll automatically find records for Quantity and Cost_Total, and allow users to create those records if needed or change them, while just submitting a rate. No problem, but it\u2019s going to take me awhile as I\u2019m no JavaScript guru.\n\nIn the meantime, I have business users who just want higher quality data sources now. They\u2019ve got deadlines and I don\u2019t know if I can finish the webapp + get my business users to input all their data quick enough. My business users do NOT (for some reason) want to take the quick start and make me an Excel/ CSV upload file.\n\nSo, I\u2019m wondering if there would be any sense at all in designing my other colleagues a file level database they can use as a single source of truth for the time being. I haven\u2019t brainstormed all the answers yet, but in theory maybe a temporary solution with SQLite3 and an ODBC driver can work for now. I could fill this much more quickly with basic data they\u2019d need and it could be a \u201csingle source of truth.\u201d \n\nRight now, an Excel file isn\u2019t a \u201csingle source of truth\u201d because of various nuances in how the existing workflow works\u2026 needing to copy data here and there\u2026. We\u2019ve got a long way ahead of us.\n\nIs this a bad idea guys? I\u2019m kind of curious what all of this makes you think about.\n\nThanks.", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of quick and dirty SQLite3 solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17t3ryj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699738211.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699736490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hear me out with this one- it might be a stupid idea that\u2019s going to cause more harm than good in the long run. However, maybe a proper implementation can mean this &lt;em&gt;could&lt;/em&gt; be quite beneficial\u2026 I\u2019m not sure.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m in a scenario where I\u2019m building a data warehouse for my organization. At the moment, several departments have outsourced their storage needs to various companies. This causes issues and we want a single source for some data that gets used in some critical operations to our business. In theory, this is just going to make a painful process better, save the CEO (C-suit really) a bunch of time in meetings, you get the idea.&lt;/p&gt;\n\n&lt;p&gt;This project has become bottlenecked by another project: a webapp that needs to be smart enough for my users to input denormalized fields, and it can store the normalized records. I\u2019m not quite experienced with webapps, but seeing as this is going to require some logic I went with Django.&lt;/p&gt;\n\n&lt;p&gt;Let me explain a little about my schema. My users want to store the historic rates for building materials. The source metrics are a quantity and cost_total. Unfortunately, because this has been tracked in Excel for decades, there\u2019s a bit of missing data.&lt;/p&gt;\n\n&lt;p&gt;Now, a rate might be determined by dividing the item by a unit of measure, like square foot. Alternatively, a rate might be determined per instance of something in the project, like the number of Floors in the project (assuming we\u2019re building a house). Think how you might rate Fire Extinguisher costs per floor, but Flooring costs per Square Foot of Flooring.&lt;/p&gt;\n\n&lt;p&gt;So I created a table to store costs for items, a table for quantities of project attributes, and a table for rates. The values for items and project attributes are NULLable, so in theory a rate can be stored with missing data.&lt;/p&gt;\n\n&lt;p&gt;My webapp has to be smart enough that users can select the fundamental components (project_name, item, \u2026) and it\u2019ll automatically find records for Quantity and Cost_Total, and allow users to create those records if needed or change them, while just submitting a rate. No problem, but it\u2019s going to take me awhile as I\u2019m no JavaScript guru.&lt;/p&gt;\n\n&lt;p&gt;In the meantime, I have business users who just want higher quality data sources now. They\u2019ve got deadlines and I don\u2019t know if I can finish the webapp + get my business users to input all their data quick enough. My business users do NOT (for some reason) want to take the quick start and make me an Excel/ CSV upload file.&lt;/p&gt;\n\n&lt;p&gt;So, I\u2019m wondering if there would be any sense at all in designing my other colleagues a file level database they can use as a single source of truth for the time being. I haven\u2019t brainstormed all the answers yet, but in theory maybe a temporary solution with SQLite3 and an ODBC driver can work for now. I could fill this much more quickly with basic data they\u2019d need and it could be a \u201csingle source of truth.\u201d &lt;/p&gt;\n\n&lt;p&gt;Right now, an Excel file isn\u2019t a \u201csingle source of truth\u201d because of various nuances in how the existing workflow works\u2026 needing to copy data here and there\u2026. We\u2019ve got a long way ahead of us.&lt;/p&gt;\n\n&lt;p&gt;Is this a bad idea guys? I\u2019m kind of curious what all of this makes you think about.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17t3ryj", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17t3ryj/what_do_you_think_of_quick_and_dirty_sqlite3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17t3ryj/what_do_you_think_of_quick_and_dirty_sqlite3/", "subreddit_subscribers": 139174, "created_utc": 1699736490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \nI have been in data engineering for not so long. I am using airbyte and fivetran for past few days to build some connections. \nOut of curiosity , i wanna understand how have they build these platforms, if I need to build something like airbyte , atleast like one one connection support in start, how should I go about?\nBasically, i wanna provide a front end tool like airbyte where people can make their connection without any coding. \nAny article, blog, repos will be appreciated.", "author_fullname": "t2_vkmvzdm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No code etl tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17st2zb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699704453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, \nI have been in data engineering for not so long. I am using airbyte and fivetran for past few days to build some connections. \nOut of curiosity , i wanna understand how have they build these platforms, if I need to build something like airbyte , atleast like one one connection support in start, how should I go about?\nBasically, i wanna provide a front end tool like airbyte where people can make their connection without any coding. \nAny article, blog, repos will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17st2zb", "is_robot_indexable": true, "report_reasons": null, "author": "shaikh21", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17st2zb/no_code_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17st2zb/no_code_etl_tool/", "subreddit_subscribers": 139174, "created_utc": 1699704453.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}