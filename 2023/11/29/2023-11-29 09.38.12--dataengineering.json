{"kind": "Listing", "data": {"after": "t3_1865ulw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do data engineers want for christmas? ", "author_fullname": "t2_i9gj7554a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data engineers want for christmas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1860n25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701190337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do data engineers want for christmas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1860n25", "is_robot_indexable": true, "report_reasons": null, "author": "RadioDramatic3040", "discussion_type": null, "num_comments": 114, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1860n25/what_do_data_engineers_want_for_christmas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1860n25/what_do_data_engineers_want_for_christmas/", "subreddit_subscribers": 142471, "created_utc": 1701190337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to break into the world of data engineering and I am seeing that you need to learn all these different tools like ADF, dbt, etc. to perform ETL. \n\nTo me it seems like Python does all this but clearly I am new to this world and there is something I am missing. \n\nWhat are the benefits of using tools like the ones listed above as opposed to Python?", "author_fullname": "t2_sgpy2k4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python versus ETL tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1866ogd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701205487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to break into the world of data engineering and I am seeing that you need to learn all these different tools like ADF, dbt, etc. to perform ETL. &lt;/p&gt;\n\n&lt;p&gt;To me it seems like Python does all this but clearly I am new to this world and there is something I am missing. &lt;/p&gt;\n\n&lt;p&gt;What are the benefits of using tools like the ones listed above as opposed to Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1866ogd", "is_robot_indexable": true, "report_reasons": null, "author": "manseekingmemes1", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1866ogd/python_versus_etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1866ogd/python_versus_etl_tools/", "subreddit_subscribers": 142471, "created_utc": 1701205487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does one,  effectively clean dates and timestamps of different format to one format?? There are so many combinations and feels like the type of formats are endless.", "author_fullname": "t2_76x4aitl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WTF date formats.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185yh0m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701184855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does one,  effectively clean dates and timestamps of different format to one format?? There are so many combinations and feels like the type of formats are endless.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185yh0m", "is_robot_indexable": true, "report_reasons": null, "author": "Scratch_that_Iich", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185yh0m/wtf_date_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185yh0m/wtf_date_formats/", "subreddit_subscribers": 142471, "created_utc": 1701184855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are data warehouses a bad choice for data apps because they lack freshness, latency, and query concurrency needs?  \n\nOr if we're able to improve ingestion latency, query response time, and concurrency/scaleability, maybe it can be a good choice?  ", "author_fullname": "t2_jg3w8gbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data warehouses serve as application backends?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185uz7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701174754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are data warehouses a bad choice for data apps because they lack freshness, latency, and query concurrency needs?  &lt;/p&gt;\n\n&lt;p&gt;Or if we&amp;#39;re able to improve ingestion latency, query response time, and concurrency/scaleability, maybe it can be a good choice?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185uz7j", "is_robot_indexable": true, "report_reasons": null, "author": "tamargal91", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185uz7j/should_data_warehouses_serve_as_application/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185uz7j/should_data_warehouses_serve_as_application/", "subreddit_subscribers": 142471, "created_utc": 1701174754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am 27 years old, 3 YOE, stuck in a role at a bad company working 8-5 on site for $110K (20K pay cut from last gig). Toxic company culture as well and shoved in basement with IT support. Living at home and don\u2019t want to be in this town. No wife no kids no friends. \n\nOnly been 3 months and can\u2019t find another job especially since I was only at my last gig for 6 months. \nNot even doing DE work, stuck doing low code BI work with piece of shit software called Domo. \n\nDebating quitting and doing my MSDS full time and finishing next July. Have $40K saved up. \n\nAnyone else in a similar situation? How do you cope? Not sure how to get out of this one anytime soon, given my spotty job history and job market.", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Else Stuck in a Bad Job? How Do You Cope?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186aeh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701214302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 27 years old, 3 YOE, stuck in a role at a bad company working 8-5 on site for $110K (20K pay cut from last gig). Toxic company culture as well and shoved in basement with IT support. Living at home and don\u2019t want to be in this town. No wife no kids no friends. &lt;/p&gt;\n\n&lt;p&gt;Only been 3 months and can\u2019t find another job especially since I was only at my last gig for 6 months. \nNot even doing DE work, stuck doing low code BI work with piece of shit software called Domo. &lt;/p&gt;\n\n&lt;p&gt;Debating quitting and doing my MSDS full time and finishing next July. Have $40K saved up. &lt;/p&gt;\n\n&lt;p&gt;Anyone else in a similar situation? How do you cope? Not sure how to get out of this one anytime soon, given my spotty job history and job market.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "186aeh4", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186aeh4/anyone_else_stuck_in_a_bad_job_how_do_you_cope/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186aeh4/anyone_else_stuck_in_a_bad_job_how_do_you_cope/", "subreddit_subscribers": 142471, "created_utc": 1701214302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious about containerization and ETLs", "author_fullname": "t2_h5ydkpa8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are DEs using Docker containers for their ETLs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186fvwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701229107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious about containerization and ETLs&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186fvwk", "is_robot_indexable": true, "report_reasons": null, "author": "SignificantWords", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186fvwk/how_are_des_using_docker_containers_for_their_etls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186fvwk/how_are_des_using_docker_containers_for_their_etls/", "subreddit_subscribers": 142471, "created_utc": 1701229107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am not a data engineer. I was a reporting analyst in a job many years ago, then moved into product owner role at a different company for a mobile application. I got hired into this role (product manager/owner) because I had previous job in the industry - very niche, think healthcare, mortgage loans, etc. I've learned there is a lot of magic that goes on behind the scenes. The data doesn't just automatically move from point A to point B - there is a whole process, imagine that!\n\nSome of the products we have are:\n\n1. data lake and data warehouse\n   1. main customers are business intelligence and various reporting/analytic users\n   2. technology stack is:\n      1. airflow\n      2. dbt\n      3. postgres\n      4. custom inhouse python to extract/load data using AWS lambda or fargate \n2. report delivery\n   1. we have 2 main applications to schedule reports at designated time/frequency and drop into given location. Both systems can produce the file in various extensions (.csv, .txt, etc.)\n\nMy job in a nutshell is to intake \n\n* the various adhoc requests from business users (usually wanting to ingest data from a new source or change request to existing data ingestion process or report)\n* our internal road map items which usually consists of techdebt or improving/enhancing our processes or technologies \n* the actual project management team with various regulatory requests or new data ingestion requests\n* the business intelligence team with creating new semantic layer/wh views or supporting the reporting systems\n\nThen I will gather requirements (for example, for a new data ingestion request, I would document the source data, how do we connect or get the data, what is the primary key, is the data an alpha/delta load, what kind of error handling and notifications need to be set up, etc) then create tickets in JIRA for our engineers. I look at all initiatives in our backlog, and prioritize the work. We then commit to the work in 2 week sprints.\n\nAirflow and dbt are new technologies we implemented this year. Our team had built and was using an in house ETL process via AWS lambda, and scheduling data pipelines off of expected data refresh run times (cron job concept). As in - task 1 takes average of 2 hours to run, then schedule task 2 to start 2.5 hours after task1 is scheduled to start. It was all very custom and not the best.\n\nIn essence, I'm acting as a product manager/owner for the data engineering team at my company. I was wanting to ask this DE community what kinds of things they wish a project/product manager would define when gathering requirements for various data solutions or requests. Having what kind of details or documentation would make you most successful? \n\nAlso, in your opinion, would the data engineers create the data model or the product manager?\n\n&amp;#x200B;", "author_fullname": "t2_50son", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am a Product Manager for data, and I have some questions for Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1866sm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701205772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am not a data engineer. I was a reporting analyst in a job many years ago, then moved into product owner role at a different company for a mobile application. I got hired into this role (product manager/owner) because I had previous job in the industry - very niche, think healthcare, mortgage loans, etc. I&amp;#39;ve learned there is a lot of magic that goes on behind the scenes. The data doesn&amp;#39;t just automatically move from point A to point B - there is a whole process, imagine that!&lt;/p&gt;\n\n&lt;p&gt;Some of the products we have are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;data lake and data warehouse\n\n&lt;ol&gt;\n&lt;li&gt;main customers are business intelligence and various reporting/analytic users&lt;/li&gt;\n&lt;li&gt;technology stack is:\n\n&lt;ol&gt;\n&lt;li&gt;airflow&lt;/li&gt;\n&lt;li&gt;dbt&lt;/li&gt;\n&lt;li&gt;postgres&lt;/li&gt;\n&lt;li&gt;custom inhouse python to extract/load data using AWS lambda or fargate &lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;report delivery\n\n&lt;ol&gt;\n&lt;li&gt;we have 2 main applications to schedule reports at designated time/frequency and drop into given location. Both systems can produce the file in various extensions (.csv, .txt, etc.)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My job in a nutshell is to intake &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;the various adhoc requests from business users (usually wanting to ingest data from a new source or change request to existing data ingestion process or report)&lt;/li&gt;\n&lt;li&gt;our internal road map items which usually consists of techdebt or improving/enhancing our processes or technologies &lt;/li&gt;\n&lt;li&gt;the actual project management team with various regulatory requests or new data ingestion requests&lt;/li&gt;\n&lt;li&gt;the business intelligence team with creating new semantic layer/wh views or supporting the reporting systems&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then I will gather requirements (for example, for a new data ingestion request, I would document the source data, how do we connect or get the data, what is the primary key, is the data an alpha/delta load, what kind of error handling and notifications need to be set up, etc) then create tickets in JIRA for our engineers. I look at all initiatives in our backlog, and prioritize the work. We then commit to the work in 2 week sprints.&lt;/p&gt;\n\n&lt;p&gt;Airflow and dbt are new technologies we implemented this year. Our team had built and was using an in house ETL process via AWS lambda, and scheduling data pipelines off of expected data refresh run times (cron job concept). As in - task 1 takes average of 2 hours to run, then schedule task 2 to start 2.5 hours after task1 is scheduled to start. It was all very custom and not the best.&lt;/p&gt;\n\n&lt;p&gt;In essence, I&amp;#39;m acting as a product manager/owner for the data engineering team at my company. I was wanting to ask this DE community what kinds of things they wish a project/product manager would define when gathering requirements for various data solutions or requests. Having what kind of details or documentation would make you most successful? &lt;/p&gt;\n\n&lt;p&gt;Also, in your opinion, would the data engineers create the data model or the product manager?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1866sm4", "is_robot_indexable": true, "report_reasons": null, "author": "Honeychild06", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1866sm4/i_am_a_product_manager_for_data_and_i_have_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1866sm4/i_am_a_product_manager_for_data_and_i_have_some/", "subreddit_subscribers": 142471, "created_utc": 1701205772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One interesting thing I saw was a lot of zero-ETL features for Redshift (from Aurora, DynamoDB, others). A lot of Q stuff that I don't care about. \n\n[Updates](https://aws.amazon.com/new/?whats-new-content-all.sort-by=item.additionalFields.postDateTime&amp;whats-new-content-all.sort-order=desc&amp;awsf.whats-new-analytics=*all&amp;awsf.whats-new-app-integration=*all&amp;awsf.whats-new-arvr=*all&amp;awsf.whats-new-blockchain=*all&amp;awsf.whats-new-business-applications=*all&amp;awsf.whats-new-cloud-financial-management=*all&amp;awsf.whats-new-compute=*all&amp;awsf.whats-new-containers=*all&amp;awsf.whats-new-customer-enablement=*all&amp;awsf.whats-new-customer%20engagement=*all&amp;awsf.whats-new-database=general-products%23amazon-redshift&amp;awsf.whats-new-developer-tools=*all&amp;awsf.whats-new-end-user-computing=*all&amp;awsf.whats-new-mobile=*all&amp;awsf.whats-new-gametech=*all&amp;awsf.whats-new-iot=*all&amp;awsf.whats-new-machine-learning=*all&amp;awsf.whats-new-management-governance=*all&amp;awsf.whats-new-media-services=*all&amp;awsf.whats-new-migration-transfer=*all&amp;awsf.whats-new-networking-content-delivery=*all&amp;awsf.whats-new-quantum-tech=*all&amp;awsf.whats-new-robotics=*all&amp;awsf.whats-new-satellite=*all&amp;awsf.whats-new-security-id-compliance=*all&amp;awsf.whats-new-serverless=*all&amp;awsf.whats-new-storage=*all&amp;awsf.whats-new-categories=*all&amp;whats-new-content-all.q=redshift&amp;whats-new-content-all.q_operator=AND)\n\nNot sure if I missed anything cool. ", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any new updates from AWS re:Invent for data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186b12f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701215951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One interesting thing I saw was a lot of zero-ETL features for Redshift (from Aurora, DynamoDB, others). A lot of Q stuff that I don&amp;#39;t care about. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aws.amazon.com/new/?whats-new-content-all.sort-by=item.additionalFields.postDateTime&amp;amp;whats-new-content-all.sort-order=desc&amp;amp;awsf.whats-new-analytics=*all&amp;amp;awsf.whats-new-app-integration=*all&amp;amp;awsf.whats-new-arvr=*all&amp;amp;awsf.whats-new-blockchain=*all&amp;amp;awsf.whats-new-business-applications=*all&amp;amp;awsf.whats-new-cloud-financial-management=*all&amp;amp;awsf.whats-new-compute=*all&amp;amp;awsf.whats-new-containers=*all&amp;amp;awsf.whats-new-customer-enablement=*all&amp;amp;awsf.whats-new-customer%20engagement=*all&amp;amp;awsf.whats-new-database=general-products%23amazon-redshift&amp;amp;awsf.whats-new-developer-tools=*all&amp;amp;awsf.whats-new-end-user-computing=*all&amp;amp;awsf.whats-new-mobile=*all&amp;amp;awsf.whats-new-gametech=*all&amp;amp;awsf.whats-new-iot=*all&amp;amp;awsf.whats-new-machine-learning=*all&amp;amp;awsf.whats-new-management-governance=*all&amp;amp;awsf.whats-new-media-services=*all&amp;amp;awsf.whats-new-migration-transfer=*all&amp;amp;awsf.whats-new-networking-content-delivery=*all&amp;amp;awsf.whats-new-quantum-tech=*all&amp;amp;awsf.whats-new-robotics=*all&amp;amp;awsf.whats-new-satellite=*all&amp;amp;awsf.whats-new-security-id-compliance=*all&amp;amp;awsf.whats-new-serverless=*all&amp;amp;awsf.whats-new-storage=*all&amp;amp;awsf.whats-new-categories=*all&amp;amp;whats-new-content-all.q=redshift&amp;amp;whats-new-content-all.q_operator=AND\"&gt;Updates&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Not sure if I missed anything cool. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?auto=webp&amp;s=8afacfc14dfed09cec0415cac7d36db9c3374c61", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=64a1b1322ed94c559cb213e6a08f3eb426a3fb0b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9edddfdb28bb0e92ceb041859aacef81ab9ed42e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de73cdc9da2d0b04938bb7d051ab1a3ceb783323", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60037829d2ce04de0705a2b45123d8ab7c12d41c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5a8f0da08b9281c578a8ab6f49a5b3f577ec9b8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a9a9c1c38bd543a7ea6b718e139a9c1e6b62d18", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186b12f", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186b12f/any_new_updates_from_aws_reinvent_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186b12f/any_new_updates_from_aws_reinvent_for_data/", "subreddit_subscribers": 142471, "created_utc": 1701215951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e5fjdth0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboard: The state of Data Stack 2023 (Metabase community)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_1862o6u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kPzBYrXb59x4jO-68CuAN4T6iqF7yj8Tw9N4NQR2uSw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701195466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/p6ivlpjgr43c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?auto=webp&amp;s=61aa62378b4cc3ef92a8d08d8b2340c85bc0f8c5", "width": 2852, "height": 1582}, "resolutions": [{"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d7cb1ef842e75775ec0b62f3453d254a315fca1", "width": 108, "height": 59}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20a2c3bfe27477dc6daf834fb5b5d2b163fc6fb7", "width": 216, "height": 119}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c3415f8478bfd6c2055fa93de0e041275db50cb", "width": 320, "height": 177}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=01819bbc2ad43db644f3bf3ac582f690537be6a1", "width": 640, "height": 355}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e801796352fe033aa5ef4d89a710af6d68a8510", "width": 960, "height": 532}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=57858bb45a5ffd4798a30a0bd2383906f7bd707e", "width": 1080, "height": 599}], "variants": {}, "id": "1TaasZfLhsEDECE6-HaJk1rr8UgmjMWpjhLEMMj8Usc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1862o6u", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable_Fold4086", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1862o6u/dashboard_the_state_of_data_stack_2023_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/p6ivlpjgr43c1.png", "subreddit_subscribers": 142471, "created_utc": 1701195466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We built an ML-powered Databricks cluster optimization tool to help remove the tedious work of tuning Jobs clusters to lower costs.\n\nWe recently shipped a huge upgrade to our product, Gradient, that can automatically improve your job cluster settings to hit your business goals.\n\nThis just came out of private preview where we had awesome results with early testers.  We're looking for more feedback and would love to have folks here give it a spin!\n\nCheck out our demo video here:  [https://www.youtube.com/watch?v=i09x6B6mtjg](https://www.youtube.com/watch?v=i09x6B6mtjg)\n\nTo get started and try for yourself, [see our docs](https://docs.synccomputing.com/sync-gradient/readme)!", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-Improving Databricks Jobs Clusters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185wvhp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701180489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We built an ML-powered Databricks cluster optimization tool to help remove the tedious work of tuning Jobs clusters to lower costs.&lt;/p&gt;\n\n&lt;p&gt;We recently shipped a huge upgrade to our product, Gradient, that can automatically improve your job cluster settings to hit your business goals.&lt;/p&gt;\n\n&lt;p&gt;This just came out of private preview where we had awesome results with early testers.  We&amp;#39;re looking for more feedback and would love to have folks here give it a spin!&lt;/p&gt;\n\n&lt;p&gt;Check out our demo video here:  &lt;a href=\"https://www.youtube.com/watch?v=i09x6B6mtjg\"&gt;https://www.youtube.com/watch?v=i09x6B6mtjg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;To get started and try for yourself, &lt;a href=\"https://docs.synccomputing.com/sync-gradient/readme\"&gt;see our docs&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?auto=webp&amp;s=05ffd69102d5dddccb997f8ca93ac9307db11e9e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c7aa6eabf1b072b8fef656206ca7554e6d221dd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2743e0abe3a30633e2e4eada7906ea4ea6b32ae", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4aa313b38afb9b8f729582bea89d46839845428b", "width": 320, "height": 240}], "variants": {}, "id": "YONw8Gtri81AzcPYVOVfaJY6Sqx6CR_2aqpiGSQiky0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "185wvhp", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185wvhp/selfimproving_databricks_jobs_clusters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185wvhp/selfimproving_databricks_jobs_clusters/", "subreddit_subscribers": 142471, "created_utc": 1701180489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have used Databricks and Snowflake in the past and learned about Dremio as well, but have never used it so far.\n\nI have a hard time to grasp the differences of the products when it comes to which is the best choice for which scenario.\n\nSo far I would say I prefer Snowflake when I need an easy to use and easy to setup Data Warehouse. It's especially useful if you want to invest all your time in getting value out of data and not invest so much time into operations and setup. Its great for integration in business intelligence solutions like Tableau.\n\nI like Databricks when the data is a bit more in volume and also more diversity in Data formats. The focus of Databricks is in using Spark to move and transform data in streams or batch, but when the main focus is machine learning, AI, but also BI.\n\nWhat about Dremio? What are you pros/cons or maybe use cases for the specific platforms?", "author_fullname": "t2_6n1qa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks vs. Snowflake vs. Dremio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186j31s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701239755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have used Databricks and Snowflake in the past and learned about Dremio as well, but have never used it so far.&lt;/p&gt;\n\n&lt;p&gt;I have a hard time to grasp the differences of the products when it comes to which is the best choice for which scenario.&lt;/p&gt;\n\n&lt;p&gt;So far I would say I prefer Snowflake when I need an easy to use and easy to setup Data Warehouse. It&amp;#39;s especially useful if you want to invest all your time in getting value out of data and not invest so much time into operations and setup. Its great for integration in business intelligence solutions like Tableau.&lt;/p&gt;\n\n&lt;p&gt;I like Databricks when the data is a bit more in volume and also more diversity in Data formats. The focus of Databricks is in using Spark to move and transform data in streams or batch, but when the main focus is machine learning, AI, but also BI.&lt;/p&gt;\n\n&lt;p&gt;What about Dremio? What are you pros/cons or maybe use cases for the specific platforms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186j31s", "is_robot_indexable": true, "report_reasons": null, "author": "RonBurgundyIsBest", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186j31s/databricks_vs_snowflake_vs_dremio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186j31s/databricks_vs_snowflake_vs_dremio/", "subreddit_subscribers": 142471, "created_utc": 1701239755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nThere are loads of full courses for learning how to work with apis as a beginner and I was wondering which one is really recommender for a data engineer?\n\nI\u2019m new to learning api and I think it would be important for me to learn how to authenticate apis and pull data from api (post and get?) \n\nHope to hear from you!", "author_fullname": "t2_2cd0q7u5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best youtube course on learning api?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1868qu3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701210284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;There are loads of full courses for learning how to work with apis as a beginner and I was wondering which one is really recommender for a data engineer?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m new to learning api and I think it would be important for me to learn how to authenticate apis and pull data from api (post and get?) &lt;/p&gt;\n\n&lt;p&gt;Hope to hear from you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1868qu3", "is_robot_indexable": true, "report_reasons": null, "author": "kbic93", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1868qu3/best_youtube_course_on_learning_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1868qu3/best_youtube_course_on_learning_api/", "subreddit_subscribers": 142471, "created_utc": 1701210284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineering manager working in data science for a Fortune 500 financial company. I've been asked to take over leading a monthly meeting of the data engineers across data science. This is a broader audience of collective sub-teams supporting different parts of the business -  engineers who do not work with each other regularly, or even neccessarily know one another.\n\nI've been a participant of these meanings for some time and they have not been the most enjoyable or value-add. The content is usually a data engineer presenting a topic of interest i.e.  a new technology or an innovative way they solved the problem, etc..\n\nI work for a large company, so there are many of these communities. I question whether we need this community in the first place, but not sure if that's my choice to make. Regardless, it's an opportunity for me, but it definitely needs some love.\n\nSome challenges are:\n\n1. Participation. I feel the organizers have a hard time getting folks to present material. Curating fresh content is probably challenging. Often the monthly occurrences are canceled last minute due to this.\n2. Engagement. People are not on camera, not asking questions. Just feel lack of connection.\n\nMy initial thoughts are:\n\n1. We're engineers. We should not be lecturing or presenting PowerPoint decks. Instead there should be code on the screen and we should be coding, demoing etc.\n2. Use the time for discussion. I'm sure many of our sub departments have similar problems to solve.\n3. Get a return on the hour time investment - what this looks like, I'm not sure yet.\n\nFor those of you who work at companies, big or small, do you have similar engineering communities of practice? What goes on, and how do you organize? What would you like to see in a data engineering community at work?", "author_fullname": "t2_16he60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Establishing a Data Engineering Community at Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1861s9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701193245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineering manager working in data science for a Fortune 500 financial company. I&amp;#39;ve been asked to take over leading a monthly meeting of the data engineers across data science. This is a broader audience of collective sub-teams supporting different parts of the business -  engineers who do not work with each other regularly, or even neccessarily know one another.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a participant of these meanings for some time and they have not been the most enjoyable or value-add. The content is usually a data engineer presenting a topic of interest i.e.  a new technology or an innovative way they solved the problem, etc..&lt;/p&gt;\n\n&lt;p&gt;I work for a large company, so there are many of these communities. I question whether we need this community in the first place, but not sure if that&amp;#39;s my choice to make. Regardless, it&amp;#39;s an opportunity for me, but it definitely needs some love.&lt;/p&gt;\n\n&lt;p&gt;Some challenges are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Participation. I feel the organizers have a hard time getting folks to present material. Curating fresh content is probably challenging. Often the monthly occurrences are canceled last minute due to this.&lt;/li&gt;\n&lt;li&gt;Engagement. People are not on camera, not asking questions. Just feel lack of connection.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My initial thoughts are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We&amp;#39;re engineers. We should not be lecturing or presenting PowerPoint decks. Instead there should be code on the screen and we should be coding, demoing etc.&lt;/li&gt;\n&lt;li&gt;Use the time for discussion. I&amp;#39;m sure many of our sub departments have similar problems to solve.&lt;/li&gt;\n&lt;li&gt;Get a return on the hour time investment - what this looks like, I&amp;#39;m not sure yet.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For those of you who work at companies, big or small, do you have similar engineering communities of practice? What goes on, and how do you organize? What would you like to see in a data engineering community at work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1861s9f", "is_robot_indexable": true, "report_reasons": null, "author": "thefreakypeople", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1861s9f/establishing_a_data_engineering_community_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1861s9f/establishing_a_data_engineering_community_at_work/", "subreddit_subscribers": 142471, "created_utc": 1701193245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working as a data engineer for a company that after a merger operates in three countries with different currencies. We need to support local currency reporting, and reporting across the company using all three currencies.\n\nI'm thinking a bit about how to model this in an effective way in the data platform, and there are some options, to which I wanted to see if anyone has good/bad experiences working with multiple currencies. For the record our tech stack is dbt, Databricks and Power BI.\n\nI found this data modelling option from [Kimball](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/multiple-currencies/) that says to store the local unconverted currency (what's coming from the source) along with a chosen single \"main\" currency. Then we provide an exchange rate table and let users/analysts convert currencies in queries/notebooks/Power BI reports when needed. \n\nI imagine to prevent creating a mess of conversions in the platform I would suggest users to use the \"main\" currency in their work and only convert to local currencies in their presentation layers. That way we don't have to convert numbers back and forwards, and it's easy to know when to convert the currency.\n\nDoes anyone here have any experience modelling multiple currencies in this way? Any good or bad experiences? Or are there any other options we should consider?", "author_fullname": "t2_11b4ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle reporting in multiple currencies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185sl1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701165652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working as a data engineer for a company that after a merger operates in three countries with different currencies. We need to support local currency reporting, and reporting across the company using all three currencies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking a bit about how to model this in an effective way in the data platform, and there are some options, to which I wanted to see if anyone has good/bad experiences working with multiple currencies. For the record our tech stack is dbt, Databricks and Power BI.&lt;/p&gt;\n\n&lt;p&gt;I found this data modelling option from &lt;a href=\"https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/multiple-currencies/\"&gt;Kimball&lt;/a&gt; that says to store the local unconverted currency (what&amp;#39;s coming from the source) along with a chosen single &amp;quot;main&amp;quot; currency. Then we provide an exchange rate table and let users/analysts convert currencies in queries/notebooks/Power BI reports when needed. &lt;/p&gt;\n\n&lt;p&gt;I imagine to prevent creating a mess of conversions in the platform I would suggest users to use the &amp;quot;main&amp;quot; currency in their work and only convert to local currencies in their presentation layers. That way we don&amp;#39;t have to convert numbers back and forwards, and it&amp;#39;s easy to know when to convert the currency.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here have any experience modelling multiple currencies in this way? Any good or bad experiences? Or are there any other options we should consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185sl1j", "is_robot_indexable": true, "report_reasons": null, "author": "mmammies", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185sl1j/how_do_you_handle_reporting_in_multiple_currencies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185sl1j/how_do_you_handle_reporting_in_multiple_currencies/", "subreddit_subscribers": 142471, "created_utc": 1701165652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow DEs,\n\nI currently work as a SWE with almost 2 YOE, I've always been interested in the field of data and came across the concept of DE when researching about different job opportunities. I wanted to stay heavy coding (which rules out DA) and DE seems to be the right fit.\n\nHowever, as I read more and more posts in the sub, I realise a huge portion of DE's responsibilities involve DevOps as well. Setting up environments and configuring has always been my No.1 pet peeve in the world of software development. I didn't need to do much of it in my role of SWE as it's mostly handled by other people in the same company.\n\nAn example would be, me trying to setup Airflow + DuckDB and etc. in docker for experimentation. I am instantly mind-boggled by the configuration process (e.g., how to write a proper YAML to initialise these components). \n\nAll in all, I just want to get some insights from someone already in the field, to know how well I would do if I have an inherent resentment towards doing DevOps. Also, what would be the percentages be like for Python, SQL and DevOps in general?", "author_fullname": "t2_5tffcx87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for someone looking to transition from SWE to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186f796", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701227216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow DEs,&lt;/p&gt;\n\n&lt;p&gt;I currently work as a SWE with almost 2 YOE, I&amp;#39;ve always been interested in the field of data and came across the concept of DE when researching about different job opportunities. I wanted to stay heavy coding (which rules out DA) and DE seems to be the right fit.&lt;/p&gt;\n\n&lt;p&gt;However, as I read more and more posts in the sub, I realise a huge portion of DE&amp;#39;s responsibilities involve DevOps as well. Setting up environments and configuring has always been my No.1 pet peeve in the world of software development. I didn&amp;#39;t need to do much of it in my role of SWE as it&amp;#39;s mostly handled by other people in the same company.&lt;/p&gt;\n\n&lt;p&gt;An example would be, me trying to setup Airflow + DuckDB and etc. in docker for experimentation. I am instantly mind-boggled by the configuration process (e.g., how to write a proper YAML to initialise these components). &lt;/p&gt;\n\n&lt;p&gt;All in all, I just want to get some insights from someone already in the field, to know how well I would do if I have an inherent resentment towards doing DevOps. Also, what would be the percentages be like for Python, SQL and DevOps in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "186f796", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological_Ad9582", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186f796/advice_for_someone_looking_to_transition_from_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186f796/advice_for_someone_looking_to_transition_from_swe/", "subreddit_subscribers": 142471, "created_utc": 1701227216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Team is heavily dependent on ES and it\u2019s expensive.\n\nI\u2019ve seen OpenSearch being suggested but have no experience running it. I\u2019ve also seen Grafana Loki as an option for logs\n\nUse. Are: full text search on logs\nDeployment: Single tenant ES deployment per customer for search.\n\nAny suggestions or recommendations to move out of this into an alternative solution that is effective and maybe cheaper? Any blogs or migration stories that you can share?", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to ElasticSearch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185zu9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701193353.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701188328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Team is heavily dependent on ES and it\u2019s expensive.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen OpenSearch being suggested but have no experience running it. I\u2019ve also seen Grafana Loki as an option for logs&lt;/p&gt;\n\n&lt;p&gt;Use. Are: full text search on logs\nDeployment: Single tenant ES deployment per customer for search.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or recommendations to move out of this into an alternative solution that is effective and maybe cheaper? Any blogs or migration stories that you can share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185zu9b", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185zu9b/alternative_to_elasticsearch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185zu9b/alternative_to_elasticsearch/", "subreddit_subscribers": 142471, "created_utc": 1701188328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I put together an ETL recently for my work on a chron job API pull that has amassed something like 70,000 rows of data, 100mb of entries a month into a BigQuery dataset for downstream reporting and BI analysis. I expressed concern about aggregation of duplicate entries and entries over time to my manager, suggesting that to save some money I could switch it to a cloud-hosted traditional GCP database (Postgres or similar) with cold storage options for old data that could easily be pumped into Bigquery. They did not seem concerned enough to let me do this. \n\nI have just found out that we have a 13GB dataset for similar reasons, millions of rows of columnar data that get hit with queries frequently and those queries use at least 1GB of data each to process. That puts my smaller dataset costs into context, I suppose. \n\nI am reasonably certain I can at minimum use Dataform to create a secondary dataset adding 100 entries a month instead of 70k, since many pseudo-duplicates are created with no difference other than dates (this is a dataset to catch changes to certain things). I did this actually, because I had to know. It's just not implemented and worried proposing it will seem foolish. \n\nAt what point is it actually smart to worry about these things? Manager seems unworried. I am baby. Please help me look smart.", "author_fullname": "t2_dbmvkyyq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big is too big for a BigQuery Dataset getting frequent queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1865u8u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701203342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I put together an ETL recently for my work on a chron job API pull that has amassed something like 70,000 rows of data, 100mb of entries a month into a BigQuery dataset for downstream reporting and BI analysis. I expressed concern about aggregation of duplicate entries and entries over time to my manager, suggesting that to save some money I could switch it to a cloud-hosted traditional GCP database (Postgres or similar) with cold storage options for old data that could easily be pumped into Bigquery. They did not seem concerned enough to let me do this. &lt;/p&gt;\n\n&lt;p&gt;I have just found out that we have a 13GB dataset for similar reasons, millions of rows of columnar data that get hit with queries frequently and those queries use at least 1GB of data each to process. That puts my smaller dataset costs into context, I suppose. &lt;/p&gt;\n\n&lt;p&gt;I am reasonably certain I can at minimum use Dataform to create a secondary dataset adding 100 entries a month instead of 70k, since many pseudo-duplicates are created with no difference other than dates (this is a dataset to catch changes to certain things). I did this actually, because I had to know. It&amp;#39;s just not implemented and worried proposing it will seem foolish. &lt;/p&gt;\n\n&lt;p&gt;At what point is it actually smart to worry about these things? Manager seems unworried. I am baby. Please help me look smart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1865u8u", "is_robot_indexable": true, "report_reasons": null, "author": "artfully_rearranged", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1865u8u/how_big_is_too_big_for_a_bigquery_dataset_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1865u8u/how_big_is_too_big_for_a_bigquery_dataset_getting/", "subreddit_subscribers": 142471, "created_utc": 1701203342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to ask anyone finished MIT MicroMaster program of Data Science (via edx), how is it useful or not at Job Market? may have your experience shared? Does hiring company recognize it and give it a credit? Sorry I intend to ask this question but can't change post subject after submitted.\n\n'm afraid a little bit for it's 'not a formal Master Degree, so employer won't take it seriously as much as MIT regular on-campus students.   FYI, I finished one of its Course 'MIT x6.431 - Probability and Data Uncertainty', get good score 92/100,  have 3 remains, but I'm working full-time, progress Very slowly, by time I graduate I'll be over 50...   see my certificate in attached Image", "author_fullname": "t2_bt52hv18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My MIT course certificate in Data Science MicroMaster program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186456j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701199107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to ask anyone finished MIT MicroMaster program of Data Science (via edx), how is it useful or not at Job Market? may have your experience shared? Does hiring company recognize it and give it a credit? Sorry I intend to ask this question but can&amp;#39;t change post subject after submitted.&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;m afraid a little bit for it&amp;#39;s &amp;#39;not a formal Master Degree, so employer won&amp;#39;t take it seriously as much as MIT regular on-campus students.   FYI, I finished one of its Course &amp;#39;MIT x6.431 - Probability and Data Uncertainty&amp;#39;, get good score 92/100,  have 3 remains, but I&amp;#39;m working full-time, progress Very slowly, by time I graduate I&amp;#39;ll be over 50...   see my certificate in attached Image&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186456j", "is_robot_indexable": true, "report_reasons": null, "author": "SG-Dani20", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186456j/my_mit_course_certificate_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186456j/my_mit_course_certificate_in_data_science/", "subreddit_subscribers": 142471, "created_utc": 1701199107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody else had recruiters ask for every damn think in their mental toolbox, when all the client actually wants is somebody to hold their hand and tell them what data is? AWS, GCP, Python, Redshift,SQL, TSQL, PSQL, cloud infrastructure, terraform etc.... come on give us a chance. Give us a use case and we will go to work.", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Knobhead recruiters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185tdkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701168849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody else had recruiters ask for every damn think in their mental toolbox, when all the client actually wants is somebody to hold their hand and tell them what data is? AWS, GCP, Python, Redshift,SQL, TSQL, PSQL, cloud infrastructure, terraform etc.... come on give us a chance. Give us a use case and we will go to work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185tdkb", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185tdkb/knobhead_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185tdkb/knobhead_recruiters/", "subreddit_subscribers": 142471, "created_utc": 1701168849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nAs the title suggests, I have a certain json files available in my GCS buckets and I have to export the same using curl scripts to our vendors. Considering that the access tokens have an expiry timeline, I\u2019m looking into sending a curl script that the vendor can access for longer than the timeout. \n\nWould appreciate any help.\n\nThanks.", "author_fullname": "t2_3qc9b4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Export JSON files from GCS buckets using curl scripts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_186ksd3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701246833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;As the title suggests, I have a certain json files available in my GCS buckets and I have to export the same using curl scripts to our vendors. Considering that the access tokens have an expiry timeline, I\u2019m looking into sending a curl script that the vendor can access for longer than the timeout. &lt;/p&gt;\n\n&lt;p&gt;Would appreciate any help.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186ksd3", "is_robot_indexable": true, "report_reasons": null, "author": "apache444", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186ksd3/export_json_files_from_gcs_buckets_using_curl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186ksd3/export_json_files_from_gcs_buckets_using_curl/", "subreddit_subscribers": 142471, "created_utc": 1701246833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an SQL and Database &amp; Data table design coding round coming up with a gene-omics startup scale firm.\nWhat level of difficulty should I be expecting in the interview?\nI have some SQL foundation and experience but will have to invest some time into database design.\nThanks", "author_fullname": "t2_kgmdgive", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL and Database &amp; Data table design interview coming up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186i9g5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701236827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an SQL and Database &amp;amp; Data table design coding round coming up with a gene-omics startup scale firm.\nWhat level of difficulty should I be expecting in the interview?\nI have some SQL foundation and experience but will have to invest some time into database design.\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "186i9g5", "is_robot_indexable": true, "report_reasons": null, "author": "Grouchy-Method6979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186i9g5/sql_and_database_data_table_design_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186i9g5/sql_and_database_data_table_design_interview/", "subreddit_subscribers": 142471, "created_utc": 1701236827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here is my career progression.\n\n0-2 years - SQL DBA/BI Engineer\n\n2-4 years - BI engineer\n\n4-5 1/2 years - Big Data Analyst\n\nNow trying for DE roles and going through interviews.Got offer for a DE role, but have few more interviews to be completed.\nBefore working as a Big Data analyst I tried for DE roles but I was not able to move forward in the interviews as I didn\u2019t have any professional experience with Cloud Technologies or big data tools/technologies.\n\nIs this a general career progression or y\u2019all got into DE roles much earlier in the career.?", "author_fullname": "t2_slia7yw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Progression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186guvp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701232134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is my career progression.&lt;/p&gt;\n\n&lt;p&gt;0-2 years - SQL DBA/BI Engineer&lt;/p&gt;\n\n&lt;p&gt;2-4 years - BI engineer&lt;/p&gt;\n\n&lt;p&gt;4-5 1/2 years - Big Data Analyst&lt;/p&gt;\n\n&lt;p&gt;Now trying for DE roles and going through interviews.Got offer for a DE role, but have few more interviews to be completed.\nBefore working as a Big Data analyst I tried for DE roles but I was not able to move forward in the interviews as I didn\u2019t have any professional experience with Cloud Technologies or big data tools/technologies.&lt;/p&gt;\n\n&lt;p&gt;Is this a general career progression or y\u2019all got into DE roles much earlier in the career.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "186guvp", "is_robot_indexable": true, "report_reasons": null, "author": "cruze_8907", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186guvp/career_progression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186guvp/career_progression/", "subreddit_subscribers": 142471, "created_utc": 1701232134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "we\u2019re using Fivetran as a ETL tool and Odoo for accounting &amp; finance. However, Odoo is not one of Fivetrans\u2019 applications. \nThere\u2019s no connection between them.\n\nIs there any workaround to make this happen? and how? \n\n+ BigQuery is the DW", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran Connectors \u2014Odoo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1868hvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701209711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;we\u2019re using Fivetran as a ETL tool and Odoo for accounting &amp;amp; finance. However, Odoo is not one of Fivetrans\u2019 applications. \nThere\u2019s no connection between them.&lt;/p&gt;\n\n&lt;p&gt;Is there any workaround to make this happen? and how? &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BigQuery is the DW&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1868hvd", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1868hvd/fivetran_connectors_odoo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1868hvd/fivetran_connectors_odoo/", "subreddit_subscribers": 142471, "created_utc": 1701209711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking to create an on premise to cloud (Azure) ETL pipeline for an old ERP system.\n\nAny experience / recommendations for working with older versions of SQL Server?\n\nAlso, is there a common method of data migration for cases like this?", "author_fullname": "t2_ajotdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Server 2012 ERP system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1867nbe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701209051.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701207753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to create an on premise to cloud (Azure) ETL pipeline for an old ERP system.&lt;/p&gt;\n\n&lt;p&gt;Any experience / recommendations for working with older versions of SQL Server?&lt;/p&gt;\n\n&lt;p&gt;Also, is there a common method of data migration for cases like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1867nbe", "is_robot_indexable": true, "report_reasons": null, "author": "circuitpatrol", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1867nbe/sql_server_2012_erp_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1867nbe/sql_server_2012_erp_system/", "subreddit_subscribers": 142471, "created_utc": 1701207753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm tasked with designing a system for a database-per-client SaaS WMS. This WMS is based on MySQL and currently retains data indefinitely (with PII redacted). However, this indefinite data retention is bloating our databases for data that is accessed very infrequently, but our customers don't want us to purge the data completely.\n\nMy thoughts are to offload it to an \"archive\" data store of some sort. Cheap storage, low maintenance, durable. It needs to support occasional ad-hoc queries, grids, dashboards, exports, single-record lookups, etc. Simultaneously, we want to improve our user-friendliness for data engineers and make all of their data easily accessible without providing access to the main OLTP database, just a sort of sanitized view of it (e.g. 40 tables instead of 200) in an easy-to-consume format (a read-only db connection, or bucket containing Delta Lake files, an Airbyte connector, etc).\n\nThere are so many options I am struggling to make some decisions... Batch vs stream? DBMS vs query engine? The system doesn't need to be highly-available but the data needs to be extremely durable. So far my research has led me to strongly consider a data lakehouse backed by S3 storage and either a query engine or a materialized view of it in a non-HA database that can easily be rebuilt. I think our upper limits for the foreseeable future are well within &lt;100 million new rows per year so single-node solutions like DuckDb or just Postgres with partitioning look reasonable. However, solutions like Clickhouse also look attractive and could be a strong selling point to enterprise customers who just want to connect to the data easily with their tool of choice.\n\nSo, three questions:\n\n1. Having the data split into two separate systems (live and archived) seems like it will be cumbersome so we'd like the \"archive\" to also contain near-real-time data so that BAs can just go to one source for all. Is this a bad idea? If so, what is a better way around this?\n2. There is a challenge with some of the ETL tools since we want to \"archive\" our data: We will be deleting rows from our MySQL database to archive them, not because they should be destroyed in the data lake. How do we work around this challenge with CDC or batch tools so that the archived rows continue to exist in the archive database even though they are purged from the source database? Surely this is not a new problem but I haven't seen it discussed. Most of our data is append-only but there is some that if we wanted to use the same system for the live data we would need to be able to support deletes.\n3. What are your recommendations for this data pipeline and resting place? We want to remain on FOSS at this time. Some of the specific projects that have caught my eye so far for inclusion in our stack are:\n\n* Cube ([cube.dev](https://cube.dev)) for our out-of-the-box dashboards and reports, possibly merging data sources\n* Delta Lake or Hudi formats for long-term storage and data sharing\n* DuckDb/MotherDuck, Clickhouse or Trino for querying\n* dbt, Debezium, home-grown Python for data ingestion - is it common to use batch tool to load the initial batch and then a CDC streaming tool to keep it up-to-date?\n* Airbyte and other \"easy\" tools to either mirror a real-time database or generally provide more options for data destinations as long as they can be automated for many clients\n* Python's MySQL binlog streamer for reading updates from MySQL if we need to write a custom tool\n\nOur main core competency is still the WMS features so this is a \"side\" project (but necessary to keep our main database nimble), but we also want data availability and analytics to become a differentiating strength - keeping in mind it isn't our #1 core competency so overall investment cost needs to be relatively low at this time.\n\nWe are strongest with PHP and Node but are willing to delve into light Python or Java development if needed since we recognize PHP is not a big player in this space. We are comfortable working with SQL so that is generally more attractive than things like DataFrames.\n\nIf you got this far, thanks for that! Your thoughts would be much appreciated!", "author_fullname": "t2_ct83gg0tt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive to Data Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1865ulw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701203368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m tasked with designing a system for a database-per-client SaaS WMS. This WMS is based on MySQL and currently retains data indefinitely (with PII redacted). However, this indefinite data retention is bloating our databases for data that is accessed very infrequently, but our customers don&amp;#39;t want us to purge the data completely.&lt;/p&gt;\n\n&lt;p&gt;My thoughts are to offload it to an &amp;quot;archive&amp;quot; data store of some sort. Cheap storage, low maintenance, durable. It needs to support occasional ad-hoc queries, grids, dashboards, exports, single-record lookups, etc. Simultaneously, we want to improve our user-friendliness for data engineers and make all of their data easily accessible without providing access to the main OLTP database, just a sort of sanitized view of it (e.g. 40 tables instead of 200) in an easy-to-consume format (a read-only db connection, or bucket containing Delta Lake files, an Airbyte connector, etc).&lt;/p&gt;\n\n&lt;p&gt;There are so many options I am struggling to make some decisions... Batch vs stream? DBMS vs query engine? The system doesn&amp;#39;t need to be highly-available but the data needs to be extremely durable. So far my research has led me to strongly consider a data lakehouse backed by S3 storage and either a query engine or a materialized view of it in a non-HA database that can easily be rebuilt. I think our upper limits for the foreseeable future are well within &amp;lt;100 million new rows per year so single-node solutions like DuckDb or just Postgres with partitioning look reasonable. However, solutions like Clickhouse also look attractive and could be a strong selling point to enterprise customers who just want to connect to the data easily with their tool of choice.&lt;/p&gt;\n\n&lt;p&gt;So, three questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Having the data split into two separate systems (live and archived) seems like it will be cumbersome so we&amp;#39;d like the &amp;quot;archive&amp;quot; to also contain near-real-time data so that BAs can just go to one source for all. Is this a bad idea? If so, what is a better way around this?&lt;/li&gt;\n&lt;li&gt;There is a challenge with some of the ETL tools since we want to &amp;quot;archive&amp;quot; our data: We will be deleting rows from our MySQL database to archive them, not because they should be destroyed in the data lake. How do we work around this challenge with CDC or batch tools so that the archived rows continue to exist in the archive database even though they are purged from the source database? Surely this is not a new problem but I haven&amp;#39;t seen it discussed. Most of our data is append-only but there is some that if we wanted to use the same system for the live data we would need to be able to support deletes.&lt;/li&gt;\n&lt;li&gt;What are your recommendations for this data pipeline and resting place? We want to remain on FOSS at this time. Some of the specific projects that have caught my eye so far for inclusion in our stack are:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cube (&lt;a href=\"https://cube.dev\"&gt;cube.dev&lt;/a&gt;) for our out-of-the-box dashboards and reports, possibly merging data sources&lt;/li&gt;\n&lt;li&gt;Delta Lake or Hudi formats for long-term storage and data sharing&lt;/li&gt;\n&lt;li&gt;DuckDb/MotherDuck, Clickhouse or Trino for querying&lt;/li&gt;\n&lt;li&gt;dbt, Debezium, home-grown Python for data ingestion - is it common to use batch tool to load the initial batch and then a CDC streaming tool to keep it up-to-date?&lt;/li&gt;\n&lt;li&gt;Airbyte and other &amp;quot;easy&amp;quot; tools to either mirror a real-time database or generally provide more options for data destinations as long as they can be automated for many clients&lt;/li&gt;\n&lt;li&gt;Python&amp;#39;s MySQL binlog streamer for reading updates from MySQL if we need to write a custom tool&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Our main core competency is still the WMS features so this is a &amp;quot;side&amp;quot; project (but necessary to keep our main database nimble), but we also want data availability and analytics to become a differentiating strength - keeping in mind it isn&amp;#39;t our #1 core competency so overall investment cost needs to be relatively low at this time.&lt;/p&gt;\n\n&lt;p&gt;We are strongest with PHP and Node but are willing to delve into light Python or Java development if needed since we recognize PHP is not a big player in this space. We are comfortable working with SQL so that is generally more attractive than things like DataFrames.&lt;/p&gt;\n\n&lt;p&gt;If you got this far, thanks for that! Your thoughts would be much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?auto=webp&amp;s=54ecda4166c9e908f44e7198a512fd8217bde76f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c336be41f508d0558022cfdf2329a3aa03d0837", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cf54898c464185d690b5dc924442212254ac816", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff72f2eff48667de83eb6f0e56b166d00a6157e2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb3d40df634bb73fb7fe0ace9cce99fb91709885", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e91004d95d8289e23224a7f755fe0ffbe4b7f3c9", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/5GV9Mg6KCJjh6B6cKFsrECc1hNwneInEJmgAKhpt8bg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd9da78c13e4e678d32ffb59d64e6932b9c9c71b", "width": 1080, "height": 567}], "variants": {}, "id": "CYFlWqFefFx0WAlgFZvtSzIVYhX58H2hKywSvmvXXxw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1865ulw", "is_robot_indexable": true, "report_reasons": null, "author": "Prudent-Eye-2653", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1865ulw/archive_to_data_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1865ulw/archive_to_data_lakehouse/", "subreddit_subscribers": 142471, "created_utc": 1701203368.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}