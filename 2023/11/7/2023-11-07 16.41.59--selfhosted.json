{"kind": "Listing", "data": {"after": "t3_17pq3nf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am not an experienced user of Docker. For me, [Linuxserver.io](https://Linuxserver.io) images on docker hub have been wonderful. They are easy to configure, well documented and easy to install. It's so heartening to see an effort being made to make Docker accessible to everyone.\n\n&amp;#x200B;\n\nIf you're a beginner like me, I would strongly recommend choosing their images when possible, simply because their documentation is so consistently simple and easy to follow.\n\n&amp;#x200B;\n\nOn a different note, this is also why I can not use paperless-ngx, which does not have a corresponding LSIO image, right now. I have reached a stage where complex installs (say that of paperless-ngx, which needs me to tweak quite a few docker files individually) seem not worth the effort in the odd event that I mess something up.", "author_fullname": "t2_g56au5xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shout-out to Linuxserver.io for making Docker so easy to use for beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pclhd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 649, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 649, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699309414.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699303577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not an experienced user of Docker. For me, &lt;a href=\"https://Linuxserver.io\"&gt;Linuxserver.io&lt;/a&gt; images on docker hub have been wonderful. They are easy to configure, well documented and easy to install. It&amp;#39;s so heartening to see an effort being made to make Docker accessible to everyone.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re a beginner like me, I would strongly recommend choosing their images when possible, simply because their documentation is so consistently simple and easy to follow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;On a different note, this is also why I can not use paperless-ngx, which does not have a corresponding LSIO image, right now. I have reached a stage where complex installs (say that of paperless-ngx, which needs me to tweak quite a few docker files individually) seem not worth the effort in the odd event that I mess something up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pclhd", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Neat7754", "discussion_type": null, "num_comments": 91, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pclhd/shoutout_to_linuxserverio_for_making_docker_so/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pclhd/shoutout_to_linuxserverio_for_making_docker_so/", "subreddit_subscribers": 288861, "created_utc": 1699303577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "If you're a beginner like me, please make use of [Play with Docker](https://labs.play-with-docker.com/) to test images before you install it on your system.\n\nPlay with Docker is a virtual machine which allows you to run Docker commands for a limited duration (4 hours). The instance is deleted after that. I can't believe this is actually free to use. I only came to know of Play with Docker a few days back and I wanted to share it for beginners like me, who may not know about it.", "author_fullname": "t2_g56au5xx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you are a beginner, please make use of \"Play With Docker\" to test images", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "dockermanagement", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ppgeu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Docker Management", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699344897.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699344267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re a beginner like me, please make use of &lt;a href=\"https://labs.play-with-docker.com/\"&gt;Play with Docker&lt;/a&gt; to test images before you install it on your system.&lt;/p&gt;\n\n&lt;p&gt;Play with Docker is a virtual machine which allows you to run Docker commands for a limited duration (4 hours). The instance is deleted after that. I can&amp;#39;t believe this is actually free to use. I only came to know of Play with Docker a few days back and I wanted to share it for beginners like me, who may not know about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f7d475f2-7e6b-11e9-9d01-0e36b1616012", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ppgeu", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Neat7754", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17ppgeu/if_you_are_a_beginner_please_make_use_of_play/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17ppgeu/if_you_are_a_beginner_please_make_use_of_play/", "subreddit_subscribers": 288861, "created_utc": 1699344267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm currently in China with a 24h layover and of course shit hit the fan at work while being here behind The Great Firewall.\n\nCouldn't access anything, Proton and Mullvad not connecting, no way to google workarounds either. Nothing worked. Made me realize how utterly paralyzed I am without basic internet access..\n\nLuckily, my home server is set up as an exit node on Tailscale and I can access everything through my home network now.\n\nJust a heads up, if you ever find yourself in this part of the world, Tailscale (or the likes) can be your saviour.", "author_fullname": "t2_5bzhj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tailscale saved my ass", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "vpn", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pu95x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "VPN", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699363614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in China with a 24h layover and of course shit hit the fan at work while being here behind The Great Firewall.&lt;/p&gt;\n\n&lt;p&gt;Couldn&amp;#39;t access anything, Proton and Mullvad not connecting, no way to google workarounds either. Nothing worked. Made me realize how utterly paralyzed I am without basic internet access..&lt;/p&gt;\n\n&lt;p&gt;Luckily, my home server is set up as an exit node on Tailscale and I can access everything through my home network now.&lt;/p&gt;\n\n&lt;p&gt;Just a heads up, if you ever find yourself in this part of the world, Tailscale (or the likes) can be your saviour.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7e5c2d58-7e68-11e9-9418-0e844b9a0afc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pu95x", "is_robot_indexable": true, "report_reasons": null, "author": "sbbh1", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pu95x/tailscale_saved_my_ass/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pu95x/tailscale_saved_my_ass/", "subreddit_subscribers": 288861, "created_utc": 1699363614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am looking for something that will auto \"map channels\" under Settings&gt;LiveTV&gt;TV guide data providers in Jellyfin, preferably a docker container.\n\nI am currently using Cabernet with docker compose and I enjoy it, but it still had its wrinkles to iron out to get it working.\n\nCabernet *did* auto map Xumo and Daddylive, ~~but I can not get it to fill the info in for PlutoTV.~~  Just got this working by using the correct .xml i got from [https://i.mjh.nz](https://i.mjh.nz/PlutoTV/us.m3u8) from another reddit post - guess i dont need this post much anymore besides to fill curiosity - maybe itll help someone others\n\nAre there other alternatives besides FHDHR and Threadfin? I tried those and they did not work for me.Threadfin - seems to double the necessary workflow  requiring you to enable each channel in the GUI manually, currently bulk edit doesnt work. Either way you would still need to map each channel manually after exposing them to JF.  Had issues with container running as root in docker image despite compose config.\n\nFHDHR - had several major issues with the docker setup and I could not get it working properly.Also had issues with container running as root in docker image despite compose config as well.\n\nspecs:  \nubuntu 22.04  \ndocker compose  \n32gb ddr4/ ryzen5  \nigpu only\n\nsources:[https://github.com/jellyfin/jellyfin](https://github.com/jellyfin/jellyfin)  \n[https://github.com/cabernetwork/cabernet](https://github.com/cabernetwork/cabernet)  \n[https://github.com/Threadfin/Threadfin](https://github.com/Threadfin/Threadfin)  \n[https://github.com/fHDHR/fHDHR](https://github.com/fHDHR/fHDHR)", "author_fullname": "t2_lotg7oi5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is everyone doing LiveTV self hosted in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pq1ku", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699347375.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699347111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for something that will auto &amp;quot;map channels&amp;quot; under Settings&amp;gt;LiveTV&amp;gt;TV guide data providers in Jellyfin, preferably a docker container.&lt;/p&gt;\n\n&lt;p&gt;I am currently using Cabernet with docker compose and I enjoy it, but it still had its wrinkles to iron out to get it working.&lt;/p&gt;\n\n&lt;p&gt;Cabernet &lt;em&gt;did&lt;/em&gt; auto map Xumo and Daddylive, &lt;del&gt;but I can not get it to fill the info in for PlutoTV.&lt;/del&gt;  Just got this working by using the correct .xml i got from &lt;a href=\"https://i.mjh.nz/PlutoTV/us.m3u8\"&gt;https://i.mjh.nz&lt;/a&gt; from another reddit post - guess i dont need this post much anymore besides to fill curiosity - maybe itll help someone others&lt;/p&gt;\n\n&lt;p&gt;Are there other alternatives besides FHDHR and Threadfin? I tried those and they did not work for me.Threadfin - seems to double the necessary workflow  requiring you to enable each channel in the GUI manually, currently bulk edit doesnt work. Either way you would still need to map each channel manually after exposing them to JF.  Had issues with container running as root in docker image despite compose config.&lt;/p&gt;\n\n&lt;p&gt;FHDHR - had several major issues with the docker setup and I could not get it working properly.Also had issues with container running as root in docker image despite compose config as well.&lt;/p&gt;\n\n&lt;p&gt;specs:&lt;br/&gt;\nubuntu 22.04&lt;br/&gt;\ndocker compose&lt;br/&gt;\n32gb ddr4/ ryzen5&lt;br/&gt;\nigpu only&lt;/p&gt;\n\n&lt;p&gt;sources:&lt;a href=\"https://github.com/jellyfin/jellyfin\"&gt;https://github.com/jellyfin/jellyfin&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/cabernetwork/cabernet\"&gt;https://github.com/cabernetwork/cabernet&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/Threadfin/Threadfin\"&gt;https://github.com/Threadfin/Threadfin&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/fHDHR/fHDHR\"&gt;https://github.com/fHDHR/fHDHR&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pq1ku", "is_robot_indexable": true, "report_reasons": null, "author": "yepitsatyhrowaway2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pq1ku/how_is_everyone_doing_livetv_self_hosted_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pq1ku/how_is_everyone_doing_livetv_self_hosted_in_2023/", "subreddit_subscribers": 288861, "created_utc": 1699347111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "With Mint being [killed January 2024](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.theverge.com%2F2023%2F11%2F2%2F23943254%2Fmint-intuit-shutting-down-credit-karma%3Ffbclid%3DIwAR2zOY6b8Za2UtUAdJCIzhIhcMWt2C4wEmfizOiMJFIHdAzLjvGs6uTUO7E&amp;h=AT1uJMsKMia3RswoE94UYPFHWkPQjDFaQHsFbj7vdRSout7Od79mqQGE1yZSTuMq1wRqKTpQAS2IOnI0m3zdvwnkAfwFY9UvfsQwd9D-cE3trWlZWKTh1qRVBtYnEaLLvWE), I've been researching options for a replacement. While there are a couple of out SAS options out there... I figured I might as well make this an opportunity to claw my data back and self host whatever solution I use.  From what I've found in here, these are the most common suggestions. Feel free to drop your own in the comments!\n\n[Firefly](https://www.firefly-iii.org/)\n\n[ActualBudget](https://actualbudget.org/)\n\n[GnuCash](https://www.gnucash.org/)\n\nWhat are folks opinions here on the best self-hosted replacement for Mint considering:\n\n* Functionality of integration with banks/investments/credit cards/etc.\n* Data visualization and analysis\n* Budget tracking, planning, and forecasting\n\n[View Poll](https://www.reddit.com/poll/17pfevp)", "author_fullname": "t2_iehcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted Finance Manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "finances", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pfevp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Finance Management", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699310569.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With Mint being &lt;a href=\"https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.theverge.com%2F2023%2F11%2F2%2F23943254%2Fmint-intuit-shutting-down-credit-karma%3Ffbclid%3DIwAR2zOY6b8Za2UtUAdJCIzhIhcMWt2C4wEmfizOiMJFIHdAzLjvGs6uTUO7E&amp;amp;h=AT1uJMsKMia3RswoE94UYPFHWkPQjDFaQHsFbj7vdRSout7Od79mqQGE1yZSTuMq1wRqKTpQAS2IOnI0m3zdvwnkAfwFY9UvfsQwd9D-cE3trWlZWKTh1qRVBtYnEaLLvWE\"&gt;killed January 2024&lt;/a&gt;, I&amp;#39;ve been researching options for a replacement. While there are a couple of out SAS options out there... I figured I might as well make this an opportunity to claw my data back and self host whatever solution I use.  From what I&amp;#39;ve found in here, these are the most common suggestions. Feel free to drop your own in the comments!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.firefly-iii.org/\"&gt;Firefly&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://actualbudget.org/\"&gt;ActualBudget&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.gnucash.org/\"&gt;GnuCash&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What are folks opinions here on the best self-hosted replacement for Mint considering:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Functionality of integration with banks/investments/credit cards/etc.&lt;/li&gt;\n&lt;li&gt;Data visualization and analysis&lt;/li&gt;\n&lt;li&gt;Budget tracking, planning, and forecasting&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17pfevp\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "32410c4a-7e68-11e9-ac95-0e1f2292890c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "17pfevp", "is_robot_indexable": true, "report_reasons": null, "author": "what-shoe", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1699569769081, "options": [{"text": "Firefly", "id": "25593613"}, {"text": "ActualBudget", "id": "25593614"}, {"text": "GnuCash", "id": "25593615"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 98, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pfevp/selfhosted_finance_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/selfhosted/comments/17pfevp/selfhosted_finance_manager/", "subreddit_subscribers": 288861, "created_utc": 1699310569.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Subject is the best I could come up with. \n\nLooking to run a docker that responds (maybe I don\u2019t need a docker) that my iPhone app will consistently ping. Perhaps once per 5 minutes and confirm if my internet is down at my home. \n\nSince if my home loses internet it can\u2019t let me know, I want my iPhone to ping my home and see if it drops. \n\nTo confirm if my iPhone has consistent internet it would also ping perhaps Google and see if \n\nA) all good is good\n\nB if Google but no home= failure\n\nC) if no Google and no home= iPhone connectivity issue. \n\nThoughts?", "author_fullname": "t2_5gf4u6ou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker to check and notify of loss of ping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p7u41", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699291288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Subject is the best I could come up with. &lt;/p&gt;\n\n&lt;p&gt;Looking to run a docker that responds (maybe I don\u2019t need a docker) that my iPhone app will consistently ping. Perhaps once per 5 minutes and confirm if my internet is down at my home. &lt;/p&gt;\n\n&lt;p&gt;Since if my home loses internet it can\u2019t let me know, I want my iPhone to ping my home and see if it drops. &lt;/p&gt;\n\n&lt;p&gt;To confirm if my iPhone has consistent internet it would also ping perhaps Google and see if &lt;/p&gt;\n\n&lt;p&gt;A) all good is good&lt;/p&gt;\n\n&lt;p&gt;B if Google but no home= failure&lt;/p&gt;\n\n&lt;p&gt;C) if no Google and no home= iPhone connectivity issue. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17p7u41", "is_robot_indexable": true, "report_reasons": null, "author": "bm_preston", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17p7u41/docker_to_check_and_notify_of_loss_of_ping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17p7u41/docker_to_check_and_notify_of_loss_of_ping/", "subreddit_subscribers": 288861, "created_utc": 1699291288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi everyone,\n\nCan you give me recommendations for self-hosted database monitoring / database performance monitoring tools, other than Grafana and Prometheus?\n\nThanks", "author_fullname": "t2_cr26419w0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Give me recommendations database monitoring tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ppxme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699346576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Can you give me recommendations for self-hosted database monitoring / database performance monitoring tools, other than Grafana and Prometheus?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ppxme", "is_robot_indexable": true, "report_reasons": null, "author": "Nope-all", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17ppxme/give_me_recommendations_database_monitoring_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17ppxme/give_me_recommendations_database_monitoring_tools/", "subreddit_subscribers": 288861, "created_utc": 1699346576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Anyone have any suggestions for a SMTP service provider with a free tier, that can be used for allowing apps/devices to send notification emails?\n\nOne that doesn't require a custom domain and doesn't make you jump through hoops with valid credit cards or valid phone numbers? (I use prepaid gift cards and VoIP phone service, a lot of services are starting to detect/deny those these days).\n\nEdit: Having to enter/confirm approved recipients if fine (reduces service misuse and RBL, which is good)", "author_fullname": "t2_93qsaj0ow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Suggestions: Free SMTP Service Providers for Notifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17pvw53", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699374231.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699368422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have any suggestions for a SMTP service provider with a free tier, that can be used for allowing apps/devices to send notification emails?&lt;/p&gt;\n\n&lt;p&gt;One that doesn&amp;#39;t require a custom domain and doesn&amp;#39;t make you jump through hoops with valid credit cards or valid phone numbers? (I use prepaid gift cards and VoIP phone service, a lot of services are starting to detect/deny those these days).&lt;/p&gt;\n\n&lt;p&gt;Edit: Having to enter/confirm approved recipients if fine (reduces service misuse and RBL, which is good)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pvw53", "is_robot_indexable": true, "report_reasons": null, "author": "Kalrasto73", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pvw53/seeking_suggestions_free_smtp_service_providers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pvw53/seeking_suggestions_free_smtp_service_providers/", "subreddit_subscribers": 288861, "created_utc": 1699368422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm considering using Paperless-ngx, however the initial onboarding seems quite a project and I have some usability concerns, especially for those with ADHD.   \nSo I'm wondering if it's the right tool for us and worth the investment.\n\nTwo questions: \n\n* Is it possible to make exports from documents for specific family members, e.g. if when we have family members who move out.\n* Can we use phone camera's to make pictures of paper documents (wherever we are), and (automatically) crop the pictures and import them into Paperless-ngx?   \nIdeally in one integrated flow, e.g. with a \"Paperless Iphone app\".  \nInstead of the somewhat cumbersome process of waiting for the all-in-one scanner and PC to startup, start the scanning program, initiate a scan, crop the scan, save it, and then manually importing it into Paperless-ngx and deleting the scanned files afterwards.", "author_fullname": "t2_1bc2anuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paperless-ngx direct import from Iphone camera?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pt3c2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699359800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering using Paperless-ngx, however the initial onboarding seems quite a project and I have some usability concerns, especially for those with ADHD.&lt;br/&gt;\nSo I&amp;#39;m wondering if it&amp;#39;s the right tool for us and worth the investment.&lt;/p&gt;\n\n&lt;p&gt;Two questions: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is it possible to make exports from documents for specific family members, e.g. if when we have family members who move out.&lt;/li&gt;\n&lt;li&gt;Can we use phone camera&amp;#39;s to make pictures of paper documents (wherever we are), and (automatically) crop the pictures and import them into Paperless-ngx?&lt;br/&gt;\nIdeally in one integrated flow, e.g. with a &amp;quot;Paperless Iphone app&amp;quot;.&lt;br/&gt;\nInstead of the somewhat cumbersome process of waiting for the all-in-one scanner and PC to startup, start the scanning program, initiate a scan, crop the scan, save it, and then manually importing it into Paperless-ngx and deleting the scanned files afterwards.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pt3c2", "is_robot_indexable": true, "report_reasons": null, "author": "Gijs007", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pt3c2/paperlessngx_direct_import_from_iphone_camera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pt3c2/paperlessngx_direct_import_from_iphone_camera/", "subreddit_subscribers": 288861, "created_utc": 1699359800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Looking for an open source light bulb camera i can get.  I looked at some from Amazon amd they are like 10 to 30 bucks and really most are similar.   Any that require giving up my privacy and I have total control over?", "author_fullname": "t2_ifdehql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Light bulb camera", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pnjfo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699335895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for an open source light bulb camera i can get.  I looked at some from Amazon amd they are like 10 to 30 bucks and really most are similar.   Any that require giving up my privacy and I have total control over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pnjfo", "is_robot_indexable": true, "report_reasons": null, "author": "illathon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pnjfo/light_bulb_camera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pnjfo/light_bulb_camera/", "subreddit_subscribers": 288861, "created_utc": 1699335895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Heya,\n\nI'm in the process of making various services I host at home (mostly Plex-related, like Overseerr) available through a VPS.\n\nBasically what I want to do is run a Wireguard VPN to my VPS, and run a reverse proxy there to point specific subdomains to my home server.\n\nI currently only have the Plex port opened so my parents and friends can access it, but I would like Overseerr available as well. \n\nOn my VPS I run Docker, with the nginx-proxy image by jwilder, and the acme companion. I also run a few other things there, and it works great.\n\nI tried setting up a Wireguard VPN, and that works, but then my Plex isn't reachable through the internet anymore. My VPS is hosted at Hetzner, and I would like to avoid Plex traffic going through there, just the Overseerr service. \n\nDoes anyone know the best way to tackle this?\n\nThanks!", "author_fullname": "t2_keehnpei", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nginx reverse proxy, vps and vpn to home", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pgzxk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699314870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the process of making various services I host at home (mostly Plex-related, like Overseerr) available through a VPS.&lt;/p&gt;\n\n&lt;p&gt;Basically what I want to do is run a Wireguard VPN to my VPS, and run a reverse proxy there to point specific subdomains to my home server.&lt;/p&gt;\n\n&lt;p&gt;I currently only have the Plex port opened so my parents and friends can access it, but I would like Overseerr available as well. &lt;/p&gt;\n\n&lt;p&gt;On my VPS I run Docker, with the nginx-proxy image by jwilder, and the acme companion. I also run a few other things there, and it works great.&lt;/p&gt;\n\n&lt;p&gt;I tried setting up a Wireguard VPN, and that works, but then my Plex isn&amp;#39;t reachable through the internet anymore. My VPS is hosted at Hetzner, and I would like to avoid Plex traffic going through there, just the Overseerr service. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know the best way to tackle this?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pgzxk", "is_robot_indexable": true, "report_reasons": null, "author": "NoctisBE", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pgzxk/nginx_reverse_proxy_vps_and_vpn_to_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pgzxk/nginx_reverse_proxy_vps_and_vpn_to_home/", "subreddit_subscribers": 288861, "created_utc": 1699314870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I am self hosting my storage with good redundancy but the fear of having nothing offsite has really been creeping in due to recent earthquakes in my area.\n\nI am contemplating cloud storage for deep archiving just in case of a disaster. All of these backups will be rendered useless if something major was to strike.\n\nI am looking for some sort of community driven solution - i.e. a barter service where I'll be happy to host a cloud server for someone in exchange of them running one for me. All the data and access will be exclusive to each other and any help needed to maintain can be looked after.\n\nI am not sure what's the right place for such an arrangement or should I just instead invest in a corporate solution? I have a 1gbps internet plan so data transfer shouldn't be slow. I will be happy to invest in whatever infrastructure brings peace to someone's mind.\n\nWould love some suggestions!", "author_fullname": "t2_a3u77", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need offsite community storage for deep archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "cloudstorage", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p6zju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud Storage", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699289119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am self hosting my storage with good redundancy but the fear of having nothing offsite has really been creeping in due to recent earthquakes in my area.&lt;/p&gt;\n\n&lt;p&gt;I am contemplating cloud storage for deep archiving just in case of a disaster. All of these backups will be rendered useless if something major was to strike.&lt;/p&gt;\n\n&lt;p&gt;I am looking for some sort of community driven solution - i.e. a barter service where I&amp;#39;ll be happy to host a cloud server for someone in exchange of them running one for me. All the data and access will be exclusive to each other and any help needed to maintain can be looked after.&lt;/p&gt;\n\n&lt;p&gt;I am not sure what&amp;#39;s the right place for such an arrangement or should I just instead invest in a corporate solution? I have a 1gbps internet plan so data transfer shouldn&amp;#39;t be slow. I will be happy to invest in whatever infrastructure brings peace to someone&amp;#39;s mind.&lt;/p&gt;\n\n&lt;p&gt;Would love some suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bc5f6346-7e67-11e9-a0fe-0e631119683e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17p6zju", "is_robot_indexable": true, "report_reasons": null, "author": "limeice", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17p6zju/need_offsite_community_storage_for_deep_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17p6zju/need_offsite_community_storage_for_deep_archiving/", "subreddit_subscribers": 288861, "created_utc": 1699289119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I'm not planning to allow public access to my server. There will be another server at my Dad's house which will connect via Tailscale and sync data, and I don't have any concerns about that as I'll manage both servers and can tightly control what is running on them. Anything that provides external access will be running under Docker Compose/Portainer.\n\nMy concern is with unmanaged devices, like my family's PCs and Android phones, where I have no control over what is installed on them. I want these devices to be able to access the server via Tailscale so they can store photos, notes, etc. but I'm worried that some malware on them could take advantage of the Tailscale connection to access/delete files on the server. \n\nHow do you make sure that can't happen?", "author_fullname": "t2_4g7q3nm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing security risks from unmanaged device access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pqf0q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699348912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not planning to allow public access to my server. There will be another server at my Dad&amp;#39;s house which will connect via Tailscale and sync data, and I don&amp;#39;t have any concerns about that as I&amp;#39;ll manage both servers and can tightly control what is running on them. Anything that provides external access will be running under Docker Compose/Portainer.&lt;/p&gt;\n\n&lt;p&gt;My concern is with unmanaged devices, like my family&amp;#39;s PCs and Android phones, where I have no control over what is installed on them. I want these devices to be able to access the server via Tailscale so they can store photos, notes, etc. but I&amp;#39;m worried that some malware on them could take advantage of the Tailscale connection to access/delete files on the server. &lt;/p&gt;\n\n&lt;p&gt;How do you make sure that can&amp;#39;t happen?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pqf0q", "is_robot_indexable": true, "report_reasons": null, "author": "Big-Finding2976", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pqf0q/managing_security_risks_from_unmanaged_device/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pqf0q/managing_security_risks_from_unmanaged_device/", "subreddit_subscribers": 288861, "created_utc": 1699348912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/lbffn7gqlvyb1.png?width=391&amp;format=png&amp;auto=webp&amp;s=81abef732cc52b21b4de90b6e686c266dc7dae20\n\nVirtualbox AMD64 Testing office vdi on Virtualbox x64 on Window 11\n\n    Error installing app: ('Apt command failed with return code: 100', b'', b'\\x1b[97m INFO\\x1b[0m \\x1b[94mplinth.app \\x1b[0m Initialized apps - apache, api, names, avahi, storage, backups, cockpit, firewall, config, datetime, diagnostics, dynamicdns, first_boot, help, letsencrypt, networks, power, privacy, security, snapshot, ssh, sso, upgrades, users, bepasty, bind, calibre, coturn, deluge, ejabberd, email, gitweb, i2p, ikiwiki, infinoted, janus, jsxc, matrixsynapse, mediawiki, minetest, minidlna, mumble, openvpn, pagekite, performance, privoxy, quassel, radicale, roundcube, rssbridge, samba, searx, shaarli, shadowsocks, shadowsocksserver, sharing, syncthing, tor, transmission, ttrss, wireguard, wordpress, zoph\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-android/fonts-droid-fallback_6.0.1r16-1.1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fftw3/libfftw3-double3_3.3.10-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libf/libfontenc/libfontenc1_1.1.4-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xorg/x11-common_7.7%2b23_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xfonts-encodings/xfonts-encodings_1.0.4-2.2_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xfonts-utils/xfonts-utils_7.7%2b6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-urw-base35/fonts-urw-base35_20200910-7_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/fontconfig-config_2.14.1-4_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/libfontconfig1_2.14.1-4_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/a/aom/libaom3_3.6.0-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/dav1d/libdav1d6_1.2.1-2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libd/libde265/libde265-0_1.0.12-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/numactl/libnuma1_2.0.16-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/x265/libx265-199_3.5-2%2bb1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libh/libheif/libheif1_1.15.1-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libl/liblqr/liblqr-1-0_0.4.2-2.1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick-6-common_6.9.11.60%2bdfsg-1.6_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickcore-6.q16-6_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickwand-6.q16-6_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-apcu/php8.2-apcu_5.1.22%2b4.0.11-2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-apcu/php-apcu_5.1.22%2b4.0.11-2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-yaml/php8.2-yaml_2.2.2%2b2.1.0%2b2.0.4%2b1.3.2-6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-yaml/php-yaml_2.2.2%2b2.1.0%2b2.0.4%2b1.3.2-6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/poppler-data/poppler-data_0.4.12-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/fontconfig_2.14.1-4_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-noto/fonts-noto-mono_20201225-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs-common_10.01.2%7edfsg-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs10-common_10.01.2%7edfsg-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/ijs/libijs-0.35_0.35-15.1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jbig2dec/libjbig2dec0_0.19-3_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libp/libpaper/libpaper1_1.1.29_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libi/libice/libice6_1.0.10-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libs/libsm/libsm6_1.2.3-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxt/libxt6_1.2.1-1.1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs10_10.01.2%7edfsg-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/ghostscript_10.01.2%7edfsg-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-urw-base35/gsfonts_20200910-7_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/h/hicolor-icon-theme/hicolor-icon-theme_0.17-2_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick-6.q16_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pixman/libpixman-1-0_0.42.2-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxcb/libxcb-render0_1.15-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxcb/libxcb-shm0_1.15-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxrender/libxrender1_0.9.10-1.1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/c/cairo/libcairo2_1.16.0-7_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libd/libdatrie/libdatrie1_0.2.13-2%2bb1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/djvulibre/libdjvulibre-text_3.5.28-2_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/djvulibre/libdjvulibre21_3.5.28-2%2bb1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imath/libimath-3-1-29_3.1.6-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jxrlib/libjxr0_1.2%7egit20170615.f752187-5_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jxrlib/libjxr-tools_1.2%7egit20170615.f752187-5_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/l/lua5.1/liblua5.1-0_5.1.5-9_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/o/openexr/libopenexr-3-1-30_3.1.5-5_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libt/libthai/libthai-data_0.1.29-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libt/libthai/libthai0_0.1.29-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpango-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpangoft2-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpangocairo-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libw/libwmf/libwmflite-0.2-7_0.2.12-5.2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickcore-6.q16-6-extra_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/netpbm-free/libnetpbm11_11.01.00-2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libo/libonig/libonig5_6.9.8-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libp/libpaper/libpaper-utils_1.1.29_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxslt/libxslt1.1_1.1.35-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2_8.2.7-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-intl_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-intl_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-sqlite3_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-sqlite3_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-mbstring_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-mbstring_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-xml_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-xml_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/m/mediawiki/mediawiki-classes_1.39.2-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/m/mediawiki/mediawiki_1.39.2-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/netpbm-free/netpbm_11.01.00-2_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-curl_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-curl_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-gmp_8.2.7-1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-gmp_8.2%2b93_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-luasandbox/php-luasandbox_4.1.0-1%2bb1_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/w/wikidiff2/php-wikidiff2_1.13.0-1%2bb3_amd64.deb Could not resolve \\'deb.debian.org\\'\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pygments/python3-pygments_2.15.1%2bdfsg-1_all.deb Could not resolve \\'deb.debian.org\\'\\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\\n\\x1b[31m ERROR\\x1b[0m \\x1b[94m__main__ \\x1b[0m Error executing action: Apt command failed with return code: 100\\nTraceback (most recent call last):\\n File \"/usr/share/plinth/actions/actions\", line 92, in _call\\n return_values = func(*arguments[\\'args\\'], **arguments[\\'kwargs\\'])\\n ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n File \"/usr/lib/python3/dist-packages/plinth/privileged/packages.py\", line 69, in install\\n raise RuntimeError(\\nRuntimeError: Apt command failed with return code: 100\\n')", "author_fullname": "t2_4jurunac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FreedomBox error installing apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "mediaserving", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lbffn7gqlvyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 210, "x": 108, "u": "https://preview.redd.it/lbffn7gqlvyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=67c5fb15955de756c070a9014bb318be8d970b1d"}, {"y": 420, "x": 216, "u": "https://preview.redd.it/lbffn7gqlvyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e3cae598a0a1aa8ee07851c68b670c9825fb5e6f"}, {"y": 622, "x": 320, "u": "https://preview.redd.it/lbffn7gqlvyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d399ffe7b0126044d468eb1a9dfe06d2e367eee"}], "s": {"y": 761, "x": 391, "u": "https://preview.redd.it/lbffn7gqlvyb1.png?width=391&amp;format=png&amp;auto=webp&amp;s=81abef732cc52b21b4de90b6e686c266dc7dae20"}, "id": "lbffn7gqlvyb1"}}, "name": "t3_17poqcf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Media Serving", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/1NcAezd6IYmCP7ZQ6RDpwOhYHPR9zw7w8wuAmldQJY4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699341000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lbffn7gqlvyb1.png?width=391&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81abef732cc52b21b4de90b6e686c266dc7dae20\"&gt;https://preview.redd.it/lbffn7gqlvyb1.png?width=391&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81abef732cc52b21b4de90b6e686c266dc7dae20&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Virtualbox AMD64 Testing office vdi on Virtualbox x64 on Window 11&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Error installing app: (&amp;#39;Apt command failed with return code: 100&amp;#39;, b&amp;#39;&amp;#39;, b&amp;#39;\\x1b[97m INFO\\x1b[0m \\x1b[94mplinth.app \\x1b[0m Initialized apps - apache, api, names, avahi, storage, backups, cockpit, firewall, config, datetime, diagnostics, dynamicdns, first_boot, help, letsencrypt, networks, power, privacy, security, snapshot, ssh, sso, upgrades, users, bepasty, bind, calibre, coturn, deluge, ejabberd, email, gitweb, i2p, ikiwiki, infinoted, janus, jsxc, matrixsynapse, mediawiki, minetest, minidlna, mumble, openvpn, pagekite, performance, privoxy, quassel, radicale, roundcube, rssbridge, samba, searx, shaarli, shadowsocks, shadowsocksserver, sharing, syncthing, tor, transmission, ttrss, wireguard, wordpress, zoph\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-android/fonts-droid-fallback_6.0.1r16-1.1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fftw3/libfftw3-double3_3.3.10-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libf/libfontenc/libfontenc1_1.1.4-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xorg/x11-common_7.7%2b23_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xfonts-encodings/xfonts-encodings_1.0.4-2.2_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/xfonts-utils/xfonts-utils_7.7%2b6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-urw-base35/fonts-urw-base35_20200910-7_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/fontconfig-config_2.14.1-4_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/libfontconfig1_2.14.1-4_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/a/aom/libaom3_3.6.0-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/dav1d/libdav1d6_1.2.1-2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libd/libde265/libde265-0_1.0.12-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/numactl/libnuma1_2.0.16-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/x/x265/libx265-199_3.5-2%2bb1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libh/libheif/libheif1_1.15.1-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libl/liblqr/liblqr-1-0_0.4.2-2.1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick-6-common_6.9.11.60%2bdfsg-1.6_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickcore-6.q16-6_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickwand-6.q16-6_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-apcu/php8.2-apcu_5.1.22%2b4.0.11-2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-apcu/php-apcu_5.1.22%2b4.0.11-2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-yaml/php8.2-yaml_2.2.2%2b2.1.0%2b2.0.4%2b1.3.2-6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-yaml/php-yaml_2.2.2%2b2.1.0%2b2.0.4%2b1.3.2-6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/poppler-data/poppler-data_0.4.12-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fontconfig/fontconfig_2.14.1-4_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-noto/fonts-noto-mono_20201225-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs-common_10.01.2%7edfsg-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs10-common_10.01.2%7edfsg-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/ijs/libijs-0.35_0.35-15.1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jbig2dec/libjbig2dec0_0.19-3_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libp/libpaper/libpaper1_1.1.29_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libi/libice/libice6_1.0.10-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libs/libsm/libsm6_1.2.3-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxt/libxt6_1.2.1-1.1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/libgs10_10.01.2%7edfsg-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/g/ghostscript/ghostscript_10.01.2%7edfsg-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/f/fonts-urw-base35/gsfonts_20200910-7_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/h/hicolor-icon-theme/hicolor-icon-theme_0.17-2_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick-6.q16_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/imagemagick_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pixman/libpixman-1-0_0.42.2-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxcb/libxcb-render0_1.15-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxcb/libxcb-shm0_1.15-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxrender/libxrender1_0.9.10-1.1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/c/cairo/libcairo2_1.16.0-7_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libd/libdatrie/libdatrie1_0.2.13-2%2bb1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/djvulibre/libdjvulibre-text_3.5.28-2_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/d/djvulibre/libdjvulibre21_3.5.28-2%2bb1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imath/libimath-3-1-29_3.1.6-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jxrlib/libjxr0_1.2%7egit20170615.f752187-5_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/j/jxrlib/libjxr-tools_1.2%7egit20170615.f752187-5_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/l/lua5.1/liblua5.1-0_5.1.5-9_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/o/openexr/libopenexr-3-1-30_3.1.5-5_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libt/libthai/libthai-data_0.1.29-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libt/libthai/libthai0_0.1.29-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpango-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpangoft2-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pango1.0/libpangocairo-1.0-0_1.50.14%2bds-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libw/libwmf/libwmflite-0.2-7_0.2.12-5.2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/i/imagemagick/libmagickcore-6.q16-6-extra_6.9.11.60%2bdfsg-1.6_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/netpbm-free/libnetpbm11_11.01.00-2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libo/libonig/libonig5_6.9.8-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libp/libpaper/libpaper-utils_1.1.29_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/libx/libxslt/libxslt1.1_1.1.35-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2_8.2.7-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-intl_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-intl_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-sqlite3_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-sqlite3_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-mbstring_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-mbstring_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-xml_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-xml_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/m/mediawiki/mediawiki-classes_1.39.2-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/m/mediawiki/mediawiki_1.39.2-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/n/netpbm-free/netpbm_11.01.00-2_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-curl_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-curl_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php8.2/php8.2-gmp_8.2.7-1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-defaults/php-gmp_8.2%2b93_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/php-luasandbox/php-luasandbox_4.1.0-1%2bb1_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/w/wikidiff2/php-wikidiff2_1.13.0-1%2bb3_amd64.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Failed to fetch http://deb.debian.org/debian/pool/main/p/pygments/python3-pygments_2.15.1%2bdfsg-1_all.deb Could not resolve \\&amp;#39;deb.debian.org\\&amp;#39;\\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\\n\\x1b[31m ERROR\\x1b[0m \\x1b[94m__main__ \\x1b[0m Error executing action: Apt command failed with return code: 100\\nTraceback (most recent call last):\\n File &amp;quot;/usr/share/plinth/actions/actions&amp;quot;, line 92, in _call\\n return_values = func(*arguments[\\&amp;#39;args\\&amp;#39;], **arguments[\\&amp;#39;kwargs\\&amp;#39;])\\n ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n File &amp;quot;/usr/lib/python3/dist-packages/plinth/privileged/packages.py&amp;quot;, line 69, in install\\n raise RuntimeError(\\nRuntimeError: Apt command failed with return code: 100\\n&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb71ccc0-7e67-11e9-841a-0e67038620c2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17poqcf", "is_robot_indexable": true, "report_reasons": null, "author": "RedditNoobie777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17poqcf/freedombox_error_installing_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17poqcf/freedombox_error_installing_apps/", "subreddit_subscribers": 288861, "created_utc": 1699341000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hey all, is it possible to rename the \"My Files\" folder to something like \"My\\_Files\"? I cannot have a space in the folder name.", "author_fullname": "t2_c05k7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Filecloud \"My Files\" folder question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "cloudstorage", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17phr5k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud Storage", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699317021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, is it possible to rename the &amp;quot;My Files&amp;quot; folder to something like &amp;quot;My_Files&amp;quot;? I cannot have a space in the folder name.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bc5f6346-7e67-11e9-a0fe-0e631119683e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17phr5k", "is_robot_indexable": true, "report_reasons": null, "author": "BstoneArch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17phr5k/filecloud_my_files_folder_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17phr5k/filecloud_my_files_folder_question/", "subreddit_subscribers": 288861, "created_utc": 1699317021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have two docker containers of which I'll show their docker-compose files below. I'm trying to setup an nginx reverse proxy to the seafile container. However, when accessing the domain name I'm not getting through to the seafile webadmin page.\n\n&amp;#x200B;\n\nBased on the default [mydomain.com](https://mydomain.com) I know that the certificates are operational.\n\nI got the ip address in \"$ docker inspect seafile-arm-docker-seafile-1\" and took the ip address corresponding to the \"IPAddress\" that I found in there ([192.168.16.3](https://192.168.16.3)). Unfortunately, the session keeps loading and finally times out.\n\n&amp;#x200B;\n\nI'm using, for seafile:\n\n[https://github.com/ChatDeBlofeld/seafile-arm-docker-base](https://github.com/ChatDeBlofeld/seafile-arm-docker-base)\n\ndocker-compose.yml\n\n`version: '3'`\n\n`services:`\n\n`db:`\n\n`image: linuxserver/mariadb`\n\n`environment:`\n\n`- PUID=$PUID`\n\n`- PGID=$PGID`\n\n`- TZ=$TZ`\n\n`volumes:`\n\n`- ${DATABASE_DIR}:/config`\n\n&amp;#x200B;\n\n`seafile:`\n\n`depends_on:`\n\n`- db`\n\n`image: ${SEAFILE_IMAGE}`\n\n`restart: always`\n\n`ports:`\n\n  `- 8000:8000/tcp`\n\n `- 8080:8080/tcp`\n\n `- 8082:8082/tcp`\n\n `- 8083:8083/tcp`\n\n`environment:`\n\n`- PUID=${PGID-}`\n\n`- PGID=${PUID-}`\n\n`- TZ=${TZ-}`\n\n`- SQLITE=${SQLITE-}`\n\n`- SERVER_IP=${HOST-}`\n\n`- PORT=${PORT-}`\n\n`- USE_HTTPS=${USE_HTTPS-}`\n\n`- SEAFILE_ADMIN_EMAIL=${SEAFILE_ADMIN_EMAIL-}`\n\n`- SEAFILE_ADMIN_PASSWORD=${SEAFILE_ADMIN_PASSWORD-}`\n\n`- MYSQL_HOST=${MYSQL_HOST:-db}`\n\n`- MYSQL_PORT=${MYSQL_PORT-}`\n\n`- USE_EXISTING_DB=${USE_EXISTING_DB-}`\n\n`- MYSQL_USER=${MYSQL_USER-}`\n\n`- MYSQL_USER_PASSWD=${MYSQL_USER_PASSWD-}`\n\n`- MYSQL_USER_HOST=${MYSQL_USER_HOST-}`\n\n`- MYSQL_ROOT_PASSWD=${MYSQL_ROOT_PASSWD-}`\n\n`- CCNET_DB=${CCNET_DB-}`\n\n`- SEAFILE_DB=${SEAFILE_DB-}`\n\n`- SEAHUB_DB=${SEAHUB_DB-}`\n\n&amp;#x200B;\n\n`volumes:`\n\n`- media:/shared/media`\n\n`- ${SEAFILE_CONF_DIR}:/shared/conf`\n\n`- ${SEAFILE_LOGS_DIR}:/shared/logs`\n\n`- ${SEAFILE_DATA_DIR}:/shared/seafile-data`\n\n`- ${SEAFILE_SEAHUB_DIR}:/shared/seahub-data`\n\n&amp;#x200B;\n\n`volumes:`\n\n`media:`\n\n`#~conf:`\n\n`#~logs:`\n\n`#~data:`\n\n`#~seahub:`\n\n`#~db:`\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nReverse proxy:\n\n`version: \"3.3\"`\n\n`services:`\n\n`nginx:`\n\n`container_name: 'nginx-service'`\n\n`build:`\n\n`context: .`\n\n`dockerfile: docker/nginx.Dockerfile`\n\n`ports:`\n\n`- 80:80`\n\n`- 443:443`\n\n`volumes:`\n\n`- ./config:/config`\n\n`- /etc/letsencrypt:/etc/letsencrypt:ro`\n\n`- /tmp/acme_challenge:/tmp/acme_challenge`\n\n`networks:`\n\n`- nginx_reverse_proxy`\n\n`restart: always`\n\n&amp;#x200B;\n\n`networks:`\n\n`nginx_reverse_proxy:`\n\n`driver: bridge`\n\n&amp;#x200B;\n\nconfig.conf:\n\n`####`\t[`storage.`](https://storage.haarman.info)`mydomain.com`\n\n`server {`\n\n`listen 80;`\n\n`listen [::]:80;`\n\n`server_name` [`storage.`](https://storage.haarman.info)`mydomain.com;`\n\n`location / {`\n\n`return 301 https://$host$request_uri;`\n\n`} location ~ /.well-known/acme-challenge {`\n\n`allow all;`\n\n`root /tmp/acme_challenge;`\n\n`}`\n\n`}`\n\n&amp;#x200B;\n\n`server {`\n\n`listen 443 ssl;`\n\n`listen [::]:443 ssl http2;`\n\n`server_name` [`storage.`](https://storage.haarman.info)`mydomain.com;`\n\n`ssl_certificate /etc/letsencrypt/live/storage.mydomain.com/fullchain.pem;`\n\n`ssl_certificate_key /etc/letsencrypt/live/storage.mydomain.com/privkey.pem;`\n\n`location / {`\n\n`proxy_pass http://`[`192.168.16.3`](https://192.168.16.3)`:8000;`\n\n`proxy_set_header Host $host;`\n\n`proxy_set_header X-Real-IP $remote_addr;`\n\n`proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`\n\n`proxy_set_header X-Forwarded-Host $server_name;`\n\n`proxy_set_header X-Forwarded-Proto https;`\n\n&amp;#x200B;\n\n`access_log /var/log/nginx/seahub.access.log;`\n\n`error_log /var/log/nginx/seahub.error.log;`\n\n&amp;#x200B;\n\n`proxy_read_timeout 1200s;`\n\n&amp;#x200B;\n\n`# used for view/edit office file via Office Online Server`\n\n`#` [`https://manual.seafile.com/deploy/deploy_with_nginx.html`](https://manual.seafile.com/deploy/deploy_with_nginx.html)\n\n`# Nginx settings client_max_body_size is by default 1M. Uploading a file bigger than this limit will give you an error`\n\n`# message HTTP error code 413 (\"Request Entity Too Large\").`\n\n`# You should use 0 to disable this feature or write the same value than for the parameter`\n\n`# max_upload_size in section [fileserver] of seafile.conf. Client uploads are only partly effected by this limit.`\n\n`# With a limit of 100 MiB they can safely upload files of any size.`\n\n`client_max_body_size 0;`\n\n`}`\n\n&amp;#x200B;\n\n`location /media {`\n\n`root /opt/seafile/seafile-server-latest/seahub;`\n\n`}`\n\n&amp;#x200B;\n\n`location /seafdav {`\n\n`#` [`https://manual.seafile.com/extension/webdav.html`](https://manual.seafile.com/extension/webdav.html)\n\n`proxy_pass http://`[`192.168.16.3`](https://192.168.16.3)`:8080;`\n\n`proxy_set_header Host $host;`\n\n`proxy_set_header X-Real-IP $remote_addr;`\n\n`proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`\n\n`proxy_set_header X-Forwarded-Host $server_name;`\n\n`proxy_set_header X-Forwarded-Proto https;`\n\n`proxy_http_version 1.1;`\n\n`proxy_connect_timeout 36000s;`\n\n`proxy_read_timeout 36000s;`\n\n`proxy_send_timeout 36000s;`\n\n`send_timeout 36000s;`\n\n`client_max_body_size 0;`\n\n&amp;#x200B;\n\n`# if you want to support file uploads larger than 4GB, we suggest to install Nginx version &gt;= 1.8.0 and`\n\n`# add the following option to Nginx config file (set to \"off\") -`  [`https://manual.seafile.com/deploy/deploy_with_nginx.html`](https://manual.seafile.com/deploy/deploy_with_nginx.html)\n\n`proxy_request_buffering off;`\n\n`access_log /var/log/nginx/seafdav.access.log;`\n\n`error_log /var/log/nginx/seafdav.error.log;`\n\n`}`\n\n`location /seafhttp {`\n\n`rewrite ^/seafhttp(.*)$ $1 break;`\n\n`proxy_pass http://seafile-arm-docker_default:8082;`\n\n`client_max_body_size 0;`\n\n`proxy_connect_timeout 36000s;`\n\n`proxy_read_timeout 36000s;`\n\n`proxy_send_timeout 36000s;`\n\n`send_timeout 36000s;`\n\n`# if you want to support file uploads larger than 4GB, we suggest to install Nginx version &gt;= 1.8.0 and`\n\n`# add the following option to Nginx config file (set to \"off\") -`  [`https://manual.seafile.com/deploy/deploy_with_nginx.html`](https://manual.seafile.com/deploy/deploy_with_nginx.html)\n\n`proxy_request_buffering off;`\n\n`}`\n\n&amp;#x200B;\n\n`location /seafmedia {`\n\n`rewrite ^/seafmedia(.*)$ /media$1 break;`\n\n`root /opt/seafile/seafile-server-latest/seahub;`\n\n`}`\n\n`}`\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n`#### default`\n\n`server {`\n\n`listen 80;`\n\n`listen [::]:80;`\n\n`server_name mydomain.com;`\n\n`location / {`\n\n`return 301 https://$host$request_uri;`\n\n`}`\n\n&amp;#x200B;\n\n`location ~ /.well-known/acme-challenge {`\n\n`allow all;`\n\n`root /tmp/acme_challenge;`\n\n`}`\n\n`}`\n\n`server {`\n\n`listen 443 ssl;`\n\n`listen [::]:443 ssl http2;`\n\n`server_name mydomain.com;`\n\n`ssl_certificate /etc/letsencrypt/live/mydomain.com/fullchain.pem;`\n\n`ssl_certificate_key /etc/letsencrypt/live/mydomain.com/privkey.pem;`\n\n`}`\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nBonus question:\n\nI see linuxserver/mariadb running as well after running docker ps. Is that port 3306 closed for access from outside the container? So it will not interfere with other sql containers that I might have running on that port?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6grm2c8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "nginx reverse proxy and seafile both on separate docker containers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pe0a9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699308651.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699307041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two docker containers of which I&amp;#39;ll show their docker-compose files below. I&amp;#39;m trying to setup an nginx reverse proxy to the seafile container. However, when accessing the domain name I&amp;#39;m not getting through to the seafile webadmin page.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Based on the default &lt;a href=\"https://mydomain.com\"&gt;mydomain.com&lt;/a&gt; I know that the certificates are operational.&lt;/p&gt;\n\n&lt;p&gt;I got the ip address in &amp;quot;$ docker inspect seafile-arm-docker-seafile-1&amp;quot; and took the ip address corresponding to the &amp;quot;IPAddress&amp;quot; that I found in there (&lt;a href=\"https://192.168.16.3\"&gt;192.168.16.3&lt;/a&gt;). Unfortunately, the session keeps loading and finally times out.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using, for seafile:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ChatDeBlofeld/seafile-arm-docker-base\"&gt;https://github.com/ChatDeBlofeld/seafile-arm-docker-base&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;docker-compose.yml&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;version: &amp;#39;3&amp;#39;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;services:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;db:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;image: linuxserver/mariadb&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;environment:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- PUID=$PUID&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- PGID=$PGID&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- TZ=$TZ&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;volumes:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ${DATABASE_DIR}:/config&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;seafile:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;depends_on:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- db&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;image: ${SEAFILE_IMAGE}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;restart: always&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ports:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 8000:8000/tcp&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 8080:8080/tcp&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 8082:8082/tcp&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 8083:8083/tcp&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;environment:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- PUID=${PGID-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- PGID=${PUID-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- TZ=${TZ-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SQLITE=${SQLITE-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SERVER_IP=${HOST-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- PORT=${PORT-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- USE_HTTPS=${USE_HTTPS-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SEAFILE_ADMIN_EMAIL=${SEAFILE_ADMIN_EMAIL-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SEAFILE_ADMIN_PASSWORD=${SEAFILE_ADMIN_PASSWORD-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_HOST=${MYSQL_HOST:-db}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_PORT=${MYSQL_PORT-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- USE_EXISTING_DB=${USE_EXISTING_DB-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_USER=${MYSQL_USER-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_USER_PASSWD=${MYSQL_USER_PASSWD-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_USER_HOST=${MYSQL_USER_HOST-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- MYSQL_ROOT_PASSWD=${MYSQL_ROOT_PASSWD-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- CCNET_DB=${CCNET_DB-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SEAFILE_DB=${SEAFILE_DB-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- SEAHUB_DB=${SEAHUB_DB-}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;volumes:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- media:/shared/media&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ${SEAFILE_CONF_DIR}:/shared/conf&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ${SEAFILE_LOGS_DIR}:/shared/logs&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ${SEAFILE_DATA_DIR}:/shared/seafile-data&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ${SEAFILE_SEAHUB_DIR}:/shared/seahub-data&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;volumes:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;media:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#~conf:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#~logs:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#~data:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#~seahub:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#~db:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Reverse proxy:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;version: &amp;quot;3.3&amp;quot;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;services:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;nginx:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;container_name: &amp;#39;nginx-service&amp;#39;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;build:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;context: .&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;dockerfile: docker/nginx.Dockerfile&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ports:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 80:80&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- 443:443&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;volumes:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- ./config:/config&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- /etc/letsencrypt:/etc/letsencrypt:ro&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- /tmp/acme_challenge:/tmp/acme_challenge&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;networks:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- nginx_reverse_proxy&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;restart: always&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;networks:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;nginx_reverse_proxy:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driver: bridge&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;config.conf:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;####&lt;/code&gt;  &lt;a href=\"https://storage.haarman.info\"&gt;&lt;code&gt;storage.&lt;/code&gt;&lt;/a&gt;&lt;code&gt;mydomain.com&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen 80;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen [::]:80;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server_name&lt;/code&gt; &lt;a href=\"https://storage.haarman.info\"&gt;&lt;code&gt;storage.&lt;/code&gt;&lt;/a&gt;&lt;code&gt;mydomain.com;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location / {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;return 301 https://$host$request_uri;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;} location ~ /.well-known/acme-challenge {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;allow all;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;root /tmp/acme_challenge;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen 443 ssl;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen [::]:443 ssl http2;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server_name&lt;/code&gt; &lt;a href=\"https://storage.haarman.info\"&gt;&lt;code&gt;storage.&lt;/code&gt;&lt;/a&gt;&lt;code&gt;mydomain.com;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ssl_certificate /etc/letsencrypt/live/storage.mydomain.com/fullchain.pem;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ssl_certificate_key /etc/letsencrypt/live/storage.mydomain.com/privkey.pem;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location / {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_pass http://&lt;/code&gt;&lt;a href=\"https://192.168.16.3\"&gt;&lt;code&gt;192.168.16.3&lt;/code&gt;&lt;/a&gt;&lt;code&gt;:8000;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header Host $host;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Real-IP $remote_addr;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-Host $server_name;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-Proto https;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;access_log /var/log/nginx/seahub.access.log;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;error_log /var/log/nginx/seahub.error.log;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_read_timeout 1200s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# used for view/edit office file via Office Online Server&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#&lt;/code&gt; &lt;a href=\"https://manual.seafile.com/deploy/deploy_with_nginx.html\"&gt;&lt;code&gt;https://manual.seafile.com/deploy/deploy_with_nginx.html&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# Nginx settings client_max_body_size is by default 1M. Uploading a file bigger than this limit will give you an error&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# message HTTP error code 413 (&amp;quot;Request Entity Too Large&amp;quot;).&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# You should use 0 to disable this feature or write the same value than for the parameter&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# max_upload_size in section [fileserver] of seafile.conf. Client uploads are only partly effected by this limit.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# With a limit of 100 MiB they can safely upload files of any size.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;client_max_body_size 0;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location /media {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;root /opt/seafile/seafile-server-latest/seahub;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location /seafdav {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#&lt;/code&gt; &lt;a href=\"https://manual.seafile.com/extension/webdav.html\"&gt;&lt;code&gt;https://manual.seafile.com/extension/webdav.html&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_pass http://&lt;/code&gt;&lt;a href=\"https://192.168.16.3\"&gt;&lt;code&gt;192.168.16.3&lt;/code&gt;&lt;/a&gt;&lt;code&gt;:8080;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header Host $host;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Real-IP $remote_addr;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-Host $server_name;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_set_header X-Forwarded-Proto https;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_http_version 1.1;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_connect_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_read_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_send_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;send_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;client_max_body_size 0;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# if you want to support file uploads larger than 4GB, we suggest to install Nginx version &amp;gt;= 1.8.0 and&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# add the following option to Nginx config file (set to &amp;quot;off&amp;quot;) -&lt;/code&gt;  &lt;a href=\"https://manual.seafile.com/deploy/deploy_with_nginx.html\"&gt;&lt;code&gt;https://manual.seafile.com/deploy/deploy_with_nginx.html&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_request_buffering off;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;access_log /var/log/nginx/seafdav.access.log;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;error_log /var/log/nginx/seafdav.error.log;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location /seafhttp {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;rewrite ^/seafhttp(.*)$ $1 break;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_pass http://seafile-arm-docker_default:8082;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;client_max_body_size 0;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_connect_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_read_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_send_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;send_timeout 36000s;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# if you want to support file uploads larger than 4GB, we suggest to install Nginx version &amp;gt;= 1.8.0 and&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;# add the following option to Nginx config file (set to &amp;quot;off&amp;quot;) -&lt;/code&gt;  &lt;a href=\"https://manual.seafile.com/deploy/deploy_with_nginx.html\"&gt;&lt;code&gt;https://manual.seafile.com/deploy/deploy_with_nginx.html&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;proxy_request_buffering off;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location /seafmedia {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;rewrite ^/seafmedia(.*)$ /media$1 break;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;root /opt/seafile/seafile-server-latest/seahub;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;#### default&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen 80;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen [::]:80;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server_name mydomain.com;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location / {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;return 301 https://$host$request_uri;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;location ~ /.well-known/acme-challenge {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;allow all;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;root /tmp/acme_challenge;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server {&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen 443 ssl;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;listen [::]:443 ssl http2;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;server_name mydomain.com;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ssl_certificate /etc/letsencrypt/live/mydomain.com/fullchain.pem;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ssl_certificate_key /etc/letsencrypt/live/mydomain.com/privkey.pem;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Bonus question:&lt;/p&gt;\n\n&lt;p&gt;I see linuxserver/mariadb running as well after running docker ps. Is that port 3306 closed for access from outside the container? So it will not interfere with other sql containers that I might have running on that port?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pe0a9", "is_robot_indexable": true, "report_reasons": null, "author": "mhmert", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pe0a9/nginx_reverse_proxy_and_seafile_both_on_separate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pe0a9/nginx_reverse_proxy_and_seafile_both_on_separate/", "subreddit_subscribers": 288861, "created_utc": 1699307041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "good day,\n\n&amp;#x200B;\n\nas per title, I need an FTP/SFTP client with web ui so I can manage and download stuff to my PC and see the progress on the go. currently, have to remote desktop into my PC but it's a bit annoying ;-;. preferably something that works on windows, but will consider docker images.", "author_fullname": "t2_y6rpp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any FTP/SFTP client with web ui?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17p8oum", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Need Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699293703.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699293501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;good day,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;as per title, I need an FTP/SFTP client with web ui so I can manage and download stuff to my PC and see the progress on the go. currently, have to remote desktop into my PC but it&amp;#39;s a bit annoying ;-;. preferably something that works on windows, but will consider docker images.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82508a80-05bc-11eb-ae09-0effb713859f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17p8oum", "is_robot_indexable": true, "report_reasons": null, "author": "nanoosx", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17p8oum/any_ftpsftp_client_with_web_ui/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17p8oum/any_ftpsftp_client_with_web_ui/", "subreddit_subscribers": 288861, "created_utc": 1699293501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I have a used mini desktop computer, which I've installed 32GB of RAM and 2TB NVMe SSD.\n\nI want to use it as an all inclusive PKM, Diary/Personal Journal and Research.\n\nI have over 50GBs worth of books in various formats, over 30GBs in videos, 10GBs in photos, 12 GB of Audio, etc.\n\nI also want an OS that's friendly with Windows programs, there are a few desktop apps that aren't available in Linux. I am wanting to have multiple PKMs installed like Notion, Capacities, MS OneNote, etc. A Content Manager for all my Videos and Audio, a Calibre like Library.\n\nMy idea is to have a VPN installed (which my smartphone and laptop have already), so that my devices can easily access it remotely. And easily access its dashboard(s) via web interface (as opposed to doing remote desktop).", "author_fullname": "t2_tbw8wxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an OS or approach that is best for my Homelab Project in this specific user case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17pwyzw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699371376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a used mini desktop computer, which I&amp;#39;ve installed 32GB of RAM and 2TB NVMe SSD.&lt;/p&gt;\n\n&lt;p&gt;I want to use it as an all inclusive PKM, Diary/Personal Journal and Research.&lt;/p&gt;\n\n&lt;p&gt;I have over 50GBs worth of books in various formats, over 30GBs in videos, 10GBs in photos, 12 GB of Audio, etc.&lt;/p&gt;\n\n&lt;p&gt;I also want an OS that&amp;#39;s friendly with Windows programs, there are a few desktop apps that aren&amp;#39;t available in Linux. I am wanting to have multiple PKMs installed like Notion, Capacities, MS OneNote, etc. A Content Manager for all my Videos and Audio, a Calibre like Library.&lt;/p&gt;\n\n&lt;p&gt;My idea is to have a VPN installed (which my smartphone and laptop have already), so that my devices can easily access it remotely. And easily access its dashboard(s) via web interface (as opposed to doing remote desktop).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pwyzw", "is_robot_indexable": true, "report_reasons": null, "author": "ApolloRising434", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pwyzw/whats_an_os_or_approach_that_is_best_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pwyzw/whats_an_os_or_approach_that_is_best_for_my/", "subreddit_subscribers": 288861, "created_utc": 1699371376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "LidaTube: Get missing Lidarr albums\n\n[https://github.com/TheWicklowWolf/LidaTube](https://github.com/TheWicklowWolf/LidaTube)\n\n&amp;#x200B;\n\n[LidaTube](https://preview.redd.it/eu5cbl6s6yyb1.png?width=683&amp;format=png&amp;auto=webp&amp;s=a939672ffb1a9a724db1ef51e5ce86733771217d)\n\nSyncify: Sync a Spotify Playlist\n\n[https://github.com/TheWicklowWolf/Syncify](https://github.com/TheWicklowWolf/Syncify)\n\n&amp;#x200B;\n\n[Syncify](https://preview.redd.it/8z805t937yyb1.png?width=682&amp;format=png&amp;auto=webp&amp;s=48965ce7dd44bd07ae686b142363dfa8de3864a8)\n\n&amp;#x200B;\n\nSpotTube: Download a Spotify playlist via YouTube\n\n[https://github.com/TheWicklowWolf/SpotTube](https://github.com/TheWicklowWolf/SpotTube)\n\n&amp;#x200B;\n\n[SpotTube](https://preview.redd.it/nvmp9zgc7yyb1.png?width=682&amp;format=png&amp;auto=webp&amp;s=f95d918c4b87d6074d771c8447d559a71059c6d3)\n\n&amp;#x200B;", "author_fullname": "t2_r85zyhrd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Here are a few docker images that may be useful...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 65, "top_awarded_type": null, "hide_score": true, "media_metadata": {"nvmp9zgc7yyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/nvmp9zgc7yyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c258275bb8be2fe9e165ac65a6f20f72a10ae1b0"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/nvmp9zgc7yyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e588671375c184a6ab9a989b54f5e06a4be9d92"}, {"y": 148, "x": 320, "u": "https://preview.redd.it/nvmp9zgc7yyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9cd0485dcb24a742ad01f01ae5c96ecaca9b72be"}, {"y": 297, "x": 640, "u": "https://preview.redd.it/nvmp9zgc7yyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=919563bf70e036dc606866a5a9ec5e1ed1083a97"}], "s": {"y": 317, "x": 682, "u": "https://preview.redd.it/nvmp9zgc7yyb1.png?width=682&amp;format=png&amp;auto=webp&amp;s=f95d918c4b87d6074d771c8447d559a71059c6d3"}, "id": "nvmp9zgc7yyb1"}, "8z805t937yyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/8z805t937yyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=496b7b0d9fb02a78bc2c46bec8aeb5fb4dfc65ae"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/8z805t937yyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=99110f8b439c458b7e885f59e5ca28835ec06717"}, {"y": 148, "x": 320, "u": "https://preview.redd.it/8z805t937yyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=304e21a1351a5d6f54aedd87754deb56fabe9efe"}, {"y": 296, "x": 640, "u": "https://preview.redd.it/8z805t937yyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b21ecd9d7451d61d48efcf28a4373cdd8c05d579"}], "s": {"y": 316, "x": 682, "u": "https://preview.redd.it/8z805t937yyb1.png?width=682&amp;format=png&amp;auto=webp&amp;s=48965ce7dd44bd07ae686b142363dfa8de3864a8"}, "id": "8z805t937yyb1"}, "eu5cbl6s6yyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 50, "x": 108, "u": "https://preview.redd.it/eu5cbl6s6yyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=733d5b3b25858ebd2a774b68c44e6b920dda0a7d"}, {"y": 100, "x": 216, "u": "https://preview.redd.it/eu5cbl6s6yyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5346e8f026b66168de80de6a80354a1d43663c2"}, {"y": 149, "x": 320, "u": "https://preview.redd.it/eu5cbl6s6yyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=efd9a1b6d4d31c878aaae0f3b248b76966a5a88d"}, {"y": 298, "x": 640, "u": "https://preview.redd.it/eu5cbl6s6yyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=980d8dbb75664cad1eda76df129bddaa3feeb533"}], "s": {"y": 319, "x": 683, "u": "https://preview.redd.it/eu5cbl6s6yyb1.png?width=683&amp;format=png&amp;auto=webp&amp;s=a939672ffb1a9a724db1ef51e5ce86733771217d"}, "id": "eu5cbl6s6yyb1"}}, "name": "t3_17pw9qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HN6sNZdNWy3EkR_uyIAYYQuOcR4CwirGg2wQ3SbchcQ.jpg", "edited": 1699372645.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699369495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;LidaTube: Get missing Lidarr albums&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/TheWicklowWolf/LidaTube\"&gt;https://github.com/TheWicklowWolf/LidaTube&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eu5cbl6s6yyb1.png?width=683&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a939672ffb1a9a724db1ef51e5ce86733771217d\"&gt;LidaTube&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Syncify: Sync a Spotify Playlist&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/TheWicklowWolf/Syncify\"&gt;https://github.com/TheWicklowWolf/Syncify&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8z805t937yyb1.png?width=682&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=48965ce7dd44bd07ae686b142363dfa8de3864a8\"&gt;Syncify&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;SpotTube: Download a Spotify playlist via YouTube&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/TheWicklowWolf/SpotTube\"&gt;https://github.com/TheWicklowWolf/SpotTube&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nvmp9zgc7yyb1.png?width=682&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f95d918c4b87d6074d771c8447d559a71059c6d3\"&gt;SpotTube&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pw9qw", "is_robot_indexable": true, "report_reasons": null, "author": "TheWicklowWolf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pw9qw/here_are_a_few_docker_images_that_may_be_useful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pw9qw/here_are_a_few_docker_images_that_may_be_useful/", "subreddit_subscribers": 288861, "created_utc": 1699369495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Please treat me like a total noob - but i currently have a managed wordpress site with Ionos, and i'm looking to migrate and install something like dub to manage my own shortening of URLs  \n\n\nI will probably move to a provider such as Krystal, so wanted to get a headstart on what is needed to run my own URL shortening  service and how do i go about installing a service like dub  \n\n\nIts really important to be able to track source of clicks and utilise services such as facebook pixel, and i do like the idea of being able to create QR codes", "author_fullname": "t2_giua1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Installing Self Hosted dub or any other link shortner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pvr0p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699368012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please treat me like a total noob - but i currently have a managed wordpress site with Ionos, and i&amp;#39;m looking to migrate and install something like dub to manage my own shortening of URLs  &lt;/p&gt;\n\n&lt;p&gt;I will probably move to a provider such as Krystal, so wanted to get a headstart on what is needed to run my own URL shortening  service and how do i go about installing a service like dub  &lt;/p&gt;\n\n&lt;p&gt;Its really important to be able to track source of clicks and utilise services such as facebook pixel, and i do like the idea of being able to create QR codes&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pvr0p", "is_robot_indexable": true, "report_reasons": null, "author": "mcgrime72", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pvr0p/installing_self_hosted_dub_or_any_other_link/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pvr0p/installing_self_hosted_dub_or_any_other_link/", "subreddit_subscribers": 288861, "created_utc": 1699368012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I don't know if something like this exists, but I have multiple routers which sadly only have the option of OpenVPN to which I would like to connect and access the router interface and interfaces of devices behind the router from a central server. Is there a solution which lets me, for example create a VPN config for a device which I upload to the router who then connects to the central server? I want to only connect to the devices from the server and like the networks to be isolated between the clients. Anyone got any ideas?", "author_fullname": "t2_5icivq52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for OpenVPN server for multiple clients with web interfaces", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pv7ue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699366485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know if something like this exists, but I have multiple routers which sadly only have the option of OpenVPN to which I would like to connect and access the router interface and interfaces of devices behind the router from a central server. Is there a solution which lets me, for example create a VPN config for a device which I upload to the router who then connects to the central server? I want to only connect to the devices from the server and like the networks to be isolated between the clients. Anyone got any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pv7ue", "is_robot_indexable": true, "report_reasons": null, "author": "escitalopramm", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pv7ue/looking_for_openvpn_server_for_multiple_clients/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pv7ue/looking_for_openvpn_server_for_multiple_clients/", "subreddit_subscribers": 288861, "created_utc": 1699366485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "I would like to organize voting in an association  election, which takes place during a meeting. It should be anonymous,  while ensuring a single person can only vote once. This would probably  be best achieved with personal links that could be distributed by email.  The votes should not be stored persistently (in a database) as  accidentally losing the votes doesn\u2019t matter, but the votes must be  deleted once the election part of the meeting (lasting 15-30min) is  over.", "author_fullname": "t2_17gmye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any voting software that doesn\u2019t store votes in persistent storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pu7a2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699363453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to organize voting in an association  election, which takes place during a meeting. It should be anonymous,  while ensuring a single person can only vote once. This would probably  be best achieved with personal links that could be distributed by email.  The votes should not be stored persistently (in a database) as  accidentally losing the votes doesn\u2019t matter, but the votes must be  deleted once the election part of the meeting (lasting 15-30min) is  over.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pu7a2", "is_robot_indexable": true, "report_reasons": null, "author": "Uumas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pu7a2/any_voting_software_that_doesnt_store_votes_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pu7a2/any_voting_software_that_doesnt_store_votes_in/", "subreddit_subscribers": 288861, "created_utc": 1699363453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi there, this is my first post so please bare with me! \n\nI'm fairly new to the whole nginx proxy and cloudflare thing but I had a basic set up to access things like nextcloud etc remotely at my old house. I've just moved and tried to match my network set up to how I had it before, static ip, updated dns settings in cloudflare etc but I still get the 522 error when trying to access nextcloud through my domain.\n\nI've tried googling to no avail, most places say updating the dns settings to the new ip is all I really need to do, so is there anything else I could be missing?\n\nThanks very much", "author_fullname": "t2_786wx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moved home and now Cloudflare times out", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pqu86", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699350859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, this is my first post so please bare with me! &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly new to the whole nginx proxy and cloudflare thing but I had a basic set up to access things like nextcloud etc remotely at my old house. I&amp;#39;ve just moved and tried to match my network set up to how I had it before, static ip, updated dns settings in cloudflare etc but I still get the 522 error when trying to access nextcloud through my domain.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried googling to no avail, most places say updating the dns settings to the new ip is all I really need to do, so is there anything else I could be missing?&lt;/p&gt;\n\n&lt;p&gt;Thanks very much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pqu86", "is_robot_indexable": true, "report_reasons": null, "author": "Tattooth", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pqu86/moved_home_and_now_cloudflare_times_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pqu86/moved_home_and_now_cloudflare_times_out/", "subreddit_subscribers": 288861, "created_utc": 1699350859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hi, I'm only asking here because I found another thread here where sb else got help with gluetun docker container, so I supposed it's not off topic.\n\n&amp;#x200B;\n\nI run Debian on a htpc with a ryzen apu. Docker with several containers is running, set up with dockstarter.com.  \nThe gluetun container is unhealthy and idk how to solve it.\n\nThis is the docker compose override file (dockstarter has gluetun included, additional options are set by using a docker compose override file):\n\n`gluetun:`\n\n`cap_add:`\n\n`- NET_ADMIN`\n\n`environment:`\n\n`- VPN_SERVICE_PROVIDER=custom`\n\n`- VPN_TYPE=wireguard`\n\n`- VPN_ENDPOINT_IP=`[`185.189.115.103`](https://185.189.115.103)\n\n`- VPN_ENDPOINT_PORT=1443`\n\n`- WIREGUARD_PUBLIC_KEY=**********************`\n\n`- WIREGUARD_PRIVATE_KEY=************************`\n\n`- WIREGUARD_ADDRESSES=`[`192.168.1.111/32`](https://192.168.1.111/32)\n\nMy vpn provider is torguard. I get the following output in portainer log:\n\n `2023-11-07T10:10:42+01:00 INFO [routing] default route found: interface eth0, gateway` [`172.18.0.1`](https://172.18.0.1)`, assigned IP` [`172.18.0.22`](https://172.18.0.22) `and family v4`\n\n`2023-11-07T10:10:42+01:00 INFO [routing] adding route for` [`0.0.0.0/0`](https://0.0.0.0/0)\n\n`2023-11-07T10:10:42+01:00 INFO [firewall] setting allowed subnets...`\n\n`2023-11-07T10:10:42+01:00 INFO [routing] default route found: interface eth0, gateway` [`172.18.0.1`](https://172.18.0.1)`, assigned IP` [`172.18.0.22`](https://172.18.0.22) `and family v4`\n\n`2023-11-07T10:10:42+01:00 INFO TUN device is not available: open /dev/net/tun: no such file or directory; creating it...`\n\n`2023-11-07T10:10:42+01:00 INFO [dns] using plaintext DNS at address` [`1.1.1.1`](https://1.1.1.1)\n\n`2023-11-07T10:10:42+01:00 INFO [http server] http server listening on [::]:8000`\n\n`2023-11-07T10:10:42+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:10:42+01:00 INFO [healthcheck] listening on` [`127.0.0.1:9999`](https://127.0.0.1:9999)\n\n`2023-11-07T10:10:42+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:10:42+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:10:42+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:10:42+01:00 INFO [dns] downloading DNS over TLS cryptographic files`\n\n`2023-11-07T10:10:50+01:00 INFO [healthcheck] program has been unhealthy for 6s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:10:50+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:10:50+01:00 ERROR [vpn] cannot get version information: Get \"`[`https://api.github.com/repos/qdm12/gluetun/commits`](https://api.github.com/repos/qdm12/gluetun/commits)`\": context canceled`\n\n`2023-11-07T10:10:50+01:00 ERROR [ip getter] Get \"`[`https://ipinfo.io/`](https://ipinfo.io/)`\": dial tcp: lookup` [`ipinfo.io`](https://ipinfo.io) `on` [`1.1.1.1:53`](https://1.1.1.1:53)`: write udp 172.18.0.22:41311-&gt;`[`1.1.1.1:53`](https://1.1.1.1:53)`: write: operation not permitted - retrying in 5s`\n\n`2023-11-07T10:10:50+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:10:50+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:10:50+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:10:50+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:10:50+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:10:57+01:00 WARN [dns] cannot update files: Get \"`[`https://www.internic.net/domain/named.root`](https://www.internic.net/domain/named.root)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)`\n\n`2023-11-07T10:10:57+01:00 INFO [dns] attempting restart in 10s`\n\n`2023-11-07T10:11:01+01:00 INFO [healthcheck] program has been unhealthy for 11s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:11:01+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:11:02+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:11:02+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:11:02+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:11:02+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:11:02+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:11:07+01:00 INFO [dns] downloading DNS over TLS cryptographic files`\n\n`2023-11-07T10:11:10+01:00 ERROR [ip getter] Get \"`[`https://ipinfo.io/`](https://ipinfo.io/)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 10s`\n\n`2023-11-07T10:11:18+01:00 INFO [healthcheck] program has been unhealthy for 16s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:11:18+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:11:18+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:11:18+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:11:18+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:11:18+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:11:18+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:11:22+01:00 WARN [dns] cannot update files: Get \"`[`https://www.internic.net/domain/named.root`](https://www.internic.net/domain/named.root)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)`\n\n`2023-11-07T10:11:22+01:00 INFO [dns] attempting restart in 20s`\n\n`2023-11-07T10:11:35+01:00 ERROR [ip getter] Get \"`[`https://ipinfo.io/`](https://ipinfo.io/)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 20s`\n\n`2023-11-07T10:11:41+01:00 INFO [healthcheck] program has been unhealthy for 21s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:11:41+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:11:41+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:11:41+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:11:41+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:11:41+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:11:41+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:11:42+01:00 INFO [dns] downloading DNS over TLS cryptographic files`\n\n`2023-11-07T10:11:57+01:00 WARN [dns] cannot update files: Get \"`[`https://www.internic.net/domain/named.root`](https://www.internic.net/domain/named.root)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)`\n\n`2023-11-07T10:11:57+01:00 INFO [dns] attempting restart in 40s`\n\n`2023-11-07T10:12:08+01:00 INFO [healthcheck] program has been unhealthy for 26s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:12:08+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:12:09+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:12:09+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:12:09+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:12:09+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:12:09+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\n`2023-11-07T10:12:10+01:00 ERROR [ip getter] Get \"`[`https://ipinfo.io/`](https://ipinfo.io/)`\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 40s`\n\n`2023-11-07T10:12:37+01:00 INFO [dns] downloading DNS over TLS cryptographic files`\n\n`2023-11-07T10:12:40+01:00 INFO [healthcheck] program has been unhealthy for 31s: restarting VPN (see` [`https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md`](https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md)`)`\n\n`2023-11-07T10:12:40+01:00 INFO [vpn] stopping`\n\n`2023-11-07T10:12:40+01:00 INFO [vpn] starting`\n\n`2023-11-07T10:12:40+01:00 INFO [firewall] allowing VPN connection...`\n\n`2023-11-07T10:12:40+01:00 INFO [wireguard] Using available kernelspace implementation`\n\n`2023-11-07T10:12:40+01:00 INFO [wireguard] Connecting to` [`185.189.115.103:1443`](https://185.189.115.103:1443)\n\n`2023-11-07T10:12:40+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.`\n\nOne thing I tried is to set network mode for another container to container:gluetun  \n and map its port in the gluetun compose section.  \nAfter that I'm able to reach the container, so I guess something must have worked :)\n\nI suspect there's some routing problem, but concerning this I'm a real noob.  \nOn the host os, debian, I have firewalld running. There's a gui for that and I put all interfaces into zone public. I further allowed wireguard service and in the ports section I added port 1443 both tcp and udp.\n\nIs it possible that there's also some firewall settings on my router that prevent gluetun to work properly?", "author_fullname": "t2_117ntp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help setting up gluetun docker container?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pqbtd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699348468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m only asking here because I found another thread here where sb else got help with gluetun docker container, so I supposed it&amp;#39;s not off topic.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I run Debian on a htpc with a ryzen apu. Docker with several containers is running, set up with dockstarter.com.&lt;br/&gt;\nThe gluetun container is unhealthy and idk how to solve it.&lt;/p&gt;\n\n&lt;p&gt;This is the docker compose override file (dockstarter has gluetun included, additional options are set by using a docker compose override file):&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;gluetun:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;cap_add:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- NET_ADMIN&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;environment:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- VPN_SERVICE_PROVIDER=custom&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- VPN_TYPE=wireguard&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- VPN_ENDPOINT_IP=&lt;/code&gt;&lt;a href=\"https://185.189.115.103\"&gt;&lt;code&gt;185.189.115.103&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- VPN_ENDPOINT_PORT=1443&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- WIREGUARD_PUBLIC_KEY=**********************&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- WIREGUARD_PRIVATE_KEY=************************&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;- WIREGUARD_ADDRESSES=&lt;/code&gt;&lt;a href=\"https://192.168.1.111/32\"&gt;&lt;code&gt;192.168.1.111/32&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My vpn provider is torguard. I get the following output in portainer log:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [routing] default route found: interface eth0, gateway&lt;/code&gt; &lt;a href=\"https://172.18.0.1\"&gt;&lt;code&gt;172.18.0.1&lt;/code&gt;&lt;/a&gt;&lt;code&gt;, assigned IP&lt;/code&gt; &lt;a href=\"https://172.18.0.22\"&gt;&lt;code&gt;172.18.0.22&lt;/code&gt;&lt;/a&gt; &lt;code&gt;and family v4&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [routing] adding route for&lt;/code&gt; &lt;a href=\"https://0.0.0.0/0\"&gt;&lt;code&gt;0.0.0.0/0&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [firewall] setting allowed subnets...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [routing] default route found: interface eth0, gateway&lt;/code&gt; &lt;a href=\"https://172.18.0.1\"&gt;&lt;code&gt;172.18.0.1&lt;/code&gt;&lt;/a&gt;&lt;code&gt;, assigned IP&lt;/code&gt; &lt;a href=\"https://172.18.0.22\"&gt;&lt;code&gt;172.18.0.22&lt;/code&gt;&lt;/a&gt; &lt;code&gt;and family v4&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO TUN device is not available: open /dev/net/tun: no such file or directory; creating it...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [dns] using plaintext DNS at address&lt;/code&gt; &lt;a href=\"https://1.1.1.1\"&gt;&lt;code&gt;1.1.1.1&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [http server] http server listening on [::]:8000&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [healthcheck] listening on&lt;/code&gt; &lt;a href=\"https://127.0.0.1:9999\"&gt;&lt;code&gt;127.0.0.1:9999&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:42+01:00 INFO [dns] downloading DNS over TLS cryptographic files&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [healthcheck] program has been unhealthy for 6s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 ERROR [vpn] cannot get version information: Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://api.github.com/repos/qdm12/gluetun/commits\"&gt;&lt;code&gt;https://api.github.com/repos/qdm12/gluetun/commits&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context canceled&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 ERROR [ip getter] Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://ipinfo.io/\"&gt;&lt;code&gt;https://ipinfo.io/&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: dial tcp: lookup&lt;/code&gt; &lt;a href=\"https://ipinfo.io\"&gt;&lt;code&gt;ipinfo.io&lt;/code&gt;&lt;/a&gt; &lt;code&gt;on&lt;/code&gt; &lt;a href=\"https://1.1.1.1:53\"&gt;&lt;code&gt;1.1.1.1:53&lt;/code&gt;&lt;/a&gt;&lt;code&gt;: write udp 172.18.0.22:41311-&amp;gt;&lt;/code&gt;&lt;a href=\"https://1.1.1.1:53\"&gt;&lt;code&gt;1.1.1.1:53&lt;/code&gt;&lt;/a&gt;&lt;code&gt;: write: operation not permitted - retrying in 5s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:50+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:57+01:00 WARN [dns] cannot update files: Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://www.internic.net/domain/named.root\"&gt;&lt;code&gt;https://www.internic.net/domain/named.root&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:10:57+01:00 INFO [dns] attempting restart in 10s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:01+01:00 INFO [healthcheck] program has been unhealthy for 11s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:01+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:02+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:02+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:02+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:02+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:02+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:07+01:00 INFO [dns] downloading DNS over TLS cryptographic files&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:10+01:00 ERROR [ip getter] Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://ipinfo.io/\"&gt;&lt;code&gt;https://ipinfo.io/&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 10s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [healthcheck] program has been unhealthy for 16s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:18+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:22+01:00 WARN [dns] cannot update files: Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://www.internic.net/domain/named.root\"&gt;&lt;code&gt;https://www.internic.net/domain/named.root&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:22+01:00 INFO [dns] attempting restart in 20s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:35+01:00 ERROR [ip getter] Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://ipinfo.io/\"&gt;&lt;code&gt;https://ipinfo.io/&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 20s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [healthcheck] program has been unhealthy for 21s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:41+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:42+01:00 INFO [dns] downloading DNS over TLS cryptographic files&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:57+01:00 WARN [dns] cannot update files: Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://www.internic.net/domain/named.root\"&gt;&lt;code&gt;https://www.internic.net/domain/named.root&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:11:57+01:00 INFO [dns] attempting restart in 40s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:08+01:00 INFO [healthcheck] program has been unhealthy for 26s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:08+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:09+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:09+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:09+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:09+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:09+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:10+01:00 ERROR [ip getter] Get &amp;quot;&lt;/code&gt;&lt;a href=\"https://ipinfo.io/\"&gt;&lt;code&gt;https://ipinfo.io/&lt;/code&gt;&lt;/a&gt;&lt;code&gt;&amp;quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) - retrying in 40s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:37+01:00 INFO [dns] downloading DNS over TLS cryptographic files&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [healthcheck] program has been unhealthy for 31s: restarting VPN (see&lt;/code&gt; &lt;a href=\"https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\"&gt;&lt;code&gt;https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md&lt;/code&gt;&lt;/a&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [vpn] stopping&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [vpn] starting&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [firewall] allowing VPN connection...&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [wireguard] Using available kernelspace implementation&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [wireguard] Connecting to&lt;/code&gt; &lt;a href=\"https://185.189.115.103:1443\"&gt;&lt;code&gt;185.189.115.103:1443&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;2023-11-07T10:12:40+01:00 INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;One thing I tried is to set network mode for another container to container:gluetun&lt;br/&gt;\n and map its port in the gluetun compose section.&lt;br/&gt;\nAfter that I&amp;#39;m able to reach the container, so I guess something must have worked :)&lt;/p&gt;\n\n&lt;p&gt;I suspect there&amp;#39;s some routing problem, but concerning this I&amp;#39;m a real noob.&lt;br/&gt;\nOn the host os, debian, I have firewalld running. There&amp;#39;s a gui for that and I put all interfaces into zone public. I further allowed wireguard service and in the ports section I added port 1443 both tcp and udp.&lt;/p&gt;\n\n&lt;p&gt;Is it possible that there&amp;#39;s also some firewall settings on my router that prevent gluetun to work properly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pqbtd", "is_robot_indexable": true, "report_reasons": null, "author": "fabiustus", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pqbtd/can_anyone_help_setting_up_gluetun_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pqbtd/can_anyone_help_setting_up_gluetun_docker/", "subreddit_subscribers": 288861, "created_utc": 1699348468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "selfhosted", "selftext": "Hello everyone!\n\nI'm with **Cerbos** ([https://cerbos.dev/](https://cerbos.dev/)), a self-hosted, open-source dev tool designed to manage who can do what in your software applications.\n\nFor a couple of years now, Open Worldwide Application Security Project (OWASP) is naming authorization a [**top 10 API security risk**](https://owasp.org/API-Security/editions/2023/en/0x11-t10/).\n\nWe are thrilled to announce that Cerbos Hub is now in **public beta**!\n\nYou can think of **Cerbos Hub** as an inter, the Cerbos engine and everything that has to do with making decisions IS and will always be, and the Hub serves to help mitigate the collaborative update pains.licy updates in real-time even to the edge and end client devices via its WebAssembly extension. It is a stateless, scalable and collaborative solution for teams who want to save time, streamline their workflows and confidently roll out authZ updates.\n\nWhile the **Hub per-se is NOT self-hosted**, the Cerbos engine and everything that has to do with making decisions IS and will always be, and the hub serves to help mitigate the collaborative update pains.\n\nHelp us shape the future of authZ, and help your teams (or yourself) focus on innovation!  \n\n\nLooking forward to your feedback, with hopes of not infringing the self-hosted nature of this community.  \nMuch appreciated :)  \n\n\n[Cerbos Hub](https://preview.redd.it/gwkvooe84wyb1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=81d9974c841a6757af583bff03009766109f2fb7)", "author_fullname": "t2_81bplilvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback needed: Cerbos Hub is now in public beta!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/selfhosted", "hidden": false, "pwls": 6, "link_flair_css_class": "release", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gwkvooe84wyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa9da86a6e7e239666d41ebbf2e2aaacd4792b15"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9ff8a58d5a5df97629cebb1d4b290c2063440283"}, {"y": 172, "x": 320, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dd162aff7a771ddf47395cfa9ed705850c2ad622"}, {"y": 345, "x": 640, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1765a398a69d4ff81a176999de3bab498d0abc7f"}, {"y": 518, "x": 960, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b35b3bfc912d2dc29d73bd5d58d724397f6b310a"}, {"y": 583, "x": 1080, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=89abf6294cd482d7840ad7cbdbd1778bb6572ba4"}], "s": {"y": 1556, "x": 2880, "u": "https://preview.redd.it/gwkvooe84wyb1.png?width=2880&amp;format=png&amp;auto=webp&amp;s=81d9974c841a6757af583bff03009766109f2fb7"}, "id": "gwkvooe84wyb1"}}, "name": "t3_17pq3nf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Release", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6YVgamIhNgV7QDjkYoNR7yVEj3VF4PH6r_ahsJLs-ho.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699347402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.selfhosted", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m with &lt;strong&gt;Cerbos&lt;/strong&gt; (&lt;a href=\"https://cerbos.dev/\"&gt;https://cerbos.dev/&lt;/a&gt;), a self-hosted, open-source dev tool designed to manage who can do what in your software applications.&lt;/p&gt;\n\n&lt;p&gt;For a couple of years now, Open Worldwide Application Security Project (OWASP) is naming authorization a &lt;a href=\"https://owasp.org/API-Security/editions/2023/en/0x11-t10/\"&gt;&lt;strong&gt;top 10 API security risk&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We are thrilled to announce that Cerbos Hub is now in &lt;strong&gt;public beta&lt;/strong&gt;!&lt;/p&gt;\n\n&lt;p&gt;You can think of &lt;strong&gt;Cerbos Hub&lt;/strong&gt; as an inter, the Cerbos engine and everything that has to do with making decisions IS and will always be, and the Hub serves to help mitigate the collaborative update pains.licy updates in real-time even to the edge and end client devices via its WebAssembly extension. It is a stateless, scalable and collaborative solution for teams who want to save time, streamline their workflows and confidently roll out authZ updates.&lt;/p&gt;\n\n&lt;p&gt;While the &lt;strong&gt;Hub per-se is NOT self-hosted&lt;/strong&gt;, the Cerbos engine and everything that has to do with making decisions IS and will always be, and the hub serves to help mitigate the collaborative update pains.&lt;/p&gt;\n\n&lt;p&gt;Help us shape the future of authZ, and help your teams (or yourself) focus on innovation!  &lt;/p&gt;\n\n&lt;p&gt;Looking forward to your feedback, with hopes of not infringing the self-hosted nature of this community.&lt;br/&gt;\nMuch appreciated :)  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gwkvooe84wyb1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81d9974c841a6757af583bff03009766109f2fb7\"&gt;Cerbos Hub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7a2c90d0-4655-11ec-b067-9e334eed55f0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32hch", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17pq3nf", "is_robot_indexable": true, "report_reasons": null, "author": "AuthZ_Trooper", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/selfhosted/comments/17pq3nf/feedback_needed_cerbos_hub_is_now_in_public_beta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/selfhosted/comments/17pq3nf/feedback_needed_cerbos_hub_is_now_in_public_beta/", "subreddit_subscribers": 288861, "created_utc": 1699347402.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}