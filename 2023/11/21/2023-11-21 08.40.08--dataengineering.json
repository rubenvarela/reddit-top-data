{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm a newer DE tasked with building our DW architecture. We decided to go with Snowflake for our warehouse and dbt for our 'T'. We're primarily an Azure shop - and I'm really stuck on WHERE to execute my python code. There is so so much noise on the topic and so many options that I'm honestly feeling overwhelmed. It doesnt seem like people like ADF and say it comes with a lot of headache (I dont know how true this is), some people don't seem to like Airflow (Idk if this is bc they're using it wrong, whatever), Dagster seems to be a good option - but their managed serverless compute tier is probably overkill right now. Right now I'm thinking of Dagster/Airflow orchestrating and calling Docker containers that have my pthon code, and then running that on like Azure Kubernetes Service? What about running those docker containers on a VM and then shipping them to something more heavy duty later? Would this be preferred to azure functions or azure durable functions? Is ADF really that bad? What do you guys think has a feasible learning curve (assuming the solution isn't some managed service) while still serving as a scalable and/or cost effective solution? \n\nHopefully vendors don't infiltrate this conversation too much lol", "author_fullname": "t2_3ugqxzu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing our 'EL' stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zxmev", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700510932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m a newer DE tasked with building our DW architecture. We decided to go with Snowflake for our warehouse and dbt for our &amp;#39;T&amp;#39;. We&amp;#39;re primarily an Azure shop - and I&amp;#39;m really stuck on WHERE to execute my python code. There is so so much noise on the topic and so many options that I&amp;#39;m honestly feeling overwhelmed. It doesnt seem like people like ADF and say it comes with a lot of headache (I dont know how true this is), some people don&amp;#39;t seem to like Airflow (Idk if this is bc they&amp;#39;re using it wrong, whatever), Dagster seems to be a good option - but their managed serverless compute tier is probably overkill right now. Right now I&amp;#39;m thinking of Dagster/Airflow orchestrating and calling Docker containers that have my pthon code, and then running that on like Azure Kubernetes Service? What about running those docker containers on a VM and then shipping them to something more heavy duty later? Would this be preferred to azure functions or azure durable functions? Is ADF really that bad? What do you guys think has a feasible learning curve (assuming the solution isn&amp;#39;t some managed service) while still serving as a scalable and/or cost effective solution? &lt;/p&gt;\n\n&lt;p&gt;Hopefully vendors don&amp;#39;t infiltrate this conversation too much lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zxmev", "is_robot_indexable": true, "report_reasons": null, "author": "Casdom33", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zxmev/choosing_our_el_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zxmev/choosing_our_el_stack/", "subreddit_subscribers": 140865, "created_utc": 1700510932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.\n\nNow, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).\n\nIn fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?", "author_fullname": "t2_f4h6309d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering guidance (AWS vs AZURE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk9u0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.&lt;/p&gt;\n\n&lt;p&gt;Now, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).&lt;/p&gt;\n\n&lt;p&gt;In fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zk9u0", "is_robot_indexable": true, "report_reasons": null, "author": "paisa_byte", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "subreddit_subscribers": 140865, "created_utc": 1700470607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a personal project where I\u2019m pulling NBA data from a scraper and putting it into a database. This scraping obviously needs to be automated. Obviously going to need to automate my data cleaning as well. A little bit further down the line I\u2019m going to want to automate the process of pulling data from my database to visualize it on a website. Not sure if this calls for Airflow, I have zero data engineer experience.\n\nThanks!", "author_fullname": "t2_kc7mg3akr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1808qro", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700541639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a personal project where I\u2019m pulling NBA data from a scraper and putting it into a database. This scraping obviously needs to be automated. Obviously going to need to automate my data cleaning as well. A little bit further down the line I\u2019m going to want to automate the process of pulling data from my database to visualize it on a website. Not sure if this calls for Airflow, I have zero data engineer experience.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1808qro", "is_robot_indexable": true, "report_reasons": null, "author": "Brief-Union-3493", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1808qro/should_i_use_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1808qro/should_i_use_airflow/", "subreddit_subscribers": 140865, "created_utc": 1700541639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am currently working as a data analyst and was interested to know if someone has given the new data engineering exam from AWS (DEA-C01). It would be great if the experts/individuals can share their experiences and study pattern for the same since I am planning to give the same.", "author_fullname": "t2_a06jzj8ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Data Engineering exam( DEA-C01)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1804yfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700529816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am currently working as a data analyst and was interested to know if someone has given the new data engineering exam from AWS (DEA-C01). It would be great if the experts/individuals can share their experiences and study pattern for the same since I am planning to give the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1804yfc", "is_robot_indexable": true, "report_reasons": null, "author": "ravipar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1804yfc/aws_data_engineering_exam_deac01/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1804yfc/aws_data_engineering_exam_deac01/", "subreddit_subscribers": 140865, "created_utc": 1700529816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My goal is training a machine learning model using SageMaker. I have preprocessed my data using pyspark in Amazon EMR, and I want to save my processed data in S3 and read it from SageMaker to use Random Cut Forest.  \nIs this the best way to do it or I should change something? Should I save processed data as parquet or another type?  \nNote that I would like to train the model using pipe mode", "author_fullname": "t2_7zvlhn0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Amazon EMR and Sagemaker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zz1ez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700514519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My goal is training a machine learning model using SageMaker. I have preprocessed my data using pyspark in Amazon EMR, and I want to save my processed data in S3 and read it from SageMaker to use Random Cut Forest.&lt;br/&gt;\nIs this the best way to do it or I should change something? Should I save processed data as parquet or another type?&lt;br/&gt;\nNote that I would like to train the model using pipe mode&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zz1ez", "is_robot_indexable": true, "report_reasons": null, "author": "Omart__", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zz1ez/amazon_emr_and_sagemaker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zz1ez/amazon_emr_and_sagemaker/", "subreddit_subscribers": 140865, "created_utc": 1700514519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today, I'm just a backend web developer with a lot of SQL experience wrapping up my first semester in a Masters of CS program. I took: Advanced Operating Systems, Computer Security, Database Architecture, and Software Engineering Course. \n\nWhat sort of courses would you recommend to break into Data Engineering? I'm currently eyeing a Machine Learning Fundamentals, Data Visualization, and Distributed Systems course.", "author_fullname": "t2_anqr7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Presently in an MSCS Program -- What courses would you recommend for Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zy8sc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700512502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today, I&amp;#39;m just a backend web developer with a lot of SQL experience wrapping up my first semester in a Masters of CS program. I took: Advanced Operating Systems, Computer Security, Database Architecture, and Software Engineering Course. &lt;/p&gt;\n\n&lt;p&gt;What sort of courses would you recommend to break into Data Engineering? I&amp;#39;m currently eyeing a Machine Learning Fundamentals, Data Visualization, and Distributed Systems course.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zy8sc", "is_robot_indexable": true, "report_reasons": null, "author": "KillerSmalls", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zy8sc/presently_in_an_mscs_program_what_courses_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zy8sc/presently_in_an_mscs_program_what_courses_would/", "subreddit_subscribers": 140865, "created_utc": 1700512502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Stumbled across two tools [https://rowzero.io/](https://rowzero.io/) and [https://www.gigasheet.com/](https://www.gigasheet.com/), that are spreadsheet like tools that support significantly more rows compared to excel \\~1m rows. What do you think about these? ", "author_fullname": "t2_s94r9x1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you feel the need of spreadsheet like tools to view large datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk7g7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Stumbled across two tools &lt;a href=\"https://rowzero.io/\"&gt;https://rowzero.io/&lt;/a&gt; and &lt;a href=\"https://www.gigasheet.com/\"&gt;https://www.gigasheet.com/&lt;/a&gt;, that are spreadsheet like tools that support significantly more rows compared to excel ~1m rows. What do you think about these? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zk7g7", "is_robot_indexable": true, "report_reasons": null, "author": "EternallyTrapped", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "subreddit_subscribers": 140865, "created_utc": 1700470306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some background first: I work as a data engineer in the BI department of a medium sized e-commerce firm. Our BI architecture is currently 100% on-premise. We use a data virtualization platform as a middleware between source systems and a data warehouse (postgres). For log and web tracking analytics we also use Clickhouse. This setup is probably not state of the art but fits our current needs quiet well. \n\nThe server hosting both the dwh and the middleware is going to be renewed and management decided it has to be something cloud. I'm struggeling a bit about the right course of action. Our data warehouse is currently around 2 TB in size. Most SQL queries run within an acceptable time frame. Some large queries could be faster but we are currently shifting some of these workloads to Clickhouse, with great results. \n\nMy approach is to keep the overall setup but separate BI middleware from the postgres database by bringing the latter to the cloud. I was thinking about an AWS EC2 instance like r5b to host postgres. Budget is always tight so RDS is probably not an option. I expect an increase in query performance due to better hardware and dedicated server. But is it really recommened to hold onto a relational database for mostly analytical purposes? Should we better switch to Redshift/BigQuery instead? It would be more expensive and an even bigger migration project (no manpower lol) and maybe absolutely oversized for our needs... Anyone has any thoughts on this? I'd really appreciate it. Thank you", "author_fullname": "t2_ramk8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from on-premise to cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1803jav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700525734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background first: I work as a data engineer in the BI department of a medium sized e-commerce firm. Our BI architecture is currently 100% on-premise. We use a data virtualization platform as a middleware between source systems and a data warehouse (postgres). For log and web tracking analytics we also use Clickhouse. This setup is probably not state of the art but fits our current needs quiet well. &lt;/p&gt;\n\n&lt;p&gt;The server hosting both the dwh and the middleware is going to be renewed and management decided it has to be something cloud. I&amp;#39;m struggeling a bit about the right course of action. Our data warehouse is currently around 2 TB in size. Most SQL queries run within an acceptable time frame. Some large queries could be faster but we are currently shifting some of these workloads to Clickhouse, with great results. &lt;/p&gt;\n\n&lt;p&gt;My approach is to keep the overall setup but separate BI middleware from the postgres database by bringing the latter to the cloud. I was thinking about an AWS EC2 instance like r5b to host postgres. Budget is always tight so RDS is probably not an option. I expect an increase in query performance due to better hardware and dedicated server. But is it really recommened to hold onto a relational database for mostly analytical purposes? Should we better switch to Redshift/BigQuery instead? It would be more expensive and an even bigger migration project (no manpower lol) and maybe absolutely oversized for our needs... Anyone has any thoughts on this? I&amp;#39;d really appreciate it. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1803jav", "is_robot_indexable": true, "report_reasons": null, "author": "knabbels", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1803jav/migrating_from_onpremise_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1803jav/migrating_from_onpremise_to_cloud/", "subreddit_subscribers": 140865, "created_utc": 1700525734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After reading a bit on the internet (and even asking about it here) it seems the majority opinion is that airflow is better for task scheduling and management than it is for actual task execution. \n\nBasically: you're whole pipeline shouldn't be a shit ton of python written directly into airflow DAGs, airflow should just be triggering workflows on other computers (lambdas, cloud run, etc).\n\nBut I'm having a hard time with some of the specifics of this. The nice thing about airflow is how it lets you describe the order of DAGs. Like I can run my \"get data from someone else's API\" DAG, and once that's done, it'll run the \"normalize that data and put it in a database\" DAG. It's easy peasy to set up those relationships, and manage the failure states and stuff.\n\nWhen airflow is just triggering jobs to run elsewhere, how do you keep this nice control flow of DAGs? Do you make an intermediate DAG that uses a reschedule-mode sensor? Or is that a weird hack?", "author_fullname": "t2_8k5ls63w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused about the role of airflow in distributed environments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zxaby", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700510100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After reading a bit on the internet (and even asking about it here) it seems the majority opinion is that airflow is better for task scheduling and management than it is for actual task execution. &lt;/p&gt;\n\n&lt;p&gt;Basically: you&amp;#39;re whole pipeline shouldn&amp;#39;t be a shit ton of python written directly into airflow DAGs, airflow should just be triggering workflows on other computers (lambdas, cloud run, etc).&lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m having a hard time with some of the specifics of this. The nice thing about airflow is how it lets you describe the order of DAGs. Like I can run my &amp;quot;get data from someone else&amp;#39;s API&amp;quot; DAG, and once that&amp;#39;s done, it&amp;#39;ll run the &amp;quot;normalize that data and put it in a database&amp;quot; DAG. It&amp;#39;s easy peasy to set up those relationships, and manage the failure states and stuff.&lt;/p&gt;\n\n&lt;p&gt;When airflow is just triggering jobs to run elsewhere, how do you keep this nice control flow of DAGs? Do you make an intermediate DAG that uses a reschedule-mode sensor? Or is that a weird hack?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zxaby", "is_robot_indexable": true, "report_reasons": null, "author": "chamomile-crumbs", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zxaby/confused_about_the_role_of_airflow_in_distributed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zxaby/confused_about_the_role_of_airflow_in_distributed/", "subreddit_subscribers": 140865, "created_utc": 1700510100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have an API serving layer enabled directly from the lake? \nWhat tech stack do you use?", "author_fullname": "t2_4ncjzv2a6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API serving layer over data lake tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1809l87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700544591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have an API serving layer enabled directly from the lake? \nWhat tech stack do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1809l87", "is_robot_indexable": true, "report_reasons": null, "author": "ImpactOk7137", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1809l87/api_serving_layer_over_data_lake_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1809l87/api_serving_layer_over_data_lake_tables/", "subreddit_subscribers": 140865, "created_utc": 1700544591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI've been learning by Data Engr skills slowly but surely, and the last/current major subject I've done the least on is SQL/DWH. I have nearly completed an \"Analytics Engineering\" course, which does (from what I can tell) go over a fair bit of the data modelling terms/practices, but then the implementation is all done in DBT...\n\nThere seems to be very mixed opinions on DBT in this subreddit and it seems to highly vary by circumstance of the organization. The main insight given this, is that it is probably not good to just rely on DBT for everything it handles behind the scenes, because once I work somewhere that doesn't use DBT, I am way behind.\n\nWith all that said, can anyone recommend some courses that would be good for learning the above?\n\nThanks in advance ", "author_fullname": "t2_8chdw7c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raw SQL for DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1803j7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700525727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been learning by Data Engr skills slowly but surely, and the last/current major subject I&amp;#39;ve done the least on is SQL/DWH. I have nearly completed an &amp;quot;Analytics Engineering&amp;quot; course, which does (from what I can tell) go over a fair bit of the data modelling terms/practices, but then the implementation is all done in DBT...&lt;/p&gt;\n\n&lt;p&gt;There seems to be very mixed opinions on DBT in this subreddit and it seems to highly vary by circumstance of the organization. The main insight given this, is that it is probably not good to just rely on DBT for everything it handles behind the scenes, because once I work somewhere that doesn&amp;#39;t use DBT, I am way behind.&lt;/p&gt;\n\n&lt;p&gt;With all that said, can anyone recommend some courses that would be good for learning the above?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1803j7c", "is_robot_indexable": true, "report_reasons": null, "author": "pdxtechnologist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1803j7c/raw_sql_for_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1803j7c/raw_sql_for_dwh/", "subreddit_subscribers": 140865, "created_utc": 1700525727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what are your experiences with their security team? There is some accusations on their leadership and inaccurate communication with customers.\n\nhttps://www.teamblind.com/post/politcs-favoritism-and-unethical-databricks-security-org-xcLNEu6A", "author_fullname": "t2_w39c9q7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spicy blind thread on Databricks security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1801xn0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700521490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what are your experiences with their security team? There is some accusations on their leadership and inaccurate communication with customers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.teamblind.com/post/politcs-favoritism-and-unethical-databricks-security-org-xcLNEu6A\"&gt;https://www.teamblind.com/post/politcs-favoritism-and-unethical-databricks-security-org-xcLNEu6A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?auto=webp&amp;s=494fb506600a9642f30deafe2b5e369e54bcf7ba", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6c8a8cafa32470600d154c74aa7c3ad02694788", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4778554fc065e788daf9d7482a11fec1cd8ef528", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0759d085fb9739f3cc852b7290c58bfea4059ed4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=803999044d2dd22a6db4e5788613504e1eb23f1f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f23c2e17c4ebbf757c9dff81ba2dd0bb119bdd5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Nny4vUCELn0RRwLgCmVpejUljcO_TNFbIi3MdWBV8e0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1f5932b4e7861f1ebfe1d5704e0dd7e838575417", "width": 1080, "height": 567}], "variants": {}, "id": "Gk6YolC49N131jjEu6ojWAA-u6goSZJNsu8wwnZLzKg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1801xn0", "is_robot_indexable": true, "report_reasons": null, "author": "data-ai-nerd", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1801xn0/spicy_blind_thread_on_databricks_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1801xn0/spicy_blind_thread_on_databricks_security/", "subreddit_subscribers": 140865, "created_utc": 1700521490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you manage a Ceph cluster for data storage and you are using Kubernetes, you might be interested in our newest software, the Koor Data Control Center. We are in beta and would love to get your feedback about what features would help you most with Ceph storage.\n\nThis describes what we have built so far [https://about.koor.tech/product](https://about.koor.tech/product) Anyone can install a free trial for up to 4 storage nodes. No time limits on the trial. If you want to contact us to give feedback or discuss your situation, here's our contact form: [https://about.koor.tech/contact](https://about.koor.tech/contact)\n\nAbove all, we like to be helpful. We will take any questions about data storage.\n\n&amp;#x200B;", "author_fullname": "t2_d321jhgdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on our beta product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ztwel", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700501502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you manage a Ceph cluster for data storage and you are using Kubernetes, you might be interested in our newest software, the Koor Data Control Center. We are in beta and would love to get your feedback about what features would help you most with Ceph storage.&lt;/p&gt;\n\n&lt;p&gt;This describes what we have built so far &lt;a href=\"https://about.koor.tech/product\"&gt;https://about.koor.tech/product&lt;/a&gt; Anyone can install a free trial for up to 4 storage nodes. No time limits on the trial. If you want to contact us to give feedback or discuss your situation, here&amp;#39;s our contact form: &lt;a href=\"https://about.koor.tech/contact\"&gt;https://about.koor.tech/contact&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Above all, we like to be helpful. We will take any questions about data storage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?auto=webp&amp;s=70f74026d1c62617c1774fde3e71a198fe95429d", "width": 1917, "height": 1128}, "resolutions": [{"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b71fdef9d0fabb53d097600bc3ab7d7f6f565df", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0051a2251507bf3c8f3d3a918df32a6b3ee5eaa2", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea722a7eb0e15c6607621bd2291d974d79fea9ec", "width": 320, "height": 188}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db500642a1e74c7bb9dd71b6259f3ccd448390dd", "width": 640, "height": 376}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c95104e6468850127d68f25b4f6be57fc808672d", "width": 960, "height": 564}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=767cdbd3ee81ba9aa47d29696b97de45fd694765", "width": 1080, "height": 635}], "variants": {}, "id": "W8LZN3dTBlBXOohUIv0rRWpk-U5tJSdTcj0Vl3FmcVI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17ztwel", "is_robot_indexable": true, "report_reasons": null, "author": "Dave-at-Koor", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ztwel/looking_for_feedback_on_our_beta_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ztwel/looking_for_feedback_on_our_beta_product/", "subreddit_subscribers": 140865, "created_utc": 1700501502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently researching on orchestrating   databricks workflows with airflow, and was just wondering what resources do i need and the cost implications of deploying airflow on azure for production", "author_fullname": "t2_jettu57pn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of implementing airflow in azure for production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zr1db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700494124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently researching on orchestrating   databricks workflows with airflow, and was just wondering what resources do i need and the cost implications of deploying airflow on azure for production&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zr1db", "is_robot_indexable": true, "report_reasons": null, "author": "Slight_Award8187", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zr1db/cost_of_implementing_airflow_in_azure_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zr1db/cost_of_implementing_airflow_in_azure_for/", "subreddit_subscribers": 140865, "created_utc": 1700494124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm a Data Engineer working at a small startup, where I am currently the only data engineer. As we're noticing an increase in our monthly RDS costs, I have a question regarding our current data pipeline setup, which involves transferring data from an AWS RDS PostgreSQL (operational database) to Databricks for analysis and reporting. To minimize any potential impact on the performance of our production environment,  we've opted to use a cloned instance of our production RDS as our data source. This clone is integrated into Databricks through a notebook job, where we handle the ELT. \n\nI'm exploring the most efficient and viable approaches for this task and would appreciate any insights or recommendations from the community. Here are some specific areas where I'm seeking advice:\n\n* Considering that I don't have much influence on our dev team to implement data dumping or queue services, my access is limited to the RDS prod instance, is using an RDS clone the optimal approach, or are there more efficient alternatives?\n* If real-time data refresh isn't a current requirement but might be in the future, what would be the best strategy to adopt now to accommodate potential future needs?\n* I'm considering the following alternative solutions:\n\n1. Periodic snapshots and export to S3.\n2. Using AWS Kinesis.\n3. Using AWS Data Migration Service (DMS).\n4. Continuing with the current method - creating an RDS clone instance for Databricks connection.\n5. Does any other way come to your mind?\n\nThanks in advance for your help.", "author_fullname": "t2_nzi7c4l6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transfer data from rds to Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1806uqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700535566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a Data Engineer working at a small startup, where I am currently the only data engineer. As we&amp;#39;re noticing an increase in our monthly RDS costs, I have a question regarding our current data pipeline setup, which involves transferring data from an AWS RDS PostgreSQL (operational database) to Databricks for analysis and reporting. To minimize any potential impact on the performance of our production environment,  we&amp;#39;ve opted to use a cloned instance of our production RDS as our data source. This clone is integrated into Databricks through a notebook job, where we handle the ELT. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m exploring the most efficient and viable approaches for this task and would appreciate any insights or recommendations from the community. Here are some specific areas where I&amp;#39;m seeking advice:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Considering that I don&amp;#39;t have much influence on our dev team to implement data dumping or queue services, my access is limited to the RDS prod instance, is using an RDS clone the optimal approach, or are there more efficient alternatives?&lt;/li&gt;\n&lt;li&gt;If real-time data refresh isn&amp;#39;t a current requirement but might be in the future, what would be the best strategy to adopt now to accommodate potential future needs?&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m considering the following alternative solutions:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Periodic snapshots and export to S3.&lt;/li&gt;\n&lt;li&gt;Using AWS Kinesis.&lt;/li&gt;\n&lt;li&gt;Using AWS Data Migration Service (DMS).&lt;/li&gt;\n&lt;li&gt;Continuing with the current method - creating an RDS clone instance for Databricks connection.&lt;/li&gt;\n&lt;li&gt;Does any other way come to your mind?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1806uqj", "is_robot_indexable": true, "report_reasons": null, "author": "next_helicopter2", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1806uqj/best_way_to_transfer_data_from_rds_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1806uqj/best_way_to_transfer_data_from_rds_to_databricks/", "subreddit_subscribers": 140865, "created_utc": 1700535566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\n&amp;#x200B;\n\nMy current org. is looking to implement a central data repository (data warehouse/lake/lakehouse). Being a municipal govt., we reached out to our counterparts who have implemented DW. Some have steered away from lake/lakehouse due to security concerns. I've done some researching and unable to determine what might be the best approach. We've accounting and financial, data in a database, payroll data coming from a cloud data lake. Then we've in house and cloud databases as well serving various divisions. Probably in the the future we might also incorporate sensors, images, videos and documents. But that is unclear if it needs to be or not.\n\nI don't know if DW is getting old and if there are newer or better systems in place. As we don't have this system yet, we do not have data engineers/architects.\n\n&amp;#x200B;\n\nIs there some questionnaire or some guide that can help choose the right architecture or systems. All I know is we need a central data repository to build an analytics platform for dashboards and reports and get insights from the data and solution must be scalable", "author_fullname": "t2_np3evoin", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Central Data Repository", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zzfgd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700516037.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700515464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current org. is looking to implement a central data repository (data warehouse/lake/lakehouse). Being a municipal govt., we reached out to our counterparts who have implemented DW. Some have steered away from lake/lakehouse due to security concerns. I&amp;#39;ve done some researching and unable to determine what might be the best approach. We&amp;#39;ve accounting and financial, data in a database, payroll data coming from a cloud data lake. Then we&amp;#39;ve in house and cloud databases as well serving various divisions. Probably in the the future we might also incorporate sensors, images, videos and documents. But that is unclear if it needs to be or not.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if DW is getting old and if there are newer or better systems in place. As we don&amp;#39;t have this system yet, we do not have data engineers/architects.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is there some questionnaire or some guide that can help choose the right architecture or systems. All I know is we need a central data repository to build an analytics platform for dashboards and reports and get insights from the data and solution must be scalable&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zzfgd", "is_robot_indexable": true, "report_reasons": null, "author": "naruzum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zzfgd/central_data_repository/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zzfgd/central_data_repository/", "subreddit_subscribers": 140865, "created_utc": 1700515464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone hope you are doing fine, currently I\u2019m using elastic search for aggregations and I\u2019m really new to this data engineering and I want to know what are the available alternatives to elastic search aggregation i don\u2019t use elastic search for search needs but only for aggregation need, since our dashboard is used by vast number of users I want a alternative which can support high throughput like elastic searches kindly advise me on what are can be alternatives", "author_fullname": "t2_g66aigmk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative for elastic search aggregation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ztrzu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700501198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone hope you are doing fine, currently I\u2019m using elastic search for aggregations and I\u2019m really new to this data engineering and I want to know what are the available alternatives to elastic search aggregation i don\u2019t use elastic search for search needs but only for aggregation need, since our dashboard is used by vast number of users I want a alternative which can support high throughput like elastic searches kindly advise me on what are can be alternatives&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ztrzu", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Bug8381", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ztrzu/alternative_for_elastic_search_aggregation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ztrzu/alternative_for_elastic_search_aggregation/", "subreddit_subscribers": 140865, "created_utc": 1700501198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A nice tutorial about how to handle big data datasets efficiently when building dataflows. It uses two open source Python libraries and the tutorial builds a data pipeline to analyze customer data.\n\n[https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f](https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f)\n\nI wanted your thoughts: what libraries do you use when typically faced with managing large datasets in back-end creation?\n\nEnjoy!", "author_fullname": "t2_tfe7ylgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to build dataflows with larger than memory datasets.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zsyw6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700499200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A nice tutorial about how to handle big data datasets efficiently when building dataflows. It uses two open source Python libraries and the tutorial builds a data pipeline to analyze customer data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f\"&gt;https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wanted your thoughts: what libraries do you use when typically faced with managing large datasets in back-end creation?&lt;/p&gt;\n\n&lt;p&gt;Enjoy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?auto=webp&amp;s=3b5e410f440e95a52a35878f677e9603657b64a7", "width": 800, "height": 333}, "resolutions": [{"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=554f3f06f4a57f57464438e79c0017dfc3de512c", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=128b12489ea024c1b350a98d2d4a95e05b071e2d", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bfadd51c7dbc9524d7b5103c028ef37c492339", "width": 320, "height": 133}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ebd738d6ced9cee838c6f9d82ef7a8a155c8298", "width": 640, "height": 266}], "variants": {}, "id": "HGI-vRG7wujMoeTFgVEM9JPE4QYiHX-A8ny5bWr0L4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17zsyw6", "is_robot_indexable": true, "report_reasons": null, "author": "quicklyalienated76", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zsyw6/learn_how_to_build_dataflows_with_larger_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zsyw6/learn_how_to_build_dataflows_with_larger_than/", "subreddit_subscribers": 140865, "created_utc": 1700499200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've never used Databricks or Spark in a production environment and have been thrown onto a project that is heavily using it. I'm coming from a rdbms-heavy background, so I approach things with a SQL-like approach and have done a decent amount of query optimization.\n\nHowever I'm a little lost on deciphering Spark logical plans using the output of `df.explain`. I've tried `df.explain(True)` and I can't even figure out the difference between the Parsed Logical Plan, Analyzed Logical Plan, Optimized Logical Plan, and Physical Plan.\n\nWhat are some things I should try to avoid? From what I've learned, I should avoid shuffling, avoid skewed joins, and optimize my partitions. But I'm not even doing any joins in a notebook I'm working with. I'd appreciate suggestions, best practices, or anything to tweak my notebooks based on what I see in a physical plan.\n\nAlso, does anyone have suggestions on how to read a large data source and quickly filter it down? I'm trying to test some code but it's insanely slow (taking &gt; 1 hour) even when I try to filter it down and limit it as early as possible.", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Databricks (and Spark in general) - how do I decipher logical plans and update my notebook/script accordingly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zs8at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700497270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never used Databricks or Spark in a production environment and have been thrown onto a project that is heavily using it. I&amp;#39;m coming from a rdbms-heavy background, so I approach things with a SQL-like approach and have done a decent amount of query optimization.&lt;/p&gt;\n\n&lt;p&gt;However I&amp;#39;m a little lost on deciphering Spark logical plans using the output of &lt;code&gt;df.explain&lt;/code&gt;. I&amp;#39;ve tried &lt;code&gt;df.explain(True)&lt;/code&gt; and I can&amp;#39;t even figure out the difference between the Parsed Logical Plan, Analyzed Logical Plan, Optimized Logical Plan, and Physical Plan.&lt;/p&gt;\n\n&lt;p&gt;What are some things I should try to avoid? From what I&amp;#39;ve learned, I should avoid shuffling, avoid skewed joins, and optimize my partitions. But I&amp;#39;m not even doing any joins in a notebook I&amp;#39;m working with. I&amp;#39;d appreciate suggestions, best practices, or anything to tweak my notebooks based on what I see in a physical plan.&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone have suggestions on how to read a large data source and quickly filter it down? I&amp;#39;m trying to test some code but it&amp;#39;s insanely slow (taking &amp;gt; 1 hour) even when I try to filter it down and limit it as early as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zs8at", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zs8at/new_to_databricks_and_spark_in_general_how_do_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zs8at/new_to_databricks_and_spark_in_general_how_do_i/", "subreddit_subscribers": 140865, "created_utc": 1700497270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I'm about 4 years removed from college at my second job, both have been relatively early startups. My first title was DE Engineer and now I am an ML engineer. Neither title really encapsulates what I do as I've been involved in architecting two end-to-end data pipelines, building labeling tools, integrating ml models into the production code base, A LOT of web scraping (node, puppeteer), various IaC projects (terraform for aws resources, databricks, etc.).\n\nI'm looking for a new job, but really just don't feel like I belong in any of the positions I see. For example, I mostly do software engineering, but don't go as low level as a lot of the dedicated SE engineers at the company. I work day to day on the data science team, but don't actually do any modeling (mostly handle the data, retrain pipelines, labeling tools, implementation, liaison between teams, etc.). I feel like a competent high level data engineer because of what I have built top to bottom (data lake, aws dms, data warehouse, delta lake, etc), but really don't touch these tech stacks on a day to day anymore. As you can see I am having a hard time figuring out where/what to apply to because I've become very much a jack of all trades and master of none (which I enjoy a lot).\n\nHave any of you gone through this experience and have any advice. While I like having been able to try so many new things, I worry my lack of specializing in any one thing is hindering my career advancement.", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not sure what I should apply for", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18070j2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700536041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;m about 4 years removed from college at my second job, both have been relatively early startups. My first title was DE Engineer and now I am an ML engineer. Neither title really encapsulates what I do as I&amp;#39;ve been involved in architecting two end-to-end data pipelines, building labeling tools, integrating ml models into the production code base, A LOT of web scraping (node, puppeteer), various IaC projects (terraform for aws resources, databricks, etc.).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a new job, but really just don&amp;#39;t feel like I belong in any of the positions I see. For example, I mostly do software engineering, but don&amp;#39;t go as low level as a lot of the dedicated SE engineers at the company. I work day to day on the data science team, but don&amp;#39;t actually do any modeling (mostly handle the data, retrain pipelines, labeling tools, implementation, liaison between teams, etc.). I feel like a competent high level data engineer because of what I have built top to bottom (data lake, aws dms, data warehouse, delta lake, etc), but really don&amp;#39;t touch these tech stacks on a day to day anymore. As you can see I am having a hard time figuring out where/what to apply to because I&amp;#39;ve become very much a jack of all trades and master of none (which I enjoy a lot).&lt;/p&gt;\n\n&lt;p&gt;Have any of you gone through this experience and have any advice. While I like having been able to try so many new things, I worry my lack of specializing in any one thing is hindering my career advancement.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "18070j2", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18070j2/not_sure_what_i_should_apply_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18070j2/not_sure_what_i_should_apply_for/", "subreddit_subscribers": 140865, "created_utc": 1700536041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hey guys, I came across this interview question for Data pipeline design. Here is the question - Design a data pipeline for a user report dashboard that shows the need-to-know top Alexa user requests by different countries every hour. I want to understand  \n\n\n1. What clarifying questions to ask before approaching to solve the question ?\n2. how to approach this question ?\n\nAny guidelines or reference article would be appreciated. ", "author_fullname": "t2_73dz6l8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach a Data pipeline design question in Interview ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1801h2u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700520359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I came across this interview question for Data pipeline design. Here is the question - Design a data pipeline for a user report dashboard that shows the need-to-know top Alexa user requests by different countries every hour. I want to understand  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What clarifying questions to ask before approaching to solve the question ?&lt;/li&gt;\n&lt;li&gt;how to approach this question ?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any guidelines or reference article would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1801h2u", "is_robot_indexable": true, "report_reasons": null, "author": "indie_morty", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1801h2u/how_to_approach_a_data_pipeline_design_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1801h2u/how_to_approach_a_data_pipeline_design_question/", "subreddit_subscribers": 140865, "created_utc": 1700520359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all. I have started a new position in a company, pretty much first engineer in this division and holy crap am I running through walls. Anyways stack is Azure with ADF, blob storage and sql dB, bringing on databricks as we will be doing some pretty complex transformations and a hell of alot of forecasting, modelling, and eventually some deeper ML/AI.\n\nTo the problem, I need to go through IT for every little thing... it's driving me nuts. So off the bat, can you guys suggest what I should be asking them to sort out for databricks. So far I have the following:\n\n1. Make sure storage information like client ID tenant ID etc. Is sorted and available in key vault\n2. Need them to up the allocation on the VM from 10 to 150 I think in dev environment\n3. Connection to sql which will serve as data mart (would like to have them going straight to dbfs but that seems to scare the hell outta people right now)\n\n\nHmmmm can't really think of things straight off the top of my head, usually I just sorted these issues as they come along but it is a weird divorce of responsibilities and IT just don't really have an idea.\n\nI know people have tons of views on databricks, data factory etc. Right now, I just need some help on what's there, just get up and going on the strategic choices that were made.\n\nThanks guys", "author_fullname": "t2_ibg9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks (Azure) setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zzxz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700516683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all. I have started a new position in a company, pretty much first engineer in this division and holy crap am I running through walls. Anyways stack is Azure with ADF, blob storage and sql dB, bringing on databricks as we will be doing some pretty complex transformations and a hell of alot of forecasting, modelling, and eventually some deeper ML/AI.&lt;/p&gt;\n\n&lt;p&gt;To the problem, I need to go through IT for every little thing... it&amp;#39;s driving me nuts. So off the bat, can you guys suggest what I should be asking them to sort out for databricks. So far I have the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Make sure storage information like client ID tenant ID etc. Is sorted and available in key vault&lt;/li&gt;\n&lt;li&gt;Need them to up the allocation on the VM from 10 to 150 I think in dev environment&lt;/li&gt;\n&lt;li&gt;Connection to sql which will serve as data mart (would like to have them going straight to dbfs but that seems to scare the hell outta people right now)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Hmmmm can&amp;#39;t really think of things straight off the top of my head, usually I just sorted these issues as they come along but it is a weird divorce of responsibilities and IT just don&amp;#39;t really have an idea.&lt;/p&gt;\n\n&lt;p&gt;I know people have tons of views on databricks, data factory etc. Right now, I just need some help on what&amp;#39;s there, just get up and going on the strategic choices that were made.&lt;/p&gt;\n\n&lt;p&gt;Thanks guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zzxz9", "is_robot_indexable": true, "report_reasons": null, "author": "SimpleNoodle", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zzxz9/databricks_azure_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zzxz9/databricks_azure_setup/", "subreddit_subscribers": 140865, "created_utc": 1700516683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am just confused between which one to pick , that's why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.", "author_fullname": "t2_s0gygp2m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one has higher pay is it azure data engineer or GCP data engineer in India and in USA? Experienced people kindly also mention the pay , we ll able to know how much we ll be getting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zmuko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.32, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700481183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just confused between which one to pick , that&amp;#39;s why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zmuko", "is_robot_indexable": true, "report_reasons": null, "author": "Current_Baseball_418", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "subreddit_subscribers": 140865, "created_utc": 1700481183.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}