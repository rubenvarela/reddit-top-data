{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title is the question, how would you change the mind of someone who is ambivalent?", "author_fullname": "t2_eanzp1mp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you sell the value of Data Engineering at your org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yy1wp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700403187.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title is the question, how would you change the mind of someone who is ambivalent?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17yy1wp", "is_robot_indexable": true, "report_reasons": null, "author": "DesperateForAnalysex", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yy1wp/how_do_you_sell_the_value_of_data_engineering_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yy1wp/how_do_you_sell_the_value_of_data_engineering_at/", "subreddit_subscribers": 140695, "created_utc": 1700403187.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you define milestones of your projects so that it is easier to **deliver tangible results** to the business in *smaller chunks*?\n\nI find it easier to do such a thing in *web development* ie. A single web page can be divided into several smaller parts like header, footer, sidebar, cards\u2026 you get the point \u2013 which when presented to the stakeholders signifies an increase to the *progression* of the project. \n\n**How can we do it in Data Engineering Projects?**\n\n*A. We can slice it per **Pipeline component** for instance:*\n\n- Extraction/Ingestion\n- Transformation\n- Validation\n- Aggregation\n- Presentation\n\nThe first 4 points will make sense to a technical person, and only the last point a non-tech person will acknowledge well.\n\n*B. On the other hand, particular to Data Warehousing projects. It would make sense to slice it per **Table (dimension / facts)**.*\n\n- dim_customer\n- dim_product\n- dim_geolocation\n- \u2026\n- fact_orders\n\nThen we can deliver 1 table at a time and show to them the presentation layer with *proxy/mock data* in the undelivered tables.", "author_fullname": "t2_85ty6e1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Defining Data Engineering Project Milestones", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z2gl8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700416277.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700415787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you define milestones of your projects so that it is easier to &lt;strong&gt;deliver tangible results&lt;/strong&gt; to the business in &lt;em&gt;smaller chunks&lt;/em&gt;?&lt;/p&gt;\n\n&lt;p&gt;I find it easier to do such a thing in &lt;em&gt;web development&lt;/em&gt; ie. A single web page can be divided into several smaller parts like header, footer, sidebar, cards\u2026 you get the point \u2013 which when presented to the stakeholders signifies an increase to the &lt;em&gt;progression&lt;/em&gt; of the project. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How can we do it in Data Engineering Projects?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;A. We can slice it per *&lt;/em&gt;Pipeline component** for instance:*&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Extraction/Ingestion&lt;/li&gt;\n&lt;li&gt;Transformation&lt;/li&gt;\n&lt;li&gt;Validation&lt;/li&gt;\n&lt;li&gt;Aggregation&lt;/li&gt;\n&lt;li&gt;Presentation&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The first 4 points will make sense to a technical person, and only the last point a non-tech person will acknowledge well.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;B. On the other hand, particular to Data Warehousing projects. It would make sense to slice it per *&lt;/em&gt;Table (dimension / facts)*&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;dim_customer&lt;/li&gt;\n&lt;li&gt;dim_product&lt;/li&gt;\n&lt;li&gt;dim_geolocation&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;li&gt;fact_orders&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Then we can deliver 1 table at a time and show to them the presentation layer with &lt;em&gt;proxy/mock data&lt;/em&gt; in the undelivered tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17z2gl8", "is_robot_indexable": true, "report_reasons": null, "author": "BestBlackberry1314", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z2gl8/defining_data_engineering_project_milestones/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z2gl8/defining_data_engineering_project_milestones/", "subreddit_subscribers": 140695, "created_utc": 1700415787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to know your thoughts on Apache Hive. Is it still actively used in your projects and overall relevant to the field, or it became obsolete and you have transitioned to other tools and technologies? Share your experiences and insights pls", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Hive still being used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zgbfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700454659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to know your thoughts on Apache Hive. Is it still actively used in your projects and overall relevant to the field, or it became obsolete and you have transitioned to other tools and technologies? Share your experiences and insights pls&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zgbfg", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zgbfg/is_apache_hive_still_being_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zgbfg/is_apache_hive_still_being_used/", "subreddit_subscribers": 140695, "created_utc": 1700454659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\nI just started at a new company using Databricks and I'm kinda new to it. They asked me to define a nomenclature for Catalogs, Databases and Tables given one single use case :/  \n\n\nThe use case is quite simple :\n\nWe have a single raw data source coming from Azure Event Hub, let's call it TRUTH.\n\nUsing this single raw data, we're gonna create multiple silver layer tables which will serve multiple gold layer tables.\n\nBasically it looks like this:\n\nhttps://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;format=png&amp;auto=webp&amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf\n\nGiven the description of Unity Catalog in the official doc :\n\n&gt; Unity Catalog provides centralized access control, auditing, lineage, and data discovery capabilities across Databricks workspaces. \n\nDoes it means that each of the \"Bunch of Gold tables\" should be a Separate Unity Catalog. \n\n* \"Team 1\" for Red\n* \"Team 2\" for Green\n* \"Team 3\" for Blue\n\nIf doing so, I don't see what kind of nomenclature I would have for Databases, I mean each Team's Golden uses multiple silver data, so I can't really have like a silver database and golden database on each unity catalog.\n\nOr should I make like one single unity catalog for the whole use case then make :\n\n1. One Database for the Raw Data, with a single table\n2. One database for the Silver Data, with n silver tables\n3. X databases for the Gold Data, one per team, each database will have Y number of gold tables\n\nCan you let me know what do you think of this two approaches, or maybe suggest some other ?  \nI hope I've explained the problem properly, If not, please don't hesitate to ask me any questions. Thanks !", "author_fullname": "t2_a6b9szlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Design Unity Catalog, Databases and Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"5zlj8kmmfb1c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8f7daf248c35146d3cd9b60240f8ab7861287871"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=37e3e940a43786004989a06064679cbc51b802b8"}, {"y": 173, "x": 320, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=87faca5a7f6b0cfcb4940cd16b992db184b2ce55"}, {"y": 346, "x": 640, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=77254c6330af9881644a7920746bf3601090e772"}], "s": {"y": 401, "x": 741, "u": "https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;format=png&amp;auto=webp&amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf"}, "id": "5zlj8kmmfb1c1"}}, "name": "t3_17yyrio", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TSsaipfCcVUB-8gDwmbIBrroO0pBxX9bzbnbSIX2fe0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700405296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I just started at a new company using Databricks and I&amp;#39;m kinda new to it. They asked me to define a nomenclature for Catalogs, Databases and Tables given one single use case :/  &lt;/p&gt;\n\n&lt;p&gt;The use case is quite simple :&lt;/p&gt;\n\n&lt;p&gt;We have a single raw data source coming from Azure Event Hub, let&amp;#39;s call it TRUTH.&lt;/p&gt;\n\n&lt;p&gt;Using this single raw data, we&amp;#39;re gonna create multiple silver layer tables which will serve multiple gold layer tables.&lt;/p&gt;\n\n&lt;p&gt;Basically it looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf\"&gt;https://preview.redd.it/5zlj8kmmfb1c1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3cbbcd135994b30eab21be6b8650b71017b026cf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Given the description of Unity Catalog in the official doc :&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Unity Catalog provides centralized access control, auditing, lineage, and data discovery capabilities across Databricks workspaces. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Does it means that each of the &amp;quot;Bunch of Gold tables&amp;quot; should be a Separate Unity Catalog. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Team 1&amp;quot; for Red&lt;/li&gt;\n&lt;li&gt;&amp;quot;Team 2&amp;quot; for Green&lt;/li&gt;\n&lt;li&gt;&amp;quot;Team 3&amp;quot; for Blue&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If doing so, I don&amp;#39;t see what kind of nomenclature I would have for Databases, I mean each Team&amp;#39;s Golden uses multiple silver data, so I can&amp;#39;t really have like a silver database and golden database on each unity catalog.&lt;/p&gt;\n\n&lt;p&gt;Or should I make like one single unity catalog for the whole use case then make :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;One Database for the Raw Data, with a single table&lt;/li&gt;\n&lt;li&gt;One database for the Silver Data, with n silver tables&lt;/li&gt;\n&lt;li&gt;X databases for the Gold Data, one per team, each database will have Y number of gold tables&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Can you let me know what do you think of this two approaches, or maybe suggest some other ?&lt;br/&gt;\nI hope I&amp;#39;ve explained the problem properly, If not, please don&amp;#39;t hesitate to ask me any questions. Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yyrio", "is_robot_indexable": true, "report_reasons": null, "author": "TheFragan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yyrio/databricks_design_unity_catalog_databases_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yyrio/databricks_design_unity_catalog_databases_and/", "subreddit_subscribers": 140695, "created_utc": 1700405296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, like to ask about the potential and the pitfall for using both the DataFrame method and Spark SQL method (with dbt) simultaneously.\n\nOur current setup is getting the data through streaming (through Kafka; with Hudi streaming solution) and processing it with PySpark. The team built all this with the traditional PySpark DataFrame method for processing transactional records. \n\nNow, we are considering implementing dbt in the process for the new analytics models (and for better governance/lineage, allowing analysts to develop models for BI later on). It sounds good in theory but personally, I have never heard of anyone combining both methods in this way, so I wonder:\n\n1. Is there a best method to include dbt in our current process (My thought is not touching the established pipelines and just adding new dbt actions for BI after the original pipelines finish; basically building a dbt project in the current repo and triggering it after the spark job finishes)\n2. Is there a way to \"include\" the established DataFrame pipeline in the dbt framework without rewriting the whole thing in SQL (for the data lineage and catalog purposes)? I am not sure how UDFs in PySpark work in the dbt framework so don't like to commit to rewriting the whole thing\n\nI would appreciate any suggestions or even examples of similar solutions. Thanks!", "author_fullname": "t2_23fqgpxi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark ETL with both DataFrames and SQL (with dbt)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yy9d4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700403815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, like to ask about the potential and the pitfall for using both the DataFrame method and Spark SQL method (with dbt) simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Our current setup is getting the data through streaming (through Kafka; with Hudi streaming solution) and processing it with PySpark. The team built all this with the traditional PySpark DataFrame method for processing transactional records. &lt;/p&gt;\n\n&lt;p&gt;Now, we are considering implementing dbt in the process for the new analytics models (and for better governance/lineage, allowing analysts to develop models for BI later on). It sounds good in theory but personally, I have never heard of anyone combining both methods in this way, so I wonder:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a best method to include dbt in our current process (My thought is not touching the established pipelines and just adding new dbt actions for BI after the original pipelines finish; basically building a dbt project in the current repo and triggering it after the spark job finishes)&lt;/li&gt;\n&lt;li&gt;Is there a way to &amp;quot;include&amp;quot; the established DataFrame pipeline in the dbt framework without rewriting the whole thing in SQL (for the data lineage and catalog purposes)? I am not sure how UDFs in PySpark work in the dbt framework so don&amp;#39;t like to commit to rewriting the whole thing&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would appreciate any suggestions or even examples of similar solutions. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yy9d4", "is_robot_indexable": true, "report_reasons": null, "author": "HiIamGeoff", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yy9d4/pyspark_etl_with_both_dataframes_and_sql_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yy9d4/pyspark_etl_with_both_dataframes_and_sql_with_dbt/", "subreddit_subscribers": 140695, "created_utc": 1700403815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new to the data engineering field, I'm currently working on a project to migrate customer data from SAP to the AWS Cloud. The data comes into a S3 bucket and we are using AWS Glue for data transformations and cleaning before loading it into an RDS instance (MySQL). I'm seeking advice/ideas on the industry best practices for implementing robust data quality checks before the data is moved into the database. How to maintain data quality during both a data migration project and ongoing data integration?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ud1bwgro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practice for Data Quality Checks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17za67d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700436234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new to the data engineering field, I&amp;#39;m currently working on a project to migrate customer data from SAP to the AWS Cloud. The data comes into a S3 bucket and we are using AWS Glue for data transformations and cleaning before loading it into an RDS instance (MySQL). I&amp;#39;m seeking advice/ideas on the industry best practices for implementing robust data quality checks before the data is moved into the database. How to maintain data quality during both a data migration project and ongoing data integration?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17za67d", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Crew385", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17za67d/best_practice_for_data_quality_checks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17za67d/best_practice_for_data_quality_checks/", "subreddit_subscribers": 140695, "created_utc": 1700436234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've built a basic ETL pipeline with the following steps\n\n1. Ingest data from an air-quality API [OpenAQ](https://openaq.org) daily to get the previous days data for a specific region.\n2. Apply some transformations like changing datatypes and dropping columns\n3. Load the data into a GCS bucket partitioned by date\n4. Move the data into Bigquery from the GCS Bucket\n5. Created a simple dashboard using Looker Studio [Air Quality Dashboard](https://lookerstudio.google.com/reporting/2f9695b2-01ca-4ffe-a905-4c04f33b4a12)\n6. Used prefect to orchestrate the flow and deploy it at a specific time everyday as a docker container.\n\nThe dashboard is a very basic one. But i wanted to concentrate more on the ETL part of it. It would be great to get some feedback/suggestions on how to improve and what should I focus on learning next?\n\nI currently have one difficulty that is I run this on a google cloud VM and i have to manually start it, start prefect server, start an agent manually for this to work. I can't have the VM running all the time as I only plan to use my free credits. So is there any way to automate this process?", "author_fullname": "t2_w16t5qhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback and suggestions on a personal project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z1hc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700413069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve built a basic ETL pipeline with the following steps&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Ingest data from an air-quality API &lt;a href=\"https://openaq.org\"&gt;OpenAQ&lt;/a&gt; daily to get the previous days data for a specific region.&lt;/li&gt;\n&lt;li&gt;Apply some transformations like changing datatypes and dropping columns&lt;/li&gt;\n&lt;li&gt;Load the data into a GCS bucket partitioned by date&lt;/li&gt;\n&lt;li&gt;Move the data into Bigquery from the GCS Bucket&lt;/li&gt;\n&lt;li&gt;Created a simple dashboard using Looker Studio &lt;a href=\"https://lookerstudio.google.com/reporting/2f9695b2-01ca-4ffe-a905-4c04f33b4a12\"&gt;Air Quality Dashboard&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Used prefect to orchestrate the flow and deploy it at a specific time everyday as a docker container.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The dashboard is a very basic one. But i wanted to concentrate more on the ETL part of it. It would be great to get some feedback/suggestions on how to improve and what should I focus on learning next?&lt;/p&gt;\n\n&lt;p&gt;I currently have one difficulty that is I run this on a google cloud VM and i have to manually start it, start prefect server, start an agent manually for this to work. I can&amp;#39;t have the VM running all the time as I only plan to use my free credits. So is there any way to automate this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uhdTEewoFeBawh26EL08YBYOj3My2IdGMHqYGZIRXig.jpg?auto=webp&amp;s=180e06f53c456a3c84844c9aaee4751552b785a1", "width": 800, "height": 678}, "resolutions": [{"url": "https://external-preview.redd.it/uhdTEewoFeBawh26EL08YBYOj3My2IdGMHqYGZIRXig.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=298ef1be6355d1c09b5e3b4ef7725ca1811fd09d", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/uhdTEewoFeBawh26EL08YBYOj3My2IdGMHqYGZIRXig.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e98f0f002f0248afecf3e187f03e690e839c2ba0", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/uhdTEewoFeBawh26EL08YBYOj3My2IdGMHqYGZIRXig.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65dffe78435a3cd98b642eaa4fc2a7753e795891", "width": 320, "height": 271}, {"url": "https://external-preview.redd.it/uhdTEewoFeBawh26EL08YBYOj3My2IdGMHqYGZIRXig.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=efcf15ae152161d19f7a88f839b6fa253e76ee33", "width": 640, "height": 542}], "variants": {}, "id": "sdYBQiH4J0OJl4O5UCiHKKO3rnuBoLlX4QSJTcUiuSg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17z1hc2", "is_robot_indexable": true, "report_reasons": null, "author": "booberrypie_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17z1hc2/looking_for_feedback_and_suggestions_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z1hc2/looking_for_feedback_and_suggestions_on_a/", "subreddit_subscribers": 140695, "created_utc": 1700413069.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.\n\nNow, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).\n\nIn fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?", "author_fullname": "t2_f4h6309d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering guidance (AWS vs AZURE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk9u0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.&lt;/p&gt;\n\n&lt;p&gt;Now, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).&lt;/p&gt;\n\n&lt;p&gt;In fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zk9u0", "is_robot_indexable": true, "report_reasons": null, "author": "paisa_byte", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "subreddit_subscribers": 140695, "created_utc": 1700470607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have built a fact table that tracks an invoice for each day from when it is issued, to when it is paid. This is the lowest granularity the business needs.\n\nThis is to track certain attributes on the invoice for any given day, and hence acts as a form of CDC with daily snapshots.\n\nMy question is, how would I build a dimensional model for this? Is the best approach to create a dimension table based on invoice ID and day, and have a 1-1 relationship between fact and dimension table? Or am I approaching this the wrong way?", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a dimension table for a daily fact table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zjekz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700466765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have built a fact table that tracks an invoice for each day from when it is issued, to when it is paid. This is the lowest granularity the business needs.&lt;/p&gt;\n\n&lt;p&gt;This is to track certain attributes on the invoice for any given day, and hence acts as a form of CDC with daily snapshots.&lt;/p&gt;\n\n&lt;p&gt;My question is, how would I build a dimensional model for this? Is the best approach to create a dimension table based on invoice ID and day, and have a 1-1 relationship between fact and dimension table? Or am I approaching this the wrong way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zjekz", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zjekz/how_to_build_a_dimension_table_for_a_daily_fact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zjekz/how_to_build_a_dimension_table_for_a_daily_fact/", "subreddit_subscribers": 140695, "created_utc": 1700466765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The GCP DE certification exam has changed it\u2019s exam guide topics effective Nov 23. Can anyone here who has attended the new version of the cert exam give their feedback on the new exam pattern and how easy/hard it was?", "author_fullname": "t2_vl617oe9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Data Engineer Certification Nov 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zj163", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700465130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The GCP DE certification exam has changed it\u2019s exam guide topics effective Nov 23. Can anyone here who has attended the new version of the cert exam give their feedback on the new exam pattern and how easy/hard it was?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zj163", "is_robot_indexable": true, "report_reasons": null, "author": "DohaerasVagar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zj163/gcp_data_engineer_certification_nov_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zj163/gcp_data_engineer_certification_nov_2023/", "subreddit_subscribers": 140695, "created_utc": 1700465130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/17zaei5)", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineers of Reddit, (5+ YoE) what is your next career goal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zaei5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700436862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17zaei5\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zaei5", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1700609662968, "options": [{"text": "Senior+ (Architecture, Staff, Principal)", "id": "26079152"}, {"text": "Management (EM, PO, PO)", "id": "26079153"}, {"text": "Other Tech Role (SWE, DevOps etc.)", "id": "26079154"}, {"text": "Data Science or ML", "id": "26079155"}, {"text": "Analytics or BI", "id": "26079156"}, {"text": "No goal", "id": "26079157"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 254, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zaei5/senior_data_engineers_of_reddit_5_yoe_what_is/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/17zaei5/senior_data_engineers_of_reddit_5_yoe_what_is/", "subreddit_subscribers": 140695, "created_utc": 1700436862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I ran across this website:\n\n[https://stateofdb.com/databases](https://stateofdb.com/databases)\n\nThought I'd ask everyone if they have seen site? Do you think this is a comprehensive list of DB's, providers, and Warehouses? Does anything surprise you in these rankings? \n\nI know Postgres is popular, but surprised that it tops the lists. I work as a data analyst and I don't think I've seen a Postgres DB actually used in the financial industry. I'm sure someone somewhere in these large institutions are using it, but I haven't seen it. ", "author_fullname": "t2_djjvfxs96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State of DB website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z5ofp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700424550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I ran across this website:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://stateofdb.com/databases\"&gt;https://stateofdb.com/databases&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thought I&amp;#39;d ask everyone if they have seen site? Do you think this is a comprehensive list of DB&amp;#39;s, providers, and Warehouses? Does anything surprise you in these rankings? &lt;/p&gt;\n\n&lt;p&gt;I know Postgres is popular, but surprised that it tops the lists. I work as a data analyst and I don&amp;#39;t think I&amp;#39;ve seen a Postgres DB actually used in the financial industry. I&amp;#39;m sure someone somewhere in these large institutions are using it, but I haven&amp;#39;t seen it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?auto=webp&amp;s=316ad5b1826ec7ff5dbe7e1e579a479201d1d133", "width": 887, "height": 584}, "resolutions": [{"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0426761a7ab4f4d6e3380f1af41b782939f315e", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d425877bc6524ee6c9291c6d0848c8a51371a02", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=03aff174b673b182fba916a90a3ce3c2038b3b56", "width": 320, "height": 210}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f5c3f28ad0813e3e1ff51973cc1687c42d3c8d9", "width": 640, "height": 421}], "variants": {}, "id": "FBBD2314yNHq6sOCpDaENKMEcOYXTmbCkhx6pskDd_o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17z5ofp", "is_robot_indexable": true, "report_reasons": null, "author": "Oh_Another_Thing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z5ofp/state_of_db_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z5ofp/state_of_db_website/", "subreddit_subscribers": 140695, "created_utc": 1700424550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nIn my (big) company, they are using Jira and they decided to develop a simple analytics tool to replace Excel extracts people are doing by themselves. There is already a PostgreSQL to nightly replicate a part of the Jira data. The chosen stack : an Elasticsearch cluster, Logstash to collect data from PostgreSQL, Kibana to display dashboards.\n\nI am not a specialist, but it feels like a weird choice. Is Elastic a good fit for such a task?\n\nWhy not a simple columnar database (ClickHouse, StarRocks) to replace the PostgreSQL replica + the Elastic cluster? ", "author_fullname": "t2_14l2yd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elasticsearch for simple analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z18uf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700412405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;In my (big) company, they are using Jira and they decided to develop a simple analytics tool to replace Excel extracts people are doing by themselves. There is already a PostgreSQL to nightly replicate a part of the Jira data. The chosen stack : an Elasticsearch cluster, Logstash to collect data from PostgreSQL, Kibana to display dashboards.&lt;/p&gt;\n\n&lt;p&gt;I am not a specialist, but it feels like a weird choice. Is Elastic a good fit for such a task?&lt;/p&gt;\n\n&lt;p&gt;Why not a simple columnar database (ClickHouse, StarRocks) to replace the PostgreSQL replica + the Elastic cluster? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17z18uf", "is_robot_indexable": true, "report_reasons": null, "author": "Kamino72", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z18uf/elasticsearch_for_simple_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z18uf/elasticsearch_for_simple_analytics/", "subreddit_subscribers": 140695, "created_utc": 1700412405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi everyone\n\nI have been developing a data analytics engine, and I'd like to know if the following factors would make you interested in using it?\n\n* Execute fast queries on large datasets - the response time for query on large dataset is less than 200 milliseconds.\n* Supports very complex queries - including a variety of mathematical logic, functions, and cross-model analysis.\n* Lower operating costs - save 30% on server purchases.\n\nOr is it something else? Or will you never use a new open source product?", "author_fullname": "t2_o7wu1lyr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Under what circumstances would you try to use a new open-source data analytics engine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17yxfr6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700401245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi everyone&lt;/p&gt;\n\n&lt;p&gt;I have been developing a data analytics engine, and I&amp;#39;d like to know if the following factors would make you interested in using it?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Execute fast queries on large datasets - the response time for query on large dataset is less than 200 milliseconds.&lt;/li&gt;\n&lt;li&gt;Supports very complex queries - including a variety of mathematical logic, functions, and cross-model analysis.&lt;/li&gt;\n&lt;li&gt;Lower operating costs - save 30% on server purchases.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or is it something else? Or will you never use a new open source product?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17yxfr6", "is_robot_indexable": true, "report_reasons": null, "author": "sahara-guy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17yxfr6/under_what_circumstances_would_you_try_to_use_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17yxfr6/under_what_circumstances_would_you_try_to_use_a/", "subreddit_subscribers": 140695, "created_utc": 1700401245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,  \n\n\nI'm learning about DE, currently reading Kimball's The Data Warehouse Toolkit to learn about data warehousing. Are there any popular books/resources like this for learning Data Lake design/architecture?", "author_fullname": "t2_133hadn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a data lake (in S3)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zkg70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700471368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m learning about DE, currently reading Kimball&amp;#39;s The Data Warehouse Toolkit to learn about data warehousing. Are there any popular books/resources like this for learning Data Lake design/architecture?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zkg70", "is_robot_indexable": true, "report_reasons": null, "author": "generalNomnom", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zkg70/how_to_build_a_data_lake_in_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zkg70/how_to_build_a_data_lake_in_s3/", "subreddit_subscribers": 140695, "created_utc": 1700471368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jboiz9k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get real-time AI assistant alerts with changes in Google Docs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17zjfot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3RBmbxS4QZdPavgMc7NASjWeb5QJ4ch0iK3EIMX_eQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700466900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pathway.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pathway.com/developers/showcases/llm-alert-pathway/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?auto=webp&amp;s=bb142a79431022a27a6ccabda60c67e9d9996dae", "width": 768, "height": 581}, "resolutions": [{"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac1817573346e5b19274ed78e5e5dfcfe8c9794f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07ffeab24b4d4bd15d99bb81dd3e8f72561881f5", "width": 216, "height": 163}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe7efbcd67d7e2615448eecae2cd4da1f003f627", "width": 320, "height": 242}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=886a54fa5caee12febbd2064362c657b257e28ef", "width": 640, "height": 484}], "variants": {}, "id": "UIiH3TzxPBFekdQEoqNUB3DAUECkNeH8pyrVzlpGcoY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17zjfot", "is_robot_indexable": true, "report_reasons": null, "author": "bumurzokov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zjfot/how_to_get_realtime_ai_assistant_alerts_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pathway.com/developers/showcases/llm-alert-pathway/", "subreddit_subscribers": 140695, "created_utc": 1700466900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interviewing for a Sr DE role and made it to some cross functional interviews. I'm sure a lot of it is trying to gauge my communication and experiences working with other teams, but recruiter mentioned the DS one can be technical (although given a short 30 min time frame, probably not active coding). \n\nWhat would you expect from these conversations, talking to a data scientist and a product manager? Just trying to brainstorm ideas of what to keep in mind / brush up on.", "author_fullname": "t2_5q6un", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross functional interview for Sr DE role with data science and product folks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ziuh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700464331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interviewing for a Sr DE role and made it to some cross functional interviews. I&amp;#39;m sure a lot of it is trying to gauge my communication and experiences working with other teams, but recruiter mentioned the DS one can be technical (although given a short 30 min time frame, probably not active coding). &lt;/p&gt;\n\n&lt;p&gt;What would you expect from these conversations, talking to a data scientist and a product manager? Just trying to brainstorm ideas of what to keep in mind / brush up on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17ziuh4", "is_robot_indexable": true, "report_reasons": null, "author": "vitalemontea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ziuh4/cross_functional_interview_for_sr_de_role_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ziuh4/cross_functional_interview_for_sr_de_role_with/", "subreddit_subscribers": 140695, "created_utc": 1700464331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm new in this area, trying to make the conversion from BI to DE.\n\nI have the following problem, the company ERP uses a MySQL 5 database on the company local server and I'm building a SQL Server DW on the same server, I have to automate the ETL from one database to another, preferably with open source tools or low cost tools.\n\nI'm wondering which is the best way to do this, I'm exploring the SSIS option but perhaps there is a better way or something similar but more convenient or useful to learn at this time.\n\nThank you very much for your answers.", "author_fullname": "t2_9bsrz4l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to sync data between SQL Server and MySQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zb8dm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700439143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m new in this area, trying to make the conversion from BI to DE.&lt;/p&gt;\n\n&lt;p&gt;I have the following problem, the company ERP uses a MySQL 5 database on the company local server and I&amp;#39;m building a SQL Server DW on the same server, I have to automate the ETL from one database to another, preferably with open source tools or low cost tools.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering which is the best way to do this, I&amp;#39;m exploring the SSIS option but perhaps there is a better way or something similar but more convenient or useful to learn at this time.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for your answers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zb8dm", "is_robot_indexable": true, "report_reasons": null, "author": "Evigil24", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zb8dm/best_way_to_sync_data_between_sql_server_and_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zb8dm/best_way_to_sync_data_between_sql_server_and_mysql/", "subreddit_subscribers": 140695, "created_utc": 1700439143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Stumbled across two tools [https://rowzero.io/](https://rowzero.io/) and [https://www.gigasheet.com/](https://www.gigasheet.com/), that are spreadsheet like tools that support significantly more rows compared to excel \\~1m rows. What do you think about these? ", "author_fullname": "t2_s94r9x1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you feel the need of spreadsheet like tools to view large datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk7g7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Stumbled across two tools &lt;a href=\"https://rowzero.io/\"&gt;https://rowzero.io/&lt;/a&gt; and &lt;a href=\"https://www.gigasheet.com/\"&gt;https://www.gigasheet.com/&lt;/a&gt;, that are spreadsheet like tools that support significantly more rows compared to excel ~1m rows. What do you think about these? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zk7g7", "is_robot_indexable": true, "report_reasons": null, "author": "EternallyTrapped", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "subreddit_subscribers": 140695, "created_utc": 1700470306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DE's.Soon I'll be starting my first project, where I'd be *one man army.* It means, I'll be the one DE in the team and an architect responsible for building and ETL process for survey data analysis. Have someone worked with such data? Could you please give me some hints how to do that most efficiently?\n\nWhat do I know:\n\n* there is some external team which doing certain activities and as an output I've will be provided with xls file, out of SPSS I believe, so I'll have two worksheets, one with data so attributes with lets say 1-9 numbers as answers, the second worksheet will be just an explaination what's behind 1-9 numbers for given question. Where it will land? Its yet to decide, by me and business. Initially I was thinking of sharepoint as everyone got access there as opposed to storing it in lets say blob storage in Azure\n* ADF will be used as an ingestion and orchestration tool\n* Each survey data will have different sample size\n* Transform tool will be databricks\n* Load will be to Databricks Warehouse\n* Data will be loaded in PowerBI and reports will be made out of those\n\nI plan to run \"medallion\" architecture - raw/curated/serving layers. In curated layer, besides running dictionary from worksheet(2) over worksheet(1) to translate numbers to string answers, also run some statistical methods. Moreover they want serving layer to be aggregated and each country available there. How would I do that, considering each sample size is different? Does it matter, considering I'll run statistics in curated layer, only for given country? How can I do that? Just join dataframes over some key I'll be provided?\n\nMoreover, with nature of survey analysis - it may happen that i'd need to make upsert in some layer, in case new responds arrive and the sample will get bigger? or if they run the same survey next year? I know its highly hipotetical, but I want to anticipate everything?\n\nRegarding PowerBI - will I need to make a star schema, so divide the file for both dim and fact table? I think its generally bad practice to get both of those from one table. If its just survey do ID/name of respondent and answers for question, there are no dims I guess. It's going to be OBT?\n\nI would be grateful for each view on that, each tip and consideration. Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey data ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z40k2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700420251.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700420054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DE&amp;#39;s.Soon I&amp;#39;ll be starting my first project, where I&amp;#39;d be &lt;em&gt;one man army.&lt;/em&gt; It means, I&amp;#39;ll be the one DE in the team and an architect responsible for building and ETL process for survey data analysis. Have someone worked with such data? Could you please give me some hints how to do that most efficiently?&lt;/p&gt;\n\n&lt;p&gt;What do I know:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;there is some external team which doing certain activities and as an output I&amp;#39;ve will be provided with xls file, out of SPSS I believe, so I&amp;#39;ll have two worksheets, one with data so attributes with lets say 1-9 numbers as answers, the second worksheet will be just an explaination what&amp;#39;s behind 1-9 numbers for given question. Where it will land? Its yet to decide, by me and business. Initially I was thinking of sharepoint as everyone got access there as opposed to storing it in lets say blob storage in Azure&lt;/li&gt;\n&lt;li&gt;ADF will be used as an ingestion and orchestration tool&lt;/li&gt;\n&lt;li&gt;Each survey data will have different sample size&lt;/li&gt;\n&lt;li&gt;Transform tool will be databricks&lt;/li&gt;\n&lt;li&gt;Load will be to Databricks Warehouse&lt;/li&gt;\n&lt;li&gt;Data will be loaded in PowerBI and reports will be made out of those&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I plan to run &amp;quot;medallion&amp;quot; architecture - raw/curated/serving layers. In curated layer, besides running dictionary from worksheet(2) over worksheet(1) to translate numbers to string answers, also run some statistical methods. Moreover they want serving layer to be aggregated and each country available there. How would I do that, considering each sample size is different? Does it matter, considering I&amp;#39;ll run statistics in curated layer, only for given country? How can I do that? Just join dataframes over some key I&amp;#39;ll be provided?&lt;/p&gt;\n\n&lt;p&gt;Moreover, with nature of survey analysis - it may happen that i&amp;#39;d need to make upsert in some layer, in case new responds arrive and the sample will get bigger? or if they run the same survey next year? I know its highly hipotetical, but I want to anticipate everything?&lt;/p&gt;\n\n&lt;p&gt;Regarding PowerBI - will I need to make a star schema, so divide the file for both dim and fact table? I think its generally bad practice to get both of those from one table. If its just survey do ID/name of respondent and answers for question, there are no dims I guess. It&amp;#39;s going to be OBT?&lt;/p&gt;\n\n&lt;p&gt;I would be grateful for each view on that, each tip and consideration. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17z40k2", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z40k2/survey_data_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z40k2/survey_data_etl/", "subreddit_subscribers": 140695, "created_utc": 1700420054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am just confused between which one to pick , that's why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.", "author_fullname": "t2_s0gygp2m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one has higher pay is it azure data engineer or GCP data engineer in India and in USA? Experienced people kindly also mention the pay , we ll able to know how much we ll be getting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17zmuko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700481183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just confused between which one to pick , that&amp;#39;s why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zmuko", "is_robot_indexable": true, "report_reasons": null, "author": "Current_Baseball_418", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "subreddit_subscribers": 140695, "created_utc": 1700481183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am a 24M Alg Eng. working mostly as a data scientist with Master of Sci. in Eng. with focus on CNN face recognition. I am concerned with the growth I have had at my current workplace. In Graduate School, I trained and edited CNNs for research using TensorFlow &amp; PyTorch and had a good introduction to utilizing python for ML and AI. I would say I had a mid-average proficiency in python at this point and good concepts of ML but no NLP. At my current job, I have learned the pandas library and expanded my knowledge of scipy library for statistical analysis and fitting functions. It has been a year here and I have still yet to utilize ML for our projects. Granted ML is not the solution to all problems. However, I wish to remain relevant and keep my skills with the times.\n\nMy role now is mainly deploying the algorithms we utilize now, measuring performance, optimizing, and delivering results. These are valuable skills but nothing really challenging me. Although I'm making this post I wouldn't say I wasted time here, I definitely learned a lot about fitting algorithms and random forest/decision trees. I would like to know where you as a fellow data scientist are at your career stand with respect to what you know, what you think you should know, and what is expected of you.", "author_fullname": "t2_4t36ii9ti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to know if I'm growing in my career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zhnv0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700459530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a 24M Alg Eng. working mostly as a data scientist with Master of Sci. in Eng. with focus on CNN face recognition. I am concerned with the growth I have had at my current workplace. In Graduate School, I trained and edited CNNs for research using TensorFlow &amp;amp; PyTorch and had a good introduction to utilizing python for ML and AI. I would say I had a mid-average proficiency in python at this point and good concepts of ML but no NLP. At my current job, I have learned the pandas library and expanded my knowledge of scipy library for statistical analysis and fitting functions. It has been a year here and I have still yet to utilize ML for our projects. Granted ML is not the solution to all problems. However, I wish to remain relevant and keep my skills with the times.&lt;/p&gt;\n\n&lt;p&gt;My role now is mainly deploying the algorithms we utilize now, measuring performance, optimizing, and delivering results. These are valuable skills but nothing really challenging me. Although I&amp;#39;m making this post I wouldn&amp;#39;t say I wasted time here, I definitely learned a lot about fitting algorithms and random forest/decision trees. I would like to know where you as a fellow data scientist are at your career stand with respect to what you know, what you think you should know, and what is expected of you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zhnv0", "is_robot_indexable": true, "report_reasons": null, "author": "Magic_Jawn", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zhnv0/how_to_know_if_im_growing_in_my_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zhnv0/how_to_know_if_im_growing_in_my_career/", "subreddit_subscribers": 140695, "created_utc": 1700459530.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}