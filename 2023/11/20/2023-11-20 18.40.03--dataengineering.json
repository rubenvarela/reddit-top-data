{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title says it. According to your experience what would be the best certificates to have as a data engineer?", "author_fullname": "t2_2lt1q4pa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the best certificates to pursue as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zqhps", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700492634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title says it. According to your experience what would be the best certificates to have as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zqhps", "is_robot_indexable": true, "report_reasons": null, "author": "Kairo1004", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zqhps/what_would_be_the_best_certificates_to_pursue_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zqhps/what_would_be_the_best_certificates_to_pursue_as/", "subreddit_subscribers": 140757, "created_utc": 1700492634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to know your thoughts on Apache Hive. Is it still actively used in your projects and overall relevant to the field, or it became obsolete and you have transitioned to other tools and technologies? Share your experiences and insights pls", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Apache Hive still being used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zgbfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700454659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to know your thoughts on Apache Hive. Is it still actively used in your projects and overall relevant to the field, or it became obsolete and you have transitioned to other tools and technologies? Share your experiences and insights pls&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zgbfg", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zgbfg/is_apache_hive_still_being_used/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zgbfg/is_apache_hive_still_being_used/", "subreddit_subscribers": 140757, "created_utc": 1700454659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm fairly new to the data engineering field, I'm currently working on a project to migrate customer data from SAP to the AWS Cloud. The data comes into a S3 bucket and we are using AWS Glue for data transformations and cleaning before loading it into an RDS instance (MySQL). I'm seeking advice/ideas on the industry best practices for implementing robust data quality checks before the data is moved into the database. How to maintain data quality during both a data migration project and ongoing data integration?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ud1bwgro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practice for Data Quality Checks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17za67d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700436234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m fairly new to the data engineering field, I&amp;#39;m currently working on a project to migrate customer data from SAP to the AWS Cloud. The data comes into a S3 bucket and we are using AWS Glue for data transformations and cleaning before loading it into an RDS instance (MySQL). I&amp;#39;m seeking advice/ideas on the industry best practices for implementing robust data quality checks before the data is moved into the database. How to maintain data quality during both a data migration project and ongoing data integration?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17za67d", "is_robot_indexable": true, "report_reasons": null, "author": "Zealousideal_Crew385", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17za67d/best_practice_for_data_quality_checks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17za67d/best_practice_for_data_quality_checks/", "subreddit_subscribers": 140757, "created_utc": 1700436234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I have built a fact table that tracks an invoice for each day from when it is issued, to when it is paid. This is the lowest granularity the business needs.\n\nThis is to track certain attributes on the invoice for any given day, and hence acts as a form of CDC with daily snapshots.\n\nMy question is, how would I build a dimensional model for this? Is the best approach to create a dimension table based on invoice ID and day, and have a 1-1 relationship between fact and dimension table? Or am I approaching this the wrong way?", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to build a dimension table for a daily fact table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zjekz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700466765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I have built a fact table that tracks an invoice for each day from when it is issued, to when it is paid. This is the lowest granularity the business needs.&lt;/p&gt;\n\n&lt;p&gt;This is to track certain attributes on the invoice for any given day, and hence acts as a form of CDC with daily snapshots.&lt;/p&gt;\n\n&lt;p&gt;My question is, how would I build a dimensional model for this? Is the best approach to create a dimension table based on invoice ID and day, and have a 1-1 relationship between fact and dimension table? Or am I approaching this the wrong way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zjekz", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zjekz/how_to_build_a_dimension_table_for_a_daily_fact/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zjekz/how_to_build_a_dimension_table_for_a_daily_fact/", "subreddit_subscribers": 140757, "created_utc": 1700466765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.\n\nNow, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).\n\nIn fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?", "author_fullname": "t2_f4h6309d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering guidance (AWS vs AZURE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk9u0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I need guidance for my career. I completed my BTech in 2014, and since then, I have been working in non-technical fields. In fact, I spent 7 years in the same company, moving from sales to support to tech support.&lt;/p&gt;\n\n&lt;p&gt;Now, I want to switch to the data engineering field, but I am confused about choosing between the AWS stack (EMR, Glue, Flink, etc.) and the Azure stack (ADF, Synapse, ADB, etc.). I know SQL and Python, Cassandra, and have a basic understanding of AWS (self-learned as a weekend hobby).&lt;/p&gt;\n\n&lt;p&gt;In fact, during COVID, I tried my hand at front-end development but gave up on CSS and JavaScript. I am planning to pursue certifications accordingly. Kindly suggest which one will be easier to switch to, along with any package information. AWS or Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zk9u0", "is_robot_indexable": true, "report_reasons": null, "author": "paisa_byte", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk9u0/data_engineering_guidance_aws_vs_azure/", "subreddit_subscribers": 140757, "created_utc": 1700470607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jboiz9k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get real-time AI assistant alerts with changes in Google Docs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17zjfot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3RBmbxS4QZdPavgMc7NASjWeb5QJ4ch0iK3EIMX_eQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1700466900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pathway.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pathway.com/developers/showcases/llm-alert-pathway/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?auto=webp&amp;s=bb142a79431022a27a6ccabda60c67e9d9996dae", "width": 768, "height": 581}, "resolutions": [{"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ac1817573346e5b19274ed78e5e5dfcfe8c9794f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07ffeab24b4d4bd15d99bb81dd3e8f72561881f5", "width": 216, "height": 163}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe7efbcd67d7e2615448eecae2cd4da1f003f627", "width": 320, "height": 242}, {"url": "https://external-preview.redd.it/DrfWxtSZ2iTJxPLPr0v3Ms_sa5nfUENVadIJHoxqr6Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=886a54fa5caee12febbd2064362c657b257e28ef", "width": 640, "height": 484}], "variants": {}, "id": "UIiH3TzxPBFekdQEoqNUB3DAUECkNeH8pyrVzlpGcoY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17zjfot", "is_robot_indexable": true, "report_reasons": null, "author": "bumurzokov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zjfot/how_to_get_realtime_ai_assistant_alerts_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pathway.com/developers/showcases/llm-alert-pathway/", "subreddit_subscribers": 140757, "created_utc": 1700466900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently researching on orchestrating   databricks workflows with airflow, and was just wondering what resources do i need and the cost implications of deploying airflow on azure for production", "author_fullname": "t2_jettu57pn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of implementing airflow in azure for production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zr1db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700494124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently researching on orchestrating   databricks workflows with airflow, and was just wondering what resources do i need and the cost implications of deploying airflow on azure for production&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zr1db", "is_robot_indexable": true, "report_reasons": null, "author": "Slight_Award8187", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zr1db/cost_of_implementing_airflow_in_azure_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zr1db/cost_of_implementing_airflow_in_azure_for/", "subreddit_subscribers": 140757, "created_utc": 1700494124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Stumbled across two tools [https://rowzero.io/](https://rowzero.io/) and [https://www.gigasheet.com/](https://www.gigasheet.com/), that are spreadsheet like tools that support significantly more rows compared to excel \\~1m rows. What do you think about these? ", "author_fullname": "t2_s94r9x1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you feel the need of spreadsheet like tools to view large datasets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zk7g7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700470306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Stumbled across two tools &lt;a href=\"https://rowzero.io/\"&gt;https://rowzero.io/&lt;/a&gt; and &lt;a href=\"https://www.gigasheet.com/\"&gt;https://www.gigasheet.com/&lt;/a&gt;, that are spreadsheet like tools that support significantly more rows compared to excel ~1m rows. What do you think about these? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zk7g7", "is_robot_indexable": true, "report_reasons": null, "author": "EternallyTrapped", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zk7g7/do_you_feel_the_need_of_spreadsheet_like_tools_to/", "subreddit_subscribers": 140757, "created_utc": 1700470306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/17zaei5)", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineers of Reddit, (5+ YoE) what is your next career goal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zaei5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700436862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17zaei5\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zaei5", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1700609662968, "options": [{"text": "Senior+ (Architecture, Staff, Principal)", "id": "26079152"}, {"text": "Management (EM, PO, PO)", "id": "26079153"}, {"text": "Other Tech Role (SWE, DevOps etc.)", "id": "26079154"}, {"text": "Data Science or ML", "id": "26079155"}, {"text": "Analytics or BI", "id": "26079156"}, {"text": "No goal", "id": "26079157"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 325, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zaei5/senior_data_engineers_of_reddit_5_yoe_what_is/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/17zaei5/senior_data_engineers_of_reddit_5_yoe_what_is/", "subreddit_subscribers": 140757, "created_utc": 1700436862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I ran across this website:\n\n[https://stateofdb.com/databases](https://stateofdb.com/databases)\n\nThought I'd ask everyone if they have seen site? Do you think this is a comprehensive list of DB's, providers, and Warehouses? Does anything surprise you in these rankings? \n\nI know Postgres is popular, but surprised that it tops the lists. I work as a data analyst and I don't think I've seen a Postgres DB actually used in the financial industry. I'm sure someone somewhere in these large institutions are using it, but I haven't seen it. ", "author_fullname": "t2_djjvfxs96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State of DB website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z5ofp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700424550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I ran across this website:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://stateofdb.com/databases\"&gt;https://stateofdb.com/databases&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thought I&amp;#39;d ask everyone if they have seen site? Do you think this is a comprehensive list of DB&amp;#39;s, providers, and Warehouses? Does anything surprise you in these rankings? &lt;/p&gt;\n\n&lt;p&gt;I know Postgres is popular, but surprised that it tops the lists. I work as a data analyst and I don&amp;#39;t think I&amp;#39;ve seen a Postgres DB actually used in the financial industry. I&amp;#39;m sure someone somewhere in these large institutions are using it, but I haven&amp;#39;t seen it. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?auto=webp&amp;s=316ad5b1826ec7ff5dbe7e1e579a479201d1d133", "width": 887, "height": 584}, "resolutions": [{"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0426761a7ab4f4d6e3380f1af41b782939f315e", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d425877bc6524ee6c9291c6d0848c8a51371a02", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=03aff174b673b182fba916a90a3ce3c2038b3b56", "width": 320, "height": 210}, {"url": "https://external-preview.redd.it/GnNlH1o0JwARd5B_2lo2s1scUD4x5_9mEYBfSPviPjE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f5c3f28ad0813e3e1ff51973cc1687c42d3c8d9", "width": 640, "height": 421}], "variants": {}, "id": "FBBD2314yNHq6sOCpDaENKMEcOYXTmbCkhx6pskDd_o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17z5ofp", "is_robot_indexable": true, "report_reasons": null, "author": "Oh_Another_Thing", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z5ofp/state_of_db_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z5ofp/state_of_db_website/", "subreddit_subscribers": 140757, "created_utc": 1700424550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to preprocess data in Amazon EMR using PySpark and train a machine learning model in SageMaker using pipe mode. The issue I am having now is saving data in S3 and feeding it to the model.\n\nSageMaker models accept the application/x-recordio-protobuf type. Therefore, I have saved my data as:\n\n    output_path = f\"s3://my_path/output_processed\"\n    df_transformed.write.format(\"sagemaker\").mode(\"overwrite\").save(output_path)\n\nWhere df\\_transformed is a pyspark dataframe.\n\nWhen I am trying to feed my data to the model:\n\nrecords = RecordSet(s3\\_data=train\\_path, s3\\_data\\_type='S3Prefix', num\\_records=-1, feature\\_dim=50) rcf.fit(records)\n\nI am getting this error:\n\nFailed. Reason: ClientError: Unable to read data channel 'train'. Requested content-type is 'application/x-recordio-protobuf'. Please verify the data matches the requested content-type. (caused by MXNetError)\n\nDo you have any idea what I am doing wrong? And is it necessary to preprocess data separately in EMR and train in SageMaker, or can I just do everything in SageMaker? (Considering the cost).\n\n [Using Pipe input mode for Amazon SageMaker algorithms | AWS Machine Learning Blog](https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/) \n\nThanks in advance for any help.", "author_fullname": "t2_7zvlhn0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Amazon EMR and SageMaker data type issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17zuhol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700504169.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700503025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to preprocess data in Amazon EMR using PySpark and train a machine learning model in SageMaker using pipe mode. The issue I am having now is saving data in S3 and feeding it to the model.&lt;/p&gt;\n\n&lt;p&gt;SageMaker models accept the application/x-recordio-protobuf type. Therefore, I have saved my data as:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;output_path = f&amp;quot;s3://my_path/output_processed&amp;quot;\ndf_transformed.write.format(&amp;quot;sagemaker&amp;quot;).mode(&amp;quot;overwrite&amp;quot;).save(output_path)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Where df_transformed is a pyspark dataframe.&lt;/p&gt;\n\n&lt;p&gt;When I am trying to feed my data to the model:&lt;/p&gt;\n\n&lt;p&gt;records = RecordSet(s3_data=train_path, s3_data_type=&amp;#39;S3Prefix&amp;#39;, num_records=-1, feature_dim=50) rcf.fit(records)&lt;/p&gt;\n\n&lt;p&gt;I am getting this error:&lt;/p&gt;\n\n&lt;p&gt;Failed. Reason: ClientError: Unable to read data channel &amp;#39;train&amp;#39;. Requested content-type is &amp;#39;application/x-recordio-protobuf&amp;#39;. Please verify the data matches the requested content-type. (caused by MXNetError)&lt;/p&gt;\n\n&lt;p&gt;Do you have any idea what I am doing wrong? And is it necessary to preprocess data separately in EMR and train in SageMaker, or can I just do everything in SageMaker? (Considering the cost).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/\"&gt;Using Pipe input mode for Amazon SageMaker algorithms | AWS Machine Learning Blog&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kswp4uBe2GsV5mPWqqjORXJTx9wegm-j-4XbbS8wPRc.jpg?auto=webp&amp;s=fb4e0b10b3df74b1efe5e74f131e5ad4c4fc037d", "width": 800, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/kswp4uBe2GsV5mPWqqjORXJTx9wegm-j-4XbbS8wPRc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b89a5bfc384674a8a145503ec6e6a9f2c7bd846c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/kswp4uBe2GsV5mPWqqjORXJTx9wegm-j-4XbbS8wPRc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f08165c17a828e0b33c13b91a058aa1912ce03bd", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/kswp4uBe2GsV5mPWqqjORXJTx9wegm-j-4XbbS8wPRc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9fd714ce4c21e83ec25b7b9625ca2aeb9ea7d800", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/kswp4uBe2GsV5mPWqqjORXJTx9wegm-j-4XbbS8wPRc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acc6ae1ed45f2046fc98f38217deda3e7c727222", "width": 640, "height": 320}], "variants": {}, "id": "AZPWW7vtK188vS3p_QADHvAL4KfnIusJDw1oyvm6YWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zuhol", "is_robot_indexable": true, "report_reasons": null, "author": "Omart__", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zuhol/amazon_emr_and_sagemaker_data_type_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zuhol/amazon_emr_and_sagemaker_data_type_issue/", "subreddit_subscribers": 140757, "created_utc": 1700503025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you manage a Ceph cluster for data storage and you are using Kubernetes, you might be interested in our newest software, the Koor Data Control Center. We are in beta and would love to get your feedback about what features would help you most with Ceph storage.\n\nThis describes what we have built so far [https://about.koor.tech/product](https://about.koor.tech/product) Anyone can install a free trial for up to 4 storage nodes. No time limits on the trial. If you want to contact us to give feedback or discuss your situation, here's our contact form: [https://about.koor.tech/contact](https://about.koor.tech/contact)\n\nAbove all, we like to be helpful. We will take any questions about data storage.\n\n&amp;#x200B;", "author_fullname": "t2_d321jhgdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback on our beta product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ztwel", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700501502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you manage a Ceph cluster for data storage and you are using Kubernetes, you might be interested in our newest software, the Koor Data Control Center. We are in beta and would love to get your feedback about what features would help you most with Ceph storage.&lt;/p&gt;\n\n&lt;p&gt;This describes what we have built so far &lt;a href=\"https://about.koor.tech/product\"&gt;https://about.koor.tech/product&lt;/a&gt; Anyone can install a free trial for up to 4 storage nodes. No time limits on the trial. If you want to contact us to give feedback or discuss your situation, here&amp;#39;s our contact form: &lt;a href=\"https://about.koor.tech/contact\"&gt;https://about.koor.tech/contact&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Above all, we like to be helpful. We will take any questions about data storage.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?auto=webp&amp;s=70f74026d1c62617c1774fde3e71a198fe95429d", "width": 1917, "height": 1128}, "resolutions": [{"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b71fdef9d0fabb53d097600bc3ab7d7f6f565df", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0051a2251507bf3c8f3d3a918df32a6b3ee5eaa2", "width": 216, "height": 127}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea722a7eb0e15c6607621bd2291d974d79fea9ec", "width": 320, "height": 188}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db500642a1e74c7bb9dd71b6259f3ccd448390dd", "width": 640, "height": 376}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c95104e6468850127d68f25b4f6be57fc808672d", "width": 960, "height": 564}, {"url": "https://external-preview.redd.it/pXsV2SXS9SbquPI5gahzjKefpG8-btfZnjO0uPAPCNA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=767cdbd3ee81ba9aa47d29696b97de45fd694765", "width": 1080, "height": 635}], "variants": {}, "id": "W8LZN3dTBlBXOohUIv0rRWpk-U5tJSdTcj0Vl3FmcVI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17ztwel", "is_robot_indexable": true, "report_reasons": null, "author": "Dave-at-Koor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ztwel/looking_for_feedback_on_our_beta_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ztwel/looking_for_feedback_on_our_beta_product/", "subreddit_subscribers": 140757, "created_utc": 1700501502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone hope you are doing fine, currently I\u2019m using elastic search for aggregations and I\u2019m really new to this data engineering and I want to know what are the available alternatives to elastic search aggregation i don\u2019t use elastic search for search needs but only for aggregation need, since our dashboard is used by vast number of users I want a alternative which can support high throughput like elastic searches kindly advise me on what are can be alternatives", "author_fullname": "t2_g66aigmk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative for elastic search aggregation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ztrzu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700501198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone hope you are doing fine, currently I\u2019m using elastic search for aggregations and I\u2019m really new to this data engineering and I want to know what are the available alternatives to elastic search aggregation i don\u2019t use elastic search for search needs but only for aggregation need, since our dashboard is used by vast number of users I want a alternative which can support high throughput like elastic searches kindly advise me on what are can be alternatives&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ztrzu", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Bug8381", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ztrzu/alternative_for_elastic_search_aggregation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ztrzu/alternative_for_elastic_search_aggregation/", "subreddit_subscribers": 140757, "created_utc": 1700501198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A nice tutorial about how to handle big data datasets efficiently when building dataflows. It uses two open source Python libraries and the tutorial builds a data pipeline to analyze customer data.\n\n[https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f](https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f)\n\nI wanted your thoughts: what libraries do you use when typically faced with managing large datasets in back-end creation?\n\nEnjoy!", "author_fullname": "t2_tfe7ylgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to build dataflows with larger than memory datasets.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17zsyw6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700499200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A nice tutorial about how to handle big data datasets efficiently when building dataflows. It uses two open source Python libraries and the tutorial builds a data pipeline to analyze customer data.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f\"&gt;https://medium.com/@marine.gosselin/big-data-models-vs-computer-memory-b345814ece9f&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wanted your thoughts: what libraries do you use when typically faced with managing large datasets in back-end creation?&lt;/p&gt;\n\n&lt;p&gt;Enjoy!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?auto=webp&amp;s=3b5e410f440e95a52a35878f677e9603657b64a7", "width": 800, "height": 333}, "resolutions": [{"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=554f3f06f4a57f57464438e79c0017dfc3de512c", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=128b12489ea024c1b350a98d2d4a95e05b071e2d", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bfadd51c7dbc9524d7b5103c028ef37c492339", "width": 320, "height": 133}, {"url": "https://external-preview.redd.it/eDCKNhUuH6cQH47OKAtUEw6f8qHgkXSvBsUjXqP-Bd4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ebd738d6ced9cee838c6f9d82ef7a8a155c8298", "width": 640, "height": 266}], "variants": {}, "id": "HGI-vRG7wujMoeTFgVEM9JPE4QYiHX-A8ny5bWr0L4s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17zsyw6", "is_robot_indexable": true, "report_reasons": null, "author": "quicklyalienated76", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zsyw6/learn_how_to_build_dataflows_with_larger_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zsyw6/learn_how_to_build_dataflows_with_larger_than/", "subreddit_subscribers": 140757, "created_utc": 1700499200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've never used Databricks or Spark in a production environment and have been thrown onto a project that is heavily using it. I'm coming from a rdbms-heavy background, so I approach things with a SQL-like approach and have done a decent amount of query optimization.\n\nHowever I'm a little lost on deciphering Spark logical plans using the output of `df.explain`. I've tried `df.explain(True)` and I can't even figure out the difference between the Parsed Logical Plan, Analyzed Logical Plan, Optimized Logical Plan, and Physical Plan.\n\nWhat are some things I should try to avoid? From what I've learned, I should avoid shuffling, avoid skewed joins, and optimize my partitions. But I'm not even doing any joins in a notebook I'm working with. I'd appreciate suggestions, best practices, or anything to tweak my notebooks based on what I see in a physical plan.\n\nAlso, does anyone have suggestions on how to read a large data source and quickly filter it down? I'm trying to test some code but it's insanely slow (taking &gt; 1 hour) even when I try to filter it down and limit it as early as possible.", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Databricks (and Spark in general) - how do I decipher logical plans and update my notebook/script accordingly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zs8at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700497270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never used Databricks or Spark in a production environment and have been thrown onto a project that is heavily using it. I&amp;#39;m coming from a rdbms-heavy background, so I approach things with a SQL-like approach and have done a decent amount of query optimization.&lt;/p&gt;\n\n&lt;p&gt;However I&amp;#39;m a little lost on deciphering Spark logical plans using the output of &lt;code&gt;df.explain&lt;/code&gt;. I&amp;#39;ve tried &lt;code&gt;df.explain(True)&lt;/code&gt; and I can&amp;#39;t even figure out the difference between the Parsed Logical Plan, Analyzed Logical Plan, Optimized Logical Plan, and Physical Plan.&lt;/p&gt;\n\n&lt;p&gt;What are some things I should try to avoid? From what I&amp;#39;ve learned, I should avoid shuffling, avoid skewed joins, and optimize my partitions. But I&amp;#39;m not even doing any joins in a notebook I&amp;#39;m working with. I&amp;#39;d appreciate suggestions, best practices, or anything to tweak my notebooks based on what I see in a physical plan.&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone have suggestions on how to read a large data source and quickly filter it down? I&amp;#39;m trying to test some code but it&amp;#39;s insanely slow (taking &amp;gt; 1 hour) even when I try to filter it down and limit it as early as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zs8at", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zs8at/new_to_databricks_and_spark_in_general_how_do_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zs8at/new_to_databricks_and_spark_in_general_how_do_i/", "subreddit_subscribers": 140757, "created_utc": 1700497270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The GCP DE certification exam has changed it\u2019s exam guide topics effective Nov 23. Can anyone here who has attended the new version of the cert exam give their feedback on the new exam pattern and how easy/hard it was?", "author_fullname": "t2_vl617oe9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Data Engineer Certification Nov 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zj163", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700465130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The GCP DE certification exam has changed it\u2019s exam guide topics effective Nov 23. Can anyone here who has attended the new version of the cert exam give their feedback on the new exam pattern and how easy/hard it was?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17zj163", "is_robot_indexable": true, "report_reasons": null, "author": "DohaerasVagar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zj163/gcp_data_engineer_certification_nov_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zj163/gcp_data_engineer_certification_nov_2023/", "subreddit_subscribers": 140757, "created_utc": 1700465130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Interviewing for a Sr DE role and made it to some cross functional interviews. I'm sure a lot of it is trying to gauge my communication and experiences working with other teams, but recruiter mentioned the DS one can be technical (although given a short 30 min time frame, probably not active coding). \n\nWhat would you expect from these conversations, talking to a data scientist and a product manager? Just trying to brainstorm ideas of what to keep in mind / brush up on.", "author_fullname": "t2_5q6un", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cross functional interview for Sr DE role with data science and product folks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ziuh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700464331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interviewing for a Sr DE role and made it to some cross functional interviews. I&amp;#39;m sure a lot of it is trying to gauge my communication and experiences working with other teams, but recruiter mentioned the DS one can be technical (although given a short 30 min time frame, probably not active coding). &lt;/p&gt;\n\n&lt;p&gt;What would you expect from these conversations, talking to a data scientist and a product manager? Just trying to brainstorm ideas of what to keep in mind / brush up on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17ziuh4", "is_robot_indexable": true, "report_reasons": null, "author": "vitalemontea", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ziuh4/cross_functional_interview_for_sr_de_role_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ziuh4/cross_functional_interview_for_sr_de_role_with/", "subreddit_subscribers": 140757, "created_utc": 1700464331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm new in this area, trying to make the conversion from BI to DE.\n\nI have the following problem, the company ERP uses a MySQL 5 database on the company local server and I'm building a SQL Server DW on the same server, I have to automate the ETL from one database to another, preferably with open source tools or low cost tools.\n\nI'm wondering which is the best way to do this, I'm exploring the SSIS option but perhaps there is a better way or something similar but more convenient or useful to learn at this time.\n\nThank you very much for your answers.", "author_fullname": "t2_9bsrz4l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to sync data between SQL Server and MySQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zb8dm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700439143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m new in this area, trying to make the conversion from BI to DE.&lt;/p&gt;\n\n&lt;p&gt;I have the following problem, the company ERP uses a MySQL 5 database on the company local server and I&amp;#39;m building a SQL Server DW on the same server, I have to automate the ETL from one database to another, preferably with open source tools or low cost tools.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering which is the best way to do this, I&amp;#39;m exploring the SSIS option but perhaps there is a better way or something similar but more convenient or useful to learn at this time.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much for your answers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17zb8dm", "is_robot_indexable": true, "report_reasons": null, "author": "Evigil24", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zb8dm/best_way_to_sync_data_between_sql_server_and_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zb8dm/best_way_to_sync_data_between_sql_server_and_mysql/", "subreddit_subscribers": 140757, "created_utc": 1700439143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DE's.Soon I'll be starting my first project, where I'd be *one man army.* It means, I'll be the one DE in the team and an architect responsible for building and ETL process for survey data analysis. Have someone worked with such data? Could you please give me some hints how to do that most efficiently?\n\nWhat do I know:\n\n* there is some external team which doing certain activities and as an output I've will be provided with xls file, out of SPSS I believe, so I'll have two worksheets, one with data so attributes with lets say 1-9 numbers as answers, the second worksheet will be just an explaination what's behind 1-9 numbers for given question. Where it will land? Its yet to decide, by me and business. Initially I was thinking of sharepoint as everyone got access there as opposed to storing it in lets say blob storage in Azure\n* ADF will be used as an ingestion and orchestration tool\n* Each survey data will have different sample size\n* Transform tool will be databricks\n* Load will be to Databricks Warehouse\n* Data will be loaded in PowerBI and reports will be made out of those\n\nI plan to run \"medallion\" architecture - raw/curated/serving layers. In curated layer, besides running dictionary from worksheet(2) over worksheet(1) to translate numbers to string answers, also run some statistical methods. Moreover they want serving layer to be aggregated and each country available there. How would I do that, considering each sample size is different? Does it matter, considering I'll run statistics in curated layer, only for given country? How can I do that? Just join dataframes over some key I'll be provided?\n\nMoreover, with nature of survey analysis - it may happen that i'd need to make upsert in some layer, in case new responds arrive and the sample will get bigger? or if they run the same survey next year? I know its highly hipotetical, but I want to anticipate everything?\n\nRegarding PowerBI - will I need to make a star schema, so divide the file for both dim and fact table? I think its generally bad practice to get both of those from one table. If its just survey do ID/name of respondent and answers for question, there are no dims I guess. It's going to be OBT?\n\nI would be grateful for each view on that, each tip and consideration. Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Survey data ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17z40k2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700420251.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700420054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DE&amp;#39;s.Soon I&amp;#39;ll be starting my first project, where I&amp;#39;d be &lt;em&gt;one man army.&lt;/em&gt; It means, I&amp;#39;ll be the one DE in the team and an architect responsible for building and ETL process for survey data analysis. Have someone worked with such data? Could you please give me some hints how to do that most efficiently?&lt;/p&gt;\n\n&lt;p&gt;What do I know:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;there is some external team which doing certain activities and as an output I&amp;#39;ve will be provided with xls file, out of SPSS I believe, so I&amp;#39;ll have two worksheets, one with data so attributes with lets say 1-9 numbers as answers, the second worksheet will be just an explaination what&amp;#39;s behind 1-9 numbers for given question. Where it will land? Its yet to decide, by me and business. Initially I was thinking of sharepoint as everyone got access there as opposed to storing it in lets say blob storage in Azure&lt;/li&gt;\n&lt;li&gt;ADF will be used as an ingestion and orchestration tool&lt;/li&gt;\n&lt;li&gt;Each survey data will have different sample size&lt;/li&gt;\n&lt;li&gt;Transform tool will be databricks&lt;/li&gt;\n&lt;li&gt;Load will be to Databricks Warehouse&lt;/li&gt;\n&lt;li&gt;Data will be loaded in PowerBI and reports will be made out of those&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I plan to run &amp;quot;medallion&amp;quot; architecture - raw/curated/serving layers. In curated layer, besides running dictionary from worksheet(2) over worksheet(1) to translate numbers to string answers, also run some statistical methods. Moreover they want serving layer to be aggregated and each country available there. How would I do that, considering each sample size is different? Does it matter, considering I&amp;#39;ll run statistics in curated layer, only for given country? How can I do that? Just join dataframes over some key I&amp;#39;ll be provided?&lt;/p&gt;\n\n&lt;p&gt;Moreover, with nature of survey analysis - it may happen that i&amp;#39;d need to make upsert in some layer, in case new responds arrive and the sample will get bigger? or if they run the same survey next year? I know its highly hipotetical, but I want to anticipate everything?&lt;/p&gt;\n\n&lt;p&gt;Regarding PowerBI - will I need to make a star schema, so divide the file for both dim and fact table? I think its generally bad practice to get both of those from one table. If its just survey do ID/name of respondent and answers for question, there are no dims I guess. It&amp;#39;s going to be OBT?&lt;/p&gt;\n\n&lt;p&gt;I would be grateful for each view on that, each tip and consideration. Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17z40k2", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17z40k2/survey_data_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17z40k2/survey_data_etl/", "subreddit_subscribers": 140757, "created_utc": 1700420054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am just confused between which one to pick , that's why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.", "author_fullname": "t2_s0gygp2m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which one has higher pay is it azure data engineer or GCP data engineer in India and in USA? Experienced people kindly also mention the pay , we ll able to know how much we ll be getting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17zmuko", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700481183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just confused between which one to pick , that&amp;#39;s why a bit of dilemma becuz I felt azure is easy with all the UI stuff, but my company is using GCP which involves a lot of writing code for pipelines when compared to azure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17zmuko", "is_robot_indexable": true, "report_reasons": null, "author": "Current_Baseball_418", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17zmuko/which_one_has_higher_pay_is_it_azure_data/", "subreddit_subscribers": 140757, "created_utc": 1700481183.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}