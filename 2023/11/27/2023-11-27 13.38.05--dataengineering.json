{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are your favourite data buzzwords? I.e. Terms or words or sayings that make you want to barf or roll your eyes every time you hear it.", "author_fullname": "t2_6jsoipfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your favourite data buzzwords? I.e. Terms or words or sayings that make you want to barf or roll your eyes every time you hear it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184cqy2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701011453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your favourite data buzzwords? I.e. Terms or words or sayings that make you want to barf or roll your eyes every time you hear it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184cqy2", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataGentleman", "discussion_type": null, "num_comments": 194, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184cqy2/what_are_your_favourite_data_buzzwords_ie_terms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184cqy2/what_are_your_favourite_data_buzzwords_ie_terms/", "subreddit_subscribers": 142055, "created_utc": 1701011453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anything from CLI to deployment. Curious to know your answers \ud83e\udd13", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Airflow hacks you wish you knew sooner?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184bse1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701008627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anything from CLI to deployment. Curious to know your answers \ud83e\udd13&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184bse1", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184bse1/what_airflow_hacks_you_wish_you_knew_sooner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184bse1/what_airflow_hacks_you_wish_you_knew_sooner/", "subreddit_subscribers": 142055, "created_utc": 1701008627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been tasked with implementing some code-based tools/frameworks that will be critical to our company's data platform.  I am essentially the solo driver of this project since neither management/PM's nor engineers have any experience with this type of work.  Team is primarily SQL + GUI ETL focused on data warehousing.  Management has my back and trusts me, but I want to avoid a situation where I get enough pushback from engineers that causes management to second guess.    \nI've been slowly exposing the team to these tools/practices over the last few months, but it will become critical that devs are somewhat comfortable with:\n\n* Containers\n* Non-SQL programming (Python)\n* Version Control\n* Code quality/readability/reviews\n* Unit testing\n* CI/CD pipelines\n* Prod/Test/Dev environments  \n\n\nSome questions:\n\nRegarding devs, most are more adaptable and willing to learn.  However, some will strongly push back in favor of keeping their old practices, and I'm worried some won't even be able to upskill at all.  Any tips to make the transition and training smoother?  \n\n\nDo PM's/BA's need to be upskilled/informed as well? They're solely concerned with the business side of things, so I've been pretty much ignored, but I have a feeling they will come knocking once stuff starts really rolling out.  \n\n\nI'm not a senior, but management pretty much told me to do it, and they've given me free reign with no oversight. I'm doing my best to set a good precedent for initial development by keeping code as high quality as possible (writing tests, consistency, modular, documented, future-proof, and as simple + readable as possible).  Any general advice for handling a large initiative like this?  \n\n\nBonus question: it is very likely I will receive negative heat from some senior engineers, and I will most likely have to deal with a lot of complaining and criticism. I mostly just tune it out, but I do not need this making my life more difficult. Any advice for dealing with this?", "author_fullname": "t2_4rifsjav", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to sell SWE best practices to team and management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184kvgi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701032837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been tasked with implementing some code-based tools/frameworks that will be critical to our company&amp;#39;s data platform.  I am essentially the solo driver of this project since neither management/PM&amp;#39;s nor engineers have any experience with this type of work.  Team is primarily SQL + GUI ETL focused on data warehousing.  Management has my back and trusts me, but I want to avoid a situation where I get enough pushback from engineers that causes management to second guess.&lt;br/&gt;\nI&amp;#39;ve been slowly exposing the team to these tools/practices over the last few months, but it will become critical that devs are somewhat comfortable with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Containers&lt;/li&gt;\n&lt;li&gt;Non-SQL programming (Python)&lt;/li&gt;\n&lt;li&gt;Version Control&lt;/li&gt;\n&lt;li&gt;Code quality/readability/reviews&lt;/li&gt;\n&lt;li&gt;Unit testing&lt;/li&gt;\n&lt;li&gt;CI/CD pipelines&lt;/li&gt;\n&lt;li&gt;Prod/Test/Dev environments&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Some questions:&lt;/p&gt;\n\n&lt;p&gt;Regarding devs, most are more adaptable and willing to learn.  However, some will strongly push back in favor of keeping their old practices, and I&amp;#39;m worried some won&amp;#39;t even be able to upskill at all.  Any tips to make the transition and training smoother?  &lt;/p&gt;\n\n&lt;p&gt;Do PM&amp;#39;s/BA&amp;#39;s need to be upskilled/informed as well? They&amp;#39;re solely concerned with the business side of things, so I&amp;#39;ve been pretty much ignored, but I have a feeling they will come knocking once stuff starts really rolling out.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a senior, but management pretty much told me to do it, and they&amp;#39;ve given me free reign with no oversight. I&amp;#39;m doing my best to set a good precedent for initial development by keeping code as high quality as possible (writing tests, consistency, modular, documented, future-proof, and as simple + readable as possible).  Any general advice for handling a large initiative like this?  &lt;/p&gt;\n\n&lt;p&gt;Bonus question: it is very likely I will receive negative heat from some senior engineers, and I will most likely have to deal with a lot of complaining and criticism. I mostly just tune it out, but I do not need this making my life more difficult. Any advice for dealing with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184kvgi", "is_robot_indexable": true, "report_reasons": null, "author": "Techthrowaway2222888", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184kvgi/how_to_sell_swe_best_practices_to_team_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184kvgi/how_to_sell_swe_best_practices_to_team_and/", "subreddit_subscribers": 142055, "created_utc": 1701032837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are using dbt, but still, it's getting messy pretty fast with tons of models, sometimes overlapping logic. Is there a clear convention you're using to write models, architecture wise?", "author_fullname": "t2_85sq3osr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you avoid DWH mess?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184xh8c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701072748.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701070499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are using dbt, but still, it&amp;#39;s getting messy pretty fast with tons of models, sometimes overlapping logic. Is there a clear convention you&amp;#39;re using to write models, architecture wise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184xh8c", "is_robot_indexable": true, "report_reasons": null, "author": "lirco_", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184xh8c/how_do_you_avoid_dwh_mess/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184xh8c/how_do_you_avoid_dwh_mess/", "subreddit_subscribers": 142055, "created_utc": 1701070499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm designing a solution that includes one big table (OBT) as a consumption layer above our DW. Naturally, this includes looking for information about designing OBT. It seems like there are two definitions that people have in their head, but don't specifically call out when discussing the patterns and critiques. \n\n1. Simply add dimension columns to a fact table\n2. Create one table that represents multiple entities where rows can be at different grains. \n\nWhich definition do you consider?", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you define one big table (OBT)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184oj6m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701041890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m designing a solution that includes one big table (OBT) as a consumption layer above our DW. Naturally, this includes looking for information about designing OBT. It seems like there are two definitions that people have in their head, but don&amp;#39;t specifically call out when discussing the patterns and critiques. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Simply add dimension columns to a fact table&lt;/li&gt;\n&lt;li&gt;Create one table that represents multiple entities where rows can be at different grains. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which definition do you consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184oj6m", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184oj6m/how_do_you_define_one_big_table_obt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184oj6m/how_do_you_define_one_big_table_obt/", "subreddit_subscribers": 142055, "created_utc": 1701041890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am senior studying statistics/data science and I (like many others) are  freaking out about my prospects right out of college. As for  experience, all I have is that I am currently working as a software  developer (web) for a tiny startup (based at my university) part-time  which is also what I did this over last summer. I feel super  disadvantaged with my degree, but I will be taking as many CS classes as  I can.  \nSeeing that I am pretty late to the party and haven't sent in  a single application currently, I am not really sure where to start. I  am pretty slammed with my classes and work, so I haven't had much time  to build other projects (that are not work) for the resume or even apply  to anything. Where do you guys think I should start? For a non-CS major  what should my first step be? I could pivot to analytics as that makes  much more sense with my degree but I enjoy building things than  discovering I suppose. A lot of people I know and stories I have heard  have gone with pursuing a masters degree but I don't want to more school  just because everyone else is. I feel like learning on the job or with  projects would be much more cost-efficient and a better plan for me.\n\nThanks!", "author_fullname": "t2_vkg8wnuu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you were a senior in college and just realized that this career was the right choice for you, what you do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184vr3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701063788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am senior studying statistics/data science and I (like many others) are  freaking out about my prospects right out of college. As for  experience, all I have is that I am currently working as a software  developer (web) for a tiny startup (based at my university) part-time  which is also what I did this over last summer. I feel super  disadvantaged with my degree, but I will be taking as many CS classes as  I can.&lt;br/&gt;\nSeeing that I am pretty late to the party and haven&amp;#39;t sent in  a single application currently, I am not really sure where to start. I  am pretty slammed with my classes and work, so I haven&amp;#39;t had much time  to build other projects (that are not work) for the resume or even apply  to anything. Where do you guys think I should start? For a non-CS major  what should my first step be? I could pivot to analytics as that makes  much more sense with my degree but I enjoy building things than  discovering I suppose. A lot of people I know and stories I have heard  have gone with pursuing a masters degree but I don&amp;#39;t want to more school  just because everyone else is. I feel like learning on the job or with  projects would be much more cost-efficient and a better plan for me.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184vr3i", "is_robot_indexable": true, "report_reasons": null, "author": "neshybear_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184vr3i/if_you_were_a_senior_in_college_and_just_realized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184vr3i/if_you_were_a_senior_in_college_and_just_realized/", "subreddit_subscribers": 142055, "created_utc": 1701063788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a very large bank and  work on Ab initio for ETL devolopment. My tech stack is an abinitio,Oracle SQL Developer, autosys, and related stuff. I really done want to continue in Abinitio as there is limited scope. How do I transition to more modern techstack? Should I directly start doing projects on it or do I learn from tutorials? And should I fake my techstack for interview? Any tips?", "author_fullname": "t2_5fcjx0twd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I transition from On premise no code ETL devoloper to modern tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184alia", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701005634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701004910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a very large bank and  work on Ab initio for ETL devolopment. My tech stack is an abinitio,Oracle SQL Developer, autosys, and related stuff. I really done want to continue in Abinitio as there is limited scope. How do I transition to more modern techstack? Should I directly start doing projects on it or do I learn from tutorials? And should I fake my techstack for interview? Any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "184alia", "is_robot_indexable": true, "report_reasons": null, "author": "Tasty_Conference8547", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184alia/how_do_i_transition_from_on_premise_no_code_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184alia/how_do_i_transition_from_on_premise_no_code_etl/", "subreddit_subscribers": 142055, "created_utc": 1701004910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I am a Product Manager at a FinTech. We use Looker. I want to understand how I can analyze customer data. Currently I use Zendesk for ticketing. This flows to snowflake\u00a0+ looker for insights.   \n\n\nI need a better way to link feedback to impact metrics like CSAT, churn, expansion, referrals, etc. aka how important is this piece of feedback.\u00a0Do you have any suggestions on any tools that offer this or how I can build this in -house? ", "author_fullname": "t2_nvnticro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer Success Data Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184vzeo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701064665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am a Product Manager at a FinTech. We use Looker. I want to understand how I can analyze customer data. Currently I use Zendesk for ticketing. This flows to snowflake\u00a0+ looker for insights.   &lt;/p&gt;\n\n&lt;p&gt;I need a better way to link feedback to impact metrics like CSAT, churn, expansion, referrals, etc. aka how important is this piece of feedback.\u00a0Do you have any suggestions on any tools that offer this or how I can build this in -house? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184vzeo", "is_robot_indexable": true, "report_reasons": null, "author": "Scary-Swing2852", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184vzeo/customer_success_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184vzeo/customer_success_data_analysis/", "subreddit_subscribers": 142055, "created_utc": 1701064665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All!\n\nI currently have 3.5 years experience in primarily Teradata Architecture/ Development and looking to transition into Data Engineering. My skillset is: Teradata SQL, Query Performance Tuning, writing Teradata BTEQ scripts, Unix, AutoSys, basic Python). I briefly dabbled little bit with Hive. \n\nI mainly work in a Teradata shop and want to expand into more diverse data engineering tech stack. I understand that most interviews are based on sql+python+data modeling plus questions around my experience. \n\nCan you point out which areas in Python to focus for interviews? I don\u2019t have much industry experience in Python in my current role. What courses would you suggest to get a solid recap of Python?\n\nAlso which data structures and algorithms you suggest to learn/practice? Any resources on here ?\n\nThanks!", "author_fullname": "t2_6msghwx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning into Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184oosh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701042309.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All!&lt;/p&gt;\n\n&lt;p&gt;I currently have 3.5 years experience in primarily Teradata Architecture/ Development and looking to transition into Data Engineering. My skillset is: Teradata SQL, Query Performance Tuning, writing Teradata BTEQ scripts, Unix, AutoSys, basic Python). I briefly dabbled little bit with Hive. &lt;/p&gt;\n\n&lt;p&gt;I mainly work in a Teradata shop and want to expand into more diverse data engineering tech stack. I understand that most interviews are based on sql+python+data modeling plus questions around my experience. &lt;/p&gt;\n\n&lt;p&gt;Can you point out which areas in Python to focus for interviews? I don\u2019t have much industry experience in Python in my current role. What courses would you suggest to get a solid recap of Python?&lt;/p&gt;\n\n&lt;p&gt;Also which data structures and algorithms you suggest to learn/practice? Any resources on here ?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "184oosh", "is_robot_indexable": true, "report_reasons": null, "author": "billytimmy123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184oosh/transitioning_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184oosh/transitioning_into_data_engineering/", "subreddit_subscribers": 142055, "created_utc": 1701042309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any experience with these so-called Financial EDM such as GoldenSource, Matrix Rimes and Finbourne. Can someone shares some insights on the differences between these EDM and Snowflake/Databricks Lakehouse. ", "author_fullname": "t2_dgqi4197", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Financial EDM VS Snowflake/Databricks Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184tr6h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701056885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any experience with these so-called Financial EDM such as GoldenSource, Matrix Rimes and Finbourne. Can someone shares some insights on the differences between these EDM and Snowflake/Databricks Lakehouse. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184tr6h", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Criticism-8127", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184tr6h/financial_edm_vs_snowflakedatabricks_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184tr6h/financial_edm_vs_snowflakedatabricks_lakehouse/", "subreddit_subscribers": 142055, "created_utc": 1701056885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any thoughts welcome, expecially when linked to power bi or tableau", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with databricks sql? Opinions? Limitations? Positives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184jfyj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701029241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any thoughts welcome, expecially when linked to power bi or tableau&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184jfyj", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184jfyj/experience_with_databricks_sql_opinions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184jfyj/experience_with_databricks_sql_opinions/", "subreddit_subscribers": 142055, "created_utc": 1701029241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! \ud83d\udc4b\n\nI'm one of the folks behind Airbook. We're super excited about this project we've been working on \u2013 it's a data notebook designed for teams who need to pull information from a bunch of different places like Salesforce, Google Analytics, Hubspot, Amplitude ++ various databases (think MySQL, PostgreSQL, etc.), and data warehouses (Snowflake, Redshift, BigQuery, you name it).\n\nWhat's cool about Airbook is that it lets you connect with over 150 data sources natively and query using SQL or a no-code approach (and hey, Python is on the way!). The best part? You can do all this without the hassle of jumping between a million tools.\n\nWe've added some neat collaborative features, kind of like what you'd find in Google Docs, so teams can work together seamlessly.\n\nWe're riding high from ranking #1 on Product Hunt recently (yay us!), and now we're on the lookout for design partners. We want to make Airbook even better and validate our upcoming features.   \n\n\nIf you find value here and can spend some time giving us feedback, I'd love to chat with you!  \n\n\n&amp;#x200B;", "author_fullname": "t2_qand76u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Notebook built for collaboration and cross-tool reporting across business apps, databases &amp; data warehouses- using SQL/Python or No-code- in one place.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18506t0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701081959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m one of the folks behind Airbook. We&amp;#39;re super excited about this project we&amp;#39;ve been working on \u2013 it&amp;#39;s a data notebook designed for teams who need to pull information from a bunch of different places like Salesforce, Google Analytics, Hubspot, Amplitude ++ various databases (think MySQL, PostgreSQL, etc.), and data warehouses (Snowflake, Redshift, BigQuery, you name it).&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s cool about Airbook is that it lets you connect with over 150 data sources natively and query using SQL or a no-code approach (and hey, Python is on the way!). The best part? You can do all this without the hassle of jumping between a million tools.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve added some neat collaborative features, kind of like what you&amp;#39;d find in Google Docs, so teams can work together seamlessly.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re riding high from ranking #1 on Product Hunt recently (yay us!), and now we&amp;#39;re on the lookout for design partners. We want to make Airbook even better and validate our upcoming features.   &lt;/p&gt;\n\n&lt;p&gt;If you find value here and can spend some time giving us feedback, I&amp;#39;d love to chat with you!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18506t0", "is_robot_indexable": true, "report_reasons": null, "author": "AirbookIO", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18506t0/data_notebook_built_for_collaboration_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18506t0/data_notebook_built_for_collaboration_and/", "subreddit_subscribers": 142055, "created_utc": 1701081959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, we are in the process of recruiting a Data Engineer so please forgive my ignorance, and if this is not the right place to be asking, my apologies.\n\nAs a SQL DBA I am looking to build a date/calendar dimension table (Date, Qtr, Year, Financial Year etc.) in our DW but what is the best approach if there is an extra column in the fact table (Site) that affects a one of the date columns, e.g.\n\n\\-Fact table\n\n* RecordId (PK)\n* RecordDate \\[FK\\]\n* SiteId (FK) \\[this would be a school or office\\]\n\n\\-Calendar Dimension\n\n* Date (PK)\n* Year\n* Quarter\n* ...\n* SchoolTerm\n\nThe problem is, that for Site 1 a specific date may refer to term 1, for site 2 that may be term 2.\n\nMy thinking is that I should build a standard Calendar dimension for conformity and use cases where a fact may not be related to a site.\n\nI would then build a Term Dates dimension with a surrogate key and populate during ETL?  It feels a bit redundant to do this but feels more correct.  Also, would a surrogate like YYYYMMDD\\[SiteId\\] be the best idea, if not what is a better approach?\n\nThanks", "author_fullname": "t2_153iwm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Date dimension query for site specific column", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184z704", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701077866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, we are in the process of recruiting a Data Engineer so please forgive my ignorance, and if this is not the right place to be asking, my apologies.&lt;/p&gt;\n\n&lt;p&gt;As a SQL DBA I am looking to build a date/calendar dimension table (Date, Qtr, Year, Financial Year etc.) in our DW but what is the best approach if there is an extra column in the fact table (Site) that affects a one of the date columns, e.g.&lt;/p&gt;\n\n&lt;p&gt;-Fact table&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;RecordId (PK)&lt;/li&gt;\n&lt;li&gt;RecordDate [FK]&lt;/li&gt;\n&lt;li&gt;SiteId (FK) [this would be a school or office]&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;-Calendar Dimension&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Date (PK)&lt;/li&gt;\n&lt;li&gt;Year&lt;/li&gt;\n&lt;li&gt;Quarter&lt;/li&gt;\n&lt;li&gt;...&lt;/li&gt;\n&lt;li&gt;SchoolTerm&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The problem is, that for Site 1 a specific date may refer to term 1, for site 2 that may be term 2.&lt;/p&gt;\n\n&lt;p&gt;My thinking is that I should build a standard Calendar dimension for conformity and use cases where a fact may not be related to a site.&lt;/p&gt;\n\n&lt;p&gt;I would then build a Term Dates dimension with a surrogate key and populate during ETL?  It feels a bit redundant to do this but feels more correct.  Also, would a surrogate like YYYYMMDD[SiteId] be the best idea, if not what is a better approach?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184z704", "is_robot_indexable": true, "report_reasons": null, "author": "Rahmorak", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184z704/date_dimension_query_for_site_specific_column/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184z704/date_dimension_query_for_site_specific_column/", "subreddit_subscribers": 142055, "created_utc": 1701077866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI'm a copywriter/technical content writer. I have to write an article about Databricks and I'd love to get some insights from people who use this platform on a daily basis. Could you please help me? :)\n\n1. What does Databricks help you accomplish?\n2. What are its most remarkable features?\n3. Where does it fall flat or not deliver as expected?\n4. Could you let me know why you chose Databricks over some other competitor?\n\nOr, feel free to write anything about your experience with Databricks.\n\nThank you!\n\nP.S. I'm an independent freelancer. I am not affiliated with Databricks.", "author_fullname": "t2_u1xfod9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Research] Tell me about your experience with Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184y7cx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701073529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a copywriter/technical content writer. I have to write an article about Databricks and I&amp;#39;d love to get some insights from people who use this platform on a daily basis. Could you please help me? :)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What does Databricks help you accomplish?&lt;/li&gt;\n&lt;li&gt;What are its most remarkable features?&lt;/li&gt;\n&lt;li&gt;Where does it fall flat or not deliver as expected?&lt;/li&gt;\n&lt;li&gt;Could you let me know why you chose Databricks over some other competitor?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Or, feel free to write anything about your experience with Databricks.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;P.S. I&amp;#39;m an independent freelancer. I am not affiliated with Databricks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "184y7cx", "is_robot_indexable": true, "report_reasons": null, "author": "helenegeria", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184y7cx/research_tell_me_about_your_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184y7cx/research_tell_me_about_your_experience_with/", "subreddit_subscribers": 142055, "created_utc": 1701073529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all. I'm having difficulty with my assignment of HBase shell. I basically have a dataset consists of 10 columns with integer values. When I imported it from hdfs into Hbase the values became string as what Hbase supported. \n\nWhat I want to do is to use scan or get queries with filter of less than or more than operator. But since hbase only filters lexicographically, the results is not what I wanted. \n\nSo is there any way I can solve this problem strictly using hbase shell only? No java code etc. \n\nP/s: I'm using cloudera VM to do all this", "author_fullname": "t2_p14zx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with HBase Shell", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184tyfo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701057557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I&amp;#39;m having difficulty with my assignment of HBase shell. I basically have a dataset consists of 10 columns with integer values. When I imported it from hdfs into Hbase the values became string as what Hbase supported. &lt;/p&gt;\n\n&lt;p&gt;What I want to do is to use scan or get queries with filter of less than or more than operator. But since hbase only filters lexicographically, the results is not what I wanted. &lt;/p&gt;\n\n&lt;p&gt;So is there any way I can solve this problem strictly using hbase shell only? No java code etc. &lt;/p&gt;\n\n&lt;p&gt;P/s: I&amp;#39;m using cloudera VM to do all this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184tyfo", "is_robot_indexable": true, "report_reasons": null, "author": "arenoobies", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184tyfo/help_with_hbase_shell/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184tyfo/help_with_hbase_shell/", "subreddit_subscribers": 142055, "created_utc": 1701057557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI have a medaillon architecture with some dimension tables\n\nIn the silver layer, I have a dimension table (product) with millions of rows, table is saved as SCD1.\n\nI built a gold dimension table (product) with some renaming and transformation (adding primary key for example), but each time I want to load it the only way I found is to fully read the silver table, update when primary key match and insert new rows.\n\nIt works, but each time I need to read all the silver table and update/insert all my gold table.\n\nis there any better way to do it ? \n\n(i'm using notebook with pyspark)\n\nthanks for your help !", "author_fullname": "t2_gprs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental Load Data in Dimension (gold layer) without fully reading silver table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184flc4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701019087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I have a medaillon architecture with some dimension tables&lt;/p&gt;\n\n&lt;p&gt;In the silver layer, I have a dimension table (product) with millions of rows, table is saved as SCD1.&lt;/p&gt;\n\n&lt;p&gt;I built a gold dimension table (product) with some renaming and transformation (adding primary key for example), but each time I want to load it the only way I found is to fully read the silver table, update when primary key match and insert new rows.&lt;/p&gt;\n\n&lt;p&gt;It works, but each time I need to read all the silver table and update/insert all my gold table.&lt;/p&gt;\n\n&lt;p&gt;is there any better way to do it ? &lt;/p&gt;\n\n&lt;p&gt;(i&amp;#39;m using notebook with pyspark)&lt;/p&gt;\n\n&lt;p&gt;thanks for your help !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184flc4", "is_robot_indexable": true, "report_reasons": null, "author": "qintarra", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184flc4/incremental_load_data_in_dimension_gold_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184flc4/incremental_load_data_in_dimension_gold_layer/", "subreddit_subscribers": 142055, "created_utc": 1701019087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any data integration documentation/ course that they would reccomend to someone who just started in this area?", "author_fullname": "t2_rq20uwoa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data integration resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184avz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701005850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any data integration documentation/ course that they would reccomend to someone who just started in this area?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "184avz3", "is_robot_indexable": true, "report_reasons": null, "author": "YesIDoHaveaVentKink", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184avz3/data_integration_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184avz3/data_integration_resources/", "subreddit_subscribers": 142055, "created_utc": 1701005850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am doing my personal project right now where I scrape the data and in the end I would like to have clean database with data feasible for analysis. I was wondering how shall I approach this - shall I load raw data to postgres database1 and then prepare another python script, which would clean the data from database1 and load it to postgres database2? I guess I would also need some metadeta for db efficiency and operational processes (I don't want to load offers to db2 if there is the exact same data already ingested)", "author_fullname": "t2_2oo6rj79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Web scraping/database ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1851f1e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701086589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am doing my personal project right now where I scrape the data and in the end I would like to have clean database with data feasible for analysis. I was wondering how shall I approach this - shall I load raw data to postgres database1 and then prepare another python script, which would clean the data from database1 and load it to postgres database2? I guess I would also need some metadeta for db efficiency and operational processes (I don&amp;#39;t want to load offers to db2 if there is the exact same data already ingested)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1851f1e", "is_robot_indexable": true, "report_reasons": null, "author": "Omnetfh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1851f1e/web_scrapingdatabase_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1851f1e/web_scrapingdatabase_ingestion/", "subreddit_subscribers": 142055, "created_utc": 1701086589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just needed some insights on the right approach that can be taken when the we need to create a dataframe by picking up selected columns from multiple dataframes. I did try union and unionall these append in the end doesn\u2019t solve my issue. I tried using merge by importing pandas in pyspark but it probably takes longer time compared to pyspark. Need some suggestions struggling for a while now", "author_fullname": "t2_ecszv3jgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Merge in pyspark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184yrfi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701075971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just needed some insights on the right approach that can be taken when the we need to create a dataframe by picking up selected columns from multiple dataframes. I did try union and unionall these append in the end doesn\u2019t solve my issue. I tried using merge by importing pandas in pyspark but it probably takes longer time compared to pyspark. Need some suggestions struggling for a while now&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "184yrfi", "is_robot_indexable": true, "report_reasons": null, "author": "Neon_Sorcerer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184yrfi/merge_in_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184yrfi/merge_in_pyspark/", "subreddit_subscribers": 142055, "created_utc": 1701075971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With our dbForge for SQL Server product line, a collection of tools for database development, management, and administration, Devart joins the Cyber Monday sale. \n\nTake advantage of this fantastic opportunity to get the database solutions you've been eyeing! This exclusive deal is valid from November 27 to December 3.\n\nJust pick the tools you need and get your big discounts now: \n\n[https://www.devart.com/cybermonday.html#sql](https://www.devart.com/cybermonday.html#sql)  ", "author_fullname": "t2_l03fko6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get up to 50% off Devart database tools!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_184zx5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701080888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With our dbForge for SQL Server product line, a collection of tools for database development, management, and administration, Devart joins the Cyber Monday sale. &lt;/p&gt;\n\n&lt;p&gt;Take advantage of this fantastic opportunity to get the database solutions you&amp;#39;ve been eyeing! This exclusive deal is valid from November 27 to December 3.&lt;/p&gt;\n\n&lt;p&gt;Just pick the tools you need and get your big discounts now: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.devart.com/cybermonday.html#sql\"&gt;https://www.devart.com/cybermonday.html#sql&lt;/a&gt;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/K2N8TUPiTmz9zd5ZVDni-jZkijo9Z4H7ZIZXchqEP-k.jpg?auto=webp&amp;s=eb237f9930b3809ef4e0f9b3dc4b565a91b4aac2", "width": 146, "height": 57}, "resolutions": [{"url": "https://external-preview.redd.it/K2N8TUPiTmz9zd5ZVDni-jZkijo9Z4H7ZIZXchqEP-k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=566bcec48eb65ff53e2c70f77becc1dbe3d5936d", "width": 108, "height": 42}], "variants": {}, "id": "y0dxQxalo2eI5xqsrBiW8YC-imuDxBqSTKF-C9qiVyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "184zx5e", "is_robot_indexable": true, "report_reasons": null, "author": "WeaknessAlive754", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/184zx5e/get_up_to_50_off_devart_database_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/184zx5e/get_up_to_50_off_devart_database_tools/", "subreddit_subscribers": 142055, "created_utc": 1701080888.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}