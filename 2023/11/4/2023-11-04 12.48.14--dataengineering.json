{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just accepted my first job as a data engineer. Before I start this new chapter, I wanted to set down my thoughts on what I did to get here. My background is pretty weird so this path won\u2019t work for everyone, but I just wanted to write it down, because it would have been helpful to my previous self 2 years ago, so may be helpful to someone else.\n\nPREFACE:\n\n* Don\u2019t do this, if you hate coding. You may not know this yet. Try a few python courses, and if you absolutely HATE IT, you should find another calling. Feeling confused and feeling that it is hard is NORMAL. \u201cConfusion is the sweat of learning.\u201d \u2014 Richard Feynman. It is hard for EVERYONE.\n* Don\u2019t do this, if you are not ready to learn about why statistics are useful. You don\u2019t have to be a stats genius at all. But you do need to intuitively recognize and endorse that statistics are useful and want to be decent with at least basic descriptive statistics. I\u2019m not talking about probability, but you will need to be good with basic descriptive statistics. If you LOVE statistics, consider data science also.\n\nDETAILS:\n\n* DataCamp python courses up to intermediate level\n* Google data analytics certificate (free through Goodwill Industries locally).\n* Many many many youtube videos. If you don\u2019t know what something is, YouTube it. If you heard about something in a course you don\u2019t understand, YouTube it. Listen to multiple people explain the idea. It will help you grasp it to hear different ways of articulating the shape of the concept. It is hard early on, because you may feel overwhelmed. Keep after it.\n* Many LinkedIn learning courses. (Free through local library). SQL, Python, and database management.\n* Learn about cloud computing. I recommend doing AWS or Azure. If you can pass the AWS SAA test, you will be well-versed in many important concepts for data engineering. BUT IT WILL NOT GET YOU A JOB. To gain AWS Cloud Practitioner and Solutions Architect Associate:\n* A Cloud Guru year membership (pretty good, but I think there are cheaper options out there that are as good \u2014 eg Learn Cantrill).\n* Many many youtube videos about AWS\u2014 Be a Better Dev, Digital Cloud Training, ExamPro, Cloud with Raj, Stephane Marek are top channels, in addition to AWS channel\n* Coursera courses on database management and many other things.\n* Learn about database normalization. Find a project to work on normalization. Find a dataset and normalize it to 3NF in an RDBMS\n* Learn what the difference is between an OLTP and OLAP db is.\n* Then learn what a data warehouse is \u2014 dimensional modeling in star schemas.\n* Nucamp Backend Bootcamp \u2014 recommend. About $2,600.00. They will have you do DB normalization in this.\n* Data Mentorship Project \u2014 look into them. Not super active, but very good. If they don\u2019t do another cohort, find mentors. Only one at a time, but one after another. This is how I got the best advice and got my first job \u2014 a mentor had a spot open up on a team she was leading and the invited me to apply. I would even say pay for a mentor if you have to. I know that sounds distasteful, but think of it as hiring a coach.\n* Turing College Data Engineering Bootcamp \u2014 seems expensive, but VERY good value for your money. About $4,800.00. Big investment. Challenging. Good.\n* If you are not in a structured program, build projects. BUILD PROJECTS. Ideally find a real world problem that you or someone you know has and see if they have any data on it OR even better see if you can think of a way to find data on it. Then start doing stuff with it.\n* Go to all the conferences, meetups, and networking events that you possibly have time for. Talk to people, ask them what they do. Tell them what you\u2019re learning. Just be curious. It does not have to be weird. Talk to all the people you know who code. Ask to take them to coffee and learn about what they know. Ask stupid questions.\n* Work every single day except 1 day off on a project. LOSE ALL YOUR OTHER NON PRODUCTIVE HABITS. I gave up TV and video games and hanging out with friends to find time. Change your mind: one type of work is a break from another type of work.\n* Learn to view coding as fun. Do not look for solutions. Look for new errors in your code. Don\u2019t be so arrogant as to think your code will work the first time you run it. Say to yourself, \u201cJust show me the next error.\u201d\n* \u201cFall in love with the problem, not the solution.\u201d -Uri Levine.\n* \u201cThe obstacle is the way.\u201d \u2014 Marcus Aurelius\n* Listen to podcasts about DE \u2014 Joe Reis Show is my favorite. Datacamp has a pretty good podcast also for general data. It is useful to be conversant in how the tools work roughly. But don\u2019t go off on tangents studying new tools. Stick with python and SQL fundamentals.\n* When your brain is stuffed, take a break and go for a walk. Especially around your neighborhood or a park if you can. There is good research that shows that walking through geographically varied places helps with memory consolidation and recall.\n* Every once in a while take a week and just do practice questions. I use LeetCode, Hackerrank, CodeSignal, and others but those mainly.\n* Again, find mentors.\n* Did I mention that it is important to find a mentor? Of all the pieces of advice, this or networking are the ones that are ultimately most likely to get you a job. But you can only impress your mentor, if you\u2019re working hard, doing many of the other things I\u2019ve already written about.", "author_fullname": "t2_74v59rzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources I Used to Become a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n51ar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 113, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 113, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699053598.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699045433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just accepted my first job as a data engineer. Before I start this new chapter, I wanted to set down my thoughts on what I did to get here. My background is pretty weird so this path won\u2019t work for everyone, but I just wanted to write it down, because it would have been helpful to my previous self 2 years ago, so may be helpful to someone else.&lt;/p&gt;\n\n&lt;p&gt;PREFACE:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Don\u2019t do this, if you hate coding. You may not know this yet. Try a few python courses, and if you absolutely HATE IT, you should find another calling. Feeling confused and feeling that it is hard is NORMAL. \u201cConfusion is the sweat of learning.\u201d \u2014 Richard Feynman. It is hard for EVERYONE.&lt;/li&gt;\n&lt;li&gt;Don\u2019t do this, if you are not ready to learn about why statistics are useful. You don\u2019t have to be a stats genius at all. But you do need to intuitively recognize and endorse that statistics are useful and want to be decent with at least basic descriptive statistics. I\u2019m not talking about probability, but you will need to be good with basic descriptive statistics. If you LOVE statistics, consider data science also.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;DETAILS:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DataCamp python courses up to intermediate level&lt;/li&gt;\n&lt;li&gt;Google data analytics certificate (free through Goodwill Industries locally).&lt;/li&gt;\n&lt;li&gt;Many many many youtube videos. If you don\u2019t know what something is, YouTube it. If you heard about something in a course you don\u2019t understand, YouTube it. Listen to multiple people explain the idea. It will help you grasp it to hear different ways of articulating the shape of the concept. It is hard early on, because you may feel overwhelmed. Keep after it.&lt;/li&gt;\n&lt;li&gt;Many LinkedIn learning courses. (Free through local library). SQL, Python, and database management.&lt;/li&gt;\n&lt;li&gt;Learn about cloud computing. I recommend doing AWS or Azure. If you can pass the AWS SAA test, you will be well-versed in many important concepts for data engineering. BUT IT WILL NOT GET YOU A JOB. To gain AWS Cloud Practitioner and Solutions Architect Associate:&lt;/li&gt;\n&lt;li&gt;A Cloud Guru year membership (pretty good, but I think there are cheaper options out there that are as good \u2014 eg Learn Cantrill).&lt;/li&gt;\n&lt;li&gt;Many many youtube videos about AWS\u2014 Be a Better Dev, Digital Cloud Training, ExamPro, Cloud with Raj, Stephane Marek are top channels, in addition to AWS channel&lt;/li&gt;\n&lt;li&gt;Coursera courses on database management and many other things.&lt;/li&gt;\n&lt;li&gt;Learn about database normalization. Find a project to work on normalization. Find a dataset and normalize it to 3NF in an RDBMS&lt;/li&gt;\n&lt;li&gt;Learn what the difference is between an OLTP and OLAP db is.&lt;/li&gt;\n&lt;li&gt;Then learn what a data warehouse is \u2014 dimensional modeling in star schemas.&lt;/li&gt;\n&lt;li&gt;Nucamp Backend Bootcamp \u2014 recommend. About $2,600.00. They will have you do DB normalization in this.&lt;/li&gt;\n&lt;li&gt;Data Mentorship Project \u2014 look into them. Not super active, but very good. If they don\u2019t do another cohort, find mentors. Only one at a time, but one after another. This is how I got the best advice and got my first job \u2014 a mentor had a spot open up on a team she was leading and the invited me to apply. I would even say pay for a mentor if you have to. I know that sounds distasteful, but think of it as hiring a coach.&lt;/li&gt;\n&lt;li&gt;Turing College Data Engineering Bootcamp \u2014 seems expensive, but VERY good value for your money. About $4,800.00. Big investment. Challenging. Good.&lt;/li&gt;\n&lt;li&gt;If you are not in a structured program, build projects. BUILD PROJECTS. Ideally find a real world problem that you or someone you know has and see if they have any data on it OR even better see if you can think of a way to find data on it. Then start doing stuff with it.&lt;/li&gt;\n&lt;li&gt;Go to all the conferences, meetups, and networking events that you possibly have time for. Talk to people, ask them what they do. Tell them what you\u2019re learning. Just be curious. It does not have to be weird. Talk to all the people you know who code. Ask to take them to coffee and learn about what they know. Ask stupid questions.&lt;/li&gt;\n&lt;li&gt;Work every single day except 1 day off on a project. LOSE ALL YOUR OTHER NON PRODUCTIVE HABITS. I gave up TV and video games and hanging out with friends to find time. Change your mind: one type of work is a break from another type of work.&lt;/li&gt;\n&lt;li&gt;Learn to view coding as fun. Do not look for solutions. Look for new errors in your code. Don\u2019t be so arrogant as to think your code will work the first time you run it. Say to yourself, \u201cJust show me the next error.\u201d&lt;/li&gt;\n&lt;li&gt;\u201cFall in love with the problem, not the solution.\u201d -Uri Levine.&lt;/li&gt;\n&lt;li&gt;\u201cThe obstacle is the way.\u201d \u2014 Marcus Aurelius&lt;/li&gt;\n&lt;li&gt;Listen to podcasts about DE \u2014 Joe Reis Show is my favorite. Datacamp has a pretty good podcast also for general data. It is useful to be conversant in how the tools work roughly. But don\u2019t go off on tangents studying new tools. Stick with python and SQL fundamentals.&lt;/li&gt;\n&lt;li&gt;When your brain is stuffed, take a break and go for a walk. Especially around your neighborhood or a park if you can. There is good research that shows that walking through geographically varied places helps with memory consolidation and recall.&lt;/li&gt;\n&lt;li&gt;Every once in a while take a week and just do practice questions. I use LeetCode, Hackerrank, CodeSignal, and others but those mainly.&lt;/li&gt;\n&lt;li&gt;Again, find mentors.&lt;/li&gt;\n&lt;li&gt;Did I mention that it is important to find a mentor? Of all the pieces of advice, this or networking are the ones that are ultimately most likely to get you a job. But you can only impress your mentor, if you\u2019re working hard, doing many of the other things I\u2019ve already written about.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17n51ar", "is_robot_indexable": true, "report_reasons": null, "author": "codeslp", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n51ar/resources_i_used_to_become_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n51ar/resources_i_used_to_become_a_data_engineer/", "subreddit_subscribers": 137809, "created_utc": 1699045433.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you build great data teams? What is the best advice or lessons you have learnt?\n\nAs a manager and a leader this is something I would love to learn about so welcome your thoughts and discussions.", "author_fullname": "t2_6jsoipfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you build great data teams? What is the best advice or lessons you have learnt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mzdka", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699029964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you build great data teams? What is the best advice or lessons you have learnt?&lt;/p&gt;\n\n&lt;p&gt;As a manager and a leader this is something I would love to learn about so welcome your thoughts and discussions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mzdka", "is_robot_indexable": true, "report_reasons": null, "author": "TheDataGentleman", "discussion_type": null, "num_comments": 32, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mzdka/how_do_you_build_great_data_teams_what_is_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mzdka/how_do_you_build_great_data_teams_what_is_the/", "subreddit_subscribers": 137809, "created_utc": 1699029964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious to understand how you guys do local testing for your pipelines. \n\nI have to wait for others to complete their work on the dev cluster and then start working. (Yes, it's ancient infrastructure).   \nWould like to understand what this experience looks like at your orgs and how much time does it take.", "author_fullname": "t2_6fccledv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys do local testing effectively?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mtri2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699013898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious to understand how you guys do local testing for your pipelines. &lt;/p&gt;\n\n&lt;p&gt;I have to wait for others to complete their work on the dev cluster and then start working. (Yes, it&amp;#39;s ancient infrastructure).&lt;br/&gt;\nWould like to understand what this experience looks like at your orgs and how much time does it take.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mtri2", "is_robot_indexable": true, "report_reasons": null, "author": "deadlypiranha", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mtri2/how_do_you_guys_do_local_testing_effectively/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mtri2/how_do_you_guys_do_local_testing_effectively/", "subreddit_subscribers": 137809, "created_utc": 1699013898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI failed an interview test.\nThere were two questions, one for modeling a Python ETL from operational to analytics DB and other to design a pipeline for alerting delayed orders. Each question should be solved in 1h.\nIn the first question I was quite nervous and it made me tremble for silly things (like connecting to DB), but I was able to develop the CTE.\nThe second question was also tense but I felt a little better. I designed the whole pipeline according to the tools I know I could use (like Kafka and Airflow). I tried to get all the scenarios and avoid data loss by using orchestrators and secondary message queueing services like SQS.\n\nThe feedback showed that I failed mostly due to overengineering SQL CTEs and pipeline design.\n\nI will not share details about the test, but I'd like to discuss ways of not overengineering. Especially while developing pipelines that may be resilient. For example,\n- How to deal with a failing Kafka container and avoid data loss? Is it overengineering to have a secondary message queue application for those cases?\n- Having many query windows in a CTE is overengineering?\n- A personal one: During technical tasks I feel like the most idiot person on earth and even silly things that I know how to do become confusing. Probably many people deal with that, how do you deal with it?\n\nEDIT: Adding more details about everything.\n\nIn a nutshell:\n\nMobile app -&gt; Operational DB -&gt; ETL -&gt; Analytics DB\n\nMobile app creates order, sends to Operational DB. Finalizes order, sends to Operational DB.\n\nOperational DB also has some tables related to order capacity of stores, etc. only to make the CTE harder.\n\nAnalytics DB contains transformed data for BI, Data Catalog, etc.\n\nFirst question: Develop ETL to obtain transformed analytics data and store in Analytics DB.\n\nMy answer: I created a SQL CTE to process data. It was considered overengineering. (This one I got more nervous about and it made me fail faster, but is not the point. As previous comments say, if I made the right questions to understand everything first I could have made a better solution).\n\nSecond question: ETL may be too slow. We want to know if an order delays NOW. No matter how. Do your best.\n(AFAIK checking if is delay or not is not important in the question, just the pipeline itself).\n\nMy answer: Kafka receives real-time data sent by the app. Data is processed in airflow dag to check if it is delayed or not, and feeds specific Analytics DB table for real-time delay checks. Everything running in a Kubernetes cluster. \nThey asked me what if Kafka fails, I suggested having a secondary Kafka container or a queue message system like SQS for when main Kafka is down.\nIt was considered also overengineering.\n", "author_fullname": "t2_9vbytbhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overengineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mub9p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699052871.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699015657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I failed an interview test.\nThere were two questions, one for modeling a Python ETL from operational to analytics DB and other to design a pipeline for alerting delayed orders. Each question should be solved in 1h.\nIn the first question I was quite nervous and it made me tremble for silly things (like connecting to DB), but I was able to develop the CTE.\nThe second question was also tense but I felt a little better. I designed the whole pipeline according to the tools I know I could use (like Kafka and Airflow). I tried to get all the scenarios and avoid data loss by using orchestrators and secondary message queueing services like SQS.&lt;/p&gt;\n\n&lt;p&gt;The feedback showed that I failed mostly due to overengineering SQL CTEs and pipeline design.&lt;/p&gt;\n\n&lt;p&gt;I will not share details about the test, but I&amp;#39;d like to discuss ways of not overengineering. Especially while developing pipelines that may be resilient. For example,\n- How to deal with a failing Kafka container and avoid data loss? Is it overengineering to have a secondary message queue application for those cases?\n- Having many query windows in a CTE is overengineering?\n- A personal one: During technical tasks I feel like the most idiot person on earth and even silly things that I know how to do become confusing. Probably many people deal with that, how do you deal with it?&lt;/p&gt;\n\n&lt;p&gt;EDIT: Adding more details about everything.&lt;/p&gt;\n\n&lt;p&gt;In a nutshell:&lt;/p&gt;\n\n&lt;p&gt;Mobile app -&amp;gt; Operational DB -&amp;gt; ETL -&amp;gt; Analytics DB&lt;/p&gt;\n\n&lt;p&gt;Mobile app creates order, sends to Operational DB. Finalizes order, sends to Operational DB.&lt;/p&gt;\n\n&lt;p&gt;Operational DB also has some tables related to order capacity of stores, etc. only to make the CTE harder.&lt;/p&gt;\n\n&lt;p&gt;Analytics DB contains transformed data for BI, Data Catalog, etc.&lt;/p&gt;\n\n&lt;p&gt;First question: Develop ETL to obtain transformed analytics data and store in Analytics DB.&lt;/p&gt;\n\n&lt;p&gt;My answer: I created a SQL CTE to process data. It was considered overengineering. (This one I got more nervous about and it made me fail faster, but is not the point. As previous comments say, if I made the right questions to understand everything first I could have made a better solution).&lt;/p&gt;\n\n&lt;p&gt;Second question: ETL may be too slow. We want to know if an order delays NOW. No matter how. Do your best.\n(AFAIK checking if is delay or not is not important in the question, just the pipeline itself).&lt;/p&gt;\n\n&lt;p&gt;My answer: Kafka receives real-time data sent by the app. Data is processed in airflow dag to check if it is delayed or not, and feeds specific Analytics DB table for real-time delay checks. Everything running in a Kubernetes cluster. \nThey asked me what if Kafka fails, I suggested having a secondary Kafka container or a queue message system like SQS for when main Kafka is down.\nIt was considered also overengineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17mub9p", "is_robot_indexable": true, "report_reasons": null, "author": "araraquest", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mub9p/overengineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mub9p/overengineering/", "subreddit_subscribers": 137809, "created_utc": 1699015657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_56xhg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Our open source philosophy around SQLMesh and SQLGlot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n06va", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1699032163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tobikodata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tobikodata.com/open-source-philosophy.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17n06va", "is_robot_indexable": true, "report_reasons": null, "author": "captaintobs", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n06va/our_open_source_philosophy_around_sqlmesh_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tobikodata.com/open-source-philosophy.html", "subreddit_subscribers": 137809, "created_utc": 1699032163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be \"not on the list\" as much as possible.\n\nIf you had the chance to build a team from scratch, what would you do?", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you had a chance to rebuild your DS/DE team, how would you do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ndwhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699072201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been asked to consolidate and rebuild a data team after a spree of layoffs and reorgs. People have to be realigned to newer projects and priorities. Some of the projects they were working on were scrapped entirely due to lack of funding. As the layoffs would still continue, I want this new  team to be &amp;quot;not on the list&amp;quot; as much as possible.&lt;/p&gt;\n\n&lt;p&gt;If you had the chance to build a team from scratch, what would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ndwhh", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ndwhh/if_you_had_a_chance_to_rebuild_your_dsde_team_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ndwhh/if_you_had_a_chance_to_rebuild_your_dsde_team_how/", "subreddit_subscribers": 137809, "created_utc": 1699072201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nA few months ago, I [posted](https://www.reddit.com/r/dataengineering/comments/14nvyxa/comment/jq9ebe6) about kafka in production. I'm really really happy that many people found it useful and even encouraged me to create another repo for apache flink . So here you go [https://github.com/dttung2905/flink-at-scale](https://github.com/dttung2905/flink-at-scale). Please give it a star if you like it! ", "author_fullname": "t2_tzt33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Flink tech blogs and talks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n82bw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699053675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;A few months ago, I &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/14nvyxa/comment/jq9ebe6\"&gt;posted&lt;/a&gt; about kafka in production. I&amp;#39;m really really happy that many people found it useful and even encouraged me to create another repo for apache flink . So here you go &lt;a href=\"https://github.com/dttung2905/flink-at-scale\"&gt;https://github.com/dttung2905/flink-at-scale&lt;/a&gt;. Please give it a star if you like it! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?auto=webp&amp;s=7f00680184c8b892a7887b77c1b449f03eefc45b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e07d67c542ddebfbba7ed59ee2e49e9fffe2146", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c95042cb3bb93fcd493ef9a65f302f4a8c8dba82", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cea9947ee4e20e24d91d341d51dac7d2862bfb5d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0f94dc413072132b6c1943d521714e2e4d669ee", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=49d1ebf3cf5f1af9011742d5315354f4b863663e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/BE1hqitJ5dK84Edd-EHl9aLs9uzL4bsA5eMVHp3yHe4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9a0948b2704d7826d0c1de2f3e16c8b74797a7cc", "width": 1080, "height": 540}], "variants": {}, "id": "XWSLn7gHr4_6A9pC_Xfus8Hhe5ltPA1aXkh1CZq2gtM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17n82bw", "is_robot_indexable": true, "report_reasons": null, "author": "dttung2905", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n82bw/apache_flink_tech_blogs_and_talks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n82bw/apache_flink_tech_blogs_and_talks/", "subreddit_subscribers": 137809, "created_utc": 1699053675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was asked at work to create an ingestion process in databricks that handles loading an entire table or file containing the entire dataset (historical and all) and only load the new records into the destination table. This destination table would already have all previous data loaded into it. And it\u2019s for a scenario where the dataset is massive so doing a full load may not be worth it. These are the reasons why we only want new data.\n\nI was specifically told we need to use a date time comparison to do so. That is fine, however the problem is that some of these data sets do not have a timestamp for source system record creation. So using a source system record creation timestamp to compare with last ingestion into databricks timestamp doesn\u2019t work. It also doesn\u2019t have an ID in some cases either to do any comparison to the existing delta table.\n\nAm I crazy or is there no way what I\u2019m being asked to do is possible.", "author_fullname": "t2_gx6xvhga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I missing something?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n9agg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699057150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked at work to create an ingestion process in databricks that handles loading an entire table or file containing the entire dataset (historical and all) and only load the new records into the destination table. This destination table would already have all previous data loaded into it. And it\u2019s for a scenario where the dataset is massive so doing a full load may not be worth it. These are the reasons why we only want new data.&lt;/p&gt;\n\n&lt;p&gt;I was specifically told we need to use a date time comparison to do so. That is fine, however the problem is that some of these data sets do not have a timestamp for source system record creation. So using a source system record creation timestamp to compare with last ingestion into databricks timestamp doesn\u2019t work. It also doesn\u2019t have an ID in some cases either to do any comparison to the existing delta table.&lt;/p&gt;\n\n&lt;p&gt;Am I crazy or is there no way what I\u2019m being asked to do is possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17n9agg", "is_robot_indexable": true, "report_reasons": null, "author": "Nelson_and_Wilmont", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n9agg/am_i_missing_something/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n9agg/am_i_missing_something/", "subreddit_subscribers": 137809, "created_utc": 1699057150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the start-up I work in, I have been everything regarding some research project that involved some sort of navigation/positioning. The data collection tool uses Raspberry-pi running ROS, lidar, smartphone, battery (because everything runs on the move), wifi without internet. The smartphone sends sound signals the whole time (44100 values every second), and other sensor data couple of times a second. Everything will be saved as csv files in the pi. Since the location may not have internet, data is directly saved on the pi first. \n\nWhen the pi is connected to our office network it sends any new data to our office NAS storage. Everything json (configs) and csv. And all our python models have to connect to some synology drive to load up the data and do any computation. Our models are only there to calculate some sort of accuracy for research purpose.\n\nMy experience with data is limited but I feel like this is messy and could have been done better. instead of NAS our data could always be pushed to cloud? stream of large continuous values like sound in sql or csv is ok? just wondering how teams who work on sensor data and machine learning models do their data management. Forgive if this is a dumb question - happens when you have no one but yourself to learn from in your company.", "author_fullname": "t2_akntrmyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you have done this better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mv1la", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699017905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the start-up I work in, I have been everything regarding some research project that involved some sort of navigation/positioning. The data collection tool uses Raspberry-pi running ROS, lidar, smartphone, battery (because everything runs on the move), wifi without internet. The smartphone sends sound signals the whole time (44100 values every second), and other sensor data couple of times a second. Everything will be saved as csv files in the pi. Since the location may not have internet, data is directly saved on the pi first. &lt;/p&gt;\n\n&lt;p&gt;When the pi is connected to our office network it sends any new data to our office NAS storage. Everything json (configs) and csv. And all our python models have to connect to some synology drive to load up the data and do any computation. Our models are only there to calculate some sort of accuracy for research purpose.&lt;/p&gt;\n\n&lt;p&gt;My experience with data is limited but I feel like this is messy and could have been done better. instead of NAS our data could always be pushed to cloud? stream of large continuous values like sound in sql or csv is ok? just wondering how teams who work on sensor data and machine learning models do their data management. Forgive if this is a dumb question - happens when you have no one but yourself to learn from in your company.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mv1la", "is_robot_indexable": true, "report_reasons": null, "author": "besabestin", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mv1la/how_would_you_have_done_this_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mv1la/how_would_you_have_done_this_better/", "subreddit_subscribers": 137809, "created_utc": 1699017905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everybody\nI wanted to know, what would your approach be to this specific problem, regarding scalability and maintainability.\nLet's say you have a dimension column with specific entries, from several data sources. While these data sources are not exactly the same, they contain the same underlying data. E.g. the product groups of two  backery shops.\n\nHow would you implement and maintain the mapping of the incoming column to a specific, predetermined entries in a final column, e.g.:\n\nSour dough Bread &gt; bread\nBagel &gt; bread\nCroissant's &gt; pastry \nBaguette &gt; bread\nBread rolls &gt; pastry\nCake &gt; pastry\n\nMy current approach is to fix this logic in a second table and use this as a mapping reference. All unmapped entries are send to a separate table as uniques and request a mapping action.", "author_fullname": "t2_yobj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice // patterns for mapping a column to specific outcome", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nhe88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699087469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody\nI wanted to know, what would your approach be to this specific problem, regarding scalability and maintainability.\nLet&amp;#39;s say you have a dimension column with specific entries, from several data sources. While these data sources are not exactly the same, they contain the same underlying data. E.g. the product groups of two  backery shops.&lt;/p&gt;\n\n&lt;p&gt;How would you implement and maintain the mapping of the incoming column to a specific, predetermined entries in a final column, e.g.:&lt;/p&gt;\n\n&lt;p&gt;Sour dough Bread &amp;gt; bread\nBagel &amp;gt; bread\nCroissant&amp;#39;s &amp;gt; pastry \nBaguette &amp;gt; bread\nBread rolls &amp;gt; pastry\nCake &amp;gt; pastry&lt;/p&gt;\n\n&lt;p&gt;My current approach is to fix this logic in a second table and use this as a mapping reference. All unmapped entries are send to a separate table as uniques and request a mapping action.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17nhe88", "is_robot_indexable": true, "report_reasons": null, "author": "lschozar", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nhe88/best_practice_patterns_for_mapping_a_column_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nhe88/best_practice_patterns_for_mapping_a_column_to/", "subreddit_subscribers": 137809, "created_utc": 1699087469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Kind of a wide-open question, but I was wondering how folks are documenting and communicating their architectures and data strategy in documentation.  I'm a data engineering manager at a company that is completely project-focused and funded, but I've been given the task of laying out an overall data strategy on the tech side.  I've seen a few templates and outlines by searching, but they all look and feel like consultant-ware and are not really helpful.  I guess I'm asking if anyone has a good reference template that has worked for them or online templates you have seen.  And yes, we do have a couple of data architects, but they communicate very poorly, have no interest in helping define a strategy, and really think all they should be doing in modeling, so I'm kind of no my own.", "author_fullname": "t2_3q5hfpq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Strategy and Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mzvga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699031310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kind of a wide-open question, but I was wondering how folks are documenting and communicating their architectures and data strategy in documentation.  I&amp;#39;m a data engineering manager at a company that is completely project-focused and funded, but I&amp;#39;ve been given the task of laying out an overall data strategy on the tech side.  I&amp;#39;ve seen a few templates and outlines by searching, but they all look and feel like consultant-ware and are not really helpful.  I guess I&amp;#39;m asking if anyone has a good reference template that has worked for them or online templates you have seen.  And yes, we do have a couple of data architects, but they communicate very poorly, have no interest in helping define a strategy, and really think all they should be doing in modeling, so I&amp;#39;m kind of no my own.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mzvga", "is_robot_indexable": true, "report_reasons": null, "author": "timewarp80", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mzvga/data_strategy_and_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mzvga/data_strategy_and_architecture/", "subreddit_subscribers": 137809, "created_utc": 1699031310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, I need some advice for my career. \n\nHere is my background. I am working as a Developer for some time now in a Big Data team where I mostly do things like automation for ETL jobs- like organising csv files so that the tool can consume the data properly, generic things like - creating scripts to automate day to day tasks in the pipeline - (archiving files, running reconciliation jobs, running stored procedures etc)\n\nThis is the first part of my work. The second part of my work is -after the ETL has been done, I create json files out of multiple transformed tables and send them to the downstream api. I have built a whole process for this.\n\n Since March, I have been trying to switch and get a better role with better salary and more engineering stuff to do and I have two offers now. \n\nOffer 1: its a market research company, looks like a proper data engineer role with good development work and good tech stack, and somewhat ok-ish pay.\n\nOffer 2 : its a product-based company that makes CRM tools. the role is Data Migration Engineer where i'll be feeding customer's data to this company's tool. Somehow this role feels very limiting and narrow. the pay is VERY good but will be doing multiple projects at a single time with each having 4-8 weeks of duration.\n\nBut in both cases, the role does not feel really the one that will help me grow. I have 3 YOE in total and feels like unless I really work on \"Big\" Data, I'll just stay at the same level. and It did not seem like either of the company is working with a large volume of data.\n\nAs of now my choice is the 2nd offer mostly because of salary, almost remote (will become hybrid but yet to decide), and it being a Product based company.\n\nplease advice me if I am making a mistake here or not...\n\nThanks if you have read till this point, was not feeling anxious before but as my last working day approaches and the more pre-joining things I do, the more I worry. So I wanted to share that and get some advice as well.", "author_fullname": "t2_6f6khk66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n278y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699037796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, I need some advice for my career. &lt;/p&gt;\n\n&lt;p&gt;Here is my background. I am working as a Developer for some time now in a Big Data team where I mostly do things like automation for ETL jobs- like organising csv files so that the tool can consume the data properly, generic things like - creating scripts to automate day to day tasks in the pipeline - (archiving files, running reconciliation jobs, running stored procedures etc)&lt;/p&gt;\n\n&lt;p&gt;This is the first part of my work. The second part of my work is -after the ETL has been done, I create json files out of multiple transformed tables and send them to the downstream api. I have built a whole process for this.&lt;/p&gt;\n\n&lt;p&gt;Since March, I have been trying to switch and get a better role with better salary and more engineering stuff to do and I have two offers now. &lt;/p&gt;\n\n&lt;p&gt;Offer 1: its a market research company, looks like a proper data engineer role with good development work and good tech stack, and somewhat ok-ish pay.&lt;/p&gt;\n\n&lt;p&gt;Offer 2 : its a product-based company that makes CRM tools. the role is Data Migration Engineer where i&amp;#39;ll be feeding customer&amp;#39;s data to this company&amp;#39;s tool. Somehow this role feels very limiting and narrow. the pay is VERY good but will be doing multiple projects at a single time with each having 4-8 weeks of duration.&lt;/p&gt;\n\n&lt;p&gt;But in both cases, the role does not feel really the one that will help me grow. I have 3 YOE in total and feels like unless I really work on &amp;quot;Big&amp;quot; Data, I&amp;#39;ll just stay at the same level. and It did not seem like either of the company is working with a large volume of data.&lt;/p&gt;\n\n&lt;p&gt;As of now my choice is the 2nd offer mostly because of salary, almost remote (will become hybrid but yet to decide), and it being a Product based company.&lt;/p&gt;\n\n&lt;p&gt;please advice me if I am making a mistake here or not...&lt;/p&gt;\n\n&lt;p&gt;Thanks if you have read till this point, was not feeling anxious before but as my last working day approaches and the more pre-joining things I do, the more I worry. So I wanted to share that and get some advice as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17n278y", "is_robot_indexable": true, "report_reasons": null, "author": "mainak17", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n278y/need_some_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n278y/need_some_advice/", "subreddit_subscribers": 137809, "created_utc": 1699037796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there folks, so im currently in the brainstorming phase of designing data infrastructure from scratch for a very small company whose owner happens to be, well my brother lol. \n\nWe plan on going over the details over this upcoming holiday vacation period, but from what I've picked up from our brief conversations about his business in the past he occupies a very narrow product niche where he's unlikely to expand his business horizontally (so probably not going to hire discrete teams managing separate business units) but his contract volume has increased to the point where hes expressed the desire for structure and automation.\n\nOf course, I plan on running him through the usual 10,000 questions about the shape of his business and his short-medium term growth plans to make informed design choices, but my gut is telling me its going to end up running on a low-medium cost on-prem machine (that I will probably build myself, 15 years of PC building experience) and will need to be able to operate long-term free of oversight from any SQL-Python trained staff. \n\nEssentially all the complexity for this system will be making sure the Ingestion and data-cleaning portions of the system don't break down and keep in line with the data warehouse(s) schema(s). Im aware he WILL reach a point where he needs a full-time hire to manage the system and/or migrate to the cloud but for now, I suspect after I set everything up hes only going to need to make periodic adjustments to changes from is inbound external data sources primarily consisting of orders and receipts from his suppliers and clients. \n\nHe works in a creative/artistic industry so I'm expecting his clientele to have very informal methods of placing orders and submitting payment. I may deem it not worth the effort to try and automate portions of this data input if it proves too erratic but id like to give it a shot and provide my brother a few options based on what hes willing to learn and manage on his own. \n\nHe is quite smart but programming was never his interest so outside of some basic troubleshooting syntax commands I plan on writing up in the final documentation I don't want to push him into having to learn any more than he has to, keeping it click and drag as much as possible.", "author_fullname": "t2_pfwkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for no-code data cleaning tools well suited for a non-technical end user?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17njn65", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699097157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there folks, so im currently in the brainstorming phase of designing data infrastructure from scratch for a very small company whose owner happens to be, well my brother lol. &lt;/p&gt;\n\n&lt;p&gt;We plan on going over the details over this upcoming holiday vacation period, but from what I&amp;#39;ve picked up from our brief conversations about his business in the past he occupies a very narrow product niche where he&amp;#39;s unlikely to expand his business horizontally (so probably not going to hire discrete teams managing separate business units) but his contract volume has increased to the point where hes expressed the desire for structure and automation.&lt;/p&gt;\n\n&lt;p&gt;Of course, I plan on running him through the usual 10,000 questions about the shape of his business and his short-medium term growth plans to make informed design choices, but my gut is telling me its going to end up running on a low-medium cost on-prem machine (that I will probably build myself, 15 years of PC building experience) and will need to be able to operate long-term free of oversight from any SQL-Python trained staff. &lt;/p&gt;\n\n&lt;p&gt;Essentially all the complexity for this system will be making sure the Ingestion and data-cleaning portions of the system don&amp;#39;t break down and keep in line with the data warehouse(s) schema(s). Im aware he WILL reach a point where he needs a full-time hire to manage the system and/or migrate to the cloud but for now, I suspect after I set everything up hes only going to need to make periodic adjustments to changes from is inbound external data sources primarily consisting of orders and receipts from his suppliers and clients. &lt;/p&gt;\n\n&lt;p&gt;He works in a creative/artistic industry so I&amp;#39;m expecting his clientele to have very informal methods of placing orders and submitting payment. I may deem it not worth the effort to try and automate portions of this data input if it proves too erratic but id like to give it a shot and provide my brother a few options based on what hes willing to learn and manage on his own. &lt;/p&gt;\n\n&lt;p&gt;He is quite smart but programming was never his interest so outside of some basic troubleshooting syntax commands I plan on writing up in the final documentation I don&amp;#39;t want to push him into having to learn any more than he has to, keeping it click and drag as much as possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17njn65", "is_robot_indexable": true, "report_reasons": null, "author": "Anic135", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17njn65/any_recommendations_for_nocode_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17njn65/any_recommendations_for_nocode_data_cleaning/", "subreddit_subscribers": 137809, "created_utc": 1699097157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So i've been preparing to take aws data analytics certification exam , and i was fully prepared, when i wanted to purchase the exam there was an issue in pearsonvue ... I ve been trying to fix the problem in the account (i have 50% discount in this account) but no solution. The budget i have is 150$, so since i cant get the data analytics exam, i now decided to switch to azure data engineer certification since its 150$, the thing i wanna know now is how much time i'll need to prepare for it (i need to get it asap for my final course project internship applications), i found a lot of common things between azure and aws and i have a background in data engineering, is 15-20 days is enough to prepare for it and shift what i learned in aws to azure.", "author_fullname": "t2_4omvafgu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Certif prep from aws to azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nit6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699093769.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i&amp;#39;ve been preparing to take aws data analytics certification exam , and i was fully prepared, when i wanted to purchase the exam there was an issue in pearsonvue ... I ve been trying to fix the problem in the account (i have 50% discount in this account) but no solution. The budget i have is 150$, so since i cant get the data analytics exam, i now decided to switch to azure data engineer certification since its 150$, the thing i wanna know now is how much time i&amp;#39;ll need to prepare for it (i need to get it asap for my final course project internship applications), i found a lot of common things between azure and aws and i have a background in data engineering, is 15-20 days is enough to prepare for it and shift what i learned in aws to azure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17nit6t", "is_robot_indexable": true, "report_reasons": null, "author": "RiyadixXxTani", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nit6t/certif_prep_from_aws_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nit6t/certif_prep_from_aws_to_azure/", "subreddit_subscribers": 137809, "created_utc": 1699093769.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_73d9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Entity Resolution with AI: DBLP and ACM publication benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17n69v6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gX8eUB_h1yR2e78eoPX7IcBotYEWZr3u36X3cHgR5Q0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699048772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "terminusdb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://terminusdb.com/blog/entity-resolution-with-ai-dblp-and-acm-publication-benchmark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?auto=webp&amp;s=6a5c273d10f004919d5327b10ebe8687e4992705", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b03be444869bb0d9ef48384d7f3d84851918cad8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e6eac6f88aa169708a10200699a389292299af7", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b279e758f71d0e2ecc8688dc403e1a26c7fddfb", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a3e5d87d8934d2afd2a3ca1cc725060907822ed", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/7N2Si7uo_8Cm6-YFkWUwvscGL_Lt__vLloNJKiXTclM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=00654b0430b076f593e2002ba042f4b4a7050775", "width": 960, "height": 960}], "variants": {}, "id": "fF5vzlRKqObgTKtUDQ6yG8l5D-AsPThkuiEQmjtrmxo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17n69v6", "is_robot_indexable": true, "report_reasons": null, "author": "GavinMendelGleason", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n69v6/entity_resolution_with_ai_dblp_and_acm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://terminusdb.com/blog/entity-resolution-with-ai-dblp-and-acm-publication-benchmark/", "subreddit_subscribers": 137809, "created_utc": 1699048772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Panda Patrol is a Python library that uses AI to generate data tests for your data, test and profile your data within your pipelines and more. \n\nAll with this comes with dashboards and alerts. You can easily drop it into your any Python-based data flow (i.e. Dagster, Airflow, etc.) and just run your pipelines are you normally would \u2014 but with monitoring and more context.\n\nGithub: [https://github.com/aivanzhang/panda\\_patrol](https://github.com/aivanzhang/panda_patrol)\n\nGive it a try here: [https://panda-patrol.vercel.app/](https://panda-patrol.vercel.app/)\n\n[Dashboard of Pipeline Health](https://preview.redd.it/uevhvqlmf7yb1.png?width=1324&amp;format=png&amp;auto=webp&amp;s=39512ca37a034847de69213a57c9d444c8205f46)\n\n[Page for a specific data test](https://preview.redd.it/juvpq2ppf7yb1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=b04ec20d22a9363e8bc34b2e38207c6fb0adeb6b)\n\n&amp;#x200B;", "author_fullname": "t2_dcdt0mh5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Panda Patrol: a Python library for generating data tests and testing your data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"juvpq2ppf7yb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb65c486570696b8f04994b1087063cc58f93f06"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4a2397f5698dce1cef4e6dde99039bb2acb3793"}, {"y": 235, "x": 320, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=de30b60a919481fe14dd91cb2d17fca1ea34052d"}, {"y": 470, "x": 640, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f966098ca32ce6c1f183bcf90a48a17df9f8a62d"}, {"y": 706, "x": 960, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e470bc9997abddf99485bd22bc1d759c35d636b0"}, {"y": 794, "x": 1080, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b15649e4afe92ff4aa31ecfe8c2069f8610b4f09"}], "s": {"y": 1218, "x": 1656, "u": "https://preview.redd.it/juvpq2ppf7yb1.png?width=1656&amp;format=png&amp;auto=webp&amp;s=b04ec20d22a9363e8bc34b2e38207c6fb0adeb6b"}, "id": "juvpq2ppf7yb1"}, "uevhvqlmf7yb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=00e6fe6a2adbaa01e01c9c3976866ab6696a5379"}, {"y": 91, "x": 216, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3038a54548a34fa3b2d92cb626129eeb491d142"}, {"y": 134, "x": 320, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=55c0155e9e53418efa5b469913dafe6d6e5705e9"}, {"y": 269, "x": 640, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bccfae503906ea25938ccd7c62208db69813b778"}, {"y": 404, "x": 960, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bcaf91c901a812d780c57e23ae131f430cd48c9d"}, {"y": 455, "x": 1080, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=30c25b1ec1fc0baf1ffb9c03821be4faef9ae93f"}], "s": {"y": 558, "x": 1324, "u": "https://preview.redd.it/uevhvqlmf7yb1.png?width=1324&amp;format=png&amp;auto=webp&amp;s=39512ca37a034847de69213a57c9d444c8205f46"}, "id": "uevhvqlmf7yb1"}}, "name": "t3_17n67k9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UxTy9O4421UD4SMkjDh6jFqGitUcaUNqo5dxeXbRG3Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1699048583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Panda Patrol is a Python library that uses AI to generate data tests for your data, test and profile your data within your pipelines and more. &lt;/p&gt;\n\n&lt;p&gt;All with this comes with dashboards and alerts. You can easily drop it into your any Python-based data flow (i.e. Dagster, Airflow, etc.) and just run your pipelines are you normally would \u2014 but with monitoring and more context.&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/aivanzhang/panda_patrol\"&gt;https://github.com/aivanzhang/panda_patrol&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Give it a try here: &lt;a href=\"https://panda-patrol.vercel.app/\"&gt;https://panda-patrol.vercel.app/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uevhvqlmf7yb1.png?width=1324&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=39512ca37a034847de69213a57c9d444c8205f46\"&gt;Dashboard of Pipeline Health&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/juvpq2ppf7yb1.png?width=1656&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b04ec20d22a9363e8bc34b2e38207c6fb0adeb6b\"&gt;Page for a specific data test&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?auto=webp&amp;s=b0853d15b465209f90ba57c6fe30be5f0178a549", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57d342a456530f0393067fc1795d84bc6facb566", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=35711f861b5fc4d27ef9e61867572b0d7bdeeb54", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e3cc466f8b0f5895e3a627a3192738df339dc37", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4085710f656af7ace6890dc6954ec7f90c7a98ec", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=09b78b37889a626ebefb46b5c7d49bcdc1c9e9c9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/nkEj-G8Nv-qVCKybJjClxib0lvI68rMfzTmHoTnbh_E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5912af276779c20afae0da423bf3a73246744a18", "width": 1080, "height": 540}], "variants": {}, "id": "0_FAX42DLS_9BPX0HcE07MZoNFmaW0RW0UbhrdUbeEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17n67k9", "is_robot_indexable": true, "report_reasons": null, "author": "gnahznavia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n67k9/panda_patrol_a_python_library_for_generating_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n67k9/panda_patrol_a_python_library_for_generating_data/", "subreddit_subscribers": 137809, "created_utc": 1699048583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have about 5 years professional experience working as a Data Analyst and am about to finish my DS Masters at the end of this Calendar Year.\n\nHow much is transferrable to DE? I did a MSDS because I thought I enjoyed it, but in reality I'm tired of having front end roles where I'm in meetings and having to build presentations. I really enjoy just being given assignments and doing heads down work in the background. Also don't care too much for the ML stuff I've learned. I had a course on building machine learning pipelines and found it really fun though it was mostly just building python scripts that work in a sequence to chain functions and give an output. \n\nAny thoughts? I don't work with sql much I know enough to be able to pull myself data but don't have what people would consider \"expert level\" sql skills to build complex queries. I've been wanting to build on my sql skills though especially since I know DE works with it a lot.", "author_fullname": "t2_310ehei3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into DE with a DS degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17n45m0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699043080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 5 years professional experience working as a Data Analyst and am about to finish my DS Masters at the end of this Calendar Year.&lt;/p&gt;\n\n&lt;p&gt;How much is transferrable to DE? I did a MSDS because I thought I enjoyed it, but in reality I&amp;#39;m tired of having front end roles where I&amp;#39;m in meetings and having to build presentations. I really enjoy just being given assignments and doing heads down work in the background. Also don&amp;#39;t care too much for the ML stuff I&amp;#39;ve learned. I had a course on building machine learning pipelines and found it really fun though it was mostly just building python scripts that work in a sequence to chain functions and give an output. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts? I don&amp;#39;t work with sql much I know enough to be able to pull myself data but don&amp;#39;t have what people would consider &amp;quot;expert level&amp;quot; sql skills to build complex queries. I&amp;#39;ve been wanting to build on my sql skills though especially since I know DE works with it a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17n45m0", "is_robot_indexable": true, "report_reasons": null, "author": "Savan88", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17n45m0/going_into_de_with_a_ds_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17n45m0/going_into_de_with_a_ds_degree/", "subreddit_subscribers": 137809, "created_utc": 1699043080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to understand schema design for Relational OLAP (ROLAP) Databases such as RedShift.  When I try to find this information I see many explanations of MDX OLAP (MOLAP) schema design and OLAP cubes, but struggle to find advice on ROLAP schema design.  Can anyone provide their mental process for deciding on schema design for ROLAP and/or some resource that could explain this to me?", "author_fullname": "t2_c430em05c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relational OLAP schema design help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mzz66", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699031578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to understand schema design for Relational OLAP (ROLAP) Databases such as RedShift.  When I try to find this information I see many explanations of MDX OLAP (MOLAP) schema design and OLAP cubes, but struggle to find advice on ROLAP schema design.  Can anyone provide their mental process for deciding on schema design for ROLAP and/or some resource that could explain this to me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mzz66", "is_robot_indexable": true, "report_reasons": null, "author": "Flaky-Associate-7434", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mzz66/relational_olap_schema_design_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mzz66/relational_olap_schema_design_help/", "subreddit_subscribers": 137809, "created_utc": 1699031578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b\n\nI recently heard a local tech talk quoting this Article\n\nThe guy resposible for the talk didnt go all negative and just quoted this article about the part where it says DE work isnt as shiny as DS or Analysts. Kind of like front-end x back-end in webdev, still that doesnt mean Back-end is dying.....\n\nBut the speaker also talked about data bricks and how that tool, even if expensive, allows a significant reduction in needed workers to keep clusters going.\n\nThen he finished talking about \"Analytics Engineer\" which is kind of a Mix between DE and Data Analysts, saying that position might grow in the future.\n\n\nI want to hear your guys opinion on the article i linked and the things the speaker said. Do you think DE as a job role is declining? Will Databricks really reduce job openings? And what about the \"Analytics engineers\"?", "author_fullname": "t2_7xe340s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future prospects of the DE role? Heard some opinions and want to hear you guys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17my21u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699026502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b\"&gt;https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I recently heard a local tech talk quoting this Article&lt;/p&gt;\n\n&lt;p&gt;The guy resposible for the talk didnt go all negative and just quoted this article about the part where it says DE work isnt as shiny as DS or Analysts. Kind of like front-end x back-end in webdev, still that doesnt mean Back-end is dying.....&lt;/p&gt;\n\n&lt;p&gt;But the speaker also talked about data bricks and how that tool, even if expensive, allows a significant reduction in needed workers to keep clusters going.&lt;/p&gt;\n\n&lt;p&gt;Then he finished talking about &amp;quot;Analytics Engineer&amp;quot; which is kind of a Mix between DE and Data Analysts, saying that position might grow in the future.&lt;/p&gt;\n\n&lt;p&gt;I want to hear your guys opinion on the article i linked and the things the speaker said. Do you think DE as a job role is declining? Will Databricks really reduce job openings? And what about the &amp;quot;Analytics engineers&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?auto=webp&amp;s=c4d5a18cca91fbec054aa905475c9fd21b0d38fb", "width": 1200, "height": 531}, "resolutions": [{"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=32cfba291242c16a9dc040d6455bd22c293144ba", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=640cb100331e492b4210b5093c121929a24cff50", "width": 216, "height": 95}, {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1a80880a7384c4539794d973af6c2f05049f1b74", "width": 320, "height": 141}, {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6713b1ddb92d2f906505bc2bc6ce73e46c996987", "width": 640, "height": 283}, {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1d7ad2520c9782f65602d13be731d3a1e7b2451", "width": 960, "height": 424}, {"url": "https://external-preview.redd.it/iQsb6T5wyznY45CPyn51iURuimv1qxrVZxu4omuGBiY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6163f2c8e32814680191f34535dfcda6212b0bd", "width": 1080, "height": 477}], "variants": {}, "id": "qGGJyg-rDxkLH5JC-NO-DO0ybGxJ41CkTIBUrN7_9M4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17my21u", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPineapples7791", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17my21u/future_prospects_of_the_de_role_heard_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17my21u/future_prospects_of_the_de_role_heard_some/", "subreddit_subscribers": 137809, "created_utc": 1699026502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I made a data catalog benchmark almost three years ago, and am now looking to update it. Any tool you think I forgot in there? Is there any feature missing? Would love your thoughts on the matter., I really want this resource to be comprehensive. \n\n  \n[https://notion.castordoc.com/catalog-of-catalogs](https://notion.castordoc.com/catalog-of-catalogs)", "author_fullname": "t2_ronab77d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog benchmark - Update", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mvp5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699019862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I made a data catalog benchmark almost three years ago, and am now looking to update it. Any tool you think I forgot in there? Is there any feature missing? Would love your thoughts on the matter., I really want this resource to be comprehensive. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://notion.castordoc.com/catalog-of-catalogs\"&gt;https://notion.castordoc.com/catalog-of-catalogs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?auto=webp&amp;s=3265e0c164d80fc686a64b7de80efb9582aa225a", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3b8daafc689beb5ab4ad6e2d2c7e28547bc2b8ae", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=792d5f886edd2c5716a64db262320835b2368bf8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=06b74e830c4a08519c75cf16a959eda77bb96934", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3bffa4da4dd0c6db4310d37b772d4b0ca247a146", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3a8a89c5a5b55b7744676f0209836f29360ccd57", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/1wTGeYgsdTYmbFZFqe4LDByjgBZhKxeY7WEKaRvGYD8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=57c944961722fbaf30d3b5b2eb9c1b630bde49ba", "width": 1080, "height": 567}], "variants": {}, "id": "x1UILE4R_6EzxHopSAmN-eRIG2rO1DZBXwWRXNjlvTI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17mvp5q", "is_robot_indexable": true, "report_reasons": null, "author": "louise_castor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mvp5q/data_catalog_benchmark_update/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mvp5q/data_catalog_benchmark_update/", "subreddit_subscribers": 137809, "created_utc": 1699019862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! \n\nIn the last 2 years I\u2019ve been working as a Business Intelligence Analyst (understanding the business needs then query the reports/ build dashboard) \n\nNow, I\u2019ll be responsible for designing data bases, handling the structure and data flow, and some data engineering responsibilities (managing the tables). \n\nI need some guidance to know what to learn next? what should I focus on? what course or YT videos/ series you recommend to watch? \n\nEvery advice will be really helpful. \n\n*if you can provide a learning roadmap I\u2019ll be grateful*\n\nThank you in advance:)", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BI Analyst -&gt; Data modelling &amp; Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mzyxp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699031560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;In the last 2 years I\u2019ve been working as a Business Intelligence Analyst (understanding the business needs then query the reports/ build dashboard) &lt;/p&gt;\n\n&lt;p&gt;Now, I\u2019ll be responsible for designing data bases, handling the structure and data flow, and some data engineering responsibilities (managing the tables). &lt;/p&gt;\n\n&lt;p&gt;I need some guidance to know what to learn next? what should I focus on? what course or YT videos/ series you recommend to watch? &lt;/p&gt;\n\n&lt;p&gt;Every advice will be really helpful. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;if you can provide a learning roadmap I\u2019ll be grateful&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance:)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17mzyxp", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mzyxp/bi_analyst_data_modelling_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mzyxp/bi_analyst_data_modelling_data_engineering/", "subreddit_subscribers": 137809, "created_utc": 1699031560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good morning, everybody. Looking to get into Data Engineering and graduating soon. I have one elective left next semester and want it to be useful (at all) towards Data Engineering.\n\nI think option 2 is the obvious choice but I don't currently work as a Data Engineer, so insight from people in the field would be great! Thanks in advance.\n\nOption 1: **Data Mining**\n\n**Course Description**:   This course will provide an overview of topics such as introduction to data mining and knowledge discovery; data mining with structured and unstructured data; foundations of pattern clustering; clustering paradigms; clustering for data mining; data mining using neural networks and genetic algorithms; fast discovery of association rules; applications of data mining to pattern classification; and feature selection. The goal of this course is to introduce students to current machine learning and related data mining methods. It is intended to provide enough background to allow students to apply machine learning and data mining techniques to learning problems in a variety of application areas. \n\n&amp;#x200B;\n\nOption 2: **Scalable Databases**\n\n**Course Description**:  After reviewing relational databases and SQL, students will learn the fundamentals of alternative data storage schemas to deal with large amounts of data (structures and unstructured). The course covers big data and the development of the Hadoop file system, the MapReduce programming paradigm, and database management systems such as Cassandra, HBase and Neo4j. Students will learn about NoSQL, distributed databases, and graph databases. The course emphasizes the differences between traditional database management systems and alternatives with respect to accessibility, cost, transaction speed, and structure. Part of the course is dedicated to access, handle and process data from different sources and of different types using Python. The course provides hands-on practice. ", "author_fullname": "t2_m6v1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Between these two College courses, which one is better for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mvy3s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699020552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning, everybody. Looking to get into Data Engineering and graduating soon. I have one elective left next semester and want it to be useful (at all) towards Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;I think option 2 is the obvious choice but I don&amp;#39;t currently work as a Data Engineer, so insight from people in the field would be great! Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;Option 1: &lt;strong&gt;Data Mining&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Course Description&lt;/strong&gt;:   This course will provide an overview of topics such as introduction to data mining and knowledge discovery; data mining with structured and unstructured data; foundations of pattern clustering; clustering paradigms; clustering for data mining; data mining using neural networks and genetic algorithms; fast discovery of association rules; applications of data mining to pattern classification; and feature selection. The goal of this course is to introduce students to current machine learning and related data mining methods. It is intended to provide enough background to allow students to apply machine learning and data mining techniques to learning problems in a variety of application areas. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option 2: &lt;strong&gt;Scalable Databases&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Course Description&lt;/strong&gt;:  After reviewing relational databases and SQL, students will learn the fundamentals of alternative data storage schemas to deal with large amounts of data (structures and unstructured). The course covers big data and the development of the Hadoop file system, the MapReduce programming paradigm, and database management systems such as Cassandra, HBase and Neo4j. Students will learn about NoSQL, distributed databases, and graph databases. The course emphasizes the differences between traditional database management systems and alternatives with respect to accessibility, cost, transaction speed, and structure. Part of the course is dedicated to access, handle and process data from different sources and of different types using Python. The course provides hands-on practice. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17mvy3s", "is_robot_indexable": true, "report_reasons": null, "author": "Thermax23", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mvy3s/between_these_two_college_courses_which_one_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mvy3s/between_these_two_college_courses_which_one_is/", "subreddit_subscribers": 137809, "created_utc": 1699020552.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}