{"kind": "Listing", "data": {"after": "t3_17u0dri", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got this PM from u/reddit 5 days ago. I think it's relevant to all of us, not just people who moderate dormant subreddits, so I'm sharing it here. The ModNews link in the message gives more info on what \"dormant\" means.\n\n#Automated message from reddit begins below:\n\nHello,\n\nWe are reaching out because you moderate 1 dormant subreddit(s) that qualify for removal.\n\nWhen subreddits have had no activity, we periodically remove them to make space for new communities. For more information about what this means please visit our [r/ModNews post](https://www.reddit.com/r/modnews/comments/17pb48y/removing_dormant_subreddits/).\n\nSubreddits that you moderate that qualify for dormant removal include:\n\n* mystyrnile\n\nIf you would like any of these subreddits to remain on the platform, you may opt out by banning u/SubredditPurge from your dormant community. This will signal to us that you're aware that your subreddit is dormant and have reason to keep it. While you're at it, if you'd like to grow this community, you might want to take a look at [our tips for growing a new community](https://support.reddithelp.com/hc/en-us/articles/15484061307924-First-Week-Essentials-Checklist).\n\nWithin the next two weeks, we will be removing these dormant subreddits. If you would like your subreddit to remain on the platform, please opt out as soon as you can.", "author_fullname": "t2_fjw2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Heads up, reddit is deleting dormant subreddits (no activity within the past year, few posts/comments since inception)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tw19a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699829161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got this PM from &lt;a href=\"/u/reddit\"&gt;u/reddit&lt;/a&gt; 5 days ago. I think it&amp;#39;s relevant to all of us, not just people who moderate dormant subreddits, so I&amp;#39;m sharing it here. The ModNews link in the message gives more info on what &amp;quot;dormant&amp;quot; means.&lt;/p&gt;\n\n&lt;h1&gt;Automated message from reddit begins below:&lt;/h1&gt;\n\n&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are reaching out because you moderate 1 dormant subreddit(s) that qualify for removal.&lt;/p&gt;\n\n&lt;p&gt;When subreddits have had no activity, we periodically remove them to make space for new communities. For more information about what this means please visit our &lt;a href=\"https://www.reddit.com/r/modnews/comments/17pb48y/removing_dormant_subreddits/\"&gt;r/ModNews post&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Subreddits that you moderate that qualify for dormant removal include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;mystyrnile&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you would like any of these subreddits to remain on the platform, you may opt out by banning &lt;a href=\"/u/SubredditPurge\"&gt;u/SubredditPurge&lt;/a&gt; from your dormant community. This will signal to us that you&amp;#39;re aware that your subreddit is dormant and have reason to keep it. While you&amp;#39;re at it, if you&amp;#39;d like to grow this community, you might want to take a look at &lt;a href=\"https://support.reddithelp.com/hc/en-us/articles/15484061307924-First-Week-Essentials-Checklist\"&gt;our tips for growing a new community&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Within the next two weeks, we will be removing these dormant subreddits. If you would like your subreddit to remain on the platform, please opt out as soon as you can.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tw19a", "is_robot_indexable": true, "report_reasons": null, "author": "MystyrNile", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tw19a/heads_up_reddit_is_deleting_dormant_subreddits_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tw19a/heads_up_reddit_is_deleting_dormant_subreddits_no/", "subreddit_subscribers": 711829, "created_utc": 1699829161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay, so I've gotten back into burning PS2 games, right? It's overall been a great time, and I made sure to stick to decent brands like Verbatim, I remember them being the top dog back in the days before my PS2 laser died out.\n\nSo, I get the first batch, a simple 25 pack, they all work perfectly. Smooth topside. They're the kind that are so clear you actually see the verbatim logo on the readable side. No issue there.\n\nThree months later, I get another batch, even contemplating getting a 50 pack. I got the 25 pack, same packaging, same exact description, but then I open the box and these fucking things are NOTICEABLY cheaper. Very scratchy topside, which is basically ALL white besides a tiny verbatim and dvd-r logo on the middle, somehow feels heavier. \n\nNow, out of the first batch, I essentially got every game perfectly fine, and also a few homebrew applications. The SECOND BATCH was essentially half a box of duds. One game was not getting past a sony logo (not the system logo mind you), another gives me a black screen after the playstation logo while still clearly spinning and apparently finding nothing for minutes, and some even give me a DVD error, meaning the burn was so bad it didn't even qualify as a game backup.\n\nSOME worked, haven't even checked all of them frankly so I might actually have even more faulty ones, but this is just a complete ripoff. Why the sudden downgrade? Some even downright gave me the deadly \"uncorrectable error,\" a clear sign that these are complete garbage. I know the console's drive is fine, I know the computer's drive burned at least half of these correctly, and I know for a fact the games I ripped are not to blame.\n\nI doubt I can get a refund for discs I've used, plus, probably not even worth it. But, maybe take it as a warning, some Verbatims have the same packaging, but are actually hunks of crap.", "author_fullname": "t2_uq4aaq89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Verbatim DVD-Rs are actual junk.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ty33v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699834881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay, so I&amp;#39;ve gotten back into burning PS2 games, right? It&amp;#39;s overall been a great time, and I made sure to stick to decent brands like Verbatim, I remember them being the top dog back in the days before my PS2 laser died out.&lt;/p&gt;\n\n&lt;p&gt;So, I get the first batch, a simple 25 pack, they all work perfectly. Smooth topside. They&amp;#39;re the kind that are so clear you actually see the verbatim logo on the readable side. No issue there.&lt;/p&gt;\n\n&lt;p&gt;Three months later, I get another batch, even contemplating getting a 50 pack. I got the 25 pack, same packaging, same exact description, but then I open the box and these fucking things are NOTICEABLY cheaper. Very scratchy topside, which is basically ALL white besides a tiny verbatim and dvd-r logo on the middle, somehow feels heavier. &lt;/p&gt;\n\n&lt;p&gt;Now, out of the first batch, I essentially got every game perfectly fine, and also a few homebrew applications. The SECOND BATCH was essentially half a box of duds. One game was not getting past a sony logo (not the system logo mind you), another gives me a black screen after the playstation logo while still clearly spinning and apparently finding nothing for minutes, and some even give me a DVD error, meaning the burn was so bad it didn&amp;#39;t even qualify as a game backup.&lt;/p&gt;\n\n&lt;p&gt;SOME worked, haven&amp;#39;t even checked all of them frankly so I might actually have even more faulty ones, but this is just a complete ripoff. Why the sudden downgrade? Some even downright gave me the deadly &amp;quot;uncorrectable error,&amp;quot; a clear sign that these are complete garbage. I know the console&amp;#39;s drive is fine, I know the computer&amp;#39;s drive burned at least half of these correctly, and I know for a fact the games I ripped are not to blame.&lt;/p&gt;\n\n&lt;p&gt;I doubt I can get a refund for discs I&amp;#39;ve used, plus, probably not even worth it. But, maybe take it as a warning, some Verbatims have the same packaging, but are actually hunks of crap.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17ty33v", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCocknose", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ty33v/new_verbatim_dvdrs_are_actual_junk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ty33v/new_verbatim_dvdrs_are_actual_junk/", "subreddit_subscribers": 711829, "created_utc": 1699834881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Posting here as I've seen Sync.com menitoned in the past in this sub. First, it's perplexing to see so many reviews online pointing out that Sync.com is end-to-end encrypted (e2ee) and that Sync.com does not have access to your unencrypted data, when at best what should be said is *\"it's closed source, and the company claims it's e2ee and zero-knowledge\"*. But anyway...\n\nI signed up to see if I can verify anything, and turns out you can verify that it's not e2ee and zero-knowledge. I uploaded a file, then shared it and Sync.com gave me a link that I can pass to friends. The link has no hash parts (that are seen only by the local browser), it looks like this:\n\nhttps://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX\n\nPutting that link in any browser gets you the unencrypted file directly - there is no password being asked.\n\nThe same URL is logged by the Sync.com server as well whenever someone requests it, hence not only can Sync.com also retrieve the unencrypted file themselves, but if it was stored encrypted then in order to produce that link that gets the unencrypted content, Sync.com must have access to your encryption key (synonymous with knowing your encryption password) ... so it can't be stated either that if you share files then those files lose e2ee somehow. What is clear is that Sync.com is not e2ee (unless your e2ee definition allows the host to know the encryption key).\n\nBasically, it's at best server-side encrypted (like most of them are, or claim they are).", "author_fullname": "t2_aq2bzze4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync.com claims it's end-to-end encrypted and that they can't decrypt your data stored on their servers. That's false.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tyupn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699839075.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699837146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posting here as I&amp;#39;ve seen Sync.com menitoned in the past in this sub. First, it&amp;#39;s perplexing to see so many reviews online pointing out that Sync.com is end-to-end encrypted (e2ee) and that Sync.com does not have access to your unencrypted data, when at best what should be said is &lt;em&gt;&amp;quot;it&amp;#39;s closed source, and the company claims it&amp;#39;s e2ee and zero-knowledge&amp;quot;&lt;/em&gt;. But anyway...&lt;/p&gt;\n\n&lt;p&gt;I signed up to see if I can verify anything, and turns out you can verify that it&amp;#39;s not e2ee and zero-knowledge. I uploaded a file, then shared it and Sync.com gave me a link that I can pass to friends. The link has no hash parts (that are seen only by the local browser), it looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX\"&gt;https://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Putting that link in any browser gets you the unencrypted file directly - there is no password being asked.&lt;/p&gt;\n\n&lt;p&gt;The same URL is logged by the Sync.com server as well whenever someone requests it, hence not only can Sync.com also retrieve the unencrypted file themselves, but if it was stored encrypted then in order to produce that link that gets the unencrypted content, Sync.com must have access to your encryption key (synonymous with knowing your encryption password) ... so it can&amp;#39;t be stated either that if you share files then those files lose e2ee somehow. What is clear is that Sync.com is not e2ee (unless your e2ee definition allows the host to know the encryption key).&lt;/p&gt;\n\n&lt;p&gt;Basically, it&amp;#39;s at best server-side encrypted (like most of them are, or claim they are).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?auto=webp&amp;s=a7dd75665aba4e9285d6e97dc5b41fcc53375536", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=588a695a838a4b6b36340282ea641f5d0fe08019", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7acefa097eb35afaf2a47243f8c8560b5bd95d4e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4adccebbfc644a0e01c02f23d05546c7d5de8d25", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a04df6714f874402025ef0fb8b6ecc3f2ba7209", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=50f72580a7e444454a7f7b53bcb9b7acf153a2d5", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14b521b5f5d98d0ed092913ff7873df50f10c8f4", "width": 1080, "height": 564}], "variants": {}, "id": "5OC09iA0QU1QptKOj0rRgMi2YTF53YfM-rKvyubxY8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tyupn", "is_robot_indexable": true, "report_reasons": null, "author": "johnfintech", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tyupn/synccom_claims_its_endtoend_encrypted_and_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tyupn/synccom_claims_its_endtoend_encrypted_and_that/", "subreddit_subscribers": 711829, "created_utc": 1699837146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, noob question here:\n\nSetting up a Mini PC with Linux to act as my Plex server, as well being my point to store/download media. I currently plan to have an external drive connected to the mini PC where everything will be stored - only 4TB so not much on it's own but for now more than plenty for me. One thing though is that I would like to at times be able to download directly from other computers running Windows directly to the external drive connected to Linux. Do I need a NAS for this, or can I set it up in such a way that Linux will make it available to my Windows computers? \n\nFor what it's worth, while the server and HDD will run most of the time, there will be extended periods where I am able to shut down both Mini PC and HDD, so it doesn't need to be truly 24/7.\n\nThanks", "author_fullname": "t2_98wvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS vs External HDD for this use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tqb0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699813737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, noob question here:&lt;/p&gt;\n\n&lt;p&gt;Setting up a Mini PC with Linux to act as my Plex server, as well being my point to store/download media. I currently plan to have an external drive connected to the mini PC where everything will be stored - only 4TB so not much on it&amp;#39;s own but for now more than plenty for me. One thing though is that I would like to at times be able to download directly from other computers running Windows directly to the external drive connected to Linux. Do I need a NAS for this, or can I set it up in such a way that Linux will make it available to my Windows computers? &lt;/p&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, while the server and HDD will run most of the time, there will be extended periods where I am able to shut down both Mini PC and HDD, so it doesn&amp;#39;t need to be truly 24/7.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tqb0l", "is_robot_indexable": true, "report_reasons": null, "author": "boundedwum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tqb0l/nas_vs_external_hdd_for_this_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tqb0l/nas_vs_external_hdd_for_this_use_case/", "subreddit_subscribers": 711829, "created_utc": 1699813737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Those who keep another copy of their hard drive (or whatever other backup source) offsite, where is that? Your mommas house? A storage locker facility? At work?", "author_fullname": "t2_vfuhm3n8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where is the \u201coffsite\u201d that you keep a second copy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u4880", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699855074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Those who keep another copy of their hard drive (or whatever other backup source) offsite, where is that? Your mommas house? A storage locker facility? At work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u4880", "is_robot_indexable": true, "report_reasons": null, "author": "inquisitiveinquirer1", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u4880/where_is_the_offsite_that_you_keep_a_second_copy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u4880/where_is_the_offsite_that_you_keep_a_second_copy/", "subreddit_subscribers": 711829, "created_utc": 1699855074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone have insight into the beta key ending this month, if there's going to be a new key issued?  If it doesn't happen and the program demands payment... what's a similar program that rips blu-rays to .mkv format in all the disc's full glory?\n\nEDIT: It's actually $60 plus state tax ($62.83 total for me) for the license.  Hoping there's a free alternative to this, or that the dev will actually release another free key after November, since it's still in beta.  For what it's worth, here's the info on the support forum [(LINK)](https://forum.makemkv.com/forum/viewtopic.php?t=1053) where the dev says '... and is valid until end of November 2023. Please check back for updated key on this page. '  So there's hope, maybe, that a new beta key will be released.", "author_fullname": "t2_1iovrpc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've been using MAKEMKV to rip my Blu-ray discs. The beta key is set to expire the end of this month (November 2023). Anyone know if a new beta key will be issued, or is this end of its free service? I'm getting ready to shuck out the $50 for the lifetime key unless there's a similar free app.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u0c9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699842315.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699841551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have insight into the beta key ending this month, if there&amp;#39;s going to be a new key issued?  If it doesn&amp;#39;t happen and the program demands payment... what&amp;#39;s a similar program that rips blu-rays to .mkv format in all the disc&amp;#39;s full glory?&lt;/p&gt;\n\n&lt;p&gt;EDIT: It&amp;#39;s actually $60 plus state tax ($62.83 total for me) for the license.  Hoping there&amp;#39;s a free alternative to this, or that the dev will actually release another free key after November, since it&amp;#39;s still in beta.  For what it&amp;#39;s worth, here&amp;#39;s the info on the support forum &lt;a href=\"https://forum.makemkv.com/forum/viewtopic.php?t=1053\"&gt;(LINK)&lt;/a&gt; where the dev says &amp;#39;... and is valid until end of November 2023. Please check back for updated key on this page. &amp;#39;  So there&amp;#39;s hope, maybe, that a new beta key will be released.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17u0c9m", "is_robot_indexable": true, "report_reasons": null, "author": "Kevalemig", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u0c9m/ive_been_using_makemkv_to_rip_my_bluray_discs_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u0c9m/ive_been_using_makemkv_to_rip_my_bluray_discs_the/", "subreddit_subscribers": 711829, "created_utc": 1699841551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI plan to fill up quite some TB worth of external 2.5\" HDDs as cold storage and think about 4-5TB capacity/drive. \n\nWhat procedure would you suggest to check for data integrity? The idea is to do that once per year to also prevent demagnetizing.", "author_fullname": "t2_4c1ocy26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] How do you check your cold storage for data integrity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tmup9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699803894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I plan to fill up quite some TB worth of external 2.5&amp;quot; HDDs as cold storage and think about 4-5TB capacity/drive. &lt;/p&gt;\n\n&lt;p&gt;What procedure would you suggest to check for data integrity? The idea is to do that once per year to also prevent demagnetizing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Quite some TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tmup9", "is_robot_indexable": true, "report_reasons": null, "author": "Turboflopper", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17tmup9/question_how_do_you_check_your_cold_storage_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tmup9/question_how_do_you_check_your_cold_storage_for/", "subreddit_subscribers": 711829, "created_utc": 1699803894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_jxi80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's going on with my ssd?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 53, "top_awarded_type": null, "hide_score": true, "name": "t3_17u5s44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z7gFBE9gR2J2J6w1zQFAUzZcwT-CzgnXTzoUbQB8RLk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699861974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/es51vquam20c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/es51vquam20c1.png?auto=webp&amp;s=161899da3c1195ff44039b9619bb2aa1f6b6acf9", "width": 671, "height": 258}, "resolutions": [{"url": "https://preview.redd.it/es51vquam20c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f898f74c3ddfab64e578c9646b35495f95afdda5", "width": 108, "height": 41}, {"url": "https://preview.redd.it/es51vquam20c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=19c6ce6bf45a8795ee643a78eabe73fd8701da29", "width": 216, "height": 83}, {"url": "https://preview.redd.it/es51vquam20c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2363ce6d4e6291e8cec67a5fd31bc31add96feaa", "width": 320, "height": 123}, {"url": "https://preview.redd.it/es51vquam20c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c63580d8fd60d6e45e051dd1aa07ba35b0993e01", "width": 640, "height": 246}], "variants": {}, "id": "ctP9XDOAGaGjwRvRoPLnnS4FcKQiZBNIhCao8Qy2eGM"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u5s44", "is_robot_indexable": true, "report_reasons": null, "author": "victorbessa96", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u5s44/whats_going_on_with_my_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/es51vquam20c1.png", "subreddit_subscribers": 711829, "created_utc": 1699861974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have some bin/cue files for PS1 games and VCDs that I\u2019ve got from the internet. Imgburn spits out miscompares when verifying. I\u2019ve read up that burning CDs in Raw mode would help but the software to do that has either been discontinued and hard to find. What software do you use for that?", "author_fullname": "t2_p12csd2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What software do you guys use to burn CDs with Raw Mode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u1dzc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699844802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some bin/cue files for PS1 games and VCDs that I\u2019ve got from the internet. Imgburn spits out miscompares when verifying. I\u2019ve read up that burning CDs in Raw mode would help but the software to do that has either been discontinued and hard to find. What software do you use for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u1dzc", "is_robot_indexable": true, "report_reasons": null, "author": "boisosm", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u1dzc/what_software_do_you_guys_use_to_burn_cds_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u1dzc/what_software_do_you_guys_use_to_burn_cds_with/", "subreddit_subscribers": 711829, "created_utc": 1699844802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, current setting up is a R510 (12 Bay) has 9 platters, and 5 SSDs raid 6 and raid 5, 4TB/512, respectively running on HW raid with ESXI 6.0U3   \nBackups are handled via Veeam to a whitebox with win server 2012 and a software raid of 5x 6TB drives   \nPower consumption has been absolutely driving me crazy (US CT) and plan on figuring out next evolution of hardware on my own.   \nQuestion is, seems the writing on the walls for awhile has been that HW raid is dying, long live ZFS which I'm 100% on board with, but the lack of being able to expand a (vdev) without adding another pool is a little scary to me but something I'm pretty sure I'll just have to deal with.   \nWhat if any hypervisor would allow me use of zfs, give me automatic health reports via email and has a veeam like backup solution avail? (Incremental/full backups) \n\nThanks so much, love this thread, hoping to up my storage in the process of all this! ", "author_fullname": "t2_50oya5bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Server Upgrade questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tsaoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699819253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, current setting up is a R510 (12 Bay) has 9 platters, and 5 SSDs raid 6 and raid 5, 4TB/512, respectively running on HW raid with ESXI 6.0U3&lt;br/&gt;\nBackups are handled via Veeam to a whitebox with win server 2012 and a software raid of 5x 6TB drives&lt;br/&gt;\nPower consumption has been absolutely driving me crazy (US CT) and plan on figuring out next evolution of hardware on my own.&lt;br/&gt;\nQuestion is, seems the writing on the walls for awhile has been that HW raid is dying, long live ZFS which I&amp;#39;m 100% on board with, but the lack of being able to expand a (vdev) without adding another pool is a little scary to me but something I&amp;#39;m pretty sure I&amp;#39;ll just have to deal with.&lt;br/&gt;\nWhat if any hypervisor would allow me use of zfs, give me automatic health reports via email and has a veeam like backup solution avail? (Incremental/full backups) &lt;/p&gt;\n\n&lt;p&gt;Thanks so much, love this thread, hoping to up my storage in the process of all this! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "25TB of rust 2TB SSD", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tsaoh", "is_robot_indexable": true, "report_reasons": null, "author": "jasonswohl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17tsaoh/server_upgrade_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tsaoh/server_upgrade_questions/", "subreddit_subscribers": 711829, "created_utc": 1699819253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My very small company (think me and one other person) collects video data for scientific analysis. We typically put the videos on external hard drives for each survey we do. A typical survey will run about 4TB in size. We always make a back up external drive so that we have two copies in case of loss etc. We do at least a dozen surveys a year.\n\nWe would like to back all of this up in the cloud. We will need to access the videos from the cloud from time to time but not on a frequent basis.\n\nSo first question, what do you fantastic data hoarders recommend as a good cloud storage service?\n\nSecond question, given the sheer size of the project, uploading from my business internet account (Spectrum/ northern Michigan) seems like a Sisyphean task. Can anyone recommend any way to increase upload speed (I am on max local program) or if there is a service that will upload rapidly for me if I send them hard drives?\n\nThanks in advance. Sorry for rookie questions.", "author_fullname": "t2_3nwzrxtf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Efficient Upload and Cloud Backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17u6k1s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699865536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My very small company (think me and one other person) collects video data for scientific analysis. We typically put the videos on external hard drives for each survey we do. A typical survey will run about 4TB in size. We always make a back up external drive so that we have two copies in case of loss etc. We do at least a dozen surveys a year.&lt;/p&gt;\n\n&lt;p&gt;We would like to back all of this up in the cloud. We will need to access the videos from the cloud from time to time but not on a frequent basis.&lt;/p&gt;\n\n&lt;p&gt;So first question, what do you fantastic data hoarders recommend as a good cloud storage service?&lt;/p&gt;\n\n&lt;p&gt;Second question, given the sheer size of the project, uploading from my business internet account (Spectrum/ northern Michigan) seems like a Sisyphean task. Can anyone recommend any way to increase upload speed (I am on max local program) or if there is a service that will upload rapidly for me if I send them hard drives?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance. Sorry for rookie questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u6k1s", "is_robot_indexable": true, "report_reasons": null, "author": "Riftbreaker", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u6k1s/efficient_upload_and_cloud_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u6k1s/efficient_upload_and_cloud_backup/", "subreddit_subscribers": 711829, "created_utc": 1699865536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello \ud83d\udc4b\n\nI'm feeling overwhelmed by the amount of work I created for my-self, my files are a mess.\n\n* How much time you spend just sorting and cleaning all you images?\n* Do you have the same folder structure for all you storage locations? (hard drives, cloud,...)\n* How many files do you have?", "author_fullname": "t2_22z2x4oh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organise 18,500 images on a hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17u68af", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699864034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling overwhelmed by the amount of work I created for my-self, my files are a mess.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How much time you spend just sorting and cleaning all you images?&lt;/li&gt;\n&lt;li&gt;Do you have the same folder structure for all you storage locations? (hard drives, cloud,...)&lt;/li&gt;\n&lt;li&gt;How many files do you have?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u68af", "is_robot_indexable": true, "report_reasons": null, "author": "antoine849502", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u68af/how_do_you_organise_18500_images_on_a_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u68af/how_do_you_organise_18500_images_on_a_hard_drive/", "subreddit_subscribers": 711829, "created_utc": 1699864034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, all,\n\nI hope this is in the right place: many searches are obfuscated by the search terms...\n\nAnyway, I have downloaded a load of rugby matches from various site around the web, YouTube, World Rugby, etc.\n\nI want to get them into my media library, so they can appear in Kodi / Plex, etc.\n\nI thought I had a solution with a Plex add on called SportScanner, but that have given me an empty library.\n\nI have added the SportsDB to Kodi, and that has picked up a couple of folders, but none of the games. \n\nI'm sure if I were to have the files named correctly, they might start appearing, but at the moment, I'm stuck. Currently, most of the files are named just as the game is, for example: \n\n\"//Rugby/English Premiership Rugby/2023/2023 \ud83d\udd34 LIVE REPLAY Harlequins v Bath Round 23 Game of the Week Gallagher Premiership Rugby.mp4\" The folder is picked up, and scraped with metadata, but neither app is picking the games up.\n\nCan anyone point me in the right direction?\n\nCheers,\n\n&amp;#x200B;", "author_fullname": "t2_6dqhxxjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cataloguing Downloaded Videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17u6419", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699863464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, all,&lt;/p&gt;\n\n&lt;p&gt;I hope this is in the right place: many searches are obfuscated by the search terms...&lt;/p&gt;\n\n&lt;p&gt;Anyway, I have downloaded a load of rugby matches from various site around the web, YouTube, World Rugby, etc.&lt;/p&gt;\n\n&lt;p&gt;I want to get them into my media library, so they can appear in Kodi / Plex, etc.&lt;/p&gt;\n\n&lt;p&gt;I thought I had a solution with a Plex add on called SportScanner, but that have given me an empty library.&lt;/p&gt;\n\n&lt;p&gt;I have added the SportsDB to Kodi, and that has picked up a couple of folders, but none of the games. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure if I were to have the files named correctly, they might start appearing, but at the moment, I&amp;#39;m stuck. Currently, most of the files are named just as the game is, for example: &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;//Rugby/English Premiership Rugby/2023/2023 \ud83d\udd34 LIVE REPLAY Harlequins v Bath Round 23 Game of the Week Gallagher Premiership Rugby.mp4&amp;quot; The folder is picked up, and scraped with metadata, but neither app is picking the games up.&lt;/p&gt;\n\n&lt;p&gt;Can anyone point me in the right direction?&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u6419", "is_robot_indexable": true, "report_reasons": null, "author": "edvbvde", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u6419/cataloguing_downloaded_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u6419/cataloguing_downloaded_videos/", "subreddit_subscribers": 711829, "created_utc": 1699863464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys, I have about 50 Taiyo Yuden DVDs I bought \\~10 years ago, it is still unopened and I didn't burn anything on them.\n\nIf I burn stuff on them now will it be in good quality, like new DVDs? Or does the quality degrade even if not used?", "author_fullname": "t2_2xftem1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "question about DVDs bought 10 years ago", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u55bv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699859028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I have about 50 Taiyo Yuden DVDs I bought ~10 years ago, it is still unopened and I didn&amp;#39;t burn anything on them.&lt;/p&gt;\n\n&lt;p&gt;If I burn stuff on them now will it be in good quality, like new DVDs? Or does the quality degrade even if not used?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u55bv", "is_robot_indexable": true, "report_reasons": null, "author": "Leonhardt90", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u55bv/question_about_dvds_bought_10_years_ago/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u55bv/question_about_dvds_bought_10_years_ago/", "subreddit_subscribers": 711829, "created_utc": 1699859028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I could really use some help to know what parts I need to order so I can have this computer built asap. A few Youtube videos said I need a HBA card or RAID cards and I also need to know what kind of cables I need for the Seagate EXOS 3.5\" sata drives. I own about 120 terabytes of music/videos stored amoung 19 drives. My current rig holds 8 drives and i have 11 external drives connected to it. The new case holds (20) 3.5\" drive and a few SSDs. My goal is to populate the new build with the same 8 drives from my current rig and add 12 empty 18TB 3.5\" drives plus connect the 11 externals to it so that I can see everything in one place so I can reorganize it all so I can in the future load my newly structured collection of music/video folders to my Synology NAS next year so this new rig I'm building will not be setup in a RAID setup. Here's a link to my PCPARTSPICKER list of what I currrently have. It's all new/unopened so I can return it or exchange it if need be. I will run Windows 10 on the new rig. Do I need more or better cooling?  [https://pcpartpicker.com/list/t9m389](https://pcpartpicker.com/list/t9m389)", "author_fullname": "t2_b4kpji3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What adapters/cables do I need to complete this build with 20 internal drives and 11 external drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u375l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699851045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I could really use some help to know what parts I need to order so I can have this computer built asap. A few Youtube videos said I need a HBA card or RAID cards and I also need to know what kind of cables I need for the Seagate EXOS 3.5&amp;quot; sata drives. I own about 120 terabytes of music/videos stored amoung 19 drives. My current rig holds 8 drives and i have 11 external drives connected to it. The new case holds (20) 3.5&amp;quot; drive and a few SSDs. My goal is to populate the new build with the same 8 drives from my current rig and add 12 empty 18TB 3.5&amp;quot; drives plus connect the 11 externals to it so that I can see everything in one place so I can reorganize it all so I can in the future load my newly structured collection of music/video folders to my Synology NAS next year so this new rig I&amp;#39;m building will not be setup in a RAID setup. Here&amp;#39;s a link to my PCPARTSPICKER list of what I currrently have. It&amp;#39;s all new/unopened so I can return it or exchange it if need be. I will run Windows 10 on the new rig. Do I need more or better cooling?  &lt;a href=\"https://pcpartpicker.com/list/t9m389\"&gt;https://pcpartpicker.com/list/t9m389&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u375l", "is_robot_indexable": true, "report_reasons": null, "author": "Heavy_Sympathy_809", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u375l/what_adapterscables_do_i_need_to_complete_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u375l/what_adapterscables_do_i_need_to_complete_this/", "subreddit_subscribers": 711829, "created_utc": 1699851045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How often are there and what is a good price on high capacity, 18+ TB external HDD? I have been out of the sale game for almost a year, Now recently have a use case for an off site backup drive i can plug in at a friends NUC server and them similarly at my own place.\n\nMost recent sales seem to be for internal HDD and or refurbished HDD, Unlike back when whilst it was all about that shuck.", "author_fullname": "t2_9um7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sales on high capacity external HDD for off site backup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u20tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699847099.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699846854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How often are there and what is a good price on high capacity, 18+ TB external HDD? I have been out of the sale game for almost a year, Now recently have a use case for an off site backup drive i can plug in at a friends NUC server and them similarly at my own place.&lt;/p&gt;\n\n&lt;p&gt;Most recent sales seem to be for internal HDD and or refurbished HDD, Unlike back when whilst it was all about that shuck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u20tr", "is_robot_indexable": true, "report_reasons": null, "author": "howasdisaccounotaken", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u20tr/sales_on_high_capacity_external_hdd_for_off_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u20tr/sales_on_high_capacity_external_hdd_for_off_site/", "subreddit_subscribers": 711829, "created_utc": 1699846854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "From my understanding this is not directly a cloud system or at least not the usual. I need one where I can upload a file, make a download link, and send it to my recipient.\n\nI know of Google Drive, Mega, Mediafire, GoFile and Yandex Disk that offer these things.\n\nI actually had Yandex Disk until recently but I cannot pay there anymore, guess they have been put under restrictions since they are Russian. Shame, they were dirtcheap in comparison to everything else.\n\nThe requirements are the following:\nAt least 500GB\nPossibility to share files or even ENTIRE folders\n\nOh yeah, and I do not mind any subscription. Not neccessary to be free. Well, not like I believe theres anything free with 500GB storage and sharing functionality...", "author_fullname": "t2_4ajvjav1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best online drive system that allows downloading via link from other users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u0w3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699843243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From my understanding this is not directly a cloud system or at least not the usual. I need one where I can upload a file, make a download link, and send it to my recipient.&lt;/p&gt;\n\n&lt;p&gt;I know of Google Drive, Mega, Mediafire, GoFile and Yandex Disk that offer these things.&lt;/p&gt;\n\n&lt;p&gt;I actually had Yandex Disk until recently but I cannot pay there anymore, guess they have been put under restrictions since they are Russian. Shame, they were dirtcheap in comparison to everything else.&lt;/p&gt;\n\n&lt;p&gt;The requirements are the following:\nAt least 500GB\nPossibility to share files or even ENTIRE folders&lt;/p&gt;\n\n&lt;p&gt;Oh yeah, and I do not mind any subscription. Not neccessary to be free. Well, not like I believe theres anything free with 500GB storage and sharing functionality...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17u0w3v", "is_robot_indexable": true, "report_reasons": null, "author": "Random_Stranger69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u0w3v/what_is_the_best_online_drive_system_that_allows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u0w3v/what_is_the_best_online_drive_system_that_allows/", "subreddit_subscribers": 711829, "created_utc": 1699843243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My issue is that my 14tb target drive seems to have some issues.. I did a scan and at certain points the drive freezes for a few seconds then continues. I ran this thing called hdd llf which I think isn't true llf but rather just writes 0s over the drive.it took around 24 hours so I don't wish to repeat that, but it went smoothly without the freezing so I think it marked the bad errors and stored the info somewhere.\n\nI know I shouldn't use a suspected faulty drive but I just want to do this now before a new drive arrives as it will take some time.\n\nMy question now is, if I use macrium reflect to clone a drive onro this one and use intelligent sector copy, does macriim reflect reformat the drive again? Will the stored info on the bad areas, made by HDD llf, be lost?", "author_fullname": "t2_2yggv6i0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloning with macrium reflect. - any need to format beforehand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tz8dx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699838263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My issue is that my 14tb target drive seems to have some issues.. I did a scan and at certain points the drive freezes for a few seconds then continues. I ran this thing called hdd llf which I think isn&amp;#39;t true llf but rather just writes 0s over the drive.it took around 24 hours so I don&amp;#39;t wish to repeat that, but it went smoothly without the freezing so I think it marked the bad errors and stored the info somewhere.&lt;/p&gt;\n\n&lt;p&gt;I know I shouldn&amp;#39;t use a suspected faulty drive but I just want to do this now before a new drive arrives as it will take some time.&lt;/p&gt;\n\n&lt;p&gt;My question now is, if I use macrium reflect to clone a drive onro this one and use intelligent sector copy, does macriim reflect reformat the drive again? Will the stored info on the bad areas, made by HDD llf, be lost?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tz8dx", "is_robot_indexable": true, "report_reasons": null, "author": "mdknight666", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tz8dx/cloning_with_macrium_reflect_any_need_to_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tz8dx/cloning_with_macrium_reflect_any_need_to_format/", "subreddit_subscribers": 711829, "created_utc": 1699838263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have started a little operation to archive livestreams (all in H.264 HLS format.) For this purpose, I've been using yt-dlp, which has worked just fine, especially considering that it just downloads and transcodes the raw feeds, meaning that I can archive multiple streams simultaneously with minimal resource usage (other than bandwidth.)\n\nHowever, I have noticed that, while recording the streams, ffmpeg (through yt-dlp) outputs the following:\n\n\n    [hls @ 0x130e05930] Skip ('#EXT-X-VERSION:4')\n    [hls @ 0x130e05930] Skip ('#EXT-X-DISCONTINUITY-SEQUENCE:0')\n    [hls @ 0x130e05930] Skip ('#EXT-X-PROGRAM-DATE-TIME:2023-11-13T00:46:34.653+00:00')  \nmeaning that there is a sort of realtime, time-of-day timecode embedded in the stream (in the form of the EXT-X-PROGRAM-DATE-TIME tag.) I'd like to include this in my stream files to keep track of exactly when the stream took place, as well as keep track of glitches and time skips during recording. How can I do this with either yt-dlp or ffmpeg?", "author_fullname": "t2_osxpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Save HLS stream with original timecode data using ffmpeg/yt-dlp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tyo5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699836607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started a little operation to archive livestreams (all in H.264 HLS format.) For this purpose, I&amp;#39;ve been using yt-dlp, which has worked just fine, especially considering that it just downloads and transcodes the raw feeds, meaning that I can archive multiple streams simultaneously with minimal resource usage (other than bandwidth.)&lt;/p&gt;\n\n&lt;p&gt;However, I have noticed that, while recording the streams, ffmpeg (through yt-dlp) outputs the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-VERSION:4&amp;#39;)\n[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-DISCONTINUITY-SEQUENCE:0&amp;#39;)\n[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-PROGRAM-DATE-TIME:2023-11-13T00:46:34.653+00:00&amp;#39;)  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;meaning that there is a sort of realtime, time-of-day timecode embedded in the stream (in the form of the EXT-X-PROGRAM-DATE-TIME tag.) I&amp;#39;d like to include this in my stream files to keep track of exactly when the stream took place, as well as keep track of glitches and time skips during recording. How can I do this with either yt-dlp or ffmpeg?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tyo5f", "is_robot_indexable": true, "report_reasons": null, "author": "RenderedKnave", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tyo5f/save_hls_stream_with_original_timecode_data_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tyo5f/save_hls_stream_with_original_timecode_data_using/", "subreddit_subscribers": 711829, "created_utc": 1699836607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use a mini PC (n100 processor) for my home server. I just have a 6tb HDD plugged into it. I\u2019m wondering what the best solution is for me long term. I\u2019ll probably have the HDD filled in about a year.\n\nI see a lot of usb enclosures on Amazon but the idea of running like 5 disks over a single usb makes me nervous. \n\nI also keep seeing the 4 bay qnap DAS that can do raid 5. That\u2019s tempting too to prevent data loss. \n\nI\u2019d like to keep the miniPC as the center since it\u2019s configured just how I like it. \n\nWhat would you recommend for external storage?", "author_fullname": "t2_11dcf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best storage option for a mini PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ts9vs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699819205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use a mini PC (n100 processor) for my home server. I just have a 6tb HDD plugged into it. I\u2019m wondering what the best solution is for me long term. I\u2019ll probably have the HDD filled in about a year.&lt;/p&gt;\n\n&lt;p&gt;I see a lot of usb enclosures on Amazon but the idea of running like 5 disks over a single usb makes me nervous. &lt;/p&gt;\n\n&lt;p&gt;I also keep seeing the 4 bay qnap DAS that can do raid 5. That\u2019s tempting too to prevent data loss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to keep the miniPC as the center since it\u2019s configured just how I like it. &lt;/p&gt;\n\n&lt;p&gt;What would you recommend for external storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ts9vs", "is_robot_indexable": true, "report_reasons": null, "author": "wonka88", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ts9vs/best_storage_option_for_a_mini_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ts9vs/best_storage_option_for_a_mini_pc/", "subreddit_subscribers": 711829, "created_utc": 1699819205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is more just a poor me/venting type post. \nThis past week I was locked out of my iCloud and lost the last 2 plus years of pictures. Once I can regain access to my account I will still have some of them, I'm grateful for that but I could kick myself for not backing up the last photos. I'm a busy mom and it was always something I had on my to do list but I never got around to. I'm sick, anxious and can't sleep. This has happened before and I eventually was able to cope and move on but it's so hard. I have 3 children so all these memories are lost. I'm lucky I upload almost daily on facebook so I still have many, many photos there. \nThis will never happen again. What do you recommend I do with my new photos and what's left? Of course I will update daily/weekly to icloud but I would prefer an outside source as well.", "author_fullname": "t2_nmjgb3jfv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coping with Data Loss", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tmsda", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699803696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is more just a poor me/venting type post. \nThis past week I was locked out of my iCloud and lost the last 2 plus years of pictures. Once I can regain access to my account I will still have some of them, I&amp;#39;m grateful for that but I could kick myself for not backing up the last photos. I&amp;#39;m a busy mom and it was always something I had on my to do list but I never got around to. I&amp;#39;m sick, anxious and can&amp;#39;t sleep. This has happened before and I eventually was able to cope and move on but it&amp;#39;s so hard. I have 3 children so all these memories are lost. I&amp;#39;m lucky I upload almost daily on facebook so I still have many, many photos there. \nThis will never happen again. What do you recommend I do with my new photos and what&amp;#39;s left? Of course I will update daily/weekly to icloud but I would prefer an outside source as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17tmsda", "is_robot_indexable": true, "report_reasons": null, "author": "aqua_souffle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tmsda/coping_with_data_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tmsda/coping_with_data_loss/", "subreddit_subscribers": 711829, "created_utc": 1699803696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want submit bulk URLs (about 2k) to wayback machine. This is a very tiring work for me and I found this service;  [Batch process Google Sheets using archive.org services](https://archive.org/services/wayback-gsheets/options) But I faced a problem that wayback machine wouldn\u2019t process URLs. when I submit normal hosts ; such as example.com they save page. But when  I submit host which has no domain; such as 000.000.000.000 they returns error \u201cinvalid URL syntax\u201d \n\nThis is the URL I tried.  [nyushimondai.com - \u4eac\u90fd\u5927\u5b66 - \u6cd5\uff0c\u6587\uff0c\u8fb2\uff0c\u85ac\uff0c\u6559\u80b2\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u7dcf\u5408\u4eba\u9593\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u7406\uff0c\u7d4c\u6e08\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u533b\uff08\u533b\uff0c\u4eba\u9593\u5065\u5eb7\u79d1\uff09\uff0c\u5de5 - 2023 \u82f1\u8a9e](http://27.110.35.148/univsrch/ex/data/2023/1c/e01/e1c2311.html#mtop) \n\nIs this a bug or normal ?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_o51gazi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SavePageNow invalid URL syntax", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tkoxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699797275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want submit bulk URLs (about 2k) to wayback machine. This is a very tiring work for me and I found this service;  &lt;a href=\"https://archive.org/services/wayback-gsheets/options\"&gt;Batch process Google Sheets using archive.org services&lt;/a&gt; But I faced a problem that wayback machine wouldn\u2019t process URLs. when I submit normal hosts ; such as example.com they save page. But when  I submit host which has no domain; such as 000.000.000.000 they returns error \u201cinvalid URL syntax\u201d &lt;/p&gt;\n\n&lt;p&gt;This is the URL I tried.  &lt;a href=\"http://27.110.35.148/univsrch/ex/data/2023/1c/e01/e1c2311.html#mtop\"&gt;nyushimondai.com - \u4eac\u90fd\u5927\u5b66 - \u6cd5\uff0c\u6587\uff0c\u8fb2\uff0c\u85ac\uff0c\u6559\u80b2\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u7dcf\u5408\u4eba\u9593\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u7406\uff0c\u7d4c\u6e08\uff08\u6587\u7cfb\uff0c\u7406\u7cfb\uff09\uff0c\u533b\uff08\u533b\uff0c\u4eba\u9593\u5065\u5eb7\u79d1\uff09\uff0c\u5de5 - 2023 \u82f1\u8a9e&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Is this a bug or normal ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tkoxo", "is_robot_indexable": true, "report_reasons": null, "author": "Practical-Deer-9759", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tkoxo/savepagenow_invalid_url_syntax/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tkoxo/savepagenow_invalid_url_syntax/", "subreddit_subscribers": 711829, "created_utc": 1699797275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Thanks in advance", "author_fullname": "t2_v92witou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anybody have the happyish pilot (Philip Seymour Hoffman) or any other unsold/unaired comedy pilots they have or can recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u3tx3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699853429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u3tx3", "is_robot_indexable": true, "report_reasons": null, "author": "bigGarlic_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u3tx3/does_anybody_have_the_happyish_pilot_philip/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u3tx3/does_anybody_have_the_happyish_pilot_philip/", "subreddit_subscribers": 711829, "created_utc": 1699853429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm collecting vintage Japanese magazines that appear to have no documentation online, as well as cutouts of certain magazines. Often times I'm buying the magazines blind in hopes they contain ads, articles, artwork pertaining to the series I collect for, at which point the pages I want (as well as any especially interested pages I could sell) are cut out.\n\nI've become interested in the idea of archiving the magazines. Having them uploaded somewhere to help future collectors actually know what these magazines contain inside, while also providing me an easy way to getting product pictures for the cutouts I will sell online. I hate tossing all the non-flashy pages knowing that someone more equipped could have archived it all.\n\nI want a paper cutting solution that doesn't make me want to tear my hair out like my current tedious setup. A guillotine paper cutter would be ideal, something that could slide the spine off a glue-bound magazine with a consistent clean cut. I'm struggling to find products that look like they're work for me online, lots of mixed reviews on amazon for various cutters. I'm open to alternative solutions, as long as they get consistent cuts and make the process quicker than page-by-page.\n\nI also need a scanner. I'm leaning towards getting a flatbed scanner, rather than a sheet-fed scanner. Japanese magazines are not letter size, they've often A4 or slightly off-A4 (with the shorter side being a few mm longer than A4). It would also allow me to get good scans of postcards, trading/telephone cards, sticker sheets, etc. I would need this scanner to deal well with glossy surfaces as well. Again, open to alternatives.\n\nI know there are magazine archivists on this reddit, so I was just hoping to get some product recommendations from those who've been doing it awhile. Also would love info on where best to upload scans. Thank you for any advice on the subject.", "author_fullname": "t2_1063dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for scanner and paper cutter recommendations for archiving magazines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u24ug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699847231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m collecting vintage Japanese magazines that appear to have no documentation online, as well as cutouts of certain magazines. Often times I&amp;#39;m buying the magazines blind in hopes they contain ads, articles, artwork pertaining to the series I collect for, at which point the pages I want (as well as any especially interested pages I could sell) are cut out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve become interested in the idea of archiving the magazines. Having them uploaded somewhere to help future collectors actually know what these magazines contain inside, while also providing me an easy way to getting product pictures for the cutouts I will sell online. I hate tossing all the non-flashy pages knowing that someone more equipped could have archived it all.&lt;/p&gt;\n\n&lt;p&gt;I want a paper cutting solution that doesn&amp;#39;t make me want to tear my hair out like my current tedious setup. A guillotine paper cutter would be ideal, something that could slide the spine off a glue-bound magazine with a consistent clean cut. I&amp;#39;m struggling to find products that look like they&amp;#39;re work for me online, lots of mixed reviews on amazon for various cutters. I&amp;#39;m open to alternative solutions, as long as they get consistent cuts and make the process quicker than page-by-page.&lt;/p&gt;\n\n&lt;p&gt;I also need a scanner. I&amp;#39;m leaning towards getting a flatbed scanner, rather than a sheet-fed scanner. Japanese magazines are not letter size, they&amp;#39;ve often A4 or slightly off-A4 (with the shorter side being a few mm longer than A4). It would also allow me to get good scans of postcards, trading/telephone cards, sticker sheets, etc. I would need this scanner to deal well with glossy surfaces as well. Again, open to alternatives.&lt;/p&gt;\n\n&lt;p&gt;I know there are magazine archivists on this reddit, so I was just hoping to get some product recommendations from those who&amp;#39;ve been doing it awhile. Also would love info on where best to upload scans. Thank you for any advice on the subject.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u24ug", "is_robot_indexable": true, "report_reasons": null, "author": "Killerabbet", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u24ug/looking_for_scanner_and_paper_cutter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u24ug/looking_for_scanner_and_paper_cutter/", "subreddit_subscribers": 711829, "created_utc": 1699847231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I mean, I did get the 5TB for only like $10 for the first year but I didn't realize that it was going to be this painfully slow. Is there anything that I can do in order to speed this up? I'm up for any recommendations or suggestions like messing with settings, VPNs, anything! Don't be afraid if it's something small. Anything will help!", "author_fullname": "t2_7d0nbbry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just got Idrive and it's ABSURBLY/PAINFULLY sloooooooow!!! In need of some advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u0dri", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699841679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean, I did get the 5TB for only like $10 for the first year but I didn&amp;#39;t realize that it was going to be this painfully slow. Is there anything that I can do in order to speed this up? I&amp;#39;m up for any recommendations or suggestions like messing with settings, VPNs, anything! Don&amp;#39;t be afraid if it&amp;#39;s something small. Anything will help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u0dri", "is_robot_indexable": true, "report_reasons": null, "author": "UnderstandingFirm257", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u0dri/just_got_idrive_and_its_absurblypainfully/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u0dri/just_got_idrive_and_its_absurblypainfully/", "subreddit_subscribers": 711829, "created_utc": 1699841679.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}