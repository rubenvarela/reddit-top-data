{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got this PM from u/reddit 5 days ago. I think it's relevant to all of us, not just people who moderate dormant subreddits, so I'm sharing it here. The ModNews link in the message gives more info on what \"dormant\" means.\n\n#Automated message from reddit begins below:\n\nHello,\n\nWe are reaching out because you moderate 1 dormant subreddit(s) that qualify for removal.\n\nWhen subreddits have had no activity, we periodically remove them to make space for new communities. For more information about what this means please visit our [r/ModNews post](https://www.reddit.com/r/modnews/comments/17pb48y/removing_dormant_subreddits/).\n\nSubreddits that you moderate that qualify for dormant removal include:\n\n* mystyrnile\n\nIf you would like any of these subreddits to remain on the platform, you may opt out by banning u/SubredditPurge from your dormant community. This will signal to us that you're aware that your subreddit is dormant and have reason to keep it. While you're at it, if you'd like to grow this community, you might want to take a look at [our tips for growing a new community](https://support.reddithelp.com/hc/en-us/articles/15484061307924-First-Week-Essentials-Checklist).\n\nWithin the next two weeks, we will be removing these dormant subreddits. If you would like your subreddit to remain on the platform, please opt out as soon as you can.", "author_fullname": "t2_fjw2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Heads up, reddit is deleting dormant subreddits (no activity within the past year, few posts/comments since inception)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tw19a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699829161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got this PM from &lt;a href=\"/u/reddit\"&gt;u/reddit&lt;/a&gt; 5 days ago. I think it&amp;#39;s relevant to all of us, not just people who moderate dormant subreddits, so I&amp;#39;m sharing it here. The ModNews link in the message gives more info on what &amp;quot;dormant&amp;quot; means.&lt;/p&gt;\n\n&lt;h1&gt;Automated message from reddit begins below:&lt;/h1&gt;\n\n&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;We are reaching out because you moderate 1 dormant subreddit(s) that qualify for removal.&lt;/p&gt;\n\n&lt;p&gt;When subreddits have had no activity, we periodically remove them to make space for new communities. For more information about what this means please visit our &lt;a href=\"https://www.reddit.com/r/modnews/comments/17pb48y/removing_dormant_subreddits/\"&gt;r/ModNews post&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Subreddits that you moderate that qualify for dormant removal include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;mystyrnile&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you would like any of these subreddits to remain on the platform, you may opt out by banning &lt;a href=\"/u/SubredditPurge\"&gt;u/SubredditPurge&lt;/a&gt; from your dormant community. This will signal to us that you&amp;#39;re aware that your subreddit is dormant and have reason to keep it. While you&amp;#39;re at it, if you&amp;#39;d like to grow this community, you might want to take a look at &lt;a href=\"https://support.reddithelp.com/hc/en-us/articles/15484061307924-First-Week-Essentials-Checklist\"&gt;our tips for growing a new community&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Within the next two weeks, we will be removing these dormant subreddits. If you would like your subreddit to remain on the platform, please opt out as soon as you can.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tw19a", "is_robot_indexable": true, "report_reasons": null, "author": "MystyrNile", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tw19a/heads_up_reddit_is_deleting_dormant_subreddits_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tw19a/heads_up_reddit_is_deleting_dormant_subreddits_no/", "subreddit_subscribers": 711760, "created_utc": 1699829161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to start data hoarding ebooks and other educational media, this drive will live off the grid most of the time as my area gets a lot of storms and I've lost a previous setup to a surge (surge protectors did not help).\nThe drive will not see much reading, mainly writing so I was thinking maybe a surveillance drive might be best.\nI'm looking at around ~2tb of calculated storage I'll be needing so maybe a 4tb or 8tb or higher(if possible with my budget) might be better in order to have some more space for future data needs. What are my best options below 150 euro?", "author_fullname": "t2_69j5jfgc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best 4tb to 8tb drive below 150 euros", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tflov", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699776634.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699776089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to start data hoarding ebooks and other educational media, this drive will live off the grid most of the time as my area gets a lot of storms and I&amp;#39;ve lost a previous setup to a surge (surge protectors did not help).\nThe drive will not see much reading, mainly writing so I was thinking maybe a surveillance drive might be best.\nI&amp;#39;m looking at around ~2tb of calculated storage I&amp;#39;ll be needing so maybe a 4tb or 8tb or higher(if possible with my budget) might be better in order to have some more space for future data needs. What are my best options below 150 euro?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tflov", "is_robot_indexable": true, "report_reasons": null, "author": "ComfyCore", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tflov/best_4tb_to_8tb_drive_below_150_euros/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tflov/best_4tb_to_8tb_drive_below_150_euros/", "subreddit_subscribers": 711760, "created_utc": 1699776089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, noob question here:\n\nSetting up a Mini PC with Linux to act as my Plex server, as well being my point to store/download media. I currently plan to have an external drive connected to the mini PC where everything will be stored - only 4TB so not much on it's own but for now more than plenty for me. One thing though is that I would like to at times be able to download directly from other computers running Windows directly to the external drive connected to Linux. Do I need a NAS for this, or can I set it up in such a way that Linux will make it available to my Windows computers? \n\nFor what it's worth, while the server and HDD will run most of the time, there will be extended periods where I am able to shut down both Mini PC and HDD, so it doesn't need to be truly 24/7.\n\nThanks", "author_fullname": "t2_98wvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NAS vs External HDD for this use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tqb0l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699813737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, noob question here:&lt;/p&gt;\n\n&lt;p&gt;Setting up a Mini PC with Linux to act as my Plex server, as well being my point to store/download media. I currently plan to have an external drive connected to the mini PC where everything will be stored - only 4TB so not much on it&amp;#39;s own but for now more than plenty for me. One thing though is that I would like to at times be able to download directly from other computers running Windows directly to the external drive connected to Linux. Do I need a NAS for this, or can I set it up in such a way that Linux will make it available to my Windows computers? &lt;/p&gt;\n\n&lt;p&gt;For what it&amp;#39;s worth, while the server and HDD will run most of the time, there will be extended periods where I am able to shut down both Mini PC and HDD, so it doesn&amp;#39;t need to be truly 24/7.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tqb0l", "is_robot_indexable": true, "report_reasons": null, "author": "boundedwum", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tqb0l/nas_vs_external_hdd_for_this_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tqb0l/nas_vs_external_hdd_for_this_use_case/", "subreddit_subscribers": 711760, "created_utc": 1699813737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay, so I've gotten back into burning PS2 games, right? It's overall been a great time, and I made sure to stick to decent brands like Verbatim, I remember them being the top dog back in the days before my PS2 laser died out.\n\nSo, I get the first batch, a simple 25 pack, they all work perfectly. Smooth topside. They're the kind that are so clear you actually see the verbatim logo on the readable side. No issue there.\n\nThree months later, I get another batch, even contemplating getting a 50 pack. I got the 25 pack, same packaging, same exact description, but then I open the box and these fucking things are NOTICEABLY cheaper. Very scratchy topside, which is basically ALL white besides a tiny verbatim and dvd-r logo on the middle, somehow feels heavier. \n\nNow, out of the first batch, I essentially got every game perfectly fine, and also a few homebrew applications. The SECOND BATCH was essentially half a box of duds. One game was not getting past a sony logo (not the system logo mind you), another gives me a black screen after the playstation logo while still clearly spinning and apparently finding nothing for minutes, and some even give me a DVD error, meaning the burn was so bad it didn't even qualify as a game backup.\n\nSOME worked, haven't even checked all of them frankly so I might actually have even more faulty ones, but this is just a complete ripoff. Why the sudden downgrade? Some even downright gave me the deadly \"uncorrectable error,\" a clear sign that these are complete garbage. I know the console's drive is fine, I know the computer's drive burned at least half of these correctly, and I know for a fact the games I ripped are not to blame.\n\nI doubt I can get a refund for discs I've used, plus, probably not even worth it. But, maybe take it as a warning, some Verbatims have the same packaging, but are actually hunks of crap.", "author_fullname": "t2_uq4aaq89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Verbatim DVD-Rs are actual junk.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ty33v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699834881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay, so I&amp;#39;ve gotten back into burning PS2 games, right? It&amp;#39;s overall been a great time, and I made sure to stick to decent brands like Verbatim, I remember them being the top dog back in the days before my PS2 laser died out.&lt;/p&gt;\n\n&lt;p&gt;So, I get the first batch, a simple 25 pack, they all work perfectly. Smooth topside. They&amp;#39;re the kind that are so clear you actually see the verbatim logo on the readable side. No issue there.&lt;/p&gt;\n\n&lt;p&gt;Three months later, I get another batch, even contemplating getting a 50 pack. I got the 25 pack, same packaging, same exact description, but then I open the box and these fucking things are NOTICEABLY cheaper. Very scratchy topside, which is basically ALL white besides a tiny verbatim and dvd-r logo on the middle, somehow feels heavier. &lt;/p&gt;\n\n&lt;p&gt;Now, out of the first batch, I essentially got every game perfectly fine, and also a few homebrew applications. The SECOND BATCH was essentially half a box of duds. One game was not getting past a sony logo (not the system logo mind you), another gives me a black screen after the playstation logo while still clearly spinning and apparently finding nothing for minutes, and some even give me a DVD error, meaning the burn was so bad it didn&amp;#39;t even qualify as a game backup.&lt;/p&gt;\n\n&lt;p&gt;SOME worked, haven&amp;#39;t even checked all of them frankly so I might actually have even more faulty ones, but this is just a complete ripoff. Why the sudden downgrade? Some even downright gave me the deadly &amp;quot;uncorrectable error,&amp;quot; a clear sign that these are complete garbage. I know the console&amp;#39;s drive is fine, I know the computer&amp;#39;s drive burned at least half of these correctly, and I know for a fact the games I ripped are not to blame.&lt;/p&gt;\n\n&lt;p&gt;I doubt I can get a refund for discs I&amp;#39;ve used, plus, probably not even worth it. But, maybe take it as a warning, some Verbatims have the same packaging, but are actually hunks of crap.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17ty33v", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCocknose", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ty33v/new_verbatim_dvdrs_are_actual_junk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ty33v/new_verbatim_dvdrs_are_actual_junk/", "subreddit_subscribers": 711760, "created_utc": 1699834881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nI know there are various tools that are supposed to make this easy, but I couldn't find anything that did everything I wanted, so I made this today for fun. The web-based offerings all take forever and seem flaky, and you need to process one video at a time, with no control over the transcription settings. In contrast, my script lets you convert a whole playlist in bulk with full control over everything.\n\nIt's truly easy to use-- you can clone the repo, install to a venv, and be generating a folder full of high quality transcript text files in under 5 minutes. All you need to do is supply the URL to a YouTube playlist or to an individual video file and this tool does the rest automatically. It uses faster-whisper with a high beam_size, so it's a bit slower than you might expect, but this does result in higher accuracy. The best way to use this is to take an existing playlist, or create a new one on YouTube, start this script up, and come back the next morning with all your finished transcripts. It attempts to \"upgrade\" the output of whisper by taking all the transcript segments, gluing them together, and then splitting them back into sentences (it uses Spacy for this, or a simpler regex-based function). You end up with a single text file with the full transcript all ready to go for each video in the playlist, with a sensible file name based on the title of the video.\n\nIf you have CUDA installed, it will try to use it, but as with all things CUDA, it's annoyingly fragile and picky, so don't be surprised if you get a CUDA error even if you know for a fact CUDA is installed on your system. If you're looking for reliability, disable CUDA. But if you need to transcribe a LOT of transcripts, it does go much, much faster on a GPU.\n\nEven if you don't have a GPU, if you have a powerful machine with a lot of RAM and cores, this script will fully saturate them and can download and process multiple videos at the same time. The default settings are pretty good for that situation. But if you have a slower machine, you might want to use a smaller Whisper model (like `base.en` or even `tiny.en`) and dial down the beam_size to 2.", "author_fullname": "t2_aod18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Creation of Transcripts from YouTube Playlists with Whisper", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17t9njk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/D-XXy6YrNXiUtVtN5bMxWdMP4sgukGjnQ30cIIMRo5A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699753392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know there are various tools that are supposed to make this easy, but I couldn&amp;#39;t find anything that did everything I wanted, so I made this today for fun. The web-based offerings all take forever and seem flaky, and you need to process one video at a time, with no control over the transcription settings. In contrast, my script lets you convert a whole playlist in bulk with full control over everything.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s truly easy to use-- you can clone the repo, install to a venv, and be generating a folder full of high quality transcript text files in under 5 minutes. All you need to do is supply the URL to a YouTube playlist or to an individual video file and this tool does the rest automatically. It uses faster-whisper with a high beam_size, so it&amp;#39;s a bit slower than you might expect, but this does result in higher accuracy. The best way to use this is to take an existing playlist, or create a new one on YouTube, start this script up, and come back the next morning with all your finished transcripts. It attempts to &amp;quot;upgrade&amp;quot; the output of whisper by taking all the transcript segments, gluing them together, and then splitting them back into sentences (it uses Spacy for this, or a simpler regex-based function). You end up with a single text file with the full transcript all ready to go for each video in the playlist, with a sensible file name based on the title of the video.&lt;/p&gt;\n\n&lt;p&gt;If you have CUDA installed, it will try to use it, but as with all things CUDA, it&amp;#39;s annoyingly fragile and picky, so don&amp;#39;t be surprised if you get a CUDA error even if you know for a fact CUDA is installed on your system. If you&amp;#39;re looking for reliability, disable CUDA. But if you need to transcribe a LOT of transcripts, it does go much, much faster on a GPU.&lt;/p&gt;\n\n&lt;p&gt;Even if you don&amp;#39;t have a GPU, if you have a powerful machine with a lot of RAM and cores, this script will fully saturate them and can download and process multiple videos at the same time. The default settings are pretty good for that situation. But if you have a slower machine, you might want to use a smaller Whisper model (like &lt;code&gt;base.en&lt;/code&gt; or even &lt;code&gt;tiny.en&lt;/code&gt;) and dial down the beam_size to 2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/Dicklesworthstone/bulk_transcribe_youtube_videos_from_playlist", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?auto=webp&amp;s=a5c47fe51bbccf0042e5be1ac685c7e1ada6785b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d74027886f21186594414c9e5442db3302b84319", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a68965eaa4d977135a9db6348742ecbf14ccb39", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=224f1d15fe382d62897ece3d3b0cbca3dc4ddc8d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=12d4c43e9677640dd45453e7571e526344042af1", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6458c4abe5f18282bdf72aae5e0bc6c2acd79ca9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/MUozvfgo8u4muJQOTz314mQ1qADma4Ek07wZoyHV3vw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96b0dc841672059c889a1b90c380b65ab5d9cb37", "width": 1080, "height": 540}], "variants": {}, "id": "v-Wj3rAYmAz36GP-eHRThTYuIed01ANmkIAj0Pls8HQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17t9njk", "is_robot_indexable": true, "report_reasons": null, "author": "dicklesworth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17t9njk/bulk_creation_of_transcripts_from_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/Dicklesworthstone/bulk_transcribe_youtube_videos_from_playlist", "subreddit_subscribers": 711760, "created_utc": 1699753392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI plan to fill up quite some TB worth of external 2.5\" HDDs as cold storage and think about 4-5TB capacity/drive. \n\nWhat procedure would you suggest to check for data integrity? The idea is to do that once per year to also prevent demagnetizing.", "author_fullname": "t2_4c1ocy26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] How do you check your cold storage for data integrity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tmup9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699803894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I plan to fill up quite some TB worth of external 2.5&amp;quot; HDDs as cold storage and think about 4-5TB capacity/drive. &lt;/p&gt;\n\n&lt;p&gt;What procedure would you suggest to check for data integrity? The idea is to do that once per year to also prevent demagnetizing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Quite some TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tmup9", "is_robot_indexable": true, "report_reasons": null, "author": "Turboflopper", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17tmup9/question_how_do_you_check_your_cold_storage_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tmup9/question_how_do_you_check_your_cold_storage_for/", "subreddit_subscribers": 711760, "created_utc": 1699803894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I will digitize a couple of thousand pictures for my family and some of them range from 40-50 years ago, which means they are discolored and blurred.\n\nThe scanner I have doesn't have a good auto processing software (Canon Imageformula R40), it increases the contrast way too much and doesn't seem to understand that old photos get red with time.\n\nSo I was looking at ways to bulk process these images. It doesn't need to be perfect, it just need to improve a little bit. Does anyone has any tip?", "author_fullname": "t2_eg24o7dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips on how to bulk process digitized photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tc9gy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699762286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will digitize a couple of thousand pictures for my family and some of them range from 40-50 years ago, which means they are discolored and blurred.&lt;/p&gt;\n\n&lt;p&gt;The scanner I have doesn&amp;#39;t have a good auto processing software (Canon Imageformula R40), it increases the contrast way too much and doesn&amp;#39;t seem to understand that old photos get red with time.&lt;/p&gt;\n\n&lt;p&gt;So I was looking at ways to bulk process these images. It doesn&amp;#39;t need to be perfect, it just need to improve a little bit. Does anyone has any tip?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tc9gy", "is_robot_indexable": true, "report_reasons": null, "author": "backwards_watch", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tc9gy/any_tips_on_how_to_bulk_process_digitized_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tc9gy/any_tips_on_how_to_bulk_process_digitized_photos/", "subreddit_subscribers": 711760, "created_utc": 1699762286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Posting here as I've seen Sync.com menitoned in the past in this sub. First, it's perplexing to see so many reviews online pointing out that Sync.com is end-to-end encrypted (e2ee) and that Sync.com does not have access to your unencrypted data, when at best what should be said is *\"it's closed source, and the company claims it's e2ee and zero-knowledge\"*. But anyway...\n\nI signed up to see if I can verify anything, and turns out you can verify that it's not e2ee and zero-knowledge. I uploaded a file, then shared it and Sync.com gave me a link that I can pass to friends. The link has no hash parts (that are seen only by the local browser), it looks like this:\n\nhttps://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX\n\nPutting that link in any browser gets you the unencrypted file directly - there is no password being asked.\n\nThe same URL is logged by the Sync.com server as well whenever someone requests it, hence not only can Sync.com also retrieve the unencrypted file themselves, but if it was stored encrypted then in order to produce that link that gets the unencrypted content, Sync.com must have access to your encryption key (synonymous with knowing your encryption password) ... so it can't be stated either that if you share files then those files lose e2ee somehow. What is clear is that Sync.com is not e2ee (unless your e2ee definition allows the host to know the encryption key).\n\nBasically, it's at best server-side encrypted (like most of them are, or claim they are).", "author_fullname": "t2_aq2bzze4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync.com claims it's end-to-end encrypted and that they can't decrypt your data stored on their servers. That's false.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17tyupn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699839075.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699837146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posting here as I&amp;#39;ve seen Sync.com menitoned in the past in this sub. First, it&amp;#39;s perplexing to see so many reviews online pointing out that Sync.com is end-to-end encrypted (e2ee) and that Sync.com does not have access to your unencrypted data, when at best what should be said is &lt;em&gt;&amp;quot;it&amp;#39;s closed source, and the company claims it&amp;#39;s e2ee and zero-knowledge&amp;quot;&lt;/em&gt;. But anyway...&lt;/p&gt;\n\n&lt;p&gt;I signed up to see if I can verify anything, and turns out you can verify that it&amp;#39;s not e2ee and zero-knowledge. I uploaded a file, then shared it and Sync.com gave me a link that I can pass to friends. The link has no hash parts (that are seen only by the local browser), it looks like this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX\"&gt;https://ln5.sync.com/dl/XXXXXXXXXX/XXXXXXXX-XXXXXXXXXX-XXXXXXXXX-XXXXXXXXX&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Putting that link in any browser gets you the unencrypted file directly - there is no password being asked.&lt;/p&gt;\n\n&lt;p&gt;The same URL is logged by the Sync.com server as well whenever someone requests it, hence not only can Sync.com also retrieve the unencrypted file themselves, but if it was stored encrypted then in order to produce that link that gets the unencrypted content, Sync.com must have access to your encryption key (synonymous with knowing your encryption password) ... so it can&amp;#39;t be stated either that if you share files then those files lose e2ee somehow. What is clear is that Sync.com is not e2ee (unless your e2ee definition allows the host to know the encryption key).&lt;/p&gt;\n\n&lt;p&gt;Basically, it&amp;#39;s at best server-side encrypted (like most of them are, or claim they are).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?auto=webp&amp;s=a7dd75665aba4e9285d6e97dc5b41fcc53375536", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=588a695a838a4b6b36340282ea641f5d0fe08019", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7acefa097eb35afaf2a47243f8c8560b5bd95d4e", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4adccebbfc644a0e01c02f23d05546c7d5de8d25", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a04df6714f874402025ef0fb8b6ecc3f2ba7209", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=50f72580a7e444454a7f7b53bcb9b7acf153a2d5", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/qZSFT58Xh-xe3oorbpEGABvGfC-aoTUVTZWtiUaqFIk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=14b521b5f5d98d0ed092913ff7873df50f10c8f4", "width": 1080, "height": 564}], "variants": {}, "id": "5OC09iA0QU1QptKOj0rRgMi2YTF53YfM-rKvyubxY8Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tyupn", "is_robot_indexable": true, "report_reasons": null, "author": "johnfintech", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tyupn/synccom_claims_its_endtoend_encrypted_and_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tyupn/synccom_claims_its_endtoend_encrypted_and_that/", "subreddit_subscribers": 711760, "created_utc": 1699837146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have started a little operation to archive livestreams (all in H.264 HLS format.) For this purpose, I've been using yt-dlp, which has worked just fine, especially considering that it just downloads and transcodes the raw feeds, meaning that I can archive multiple streams simultaneously with minimal resource usage (other than bandwidth.)\n\nHowever, I have noticed that, while recording the streams, ffmpeg (through yt-dlp) outputs the following:\n\n\n    [hls @ 0x130e05930] Skip ('#EXT-X-VERSION:4')\n    [hls @ 0x130e05930] Skip ('#EXT-X-DISCONTINUITY-SEQUENCE:0')\n    [hls @ 0x130e05930] Skip ('#EXT-X-PROGRAM-DATE-TIME:2023-11-13T00:46:34.653+00:00')  \nmeaning that there is a sort of realtime, time-of-day timecode embedded in the stream (in the form of the EXT-X-PROGRAM-DATE-TIME tag.) I'd like to include this in my stream files to keep track of exactly when the stream took place, as well as keep track of glitches and time skips during recording. How can I do this with either yt-dlp or ffmpeg?", "author_fullname": "t2_osxpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Save HLS stream with original timecode data using ffmpeg/yt-dlp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17tyo5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699836607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started a little operation to archive livestreams (all in H.264 HLS format.) For this purpose, I&amp;#39;ve been using yt-dlp, which has worked just fine, especially considering that it just downloads and transcodes the raw feeds, meaning that I can archive multiple streams simultaneously with minimal resource usage (other than bandwidth.)&lt;/p&gt;\n\n&lt;p&gt;However, I have noticed that, while recording the streams, ffmpeg (through yt-dlp) outputs the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-VERSION:4&amp;#39;)\n[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-DISCONTINUITY-SEQUENCE:0&amp;#39;)\n[hls @ 0x130e05930] Skip (&amp;#39;#EXT-X-PROGRAM-DATE-TIME:2023-11-13T00:46:34.653+00:00&amp;#39;)  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;meaning that there is a sort of realtime, time-of-day timecode embedded in the stream (in the form of the EXT-X-PROGRAM-DATE-TIME tag.) I&amp;#39;d like to include this in my stream files to keep track of exactly when the stream took place, as well as keep track of glitches and time skips during recording. How can I do this with either yt-dlp or ffmpeg?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tyo5f", "is_robot_indexable": true, "report_reasons": null, "author": "RenderedKnave", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tyo5f/save_hls_stream_with_original_timecode_data_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tyo5f/save_hls_stream_with_original_timecode_data_using/", "subreddit_subscribers": 711760, "created_utc": 1699836607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, current setting up is a R510 (12 Bay) has 9 platters, and 5 SSDs raid 6 and raid 5, 4TB/512, respectively running on HW raid with ESXI 6.0U3   \nBackups are handled via Veeam to a whitebox with win server 2012 and a software raid of 5x 6TB drives   \nPower consumption has been absolutely driving me crazy (US CT) and plan on figuring out next evolution of hardware on my own.   \nQuestion is, seems the writing on the walls for awhile has been that HW raid is dying, long live ZFS which I'm 100% on board with, but the lack of being able to expand a (vdev) without adding another pool is a little scary to me but something I'm pretty sure I'll just have to deal with.   \nWhat if any hypervisor would allow me use of zfs, give me automatic health reports via email and has a veeam like backup solution avail? (Incremental/full backups) \n\nThanks so much, love this thread, hoping to up my storage in the process of all this! ", "author_fullname": "t2_50oya5bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Server Upgrade questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tsaoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699819253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, current setting up is a R510 (12 Bay) has 9 platters, and 5 SSDs raid 6 and raid 5, 4TB/512, respectively running on HW raid with ESXI 6.0U3&lt;br/&gt;\nBackups are handled via Veeam to a whitebox with win server 2012 and a software raid of 5x 6TB drives&lt;br/&gt;\nPower consumption has been absolutely driving me crazy (US CT) and plan on figuring out next evolution of hardware on my own.&lt;br/&gt;\nQuestion is, seems the writing on the walls for awhile has been that HW raid is dying, long live ZFS which I&amp;#39;m 100% on board with, but the lack of being able to expand a (vdev) without adding another pool is a little scary to me but something I&amp;#39;m pretty sure I&amp;#39;ll just have to deal with.&lt;br/&gt;\nWhat if any hypervisor would allow me use of zfs, give me automatic health reports via email and has a veeam like backup solution avail? (Incremental/full backups) &lt;/p&gt;\n\n&lt;p&gt;Thanks so much, love this thread, hoping to up my storage in the process of all this! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "25TB of rust 2TB SSD", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tsaoh", "is_robot_indexable": true, "report_reasons": null, "author": "jasonswohl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17tsaoh/server_upgrade_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tsaoh/server_upgrade_questions/", "subreddit_subscribers": 711760, "created_utc": 1699819253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHi, for instance this webpage:\n\n[https://www.scientificamerican.com/article/flavor-connection-taste-map-interactive/](https://www.scientificamerican.com/article/flavor-connection-taste-map-interactive/)\n\nI tried save as webpage complete, HTML only, single file, but none save the interactive part.", "author_fullname": "t2_vnept3cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I save an interactive website on Chrome for offline use? Example inside.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17txy8p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699834477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, for instance this webpage:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.scientificamerican.com/article/flavor-connection-taste-map-interactive/\"&gt;https://www.scientificamerican.com/article/flavor-connection-taste-map-interactive/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I tried save as webpage complete, HTML only, single file, but none save the interactive part.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0Sf6aBbyeBdB1DiyJpjfF471ER6u35VOHh2896BySD4.jpg?auto=webp&amp;s=98e153f8914eac95ded24af287b940b528ff9712", "width": 790, "height": 496}, "resolutions": [{"url": "https://external-preview.redd.it/0Sf6aBbyeBdB1DiyJpjfF471ER6u35VOHh2896BySD4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0efbc3a96b7e3d37def26e13e140f5f1dc855b3", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/0Sf6aBbyeBdB1DiyJpjfF471ER6u35VOHh2896BySD4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fd6fe11d7fc70c83af3d4ed422fcea8396e7ca65", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/0Sf6aBbyeBdB1DiyJpjfF471ER6u35VOHh2896BySD4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ce701c2f61be5cba766a92f9c4aa121ef96361b", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/0Sf6aBbyeBdB1DiyJpjfF471ER6u35VOHh2896BySD4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f74944415e81d02cc8602bed88b866b3606cc72", "width": 640, "height": 401}], "variants": {}, "id": "3tT-YbCcjRTgF93ldFglNGAWvkfesUgzq3dvn3ccaTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17txy8p", "is_robot_indexable": true, "report_reasons": null, "author": "Fin_al", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17txy8p/how_can_i_save_an_interactive_website_on_chrome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17txy8p/how_can_i_save_an_interactive_website_on_chrome/", "subreddit_subscribers": 711760, "created_utc": 1699834477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I plan on having two of them, with the same data. I heard flash drives are not good for cold storage, but aren\u2019t all SSDs not good for cold storage? So what\u2019s the difference? And does this premium solid state flash drive model make it as good for cold storage as any traditional big ssd? \n\nAlso, is the Kingston DataTraveler Max Flashdrive (1000mb/s) a good alternative, or is this SanDisk FlashDrive still the best over the Kingston in terms of build quality and safe longevity of data, even with the SanDisk having half the speed? \n\nThank you for the help in advance. It\u2019s so confusing.", "author_fullname": "t2_kxz5a4fi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the SanDisk Extreme Pro 3.2 Solid State Flash Drive good for long-term cold storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17txvpj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699834873.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699834267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan on having two of them, with the same data. I heard flash drives are not good for cold storage, but aren\u2019t all SSDs not good for cold storage? So what\u2019s the difference? And does this premium solid state flash drive model make it as good for cold storage as any traditional big ssd? &lt;/p&gt;\n\n&lt;p&gt;Also, is the Kingston DataTraveler Max Flashdrive (1000mb/s) a good alternative, or is this SanDisk FlashDrive still the best over the Kingston in terms of build quality and safe longevity of data, even with the SanDisk having half the speed? &lt;/p&gt;\n\n&lt;p&gt;Thank you for the help in advance. It\u2019s so confusing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17txvpj", "is_robot_indexable": true, "report_reasons": null, "author": "BluebirdSpare7343", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17txvpj/is_the_sandisk_extreme_pro_32_solid_state_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17txvpj/is_the_sandisk_extreme_pro_32_solid_state_flash/", "subreddit_subscribers": 711760, "created_utc": 1699834267.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_gh9x9qzou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refurbished Seagate Exos X16 16TB for $150/ea or $9.38/TB @ serverpartdeals...thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_17txi52", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ZhpcoLCPbBkM4plDZQY-wJUNMtmQz302r3RsfdAQ0A0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699833175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serverpartdeals.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serverpartdeals.com/products/seagate-exos-x16-st16000nm002g-16tb-7-2k-rpm-sas-12gb-s-512e-4kn-3-5-refurbished-hdd", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MJBqVaNqu4J84sNfUs5qa9jnHA37TGlNtw7ki5crmFs.jpg?auto=webp&amp;s=469424e9b40ecb49b6c907ce8a29eef3dafef48a", "width": 720, "height": 720}, "resolutions": [{"url": "https://external-preview.redd.it/MJBqVaNqu4J84sNfUs5qa9jnHA37TGlNtw7ki5crmFs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=31902afa3154e6eed5a0b523ec6d5b4ba1d73140", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MJBqVaNqu4J84sNfUs5qa9jnHA37TGlNtw7ki5crmFs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8f1f8d927b882d1748cd6fc7f82c304874ff4b03", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/MJBqVaNqu4J84sNfUs5qa9jnHA37TGlNtw7ki5crmFs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8240287cd61218274cb20adaabeaad9798708eb6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/MJBqVaNqu4J84sNfUs5qa9jnHA37TGlNtw7ki5crmFs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de4bfcefb81f9c85aa90351c977a759f366e0620", "width": 640, "height": 640}], "variants": {}, "id": "qInIi55FvBcw_GiKnk2IN-2OKag_5b7ukHKdQtHkV3U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "17txi52", "is_robot_indexable": true, "report_reasons": null, "author": "Frankensteins_Chick", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17txi52/refurbished_seagate_exos_x16_16tb_for_150ea_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serverpartdeals.com/products/seagate-exos-x16-st16000nm002g-16tb-7-2k-rpm-sas-12gb-s-512e-4kn-3-5-refurbished-hdd", "subreddit_subscribers": 711760, "created_utc": 1699833175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi,\n\nthe modular (internal turned external) dvd drive from my old laptop has died recently, and I have to buy a new one for audio-ripping. which one of easily available on ebay/amazon supports accuraterip feature?", "author_fullname": "t2_15t7lk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best external DVD for audio ripping?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tssen", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699820554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi,&lt;/p&gt;\n\n&lt;p&gt;the modular (internal turned external) dvd drive from my old laptop has died recently, and I have to buy a new one for audio-ripping. which one of easily available on ebay/amazon supports accuraterip feature?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tssen", "is_robot_indexable": true, "report_reasons": null, "author": "ViolatorOfVirgins", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tssen/best_external_dvd_for_audio_ripping/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tssen/best_external_dvd_for_audio_ripping/", "subreddit_subscribers": 711760, "created_utc": 1699820554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I use a mini PC (n100 processor) for my home server. I just have a 6tb HDD plugged into it. I\u2019m wondering what the best solution is for me long term. I\u2019ll probably have the HDD filled in about a year.\n\nI see a lot of usb enclosures on Amazon but the idea of running like 5 disks over a single usb makes me nervous. \n\nI also keep seeing the 4 bay qnap DAS that can do raid 5. That\u2019s tempting too to prevent data loss. \n\nI\u2019d like to keep the miniPC as the center since it\u2019s configured just how I like it. \n\nWhat would you recommend for external storage?", "author_fullname": "t2_11dcf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best storage option for a mini PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ts9vs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699819205.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use a mini PC (n100 processor) for my home server. I just have a 6tb HDD plugged into it. I\u2019m wondering what the best solution is for me long term. I\u2019ll probably have the HDD filled in about a year.&lt;/p&gt;\n\n&lt;p&gt;I see a lot of usb enclosures on Amazon but the idea of running like 5 disks over a single usb makes me nervous. &lt;/p&gt;\n\n&lt;p&gt;I also keep seeing the 4 bay qnap DAS that can do raid 5. That\u2019s tempting too to prevent data loss. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d like to keep the miniPC as the center since it\u2019s configured just how I like it. &lt;/p&gt;\n\n&lt;p&gt;What would you recommend for external storage?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ts9vs", "is_robot_indexable": true, "report_reasons": null, "author": "wonka88", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ts9vs/best_storage_option_for_a_mini_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ts9vs/best_storage_option_for_a_mini_pc/", "subreddit_subscribers": 711760, "created_utc": 1699819205.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm extremely worried about data deletion or including it into ai. When ai can extrapolate beyond its trainingsdata, there might be a chance of not needing the dataset anymore. Well yes i could just go with the synthetical stuff which will come, and there is no way that this timelines progress will stop. But then again, keeping the data that has led to this progress alone is worth it. Thats like the invention of fire and how our ancestors did it. Ofcourse i want to keep such things and not change it at all.\n\nInformation isnt as preservable as i thought and i hope science will find a way to keep what we did.\nI can't imagine losing everything and to life with that alone is a pain. Atleast for the next 30-100 years.\n\nWhat do you think about that?", "author_fullname": "t2_klhvque3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17txo7c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699833662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m extremely worried about data deletion or including it into ai. When ai can extrapolate beyond its trainingsdata, there might be a chance of not needing the dataset anymore. Well yes i could just go with the synthetical stuff which will come, and there is no way that this timelines progress will stop. But then again, keeping the data that has led to this progress alone is worth it. Thats like the invention of fire and how our ancestors did it. Ofcourse i want to keep such things and not change it at all.&lt;/p&gt;\n\n&lt;p&gt;Information isnt as preservable as i thought and i hope science will find a way to keep what we did.\nI can&amp;#39;t imagine losing everything and to life with that alone is a pain. Atleast for the next 30-100 years.&lt;/p&gt;\n\n&lt;p&gt;What do you think about that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17txo7c", "is_robot_indexable": true, "report_reasons": null, "author": "Cultural_League_3539", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17txo7c/future_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17txo7c/future_of_data/", "subreddit_subscribers": 711760, "created_utc": 1699833662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "At less than 10$ a TB and 5 year warranty would this be a good deal? Looking to set up my first home media server so no crucial data and would have 4 set up in raid 5.", "author_fullname": "t2_5jjtzd3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worth the risk ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17toctc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lw8aQ6Yma_L_cmldB2z7DEgsVCtyXLPsy4ThJIpV-Uc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699808223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At less than 10$ a TB and 5 year warranty would this be a good deal? Looking to set up my first home media server so no crucial data and would have 4 set up in raid 5.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rddk5u2k6yzb1.jpeg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?auto=webp&amp;s=96fa725f4bbe9c7b7335fa40fcae10a1dbe174f9", "width": 1125, "height": 2436}, "resolutions": [{"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9aae4fbff775732643f8f99199a05d178256b770", "width": 108, "height": 216}, {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ea0ffdca827398b315c9e0056e9ca40d62cdf5c3", "width": 216, "height": 432}, {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=211b1f63ffade5a61c3083a0339a8e5a428932de", "width": 320, "height": 640}, {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5beaaa0cfe926d537cc513a98fbc43b1bff1322a", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9d83efbeb27f7013c6ce9817360bc4c659d2928", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/rddk5u2k6yzb1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=84a89dedc053e1d7ca833ebe208814c07107d969", "width": 1080, "height": 2160}], "variants": {}, "id": "CUw72THRoWr0kOlshPZpEa0Km0guQdMiRWmIQxdo2Bo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17toctc", "is_robot_indexable": true, "report_reasons": null, "author": "Deep_Potato3080", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17toctc/worth_the_risk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rddk5u2k6yzb1.jpeg", "subreddit_subscribers": 711760, "created_utc": 1699808223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\ni found a offering on Ebay for refurbished seagate enterprise capacity harddrives with a good price (12tb/120\u20ac).\n\nHas anyone experience using these drives in a nas and would recommend them ? Or should I stay away?\n\nI\u2019m running a 4 bay nas with raid5.\n\nThanks.", "author_fullname": "t2_18d60sm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Refurbished Seagate Enterprise Capacity for Nas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17tg4ul", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.48, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i53F1Hnz0SHAvA6GsiwkP9Vu8oAZADbATdfixHZUe8M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699778560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\ni found a offering on Ebay for refurbished seagate enterprise capacity harddrives with a good price (12tb/120\u20ac).&lt;/p&gt;\n\n&lt;p&gt;Has anyone experience using these drives in a nas and would recommend them ? Or should I stay away?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m running a 4 bay nas with raid5.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4e9lshqcqvzb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?auto=webp&amp;s=746162479822935741d51396cb1e9168f08ed7a2", "width": 1125, "height": 1637}, "resolutions": [{"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27f91d59bab9bb41057dabb4fd965489477f7291", "width": 108, "height": 157}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47458dc7a2c8d8207d3cebb6e6eb2ab9803747f6", "width": 216, "height": 314}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1f1f6664bc6389786529e606d40533a8fe4bbf7", "width": 320, "height": 465}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c333f31de9209635cda4e8174ffe5874008a1a1", "width": 640, "height": 931}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2632bf64cbfa9747aa157dee01ba798cbe2706a4", "width": 960, "height": 1396}, {"url": "https://preview.redd.it/4e9lshqcqvzb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9c01decaae033b33c1c4711a47c89a316fddd470", "width": 1080, "height": 1571}], "variants": {}, "id": "XYYwksRwZfPHxHbKXeBYXQwy5RGyXQ5W-RMNNxD6pXI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tg4ul", "is_robot_indexable": true, "report_reasons": null, "author": "chaosys", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tg4ul/has_anyone_used_refurbished_seagate_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4e9lshqcqvzb1.jpg", "subreddit_subscribers": 711760, "created_utc": 1699778560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all. I know this isn't exactly the correct subreddit for what I'm looking for, so mods if you delete this I won't be offended, but I'm hoping someone can point me in the right direction. I just finished scanning some '70's first aid booklets and thought it would be cool to upload them online on some sort of website dedicated to archiving old stuff like that, but I don't know where to search. Any help would be cool!", "author_fullname": "t2_a7k38pov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to upload some document scans?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tpgwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699811393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. I know this isn&amp;#39;t exactly the correct subreddit for what I&amp;#39;m looking for, so mods if you delete this I won&amp;#39;t be offended, but I&amp;#39;m hoping someone can point me in the right direction. I just finished scanning some &amp;#39;70&amp;#39;s first aid booklets and thought it would be cool to upload them online on some sort of website dedicated to archiving old stuff like that, but I don&amp;#39;t know where to search. Any help would be cool!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tpgwf", "is_robot_indexable": true, "report_reasons": null, "author": "caeserlettuce", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17tpgwf/where_to_upload_some_document_scans/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tpgwf/where_to_upload_some_document_scans/", "subreddit_subscribers": 711760, "created_utc": 1699811393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2](https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2)\n\nI want to archive just this auction, mainly the photos but the closing prices would be nice too. So my goal is either a folder of photos, or that and a browsable offline copy.  \n\nSimply right clicking and saving works decently enough but surely there is a faster way. There are 16 pages and I'm actually doing 2 separate auctions. \n\nMy usual script for a webpage is crawling the whole site and pulling various vendor information instead of just this webpage. My script usually doesn't do that so I'm thinking it's something to do with how the site is structured. \n\n    wget -p --convert-links -e robots=off -U mozilla --no-parent https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2\n\nAny advice would be appreciated. ", "author_fullname": "t2_ay7tp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I archive this particular auction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tkwvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699797954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2\"&gt;https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to archive just this auction, mainly the photos but the closing prices would be nice too. So my goal is either a folder of photos, or that and a browsable offline copy.  &lt;/p&gt;\n\n&lt;p&gt;Simply right clicking and saving works decently enough but surely there is a faster way. There are 16 pages and I&amp;#39;m actually doing 2 separate auctions. &lt;/p&gt;\n\n&lt;p&gt;My usual script for a webpage is crawling the whole site and pulling various vendor information instead of just this webpage. My script usually doesn&amp;#39;t do that so I&amp;#39;m thinking it&amp;#39;s something to do with how the site is structured. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;wget -p --convert-links -e robots=off -U mozilla --no-parent https://www.resauctions.com/auctions/24572-two-day-richard-and-mary-lou-taylor-lifetime-collection-absolute-auction?page=2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Any advice would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "244TB ZFS and Synology", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17tkwvv", "is_robot_indexable": true, "report_reasons": null, "author": "erik530195", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17tkwvv/how_can_i_archive_this_particular_auction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17tkwvv/how_can_i_archive_this_particular_auction/", "subreddit_subscribers": 711760, "created_utc": 1699797954.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}