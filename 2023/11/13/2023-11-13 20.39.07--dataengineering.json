{"kind": "Listing", "data": {"after": "t3_17u5wru", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically the title.\n\nCurrently I\u2019m an Azure ETL developer and want to break into real time streaming jobs. I need all your advices to transition from no code to software development jobs.", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People that transitioned for no-code/low code to databricks/spark/python sw development: how did you do it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uc34w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699886485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically the title.&lt;/p&gt;\n\n&lt;p&gt;Currently I\u2019m an Azure ETL developer and want to break into real time streaming jobs. I need all your advices to transition from no code to software development jobs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17uc34w", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uc34w/people_that_transitioned_for_nocodelow_code_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uc34w/people_that_transitioned_for_nocodelow_code_to/", "subreddit_subscribers": 139503, "created_utc": 1699886485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking for insight on the technical limits of doing aggregate queries in OLTP systems like MySQL or psql. Figuring an example might be easy to understand. Trying to go a little deeper than the marketing material. \n\nI know it\u2019s probably possible. But what makes OLAPs suited for the purpose? \n\nThanks for any pointers.", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What sort of query is possible in redshift/BQ/ClickHouse that isn\u2019t feasible/cheap in OLTPs like PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uay2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699883098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for insight on the technical limits of doing aggregate queries in OLTP systems like MySQL or psql. Figuring an example might be easy to understand. Trying to go a little deeper than the marketing material. &lt;/p&gt;\n\n&lt;p&gt;I know it\u2019s probably possible. But what makes OLAPs suited for the purpose? &lt;/p&gt;\n\n&lt;p&gt;Thanks for any pointers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17uay2v", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uay2v/what_sort_of_query_is_possible_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uay2v/what_sort_of_query_is_possible_in/", "subreddit_subscribers": 139503, "created_utc": 1699883098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been conducting a research around OLAP dbs that are relevant in 2023 with my data science team for a new project. \n\nThe ideal solution would be *a db that can make use of an S3 bucket as long term storage, while being easy to deploy and manage on Kubernetes.* They will be consuming *kafka topics.*\n\nI have narrowed down the solutions between **Apache Druid**, **Starrocks** and of course **Clickhouse**.\n\nWhile **Druid** shows some very neat tricks on real time data storing/indexing, its *deployment on kubernetes is really ugly*. \n\n**Starrocks** is not so far, also a bit complex to deploy and manage the *\"front end and back end\" clusters*, while **Clickhouse** *makes the k8s deployment a bliss*. \n\nWhat got me in **Clikchouse** is the *kafka topics ingestion*, its a lot of work to create and keep managing sql materialized things everytime I need to get some new data. **Druid** otherwise makes it super cool by *almost automatically understanding the json received from the kafka topics*.\n\nHowever I feel like **Druid** is getting a bit old and with not so much community or development resources or attention. ChatGPT is saving my ass I must admit. Tho, a lot of \"what corps are using this tech\" sites show that Twitter, Neflix and Reddit itself use Druid. I'm not sure if that is true or old data. \n\n**Clickhouse** otherwise feels like the industry baby, ultra-seeded and megacorp friendly, but with its own problems like painful cross table joins. **Starrocks** have a nice fanbase, but falls a bit in the same place as Druid, even being some years ahead of Apache Doris, plus the fact it is mantained by the Linux Foundation.\n\nSo, what are your thoughts on these three OLAP databases today? \n\n&amp;#x200B;", "author_fullname": "t2_16eobxdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your Thoughts on OLAPs Clickhouse vs Apache Druid vs Starrocks in 2023/2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u2ova", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699849147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been conducting a research around OLAP dbs that are relevant in 2023 with my data science team for a new project. &lt;/p&gt;\n\n&lt;p&gt;The ideal solution would be &lt;em&gt;a db that can make use of an S3 bucket as long term storage, while being easy to deploy and manage on Kubernetes.&lt;/em&gt; They will be consuming &lt;em&gt;kafka topics.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;I have narrowed down the solutions between &lt;strong&gt;Apache Druid&lt;/strong&gt;, &lt;strong&gt;Starrocks&lt;/strong&gt; and of course &lt;strong&gt;Clickhouse&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;While &lt;strong&gt;Druid&lt;/strong&gt; shows some very neat tricks on real time data storing/indexing, its &lt;em&gt;deployment on kubernetes is really ugly&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Starrocks&lt;/strong&gt; is not so far, also a bit complex to deploy and manage the &lt;em&gt;&amp;quot;front end and back end&amp;quot; clusters&lt;/em&gt;, while &lt;strong&gt;Clickhouse&lt;/strong&gt; &lt;em&gt;makes the k8s deployment a bliss&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;What got me in &lt;strong&gt;Clikchouse&lt;/strong&gt; is the &lt;em&gt;kafka topics ingestion&lt;/em&gt;, its a lot of work to create and keep managing sql materialized things everytime I need to get some new data. &lt;strong&gt;Druid&lt;/strong&gt; otherwise makes it super cool by &lt;em&gt;almost automatically understanding the json received from the kafka topics&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;However I feel like &lt;strong&gt;Druid&lt;/strong&gt; is getting a bit old and with not so much community or development resources or attention. ChatGPT is saving my ass I must admit. Tho, a lot of &amp;quot;what corps are using this tech&amp;quot; sites show that Twitter, Neflix and Reddit itself use Druid. I&amp;#39;m not sure if that is true or old data. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Clickhouse&lt;/strong&gt; otherwise feels like the industry baby, ultra-seeded and megacorp friendly, but with its own problems like painful cross table joins. &lt;strong&gt;Starrocks&lt;/strong&gt; have a nice fanbase, but falls a bit in the same place as Druid, even being some years ahead of Apache Doris, plus the fact it is mantained by the Linux Foundation.&lt;/p&gt;\n\n&lt;p&gt;So, what are your thoughts on these three OLAP databases today? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17u2ova", "is_robot_indexable": true, "report_reasons": null, "author": "Neptun0", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u2ova/your_thoughts_on_olaps_clickhouse_vs_apache_druid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u2ova/your_thoughts_on_olaps_clickhouse_vs_apache_druid/", "subreddit_subscribers": 139503, "created_utc": 1699849147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, I am the cofounder of [dlt](https://pypi.org/project/dlt/), the opensource data loading library.\n\nWe are looking into supporting databricks and we have some doubts about which loading method to best use.\n\ndlt can take semi structured data and structure it to parquet or sql with schema evolution. So we can already output parquet to s3\n\nWe are looking into what's the best way for loading into databricks ecosystem.\n\n**Question**: The docs talk about these modes: [COPY INTO](https://docs.databricks.com/en/ingestion/copy-into/index.html) or [AutoLoader](https://docs.databricks.com/en/ingestion/auto-loader/index.html). Which one do you use and why?  We could support any of the patterns, and we would like to understand which ones are used, useful and why.\n\nIf you want to give feedback directly in github, our ticket is here [https://github.com/dlt-hub/dlt/issues/762](https://github.com/dlt-hub/dlt/issues/762)", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you load to databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u90tc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699876481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I am the cofounder of &lt;a href=\"https://pypi.org/project/dlt/\"&gt;dlt&lt;/a&gt;, the opensource data loading library.&lt;/p&gt;\n\n&lt;p&gt;We are looking into supporting databricks and we have some doubts about which loading method to best use.&lt;/p&gt;\n\n&lt;p&gt;dlt can take semi structured data and structure it to parquet or sql with schema evolution. So we can already output parquet to s3&lt;/p&gt;\n\n&lt;p&gt;We are looking into what&amp;#39;s the best way for loading into databricks ecosystem.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: The docs talk about these modes: &lt;a href=\"https://docs.databricks.com/en/ingestion/copy-into/index.html\"&gt;COPY INTO&lt;/a&gt; or &lt;a href=\"https://docs.databricks.com/en/ingestion/auto-loader/index.html\"&gt;AutoLoader&lt;/a&gt;. Which one do you use and why?  We could support any of the patterns, and we would like to understand which ones are used, useful and why.&lt;/p&gt;\n\n&lt;p&gt;If you want to give feedback directly in github, our ticket is here &lt;a href=\"https://github.com/dlt-hub/dlt/issues/762\"&gt;https://github.com/dlt-hub/dlt/issues/762&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?auto=webp&amp;s=85f19a22cbd85fa784cdb417359d8ff7cda9e394", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46fa55dd1b1e587ab93bcbbdc6cb2de37b810bf3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MoP6enMQ2Q6o4o23d5xCmvlBtpeCXWiqxc63UVCX5Rk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfd7f76ac4c13cdc287edd9856ef0430dbc862a5", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17u90tc", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u90tc/how_do_you_load_to_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u90tc/how_do_you_load_to_databricks/", "subreddit_subscribers": 139503, "created_utc": 1699876481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 classes remaining after this semester to finish my MSDS. I have 3 YOE working in low quality DS/DE roles. \n\nCurrently working a really trash DE job for the past 3 months that is just a 50 hour a week on-site BI role for $110K. Previously left last company after 6 months which was also a trash job where my DE skills stagnated. \n\nShould I quit my MSDS, that has been of marginal quality so far, in order to allocate those ~10 hours per week to upskilling via certifications (AWS Data Engineer, Databricks Spark Certification, Astronomer Airflow Certification) and leetcode? \n\nMy plan is to interview Q1 next year to try and save my career with an actual DE role using in demand technologies.", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I Finish my Masters in DS or Just Get Some Certifications/Upskill?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u0fn6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699841835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 classes remaining after this semester to finish my MSDS. I have 3 YOE working in low quality DS/DE roles. &lt;/p&gt;\n\n&lt;p&gt;Currently working a really trash DE job for the past 3 months that is just a 50 hour a week on-site BI role for $110K. Previously left last company after 6 months which was also a trash job where my DE skills stagnated. &lt;/p&gt;\n\n&lt;p&gt;Should I quit my MSDS, that has been of marginal quality so far, in order to allocate those ~10 hours per week to upskilling via certifications (AWS Data Engineer, Databricks Spark Certification, Astronomer Airflow Certification) and leetcode? &lt;/p&gt;\n\n&lt;p&gt;My plan is to interview Q1 next year to try and save my career with an actual DE role using in demand technologies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17u0fn6", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u0fn6/should_i_finish_my_masters_in_ds_or_just_get_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u0fn6/should_i_finish_my_masters_in_ds_or_just_get_some/", "subreddit_subscribers": 139503, "created_utc": 1699841835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently we are using AWS DMS for CDC from PostgreSQL to s3 and in some very rare cases some updates are just silently not getting delivered. Had a long back-and-forth with AWS support, but they couldn't tell how to fully avoid it.\n\nConsidering switching to Debezium because of it - some use cases of ours can't tolerate missing even a single change.\n\nI'm wondering if there are edge cases in which Debezium can loose updates coming from PostgreSQL DB (without raising an error indicating it)? Would be extremely dumb to migrate to it and then end up with the same problem.\n\nI understand that by design Debezium should guarantee at least once delivery, and I've even seen an article describing exactly once with it, but maybe there can be some unfortunate combinations of failures I can't think of now that lead to breaking of such guarantees?", "author_fullname": "t2_mv7wziv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Debezium loose updates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ttw5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699823528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we are using AWS DMS for CDC from PostgreSQL to s3 and in some very rare cases some updates are just silently not getting delivered. Had a long back-and-forth with AWS support, but they couldn&amp;#39;t tell how to fully avoid it.&lt;/p&gt;\n\n&lt;p&gt;Considering switching to Debezium because of it - some use cases of ours can&amp;#39;t tolerate missing even a single change.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if there are edge cases in which Debezium can loose updates coming from PostgreSQL DB (without raising an error indicating it)? Would be extremely dumb to migrate to it and then end up with the same problem.&lt;/p&gt;\n\n&lt;p&gt;I understand that by design Debezium should guarantee at least once delivery, and I&amp;#39;ve even seen an article describing exactly once with it, but maybe there can be some unfortunate combinations of failures I can&amp;#39;t think of now that lead to breaking of such guarantees?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ttw5e", "is_robot_indexable": true, "report_reasons": null, "author": "quadraaa", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ttw5e/can_debezium_loose_updates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ttw5e/can_debezium_loose_updates/", "subreddit_subscribers": 139503, "created_utc": 1699823528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been in my role as a junior engineer for over a year now. It's dawned on me that coding/programming is not for me. But I'm stuck. I still want to be in tech, but not sure which areas I can go into. Project management type roles seem interesting, but I have no idea where to begin.\n\nWhich careers/roles, do you advise and how would navigate myself to get a job in that role? Thank you all!", "author_fullname": "t2_gf4hocwmk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering is not for me. Please advise!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17udkju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699890644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been in my role as a junior engineer for over a year now. It&amp;#39;s dawned on me that coding/programming is not for me. But I&amp;#39;m stuck. I still want to be in tech, but not sure which areas I can go into. Project management type roles seem interesting, but I have no idea where to begin.&lt;/p&gt;\n\n&lt;p&gt;Which careers/roles, do you advise and how would navigate myself to get a job in that role? Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17udkju", "is_robot_indexable": true, "report_reasons": null, "author": "akhi960", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17udkju/data_engineering_is_not_for_me_please_advise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17udkju/data_engineering_is_not_for_me_please_advise/", "subreddit_subscribers": 139503, "created_utc": 1699890644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My org is struggling to get test data that behaves the same as production data but has obfuscated PCI and PII data. What is the best way to get good quality test data for both pipelines and Data Scientist to use in their testing?  ", "author_fullname": "t2_6lh4st48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gathering or Generating Test Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ug9ms", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699897774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My org is struggling to get test data that behaves the same as production data but has obfuscated PCI and PII data. What is the best way to get good quality test data for both pipelines and Data Scientist to use in their testing?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ug9ms", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Bluebird7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ug9ms/gathering_or_generating_test_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ug9ms/gathering_or_generating_test_data/", "subreddit_subscribers": 139503, "created_utc": 1699897774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I've been thinking about a problem for a long time, and I'd like your insights. I\u2019m trying to have a standard, mathematical approach to the late arriving facts problem.\n\nHere\u2019s where I\u2019m so far.\n\nSay you have a fact table, with a unique\\_key, some dimensions (date or else) and some metrics (numbers, you'll average or sum). We snapshot that table at date 1 and at date 2. We suppose there is no schema update. And we ignore the collection of new data between date 1 and date 2.\n\nThis data is non moving. It\u2019s our orders, our billings, our rides, our bookings, etc.\n\nIn a perfect world, snapshot1 and snapshot2 are equal. In our case they are not equal.\n\n# Technical approach vs real-world approach \n\nTechnically, the diff between snapshot1 and 2 is composed of:\n\n* Added lines\n* Deleted lines\n* Modified lines, being the sum of:\n   * Affected column name, before\\_value, after\\_value \n\nThe breakdown of this data is pretty easy to compute. But this is pretty useless, without a root cause.\n\nThe root cause, is in one of 3 category (the trichotomy):\n\n1. External to the company\n2. Internal to the company, but external to the data team\n3. Internal to the company, and internal to the data team\n\nDo you agree so far ?\n\n# Category - Response\n\nMy first assumption is that each category has this best specific response:\n\nFor *category 1* (external to the company e.g. refunded transaction, cancelled booking). This will happen consistently, you have to deal with it once and for all. Ex: there is estimated metric, and actual metric. You know how to compute \u201cthis late arriving fact\u201d impact (e.g. all cancelled bookings that happened between \u201cestimated\u201d and \u201cactual\u201d). And, normally, estimated + late arriving fact impact = actual metric. It is quite expensive.\n\nFor *category 2* (internal to the company, but outside the data team e.g. production database update, CRM updates). This is my favorite. What I have observed is, as data team member you have to prove as fast as possible that is comes from another team. And make it their problem. Because, you cannot handle it as a category 1 because it would be too expensive, and there is a new case every month so the generic case is not solvable. It\u2019s an internal process problem. I'd like to break it down into more specific problems\n\nFor *category 3* (internal to the company, inside the data team e.g. it either a bug, or a bug fix). In that case, your data consumer do not have anything to know about it, the bug and the bugfix should be as close as possible (aka fix the bug asap). And, for self improvement, you measure how many category 3 happened and how long it took to fix it.\n\nSo I'm [developing this tool](https://github.com/data-drift/data-drift) and there are these 2 challenges where I\u2019m stuck: \n\n* from the technical perspective (added, deleted, modified lines) is there a way to find the category ? I think it is possible, as code, with a user defined function that takes the added, deleted, modified lines, and decides if it is a known case of category 1, or not. But for category 2 or 3, I think it has to be a **human process**. Or maybe something about \"for that table, if there is more than 10 lines its most likely a bug category 3, other wise it is a human modification somewhere\"\n* What to do for category 2 ? We can report it and try reduce it. I don't know so I try to break the problem down to sub categories. My examples are \"bugs from software team\", \"adjusting the CRM/billing data\" . There is maybe something about, \"is it supposed to happen again ?\" and \"will we revert that change ?\", waiting for ideas :D \n\nThanks for reading ! ", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Late arriving facts: trichotomy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ufwv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699896839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I&amp;#39;ve been thinking about a problem for a long time, and I&amp;#39;d like your insights. I\u2019m trying to have a standard, mathematical approach to the late arriving facts problem.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s where I\u2019m so far.&lt;/p&gt;\n\n&lt;p&gt;Say you have a fact table, with a unique_key, some dimensions (date or else) and some metrics (numbers, you&amp;#39;ll average or sum). We snapshot that table at date 1 and at date 2. We suppose there is no schema update. And we ignore the collection of new data between date 1 and date 2.&lt;/p&gt;\n\n&lt;p&gt;This data is non moving. It\u2019s our orders, our billings, our rides, our bookings, etc.&lt;/p&gt;\n\n&lt;p&gt;In a perfect world, snapshot1 and snapshot2 are equal. In our case they are not equal.&lt;/p&gt;\n\n&lt;h1&gt;Technical approach vs real-world approach&lt;/h1&gt;\n\n&lt;p&gt;Technically, the diff between snapshot1 and 2 is composed of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Added lines&lt;/li&gt;\n&lt;li&gt;Deleted lines&lt;/li&gt;\n&lt;li&gt;Modified lines, being the sum of:\n\n&lt;ul&gt;\n&lt;li&gt;Affected column name, before_value, after_value &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The breakdown of this data is pretty easy to compute. But this is pretty useless, without a root cause.&lt;/p&gt;\n\n&lt;p&gt;The root cause, is in one of 3 category (the trichotomy):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;External to the company&lt;/li&gt;\n&lt;li&gt;Internal to the company, but external to the data team&lt;/li&gt;\n&lt;li&gt;Internal to the company, and internal to the data team&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Do you agree so far ?&lt;/p&gt;\n\n&lt;h1&gt;Category - Response&lt;/h1&gt;\n\n&lt;p&gt;My first assumption is that each category has this best specific response:&lt;/p&gt;\n\n&lt;p&gt;For &lt;em&gt;category 1&lt;/em&gt; (external to the company e.g. refunded transaction, cancelled booking). This will happen consistently, you have to deal with it once and for all. Ex: there is estimated metric, and actual metric. You know how to compute \u201cthis late arriving fact\u201d impact (e.g. all cancelled bookings that happened between \u201cestimated\u201d and \u201cactual\u201d). And, normally, estimated + late arriving fact impact = actual metric. It is quite expensive.&lt;/p&gt;\n\n&lt;p&gt;For &lt;em&gt;category 2&lt;/em&gt; (internal to the company, but outside the data team e.g. production database update, CRM updates). This is my favorite. What I have observed is, as data team member you have to prove as fast as possible that is comes from another team. And make it their problem. Because, you cannot handle it as a category 1 because it would be too expensive, and there is a new case every month so the generic case is not solvable. It\u2019s an internal process problem. I&amp;#39;d like to break it down into more specific problems&lt;/p&gt;\n\n&lt;p&gt;For &lt;em&gt;category 3&lt;/em&gt; (internal to the company, inside the data team e.g. it either a bug, or a bug fix). In that case, your data consumer do not have anything to know about it, the bug and the bugfix should be as close as possible (aka fix the bug asap). And, for self improvement, you measure how many category 3 happened and how long it took to fix it.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m &lt;a href=\"https://github.com/data-drift/data-drift\"&gt;developing this tool&lt;/a&gt; and there are these 2 challenges where I\u2019m stuck: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;from the technical perspective (added, deleted, modified lines) is there a way to find the category ? I think it is possible, as code, with a user defined function that takes the added, deleted, modified lines, and decides if it is a known case of category 1, or not. But for category 2 or 3, I think it has to be a &lt;strong&gt;human process&lt;/strong&gt;. Or maybe something about &amp;quot;for that table, if there is more than 10 lines its most likely a bug category 3, other wise it is a human modification somewhere&amp;quot;&lt;/li&gt;\n&lt;li&gt;What to do for category 2 ? We can report it and try reduce it. I don&amp;#39;t know so I try to break the problem down to sub categories. My examples are &amp;quot;bugs from software team&amp;quot;, &amp;quot;adjusting the CRM/billing data&amp;quot; . There is maybe something about, &amp;quot;is it supposed to happen again ?&amp;quot; and &amp;quot;will we revert that change ?&amp;quot;, waiting for ideas :D &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks for reading ! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?auto=webp&amp;s=f5071d66ba016d02d16d8fe542a9d3a1362d5bf7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=63aec543dc09e53536c18730de8b14feffd9616c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=77721d607863f9dcc0b35ce27084cf2b324c0495", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=10f6776ecf4e47448be36f11ff95ea973265598d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62fafe3a3592eb7c8d5c5a62769451734ab17e0d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9a7b8452647be660d7b238d31a61a5c70c538f3d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZgqAxsNyaTJF1vvgaDOQkXcup_o7LohGKlA2FWW9vOo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=73bf82c5fd0823a47c23d23ce9ced940a09a6407", "width": 1080, "height": 540}], "variants": {}, "id": "gaq4gpMffllPSr4TtkFHfZvBLuKF-ddT00PmCOIaLdo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17ufwv5", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ufwv5/late_arriving_facts_trichotomy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ufwv5/late_arriving_facts_trichotomy/", "subreddit_subscribers": 139503, "created_utc": 1699896839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lk4nwwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataCamp Black Friday Sale 50% OFF", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_17ucwbv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/T8i8CFUa7nptxBQq7xJYLh36Ug2RzEP8H89WdBqL9tk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699888806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.google.com/amp/s/onlinecoursesgalore.com/datacamp-black-friday-sale/amp/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ppmy4qvcSCSVlQgBiYhbXioRIMfepttWdKBLzRPtaV0.jpg?auto=webp&amp;s=75f6f761ea64c9400576f70b2ad299b3aef73ce5", "width": 800, "height": 445}, "resolutions": [{"url": "https://external-preview.redd.it/ppmy4qvcSCSVlQgBiYhbXioRIMfepttWdKBLzRPtaV0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f63c2de49fa78f19e877f232c10543b1be5f72a5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/ppmy4qvcSCSVlQgBiYhbXioRIMfepttWdKBLzRPtaV0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9aeac477eb602d2534eebebbffc52e76b167195", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/ppmy4qvcSCSVlQgBiYhbXioRIMfepttWdKBLzRPtaV0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=08b98c3463a7abe4c621ccf06cab2cc58cd8234a", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/ppmy4qvcSCSVlQgBiYhbXioRIMfepttWdKBLzRPtaV0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2681d47f93000ff07c192d05fd5c9cd8fbe4873", "width": 640, "height": 356}], "variants": {}, "id": "CT4bgrJlc2B-Eu0LBa6UNhPMnqnVZMp1hJ9BfFVHLGs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ucwbv", "is_robot_indexable": true, "report_reasons": null, "author": "iphone6plususer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ucwbv/datacamp_black_friday_sale_50_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.google.com/amp/s/onlinecoursesgalore.com/datacamp-black-friday-sale/amp/", "subreddit_subscribers": 139503, "created_utc": 1699888806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm aware that images like this exist:\n\n[https://hub.docker.com/r/jupyter/pyspark-notebook](https://hub.docker.com/r/jupyter/pyspark-notebook)\n\nAfter getting the image\n\n`docker pull jupyter/pyspark-notebook`\n\nWe can run it with\n\n`docker run -it --rm -p 8888:8888 jupyter/pyspark-notebook`\n\nand write/run code from the notebook.\n\nHowever, I'm completely lost as to how to run PySpark with docker (also locally) but *from an IDE* (in my case I'm using PyCharm).  Is there any guide, somewhere, that I could follow? I'm guessing that, somehow, I should be able to link an image such as this one: [https://hub.docker.com/r/apache/spark-p](https://hub.docker.com/r/apache/spark-p)", "author_fullname": "t2_nqspn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help running PySpark from a docker container with an IDE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u97lr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699877189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that images like this exist:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://hub.docker.com/r/jupyter/pyspark-notebook\"&gt;https://hub.docker.com/r/jupyter/pyspark-notebook&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;After getting the image&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;docker pull jupyter/pyspark-notebook&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;We can run it with&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;docker run -it --rm -p 8888:8888 jupyter/pyspark-notebook&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;and write/run code from the notebook.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m completely lost as to how to run PySpark with docker (also locally) but &lt;em&gt;from an IDE&lt;/em&gt; (in my case I&amp;#39;m using PyCharm).  Is there any guide, somewhere, that I could follow? I&amp;#39;m guessing that, somehow, I should be able to link an image such as this one: &lt;a href=\"https://hub.docker.com/r/apache/spark-p\"&gt;https://hub.docker.com/r/apache/spark-p&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17u97lr", "is_robot_indexable": true, "report_reasons": null, "author": "polidrupa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u97lr/help_running_pyspark_from_a_docker_container_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u97lr/help_running_pyspark_from_a_docker_container_with/", "subreddit_subscribers": 139503, "created_utc": 1699877189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Log-Structured Merge Tree implementation\n\nHey everyone,  \nI wanted to share a project I've dedicated some time to - my Java  implementation of a Log-Structured Merge Tree. The repository includes a  skip list implementation and an SSTable built entirely from scratch. The tree performs background flushing to disk and table compaction.\n\nIf you're keen to dive into the details, I've also written a Medium article about the project.  \n\\- **GitHub Repository:** [Link](https://github.com/tomfran/LSM-Tree)  \n\\- **Medium Article**: [Link](https://medium.com/@tomfran/log-structured-merge-tree-a79241c959e3)\n\nI'm open to any questions or discussions, so feel free to reach out!", "author_fullname": "t2_4cqk2hkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Log-Structured Merge Tree implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u6ce1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699864551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Log-Structured Merge Tree implementation&lt;/p&gt;\n\n&lt;p&gt;Hey everyone,&lt;br/&gt;\nI wanted to share a project I&amp;#39;ve dedicated some time to - my Java  implementation of a Log-Structured Merge Tree. The repository includes a  skip list implementation and an SSTable built entirely from scratch. The tree performs background flushing to disk and table compaction.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re keen to dive into the details, I&amp;#39;ve also written a Medium article about the project.&lt;br/&gt;\n- &lt;strong&gt;GitHub Repository:&lt;/strong&gt; &lt;a href=\"https://github.com/tomfran/LSM-Tree\"&gt;Link&lt;/a&gt;&lt;br/&gt;\n- &lt;strong&gt;Medium Article&lt;/strong&gt;: &lt;a href=\"https://medium.com/@tomfran/log-structured-merge-tree-a79241c959e3\"&gt;Link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to any questions or discussions, so feel free to reach out!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?auto=webp&amp;s=457bfd94d3eee6eea66d0eb8ca7ec82636810b32", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1d6a92eb23ee12ff135d0f5d82f3379e26feefd5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=95f166cf7b8063f91d8cdc6fb91af6d75e21ba49", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1b4f97bc27f47bba7a64e827a97843bb27719e8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1e44257cdfff76a0d5ff4ecc45fbc18c05dff27", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b42cf6e91ed88ded717818f5df49c4475685d864", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/iOrKBQq5-u_inWXACyH4qZKCXMpUu-TZgMb15lQQHQg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=960a01a88e784d505ae366102c09d3f2d81dbe3f", "width": 1080, "height": 540}], "variants": {}, "id": "a_e13vulszkGwKFJfcyBROGvWtuCZgAIeKxPu3VmdTA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17u6ce1", "is_robot_indexable": true, "report_reasons": null, "author": "fran-sch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u6ce1/logstructured_merge_tree_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u6ce1/logstructured_merge_tree_implementation/", "subreddit_subscribers": 139503, "created_utc": 1699864551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to make a sample database available for download with a link. A good example is of what I'm trying to do is captured on this website: [dvdrental SQL tarball hosted on postgresqltutorial.com](https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/),\n\nI'm using AWS, any direction would be helpful. Do i have to do something fancy with CORS?\n\nThe database I'm trying to share is 220.2 MB when zipped. Are there other ways to share this database securely? The more details, the better. ", "author_fullname": "t2_abp0y2t2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL database sharing help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u2dqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699848459.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699848059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to make a sample database available for download with a link. A good example is of what I&amp;#39;m trying to do is captured on this website: &lt;a href=\"https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/\"&gt;dvdrental SQL tarball hosted on postgresqltutorial.com&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using AWS, any direction would be helpful. Do i have to do something fancy with CORS?&lt;/p&gt;\n\n&lt;p&gt;The database I&amp;#39;m trying to share is 220.2 MB when zipped. Are there other ways to share this database securely? The more details, the better. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17u2dqq", "is_robot_indexable": true, "report_reasons": null, "author": "bad__glitch", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u2dqq/sql_database_sharing_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u2dqq/sql_database_sharing_help/", "subreddit_subscribers": 139503, "created_utc": 1699848059.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! First time posting, and looking for some help on setting up a data warehouse (open to other recommendations) for a smaller medium-sized business in hopes of unifying data from multiple sources for reporting purposes (mostly).\n\nSome background on me, graduated from university a few years ago and have been working as a data analyst at a marketing agency (analyzing data only, worked with but not was a data engineer). I recently took a new job with a financial services company.\n\nI've been tasked with creating a data warehouse that would be used to set up reporting in PowerBI as well as ad-hoc report pulls when requested by others. Here are the sources of data that I'll be ingesting from:\n\n* On-premise SQL server, database that hosts data from a customer-related platform (about 250gb)\n* Salesforce, CRM that is going through the final setup (size TBD)\n* Accounting platform (SaaS platform / size tbd)\n\nWith these sources in mind, I've reviewed the following products from Azure and AWS:\n\n* Azure flow: Data factory -&gt; blob (or adls gen 2) -&gt; synapse for larger analytic applications\n* AWS flow: S3 -&gt; glue -&gt; rds\n\nI'm missing other products that would be needed in both flows, but what would you recommend doing in terms of cost efficiency, and simplicity to create a data warehouse that hosts data from the previous day across all 3 sources?\n\n*side note:* My boss wants me to look into cdata for extracting data from sources into next step of flows? Worth the cost? allow business users to understand flow more?\n\nI've spent a lot of time reviewing the wiki and other people's questions that are similar to mine. Been lots of help but still so many questions to ask.\n\n**TLDR: what would you recommend doing in terms of cost efficiency, and simplicity to create a data warehouse that hosts data from the previous day across all 3 sources? Open to any/all reccommendations**", "author_fullname": "t2_nrlipko4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse for smaller business Qs / help?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17tv5qe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699826787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! First time posting, and looking for some help on setting up a data warehouse (open to other recommendations) for a smaller medium-sized business in hopes of unifying data from multiple sources for reporting purposes (mostly).&lt;/p&gt;\n\n&lt;p&gt;Some background on me, graduated from university a few years ago and have been working as a data analyst at a marketing agency (analyzing data only, worked with but not was a data engineer). I recently took a new job with a financial services company.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been tasked with creating a data warehouse that would be used to set up reporting in PowerBI as well as ad-hoc report pulls when requested by others. Here are the sources of data that I&amp;#39;ll be ingesting from:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;On-premise SQL server, database that hosts data from a customer-related platform (about 250gb)&lt;/li&gt;\n&lt;li&gt;Salesforce, CRM that is going through the final setup (size TBD)&lt;/li&gt;\n&lt;li&gt;Accounting platform (SaaS platform / size tbd)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;With these sources in mind, I&amp;#39;ve reviewed the following products from Azure and AWS:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Azure flow: Data factory -&amp;gt; blob (or adls gen 2) -&amp;gt; synapse for larger analytic applications&lt;/li&gt;\n&lt;li&gt;AWS flow: S3 -&amp;gt; glue -&amp;gt; rds&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m missing other products that would be needed in both flows, but what would you recommend doing in terms of cost efficiency, and simplicity to create a data warehouse that hosts data from the previous day across all 3 sources?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;side note:&lt;/em&gt; My boss wants me to look into cdata for extracting data from sources into next step of flows? Worth the cost? allow business users to understand flow more?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve spent a lot of time reviewing the wiki and other people&amp;#39;s questions that are similar to mine. Been lots of help but still so many questions to ask.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR: what would you recommend doing in terms of cost efficiency, and simplicity to create a data warehouse that hosts data from the previous day across all 3 sources? Open to any/all reccommendations&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17tv5qe", "is_robot_indexable": true, "report_reasons": null, "author": "inquisitivedataddude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17tv5qe/data_warehouse_for_smaller_business_qs_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17tv5qe/data_warehouse_for_smaller_business_qs_help/", "subreddit_subscribers": 139503, "created_utc": 1699826787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently a data analyst considering going in a data engineering direction. However, I don\u2019t quite have the experience for it yet, and I plan to get some certifications for Snowflake, AWS, and Airflow (or if you have other recs, please let me know).\n\nI don\u2019t like my current manager and have an opportunity for a data governance analyst role. Would this help me at all in the future, or should I just stick it out in my current position?", "author_fullname": "t2_46o0lefg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would a data governance role help in a data engineering career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17uje8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699905771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently a data analyst considering going in a data engineering direction. However, I don\u2019t quite have the experience for it yet, and I plan to get some certifications for Snowflake, AWS, and Airflow (or if you have other recs, please let me know).&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t like my current manager and have an opportunity for a data governance analyst role. Would this help me at all in the future, or should I just stick it out in my current position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17uje8i", "is_robot_indexable": true, "report_reasons": null, "author": "love2eatalot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uje8i/would_a_data_governance_role_help_in_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uje8i/would_a_data_governance_role_help_in_a_data/", "subreddit_subscribers": 139503, "created_utc": 1699905771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I need to EL from a REST API, which requires a startDate and endDate parameter for each call that can't be greater than a 2 week range (source SaaS platform sets the limit). How do you guys work around this? Do you connect to your table (in my case on Snowflake) and pull the max date and use that as your startDate for each execution of the code? Planning on using Dagster running python code - and I'm pretty new to python. I can input credentials - get the athorization token, and get the JSON loaded into a dataframe just fine, but as far as making this a scalable/automated pipeline I'm a bit stuck... I'm sure someone has run into this at some point lol.", "author_fullname": "t2_3ugqxzu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage/store date parameters within API integrations for incremental loads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17uimxt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699903831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I need to EL from a REST API, which requires a startDate and endDate parameter for each call that can&amp;#39;t be greater than a 2 week range (source SaaS platform sets the limit). How do you guys work around this? Do you connect to your table (in my case on Snowflake) and pull the max date and use that as your startDate for each execution of the code? Planning on using Dagster running python code - and I&amp;#39;m pretty new to python. I can input credentials - get the athorization token, and get the JSON loaded into a dataframe just fine, but as far as making this a scalable/automated pipeline I&amp;#39;m a bit stuck... I&amp;#39;m sure someone has run into this at some point lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17uimxt", "is_robot_indexable": true, "report_reasons": null, "author": "Casdom33", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uimxt/how_do_you_managestore_date_parameters_within_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uimxt/how_do_you_managestore_date_parameters_within_api/", "subreddit_subscribers": 139503, "created_utc": 1699903831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ll try to keep this concise without too much venting. Jump to TLDR at bottom if necessary.\n\nI\u2019m currently a DA excel monkey that has been teaching myself SQL and PYTHON, passing Azure Certs, and building my own DE projects in my free time all in hopes to get out of this dreaded DA function that\u2019s I\u2019ve been stuck in for the last 4 years.\n\nI\u2019d argue I\u2019m above decent at SQL, basic in Python, really good in excel,  passed the DP-203 and DP-900, built an end-to-end ETL pipeline using azure (ADF -&gt; Databricks -&gt; Synapse -&gt; BI) currently working on CI/CD project using AzureDevOps, Databricks, Azure, GitHub. \n\nAll of this learning started July of this year and I  have not slowed down one bit. So I guess my question is do I have enough to try and make a jump into DE? I plan to finish this CI/CD project but I absolutely can\u2019t see myself working as a freaking data analyst anymore, I can confidently say I hate this type of function: endless pointless meetings, endless excel tools that never freaking work, unrealistic expectations from managers (dropping a request on you that they need back in an hour wtf), so much dirty in useable data I don\u2019t know how this company gets anything done ect.\n\nI\u2019m not saying that DE won\u2019t have its issues, but I believe me being this interested in DE work is enough for me to get passed any BS that would come alone. I haven\u2019t studied this hard, going over content/certs/taking test since college 10 years ago.\n\nThanks for reading. \n\nTLDR: it\u2019s been 6 months, Do I have enough under my belt to realistically jump from DA to DE? \n\nCurrent Industry: Govt/Defense Contractor\nCurrent Salary: 85k\nCurrent position: Data Analyst (Excel Monkey)", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ready to jump ship (Into DE)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17uhp3y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699901445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll try to keep this concise without too much venting. Jump to TLDR at bottom if necessary.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a DA excel monkey that has been teaching myself SQL and PYTHON, passing Azure Certs, and building my own DE projects in my free time all in hopes to get out of this dreaded DA function that\u2019s I\u2019ve been stuck in for the last 4 years.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d argue I\u2019m above decent at SQL, basic in Python, really good in excel,  passed the DP-203 and DP-900, built an end-to-end ETL pipeline using azure (ADF -&amp;gt; Databricks -&amp;gt; Synapse -&amp;gt; BI) currently working on CI/CD project using AzureDevOps, Databricks, Azure, GitHub. &lt;/p&gt;\n\n&lt;p&gt;All of this learning started July of this year and I  have not slowed down one bit. So I guess my question is do I have enough to try and make a jump into DE? I plan to finish this CI/CD project but I absolutely can\u2019t see myself working as a freaking data analyst anymore, I can confidently say I hate this type of function: endless pointless meetings, endless excel tools that never freaking work, unrealistic expectations from managers (dropping a request on you that they need back in an hour wtf), so much dirty in useable data I don\u2019t know how this company gets anything done ect.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not saying that DE won\u2019t have its issues, but I believe me being this interested in DE work is enough for me to get passed any BS that would come alone. I haven\u2019t studied this hard, going over content/certs/taking test since college 10 years ago.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading. &lt;/p&gt;\n\n&lt;p&gt;TLDR: it\u2019s been 6 months, Do I have enough under my belt to realistically jump from DA to DE? &lt;/p&gt;\n\n&lt;p&gt;Current Industry: Govt/Defense Contractor\nCurrent Salary: 85k\nCurrent position: Data Analyst (Excel Monkey)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17uhp3y", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uhp3y/ready_to_jump_ship_into_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uhp3y/ready_to_jump_ship_into_de/", "subreddit_subscribers": 139503, "created_utc": 1699901445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm in search of an API that can efficiently extract tables from PDFs, including style details like font and color. While I've used Azure Form Recognizer, I'm facing some accuracy issues.\n\nDoes anyone have suggestions for an API that is particularly good at both data extraction and style retention?\n\nAppreciate your insights!", "author_fullname": "t2_ncbwzerb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PDF Table Extraction APIs with Style Preservation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ub6vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699883870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in search of an API that can efficiently extract tables from PDFs, including style details like font and color. While I&amp;#39;ve used Azure Form Recognizer, I&amp;#39;m facing some accuracy issues.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have suggestions for an API that is particularly good at both data extraction and style retention?&lt;/p&gt;\n\n&lt;p&gt;Appreciate your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ub6vq", "is_robot_indexable": true, "report_reasons": null, "author": "PlatypusPrudent3076", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ub6vq/pdf_table_extraction_apis_with_style_preservation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ub6vq/pdf_table_extraction_apis_with_style_preservation/", "subreddit_subscribers": 139503, "created_utc": 1699883870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: I want to use airflow to post jobs in rabbitmq for a python environment to pick up and run.\n\nHey y'all I work at a teeny tiny company without any dedicated data engineers, so I really have close to zero knowledge of what a standard pipeline looks like. I'm just a junior-ish software dev who is somehow the most qualified person to manage this stuff. So I'm providing a ton of context in case anybody has ANY feedback on ANY of this lol.\n\nWe have a pretty basic pipeline that pulls in data from a few sources, normalizes it, and then inserts it into our database. The code is basic, but the quantity is large enough that things are getting difficult. \n\nWe used to have a few scripts that just ran on crons. We had aa handful of scripts that we would run for each client, some of them taking up to 40 minutes! It started to get unwieldy: trying to track how many scripts were running at a given time, prioritizing certain clients/scripts, making sure we didn't overload the server (the whole operation is running on one beefy VPS).\n\nSo, we got a recommendation to move the heavy lifting to airflow. We went with google cloud composer, because apparently managing airflow yourself can suck. I don't love airflow, but I guess it works well enough. It helps with the scheduling and prioritizing, but we're once again bumping up against our usage limit. Instead of being constrained by memory on a VPS, cloud composer has a limited number of concurrent jobs you can run. And they are NOT cheap!\n\nI've been doing some reading, and apparently airflow is better for orchestration of tasks than execution of tasks directly. We're running all of our data pulling and normalization directly in airflow DAGs with python. \n\nI've seen recommendations of python + celery + rabbtimq for async long-running jobs, and now I'm tempted to switch to that. Does it make any sense to use airflow for scheduling if all it's going to do is post rabbitmq jobs?", "author_fullname": "t2_8k5ls63w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would it be weird to use airflow AND a message broker like rabbitmq?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uayeu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699883123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: I want to use airflow to post jobs in rabbitmq for a python environment to pick up and run.&lt;/p&gt;\n\n&lt;p&gt;Hey y&amp;#39;all I work at a teeny tiny company without any dedicated data engineers, so I really have close to zero knowledge of what a standard pipeline looks like. I&amp;#39;m just a junior-ish software dev who is somehow the most qualified person to manage this stuff. So I&amp;#39;m providing a ton of context in case anybody has ANY feedback on ANY of this lol.&lt;/p&gt;\n\n&lt;p&gt;We have a pretty basic pipeline that pulls in data from a few sources, normalizes it, and then inserts it into our database. The code is basic, but the quantity is large enough that things are getting difficult. &lt;/p&gt;\n\n&lt;p&gt;We used to have a few scripts that just ran on crons. We had aa handful of scripts that we would run for each client, some of them taking up to 40 minutes! It started to get unwieldy: trying to track how many scripts were running at a given time, prioritizing certain clients/scripts, making sure we didn&amp;#39;t overload the server (the whole operation is running on one beefy VPS).&lt;/p&gt;\n\n&lt;p&gt;So, we got a recommendation to move the heavy lifting to airflow. We went with google cloud composer, because apparently managing airflow yourself can suck. I don&amp;#39;t love airflow, but I guess it works well enough. It helps with the scheduling and prioritizing, but we&amp;#39;re once again bumping up against our usage limit. Instead of being constrained by memory on a VPS, cloud composer has a limited number of concurrent jobs you can run. And they are NOT cheap!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been doing some reading, and apparently airflow is better for orchestration of tasks than execution of tasks directly. We&amp;#39;re running all of our data pulling and normalization directly in airflow DAGs with python. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen recommendations of python + celery + rabbtimq for async long-running jobs, and now I&amp;#39;m tempted to switch to that. Does it make any sense to use airflow for scheduling if all it&amp;#39;s going to do is post rabbitmq jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17uayeu", "is_robot_indexable": true, "report_reasons": null, "author": "chamomile-crumbs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17uayeu/would_it_be_weird_to_use_airflow_and_a_message/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17uayeu/would_it_be_weird_to_use_airflow_and_a_message/", "subreddit_subscribers": 139503, "created_utc": 1699883123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6y0b4txf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Epsio's Diff in the Streaming Landscape", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17u9lwe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/A0inDn2raTgxJiJfkThlVaW0NsOvc3GBVEesydz7LQ8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699878644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "epsio.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.epsio.io/blog/epsios-diff-in-the-streaming-landscape", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?auto=webp&amp;s=84fcf1023d3e51a80ce9f64a66cf708e81ba2062", "width": 3601, "height": 1882}, "resolutions": [{"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11439bae647f340ed0e2d99cdbff4753c9c844e5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=146460672e058257974b1ce3964205c53c72160b", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=098aab610ac60cc7e31272006bb6713e379eeddb", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8881275e3140901452589cc54036d2f8b8ce950", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8d5b08ce0050aa5891cda38a7e9ea20199c755d9", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/Kks7FhVsdV_NNcHIydfXmKPRDcDLNZpCzOrSbsF3a1k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cd45d1f859abc146d7444c5071efdde81e18f6fc", "width": 1080, "height": 564}], "variants": {}, "id": "rdMzXwi9Lwr9oaQScYGaue8Xsrg6npq89RCo6pYwjjw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17u9lwe", "is_robot_indexable": true, "report_reasons": null, "author": "Giladkl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u9lwe/epsios_diff_in_the_streaming_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.epsio.io/blog/epsios-diff-in-the-streaming-landscape", "subreddit_subscribers": 139503, "created_utc": 1699878644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have new capabilities of lakehouse formats like Delta and Iceberg, or any new streaming ingestion capabilities in data warehouses, reduced this time? \n\nIt used to be ok for reporting queries in DWHs and DLs to be run against data that was around 18h - 24h behind live data but this seems to be changing? Is getting closer to live data access (say 1hr -&gt; 10mins -&gt; or less??) a requirement that is here to stay, or just a passing fad? \n\n&amp;#x200B;", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is ETL job execution time (e.g. in Spark, or in your DWH) one of the biggest factors when it comes to being able to query the latest data? Which other factors play a major role and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u918f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699876534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have new capabilities of lakehouse formats like Delta and Iceberg, or any new streaming ingestion capabilities in data warehouses, reduced this time? &lt;/p&gt;\n\n&lt;p&gt;It used to be ok for reporting queries in DWHs and DLs to be run against data that was around 18h - 24h behind live data but this seems to be changing? Is getting closer to live data access (say 1hr -&amp;gt; 10mins -&amp;gt; or less??) a requirement that is here to stay, or just a passing fad? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17u918f", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u918f/is_etl_job_execution_time_eg_in_spark_or_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u918f/is_etl_job_execution_time_eg_in_spark_or_in_your/", "subreddit_subscribers": 139503, "created_utc": 1699876534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\ni\u2019m relatively new to this, and wondering if anyone with experience in consulting would be able to weigh in here. \n\nThe use case is building a green field data warehouse for reporting and building dashboards, so basically it will be for the BI. \n\nStack: \nGCP, BigQuery, DBT, DbVisualizer \n\nfor EL; Not quite sure I should go with Talend or Meltano \ud83d\ude13\nAlso, I\u2019ve been searching a lot lately and I came across Dagster.. will it be useful here? what is the use-cases? \n\nThank you in advance \ud83d\ude4f", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u6us0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699866905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;i\u2019m relatively new to this, and wondering if anyone with experience in consulting would be able to weigh in here. &lt;/p&gt;\n\n&lt;p&gt;The use case is building a green field data warehouse for reporting and building dashboards, so basically it will be for the BI. &lt;/p&gt;\n\n&lt;p&gt;Stack: \nGCP, BigQuery, DBT, DbVisualizer &lt;/p&gt;\n\n&lt;p&gt;for EL; Not quite sure I should go with Talend or Meltano \ud83d\ude13\nAlso, I\u2019ve been searching a lot lately and I came across Dagster.. will it be useful here? what is the use-cases? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17u6us0", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u6us0/data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u6us0/data_stack/", "subreddit_subscribers": 139503, "created_utc": 1699866905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/17u4596)", "author_fullname": "t2_eajtr4nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do your users accept as a \"fast dashboard\"? Is the expectation of \"fast\" changing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u4596", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699854720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/17u4596\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17u4596", "is_robot_indexable": true, "report_reasons": null, "author": "alneuman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1700113920098, "options": [{"text": "&lt; 3 seconds, no pressure to make this faster", "id": "25675334"}, {"text": "&lt; 3 seconds, definite pressure to make this faster", "id": "25675335"}, {"text": "3 - 6 seconds, no pressure to make this faster", "id": "25675336"}, {"text": "3 - 6 seconds, definite pressure to make this faster", "id": "25675337"}, {"text": "&gt; 6 seconds, no pressure to make this faster", "id": "25675338"}, {"text": "&gt; 6 seconds, definite pressure to make this faster", "id": "25675339"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 97, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u4596/what_do_your_users_accept_as_a_fast_dashboard_is/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/17u4596/what_do_your_users_accept_as_a_fast_dashboard_is/", "subreddit_subscribers": 139503, "created_utc": 1699854720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nOld hand at engineering, but very new to Power platform + AI builder etc. \n\nHow are folk's feelings on use of AI builder/AI Copilot for production level use? personally, I am concerned that these tools are great for basic use, but doesnt give us access to under the hood for any level of optimization.\n\nAI builder does allow me to re-train models. However, I worry about the cost of doing so, spcilly given that I can do the same on a freely available AI model, and no have to pay the premium to 'click on a few buttons'", "author_fullname": "t2_86i2wuip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI builder/power platform/AI copilot for production use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u061j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699841035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Old hand at engineering, but very new to Power platform + AI builder etc. &lt;/p&gt;\n\n&lt;p&gt;How are folk&amp;#39;s feelings on use of AI builder/AI Copilot for production level use? personally, I am concerned that these tools are great for basic use, but doesnt give us access to under the hood for any level of optimization.&lt;/p&gt;\n\n&lt;p&gt;AI builder does allow me to re-train models. However, I worry about the cost of doing so, spcilly given that I can do the same on a freely available AI model, and no have to pay the premium to &amp;#39;click on a few buttons&amp;#39;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17u061j", "is_robot_indexable": true, "report_reasons": null, "author": "Available-Entry-1264", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u061j/ai_builderpower_platformai_copilot_for_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u061j/ai_builderpower_platformai_copilot_for_production/", "subreddit_subscribers": 139503, "created_utc": 1699841035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys. So I recently changed my job. Preciously I was in a startup where I was pretty much on the bench doing POCs, doing certifications and no actual production environment exposure. This was because the firm had no business and were actually pitching to clients, it's whole another story but more or less, it was less of a job and more like an extended year of college.\n\nI am decent at the tech and can adapt quickly and my new company and the seniors seem to be good (touchwood), so I am able to cope up more or less, but the impostor syndrome has worsened since I know that I didn't work on a live project.\n\nI know Pyspark, SQL, fairly comfortable with the azure stack but I need help seeing the bigger picture on how actually organizations use data engineering.\n\nThere's a lot of work to be done. Theory and practical both.\n\nI like this field, but I feel I am a chess piece forced to play both the piece and be mindful of the bigger strategy. I see my colleagues looking at a simple table and they have doubts I feel like I should've had in the first place. Also, should I be using genAI to solve my problems at this stage?\n\nWhat should I do to approach this methodically? I have access to the learning resources, but how should I approach these sources? Like I know Pyspark, I have worked on databricks and can visualize solutions but I feel sometimes impaired on building these solutions, find the most optimal path, ask the right questions etc.\n\nPlease consider me as a absolute idiot as I am and kindly help me, I want to get better at this work.\n\nThanks!", "author_fullname": "t2_9d4i4lxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u5wru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699862536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. So I recently changed my job. Preciously I was in a startup where I was pretty much on the bench doing POCs, doing certifications and no actual production environment exposure. This was because the firm had no business and were actually pitching to clients, it&amp;#39;s whole another story but more or less, it was less of a job and more like an extended year of college.&lt;/p&gt;\n\n&lt;p&gt;I am decent at the tech and can adapt quickly and my new company and the seniors seem to be good (touchwood), so I am able to cope up more or less, but the impostor syndrome has worsened since I know that I didn&amp;#39;t work on a live project.&lt;/p&gt;\n\n&lt;p&gt;I know Pyspark, SQL, fairly comfortable with the azure stack but I need help seeing the bigger picture on how actually organizations use data engineering.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of work to be done. Theory and practical both.&lt;/p&gt;\n\n&lt;p&gt;I like this field, but I feel I am a chess piece forced to play both the piece and be mindful of the bigger strategy. I see my colleagues looking at a simple table and they have doubts I feel like I should&amp;#39;ve had in the first place. Also, should I be using genAI to solve my problems at this stage?&lt;/p&gt;\n\n&lt;p&gt;What should I do to approach this methodically? I have access to the learning resources, but how should I approach these sources? Like I know Pyspark, I have worked on databricks and can visualize solutions but I feel sometimes impaired on building these solutions, find the most optimal path, ask the right questions etc.&lt;/p&gt;\n\n&lt;p&gt;Please consider me as a absolute idiot as I am and kindly help me, I want to get better at this work.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17u5wru", "is_robot_indexable": true, "report_reasons": null, "author": "New_Introduction_154", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17u5wru/need_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17u5wru/need_guidance/", "subreddit_subscribers": 139503, "created_utc": 1699862536.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}