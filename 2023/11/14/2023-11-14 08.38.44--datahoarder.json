{"kind": "Listing", "data": {"after": "t3_17u8s4s", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7k499ptf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost Doctor Who episodes found \u2013 but owner is reluctant to hand them to BBC", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u8v5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 389, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 389, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1699875837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "archive.md", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://archive.md/A20Q1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Collector", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u8v5q", "is_robot_indexable": true, "report_reasons": null, "author": "NXGZ", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17u8v5q/lost_doctor_who_episodes_found_but_owner_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://archive.md/A20Q1", "subreddit_subscribers": 711985, "created_utc": 1699875837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_u4kys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The 7 orders of HDD magnitude. 1980 - present.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 115, "top_awarded_type": null, "hide_score": false, "name": "t3_17u8c5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 161, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Graph", "can_mod_post": false, "score": 161, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/aLKgjbl6Cbvm_54C8noPCArQ6mekuequSauZuEupD28.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699873636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/t83h7tzrk30c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/t83h7tzrk30c1.png?auto=webp&amp;s=3149969af82db5cb0f52faf6c979687cb2cef793", "width": 1416, "height": 1168}, "resolutions": [{"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d4c80100a131446e113d8172bba6d6ade0a5eb00", "width": 108, "height": 89}, {"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8f5d34f025cb3108faad4c74885eb7e7f9ac05d", "width": 216, "height": 178}, {"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=588a94a447f3dc6840d7963c0fbedf89353fe9d0", "width": 320, "height": 263}, {"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4337c149d2bbf2a6d744625da644f53dec62c76c", "width": 640, "height": 527}, {"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e20de9dfaca1002580f70ce7b3ac0235a016b561", "width": 960, "height": 791}, {"url": "https://preview.redd.it/t83h7tzrk30c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3337ba58749a215edc45791c7571538125c3a6bb", "width": 1080, "height": 890}], "variants": {}, "id": "oehn194sTXfOYtOkFdgi4jpP6JPTpc4CmDSW0rmXidE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17u8c5q", "is_robot_indexable": true, "report_reasons": null, "author": "CokeZoro", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u8c5q/the_7_orders_of_hdd_magnitude_1980_present/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/t83h7tzrk30c1.png", "subreddit_subscribers": 711985, "created_utc": 1699873636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\n\nGoing through my childhood as I clean out my moms home. Any recommendations for digitizing these? I\u2019ve checked legacybox but they charge per reel. These are short reels so would end up costing a fortune. Would it be worth somehow transferring to one larger reel which would count as one reel therefore much cheaper. If so, how would I do this? Or is there a company that would charge by foot instead? Amy advice appreciated.", "author_fullname": "t2_a1jzufal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing old film", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17ujwok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nGcwE6xzLv38jfKAl2z2vEzjVjcKsTxy-NfaD2evWfE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699907088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Going through my childhood as I clean out my moms home. Any recommendations for digitizing these? I\u2019ve checked legacybox but they charge per reel. These are short reels so would end up costing a fortune. Would it be worth somehow transferring to one larger reel which would count as one reel therefore much cheaper. If so, how would I do this? Or is there a company that would charge by foot instead? Amy advice appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/56n8mqzic60c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?auto=webp&amp;s=b9a4b2998088eb29583c63f92ece5a43ee548f96", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee7af47eae0f747ddd13cd899083a2131ddc1172", "width": 108, "height": 81}, {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a7fe9ef7bfd8abdb39098f0c2f03bf302ab3710", "width": 216, "height": 162}, {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4cb81eaa3663d6a53b0a0d669d2662e3db028caf", "width": 320, "height": 240}, {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=303f2de1f34786244885629ea835f34f4765b2ce", "width": 640, "height": 480}, {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a96d455b340a32c198b504f28b256b9db57ba654", "width": 960, "height": 720}, {"url": "https://preview.redd.it/56n8mqzic60c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c1f2a039753d8023ead66315d302460df7d68484", "width": 1080, "height": 810}], "variants": {}, "id": "7tbW5QQSJWz1xr4dThI6W92x8WcYBIiPRIsuPHYvQfQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ujwok", "is_robot_indexable": true, "report_reasons": null, "author": "Spare-Paper6981", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ujwok/digitizing_old_film/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/56n8mqzic60c1.jpg", "subreddit_subscribers": 711985, "created_utc": 1699907088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey. \nI have a problem - i bought a very big lot of drives from which some behaved quite funky but camcontrol or setblocksize worked on all of them but these weird Oracle Sun ones. \n\nWhen plugged in they spin up just fine, no weird sounds and they do get detected as a drive - but they don't have any usable space. \nThe drives are not reporting their capacity to the systems and tools like setblocksize or camcontrol can't format them. Besides that i cannot interact with them at all with dd or tools that try to write data to them they get detected just fine. \nSomeone said there's a custom firmware running on them which blocks them from being used in another systems. \nI do only the hardware side of things (building NAS Systems, building Gaming PCs and so on) but i don't have any clues on how to figure out how to make these drives usable. Could anybody help me? I will attach a picture of one of the drives. They all behave exactly the same. Also they worked fine in the oracle system they were before.", "author_fullname": "t2_exy1qrur", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hundreds of 4 TB HGST SAS Sun Oracle branded - cannot be used.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17uobb1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kPIXkFhBXzBUPj7QulC1Sb5Dc4XR8ewGsYJ4Y8m0lSo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699918217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey. \nI have a problem - i bought a very big lot of drives from which some behaved quite funky but camcontrol or setblocksize worked on all of them but these weird Oracle Sun ones. &lt;/p&gt;\n\n&lt;p&gt;When plugged in they spin up just fine, no weird sounds and they do get detected as a drive - but they don&amp;#39;t have any usable space. \nThe drives are not reporting their capacity to the systems and tools like setblocksize or camcontrol can&amp;#39;t format them. Besides that i cannot interact with them at all with dd or tools that try to write data to them they get detected just fine. \nSomeone said there&amp;#39;s a custom firmware running on them which blocks them from being used in another systems. \nI do only the hardware side of things (building NAS Systems, building Gaming PCs and so on) but i don&amp;#39;t have any clues on how to figure out how to make these drives usable. Could anybody help me? I will attach a picture of one of the drives. They all behave exactly the same. Also they worked fine in the oracle system they were before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/72g6caam970c1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/72g6caam970c1.jpg?auto=webp&amp;s=d46abd01d6e5a3e465ca09f14a72b221cf66cd58", "width": 3072, "height": 4096}, "resolutions": [{"url": "https://preview.redd.it/72g6caam970c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f6e25fba4953dc2611b44fc80627d3f4a583aa86", "width": 108, "height": 144}, {"url": "https://preview.redd.it/72g6caam970c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0bcf945e40265d70e1f9fda8d165a8c2ed8a5497", "width": 216, "height": 288}, {"url": "https://preview.redd.it/72g6caam970c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=18cadefa8a4cfd9501a6a8bad6a241875ac515d3", "width": 320, "height": 426}, {"url": "https://preview.redd.it/72g6caam970c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=936457921980d02d9f660e7407a60e025529f892", "width": 640, "height": 853}, {"url": "https://preview.redd.it/72g6caam970c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=879e539c8cec0fe17a628858cfe1627d11b25c5a", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/72g6caam970c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7cd051bd5c6c72fd6a0d5b1397cff46768073933", "width": 1080, "height": 1440}], "variants": {}, "id": "gx0Ed0vyDlwczubpyeZGOs0Rq5KE2v0ZdM1AbaoYSwQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uobb1", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Steak_689", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uobb1/hundreds_of_4_tb_hgst_sas_sun_oracle_branded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/72g6caam970c1.jpg", "subreddit_subscribers": 711985, "created_utc": 1699918217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I am a hoarder who loves to download nearly any content I see or consume (Im not so picky, whether that be pornography, cute animals, cool scenery, random drawings, if its cool, it is mine), and a problem i ran into is organizing it. I have my D drive full of random stuff, ranging from pictures of literal rocks to a 1 hour youtube video. And two problems I face is...\n\n1. I cannot help but download any content I see, but it takes so much time and effort most of the time - i need a way to automate it then sort it out later\n2. 4TB isn't cutting for my needs and I saw my disk usage explode within the first few months of hoarding, and I cannot use my phone to check those files out\n\n&amp;#x200B;\n\nAny tips on these would be great, and any general tips I might have missed out on is would be also nice. In fact, random tips such as how to make a great plate of soup would be nice and I can guarantee that it will go straight into my data hoarder brain.", "author_fullname": "t2_89h4xh8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A beginner datahoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u85wp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699872952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am a hoarder who loves to download nearly any content I see or consume (Im not so picky, whether that be pornography, cute animals, cool scenery, random drawings, if its cool, it is mine), and a problem i ran into is organizing it. I have my D drive full of random stuff, ranging from pictures of literal rocks to a 1 hour youtube video. And two problems I face is...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I cannot help but download any content I see, but it takes so much time and effort most of the time - i need a way to automate it then sort it out later&lt;/li&gt;\n&lt;li&gt;4TB isn&amp;#39;t cutting for my needs and I saw my disk usage explode within the first few months of hoarding, and I cannot use my phone to check those files out&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any tips on these would be great, and any general tips I might have missed out on is would be also nice. In fact, random tips such as how to make a great plate of soup would be nice and I can guarantee that it will go straight into my data hoarder brain.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u85wp", "is_robot_indexable": true, "report_reasons": null, "author": "AbcMc12", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u85wp/a_beginner_datahoarder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u85wp/a_beginner_datahoarder/", "subreddit_subscribers": 711985, "created_utc": 1699872952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello \ud83d\udc4b\n\nI'm feeling overwhelmed by the amount of work I created for my-self, my files are a mess.\n\n* How much time you spend just sorting and cleaning all you images?\n* Do you have the same folder structure for all you storage locations? (hard drives, cloud,...)\n* How many files do you have?", "author_fullname": "t2_22z2x4oh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you organise 18,500 images on a hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u68af", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699864034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m feeling overwhelmed by the amount of work I created for my-self, my files are a mess.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How much time you spend just sorting and cleaning all you images?&lt;/li&gt;\n&lt;li&gt;Do you have the same folder structure for all you storage locations? (hard drives, cloud,...)&lt;/li&gt;\n&lt;li&gt;How many files do you have?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u68af", "is_robot_indexable": true, "report_reasons": null, "author": "antoine849502", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u68af/how_do_you_organise_18500_images_on_a_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u68af/how_do_you_organise_18500_images_on_a_hard_drive/", "subreddit_subscribers": 711985, "created_utc": 1699864034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for a thunderbolt solution to LTO-8 drive. Also down to do a DIY solution if it's cheaper.\n\nThe plan is to hook it up to my M1 Ultra Mac studio to backup my Synology NAS to tape to keep offsite. Maybe put tapes in a a couple layers of vacuum sealer bags if that's a safe thing to do. Is a dark closet a safe place to store tapes if they're vacuum sealed?\n\nI'm going into this blind so ofc please correct me anywhere where i'm wrong, I'd love to learn the right way to archive to tape.", "author_fullname": "t2_82jx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone who has access to a mLogic mTape or an OWC Mercury Pro: how loud are the drives when they're reading and writing? And how is YoYotta vs Hedge Canister for software?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uqqxh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699925223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a thunderbolt solution to LTO-8 drive. Also down to do a DIY solution if it&amp;#39;s cheaper.&lt;/p&gt;\n\n&lt;p&gt;The plan is to hook it up to my M1 Ultra Mac studio to backup my Synology NAS to tape to keep offsite. Maybe put tapes in a a couple layers of vacuum sealer bags if that&amp;#39;s a safe thing to do. Is a dark closet a safe place to store tapes if they&amp;#39;re vacuum sealed?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going into this blind so ofc please correct me anywhere where i&amp;#39;m wrong, I&amp;#39;d love to learn the right way to archive to tape.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uqqxh", "is_robot_indexable": true, "report_reasons": null, "author": "Endawmyke", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uqqxh/anyone_who_has_access_to_a_mlogic_mtape_or_an_owc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uqqxh/anyone_who_has_access_to_a_mlogic_mtape_or_an_owc/", "subreddit_subscribers": 711985, "created_utc": 1699925223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1oj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fediverser is a web application that can download reddit content (posts and submissions) and mirror to Lemmy communities.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17unzvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FHIInF5g_QE_Q2ZguTzP1AadtOCC3qk7ztJ9HH1DjRg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699917350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/mushroomlabs/fediverser", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?auto=webp&amp;s=56a5098767eb33a4e69818cde042723aaa1fc237", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc9edb911ac3a6acda2f043cf0449898e3756b10", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04c7aedba951a52a2730ede6d9ee9216ad227ea3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f4d98b332449932852caee9e6fd19614c33a8459", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cacc74d3d71f78e380b80ab454ee3ef295b2fdf7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=917eda2881758f51e2fff06510dccc093e2f6a68", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/KALoDoqDXwSGgF7lRF5YPeKTQFoIg-glgKlN343_mw4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a51e42ff87b6042f47d3a4a3e8a3fe74d219350e", "width": 1080, "height": 540}], "variants": {}, "id": "etZtFw_Zt6pH2v2QIvWo_EaFSYiUKHoKZURjLFXQjck"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17unzvi", "is_robot_indexable": true, "report_reasons": null, "author": "rglullis", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17unzvi/fediverser_is_a_web_application_that_can_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/mushroomlabs/fediverser", "subreddit_subscribers": 711985, "created_utc": 1699917350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "im  very new to ripping dvds and i want to know if there's anything i can do to improve the quality of my rips for my collection; when i was watching one of my dvds in my ps4 i noticed that the video quality was significantly better than my own rips; i followed the dvd decrypt \\[iso\\] to makemkv\n\ni hope this is the right subreddit lol\n\n&amp;#x200B;\n\n[dvdplayer on top](https://preview.redd.it/2qfer534y60c1.png?width=554&amp;format=png&amp;auto=webp&amp;s=c7f14ec926f917f8d4c5efd28fccbac357586a7a)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_t036dps3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "quality loss on ripped dvd collection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 119, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2qfer534y60c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 92, "x": 108, "u": "https://preview.redd.it/2qfer534y60c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c330096152780b9d956494d384b3123b32eea9d2"}, {"y": 184, "x": 216, "u": "https://preview.redd.it/2qfer534y60c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d4695c25d63130bc481f1e35e179d0cecc75ab7"}, {"y": 273, "x": 320, "u": "https://preview.redd.it/2qfer534y60c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dcdedf7c206ce9001814769a1a8f7600ff94c97d"}], "s": {"y": 474, "x": 554, "u": "https://preview.redd.it/2qfer534y60c1.png?width=554&amp;format=png&amp;auto=webp&amp;s=c7f14ec926f917f8d4c5efd28fccbac357586a7a"}, "id": "2qfer534y60c1"}}, "name": "t3_17umu75", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TMoLc9anxXXfXwTwz4QhvwfryRgodXS0Yq7sW4EnI8g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699914354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;im  very new to ripping dvds and i want to know if there&amp;#39;s anything i can do to improve the quality of my rips for my collection; when i was watching one of my dvds in my ps4 i noticed that the video quality was significantly better than my own rips; i followed the dvd decrypt [iso] to makemkv&lt;/p&gt;\n\n&lt;p&gt;i hope this is the right subreddit lol&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2qfer534y60c1.png?width=554&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7f14ec926f917f8d4c5efd28fccbac357586a7a\"&gt;dvdplayer on top&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17umu75", "is_robot_indexable": true, "report_reasons": null, "author": "lackadaisical37", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17umu75/quality_loss_on_ripped_dvd_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17umu75/quality_loss_on_ripped_dvd_collection/", "subreddit_subscribers": 711985, "created_utc": 1699914354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there, I don\u2019t know much about technology or computers so I\u2019m very amateur here. I have a 4 TB WD external drive hosting about 20 Apple photos libraries with thousands of pictures. I have probably filled up about 3 TB so far. However, I don\u2019t want to fill up the drive all the way because I want to do whatever I can to prevent it from crashing. But, I keep taking more photos and screenshots and need to keep downloading them off my phone somewhere, because my iPhone can only hold about 40,000 photos at a time.\n\nSo, my concern is that I only have these photos libraries in one place\u2014I\u2019d like to follow the 2-3 copies rule\u2014and I\u2019m trying to figure out what the best storage solution going forward is.\n\nI\u2019ve considered an NAS device so I can use RAID configuration to have several copies of each drive. However, I\u2019m not sure if this is the best option using WD external drives and Apple photo libraries.\n\nCan anyone make any suggestions for me that are user-friendly and good for beginners like me? (No complicated software programs please)\n\nI think I favor physical copies rather than cloud storage because my iCloud is very very slow to load.", "author_fullname": "t2_4cndkbvc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with storage solution for my large Apple photo libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uhsl5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699901699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I don\u2019t know much about technology or computers so I\u2019m very amateur here. I have a 4 TB WD external drive hosting about 20 Apple photos libraries with thousands of pictures. I have probably filled up about 3 TB so far. However, I don\u2019t want to fill up the drive all the way because I want to do whatever I can to prevent it from crashing. But, I keep taking more photos and screenshots and need to keep downloading them off my phone somewhere, because my iPhone can only hold about 40,000 photos at a time.&lt;/p&gt;\n\n&lt;p&gt;So, my concern is that I only have these photos libraries in one place\u2014I\u2019d like to follow the 2-3 copies rule\u2014and I\u2019m trying to figure out what the best storage solution going forward is.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve considered an NAS device so I can use RAID configuration to have several copies of each drive. However, I\u2019m not sure if this is the best option using WD external drives and Apple photo libraries.&lt;/p&gt;\n\n&lt;p&gt;Can anyone make any suggestions for me that are user-friendly and good for beginners like me? (No complicated software programs please)&lt;/p&gt;\n\n&lt;p&gt;I think I favor physical copies rather than cloud storage because my iCloud is very very slow to load.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uhsl5", "is_robot_indexable": true, "report_reasons": null, "author": "roseofucf", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uhsl5/need_help_with_storage_solution_for_my_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uhsl5/need_help_with_storage_solution_for_my_large/", "subreddit_subscribers": 711985, "created_utc": 1699901699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to expand a NAS soon, already have a couple WD Red Pros that have been kind to me so I want to stick with them.\n\nWD currently has a \u201cbuy 2 20TB for $600\u201d on Red Pros and a 6 drive limit which is $80 cheaper per drive than listed (which I believe is also a discounted price from what I\u2019ve seen listed).\n\nSo real question because I haven\u2019t bought a large number of drives at once; are Black Friday deals actually worth waiting for or is this deal already good enough to match anything I\u2019d likely see next week?\n\nEdit: The deal was 10/31-11/12 so rip me. Question still stands, what can I expect for drive deals on Black Friday?", "author_fullname": "t2_c79wk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New HDD deals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uezyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699895607.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699894461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to expand a NAS soon, already have a couple WD Red Pros that have been kind to me so I want to stick with them.&lt;/p&gt;\n\n&lt;p&gt;WD currently has a \u201cbuy 2 20TB for $600\u201d on Red Pros and a 6 drive limit which is $80 cheaper per drive than listed (which I believe is also a discounted price from what I\u2019ve seen listed).&lt;/p&gt;\n\n&lt;p&gt;So real question because I haven\u2019t bought a large number of drives at once; are Black Friday deals actually worth waiting for or is this deal already good enough to match anything I\u2019d likely see next week?&lt;/p&gt;\n\n&lt;p&gt;Edit: The deal was 10/31-11/12 so rip me. Question still stands, what can I expect for drive deals on Black Friday?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uezyu", "is_robot_indexable": true, "report_reasons": null, "author": "senagorules", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uezyu/new_hdd_deals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uezyu/new_hdd_deals/", "subreddit_subscribers": 711985, "created_utc": 1699894461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I have possibly messed up...\n\nI scored a 10Tb SAS drive (Ultrastar DC HC330) and went looking for an interface card. I have ordered a  9212-4i4e, which has 4x SATA ports internal and one external  SFF-8088 SAS port. I figured future drives I add were more likely to be sata than sas but my read of the manual is that the sata ports can also take SAS drives.\n\nTrying to figure out what cables I need for SATA to SAS and got a bit lost. I then figured I could just loop the external SFF-8088 back inside the case and that looks like is really more for an external device that houses the SAS drives?\n\nHelp!\n\n&amp;#x200B;\n\nedit : link to specs\n\n[https://docs.broadcom.com/doc/12353334](https://docs.broadcom.com/doc/12353334)\n\nedit 2: I am looking to run in IT mode and the card apparently supports that.", "author_fullname": "t2_154zxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with LSI 9212-4i4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ux8u9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699948047.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699947712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have possibly messed up...&lt;/p&gt;\n\n&lt;p&gt;I scored a 10Tb SAS drive (Ultrastar DC HC330) and went looking for an interface card. I have ordered a  9212-4i4e, which has 4x SATA ports internal and one external  SFF-8088 SAS port. I figured future drives I add were more likely to be sata than sas but my read of the manual is that the sata ports can also take SAS drives.&lt;/p&gt;\n\n&lt;p&gt;Trying to figure out what cables I need for SATA to SAS and got a bit lost. I then figured I could just loop the external SFF-8088 back inside the case and that looks like is really more for an external device that houses the SAS drives?&lt;/p&gt;\n\n&lt;p&gt;Help!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit : link to specs&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.broadcom.com/doc/12353334\"&gt;https://docs.broadcom.com/doc/12353334&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit 2: I am looking to run in IT mode and the card apparently supports that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ux8u9", "is_robot_indexable": true, "report_reasons": null, "author": "jcatemysandwich", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ux8u9/help_with_lsi_92124i4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ux8u9/help_with_lsi_92124i4/", "subreddit_subscribers": 711985, "created_utc": 1699947712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was recently trying to download Lockpick_RCM when I found out that Nintendo filed a DMCA notice against them and the repo was taken down. This got me thinking about how I might be able to build a system that automatically and periodically clones/pulls repos. On the surface, this seems like something that would be super straight forward with a crappy script and a systemd service, but I have one thought that adds complexity. In theory, it would be possible for the maintainers of the repo to rebase and squash all commits back to some point in time. I would like to make sure that I don't lose commits that have been squashed on the main branch, while also not losing the ability to continue updating.\n\nAs I'm writing this, I realized that one solution could be to have some logic in the script that catches when a pull fails due to a history conflict, move the current working directory off to a timestamped directory, and then clone a new copy.\n\nI have thought about the workflow of hosting Gitea and setting up mirrors there. It sounds like a good idea, but squashed repo's, etc would get clobbered.\n\nHave any of set up anything to create historical (vs functional) archives of Git repo's you don't want to lose?", "author_fullname": "t2_b38kv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a system in place for creating historical archives of Git Repo's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17umxwn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699914625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was recently trying to download Lockpick_RCM when I found out that Nintendo filed a DMCA notice against them and the repo was taken down. This got me thinking about how I might be able to build a system that automatically and periodically clones/pulls repos. On the surface, this seems like something that would be super straight forward with a crappy script and a systemd service, but I have one thought that adds complexity. In theory, it would be possible for the maintainers of the repo to rebase and squash all commits back to some point in time. I would like to make sure that I don&amp;#39;t lose commits that have been squashed on the main branch, while also not losing the ability to continue updating.&lt;/p&gt;\n\n&lt;p&gt;As I&amp;#39;m writing this, I realized that one solution could be to have some logic in the script that catches when a pull fails due to a history conflict, move the current working directory off to a timestamped directory, and then clone a new copy.&lt;/p&gt;\n\n&lt;p&gt;I have thought about the workflow of hosting Gitea and setting up mirrors there. It sounds like a good idea, but squashed repo&amp;#39;s, etc would get clobbered.&lt;/p&gt;\n\n&lt;p&gt;Have any of set up anything to create historical (vs functional) archives of Git repo&amp;#39;s you don&amp;#39;t want to lose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17umxwn", "is_robot_indexable": true, "report_reasons": null, "author": "bamhm182", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17umxwn/anyone_have_a_system_in_place_for_creating/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17umxwn/anyone_have_a_system_in_place_for_creating/", "subreddit_subscribers": 711985, "created_utc": 1699914625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using teracopy and don't want my data to get damaged", "author_fullname": "t2_r76xkp0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When transfering data from a hdd with a rellocated sector count-warning, is there anything special to keep in mind?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ujyin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699907218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using teracopy and don&amp;#39;t want my data to get damaged&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ujyin", "is_robot_indexable": true, "report_reasons": null, "author": "mediamystery", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ujyin/when_transfering_data_from_a_hdd_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ujyin/when_transfering_data_from_a_hdd_with_a/", "subreddit_subscribers": 711985, "created_utc": 1699907218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys, i have a few questions. So i just return my Seagate Backup Plus because there's a problem with it, and Seagate gave me a new external HDD, it's a  2TB Seagate One Touch, and from what i read it's an SMR type. \n\nWhile researching what to do with a new hard drive on the subreddit, i came across suggestions to perform a full format so the bad sector is getting checked (in windows) then do a long SMART test.\n\nFrom what i've gathered, a full format involves writing zeroes to the drive. now, my questions are:\n\n1. For a new external hard drive with SMR type, is it recommended to perform a full format? Will it potentially make the drive slower because it fills the drive with zeroes?\n\n\n2. Currently I've already completed a full format on the drive, and I've noticed that after one hour, the drive's light is still on, and the drive hasn't spin down. Normally, it would spin down within just a few minutes. Could this be a result of the full format process? \n\nThanks in advance!  \n\n\n&amp;#x200B;", "author_fullname": "t2_169wvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need to full format a new SMR external hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uiwg4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699911382.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699904505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, i have a few questions. So i just return my Seagate Backup Plus because there&amp;#39;s a problem with it, and Seagate gave me a new external HDD, it&amp;#39;s a  2TB Seagate One Touch, and from what i read it&amp;#39;s an SMR type. &lt;/p&gt;\n\n&lt;p&gt;While researching what to do with a new hard drive on the subreddit, i came across suggestions to perform a full format so the bad sector is getting checked (in windows) then do a long SMART test.&lt;/p&gt;\n\n&lt;p&gt;From what i&amp;#39;ve gathered, a full format involves writing zeroes to the drive. now, my questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;For a new external hard drive with SMR type, is it recommended to perform a full format? Will it potentially make the drive slower because it fills the drive with zeroes?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Currently I&amp;#39;ve already completed a full format on the drive, and I&amp;#39;ve noticed that after one hour, the drive&amp;#39;s light is still on, and the drive hasn&amp;#39;t spin down. Normally, it would spin down within just a few minutes. Could this be a result of the full format process? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uiwg4", "is_robot_indexable": true, "report_reasons": null, "author": "Silversadness", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uiwg4/do_i_need_to_full_format_a_new_smr_external_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uiwg4/do_i_need_to_full_format_a_new_smr_external_hard/", "subreddit_subscribers": 711985, "created_utc": 1699904505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking to buy drives for a RAID setup (not super critical data, raid is enough).\n\nI have old WD RED's that worked for years so I looked the pricing for new ones. On Amazon.it they go around 210\u20ac for an 8TB RED Plus.\n\nNow, looking on Ebay (European Union), I find many refurbished drives like this Seagate Exos 12TB for 165\u20ac:\nhttps://www.ebay.it/itm/404523811058?mkcid=16&amp;mkevt=1&amp;mkrid=711-127632-2357-0&amp;ssspo=LLFi6ZEISiG&amp;sssrc=4429486&amp;ssuid=DzL4hzgbRtu&amp;var=&amp;widget_ver=artemis&amp;media=COPY\n\nIs it a big deal if I buy refurbished drives an put them in a RAID or better to get new ones?\n\nI'm from Italy so Reginald pricing and European stores are desirable if you have any places to recommend for buying HDDs.", "author_fullname": "t2_1hsjxygy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refurbished drives or not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uh9wj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699900344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to buy drives for a RAID setup (not super critical data, raid is enough).&lt;/p&gt;\n\n&lt;p&gt;I have old WD RED&amp;#39;s that worked for years so I looked the pricing for new ones. On Amazon.it they go around 210\u20ac for an 8TB RED Plus.&lt;/p&gt;\n\n&lt;p&gt;Now, looking on Ebay (European Union), I find many refurbished drives like this Seagate Exos 12TB for 165\u20ac:\n&lt;a href=\"https://www.ebay.it/itm/404523811058?mkcid=16&amp;amp;mkevt=1&amp;amp;mkrid=711-127632-2357-0&amp;amp;ssspo=LLFi6ZEISiG&amp;amp;sssrc=4429486&amp;amp;ssuid=DzL4hzgbRtu&amp;amp;var=&amp;amp;widget_ver=artemis&amp;amp;media=COPY\"&gt;https://www.ebay.it/itm/404523811058?mkcid=16&amp;amp;mkevt=1&amp;amp;mkrid=711-127632-2357-0&amp;amp;ssspo=LLFi6ZEISiG&amp;amp;sssrc=4429486&amp;amp;ssuid=DzL4hzgbRtu&amp;amp;var=&amp;amp;widget_ver=artemis&amp;amp;media=COPY&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is it a big deal if I buy refurbished drives an put them in a RAID or better to get new ones?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m from Italy so Reginald pricing and European stores are desirable if you have any places to recommend for buying HDDs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/p4p_06fikhzWFgDPgSRJMikebtHswCTGZKckL2J0QS0.jpg?auto=webp&amp;s=2e5e2c38ff759826f999dcfd000338f3c96a5e24", "width": 287, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/p4p_06fikhzWFgDPgSRJMikebtHswCTGZKckL2J0QS0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3b466e4bde86069d4e5035f9c42eb004b310a2a", "width": 108, "height": 150}, {"url": "https://external-preview.redd.it/p4p_06fikhzWFgDPgSRJMikebtHswCTGZKckL2J0QS0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=be96dd272f200a67ba09d7fe4a8eec3b1104abc4", "width": 216, "height": 301}], "variants": {}, "id": "SE1UDYWXRikKq0xib6qU3J34lsrQti_Fzqq7OFkQxJ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17uh9wj", "is_robot_indexable": true, "report_reasons": null, "author": "DAndreyD", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uh9wj/refurbished_drives_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uh9wj/refurbished_drives_or_not/", "subreddit_subscribers": 711985, "created_utc": 1699900344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've watched several YT videos reviewing both cases but nothing that explicitly calls out the noise levels with several HDDs running.\n\nI'm about to rebuild my unraid server and looking to buy the 7XL or R5, I already have 6 HDDs and will likely add some more in over time. At the moment, the server will need to be in my home office sitting 3 - 4ft away from me and I'm trying to understand how much noise isolation I can expect. Most of my drives are WD Blue 8TB but I have one Exos X16 14TB for parity. I've seen reviewes of the R5 that show some kind of dampening on the panels but I didn't see that with the 7 XL.\n\nAnyone with some experience with these cases able to comment?", "author_fullname": "t2_ynvh6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fractal Define 7 XL or R5 case for lower HDD noise?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ugips", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699898441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve watched several YT videos reviewing both cases but nothing that explicitly calls out the noise levels with several HDDs running.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to rebuild my unraid server and looking to buy the 7XL or R5, I already have 6 HDDs and will likely add some more in over time. At the moment, the server will need to be in my home office sitting 3 - 4ft away from me and I&amp;#39;m trying to understand how much noise isolation I can expect. Most of my drives are WD Blue 8TB but I have one Exos X16 14TB for parity. I&amp;#39;ve seen reviewes of the R5 that show some kind of dampening on the panels but I didn&amp;#39;t see that with the 7 XL.&lt;/p&gt;\n\n&lt;p&gt;Anyone with some experience with these cases able to comment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ugips", "is_robot_indexable": true, "report_reasons": null, "author": "ososoba", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ugips/fractal_define_7_xl_or_r5_case_for_lower_hdd_noise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ugips/fractal_define_7_xl_or_r5_case_for_lower_hdd_noise/", "subreddit_subscribers": 711985, "created_utc": 1699898441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all!\n\nI'm just starting my hoarding journey. So far, I'm running Plex for video content and audiobooks. I've found Libation to be great for backing up my Audible library. Is there anything like it for Kindle ebooks? I'm looking at using Kavita to manage the system.\n\nThanks!", "author_fullname": "t2_gvhny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginning Hoarder - Something like Libation for ebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uggda", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699898275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just starting my hoarding journey. So far, I&amp;#39;m running Plex for video content and audiobooks. I&amp;#39;ve found Libation to be great for backing up my Audible library. Is there anything like it for Kindle ebooks? I&amp;#39;m looking at using Kavita to manage the system.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uggda", "is_robot_indexable": true, "report_reasons": null, "author": "hadronwulf", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uggda/beginning_hoarder_something_like_libation_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uggda/beginning_hoarder_something_like_libation_for/", "subreddit_subscribers": 711985, "created_utc": 1699898275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, all,\n\nI hope this is in the right place: many searches are obfuscated by the search terms...\n\nAnyway, I have downloaded a load of rugby matches from various site around the web, YouTube, World Rugby, etc.\n\nI want to get them into my media library, so they can appear in Kodi / Plex, etc.\n\nI thought I had a solution with a Plex add on called SportScanner, but that have given me an empty library.\n\nI have added the SportsDB to Kodi, and that has picked up a couple of folders, but none of the games. \n\nI'm sure if I were to have the files named correctly, they might start appearing, but at the moment, I'm stuck. Currently, most of the files are named just as the game is, for example: \n\n\"//Rugby/English Premiership Rugby/2023/2023 \ud83d\udd34 LIVE REPLAY Harlequins v Bath Round 23 Game of the Week Gallagher Premiership Rugby.mp4\" The folder is picked up, and scraped with metadata, but neither app is picking the games up.\n\nCan anyone point me in the right direction?\n\nCheers,\n\n&amp;#x200B;", "author_fullname": "t2_6dqhxxjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cataloguing Downloaded Videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u6419", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699863464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, all,&lt;/p&gt;\n\n&lt;p&gt;I hope this is in the right place: many searches are obfuscated by the search terms...&lt;/p&gt;\n\n&lt;p&gt;Anyway, I have downloaded a load of rugby matches from various site around the web, YouTube, World Rugby, etc.&lt;/p&gt;\n\n&lt;p&gt;I want to get them into my media library, so they can appear in Kodi / Plex, etc.&lt;/p&gt;\n\n&lt;p&gt;I thought I had a solution with a Plex add on called SportScanner, but that have given me an empty library.&lt;/p&gt;\n\n&lt;p&gt;I have added the SportsDB to Kodi, and that has picked up a couple of folders, but none of the games. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure if I were to have the files named correctly, they might start appearing, but at the moment, I&amp;#39;m stuck. Currently, most of the files are named just as the game is, for example: &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;//Rugby/English Premiership Rugby/2023/2023 \ud83d\udd34 LIVE REPLAY Harlequins v Bath Round 23 Game of the Week Gallagher Premiership Rugby.mp4&amp;quot; The folder is picked up, and scraped with metadata, but neither app is picking the games up.&lt;/p&gt;\n\n&lt;p&gt;Can anyone point me in the right direction?&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u6419", "is_robot_indexable": true, "report_reasons": null, "author": "edvbvde", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u6419/cataloguing_downloaded_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u6419/cataloguing_downloaded_videos/", "subreddit_subscribers": 711985, "created_utc": 1699863464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There are plenty of downloaders that I've found but maybe [one utility](https://hydrusnetwork.github.io/) which *might* be good for it but isn't geared towards it specifically. Is there something I'm missing? I'm interested in preserving tags and maybe translation overlays (Danbooru-centric, again I've [found a utility](https://github.com/nostrenz/kosuzu) that would do that but *only* that).\n\nIdeally I would want to have it as something very simple (managed to find one for the numbers website) but if I have to run a local light instance of a booru I'll still live but want to know my options", "author_fullname": "t2_n9dsi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a local booru viewer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17upmh8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699922479.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699921936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are plenty of downloaders that I&amp;#39;ve found but maybe &lt;a href=\"https://hydrusnetwork.github.io/\"&gt;one utility&lt;/a&gt; which &lt;em&gt;might&lt;/em&gt; be good for it but isn&amp;#39;t geared towards it specifically. Is there something I&amp;#39;m missing? I&amp;#39;m interested in preserving tags and maybe translation overlays (Danbooru-centric, again I&amp;#39;ve &lt;a href=\"https://github.com/nostrenz/kosuzu\"&gt;found a utility&lt;/a&gt; that would do that but &lt;em&gt;only&lt;/em&gt; that).&lt;/p&gt;\n\n&lt;p&gt;Ideally I would want to have it as something very simple (managed to find one for the numbers website) but if I have to run a local light instance of a booru I&amp;#39;ll still live but want to know my options&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17upmh8", "is_robot_indexable": true, "report_reasons": null, "author": "Qreczek", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17upmh8/looking_for_a_local_booru_viewer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17upmh8/looking_for_a_local_booru_viewer/", "subreddit_subscribers": 711985, "created_utc": 1699921936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I plan to put some 1TB SSDs into long term (2-4 years) storage. I was told that the memory in SSDs lose charge over time so this might result in me returning to completely lost data\n\n1. Is there a \"safe\" time period where I can assume the SSDs still have the data on them?\n2. Do I need to read the whole 1TB worth of data off each SSD or would plugging them in every time period above be enough to have the data be reliably stored on them?", "author_fullname": "t2_fnmfbv52", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD for long term (2-4 years) storage ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uo9ua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699918098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I plan to put some 1TB SSDs into long term (2-4 years) storage. I was told that the memory in SSDs lose charge over time so this might result in me returning to completely lost data&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a &amp;quot;safe&amp;quot; time period where I can assume the SSDs still have the data on them?&lt;/li&gt;\n&lt;li&gt;Do I need to read the whole 1TB worth of data off each SSD or would plugging them in every time period above be enough to have the data be reliably stored on them?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uo9ua", "is_robot_indexable": true, "report_reasons": null, "author": "datanxiete", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uo9ua/ssd_for_long_term_24_years_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uo9ua/ssd_for_long_term_24_years_storage/", "subreddit_subscribers": 711985, "created_utc": 1699918098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! Three days ago, I embarked on creating a program designed to conceal any type of file within a PNG (with JPEG/JPG support coming soon). I'm excited to share it with all of you and welcome contributions. Feel free to join in\u2014I appreciate it when people contribute! You can find the project here: [https://github.com/JoshuaKasa/van-gonography](https://github.com/JoshuaKasa/van-gonography)", "author_fullname": "t2_5gusxohh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hiding data inside images with just 3 clicks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17un843", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699915378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Three days ago, I embarked on creating a program designed to conceal any type of file within a PNG (with JPEG/JPG support coming soon). I&amp;#39;m excited to share it with all of you and welcome contributions. Feel free to join in\u2014I appreciate it when people contribute! You can find the project here: &lt;a href=\"https://github.com/JoshuaKasa/van-gonography\"&gt;https://github.com/JoshuaKasa/van-gonography&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?auto=webp&amp;s=37fc952be8a8ae1825f23cbcdf803be8402627a7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b52d1bfe11eab751b5e9d301f8558e2ab3d0af9d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6da856174c92e2f6819a16eb01f23ba9ae7084cf", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=81fc5ee8a97550dd1601fbcbbc1fe80cbece9ae2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8101bdddb9a00d3d579cac5588778e92fc501d45", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa746a55a2d7c1f4d6293b6b35c01b4c2b320a99", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/-7Hj9TU5iNRC2YnZtPuDy98W4pU0-G5SxWJrK-hqClE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9903eb900944a54eb1693033fc166da344403a19", "width": 1080, "height": 540}], "variants": {}, "id": "xCjnt7IWDVvV_sL4uS8rRbeQXPGlECUCQzvWBtpxZEI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17un843", "is_robot_indexable": true, "report_reasons": null, "author": "JizosKasa", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17un843/hiding_data_inside_images_with_just_3_clicks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17un843/hiding_data_inside_images_with_just_3_clicks/", "subreddit_subscribers": 711985, "created_utc": 1699915378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Yes, I know now SSDs aren\u2019t good for cold storage. But is a full sized SSD and this solid state flash drive the same in terms of data decay / safety?", "author_fullname": "t2_kxz5a4fi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the SanDisk Extreme Pro 3.2 Solid State Flash Drive essentially a compacted SSD? Is it as safe as a full sized SSD for data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uesko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699893897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, I know now SSDs aren\u2019t good for cold storage. But is a full sized SSD and this solid state flash drive the same in terms of data decay / safety?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17uesko", "is_robot_indexable": true, "report_reasons": null, "author": "BluebirdSpare7343", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17uesko/is_the_sandisk_extreme_pro_32_solid_state_flash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17uesko/is_the_sandisk_extreme_pro_32_solid_state_flash/", "subreddit_subscribers": 711985, "created_utc": 1699893897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I should preface this by mentioning that I'm not really a data hoarder, but I've been tasked with downloading and preserving the content from some MediaWiki based wikis, and a couple of Fandom ones too (which to my knowledge) in order to preserve their contents (which I feel is in the spirit of this sub.)\n\nSo far I've managed to figure out that I need to use WikiTaxi, but the trouble I'm running into is that, while Wikipedia XML dumps are readily available for download, other Mediawiki sites are not so forthcoming from what I've seen so far.\n\nIs there any way that I can get my hands on those? Preferably through a self-contained program or similar that doesn't necessitate running Python or similar things (I'm by no means nearly tech-savyy enough to know how to use Python and would like to avoid such things since there are a few Wikis and would like to simplify the process as much as humanly possible).\n\nI would genuinely appreciate any kind of advice or information any of you might be able to provide me with.", "author_fullname": "t2_c1vm594iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with downloading XML dumps off Wikis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ub5ls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699883756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I should preface this by mentioning that I&amp;#39;m not really a data hoarder, but I&amp;#39;ve been tasked with downloading and preserving the content from some MediaWiki based wikis, and a couple of Fandom ones too (which to my knowledge) in order to preserve their contents (which I feel is in the spirit of this sub.)&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve managed to figure out that I need to use WikiTaxi, but the trouble I&amp;#39;m running into is that, while Wikipedia XML dumps are readily available for download, other Mediawiki sites are not so forthcoming from what I&amp;#39;ve seen so far.&lt;/p&gt;\n\n&lt;p&gt;Is there any way that I can get my hands on those? Preferably through a self-contained program or similar that doesn&amp;#39;t necessitate running Python or similar things (I&amp;#39;m by no means nearly tech-savyy enough to know how to use Python and would like to avoid such things since there are a few Wikis and would like to simplify the process as much as humanly possible).&lt;/p&gt;\n\n&lt;p&gt;I would genuinely appreciate any kind of advice or information any of you might be able to provide me with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ub5ls", "is_robot_indexable": true, "report_reasons": null, "author": "AndYet_19", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ub5ls/need_help_with_downloading_xml_dumps_off_wikis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ub5ls/need_help_with_downloading_xml_dumps_off_wikis/", "subreddit_subscribers": 711985, "created_utc": 1699883756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hard drive I use for games (so very large files) which is almost full has been giving me an error every now and again when attempting to access certain folders on the HDD. After a restart, my pc can access the folders in question. However, after a few hours the error will come back. After a bit of research, it sounds like it's on it's way out. I've attempted CHKDSK which I've left on for 3 days, running extremely slowly. \n\n&amp;#x200B;\n\nUnfortunately it's now stuck at 53% (screenshot: [https://i.postimg.cc/qBCp37Rc/image-2023-11-13-113638901.png](https://i.postimg.cc/qBCp37Rc/image-2023-11-13-113638901.png)) and hasn't moved for 24 hours so I don't see it moving any further.\n\n&amp;#x200B;\n\nI understand this isn't a tech support reddit but I was wondering if anybody has some advice on the best/quickest way to transfer this data to another HDD. As the HDD tends to fail at random points after a few hours, I can't simply copy and paste it ALL in one go. Am I just going to have to simply copy and paste the files I need manually over a period of time? Or can anybody advise on a better way?\n\nThanks in advance.", "author_fullname": "t2_jpu4izt2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to transfer from a dying 8TB HDD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17u8s4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699875497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hard drive I use for games (so very large files) which is almost full has been giving me an error every now and again when attempting to access certain folders on the HDD. After a restart, my pc can access the folders in question. However, after a few hours the error will come back. After a bit of research, it sounds like it&amp;#39;s on it&amp;#39;s way out. I&amp;#39;ve attempted CHKDSK which I&amp;#39;ve left on for 3 days, running extremely slowly. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Unfortunately it&amp;#39;s now stuck at 53% (screenshot: &lt;a href=\"https://i.postimg.cc/qBCp37Rc/image-2023-11-13-113638901.png\"&gt;https://i.postimg.cc/qBCp37Rc/image-2023-11-13-113638901.png&lt;/a&gt;) and hasn&amp;#39;t moved for 24 hours so I don&amp;#39;t see it moving any further.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I understand this isn&amp;#39;t a tech support reddit but I was wondering if anybody has some advice on the best/quickest way to transfer this data to another HDD. As the HDD tends to fail at random points after a few hours, I can&amp;#39;t simply copy and paste it ALL in one go. Am I just going to have to simply copy and paste the files I need manually over a period of time? Or can anybody advise on a better way?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5nofNHpcL2UqdkC-22onip47SZ5Z0QXwFG5ifEZyFRM.png?auto=webp&amp;s=29f56545333c0406cda3bb44f8c1310f15a69998", "width": 844, "height": 728}, "resolutions": [{"url": "https://external-preview.redd.it/5nofNHpcL2UqdkC-22onip47SZ5Z0QXwFG5ifEZyFRM.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c97558bb8c039b6e2a9715e835774c4f64fbb2f0", "width": 108, "height": 93}, {"url": "https://external-preview.redd.it/5nofNHpcL2UqdkC-22onip47SZ5Z0QXwFG5ifEZyFRM.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c227ec022ec3905d7aa32382b92d30925f89b1c9", "width": 216, "height": 186}, {"url": "https://external-preview.redd.it/5nofNHpcL2UqdkC-22onip47SZ5Z0QXwFG5ifEZyFRM.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6e77a758a36b35518a6eeb76303384d02d14f40f", "width": 320, "height": 276}, {"url": "https://external-preview.redd.it/5nofNHpcL2UqdkC-22onip47SZ5Z0QXwFG5ifEZyFRM.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce41fb567de13982bd0b1f23950ccf2577fe9b77", "width": 640, "height": 552}], "variants": {}, "id": "ef7uh6Wuovkh11s-EQDtnHO7-R53b6VtaN9CkpC13tc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17u8s4s", "is_robot_indexable": true, "report_reasons": null, "author": "SupremeFlamer", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17u8s4s/best_way_to_transfer_from_a_dying_8tb_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17u8s4s/best_way_to_transfer_from_a_dying_8tb_hdd/", "subreddit_subscribers": 711985, "created_utc": 1699875497.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}