{"kind": "Listing", "data": {"after": null, "dist": 9, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a decently paid \u201cSenior Data Scientist\u201d for a startup, who, in the two years in this role:\n1.  hasn\u2019t done a single \u201cproper\u201d data science experiment (p-values, etc etc) to inform business decisions\n2. Hasn\u2019t pushed a single model to production, hell I haven\u2019t even trained one.\n\nInstead, I\u2019m doing dashboards, data engineering, hacking scripts to improve analytics because the devs are too busy, responding to customer requests which are generally \u201ccan we have this in a csv\u201d type stuff.\n\nIt\u2019s getting to a point where I think I should either change my job title or change my job because I\u2019m not sure I\u2019m getting good experience, although despite the stupidly long hours I do enjoy it and am respected with autonomy.", "author_fullname": "t2_6ae1kvay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else a DS that doesn\u2019t actually do DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uytmb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 147, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 147, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699954994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a decently paid \u201cSenior Data Scientist\u201d for a startup, who, in the two years in this role:\n1.  hasn\u2019t done a single \u201cproper\u201d data science experiment (p-values, etc etc) to inform business decisions\n2. Hasn\u2019t pushed a single model to production, hell I haven\u2019t even trained one.&lt;/p&gt;\n\n&lt;p&gt;Instead, I\u2019m doing dashboards, data engineering, hacking scripts to improve analytics because the devs are too busy, responding to customer requests which are generally \u201ccan we have this in a csv\u201d type stuff.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s getting to a point where I think I should either change my job title or change my job because I\u2019m not sure I\u2019m getting good experience, although despite the stupidly long hours I do enjoy it and am respected with autonomy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17uytmb", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous_Classic96", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17uytmb/anyone_else_a_ds_that_doesnt_actually_do_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17uytmb/anyone_else_a_ds_that_doesnt_actually_do_ds/", "subreddit_subscribers": 1128679, "created_utc": 1699954994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Still doing DS or perhaps in another data related role?\n\nEdit: It appears everyone hates their job.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you see yourself in 5-10 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17un7gs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 88, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 88, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699929068.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699915328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Still doing DS or perhaps in another data related role?&lt;/p&gt;\n\n&lt;p&gt;Edit: It appears everyone hates their job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17un7gs", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17un7gs/where_do_you_see_yourself_in_510_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17un7gs/where_do_you_see_yourself_in_510_years/", "subreddit_subscribers": 1128679, "created_utc": 1699915328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any DS here working for StateFarm. Have the 4 hr long onxite coming. Any tips would be much appreciated \ud83d\ude4f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17up1hr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699920252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17up1hr", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17up1hr/any_ds_here_working_for_statefarm_have_the_4_hr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17up1hr/any_ds_here_working_for_statefarm_have_the_4_hr/", "subreddit_subscribers": 1128679, "created_utc": 1699920252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Please help shed light on actual salary expectations per city/state \ud83d\ude4f\ud83c\udffb", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your salary progression in DS? (Base/Bonus) + Location", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17v1jv7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699966274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help shed light on actual salary expectations per city/state \ud83d\ude4f\ud83c\udffb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17v1jv7", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17v1jv7/what_was_your_salary_progression_in_ds_basebonus/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17v1jv7/what_was_your_salary_progression_in_ds_basebonus/", "subreddit_subscribers": 1128679, "created_utc": 1699966274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm rather new at working with SQL, and went from one Fortune 500 to another. Previously I worked in Access, I know, horrible right? Now I work in Oracle and SQL server. I often see these nightmare SQL queries, 1200 lines of code are more,  truly horrific size and filled with tons of crazy things that are not commented, have no explanation as to why they are done, and I'm supposed to just jump in and explain why they are the way they are.... How? How does it make any sense? \n\n\nFor example, dealing with product analytics. We have about 15 to 20 products, so one query might have 20 different columns brought in, but that's on one select statement. There's about 30 to 40 select statements each inside their own temporary tables, or their own block of code. They have a lot of operations on them, addition and multiplication, coalesce, casting, stuff like that. It's very very messy....\n\n\n\nWhat I want to know is how to survive in this kind of environment where they have no comments and you're just supposed to figure it out on your own? How do other people do it? Do they just copy all this stuff and throw it into chat GPT and have them explain what's going on?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you overcome the endless maze of code in a query?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17v1g46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699965898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m rather new at working with SQL, and went from one Fortune 500 to another. Previously I worked in Access, I know, horrible right? Now I work in Oracle and SQL server. I often see these nightmare SQL queries, 1200 lines of code are more,  truly horrific size and filled with tons of crazy things that are not commented, have no explanation as to why they are done, and I&amp;#39;m supposed to just jump in and explain why they are the way they are.... How? How does it make any sense? &lt;/p&gt;\n\n&lt;p&gt;For example, dealing with product analytics. We have about 15 to 20 products, so one query might have 20 different columns brought in, but that&amp;#39;s on one select statement. There&amp;#39;s about 30 to 40 select statements each inside their own temporary tables, or their own block of code. They have a lot of operations on them, addition and multiplication, coalesce, casting, stuff like that. It&amp;#39;s very very messy....&lt;/p&gt;\n\n&lt;p&gt;What I want to know is how to survive in this kind of environment where they have no comments and you&amp;#39;re just supposed to figure it out on your own? How do other people do it? Do they just copy all this stuff and throw it into chat GPT and have them explain what&amp;#39;s going on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17v1g46", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17v1g46/how_do_you_overcome_the_endless_maze_of_code_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17v1g46/how_do_you_overcome_the_endless_maze_of_code_in_a/", "subreddit_subscribers": 1128679, "created_utc": 1699965898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have created a Content Based Recommender using k-NN to recommend the 5 most similar books within a corpus. The corpus has been processed using nltk and I have applied TF-IDF Vectoriser from sklearn to get in the form of an array. \n\nIt works well, but I need to objectively assess it, and I have decided to use Normalised Discounted Cumulative Gain (NDCG).\n\nHow do I assess the test data against the training using NDCG? Do I need to create an extra variable of relevance?", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For a change in this sub- An actual Data Science question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uuxxh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699938505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have created a Content Based Recommender using k-NN to recommend the 5 most similar books within a corpus. The corpus has been processed using nltk and I have applied TF-IDF Vectoriser from sklearn to get in the form of an array. &lt;/p&gt;\n\n&lt;p&gt;It works well, but I need to objectively assess it, and I have decided to use Normalised Discounted Cumulative Gain (NDCG).&lt;/p&gt;\n\n&lt;p&gt;How do I assess the test data against the training using NDCG? Do I need to create an extra variable of relevance?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17uuxxh", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17uuxxh/for_a_change_in_this_sub_an_actual_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17uuxxh/for_a_change_in_this_sub_an_actual_data_science/", "subreddit_subscribers": 1128679, "created_utc": 1699938505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not sure how to approach this, product has been giving increasingly difficult demands on the models, and setting them as goals, with deadlines etc', the benchmark seems to be \"well a human is capable of recognising that this is X, so should our product/feature\", sometimes its possible, but in other times, the contextual knowledge that is required, along with the computation requirements and other difficulties related to the domain and sample conditions make this task delusional.\n\nWe used to have an exec with enough background who would shield us from these kinds of requests, he was let go.", "author_fullname": "t2_b4lh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle Product/Executives who ask too much", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17uyqic", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699954600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure how to approach this, product has been giving increasingly difficult demands on the models, and setting them as goals, with deadlines etc&amp;#39;, the benchmark seems to be &amp;quot;well a human is capable of recognising that this is X, so should our product/feature&amp;quot;, sometimes its possible, but in other times, the contextual knowledge that is required, along with the computation requirements and other difficulties related to the domain and sample conditions make this task delusional.&lt;/p&gt;\n\n&lt;p&gt;We used to have an exec with enough background who would shield us from these kinds of requests, he was let go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17uyqic", "is_robot_indexable": true, "report_reasons": null, "author": "DisWastingMyTime", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17uyqic/how_do_you_handle_productexecutives_who_ask_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17uyqic/how_do_you_handle_productexecutives_who_ask_too/", "subreddit_subscribers": 1128679, "created_utc": 1699954600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m currently debating between pursuing either a Masters in Data Science (MS-DS) or a Masters in Applied &amp; Computational Math (MS-AM). For the MS-DS, my choices right now are either Rutgers NB or Georgia Tech\u2019s online program (OMSA). I know most data science programs tend to be \u201ccash cows\u201d or too watered down but I did extensive research into their curriculums and they\u2019re both pretty rigorous. And they\u2019re both ranked well. \n\nOn the other hand, for the MS-AP, I\u2019m looking into John Hopkins\u2019 Engineering for Professionals program\u2019s online masters. This program is very rigorous, offers flexibility to tailor your degree to however you want via their numerous course offerings, and doesn\u2019t compromise depth of knowledge. I like this because I can take classes that excite me and might be relevant but aren\u2019t offered in a typical data science degree. Plus, it\u2019ll build a very strong mathematical foundation. It\u2019s also ranked well. But its very expensive. \n\nRutgers would be in-person and the other two are online and part-time so that I can start working and gaining experience. Though with just a bachelor\u2019s, it\u2019s virtually impossible to get a job in a relevant field right now. So being in-person at Rutgers would help me network better and perhaps do paid research on campus.", "author_fullname": "t2_3yx8ekgr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters in Data Science vs Applied &amp; Computational Math?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17v6qht", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699981354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently debating between pursuing either a Masters in Data Science (MS-DS) or a Masters in Applied &amp;amp; Computational Math (MS-AM). For the MS-DS, my choices right now are either Rutgers NB or Georgia Tech\u2019s online program (OMSA). I know most data science programs tend to be \u201ccash cows\u201d or too watered down but I did extensive research into their curriculums and they\u2019re both pretty rigorous. And they\u2019re both ranked well. &lt;/p&gt;\n\n&lt;p&gt;On the other hand, for the MS-AP, I\u2019m looking into John Hopkins\u2019 Engineering for Professionals program\u2019s online masters. This program is very rigorous, offers flexibility to tailor your degree to however you want via their numerous course offerings, and doesn\u2019t compromise depth of knowledge. I like this because I can take classes that excite me and might be relevant but aren\u2019t offered in a typical data science degree. Plus, it\u2019ll build a very strong mathematical foundation. It\u2019s also ranked well. But its very expensive. &lt;/p&gt;\n\n&lt;p&gt;Rutgers would be in-person and the other two are online and part-time so that I can start working and gaining experience. Though with just a bachelor\u2019s, it\u2019s virtually impossible to get a job in a relevant field right now. So being in-person at Rutgers would help me network better and perhaps do paid research on campus.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17v6qht", "is_robot_indexable": true, "report_reasons": null, "author": "mowa0199", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17v6qht/masters_in_data_science_vs_applied_computational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17v6qht/masters_in_data_science_vs_applied_computational/", "subreddit_subscribers": 1128679, "created_utc": 1699981354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone have tips on how to improve answers from a document retrieval chain? \nCurrent set up is got-3.5-turbo, chroma, lang chain, the whole thing is dockerized and hosted on kubernetes. I fed couple of regulation documents to both my bot and AskYourPDF, and the answer I get from AskYourPDF is much better.\nI provided a prompt template asking the LLM to be truthful, comprehensive, detail, and provide source to the answers. LLM is set to Temp=0, top_n=3, token_limit=200, using Stuff chain. The answer I get is technically correct but not a lot of context, just one short sentence pulled from the most relevant paragraph, quite concise. However the answer I get from AskYourPDF provides not only correct answer but also with additional details relevant to the question, from various paragraphs throughout the doc. \nI\u2019m wondering what I can do to make my bot provide a correct, comprehensive and contextualized answer?", "author_fullname": "t2_16kgog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retriever chain answer quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17utoiq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699934153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have tips on how to improve answers from a document retrieval chain? \nCurrent set up is got-3.5-turbo, chroma, lang chain, the whole thing is dockerized and hosted on kubernetes. I fed couple of regulation documents to both my bot and AskYourPDF, and the answer I get from AskYourPDF is much better.\nI provided a prompt template asking the LLM to be truthful, comprehensive, detail, and provide source to the answers. LLM is set to Temp=0, top_n=3, token_limit=200, using Stuff chain. The answer I get is technically correct but not a lot of context, just one short sentence pulled from the most relevant paragraph, quite concise. However the answer I get from AskYourPDF provides not only correct answer but also with additional details relevant to the question, from various paragraphs throughout the doc. \nI\u2019m wondering what I can do to make my bot provide a correct, comprehensive and contextualized answer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17utoiq", "is_robot_indexable": true, "report_reasons": null, "author": "balpby1989", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17utoiq/retriever_chain_answer_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17utoiq/retriever_chain_answer_quality/", "subreddit_subscribers": 1128679, "created_utc": 1699934153.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}