{"kind": "Listing", "data": {"after": "t3_17m0yv5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking about it for quite a while now.   \n\n\nWhat is the alternate for Data Engineers when it comes to upskilling and showcasing their skills.   \nLike, Developers usually have coding questions like Leetcode, Codeforces etc. \n\nWhat do the DEs have to practice or work on?   \n\n\nI've seen few companies ask LC questions as well in interviews for DE, Analyst etc and these companies are legit Fortune 500 ones. ", "author_fullname": "t2_8laf2pzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LeetCode for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0ioz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 62, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 62, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698921306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking about it for quite a while now.   &lt;/p&gt;\n\n&lt;p&gt;What is the alternate for Data Engineers when it comes to upskilling and showcasing their skills.&lt;br/&gt;\nLike, Developers usually have coding questions like Leetcode, Codeforces etc. &lt;/p&gt;\n\n&lt;p&gt;What do the DEs have to practice or work on?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen few companies ask LC questions as well in interviews for DE, Analyst etc and these companies are legit Fortune 500 ones. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m0ioz", "is_robot_indexable": true, "report_reasons": null, "author": "Key_Consideration385", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0ioz/leetcode_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0ioz/leetcode_for_data_engineers/", "subreddit_subscribers": 137582, "created_utc": 1698921306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are things that you dedicated a lot of hours to learn (through books, bootcamps...) thinking that they are going to boost your knowledge/skills in DE but that are of no use in a DE job?\n\n(learning by avoiding other people's mistakes)", "author_fullname": "t2_7mkrswyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Things you learned that were of no use. [mainly juniors-mediors]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m94wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698947023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are things that you dedicated a lot of hours to learn (through books, bootcamps...) thinking that they are going to boost your knowledge/skills in DE but that are of no use in a DE job?&lt;/p&gt;\n\n&lt;p&gt;(learning by avoiding other people&amp;#39;s mistakes)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m94wu", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic_Tooth_1096", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m94wu/things_you_learned_that_were_of_no_use_mainly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m94wu/things_you_learned_that_were_of_no_use_mainly/", "subreddit_subscribers": 137582, "created_utc": 1698947023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got a demo of a new product a team is gonna implement in my company that is going to \u2018use AI to help users find data and reports\u2019. \n\nIt had nothing to do with AI. You had to manually tag every report with answers that report could answer. Then if someone\u2019s question they typed in matched a tag it would put it at the top of the search results. \n\nI asked what was the AI component of this? They said because the bot responds to the question. \n\nIt\u2019s a good reminder to try and educate business users about AI and how it isn\u2019t currently going to solve all their issues.", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Be aware of the AI snake salesman", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17mi1iz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a demo of a new product a team is gonna implement in my company that is going to \u2018use AI to help users find data and reports\u2019. &lt;/p&gt;\n\n&lt;p&gt;It had nothing to do with AI. You had to manually tag every report with answers that report could answer. Then if someone\u2019s question they typed in matched a tag it would put it at the top of the search results. &lt;/p&gt;\n\n&lt;p&gt;I asked what was the AI component of this? They said because the bot responds to the question. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s a good reminder to try and educate business users about AI and how it isn\u2019t currently going to solve all their issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mi1iz", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi1iz/be_aware_of_the_ai_snake_salesman/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi1iz/be_aware_of_the_ai_snake_salesman/", "subreddit_subscribers": 137582, "created_utc": 1698970536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vawpw1e3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Databricks Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0jor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qHZMVmx8tcPF-ls1nqwhKRq4lLrm1qqjBxYCPpIDubk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698921421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/databricks-lakehouse/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?auto=webp&amp;s=55ce104c732d20006574c94135132de41e8154e7", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46f588bdb7899ca2e25c0011bff500331216db71", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b12af7287045a8f860c5a44f9d4947534470b20", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=287348298269d0d4b247a1b0f2f7239752a46cb9", "width": 320, "height": 274}], "variants": {}, "id": "7ellfxDweEooh_Jw1w5X3I9gYXoPrVswM_cK4FhkLaA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17m0jor", "is_robot_indexable": true, "report_reasons": null, "author": "oatridbed", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0jor/getting_started_with_databricks_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/databricks-lakehouse/", "subreddit_subscribers": 137582, "created_utc": 1698921421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone else feel a little stuck in their career progress, and if so, what are you doing about it?\n\n\n\n\n\nFor me, I've just been practicing Leetcode and system design for the past year and a half.  Not that many companies are interviewing data engineers in my area, and the companies that are hiring are paying less or are startups that seem risky to take a job offer at.\n\n\n\n\n\nI'm currently a data engineer with 5 years of experience, with 3 years at a well known tech company.  I'm in a position where I want to learn more but I'm not in a position to internally transfer teams, or apply to different companies because of the economy.  My technical skills are not improving.\n\n\n\n\nIt seems like most other jobs out there pay much less or at startups with less job security.  And to get those jobs, I would need to have a much better resume and be much better at technical interviewing just to work there.  The funny thing is, I feel better about my technical interview skills now than at any other point in my career, since I started studying in the middle of 2022 when the job market started to go get worse.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the economy have anyone else feeling stuck in their careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m1uuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698926378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone else feel a little stuck in their career progress, and if so, what are you doing about it?&lt;/p&gt;\n\n&lt;p&gt;For me, I&amp;#39;ve just been practicing Leetcode and system design for the past year and a half.  Not that many companies are interviewing data engineers in my area, and the companies that are hiring are paying less or are startups that seem risky to take a job offer at.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer with 5 years of experience, with 3 years at a well known tech company.  I&amp;#39;m in a position where I want to learn more but I&amp;#39;m not in a position to internally transfer teams, or apply to different companies because of the economy.  My technical skills are not improving.&lt;/p&gt;\n\n&lt;p&gt;It seems like most other jobs out there pay much less or at startups with less job security.  And to get those jobs, I would need to have a much better resume and be much better at technical interviewing just to work there.  The funny thing is, I feel better about my technical interview skills now than at any other point in my career, since I started studying in the middle of 2022 when the job market started to go get worse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m1uuo", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17m1uuo/does_the_economy_have_anyone_else_feeling_stuck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m1uuo/does_the_economy_have_anyone_else_feeling_stuck/", "subreddit_subscribers": 137582, "created_utc": 1698926378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\nI'm just starting my journey into learning Kafka, and I'm looking for some guidance on the best free resources and documentation available for beginners. Kafka seems like a fascinating technology, but I could use some help finding the right learning materials to get started.\n\nIf you have any suggestions or recommendations for online tutorials, documentation, video courses, or any other free resources that helped you learn Kafka from scratch, please share them here. I'm eager to dive into Kafka and appreciate your valuable insights!\n\n \\#Kafka#LearningResources#Beginner#Documentation#Tutorials#GettingStarted#FreeResources", "author_fullname": "t2_ttkjwcb9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for the Best Free Resources to Learn Kafka as a Beginner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0izo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698921340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just starting my journey into learning Kafka, and I&amp;#39;m looking for some guidance on the best free resources and documentation available for beginners. Kafka seems like a fascinating technology, but I could use some help finding the right learning materials to get started.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions or recommendations for online tutorials, documentation, video courses, or any other free resources that helped you learn Kafka from scratch, please share them here. I&amp;#39;m eager to dive into Kafka and appreciate your valuable insights!&lt;/p&gt;\n\n&lt;p&gt;#Kafka#LearningResources#Beginner#Documentation#Tutorials#GettingStarted#FreeResources&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17m0izo", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Woodpecker9626", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0izo/looking_for_the_best_free_resources_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0izo/looking_for_the_best_free_resources_to_learn/", "subreddit_subscribers": 137582, "created_utc": 1698921340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys,\n\nMy name is Alessio and I am a student at the University of Turin. I am currently conducting a research for my thesis based on the evaluation of data pipeline software with the focus in the enterprise field.\n\nI understand that your time is valuable, but I would be extremly grateful if you could take a few minutes to respond to a short survey that will help me make informed decisions. Your opinions are crucial for my research and to identify the best software among those listed.\n\nYou can find the survey here, it is a google form: [https://forms.gle/APcom1Eizp3Js34z5](https://forms.gle/APcom1Eizp3Js34z5)\n\nIf you don't know all the five software, just evaluate the ones you're familiar with.\n\nTo show my gratitude to the community, I would like to offer you the survey results as a token of appreciation for your participation and find out what the community thinks about these software.\n\nYour contribution will be completely anonymous and will not take more than 15 minutes.\n\nThank you in advance for your participation!", "author_fullname": "t2_kx22ifsjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best data pipeline software at the moment? Airflow vs Dagster vs NiFi vs Prefect vs Keboola", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lzwkm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698918791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys,&lt;/p&gt;\n\n&lt;p&gt;My name is Alessio and I am a student at the University of Turin. I am currently conducting a research for my thesis based on the evaluation of data pipeline software with the focus in the enterprise field.&lt;/p&gt;\n\n&lt;p&gt;I understand that your time is valuable, but I would be extremly grateful if you could take a few minutes to respond to a short survey that will help me make informed decisions. Your opinions are crucial for my research and to identify the best software among those listed.&lt;/p&gt;\n\n&lt;p&gt;You can find the survey here, it is a google form: &lt;a href=\"https://forms.gle/APcom1Eizp3Js34z5\"&gt;https://forms.gle/APcom1Eizp3Js34z5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t know all the five software, just evaluate the ones you&amp;#39;re familiar with.&lt;/p&gt;\n\n&lt;p&gt;To show my gratitude to the community, I would like to offer you the survey results as a token of appreciation for your participation and find out what the community thinks about these software.&lt;/p&gt;\n\n&lt;p&gt;Your contribution will be completely anonymous and will not take more than 15 minutes.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your participation!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?auto=webp&amp;s=3219d3381d57033e78c87d562aeec0e79110e4a9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba2fdf0ac276285c9b09f897392958c7042d2b5d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6501ac6fb09aec93e4c7d7ff6f5cda0b372ec1e4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7593ed9e1c0d8e5878b676152338158a0fd954b8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e8099be239f5e112be7fdc4757c12423fe16d93", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=929edd0789bd94751ed7fedf97362682b3b4226a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ffd3b179325a733092988baad49a603677ff0021", "width": 1080, "height": 567}], "variants": {}, "id": "Li1WKefx44mxVpgeuKbJSwC4uxit4IhPi_jLoBPU-Mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lzwkm", "is_robot_indexable": true, "report_reasons": null, "author": "Moist_Pomegranate521", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lzwkm/which_is_the_best_data_pipeline_software_at_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lzwkm/which_is_the_best_data_pipeline_software_at_the/", "subreddit_subscribers": 137582, "created_utc": 1698918791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.\n\nSo I have a rather simple question really.\n\nSo I am looking at a CDC use case, where the data **source** is a event-based data source, like Azure Event Hub or Kafka, and each record is a change to the source data, and the data **destination** is a file-based data lake (i.e. AWS S3 .parquet)\n\n&amp;#x200B;\n\nHere is my question:\n\nHow would you store the information coming from the messaging service (Kafka etc).?\n\nLets say we have a source with potentially thousands of updates per minute, if I store each update as an individual file, I'd end up with millions of minature files. Wouldn't this be inefficient if you want to access this data using say Redshift Spectrum or add it to Databricks Delta lake?\n\nHow would you guys approach this?\n\n&amp;#x200B;\n\nBonus info:\n\nI did this with BigQuery once as the destination, but that was simpler, as all of the file management is \"hidden\", and thus I really didn't care about these minature updates.", "author_fullname": "t2_onmeo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time/CDC data into delta-lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lz2k8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698915395.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698914814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;So I have a rather simple question really.&lt;/p&gt;\n\n&lt;p&gt;So I am looking at a CDC use case, where the data &lt;strong&gt;source&lt;/strong&gt; is a event-based data source, like Azure Event Hub or Kafka, and each record is a change to the source data, and the data &lt;strong&gt;destination&lt;/strong&gt; is a file-based data lake (i.e. AWS S3 .parquet)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is my question:&lt;/p&gt;\n\n&lt;p&gt;How would you store the information coming from the messaging service (Kafka etc).?&lt;/p&gt;\n\n&lt;p&gt;Lets say we have a source with potentially thousands of updates per minute, if I store each update as an individual file, I&amp;#39;d end up with millions of minature files. Wouldn&amp;#39;t this be inefficient if you want to access this data using say Redshift Spectrum or add it to Databricks Delta lake?&lt;/p&gt;\n\n&lt;p&gt;How would you guys approach this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Bonus info:&lt;/p&gt;\n\n&lt;p&gt;I did this with BigQuery once as the destination, but that was simpler, as all of the file management is &amp;quot;hidden&amp;quot;, and thus I really didn&amp;#39;t care about these minature updates.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lz2k8", "is_robot_indexable": true, "report_reasons": null, "author": "Hinkakan", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lz2k8/realtimecdc_data_into_deltalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lz2k8/realtimecdc_data_into_deltalake/", "subreddit_subscribers": 137582, "created_utc": 1698914814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m in a bit of a weird situation and looking for any advice, guidance, or any information!\n\nI'd ideally like to work in data science/data engineering/software engineering, but these all seems locked behind CS degrees or a master's, and I'm currently pursuing a statistics degree. I'm fully aware of the necessity of internships/projects/self-learning, and I'm mostly concerned with what opportunities I'm limited to by my degree.\n\n**TL;DR:** worried about the opportunities my stats degree will offer. Looking for guidance into getting into the tech field, with a preference for data science/data engineering/software engineering.\n\n**TL;DR question:** How would a BS statistics degree (with lots of programming experience/projects etc.) fare in the tech job market? How important is the CS degree for getting a job compared to another STEM degree like statistics?\n\n&amp;#x200B;\n\n**My situation:**\n\nI originally wanted to go into data science (like all the kids these days) and figured a stats and cs double degree would be the best bet. However, these jobs seem not only scarce and very competitive, but it seems that a straight masters degree is required for a lot of them. Something I would rather not do immediately, but would be open to in the future.\n\nI\u2019m currently a 3rd year statistics major that just transferred to a UC from community college. I wanted to switch to computer science or add as a double major, but there were some policy changes this year that threw a wrench into my plans. I've taken 2 full series of OOP/DSA courses in both C++ and python, but didn't complete computer architecture, which I need to take to switch majors and is very hard to register for as a non-major. At worst, I wouldn\u2019t be able to start the major until senior year (next fall) assuming they accept my petition\u2026 and with the current state of CS at my school it is very hard to get into. So I may be denied to do a CS degree altogether from this university. If I get lucky and am able to switch to computer science, I would likely have to stay another year, and at that point I may as well finish my stats degree and double major as it wouldn\u2019t add any extra time (1 extra quarter if it did).\n\nLike I mentioned above, I'd ideally like to work in data science/data engineering/software engineering, but these all seems locked to just a BS stats degree. I\u2019ve heard about people starting in data analytics and then moving into data engineering or software engineering. However, in this market, I\u2019m concerned that won\u2019t be possible anymore.\n\n**My questions/options:**\n\nDoes anyone have any recommendations for what I should do to get into the space?\n\nShould I apply for data analytics jobs and then try to switch into data engineer/software engineering?\n\nShould I maybe do an online school such as WGU to get a CS degree if I can't get it from my university?\n\nShould I go get a masters degree right after school?\n\nWhat are my options for getting into tech if I don't have a CS degree?\n\nThanks for reading and your time!", "author_fullname": "t2_7n1o98a9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Viability of an undergraduate statistics degree for starting a career in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ltaqz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698891949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m in a bit of a weird situation and looking for any advice, guidance, or any information!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d ideally like to work in data science/data engineering/software engineering, but these all seems locked behind CS degrees or a master&amp;#39;s, and I&amp;#39;m currently pursuing a statistics degree. I&amp;#39;m fully aware of the necessity of internships/projects/self-learning, and I&amp;#39;m mostly concerned with what opportunities I&amp;#39;m limited to by my degree.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; worried about the opportunities my stats degree will offer. Looking for guidance into getting into the tech field, with a preference for data science/data engineering/software engineering.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR question:&lt;/strong&gt; How would a BS statistics degree (with lots of programming experience/projects etc.) fare in the tech job market? How important is the CS degree for getting a job compared to another STEM degree like statistics?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My situation:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I originally wanted to go into data science (like all the kids these days) and figured a stats and cs double degree would be the best bet. However, these jobs seem not only scarce and very competitive, but it seems that a straight masters degree is required for a lot of them. Something I would rather not do immediately, but would be open to in the future.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a 3rd year statistics major that just transferred to a UC from community college. I wanted to switch to computer science or add as a double major, but there were some policy changes this year that threw a wrench into my plans. I&amp;#39;ve taken 2 full series of OOP/DSA courses in both C++ and python, but didn&amp;#39;t complete computer architecture, which I need to take to switch majors and is very hard to register for as a non-major. At worst, I wouldn\u2019t be able to start the major until senior year (next fall) assuming they accept my petition\u2026 and with the current state of CS at my school it is very hard to get into. So I may be denied to do a CS degree altogether from this university. If I get lucky and am able to switch to computer science, I would likely have to stay another year, and at that point I may as well finish my stats degree and double major as it wouldn\u2019t add any extra time (1 extra quarter if it did).&lt;/p&gt;\n\n&lt;p&gt;Like I mentioned above, I&amp;#39;d ideally like to work in data science/data engineering/software engineering, but these all seems locked to just a BS stats degree. I\u2019ve heard about people starting in data analytics and then moving into data engineering or software engineering. However, in this market, I\u2019m concerned that won\u2019t be possible anymore.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My questions/options:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any recommendations for what I should do to get into the space?&lt;/p&gt;\n\n&lt;p&gt;Should I apply for data analytics jobs and then try to switch into data engineer/software engineering?&lt;/p&gt;\n\n&lt;p&gt;Should I maybe do an online school such as WGU to get a CS degree if I can&amp;#39;t get it from my university?&lt;/p&gt;\n\n&lt;p&gt;Should I go get a masters degree right after school?&lt;/p&gt;\n\n&lt;p&gt;What are my options for getting into tech if I don&amp;#39;t have a CS degree?&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading and your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ltaqz", "is_robot_indexable": true, "report_reasons": null, "author": "Aidann8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ltaqz/viability_of_an_undergraduate_statistics_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ltaqz/viability_of_an_undergraduate_statistics_degree/", "subreddit_subscribers": 137582, "created_utc": 1698891949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m in this position where I develop technical apps for non-technical business users. They tell me what they want, I evaluate if it makes business sense, and then I build it. My business users don\u2019t understand ERDs and whatnot, so I\u2019m bridging most of gap between business sense and data sense.\n\nRecently I presented some deliverables (a database and frontend for input), and the database model didn\u2019t fit the business need\u2026 it actually needed to be more denormalized because we wouldn\u2019t have this and that\u2026 yada yada.\n\nI had the bright idea of hosting a meeting where we breakdown the entire ERD and Frontend Workflow Diagram (is there a better name for that?). I wanted to make sure every little nuance was pulled out of the weeds ahead of time, and I spent a good while preparing decent documentation for this- knowing my audience was nontechnical users.\n\nLong story short, we were able to ring out some misconceptions that would have definitely cost us more time in the long run otherwise\u2026 so that\u2019s a win. At the same time, we spent 40 minutes arguing about things that don\u2019t even make sense (to an engineer). Like needing to introduce a foreign key column in an Expenses table for ProjectAttribute quantities so that Rates could be derived. It took me 40 minutes to unsuccessfully explain that the table would no longer be an \u201cExpenses\u201d table then because that broadens the scope of its PK- as an expense may have more than one association.\n\nSo, where do you usually draw the line to get that value of discussing these hard topics with nontechnical business users- but without all that added pain? Maybe something like, \u201cstop divulging once technical level reaches ERD.\u201d\n\nOr, instead of drawing a fine line in the sand, maybe there\u2019s instead a method / approach you use to keep the discussion beneficial? Such as including more drawings, meeting preview emails, \u2026 \n\nWhat\u2019s the best way to go about this?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to avoid arguing with nontechnical business users during the development process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17mi3f5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m in this position where I develop technical apps for non-technical business users. They tell me what they want, I evaluate if it makes business sense, and then I build it. My business users don\u2019t understand ERDs and whatnot, so I\u2019m bridging most of gap between business sense and data sense.&lt;/p&gt;\n\n&lt;p&gt;Recently I presented some deliverables (a database and frontend for input), and the database model didn\u2019t fit the business need\u2026 it actually needed to be more denormalized because we wouldn\u2019t have this and that\u2026 yada yada.&lt;/p&gt;\n\n&lt;p&gt;I had the bright idea of hosting a meeting where we breakdown the entire ERD and Frontend Workflow Diagram (is there a better name for that?). I wanted to make sure every little nuance was pulled out of the weeds ahead of time, and I spent a good while preparing decent documentation for this- knowing my audience was nontechnical users.&lt;/p&gt;\n\n&lt;p&gt;Long story short, we were able to ring out some misconceptions that would have definitely cost us more time in the long run otherwise\u2026 so that\u2019s a win. At the same time, we spent 40 minutes arguing about things that don\u2019t even make sense (to an engineer). Like needing to introduce a foreign key column in an Expenses table for ProjectAttribute quantities so that Rates could be derived. It took me 40 minutes to unsuccessfully explain that the table would no longer be an \u201cExpenses\u201d table then because that broadens the scope of its PK- as an expense may have more than one association.&lt;/p&gt;\n\n&lt;p&gt;So, where do you usually draw the line to get that value of discussing these hard topics with nontechnical business users- but without all that added pain? Maybe something like, \u201cstop divulging once technical level reaches ERD.\u201d&lt;/p&gt;\n\n&lt;p&gt;Or, instead of drawing a fine line in the sand, maybe there\u2019s instead a method / approach you use to keep the discussion beneficial? Such as including more drawings, meeting preview emails, \u2026 &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mi3f5", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi3f5/how_to_avoid_arguing_with_nontechnical_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi3f5/how_to_avoid_arguing_with_nontechnical_business/", "subreddit_subscribers": 137582, "created_utc": 1698970691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was thinking of deploying a new IDE to our engineering team called CodeFortress. \n\nthought of using pygame to write a top-down RPG that looks like Dwarf Fortress where I have a character that I can navigate with to enter different rooms or spaces and mine ore, harvest herbs, skin leftover animal hides and defeat mobs. \n\nEach time I complete one of those actions, there is a chance for random loot. \n\nOne idea is to have some of that random loot be productive things I need to get done at work. \n\nFor example, after a few pings of that pickaxe, not only did I receive 3x Ore but also a rare SQL optimization that I can apply to my codebase, or new metrics that have been added, or entire models created \u2014 that I can approve, modify, or publish to a remote branch \u2014 and then continue mining or questing or whatever else I was doing. \n\nQuesting becomes the new pair-programming with 5 and 10 man raids that unlock rare and epic loot. \n\nLooting an item of greater-than-uncommon value will initiate a git workflow that results in a successful merge only after merge conflicts squashed. \n\nFor an intern's commit to result in a successful merge, a /roll of 20 or greater must be achieved, otherwise bits must be spent to re-roll until the commit ultimately is successful. \n\nCode commits become completions used to train the model using the relevant prompts along the way as the user tried for a successful loot. \n\nWhere it gets really strange is that the higher level the version number of the repository, the harder it is to down bosses in raids and defeat mobs guarding resources. \n\nClient deadline estimation will be driven by the level of each of our characters. \n\nAt max level, the end game is made up of several 20-40 man raids in increasing difficulty that require weeks worth of farming and research into internal game mechanics to master. \n\nSorry boss, our frontend team keeps wiping on Lord Automagus, they can't access the loot we need to patch the latest version of our platform and our customers are blowing up the support channel asking why Dishurt is still the main tank. They demand that Benjimus main tank this fight instead.", "author_fullname": "t2_hg3enfgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lord of Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mexj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698962307.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698962103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was thinking of deploying a new IDE to our engineering team called CodeFortress. &lt;/p&gt;\n\n&lt;p&gt;thought of using pygame to write a top-down RPG that looks like Dwarf Fortress where I have a character that I can navigate with to enter different rooms or spaces and mine ore, harvest herbs, skin leftover animal hides and defeat mobs. &lt;/p&gt;\n\n&lt;p&gt;Each time I complete one of those actions, there is a chance for random loot. &lt;/p&gt;\n\n&lt;p&gt;One idea is to have some of that random loot be productive things I need to get done at work. &lt;/p&gt;\n\n&lt;p&gt;For example, after a few pings of that pickaxe, not only did I receive 3x Ore but also a rare SQL optimization that I can apply to my codebase, or new metrics that have been added, or entire models created \u2014 that I can approve, modify, or publish to a remote branch \u2014 and then continue mining or questing or whatever else I was doing. &lt;/p&gt;\n\n&lt;p&gt;Questing becomes the new pair-programming with 5 and 10 man raids that unlock rare and epic loot. &lt;/p&gt;\n\n&lt;p&gt;Looting an item of greater-than-uncommon value will initiate a git workflow that results in a successful merge only after merge conflicts squashed. &lt;/p&gt;\n\n&lt;p&gt;For an intern&amp;#39;s commit to result in a successful merge, a /roll of 20 or greater must be achieved, otherwise bits must be spent to re-roll until the commit ultimately is successful. &lt;/p&gt;\n\n&lt;p&gt;Code commits become completions used to train the model using the relevant prompts along the way as the user tried for a successful loot. &lt;/p&gt;\n\n&lt;p&gt;Where it gets really strange is that the higher level the version number of the repository, the harder it is to down bosses in raids and defeat mobs guarding resources. &lt;/p&gt;\n\n&lt;p&gt;Client deadline estimation will be driven by the level of each of our characters. &lt;/p&gt;\n\n&lt;p&gt;At max level, the end game is made up of several 20-40 man raids in increasing difficulty that require weeks worth of farming and research into internal game mechanics to master. &lt;/p&gt;\n\n&lt;p&gt;Sorry boss, our frontend team keeps wiping on Lord Automagus, they can&amp;#39;t access the loot we need to patch the latest version of our platform and our customers are blowing up the support channel asking why Dishurt is still the main tank. They demand that Benjimus main tank this fight instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17mexj6", "is_robot_indexable": true, "report_reasons": null, "author": "Salmon-Advantage", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mexj6/lord_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mexj6/lord_of_data/", "subreddit_subscribers": 137582, "created_utc": 1698962103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Q1. Does anyone have a good resource to study up on the different concepts of structuring a data warehouse? It seems to me like the dbt approach differs vastly from the Databricks medallion architecture of bronze/silver/gold layers, for example. I know that dbt has some really good docs on this subject - found [here](https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview) - in which they advocate the staging/intermediate/marts approach. I really like the way they describe the materialization choices of these as well. Underneath the intermediate and marts layers, we find the different business units (dbt_project/marts/finance) that each model is created for, for analysis.\n\nQ2. How do you structure the models that would be serving (generally speaking) more than one unit? A good example for that would be a customers model. Is this best placed in a core folder? To compare this to the medallion architecture, it seems like a customers table would be placed in and queried from the silver zone?", "author_fullname": "t2_2iwhn32y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Structuring your warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mahsn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698950566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Q1. Does anyone have a good resource to study up on the different concepts of structuring a data warehouse? It seems to me like the dbt approach differs vastly from the Databricks medallion architecture of bronze/silver/gold layers, for example. I know that dbt has some really good docs on this subject - found &lt;a href=\"https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview\"&gt;here&lt;/a&gt; - in which they advocate the staging/intermediate/marts approach. I really like the way they describe the materialization choices of these as well. Underneath the intermediate and marts layers, we find the different business units (dbt_project/marts/finance) that each model is created for, for analysis.&lt;/p&gt;\n\n&lt;p&gt;Q2. How do you structure the models that would be serving (generally speaking) more than one unit? A good example for that would be a customers model. Is this best placed in a core folder? To compare this to the medallion architecture, it seems like a customers table would be placed in and queried from the silver zone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?auto=webp&amp;s=2a89f01968bbb7160773570a5739ba364e017ebf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e39c972215449e24ba187a3b3e6d0289aad02d1b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e48b5b0440098be5b7b54dcdd6d78e80f77e948", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c583ec988ffb5d6d8292b88b38a2a7ac9fc2b799", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a97be3626c69aab79c2204db47f040a6a8bb9820", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ba90b674ccf1906f5a13abd09b27db16d203bd0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=197f95d4689989cecbdb537c3aa18035536b0c50", "width": 1080, "height": 567}], "variants": {}, "id": "KBohsdqrfvkRxfqADmI_uqtotFtqgZjYu8NQbRpJlaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mahsn", "is_robot_indexable": true, "report_reasons": null, "author": "yeykawb", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mahsn/structuring_your_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mahsn/structuring_your_warehouse/", "subreddit_subscribers": 137582, "created_utc": 1698950566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'm relatively new to Argo Workflows and have encountered a peculiar issue that I hope to get some insights on.\n\n**Background:**  \nI have Argo Workflows running on a stable K3s cluster. It was functioning smoothly until recently. After a period of two weeks without accessing Argo, I logged into the Argo Web UI and was greeted with a message about a new version of Argo being available. I clicked \"OK\" without giving it much thought.\n\n**Issue:**  \nTo my surprise, all my workflow templates and cron workflow templates were no longer listed in the UI\u2014they appeared empty. However, when I checked the Argo-related pods within Kubernetes, they were all running and have been up for 30 days. The K3s cluster itself is stable, and there are no issues with other pods.\n\n**Observation:**  \nAfter spending some time trying to figure out what was wrong, the templates and cron templates suddenly reappeared in the UI without any action on my part. This was quite baffling.\n\n**Questions:**\n\n1. Is there an auto-update feature in Argo that might have triggered this behavior?\n2. Does Argo have any form of 'hibernation' mode that could cause the templates to temporarily disappear from the UI?\n3. Could this be related to the new version notification I dismissed?\n4. Any insights or similar experiences shared would be greatly appreciated as I navigate this issue.\n\nThank you for your assistance.", "author_fullname": "t2_71zj27dw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue with Disappearing and Reappearing Templates in Argo Workflows UI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lutjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698896658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m relatively new to Argo Workflows and have encountered a peculiar issue that I hope to get some insights on.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI have Argo Workflows running on a stable K3s cluster. It was functioning smoothly until recently. After a period of two weeks without accessing Argo, I logged into the Argo Web UI and was greeted with a message about a new version of Argo being available. I clicked &amp;quot;OK&amp;quot; without giving it much thought.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Issue:&lt;/strong&gt;&lt;br/&gt;\nTo my surprise, all my workflow templates and cron workflow templates were no longer listed in the UI\u2014they appeared empty. However, when I checked the Argo-related pods within Kubernetes, they were all running and have been up for 30 days. The K3s cluster itself is stable, and there are no issues with other pods.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Observation:&lt;/strong&gt;&lt;br/&gt;\nAfter spending some time trying to figure out what was wrong, the templates and cron templates suddenly reappeared in the UI without any action on my part. This was quite baffling.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there an auto-update feature in Argo that might have triggered this behavior?&lt;/li&gt;\n&lt;li&gt;Does Argo have any form of &amp;#39;hibernation&amp;#39; mode that could cause the templates to temporarily disappear from the UI?&lt;/li&gt;\n&lt;li&gt;Could this be related to the new version notification I dismissed?&lt;/li&gt;\n&lt;li&gt;Any insights or similar experiences shared would be greatly appreciated as I navigate this issue.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you for your assistance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lutjj", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryHunt753", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lutjj/issue_with_disappearing_and_reappearing_templates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lutjj/issue_with_disappearing_and_reappearing_templates/", "subreddit_subscribers": 137582, "created_utc": 1698896658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nHave a tight deadline and struggling to figure this out as a relatively new engineer (business background).\n\nI need to compute change data for marketing customer data\u2026 the data is in the form of a materialized DBT table in bigquery. After it updates, I have a python based process that is orchestrated in dagster that creates a dataframe from that table, and compares it to a csv copy of the table from the last run. I need to format user update requests from this changed data, and send all new rows and any changed values from an existing row.\n\nI\u2019m having a bit of trouble successfully implementing this change data computation using pandas\u2026 is there any better way or best strategy to approach this?", "author_fullname": "t2_ronx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob data engineer up against it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lt848", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698891732.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Have a tight deadline and struggling to figure this out as a relatively new engineer (business background).&lt;/p&gt;\n\n&lt;p&gt;I need to compute change data for marketing customer data\u2026 the data is in the form of a materialized DBT table in bigquery. After it updates, I have a python based process that is orchestrated in dagster that creates a dataframe from that table, and compares it to a csv copy of the table from the last run. I need to format user update requests from this changed data, and send all new rows and any changed values from an existing row.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m having a bit of trouble successfully implementing this change data computation using pandas\u2026 is there any better way or best strategy to approach this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lt848", "is_robot_indexable": true, "report_reasons": null, "author": "seanpool3", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17lt848/noob_data_engineer_up_against_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lt848/noob_data_engineer_up_against_it/", "subreddit_subscribers": 137582, "created_utc": 1698891732.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Snowflake somewhat recently released dynamic tables in Snowflake, which is similar but different to materialized views. DBT added some support for it in the latest version as well.\n\nFeatures look very promising. Less effort around airflow, simplified orchestration, etc. I'm tempted to want to use these almost everywhere that I can. Where should I not use them?\n\nAlso - how are other people handling monitoring and alerting for these?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When not to use dynamic tables in Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mfljg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698963850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Snowflake somewhat recently released dynamic tables in Snowflake, which is similar but different to materialized views. DBT added some support for it in the latest version as well.&lt;/p&gt;\n\n&lt;p&gt;Features look very promising. Less effort around airflow, simplified orchestration, etc. I&amp;#39;m tempted to want to use these almost everywhere that I can. Where should I not use them?&lt;/p&gt;\n\n&lt;p&gt;Also - how are other people handling monitoring and alerting for these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mfljg", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mfljg/when_not_to_use_dynamic_tables_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mfljg/when_not_to_use_dynamic_tables_in_snowflake/", "subreddit_subscribers": 137582, "created_utc": 1698963850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am migrating from a source to databricks. I need to create workflows but I have complex dependencies in different objects. For instance a table1 is required to create table2 and table3, similarly table4 is also required to create table3. This is just simple example.\n\nThere are multiple redundant objects that are in dependency of other objects. \n\nHow should I approach this, consider number of tables is around 500 and each workflow will be used to refresh tables which are further used in dashboards. \n\nHelp me in:\n\nHow to approach and sort dependency for this number?\n\nHow can I visualize using any tool text which help me visualise using text input or excel?\n\nAny other recommendations are much appreciated.", "author_fullname": "t2_3avqegqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualize workflow dependencies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mejca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698961077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am migrating from a source to databricks. I need to create workflows but I have complex dependencies in different objects. For instance a table1 is required to create table2 and table3, similarly table4 is also required to create table3. This is just simple example.&lt;/p&gt;\n\n&lt;p&gt;There are multiple redundant objects that are in dependency of other objects. &lt;/p&gt;\n\n&lt;p&gt;How should I approach this, consider number of tables is around 500 and each workflow will be used to refresh tables which are further used in dashboards. &lt;/p&gt;\n\n&lt;p&gt;Help me in:&lt;/p&gt;\n\n&lt;p&gt;How to approach and sort dependency for this number?&lt;/p&gt;\n\n&lt;p&gt;How can I visualize using any tool text which help me visualise using text input or excel?&lt;/p&gt;\n\n&lt;p&gt;Any other recommendations are much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mejca", "is_robot_indexable": true, "report_reasons": null, "author": "saadcarnot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mejca/visualize_workflow_dependencies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mejca/visualize_workflow_dependencies/", "subreddit_subscribers": 137582, "created_utc": 1698961077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a test tool that compares data from a variety of sources, some on-premise, some in the cloud. The connection strings, test configurations and test results are all stored inside SQL tables. The tool itself is written in Python, and it uses the Windows scheduler to look at a test configuration table every minute to check if a test should run and if so, run it. Thousands of tests are carried out by this tool every day.\n\nWhat would be the best service/approach to move this tool into Azure, as a part of an initiative to move everything (including the databases) into the cloud? We really wish to get away from Windows scheduler because of reasons like time zones, maintainability, etc. We are currently subscribed to Azure Data Factory and Databricks. We are looking at Azure Functions, but it looks like having it work on multiple on-prem data sources is difficult.\n\nThanks!", "author_fullname": "t2_5eskxtx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to migrate a Python test tool application to Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m94hv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698946991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a test tool that compares data from a variety of sources, some on-premise, some in the cloud. The connection strings, test configurations and test results are all stored inside SQL tables. The tool itself is written in Python, and it uses the Windows scheduler to look at a test configuration table every minute to check if a test should run and if so, run it. Thousands of tests are carried out by this tool every day.&lt;/p&gt;\n\n&lt;p&gt;What would be the best service/approach to move this tool into Azure, as a part of an initiative to move everything (including the databases) into the cloud? We really wish to get away from Windows scheduler because of reasons like time zones, maintainability, etc. We are currently subscribed to Azure Data Factory and Databricks. We are looking at Azure Functions, but it looks like having it work on multiple on-prem data sources is difficult.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m94hv", "is_robot_indexable": true, "report_reasons": null, "author": "ashmapleleaf", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m94hv/best_way_to_migrate_a_python_test_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m94hv/best_way_to_migrate_a_python_test_tool/", "subreddit_subscribers": 137582, "created_utc": 1698946991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm having a spark cluster running in azure databricks, I want to connect my local notebook to this cluster. I have configured the databricks cli for account, and am also able to start to the cluster using the command line.\n\nIs there a way I can run my notebook locally attached with this cluster?\n\nEdit: I am using databricks connect but still not able to find how to connect to a cluster.\n\nA link for a tutorial would be great help.\n\nEdit2: I did try using vscode extension but still not able to attach the cluster, also attached the screenshot. When I click on \"Databricks connect is disabled\" then pop up comes on the down-right corner after clicking on \"Attach\", I again click on my cluster but it still does not get attached.\n\nhttps://preview.redd.it/l69lmwlgpxxb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=0a0b4f82f6be37a225e0414dc7d4c3b38b95594d", "author_fullname": "t2_d3p9cbbr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to attach a local notebook to a azure databricks cluster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l69lmwlgpxxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bcd2ebcac8cdc792567c17eff98b85eda24b551c"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=27ff430957ef06594bf99aa0b20ed22c139d6d29"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=16314bb70fe24245442ab58c006c9c25c91b1a93"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=67c18a9ac73cbdd2682e947d1f343598a66f61a5"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9ecb63a46658545a6278696de94919e243639373"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc2b5dee36195d71fda7256c354a04754b1ebcc2"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/l69lmwlgpxxb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=0a0b4f82f6be37a225e0414dc7d4c3b38b95594d"}, "id": "l69lmwlgpxxb1"}}, "name": "t3_17lxu7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lFMCWOSA52xuZmMLOMZj-Geg5tm0Gk1O3iTCvKwVDTU.jpg", "edited": 1698930854.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698908846.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having a spark cluster running in azure databricks, I want to connect my local notebook to this cluster. I have configured the databricks cli for account, and am also able to start to the cluster using the command line.&lt;/p&gt;\n\n&lt;p&gt;Is there a way I can run my notebook locally attached with this cluster?&lt;/p&gt;\n\n&lt;p&gt;Edit: I am using databricks connect but still not able to find how to connect to a cluster.&lt;/p&gt;\n\n&lt;p&gt;A link for a tutorial would be great help.&lt;/p&gt;\n\n&lt;p&gt;Edit2: I did try using vscode extension but still not able to attach the cluster, also attached the screenshot. When I click on &amp;quot;Databricks connect is disabled&amp;quot; then pop up comes on the down-right corner after clicking on &amp;quot;Attach&amp;quot;, I again click on my cluster but it still does not get attached.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/l69lmwlgpxxb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a0b4f82f6be37a225e0414dc7d4c3b38b95594d\"&gt;https://preview.redd.it/l69lmwlgpxxb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a0b4f82f6be37a225e0414dc7d4c3b38b95594d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17lxu7b", "is_robot_indexable": true, "report_reasons": null, "author": "_Data_Nerd_", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lxu7b/how_to_attach_a_local_notebook_to_a_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lxu7b/how_to_attach_a_local_notebook_to_a_azure/", "subreddit_subscribers": 137582, "created_utc": 1698908846.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're thinking about implementing the DBT / Fivetran Ad Reporting model. I was wondering if anyone had any experience with this and any advice to offer?", "author_fullname": "t2_31hl2gk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT / Fivetran Ad Reporting Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lw2eb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698901227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re thinking about implementing the DBT / Fivetran Ad Reporting model. I was wondering if anyone had any experience with this and any advice to offer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lw2eb", "is_robot_indexable": true, "report_reasons": null, "author": "Tom9274", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lw2eb/dbt_fivetran_ad_reporting_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lw2eb/dbt_fivetran_ad_reporting_model/", "subreddit_subscribers": 137582, "created_utc": 1698901227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "- What do you think about this change of role ? \n-  Could I use back end skills in DE position ?\n\nThank you for your time", "author_fullname": "t2_5fybpn5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back end dev -&gt; Data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17mi1rb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;What do you think about this change of role ? &lt;/li&gt;\n&lt;li&gt; Could I use back end skills in DE position ?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for your time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17mi1rb", "is_robot_indexable": true, "report_reasons": null, "author": "plotarch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi1rb/back_end_dev_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi1rb/back_end_dev_data_engineer/", "subreddit_subscribers": 137582, "created_utc": 1698970552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello colleagues, I have a question regarding Pentaho Data Integration, in case someone could assist me. I have 3 jobs connected in sequence. In the first one, I want to perform data extraction, in the second one, data cleaning and transformations, and in the third one, data loading into the database. When I extract the data from the CSV file in the first job, how do I pass it to the transformations inside the second job without loading the CSV again? Thank you very much in advance guys", "author_fullname": "t2_lbv5jovg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Desesperate with Pentaho Data Integration. Need help..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mej21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698961055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello colleagues, I have a question regarding Pentaho Data Integration, in case someone could assist me. I have 3 jobs connected in sequence. In the first one, I want to perform data extraction, in the second one, data cleaning and transformations, and in the third one, data loading into the database. When I extract the data from the CSV file in the first job, how do I pass it to the transformations inside the second job without loading the CSV again? Thank you very much in advance guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mej21", "is_robot_indexable": true, "report_reasons": null, "author": "Ocan23", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mej21/desesperate_with_pentaho_data_integration_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mej21/desesperate_with_pentaho_data_integration_need/", "subreddit_subscribers": 137582, "created_utc": 1698961055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One option I'm think of is using DBpedia Category list and training an model that can infer the category without having to run the DBpedia heuristics parser. And using something like this Kaggle category dataset as supervised training to train a model to predict the categories without having to run DBpedia code that runs their parser rules.\n\n[https://www.kaggle.com/datasets/danofer/dbpedia-classes](https://www.kaggle.com/datasets/danofer/dbpedia-classes)The other option, I'm think of is using Spacy MultiLabel\\_TextCategorizer to train a model with 80 categories. But I fear that 80+ categories would not perform well compare to the toy examples I've seen", "author_fullname": "t2_1h0t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on classification for Wikipedia articles and producing 80 to 300 categories (or ontology). I've looked at Spacy or NLTK or any other library. But only seen toy examples with 4-10 categories. As your category list grows does the complexity of the model need to increase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m9vx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698948994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One option I&amp;#39;m think of is using DBpedia Category list and training an model that can infer the category without having to run the DBpedia heuristics parser. And using something like this Kaggle category dataset as supervised training to train a model to predict the categories without having to run DBpedia code that runs their parser rules.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kaggle.com/datasets/danofer/dbpedia-classes\"&gt;https://www.kaggle.com/datasets/danofer/dbpedia-classes&lt;/a&gt;The other option, I&amp;#39;m think of is using Spacy MultiLabel_TextCategorizer to train a model with 80 categories. But I fear that 80+ categories would not perform well compare to the toy examples I&amp;#39;ve seen&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?auto=webp&amp;s=0d54c504a4090e06def25a5b68832f1754b7f912", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb55347925de089f4e7fb0a34354d8762e612ed8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d745fbdc9c34183017506b4055f63ccd2f9dde01", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b98350ec18ce846061c7ebcaaf0f19683865aa8", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afdfa60c73e0a87c3c2e9e996d7d2674971ec473", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e98e63b85050a14116c84e099b3ecc32c8d602b", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4cb37706de561c5280d696f4614f162d6034f2e3", "width": 1080, "height": 1080}], "variants": {}, "id": "FO3XV-QgDk9z6prdjHIqNG6zW8fQ6Osd7KTuBD5i-m8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17m9vx3", "is_robot_indexable": true, "report_reasons": null, "author": "RuairiSpain", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m9vx3/looking_for_advice_on_classification_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m9vx3/looking_for_advice_on_classification_for/", "subreddit_subscribers": 137582, "created_utc": 1698948994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI was interested in exploring Redpanda for a while and finally got to do it over the weekend. I put together this [short 5 min overview](https://www.kerno.io/blog/issue-005-redpanda) for anyone interested in getting a high-level idea of what it's all about.\n\nThis is not meant to be a deep dive or anything of the sort. I tried to add a few useful resources throughout the article if you to dig deeper if interested.  \n\n\nI hope this helps. Please let me know if I missed something that I could add.", "author_fullname": "t2_7a6mtdqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redpanda intro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m3vf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698932886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I was interested in exploring Redpanda for a while and finally got to do it over the weekend. I put together this &lt;a href=\"https://www.kerno.io/blog/issue-005-redpanda\"&gt;short 5 min overview&lt;/a&gt; for anyone interested in getting a high-level idea of what it&amp;#39;s all about.&lt;/p&gt;\n\n&lt;p&gt;This is not meant to be a deep dive or anything of the sort. I tried to add a few useful resources throughout the article if you to dig deeper if interested.  &lt;/p&gt;\n\n&lt;p&gt;I hope this helps. Please let me know if I missed something that I could add.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17m3vf0", "is_robot_indexable": true, "report_reasons": null, "author": "Fluffybaxter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m3vf0/redpanda_intro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m3vf0/redpanda_intro/", "subreddit_subscribers": 137582, "created_utc": 1698932886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Integration in the Modern Age: Adapting to Dynamic Landscapes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17m2zqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Owu1PTtzWLHjSPFqDkONsYolzVL7SKDgk2_OCEIny_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698930128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-integration-in-the-modern-age-adapting-to-dynamic-landscapes", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?auto=webp&amp;s=df9f167d1fe7fc818fc6206dc983826213f34039", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97920166977f5f4aa4bb9a1a9c7246d18c10926e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=887aa8d6de22abe50a184fb40b9e09aab787cb8e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7a2666b64cca7c7f63fa0cd9e8c131a83db22af", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39a89eb4732e9fca661fdb7ff150f2bb1f6c916a", "width": 640, "height": 336}], "variants": {}, "id": "rpkN0Tdw6HYFuZPfrapj20HrkZVXb_VPGTmpUZ89KJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m2zqw", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m2zqw/data_integration_in_the_modern_age_adapting_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-integration-in-the-modern-age-adapting-to-dynamic-landscapes", "subreddit_subscribers": 137582, "created_utc": 1698930128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm new to both Reddit and Data Engineering. I have a query. If we have a source table in Oracle DB and a target table in staging layer where data is being ingested (accessible in Databricks), what could be the approach to ensure that the data has been loaded successfully? How can we compare and ensure that there are no missing records?\n\nThank you!", "author_fullname": "t2_n1ra8paa2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0yv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698922997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to both Reddit and Data Engineering. I have a query. If we have a source table in Oracle DB and a target table in staging layer where data is being ingested (accessible in Databricks), what could be the approach to ensure that the data has been loaded successfully? How can we compare and ensure that there are no missing records?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17m0yv5", "is_robot_indexable": true, "report_reasons": null, "author": "Ultimate_t2s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0yv5/new_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0yv5/new_to_data_engineering/", "subreddit_subscribers": 137582, "created_utc": 1698922997.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}