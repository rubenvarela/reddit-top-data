{"kind": "Listing", "data": {"after": "t3_17masui", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got a demo of a new product a team is gonna implement in my company that is going to \u2018use AI to help users find data and reports\u2019. \n\nIt had nothing to do with AI. You had to manually tag every report with answers that report could answer. Then if someone\u2019s question they typed in matched a tag it would put it at the top of the search results. \n\nI asked what was the AI component of this? They said because the bot responds to the question. \n\nIt\u2019s a good reminder to try and educate business users about AI and how it isn\u2019t currently going to solve all their issues.", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Be aware of the AI snake salesman", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mi1iz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a demo of a new product a team is gonna implement in my company that is going to \u2018use AI to help users find data and reports\u2019. &lt;/p&gt;\n\n&lt;p&gt;It had nothing to do with AI. You had to manually tag every report with answers that report could answer. Then if someone\u2019s question they typed in matched a tag it would put it at the top of the search results. &lt;/p&gt;\n\n&lt;p&gt;I asked what was the AI component of this? They said because the bot responds to the question. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s a good reminder to try and educate business users about AI and how it isn\u2019t currently going to solve all their issues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mi1iz", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi1iz/be_aware_of_the_ai_snake_salesman/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi1iz/be_aware_of_the_ai_snake_salesman/", "subreddit_subscribers": 137614, "created_utc": 1698970536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been thinking about it for quite a while now.   \n\n\nWhat is the alternate for Data Engineers when it comes to upskilling and showcasing their skills.   \nLike, Developers usually have coding questions like Leetcode, Codeforces etc. \n\nWhat do the DEs have to practice or work on?   \n\n\nI've seen few companies ask LC questions as well in interviews for DE, Analyst etc and these companies are legit Fortune 500 ones. ", "author_fullname": "t2_8laf2pzn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LeetCode for Data Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0ioz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698921306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking about it for quite a while now.   &lt;/p&gt;\n\n&lt;p&gt;What is the alternate for Data Engineers when it comes to upskilling and showcasing their skills.&lt;br/&gt;\nLike, Developers usually have coding questions like Leetcode, Codeforces etc. &lt;/p&gt;\n\n&lt;p&gt;What do the DEs have to practice or work on?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen few companies ask LC questions as well in interviews for DE, Analyst etc and these companies are legit Fortune 500 ones. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m0ioz", "is_robot_indexable": true, "report_reasons": null, "author": "Key_Consideration385", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0ioz/leetcode_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0ioz/leetcode_for_data_engineers/", "subreddit_subscribers": 137614, "created_utc": 1698921306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are things that you dedicated a lot of hours to learn (through books, bootcamps...) thinking that they are going to boost your knowledge/skills in DE but that are of no use in a DE job?\n\n(learning by avoiding other people's mistakes)", "author_fullname": "t2_7mkrswyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Things you learned that were of no use. [mainly juniors-mediors]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m94wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698947023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are things that you dedicated a lot of hours to learn (through books, bootcamps...) thinking that they are going to boost your knowledge/skills in DE but that are of no use in a DE job?&lt;/p&gt;\n\n&lt;p&gt;(learning by avoiding other people&amp;#39;s mistakes)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m94wu", "is_robot_indexable": true, "report_reasons": null, "author": "Ecstatic_Tooth_1096", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m94wu/things_you_learned_that_were_of_no_use_mainly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m94wu/things_you_learned_that_were_of_no_use_mainly/", "subreddit_subscribers": 137614, "created_utc": 1698947023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone else feel a little stuck in their career progress, and if so, what are you doing about it?\n\n\n\n\n\nFor me, I've just been practicing Leetcode and system design for the past year and a half.  Not that many companies are interviewing data engineers in my area, and the companies that are hiring are paying less or are startups that seem risky to take a job offer at.\n\n\n\n\n\nI'm currently a data engineer with 5 years of experience, with 3 years at a well known tech company.  I'm in a position where I want to learn more but I'm not in a position to internally transfer teams, or apply to different companies because of the economy.  My technical skills are not improving.\n\n\n\n\nIt seems like most other jobs out there pay much less or at startups with less job security.  And to get those jobs, I would need to have a much better resume and be much better at technical interviewing just to work there.  The funny thing is, I feel better about my technical interview skills now than at any other point in my career, since I started studying in the middle of 2022 when the job market started to go get worse.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the economy have anyone else feeling stuck in their careers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m1uuo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698926378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone else feel a little stuck in their career progress, and if so, what are you doing about it?&lt;/p&gt;\n\n&lt;p&gt;For me, I&amp;#39;ve just been practicing Leetcode and system design for the past year and a half.  Not that many companies are interviewing data engineers in my area, and the companies that are hiring are paying less or are startups that seem risky to take a job offer at.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data engineer with 5 years of experience, with 3 years at a well known tech company.  I&amp;#39;m in a position where I want to learn more but I&amp;#39;m not in a position to internally transfer teams, or apply to different companies because of the economy.  My technical skills are not improving.&lt;/p&gt;\n\n&lt;p&gt;It seems like most other jobs out there pay much less or at startups with less job security.  And to get those jobs, I would need to have a much better resume and be much better at technical interviewing just to work there.  The funny thing is, I feel better about my technical interview skills now than at any other point in my career, since I started studying in the middle of 2022 when the job market started to go get worse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m1uuo", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17m1uuo/does_the_economy_have_anyone_else_feeling_stuck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m1uuo/does_the_economy_have_anyone_else_feeling_stuck/", "subreddit_subscribers": 137614, "created_utc": 1698926378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those who are new to Apache Doris, this is a technical overview of it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "name": "t3_17mlyzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oRT-9BX7TtUrvyrJ6T1Rg_ekmoWMdMgDruCJoob47VM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698982351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mawozcg5y1yb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mawozcg5y1yb1.png?auto=webp&amp;s=6d1e476d6ff7d6b4656ca21b19c8afb5406eab83", "width": 1280, "height": 654}, "resolutions": [{"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d9360ad6f87438323b29fee83ef00d6de604b0a", "width": 108, "height": 55}, {"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=71e96c360ba61fa3acad7ab3a78514278dd4442d", "width": 216, "height": 110}, {"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ee641aa68a3f32dee4437e3c1964e3606a08b88", "width": 320, "height": 163}, {"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4721c74ebe34277e12349c2ddf8c6d9aedcfb4f7", "width": 640, "height": 327}, {"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a1109473c1c03e1bef908b2629c7ef2b51d52070", "width": 960, "height": 490}, {"url": "https://preview.redd.it/mawozcg5y1yb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aeab2bb7a0b4294b3bf6b08826646daa23f12f79", "width": 1080, "height": 551}], "variants": {}, "id": "x7ASOkVao82EdOyTk14P-B8qXshCyvzWiMXSuokplxc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17mlyzp", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mlyzp/for_those_who_are_new_to_apache_doris_this_is_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mawozcg5y1yb1.png", "subreddit_subscribers": 137614, "created_utc": 1698982351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have recently made a video on how to approach system design interview round for data engineers especially for beginners. Please take a look at\nhttps://youtu.be/ceClqzlmXaM\n\nPlease let me know your comments and any specific use cases that you would like to see in future. Thanks!", "author_fullname": "t2_8vjbfemu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering System Design Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mlc8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698980355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have recently made a video on how to approach system design interview round for data engineers especially for beginners. Please take a look at\n&lt;a href=\"https://youtu.be/ceClqzlmXaM\"&gt;https://youtu.be/ceClqzlmXaM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Please let me know your comments and any specific use cases that you would like to see in future. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AefpXIpemvsuITdA3IMzIMJXbWposiJ2dESJSDOELVc.jpg?auto=webp&amp;s=09aa49e5f4f66eb6d37948457553a89b2c7afa3b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/AefpXIpemvsuITdA3IMzIMJXbWposiJ2dESJSDOELVc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6180cc96fb1847421fd2588866182551cee82d91", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/AefpXIpemvsuITdA3IMzIMJXbWposiJ2dESJSDOELVc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c8d50140f3c277f3d1e55797f727fb7344e148c6", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/AefpXIpemvsuITdA3IMzIMJXbWposiJ2dESJSDOELVc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d8fc747e21f535b5b5acb3d759b4189d4e23088", "width": 320, "height": 240}], "variants": {}, "id": "LWX2ob4xHuU05EwOoBn_8sQO6p2CWwaVpHuvHWRMSKM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17mlc8x", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Guy81", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mlc8x/data_engineering_system_design_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mlc8x/data_engineering_system_design_interview/", "subreddit_subscribers": 137614, "created_utc": 1698980355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m in this position where I develop technical apps for non-technical business users. They tell me what they want, I evaluate if it makes business sense, and then I build it. My business users don\u2019t understand ERDs and whatnot, so I\u2019m bridging most of gap between business sense and data sense.\n\nRecently I presented some deliverables (a database and frontend for input), and the database model didn\u2019t fit the business need\u2026 it actually needed to be more denormalized because we wouldn\u2019t have this and that\u2026 yada yada.\n\nI had the bright idea of hosting a meeting where we breakdown the entire ERD and Frontend Workflow Diagram (is there a better name for that?). I wanted to make sure every little nuance was pulled out of the weeds ahead of time, and I spent a good while preparing decent documentation for this- knowing my audience was nontechnical users.\n\nLong story short, we were able to ring out some misconceptions that would have definitely cost us more time in the long run otherwise\u2026 so that\u2019s a win. At the same time, we spent 40 minutes arguing about things that don\u2019t even make sense (to an engineer). Like needing to introduce a foreign key column in an Expenses table for ProjectAttribute quantities so that Rates could be derived. It took me 40 minutes to unsuccessfully explain that the table would no longer be an \u201cExpenses\u201d table then because that broadens the scope of its PK- as an expense may have more than one association.\n\nSo, where do you usually draw the line to get that value of discussing these hard topics with nontechnical business users- but without all that added pain? Maybe something like, \u201cstop divulging once technical level reaches ERD.\u201d\n\nOr, instead of drawing a fine line in the sand, maybe there\u2019s instead a method / approach you use to keep the discussion beneficial? Such as including more drawings, meeting preview emails, \u2026 \n\nWhat\u2019s the best way to go about this?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to avoid arguing with nontechnical business users during the development process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mi3f5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m in this position where I develop technical apps for non-technical business users. They tell me what they want, I evaluate if it makes business sense, and then I build it. My business users don\u2019t understand ERDs and whatnot, so I\u2019m bridging most of gap between business sense and data sense.&lt;/p&gt;\n\n&lt;p&gt;Recently I presented some deliverables (a database and frontend for input), and the database model didn\u2019t fit the business need\u2026 it actually needed to be more denormalized because we wouldn\u2019t have this and that\u2026 yada yada.&lt;/p&gt;\n\n&lt;p&gt;I had the bright idea of hosting a meeting where we breakdown the entire ERD and Frontend Workflow Diagram (is there a better name for that?). I wanted to make sure every little nuance was pulled out of the weeds ahead of time, and I spent a good while preparing decent documentation for this- knowing my audience was nontechnical users.&lt;/p&gt;\n\n&lt;p&gt;Long story short, we were able to ring out some misconceptions that would have definitely cost us more time in the long run otherwise\u2026 so that\u2019s a win. At the same time, we spent 40 minutes arguing about things that don\u2019t even make sense (to an engineer). Like needing to introduce a foreign key column in an Expenses table for ProjectAttribute quantities so that Rates could be derived. It took me 40 minutes to unsuccessfully explain that the table would no longer be an \u201cExpenses\u201d table then because that broadens the scope of its PK- as an expense may have more than one association.&lt;/p&gt;\n\n&lt;p&gt;So, where do you usually draw the line to get that value of discussing these hard topics with nontechnical business users- but without all that added pain? Maybe something like, \u201cstop divulging once technical level reaches ERD.\u201d&lt;/p&gt;\n\n&lt;p&gt;Or, instead of drawing a fine line in the sand, maybe there\u2019s instead a method / approach you use to keep the discussion beneficial? Such as including more drawings, meeting preview emails, \u2026 &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mi3f5", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi3f5/how_to_avoid_arguing_with_nontechnical_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi3f5/how_to_avoid_arguing_with_nontechnical_business/", "subreddit_subscribers": 137614, "created_utc": 1698970691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vawpw1e3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Databricks Lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0jor", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qHZMVmx8tcPF-ls1nqwhKRq4lLrm1qqjBxYCPpIDubk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698921421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/databricks-lakehouse/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?auto=webp&amp;s=55ce104c732d20006574c94135132de41e8154e7", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=46f588bdb7899ca2e25c0011bff500331216db71", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b12af7287045a8f860c5a44f9d4947534470b20", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/O5PQAdNc5ysHYu71zxTCDj-xwq-ZJyZwxXfzB4QWs7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=287348298269d0d4b247a1b0f2f7239752a46cb9", "width": 320, "height": 274}], "variants": {}, "id": "7ellfxDweEooh_Jw1w5X3I9gYXoPrVswM_cK4FhkLaA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17m0jor", "is_robot_indexable": true, "report_reasons": null, "author": "oatridbed", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0jor/getting_started_with_databricks_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/databricks-lakehouse/", "subreddit_subscribers": 137614, "created_utc": 1698921421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was thinking of deploying a new IDE to our engineering team called CodeFortress. \n\nthought of using pygame to write a top-down RPG that looks like Dwarf Fortress where I have a character that I can navigate with to enter different rooms or spaces and mine ore, harvest herbs, skin leftover animal hides and defeat mobs. \n\nEach time I complete one of those actions, there is a chance for random loot. \n\nOne idea is to have some of that random loot be productive things I need to get done at work. \n\nFor example, after a few pings of that pickaxe, not only did I receive 3x Ore but also a rare SQL optimization that I can apply to my codebase, or new metrics that have been added, or entire models created \u2014 that I can approve, modify, or publish to a remote branch \u2014 and then continue mining or questing or whatever else I was doing. \n\nQuesting becomes the new pair-programming with 5 and 10 man raids that unlock rare and epic loot. \n\nLooting an item of greater-than-uncommon value will initiate a git workflow that results in a successful merge only after merge conflicts squashed. \n\nFor an intern's commit to result in a successful merge, a /roll of 20 or greater must be achieved, otherwise bits must be spent to re-roll until the commit ultimately is successful. \n\nCode commits become completions used to train the model using the relevant prompts along the way as the user tried for a successful loot. \n\nWhere it gets really strange is that the higher level the version number of the repository, the harder it is to down bosses in raids and defeat mobs guarding resources. \n\nClient deadline estimation will be driven by the level of each of our characters. \n\nAt max level, the end game is made up of several 20-40 man raids in increasing difficulty that require weeks worth of farming and research into internal game mechanics to master. \n\nSorry boss, our frontend team keeps wiping on Lord Automagus, they can't access the loot we need to patch the latest version of our platform and our customers are blowing up the support channel asking why Dishurt is still the main tank. They demand that Benjimus main tank this fight instead.", "author_fullname": "t2_hg3enfgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lord of Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mexj6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698962307.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698962103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was thinking of deploying a new IDE to our engineering team called CodeFortress. &lt;/p&gt;\n\n&lt;p&gt;thought of using pygame to write a top-down RPG that looks like Dwarf Fortress where I have a character that I can navigate with to enter different rooms or spaces and mine ore, harvest herbs, skin leftover animal hides and defeat mobs. &lt;/p&gt;\n\n&lt;p&gt;Each time I complete one of those actions, there is a chance for random loot. &lt;/p&gt;\n\n&lt;p&gt;One idea is to have some of that random loot be productive things I need to get done at work. &lt;/p&gt;\n\n&lt;p&gt;For example, after a few pings of that pickaxe, not only did I receive 3x Ore but also a rare SQL optimization that I can apply to my codebase, or new metrics that have been added, or entire models created \u2014 that I can approve, modify, or publish to a remote branch \u2014 and then continue mining or questing or whatever else I was doing. &lt;/p&gt;\n\n&lt;p&gt;Questing becomes the new pair-programming with 5 and 10 man raids that unlock rare and epic loot. &lt;/p&gt;\n\n&lt;p&gt;Looting an item of greater-than-uncommon value will initiate a git workflow that results in a successful merge only after merge conflicts squashed. &lt;/p&gt;\n\n&lt;p&gt;For an intern&amp;#39;s commit to result in a successful merge, a /roll of 20 or greater must be achieved, otherwise bits must be spent to re-roll until the commit ultimately is successful. &lt;/p&gt;\n\n&lt;p&gt;Code commits become completions used to train the model using the relevant prompts along the way as the user tried for a successful loot. &lt;/p&gt;\n\n&lt;p&gt;Where it gets really strange is that the higher level the version number of the repository, the harder it is to down bosses in raids and defeat mobs guarding resources. &lt;/p&gt;\n\n&lt;p&gt;Client deadline estimation will be driven by the level of each of our characters. &lt;/p&gt;\n\n&lt;p&gt;At max level, the end game is made up of several 20-40 man raids in increasing difficulty that require weeks worth of farming and research into internal game mechanics to master. &lt;/p&gt;\n\n&lt;p&gt;Sorry boss, our frontend team keeps wiping on Lord Automagus, they can&amp;#39;t access the loot we need to patch the latest version of our platform and our customers are blowing up the support channel asking why Dishurt is still the main tank. They demand that Benjimus main tank this fight instead.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17mexj6", "is_robot_indexable": true, "report_reasons": null, "author": "Salmon-Advantage", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mexj6/lord_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mexj6/lord_of_data/", "subreddit_subscribers": 137614, "created_utc": 1698962103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\nI'm just starting my journey into learning Kafka, and I'm looking for some guidance on the best free resources and documentation available for beginners. Kafka seems like a fascinating technology, but I could use some help finding the right learning materials to get started.\n\nIf you have any suggestions or recommendations for online tutorials, documentation, video courses, or any other free resources that helped you learn Kafka from scratch, please share them here. I'm eager to dive into Kafka and appreciate your valuable insights!\n\n \\#Kafka#LearningResources#Beginner#Documentation#Tutorials#GettingStarted#FreeResources", "author_fullname": "t2_ttkjwcb9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for the Best Free Resources to Learn Kafka as a Beginner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0izo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698921340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just starting my journey into learning Kafka, and I&amp;#39;m looking for some guidance on the best free resources and documentation available for beginners. Kafka seems like a fascinating technology, but I could use some help finding the right learning materials to get started.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions or recommendations for online tutorials, documentation, video courses, or any other free resources that helped you learn Kafka from scratch, please share them here. I&amp;#39;m eager to dive into Kafka and appreciate your valuable insights!&lt;/p&gt;\n\n&lt;p&gt;#Kafka#LearningResources#Beginner#Documentation#Tutorials#GettingStarted#FreeResources&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17m0izo", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Woodpecker9626", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0izo/looking_for_the_best_free_resources_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0izo/looking_for_the_best_free_resources_to_learn/", "subreddit_subscribers": 137614, "created_utc": 1698921340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Q1. Does anyone have a good resource to study up on the different concepts of structuring a data warehouse? It seems to me like the dbt approach differs vastly from the Databricks medallion architecture of bronze/silver/gold layers, for example. I know that dbt has some really good docs on this subject - found [here](https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview) - in which they advocate the staging/intermediate/marts approach. I really like the way they describe the materialization choices of these as well. Underneath the intermediate and marts layers, we find the different business units (dbt_project/marts/finance) that each model is created for, for analysis.\n\nQ2. How do you structure the models that would be serving (generally speaking) more than one unit? A good example for that would be a customers model. Is this best placed in a core folder? To compare this to the medallion architecture, it seems like a customers table would be placed in and queried from the silver zone?", "author_fullname": "t2_2iwhn32y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Structuring your warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mahsn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698950566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Q1. Does anyone have a good resource to study up on the different concepts of structuring a data warehouse? It seems to me like the dbt approach differs vastly from the Databricks medallion architecture of bronze/silver/gold layers, for example. I know that dbt has some really good docs on this subject - found &lt;a href=\"https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview\"&gt;here&lt;/a&gt; - in which they advocate the staging/intermediate/marts approach. I really like the way they describe the materialization choices of these as well. Underneath the intermediate and marts layers, we find the different business units (dbt_project/marts/finance) that each model is created for, for analysis.&lt;/p&gt;\n\n&lt;p&gt;Q2. How do you structure the models that would be serving (generally speaking) more than one unit? A good example for that would be a customers model. Is this best placed in a core folder? To compare this to the medallion architecture, it seems like a customers table would be placed in and queried from the silver zone?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?auto=webp&amp;s=2a89f01968bbb7160773570a5739ba364e017ebf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e39c972215449e24ba187a3b3e6d0289aad02d1b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e48b5b0440098be5b7b54dcdd6d78e80f77e948", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c583ec988ffb5d6d8292b88b38a2a7ac9fc2b799", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a97be3626c69aab79c2204db47f040a6a8bb9820", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ba90b674ccf1906f5a13abd09b27db16d203bd0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=197f95d4689989cecbdb537c3aa18035536b0c50", "width": 1080, "height": 567}], "variants": {}, "id": "KBohsdqrfvkRxfqADmI_uqtotFtqgZjYu8NQbRpJlaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mahsn", "is_robot_indexable": true, "report_reasons": null, "author": "yeykawb", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mahsn/structuring_your_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mahsn/structuring_your_warehouse/", "subreddit_subscribers": 137614, "created_utc": 1698950566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Snowflake somewhat recently released dynamic tables in Snowflake, which is similar but different to materialized views. DBT added some support for it in the latest version as well.\n\nFeatures look very promising. Less effort around airflow, simplified orchestration, etc. I'm tempted to want to use these almost everywhere that I can. Where should I not use them?\n\nAlso - how are other people handling monitoring and alerting for these?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When not to use dynamic tables in Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mfljg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698963850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Snowflake somewhat recently released dynamic tables in Snowflake, which is similar but different to materialized views. DBT added some support for it in the latest version as well.&lt;/p&gt;\n\n&lt;p&gt;Features look very promising. Less effort around airflow, simplified orchestration, etc. I&amp;#39;m tempted to want to use these almost everywhere that I can. Where should I not use them?&lt;/p&gt;\n\n&lt;p&gt;Also - how are other people handling monitoring and alerting for these?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mfljg", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mfljg/when_not_to_use_dynamic_tables_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mfljg/when_not_to_use_dynamic_tables_in_snowflake/", "subreddit_subscribers": 137614, "created_utc": 1698963850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, as per title. Would like advice on a full time masters program based on my background. Sept 2024 intake as a late 30yo.\n\nI\u2019m currently in email marketing and enjoy the little SQL I do for the job. 1.5 YOE as a sys admin but that was a decade ago. Got the A+ &amp; CCNA at that time. I was young and got out of the industry due to freelancing (marketing) and traveling. My bachelors was in Philosophy. Have done (2) intro to python courses and the Google Data Analytics course on Coursera.\n\nMy partner also plans to do her masters in the UK and I want to get back into IT. As we are not British citizens, and coming from the Philippines, we\u2019d like to have a better quality of life in the UK.\n\nSo, we plan to go through the student route to migrate.\n\nMy question is, should I go for a conversion CS MSc to get more foundational knowledge (and perhaps applicable to more jobs) or straight into a course more data engineering-related? The end goal is finding a company who will sponsor a work visa. I would be open as well to SWE position but who knows what the job market will look like. Note that I have time so I could do/read/watch stuff before the MSc such as MOOCs. \n\nFor example,\n\nThis looks more DE-related: [https://www.bbk.ac.uk/courses/postgraduate/advanced-computing/](https://www.bbk.ac.uk/courses/postgraduate/advanced-computing/) (course modules found under \"Key Information &amp; Modules\")\n\nConversion CS: [https://www.bbk.ac.uk/courses/postgraduate/computer-science/](https://www.bbk.ac.uk/courses/postgraduate/computer-science/)\n\nThank you for your time!", "author_fullname": "t2_8b1mom94", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which MSc from the UK (in order to migrate)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ml80m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698979965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, as per title. Would like advice on a full time masters program based on my background. Sept 2024 intake as a late 30yo.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently in email marketing and enjoy the little SQL I do for the job. 1.5 YOE as a sys admin but that was a decade ago. Got the A+ &amp;amp; CCNA at that time. I was young and got out of the industry due to freelancing (marketing) and traveling. My bachelors was in Philosophy. Have done (2) intro to python courses and the Google Data Analytics course on Coursera.&lt;/p&gt;\n\n&lt;p&gt;My partner also plans to do her masters in the UK and I want to get back into IT. As we are not British citizens, and coming from the Philippines, we\u2019d like to have a better quality of life in the UK.&lt;/p&gt;\n\n&lt;p&gt;So, we plan to go through the student route to migrate.&lt;/p&gt;\n\n&lt;p&gt;My question is, should I go for a conversion CS MSc to get more foundational knowledge (and perhaps applicable to more jobs) or straight into a course more data engineering-related? The end goal is finding a company who will sponsor a work visa. I would be open as well to SWE position but who knows what the job market will look like. Note that I have time so I could do/read/watch stuff before the MSc such as MOOCs. &lt;/p&gt;\n\n&lt;p&gt;For example,&lt;/p&gt;\n\n&lt;p&gt;This looks more DE-related: &lt;a href=\"https://www.bbk.ac.uk/courses/postgraduate/advanced-computing/\"&gt;https://www.bbk.ac.uk/courses/postgraduate/advanced-computing/&lt;/a&gt; (course modules found under &amp;quot;Key Information &amp;amp; Modules&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;Conversion CS: &lt;a href=\"https://www.bbk.ac.uk/courses/postgraduate/computer-science/\"&gt;https://www.bbk.ac.uk/courses/postgraduate/computer-science/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ml80m", "is_robot_indexable": true, "report_reasons": null, "author": "InternationalAd9714", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ml80m/which_msc_from_the_uk_in_order_to_migrate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ml80m/which_msc_from_the_uk_in_order_to_migrate/", "subreddit_subscribers": 137614, "created_utc": 1698979965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Guys,\n\nMy name is Alessio and I am a student at the University of Turin. I am currently conducting a research for my thesis based on the evaluation of data pipeline software with the focus in the enterprise field.\n\nI understand that your time is valuable, but I would be extremly grateful if you could take a few minutes to respond to a short survey that will help me make informed decisions. Your opinions are crucial for my research and to identify the best software among those listed.\n\nYou can find the survey here, it is a google form: [https://forms.gle/APcom1Eizp3Js34z5](https://forms.gle/APcom1Eizp3Js34z5)\n\nIf you don't know all the five software, just evaluate the ones you're familiar with.\n\nTo show my gratitude to the community, I would like to offer you the survey results as a token of appreciation for your participation and find out what the community thinks about these software.\n\nYour contribution will be completely anonymous and will not take more than 15 minutes.\n\nThank you in advance for your participation!", "author_fullname": "t2_kx22ifsjy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best data pipeline software at the moment? Airflow vs Dagster vs NiFi vs Prefect vs Keboola", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lzwkm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698918791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Guys,&lt;/p&gt;\n\n&lt;p&gt;My name is Alessio and I am a student at the University of Turin. I am currently conducting a research for my thesis based on the evaluation of data pipeline software with the focus in the enterprise field.&lt;/p&gt;\n\n&lt;p&gt;I understand that your time is valuable, but I would be extremly grateful if you could take a few minutes to respond to a short survey that will help me make informed decisions. Your opinions are crucial for my research and to identify the best software among those listed.&lt;/p&gt;\n\n&lt;p&gt;You can find the survey here, it is a google form: &lt;a href=\"https://forms.gle/APcom1Eizp3Js34z5\"&gt;https://forms.gle/APcom1Eizp3Js34z5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you don&amp;#39;t know all the five software, just evaluate the ones you&amp;#39;re familiar with.&lt;/p&gt;\n\n&lt;p&gt;To show my gratitude to the community, I would like to offer you the survey results as a token of appreciation for your participation and find out what the community thinks about these software.&lt;/p&gt;\n\n&lt;p&gt;Your contribution will be completely anonymous and will not take more than 15 minutes.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your participation!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?auto=webp&amp;s=3219d3381d57033e78c87d562aeec0e79110e4a9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba2fdf0ac276285c9b09f897392958c7042d2b5d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6501ac6fb09aec93e4c7d7ff6f5cda0b372ec1e4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7593ed9e1c0d8e5878b676152338158a0fd954b8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3e8099be239f5e112be7fdc4757c12423fe16d93", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=929edd0789bd94751ed7fedf97362682b3b4226a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Z0OJB_Szqa_rP6lV16f_PczO7LDFEPQMDy3ITiUc5dM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ffd3b179325a733092988baad49a603677ff0021", "width": 1080, "height": 567}], "variants": {}, "id": "Li1WKefx44mxVpgeuKbJSwC4uxit4IhPi_jLoBPU-Mo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lzwkm", "is_robot_indexable": true, "report_reasons": null, "author": "Moist_Pomegranate521", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lzwkm/which_is_the_best_data_pipeline_software_at_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lzwkm/which_is_the_best_data_pipeline_software_at_the/", "subreddit_subscribers": 137614, "created_utc": 1698918791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "- What do you think about this change of role ? \n-  Could I use back end skills in DE position ?\n\nThank you for your time", "author_fullname": "t2_5fybpn5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Back end dev -&gt; Data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mi1rb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698970552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;What do you think about this change of role ? &lt;/li&gt;\n&lt;li&gt; Could I use back end skills in DE position ?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thank you for your time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17mi1rb", "is_robot_indexable": true, "report_reasons": null, "author": "plotarch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mi1rb/back_end_dev_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mi1rb/back_end_dev_data_engineer/", "subreddit_subscribers": 137614, "created_utc": 1698970552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am migrating from a source to databricks. I need to create workflows but I have complex dependencies in different objects. For instance a table1 is required to create table2 and table3, similarly table4 is also required to create table3. This is just simple example.\n\nThere are multiple redundant objects that are in dependency of other objects. \n\nHow should I approach this, consider number of tables is around 500 and each workflow will be used to refresh tables which are further used in dashboards. \n\nHelp me in:\n\nHow to approach and sort dependency for this number?\n\nHow can I visualize using any tool text which help me visualise using text input or excel?\n\nAny other recommendations are much appreciated.", "author_fullname": "t2_3avqegqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualize workflow dependencies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mejca", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698961077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am migrating from a source to databricks. I need to create workflows but I have complex dependencies in different objects. For instance a table1 is required to create table2 and table3, similarly table4 is also required to create table3. This is just simple example.&lt;/p&gt;\n\n&lt;p&gt;There are multiple redundant objects that are in dependency of other objects. &lt;/p&gt;\n\n&lt;p&gt;How should I approach this, consider number of tables is around 500 and each workflow will be used to refresh tables which are further used in dashboards. &lt;/p&gt;\n\n&lt;p&gt;Help me in:&lt;/p&gt;\n\n&lt;p&gt;How to approach and sort dependency for this number?&lt;/p&gt;\n\n&lt;p&gt;How can I visualize using any tool text which help me visualise using text input or excel?&lt;/p&gt;\n\n&lt;p&gt;Any other recommendations are much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mejca", "is_robot_indexable": true, "report_reasons": null, "author": "saadcarnot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mejca/visualize_workflow_dependencies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mejca/visualize_workflow_dependencies/", "subreddit_subscribers": 137614, "created_utc": 1698961077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a test tool that compares data from a variety of sources, some on-premise, some in the cloud. The connection strings, test configurations and test results are all stored inside SQL tables. The tool itself is written in Python, and it uses the Windows scheduler to look at a test configuration table every minute to check if a test should run and if so, run it. Thousands of tests are carried out by this tool every day.\n\nWhat would be the best service/approach to move this tool into Azure, as a part of an initiative to move everything (including the databases) into the cloud? We really wish to get away from Windows scheduler because of reasons like time zones, maintainability, etc. We are currently subscribed to Azure Data Factory and Databricks. We are looking at Azure Functions, but it looks like having it work on multiple on-prem data sources is difficult.\n\nThanks!", "author_fullname": "t2_5eskxtx2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to migrate a Python test tool application to Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m94hv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698946991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a test tool that compares data from a variety of sources, some on-premise, some in the cloud. The connection strings, test configurations and test results are all stored inside SQL tables. The tool itself is written in Python, and it uses the Windows scheduler to look at a test configuration table every minute to check if a test should run and if so, run it. Thousands of tests are carried out by this tool every day.&lt;/p&gt;\n\n&lt;p&gt;What would be the best service/approach to move this tool into Azure, as a part of an initiative to move everything (including the databases) into the cloud? We really wish to get away from Windows scheduler because of reasons like time zones, maintainability, etc. We are currently subscribed to Azure Data Factory and Databricks. We are looking at Azure Functions, but it looks like having it work on multiple on-prem data sources is difficult.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m94hv", "is_robot_indexable": true, "report_reasons": null, "author": "ashmapleleaf", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m94hv/best_way_to_migrate_a_python_test_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m94hv/best_way_to_migrate_a_python_test_tool/", "subreddit_subscribers": 137614, "created_utc": 1698946991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm new to both Reddit and Data Engineering. I have a query. If we have a source table in Oracle DB and a target table in staging layer where data is being ingested (accessible in Databricks), what could be the approach to ensure that the data has been loaded successfully? How can we compare and ensure that there are no missing records?\n\nThank you!", "author_fullname": "t2_n1ra8paa2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m0yv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698922997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to both Reddit and Data Engineering. I have a query. If we have a source table in Oracle DB and a target table in staging layer where data is being ingested (accessible in Databricks), what could be the approach to ensure that the data has been loaded successfully? How can we compare and ensure that there are no missing records?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17m0yv5", "is_robot_indexable": true, "report_reasons": null, "author": "Ultimate_t2s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m0yv5/new_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m0yv5/new_to_data_engineering/", "subreddit_subscribers": 137614, "created_utc": 1698922997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If so what\u2019s your design / architecture and what are considerations against mayve building a data platform in the cloud. If any. \n\nIdeally for big data(petabyte scale , 5min or real time updates )  also open to non.", "author_fullname": "t2_xo4dr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any y\u2019all work on data products? Ie you monitize data sets via allowing them do download a csv, but an api, or use access / toggle reporting in ui?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mpbm2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698995385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so what\u2019s your design / architecture and what are considerations against mayve building a data platform in the cloud. If any. &lt;/p&gt;\n\n&lt;p&gt;Ideally for big data(petabyte scale , 5min or real time updates )  also open to non.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17mpbm2", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mpbm2/any_yall_work_on_data_products_ie_you_monitize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mpbm2/any_yall_work_on_data_products_ie_you_monitize/", "subreddit_subscribers": 137614, "created_utc": 1698995385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello colleagues, I have a question regarding Pentaho Data Integration, in case someone could assist me. I have 3 jobs connected in sequence. In the first one, I want to perform data extraction, in the second one, data cleaning and transformations, and in the third one, data loading into the database. When I extract the data from the CSV file in the first job, how do I pass it to the transformations inside the second job without loading the CSV again? Thank you very much in advance guys", "author_fullname": "t2_lbv5jovg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Desesperate with Pentaho Data Integration. Need help..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17mej21", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698961055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello colleagues, I have a question regarding Pentaho Data Integration, in case someone could assist me. I have 3 jobs connected in sequence. In the first one, I want to perform data extraction, in the second one, data cleaning and transformations, and in the third one, data loading into the database. When I extract the data from the CSV file in the first job, how do I pass it to the transformations inside the second job without loading the CSV again? Thank you very much in advance guys&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17mej21", "is_robot_indexable": true, "report_reasons": null, "author": "Ocan23", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17mej21/desesperate_with_pentaho_data_integration_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17mej21/desesperate_with_pentaho_data_integration_need/", "subreddit_subscribers": 137614, "created_utc": 1698961055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One option I'm think of is using DBpedia Category list and training an model that can infer the category without having to run the DBpedia heuristics parser. And using something like this Kaggle category dataset as supervised training to train a model to predict the categories without having to run DBpedia code that runs their parser rules.\n\n[https://www.kaggle.com/datasets/danofer/dbpedia-classes](https://www.kaggle.com/datasets/danofer/dbpedia-classes)The other option, I'm think of is using Spacy MultiLabel\\_TextCategorizer to train a model with 80 categories. But I fear that 80+ categories would not perform well compare to the toy examples I've seen", "author_fullname": "t2_1h0t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on classification for Wikipedia articles and producing 80 to 300 categories (or ontology). I've looked at Spacy or NLTK or any other library. But only seen toy examples with 4-10 categories. As your category list grows does the complexity of the model need to increase?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m9vx3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698948994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One option I&amp;#39;m think of is using DBpedia Category list and training an model that can infer the category without having to run the DBpedia heuristics parser. And using something like this Kaggle category dataset as supervised training to train a model to predict the categories without having to run DBpedia code that runs their parser rules.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.kaggle.com/datasets/danofer/dbpedia-classes\"&gt;https://www.kaggle.com/datasets/danofer/dbpedia-classes&lt;/a&gt;The other option, I&amp;#39;m think of is using Spacy MultiLabel_TextCategorizer to train a model with 80 categories. But I fear that 80+ categories would not perform well compare to the toy examples I&amp;#39;ve seen&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?auto=webp&amp;s=0d54c504a4090e06def25a5b68832f1754b7f912", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb55347925de089f4e7fb0a34354d8762e612ed8", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d745fbdc9c34183017506b4055f63ccd2f9dde01", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b98350ec18ce846061c7ebcaaf0f19683865aa8", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afdfa60c73e0a87c3c2e9e996d7d2674971ec473", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e98e63b85050a14116c84e099b3ecc32c8d602b", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/9BLSLiEgVANnTaOwaxz350__1GIt1UbDWn1VxAeyQYI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4cb37706de561c5280d696f4614f162d6034f2e3", "width": 1080, "height": 1080}], "variants": {}, "id": "FO3XV-QgDk9z6prdjHIqNG6zW8fQ6Osd7KTuBD5i-m8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17m9vx3", "is_robot_indexable": true, "report_reasons": null, "author": "RuairiSpain", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m9vx3/looking_for_advice_on_classification_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m9vx3/looking_for_advice_on_classification_for/", "subreddit_subscribers": 137614, "created_utc": 1698948994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI was interested in exploring Redpanda for a while and finally got to do it over the weekend. I put together this [short 5 min overview](https://www.kerno.io/blog/issue-005-redpanda) for anyone interested in getting a high-level idea of what it's all about.\n\nThis is not meant to be a deep dive or anything of the sort. I tried to add a few useful resources throughout the article if you to dig deeper if interested.  \n\n\nI hope this helps. Please let me know if I missed something that I could add.", "author_fullname": "t2_7a6mtdqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redpanda intro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17m3vf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698932886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I was interested in exploring Redpanda for a while and finally got to do it over the weekend. I put together this &lt;a href=\"https://www.kerno.io/blog/issue-005-redpanda\"&gt;short 5 min overview&lt;/a&gt; for anyone interested in getting a high-level idea of what it&amp;#39;s all about.&lt;/p&gt;\n\n&lt;p&gt;This is not meant to be a deep dive or anything of the sort. I tried to add a few useful resources throughout the article if you to dig deeper if interested.  &lt;/p&gt;\n\n&lt;p&gt;I hope this helps. Please let me know if I missed something that I could add.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17m3vf0", "is_robot_indexable": true, "report_reasons": null, "author": "Fluffybaxter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m3vf0/redpanda_intro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17m3vf0/redpanda_intro/", "subreddit_subscribers": 137614, "created_utc": 1698932886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kgkprqpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Integration in the Modern Age: Adapting to Dynamic Landscapes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17m2zqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Owu1PTtzWLHjSPFqDkONsYolzVL7SKDgk2_OCEIny_8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698930128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dasca.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.dasca.org/world-of-big-data/article/data-integration-in-the-modern-age-adapting-to-dynamic-landscapes", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?auto=webp&amp;s=df9f167d1fe7fc818fc6206dc983826213f34039", "width": 800, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97920166977f5f4aa4bb9a1a9c7246d18c10926e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=887aa8d6de22abe50a184fb40b9e09aab787cb8e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7a2666b64cca7c7f63fa0cd9e8c131a83db22af", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/P-c7R50p5kHkoKnYGNas_YVdRA-iUf-cPMWwoymzlgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39a89eb4732e9fca661fdb7ff150f2bb1f6c916a", "width": 640, "height": 336}], "variants": {}, "id": "rpkN0Tdw6HYFuZPfrapj20HrkZVXb_VPGTmpUZ89KJY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17m2zqw", "is_robot_indexable": true, "report_reasons": null, "author": "Emily-joe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17m2zqw/data_integration_in_the_modern_age_adapting_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.dasca.org/world-of-big-data/article/data-integration-in-the-modern-age-adapting-to-dynamic-landscapes", "subreddit_subscribers": 137614, "created_utc": 1698930128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been refactoring a couple of dbt projects in my team lately and as part of CICD, want to include some sort of check that will tell me exactly what changed in the output table. \n\nI read about datadiff a while back but have never used it and think this might be the perfect time to. Only thing I'm not sure about is how exactly it works. For example, I have a table that refreshed daily in PRD. Someone found an issue OR I'm adding some new column/logic to adapt it to more business needs. I change the model and manually test it, dbt tests in STG also pass. Then I normally merge. Problem here is I could mess up the table or logic without knowing. I would want to include a datadiff CI test after the dbt test passes in STG. I would want to compare the entire table output to the PRD table and see all the differences (if any) to see if it breaks my model logic. \n\nHas anyone done this in their dbt projects? any tips on where to start? other easier way of doing this without datadiff", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "datadiff question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17lzi8a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698916942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been refactoring a couple of dbt projects in my team lately and as part of CICD, want to include some sort of check that will tell me exactly what changed in the output table. &lt;/p&gt;\n\n&lt;p&gt;I read about datadiff a while back but have never used it and think this might be the perfect time to. Only thing I&amp;#39;m not sure about is how exactly it works. For example, I have a table that refreshed daily in PRD. Someone found an issue OR I&amp;#39;m adding some new column/logic to adapt it to more business needs. I change the model and manually test it, dbt tests in STG also pass. Then I normally merge. Problem here is I could mess up the table or logic without knowing. I would want to include a datadiff CI test after the dbt test passes in STG. I would want to compare the entire table output to the PRD table and see all the differences (if any) to see if it breaks my model logic. &lt;/p&gt;\n\n&lt;p&gt;Has anyone done this in their dbt projects? any tips on where to start? other easier way of doing this without datadiff&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17lzi8a", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17lzi8a/datadiff_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17lzi8a/datadiff_question/", "subreddit_subscribers": 137614, "created_utc": 1698916942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.dataops.live/what-is-data-mesh](https://www.dataops.live/what-is-data-mesh)\n\nLet\u2019s Dig In to Data Mesh: Principles, Examples &amp; Best Practices. This piece explores a relatively new architectural approach that aims to solve that: data mesh.\u00a0\n\n[What is Data Mesh? ](https://preview.redd.it/ra8y5dtfezxb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=a46c5ab484bbb896d027c6aa65ba19c985ca10b4)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is Data Mesh? - The Principles, Examples, and Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ra8y5dtfezxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03845fece1c44815a52ca5f692388661e863bb55"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ff5c8da3c0f9f54f3698208b143ce9394adb760"}, {"y": 167, "x": 320, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=448bfedd04985a6f4f3265f34991bbef2123739a"}, {"y": 334, "x": 640, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=adc7210549184b113323cd1cd3831f7ba7b03c64"}, {"y": 502, "x": 960, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=842439e3b9a271d21ff4dee544e2cc1892742d6d"}, {"y": 565, "x": 1080, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02e6e48b26b722392175c9d4a839ac731f261897"}], "s": {"y": 628, "x": 1200, "u": "https://preview.redd.it/ra8y5dtfezxb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=a46c5ab484bbb896d027c6aa65ba19c985ca10b4"}, "id": "ra8y5dtfezxb1"}}, "name": "t3_17masui", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/qlwAXwvZwTx7btuBdnIXy08NZ4NYARtAQC4_wJLqSP0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698951386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.dataops.live/what-is-data-mesh\"&gt;https://www.dataops.live/what-is-data-mesh&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s Dig In to Data Mesh: Principles, Examples &amp;amp; Best Practices. This piece explores a relatively new architectural approach that aims to solve that: data mesh.\u00a0&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ra8y5dtfezxb1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a46c5ab484bbb896d027c6aa65ba19c985ca10b4\"&gt;What is Data Mesh? &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17masui", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17masui/what_is_data_mesh_the_principles_examples_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17masui/what_is_data_mesh_the_principles_examples_and/", "subreddit_subscribers": 137614, "created_utc": 1698951386.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}