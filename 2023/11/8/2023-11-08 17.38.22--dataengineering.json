{"kind": "Listing", "data": {"after": "t3_17pzepa", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m new to my team and the field this year. We\u2019ve all been working about 60 hours a week for the last 6 weeks. It seems like this may be the new norm. Is this normal in your experience?", "author_fullname": "t2_uwi4tx1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many hours do you work a week?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qa1p6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699406054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m new to my team and the field this year. We\u2019ve all been working about 60 hours a week for the last 6 weeks. It seems like this may be the new norm. Is this normal in your experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qa1p6", "is_robot_indexable": true, "report_reasons": null, "author": "HamburglerAlarmist", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qa1p6/how_many_hours_do_you_work_a_week/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qa1p6/how_many_hours_do_you_work_a_week/", "subreddit_subscribers": 138629, "created_utc": 1699406054.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been pushing back on DBT (sql on Sowflake) Pull Requests that use SELECT DISTINCT and instead ask people to create a surrogate key and aggregate/de-dupe explicitly on the keys they want to define uniqueness by. This is a lot more work. Yet, we all know the urge to SELECT DISTINCT \u201cjust in case\u201d to avoid the dreaded duplicates test error or find by a stakeholder. \n\nI find myself wondering lately if my blanket rule against SELECT DISTINCT and blocking people\u2019s work because of it, is outdated and misguided, Am I unnecessarily asking more work without enough evidence to the value add or risk mitigation? Because I\u2019ve been so strict on this my whole career (14 yrs) and my teammates along the way have also agreed, major issues resulting from its use has not come up in recent memory. \n\nBut I am now in the process of transferring the ownership of these models and reviewer pool admin to a new group who disagrees with me on this point. \n\nDoes anyone have any horror stories of how SELECT DISTINCT caused problems? Query runtimes, cost, troubleshooting issues? Or the opposite\u2014Has using SELECT DISTINCT consistently, made your life easier? I of course can do some testing myself and query plan analyses but I\u2019m also looking for anecdotes and others\u2019 experiences.", "author_fullname": "t2_yxzao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is SELECT DISTINCT really that bad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qge22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699428234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been pushing back on DBT (sql on Sowflake) Pull Requests that use SELECT DISTINCT and instead ask people to create a surrogate key and aggregate/de-dupe explicitly on the keys they want to define uniqueness by. This is a lot more work. Yet, we all know the urge to SELECT DISTINCT \u201cjust in case\u201d to avoid the dreaded duplicates test error or find by a stakeholder. &lt;/p&gt;\n\n&lt;p&gt;I find myself wondering lately if my blanket rule against SELECT DISTINCT and blocking people\u2019s work because of it, is outdated and misguided, Am I unnecessarily asking more work without enough evidence to the value add or risk mitigation? Because I\u2019ve been so strict on this my whole career (14 yrs) and my teammates along the way have also agreed, major issues resulting from its use has not come up in recent memory. &lt;/p&gt;\n\n&lt;p&gt;But I am now in the process of transferring the ownership of these models and reviewer pool admin to a new group who disagrees with me on this point. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any horror stories of how SELECT DISTINCT caused problems? Query runtimes, cost, troubleshooting issues? Or the opposite\u2014Has using SELECT DISTINCT consistently, made your life easier? I of course can do some testing myself and query plan analyses but I\u2019m also looking for anecdotes and others\u2019 experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qge22", "is_robot_indexable": true, "report_reasons": null, "author": "mrp4434", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qge22/is_select_distinct_really_that_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qge22/is_select_distinct_really_that_bad/", "subreddit_subscribers": 138629, "created_utc": 1699428234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at an org that hired a DA needing a DE. I was a DA who wanted to be a DE, so it worked out. Sadly though, nobody in the organization understands the things I talk about or what exactly I\u2019m doing when I disappear into my office for multiple days. They just recognize when the deliverables are (or aren\u2019t) as expected. That\u2019s great and all, but sometimes I just want to share my approaches and hear about other peoples projects.\n\nAnyone else in a similar boat?", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many lonely DEs here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qd6xk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699415587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at an org that hired a DA needing a DE. I was a DA who wanted to be a DE, so it worked out. Sadly though, nobody in the organization understands the things I talk about or what exactly I\u2019m doing when I disappear into my office for multiple days. They just recognize when the deliverables are (or aren\u2019t) as expected. That\u2019s great and all, but sometimes I just want to share my approaches and hear about other peoples projects.&lt;/p&gt;\n\n&lt;p&gt;Anyone else in a similar boat?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qd6xk", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qd6xk/how_many_lonely_des_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qd6xk/how_many_lonely_des_here/", "subreddit_subscribers": 138629, "created_utc": 1699415587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nAt my previous Fortune 500 company, no one EVER used temp tables. Literally never. You want data for Power BI/Looker/Tableau? You just use custom SQL and drop your query in. But at this new company, they do things completely different. They start by defining temp tables. In my current project, we have just 1 temp table selecting \\* from a table with 5 left joins. Some queries are MASSIVE, and have as many as 10-15 temp tables.\n\ntemp\\_table\\_1 AS (SELECT ...);\n\ntemp\\_table\\_2 AS (SELECT ...);\n\nBasically, they define the temp tables one after another, and then, insert them into a temporary massive table using insert. Then it's sent to architecture/DBAs, to become an official real table.\n\nAny insight why this is done?", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it unusual to consumers of data to use dozens of temp tables in their SQL queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17q8m9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699401938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my previous Fortune 500 company, no one EVER used temp tables. Literally never. You want data for Power BI/Looker/Tableau? You just use custom SQL and drop your query in. But at this new company, they do things completely different. They start by defining temp tables. In my current project, we have just 1 temp table selecting * from a table with 5 left joins. Some queries are MASSIVE, and have as many as 10-15 temp tables.&lt;/p&gt;\n\n&lt;p&gt;temp_table_1 AS (SELECT ...);&lt;/p&gt;\n\n&lt;p&gt;temp_table_2 AS (SELECT ...);&lt;/p&gt;\n\n&lt;p&gt;Basically, they define the temp tables one after another, and then, insert them into a temporary massive table using insert. Then it&amp;#39;s sent to architecture/DBAs, to become an official real table.&lt;/p&gt;\n\n&lt;p&gt;Any insight why this is done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17q8m9l", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q8m9l/is_it_unusual_to_consumers_of_data_to_use_dozens/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q8m9l/is_it_unusual_to_consumers_of_data_to_use_dozens/", "subreddit_subscribers": 138629, "created_utc": 1699401938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What would u consider are the skills of an advance data engineer? This could be a technical or non technical skills.\n\nFor me it would be\n- CI/CD on data pipelines\n- Implementing tests\n- Data Quality Checks\n- Writing maintable SQL\n\nShare your opinions", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the skills of an advance Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qlnmi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699451462.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699450143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What would u consider are the skills of an advance data engineer? This could be a technical or non technical skills.&lt;/p&gt;\n\n&lt;p&gt;For me it would be\n- CI/CD on data pipelines\n- Implementing tests\n- Data Quality Checks\n- Writing maintable SQL&lt;/p&gt;\n\n&lt;p&gt;Share your opinions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qlnmi", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qlnmi/what_are_the_skills_of_an_advance_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qlnmi/what_are_the_skills_of_an_advance_data_engineer/", "subreddit_subscribers": 138629, "created_utc": 1699450143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have plenty of experience with SQL and there are many projects that people prefer to use SQL for data transformation, doing ELT using BigQuery, for example, since it's so performatic, cheap, and you don't have to put extra pieces to it other than a scheduler/triggers. However, the queries I've built for the last years can get quite lengthy, and might be difficult to maintain, despite my best efforts to make it as simple as I can. \n\nI always end up with many CTEs and a final query. Many times I have like 8 or 10 CTEs, one depending on the other. I already thought of creating MQTs to do it \"step by step\" but then it's nothing more than splitting the same query into different steps, not sure if it would make it easier or actually more complicated.\n\nHow do you guys manage that? I have a good domain of Python and I don't have any limitations in terms of stack, but I would like to keep it as simple as it can be.", "author_fullname": "t2_l7mlroox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to better design a SQL transformation query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pzbei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699377672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have plenty of experience with SQL and there are many projects that people prefer to use SQL for data transformation, doing ELT using BigQuery, for example, since it&amp;#39;s so performatic, cheap, and you don&amp;#39;t have to put extra pieces to it other than a scheduler/triggers. However, the queries I&amp;#39;ve built for the last years can get quite lengthy, and might be difficult to maintain, despite my best efforts to make it as simple as I can. &lt;/p&gt;\n\n&lt;p&gt;I always end up with many CTEs and a final query. Many times I have like 8 or 10 CTEs, one depending on the other. I already thought of creating MQTs to do it &amp;quot;step by step&amp;quot; but then it&amp;#39;s nothing more than splitting the same query into different steps, not sure if it would make it easier or actually more complicated.&lt;/p&gt;\n\n&lt;p&gt;How do you guys manage that? I have a good domain of Python and I don&amp;#39;t have any limitations in terms of stack, but I would like to keep it as simple as it can be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17pzbei", "is_robot_indexable": true, "report_reasons": null, "author": "PaleRepresentative70", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pzbei/how_to_better_design_a_sql_transformation_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pzbei/how_to_better_design_a_sql_transformation_query/", "subreddit_subscribers": 138629, "created_utc": 1699377672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y\u2019all, \n\nI want to ask how usually companies stores the HR data in the data warehouse, I mean, the sensitive/confidential data such as the salary. \n\nYou don\u2019t want the whole data team to have access to it and the HR team are concerning how this can be done without revealing the confidentiality. \n\nThank you in advance,", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HR data in the data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qgway", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699430612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y\u2019all, &lt;/p&gt;\n\n&lt;p&gt;I want to ask how usually companies stores the HR data in the data warehouse, I mean, the sensitive/confidential data such as the salary. &lt;/p&gt;\n\n&lt;p&gt;You don\u2019t want the whole data team to have access to it and the HR team are concerning how this can be done without revealing the confidentiality. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17qgway", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qgway/hr_data_in_the_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qgway/hr_data_in_the_data_warehouse/", "subreddit_subscribers": 138629, "created_utc": 1699430612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Disclaimer**: This is a personal project I did, made possible with RPA (UiPath web scraping). The stats come from [SA Rugby](https://www.sarugby.co.za/match-centre/?teamId=e976cfc2-f80b-4c1a-8472-838cd54f0fbc&amp;returnUrl=/sa-teams-players/springboks/) website &amp; I developed automation flows to get the stats, player bio &amp; profile pictures from the same website. I used PowerQuery to transform the output &amp; to debug issues &amp; finally Tableau for visualisations.\n\nHi everyone, I'd like to share a personal project I did about the Springboks RWC Campaign.\n\nIt's match stats for all the games the Springboks played in all championships in 2023. You can see those who are consistently performing well. The stats come from [SA Rugby](https://www.sarugby.co.za/match-centre/?teamId=e976cfc2-f80b-4c1a-8472-838cd54f0fbc&amp;returnUrl=/sa-teams-players/springboks/)\n\nEach match has highlight reels &amp; tiktoks of the players' game contributions (71 total). The project also covers all the matches that the Boks under Rassie have played NZ (5 Wins, 5 Losses &amp; 1 Draw).\n\nUltimately, the project shows how tough this World Cup was &amp; the pressure the team faced, especially in the knockout phases.\n\nYou can check out the full work [Here](https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;:display_count=n&amp;:origin=viz_share_link): \n\n[https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;:display\\_count=n&amp;:origin=viz\\_share\\_link](https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;:display_count=n&amp;:origin=viz_share_link)\n\n&amp;#x200B;\n\n[Final vs NZ](https://preview.redd.it/iff83xsq23zb1.png?width=1831&amp;format=png&amp;auto=webp&amp;s=b623cba2d503fe4ebd4d2f4dc051c86929bb6d0e)\n\n&amp;#x200B;\n\n[Semi Finals vs England](https://preview.redd.it/0o7o9a2s23zb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=53f5f148ec5f0337c8a33b94f02dd27eda81794a)\n\n&amp;#x200B;\n\n[Quarter Finals vs France](https://preview.redd.it/2mwzchss23zb1.png?width=1847&amp;format=png&amp;auto=webp&amp;s=50e412eae83e1dbfcf8335e106042243f16764a5)", "author_fullname": "t2_eh40i5mp7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "South Africa 2023 RWC Campaign Stats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"iff83xsq23zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5cc86803ec4173f2fffc6a7126caa2fc305a887c"}, {"y": 109, "x": 216, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=97fbeef203186e4b9ed2ded86005b94c5276b0ee"}, {"y": 161, "x": 320, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1adde5a620d4d64bc5fee824d2dd06b0c71db3a5"}, {"y": 323, "x": 640, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2e73f427567003a6e7498ed514f8d6fd410c2cb4"}, {"y": 485, "x": 960, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=60237391d876f3a0be316306ba09c59d1d41f549"}, {"y": 546, "x": 1080, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec732708470a5eef382de1d3cd424ae43f2b8a4f"}], "s": {"y": 926, "x": 1831, "u": "https://preview.redd.it/iff83xsq23zb1.png?width=1831&amp;format=png&amp;auto=webp&amp;s=b623cba2d503fe4ebd4d2f4dc051c86929bb6d0e"}, "id": "iff83xsq23zb1"}, "0o7o9a2s23zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=deda070e1e375ef90982109e216a887dbfb0bc1a"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=667c61c2d4eb689dcfc07267f8d14fb4e6abd38b"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c1749cf0a020b99007ee9b3f2c0ade25548a685"}, {"y": 329, "x": 640, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5fd3d3c0f761f66874d00df4bfd1f0956bf8a559"}, {"y": 494, "x": 960, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=53fb1125f982b66e8b1ddaacfe1564764f5c6893"}, {"y": 555, "x": 1080, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb2e5695d10f2a75aa9a96ad1eec91bf21704af6"}], "s": {"y": 840, "x": 1632, "u": "https://preview.redd.it/0o7o9a2s23zb1.png?width=1632&amp;format=png&amp;auto=webp&amp;s=53f5f148ec5f0337c8a33b94f02dd27eda81794a"}, "id": "0o7o9a2s23zb1"}, "2mwzchss23zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9793d650f7d19e57e140e402e2276dabf1673137"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe0df1ec549a47cf23d2e3af84f04869e8cbe0bf"}, {"y": 172, "x": 320, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d4599bb62533627ce58622cd59e2b8399418c20"}, {"y": 345, "x": 640, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8106f440fcdbf19d7dae485e6d251729e136381b"}, {"y": 517, "x": 960, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0733daf871b4a036bdec02b57f74577df2e4e514"}, {"y": 582, "x": 1080, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49a1201ad8f303fd5c6cd7f40f84489cf60dd7ac"}], "s": {"y": 996, "x": 1847, "u": "https://preview.redd.it/2mwzchss23zb1.png?width=1847&amp;format=png&amp;auto=webp&amp;s=50e412eae83e1dbfcf8335e106042243f16764a5"}, "id": "2mwzchss23zb1"}}, "name": "t3_17qh4bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gYQLW7y-METdCVp7Toyju9_BDI0rjJFYM95c25uos8w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699431662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: This is a personal project I did, made possible with RPA (UiPath web scraping). The stats come from &lt;a href=\"https://www.sarugby.co.za/match-centre/?teamId=e976cfc2-f80b-4c1a-8472-838cd54f0fbc&amp;amp;returnUrl=/sa-teams-players/springboks/\"&gt;SA Rugby&lt;/a&gt; website &amp;amp; I developed automation flows to get the stats, player bio &amp;amp; profile pictures from the same website. I used PowerQuery to transform the output &amp;amp; to debug issues &amp;amp; finally Tableau for visualisations.&lt;/p&gt;\n\n&lt;p&gt;Hi everyone, I&amp;#39;d like to share a personal project I did about the Springboks RWC Campaign.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s match stats for all the games the Springboks played in all championships in 2023. You can see those who are consistently performing well. The stats come from &lt;a href=\"https://www.sarugby.co.za/match-centre/?teamId=e976cfc2-f80b-4c1a-8472-838cd54f0fbc&amp;amp;returnUrl=/sa-teams-players/springboks/\"&gt;SA Rugby&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each match has highlight reels &amp;amp; tiktoks of the players&amp;#39; game contributions (71 total). The project also covers all the matches that the Boks under Rassie have played NZ (5 Wins, 5 Losses &amp;amp; 1 Draw).&lt;/p&gt;\n\n&lt;p&gt;Ultimately, the project shows how tough this World Cup was &amp;amp; the pressure the team faced, especially in the knockout phases.&lt;/p&gt;\n\n&lt;p&gt;You can check out the full work &lt;a href=\"https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;amp;:display_count=n&amp;amp;:origin=viz_share_link\"&gt;Here&lt;/a&gt;: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;amp;:display_count=n&amp;amp;:origin=viz_share_link\"&gt;https://public.tableau.com/views/Springboks2023RugbyWorldCupCampaign/TheSpringboks2023Campaign?:language=en-US&amp;amp;:display_count=n&amp;amp;:origin=viz_share_link&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/iff83xsq23zb1.png?width=1831&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b623cba2d503fe4ebd4d2f4dc051c86929bb6d0e\"&gt;Final vs NZ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0o7o9a2s23zb1.png?width=1632&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=53f5f148ec5f0337c8a33b94f02dd27eda81794a\"&gt;Semi Finals vs England&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2mwzchss23zb1.png?width=1847&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=50e412eae83e1dbfcf8335e106042243f16764a5\"&gt;Quarter Finals vs France&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17qh4bx", "is_robot_indexable": true, "report_reasons": null, "author": "BigIntroduction4586", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qh4bx/south_africa_2023_rwc_campaign_stats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qh4bx/south_africa_2023_rwc_campaign_stats/", "subreddit_subscribers": 138629, "created_utc": 1699431662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_k91jqqv2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data broker\u2019s \u201cstaggering\u201d sale of sensitive info exposed in unsealed FTC filing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17qgsu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uZazDmteb7Xb7BtD0CbuxMcHv-erOQ5M2-MdQLP1GmA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699430169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/tech-policy/2023/11/data-brokers-staggering-sale-of-sensitive-info-exposed-in-unsealed-ftc-filing/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KjIZXLHP8rNNE0IWxMu1OIoQukcUZTIvzUUj7TtdUgY.jpg?auto=webp&amp;s=563ae2eca4d5f9817a15b884c28cffcd8074c1a2", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/KjIZXLHP8rNNE0IWxMu1OIoQukcUZTIvzUUj7TtdUgY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bed874edf7592f9402645aa24d9cee920ec35084", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/KjIZXLHP8rNNE0IWxMu1OIoQukcUZTIvzUUj7TtdUgY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b19a33b3b169b1b173cb40f1ce824f584e1f54d3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/KjIZXLHP8rNNE0IWxMu1OIoQukcUZTIvzUUj7TtdUgY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=64b3342e7dd5dc9c40e341aa2273d3ac18c94b18", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/KjIZXLHP8rNNE0IWxMu1OIoQukcUZTIvzUUj7TtdUgY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a9b3b4c17c2e1e62104e48d7550d74f6930401c0", "width": 640, "height": 320}], "variants": {}, "id": "U88NRW4BPIOX_4xBgLWcHMAUvuG6KdDVW-l64yCr05U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17qgsu8", "is_robot_indexable": true, "report_reasons": null, "author": "nipeat179", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qgsu8/data_brokers_staggering_sale_of_sensitive_info/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/tech-policy/2023/11/data-brokers-staggering-sale-of-sensitive-info-exposed-in-unsealed-ftc-filing/", "subreddit_subscribers": 138629, "created_utc": 1699430169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently became a data engineer (yay!) at a new company. At my last company, we used current and delete indicators. However, in doing some research on slowly changing dimensions I see that you can use a simple current flag = 'Y' / 'N'.\n\nTo me, a flag seems ideal so that you just need a simple current\\_flag = 'Y' compared to current\\_ind = 1 and delete\\_ind = 0 when you are querying/joining tables.\n\nAre there any reasons that the split current and delete indicators would be preferred over a flag that does it all in one field?", "author_fullname": "t2_j3ecksk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flag vs Indicators for Slowly Changing Dimensions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17q4xqs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699392316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently became a data engineer (yay!) at a new company. At my last company, we used current and delete indicators. However, in doing some research on slowly changing dimensions I see that you can use a simple current flag = &amp;#39;Y&amp;#39; / &amp;#39;N&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;To me, a flag seems ideal so that you just need a simple current_flag = &amp;#39;Y&amp;#39; compared to current_ind = 1 and delete_ind = 0 when you are querying/joining tables.&lt;/p&gt;\n\n&lt;p&gt;Are there any reasons that the split current and delete indicators would be preferred over a flag that does it all in one field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17q4xqs", "is_robot_indexable": true, "report_reasons": null, "author": "SellGameRent", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q4xqs/flag_vs_indicators_for_slowly_changing_dimensions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q4xqs/flag_vs_indicators_for_slowly_changing_dimensions/", "subreddit_subscribers": 138629, "created_utc": 1699392316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://kestra.io/blogs/2023-10-31-kestra-weaviate](https://kestra.io/blogs/2023-10-31-kestra-weaviate)", "author_fullname": "t2_7lbbuuh58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Work with Vector Databases 101", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pze8s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699377883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://kestra.io/blogs/2023-10-31-kestra-weaviate\"&gt;https://kestra.io/blogs/2023-10-31-kestra-weaviate&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17pze8s", "is_robot_indexable": true, "report_reasons": null, "author": "Round-Following1532", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pze8s/how_to_work_with_vector_databases_101/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pze8s/how_to_work_with_vector_databases_101/", "subreddit_subscribers": 138629, "created_utc": 1699377883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently trying to figure out our data strategy in the cloud and I\u2019m still trying to get answers on how much data we plan on ingesting into the data lake. Large global business so there is the potential to be a lot to ingest. I\u2019ve had experience of using Data Factory and aside from copying data from source to the bronze layer it is awful to use for transformations. \nWhat options do I have for running transformations with Python? I\u2019d like to use DataBricks but unsure whether we have *enough* data to make it worthwhile and I have some concerns on using Functions with memory and time limits, plus it must be a pain to dev with as opposed to a notebook?", "author_fullname": "t2_fd5v0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to run Python in Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qnvsh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699456764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently trying to figure out our data strategy in the cloud and I\u2019m still trying to get answers on how much data we plan on ingesting into the data lake. Large global business so there is the potential to be a lot to ingest. I\u2019ve had experience of using Data Factory and aside from copying data from source to the bronze layer it is awful to use for transformations. \nWhat options do I have for running transformations with Python? I\u2019d like to use DataBricks but unsure whether we have &lt;em&gt;enough&lt;/em&gt; data to make it worthwhile and I have some concerns on using Functions with memory and time limits, plus it must be a pain to dev with as opposed to a notebook?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17qnvsh", "is_robot_indexable": true, "report_reasons": null, "author": "12Eerc", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qnvsh/where_to_run_python_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qnvsh/where_to_run_python_in_azure/", "subreddit_subscribers": 138629, "created_utc": 1699456764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone!\n\nI designed a pipeline with sources, staging and datamart. However, users on PowerBi start joining these tables instead of exclusively using the datamart.\n\nI tried to restrict the access from their powerbi emails from project level to dataset level to the datamart.. however when they try to connect to bigquery via PowerBi desktop it they can't find any dataset.\n\nAnyone stumbled upon the same issue and found a solution?", "author_fullname": "t2_m0fkuha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BQ x PowerBi: How to Limit Available datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ql1z9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699448220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I designed a pipeline with sources, staging and datamart. However, users on PowerBi start joining these tables instead of exclusively using the datamart.&lt;/p&gt;\n\n&lt;p&gt;I tried to restrict the access from their powerbi emails from project level to dataset level to the datamart.. however when they try to connect to bigquery via PowerBi desktop it they can&amp;#39;t find any dataset.&lt;/p&gt;\n\n&lt;p&gt;Anyone stumbled upon the same issue and found a solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ql1z9", "is_robot_indexable": true, "report_reasons": null, "author": "anfawave", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ql1z9/bq_x_powerbi_how_to_limit_available_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ql1z9/bq_x_powerbi_how_to_limit_available_datasets/", "subreddit_subscribers": 138629, "created_utc": 1699448220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My background: mainly full stack web development \n\nHas anyone transitioned from web dev to data engineering before? Please share your experience and also the essential skills you picked up on the way", "author_fullname": "t2_2soroe8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from web dev to data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qcn20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699413799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My background: mainly full stack web development &lt;/p&gt;\n\n&lt;p&gt;Has anyone transitioned from web dev to data engineering before? Please share your experience and also the essential skills you picked up on the way&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qcn20", "is_robot_indexable": true, "report_reasons": null, "author": "applecidar312", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qcn20/transitioning_from_web_dev_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qcn20/transitioning_from_web_dev_to_data_engineering/", "subreddit_subscribers": 138629, "created_utc": 1699413799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5cgbpdbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incorporate Data Version Control into Your Analytics Workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_17qbmvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BNIDvg12321HEi4AbG6a0bfx7ZzhwcjmOYlv1l8QXJw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699410751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databend.rs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://databend.rs/blog/2023-11-02-databend-with-lakefs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-Xv4tX5Ggg5IidS3c5JLrBG7Z6a4cCuSM2zUysyyjQc.jpg?auto=webp&amp;s=d14c9b9a7dda9c5d09839b1edc4e18c65eb22b74", "width": 595, "height": 260}, "resolutions": [{"url": "https://external-preview.redd.it/-Xv4tX5Ggg5IidS3c5JLrBG7Z6a4cCuSM2zUysyyjQc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=547a1a3193805f150b344d009e086728d716f485", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/-Xv4tX5Ggg5IidS3c5JLrBG7Z6a4cCuSM2zUysyyjQc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=02e062253a08211c63c5c781339125a8716e30de", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/-Xv4tX5Ggg5IidS3c5JLrBG7Z6a4cCuSM2zUysyyjQc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f65273d0d74622a2b2fc0fdc82a547447853d4b4", "width": 320, "height": 139}], "variants": {}, "id": "a6UvO2SVqLWsWC0XsJy63qQHlCfy41ygQfRmuADYK4c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17qbmvd", "is_robot_indexable": true, "report_reasons": null, "author": "PsiACE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qbmvd/incorporate_data_version_control_into_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://databend.rs/blog/2023-11-02-databend-with-lakefs", "subreddit_subscribers": 138629, "created_utc": 1699410751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\n\nI recently had a recruiter reach out to me, suggesting that I could be a good fit for a middle data engineer position. Currently, I work as a data analyst/scientist, and my primary skills are in SQL, Python, statistics and analytical thinking. I've successfully passed the initial screening interview and a technical test, but there's still a technical interview looming ahead.\n\nI'm excited about the opportunity, but I'm feeling a bit anxious about some of the specific requirements for this role. The technologies that worry me include:\n\n- Building data pipelines using NiFi for ETL (Extract, Transform, Load) flows.\n- Creating Data Warehouses with Snowflake or other DW-oriented databases like Google BigQuery or Redshift.\n- Building ETL/ELT data pipelines from scratch or using existing tools, like Apache NiFi.\n- Amazon RDS experience.\n- A working knowledge of Docker.\n\nTo be honest, I don't have any hands-on experience with these technologies. My question to you all is, how challenging are these skills to minimally pick up, especially within a short timeframe? Is there a way to become familiar with them quickly, perhaps through a small personal project or specific resources you'd recommend?\n\nI'm open to any advice, suggestions, or personal experiences you can share. Thanks in advance for your help!", "author_fullname": "t2_6f2do8cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice Needed: Opportunity as a Middle Data Engineer with Limited Experience in Key Technologies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17q9l2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699404723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;I recently had a recruiter reach out to me, suggesting that I could be a good fit for a middle data engineer position. Currently, I work as a data analyst/scientist, and my primary skills are in SQL, Python, statistics and analytical thinking. I&amp;#39;ve successfully passed the initial screening interview and a technical test, but there&amp;#39;s still a technical interview looming ahead.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited about the opportunity, but I&amp;#39;m feeling a bit anxious about some of the specific requirements for this role. The technologies that worry me include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Building data pipelines using NiFi for ETL (Extract, Transform, Load) flows.&lt;/li&gt;\n&lt;li&gt;Creating Data Warehouses with Snowflake or other DW-oriented databases like Google BigQuery or Redshift.&lt;/li&gt;\n&lt;li&gt;Building ETL/ELT data pipelines from scratch or using existing tools, like Apache NiFi.&lt;/li&gt;\n&lt;li&gt;Amazon RDS experience.&lt;/li&gt;\n&lt;li&gt;A working knowledge of Docker.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To be honest, I don&amp;#39;t have any hands-on experience with these technologies. My question to you all is, how challenging are these skills to minimally pick up, especially within a short timeframe? Is there a way to become familiar with them quickly, perhaps through a small personal project or specific resources you&amp;#39;d recommend?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m open to any advice, suggestions, or personal experiences you can share. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17q9l2y", "is_robot_indexable": true, "report_reasons": null, "author": "nirvana5b", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q9l2y/advice_needed_opportunity_as_a_middle_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q9l2y/advice_needed_opportunity_as_a_middle_data/", "subreddit_subscribers": 138629, "created_utc": 1699404723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add dbt CLI autocomplete in Docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17q1ili", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "#46d160", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rdJSMgSF6FlzDp-ljmdtwOHnYryj22o2UGNrwAI7ajA.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699383435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineering.wiki", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineering.wiki/Tutorials/dbt+CLI+autocomplete+in+Docker", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?auto=webp&amp;s=2ce153cbaf58563a0599eba1ec53615eecca8a4b", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b9b1eb7feea679a40f2c06d7a2bc2436be71b41", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=781ae9f8e7c0b4342a83c6512b8cc948c5d4e7bd", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=489008b918bf7c269ef8b9933fba4131388a67c2", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff38307da678643f74717321a717d13e100cd4a7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=febc115188d63c90b44e074b7ac3344846553950", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/EnzJq0WkebYFlAg9Vn2sKCF-VGaGsFdUACPYcQQ98ng.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e7bda8cfc023e72faee6927765112883c2e0604", "width": 1080, "height": 567}], "variants": {}, "id": "toAOII9ezRnHNk9hYuZoQm1XtgMDxjuRZ7mblrksd9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17q1ili", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/17q1ili/how_to_add_dbt_cli_autocomplete_in_docker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineering.wiki/Tutorials/dbt+CLI+autocomplete+in+Docker", "subreddit_subscribers": 138629, "created_utc": 1699383435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you assess current integration processes or the ability to integrate the disjoint sources?", "author_fullname": "t2_ceoouce2p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your game plan for evaluating your current state architecture as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17qpktj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699461354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you assess current integration processes or the ability to integrate the disjoint sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17qpktj", "is_robot_indexable": true, "report_reasons": null, "author": "palomino-ridin-21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17qpktj/whats_your_game_plan_for_evaluating_your_current/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qpktj/whats_your_game_plan_for_evaluating_your_current/", "subreddit_subscribers": 138629, "created_utc": 1699461354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "OpenAI's made a series of announcements and I am more focused on the one that talks about an OpenAI Retrieval tool that doesn\u2019t require you to either create or search vectors. \n\nThe new OpenAI Retrieval tool could disrupt the need for vector-only databases by allowing direct data integration with AI models, simplifying development, reducing costs, and potentially rendering separate vector databases less essential for certain applications, leading to concerns about their future relevance. \n\nWhat do you guys think of this? ", "author_fullname": "t2_129ag6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the 'vector-only' database era at risk with OpenAI's retrieval innovation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qk7w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699445245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI&amp;#39;s made a series of announcements and I am more focused on the one that talks about an OpenAI Retrieval tool that doesn\u2019t require you to either create or search vectors. &lt;/p&gt;\n\n&lt;p&gt;The new OpenAI Retrieval tool could disrupt the need for vector-only databases by allowing direct data integration with AI models, simplifying development, reducing costs, and potentially rendering separate vector databases less essential for certain applications, leading to concerns about their future relevance. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think of this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qk7w0", "is_robot_indexable": true, "report_reasons": null, "author": "PavanBelagatti", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qk7w0/is_the_vectoronly_database_era_at_risk_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qk7w0/is_the_vectoronly_database_era_at_risk_with/", "subreddit_subscribers": 138629, "created_utc": 1699445245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here\u2019s the link to mage live tool : https://demo.mage.ai/overview", "author_fullname": "t2_udxf1u9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would you compare the recently released mage ai when compared to Orchestration tools like airflow etc?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qg6u5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699427295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here\u2019s the link to mage live tool : &lt;a href=\"https://demo.mage.ai/overview\"&gt;https://demo.mage.ai/overview&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qg6u5", "is_robot_indexable": true, "report_reasons": null, "author": "Legal_Key_7212", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qg6u5/how_would_you_compare_the_recently_released_mage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qg6u5/how_would_you_compare_the_recently_released_mage/", "subreddit_subscribers": 138629, "created_utc": 1699427295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working primarily as SQL &amp; PLSQL Developer for close to 4 years in a small service-based company.\n\nlockdowns and depression made me just do the job like chores and not look outside the scope of the tasks assigned to me. (i could even say that my SQL/PLSQL skills are not so great either. i don't know how to design a DB on my own or have a solid grasp of DB concepts like normalisation...) i just did what i was told.\n\nthe job description says ETL/DWH developer. I clearly made them understand that I know basic Python and nothing outside of the Oracle DB, but have a high-level understanding of how DWH works.\n\nthey are fine and said that i will be starting as PLSQL dev and slowly move towards Python once they decide on which tech to move from their current one.\n\nout of curiosity I also learned the basics of Numpy, Pandas (added to resume as basic NumPy, Pandas) &amp; PySpark.\n\n&amp;#x200B;\n\nthink there will be training too. am joining them in a week. but I don't wanna be too dumb.\n\nam really interested in learning now (also learning PyTorch slowly) as i don't wanna be the lazy bum i was.\n\n&amp;#x200B;\n\ni have done my fair share of search but also overwhelmed by the resources available online.\n\ncan you guys point me in the direction that makes me into a good Data Engineer?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHere's the Job description Just in case\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[JD for my new job](https://preview.redd.it/aasezodd12zb1.png?width=468&amp;format=png&amp;auto=webp&amp;s=121150509052c61f49a70b0dac8828d2911f230d)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6vn9j0vn12zb1.png?width=468&amp;format=png&amp;auto=webp&amp;s=baa6d4cbf430c5c669d5be76d80ea08f1be4b55c", "author_fullname": "t2_n2yfj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PLSQL Developer joining a new job as Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"6vn9j0vn12zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 97, "x": 108, "u": "https://preview.redd.it/6vn9j0vn12zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=94a5d8df9ba3bb7b601c4b08425f941e8c4b3bb1"}, {"y": 194, "x": 216, "u": "https://preview.redd.it/6vn9j0vn12zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cec3aea5aa1a5eb1b3f1648569c0e7cbab315d56"}, {"y": 288, "x": 320, "u": "https://preview.redd.it/6vn9j0vn12zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1ca98aa7e9c6b84da473896b26dde9e67e04442"}], "s": {"y": 422, "x": 468, "u": "https://preview.redd.it/6vn9j0vn12zb1.png?width=468&amp;format=png&amp;auto=webp&amp;s=baa6d4cbf430c5c669d5be76d80ea08f1be4b55c"}, "id": "6vn9j0vn12zb1"}, "aasezodd12zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 143, "x": 108, "u": "https://preview.redd.it/aasezodd12zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b1967f9e1f00aef81e273c5f6eddf46768692fd"}, {"y": 287, "x": 216, "u": "https://preview.redd.it/aasezodd12zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c71a6a42c5ba07dfc027b4f281ebde7e2cebf9a2"}, {"y": 425, "x": 320, "u": "https://preview.redd.it/aasezodd12zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=892308e4addb7d60ab515a1dea93961de3161e7d"}], "s": {"y": 622, "x": 468, "u": "https://preview.redd.it/aasezodd12zb1.png?width=468&amp;format=png&amp;auto=webp&amp;s=121150509052c61f49a70b0dac8828d2911f230d"}, "id": "aasezodd12zb1"}}, "name": "t3_17qe6ix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SlrXr111K_dbopM7XKZF3gEDYIc_z7Ox2AYnkW2TYfQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699419117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working primarily as SQL &amp;amp; PLSQL Developer for close to 4 years in a small service-based company.&lt;/p&gt;\n\n&lt;p&gt;lockdowns and depression made me just do the job like chores and not look outside the scope of the tasks assigned to me. (i could even say that my SQL/PLSQL skills are not so great either. i don&amp;#39;t know how to design a DB on my own or have a solid grasp of DB concepts like normalisation...) i just did what i was told.&lt;/p&gt;\n\n&lt;p&gt;the job description says ETL/DWH developer. I clearly made them understand that I know basic Python and nothing outside of the Oracle DB, but have a high-level understanding of how DWH works.&lt;/p&gt;\n\n&lt;p&gt;they are fine and said that i will be starting as PLSQL dev and slowly move towards Python once they decide on which tech to move from their current one.&lt;/p&gt;\n\n&lt;p&gt;out of curiosity I also learned the basics of Numpy, Pandas (added to resume as basic NumPy, Pandas) &amp;amp; PySpark.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;think there will be training too. am joining them in a week. but I don&amp;#39;t wanna be too dumb.&lt;/p&gt;\n\n&lt;p&gt;am really interested in learning now (also learning PyTorch slowly) as i don&amp;#39;t wanna be the lazy bum i was.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;i have done my fair share of search but also overwhelmed by the resources available online.&lt;/p&gt;\n\n&lt;p&gt;can you guys point me in the direction that makes me into a good Data Engineer?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the Job description Just in case&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aasezodd12zb1.png?width=468&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=121150509052c61f49a70b0dac8828d2911f230d\"&gt;JD for my new job&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6vn9j0vn12zb1.png?width=468&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=baa6d4cbf430c5c669d5be76d80ea08f1be4b55c\"&gt;https://preview.redd.it/6vn9j0vn12zb1.png?width=468&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=baa6d4cbf430c5c669d5be76d80ea08f1be4b55c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17qe6ix", "is_robot_indexable": true, "report_reasons": null, "author": "Globaldomination", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17qe6ix/plsql_developer_joining_a_new_job_as_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qe6ix/plsql_developer_joining_a_new_job_as_data_engineer/", "subreddit_subscribers": 138629, "created_utc": 1699419117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in a weird spot, starting a little side project to try and visually represent an orchestration piece built in ADF. A standard flowchart doesn't really work because of depth of nesting, so you effectively end up with boxes in boxes in boxes that are hard to decipher at a glance.\n\nIdeally what I'd be able to do is have the top level pipeline view represented, including the activity to execute a pipeline, in a simple flowchart style. No nesting. However, if you do want to see the activities inside a pipeline you can expand it to show the contents inside the overall flow in a larger container. Inside the container, you'd have the same simple view, with the option to expand those stages as well.\n\nMy current version is looking relatively good, but collapsing boxes is finicky at best and it's already large enough to make it hard to decipher and I am NOT done yet.\n\n&amp;#x200B;\n\nImage 1 is basically just a flowchart the same as what ADF looks like: way too simple, nowhere near enough info, especially for what's in that pipeline.\n\n[Image 1](https://preview.redd.it/m38p85z050zb1.png?width=641&amp;format=png&amp;auto=webp&amp;s=7da4a47455a4c2a362855bb35418405091e38b91)\n\nImage 2 shows how nesting starts to look early on, but with branching paths and pipelines nested several layers deep, this bloats exceptionally quick. Add another few pipelines in and very quickly things are DENSE. [draw.io](https://draw.io) does let you collapse containers, but the functionality is very limited.\n\n[Image 2](https://preview.redd.it/61kq9by350zb1.png?width=1101&amp;format=png&amp;auto=webp&amp;s=8196f248d9d918a968d4c659c30227bf27304f10)\n\nIdeally, clicking on a pipeline here would expand out to show a similar flowchart inside containing that pipeline's activities, etc.Anyone know of a tool that could enable that kind of functionallity? Anyone had experience charting a complex pipeline like this before?\n\nAny input is valuable!", "author_fullname": "t2_7sgas", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visualizing Orchestration - Is there a good tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 22, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m38p85z050zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 17, "x": 108, "u": "https://preview.redd.it/m38p85z050zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7db0fbbf07c0bdc9772cb9c3116df86037e700c"}, {"y": 34, "x": 216, "u": "https://preview.redd.it/m38p85z050zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ad724e23fb26185e0ead604f972f422fbe48a83"}, {"y": 50, "x": 320, "u": "https://preview.redd.it/m38p85z050zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dff6029d61d0c509245b8f1cacac29462aced578"}, {"y": 100, "x": 640, "u": "https://preview.redd.it/m38p85z050zb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=514073315b8455666375857636f67fd8568ccdb1"}], "s": {"y": 101, "x": 641, "u": "https://preview.redd.it/m38p85z050zb1.png?width=641&amp;format=png&amp;auto=webp&amp;s=7da4a47455a4c2a362855bb35418405091e38b91"}, "id": "m38p85z050zb1"}, "61kq9by350zb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/61kq9by350zb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7565e27f7626ac76efffbbf929fd6caae281cf12"}, {"y": 95, "x": 216, "u": "https://preview.redd.it/61kq9by350zb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e22d41ff959ddc5d5d96cce26f39f64057b5c96e"}, {"y": 141, "x": 320, "u": "https://preview.redd.it/61kq9by350zb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=688007125b14bd445f8c8838e3ca64b6baf81f8f"}, {"y": 283, "x": 640, "u": "https://preview.redd.it/61kq9by350zb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fae80009b491283f7c7d9dd36c18eb6acc65a600"}, {"y": 424, "x": 960, "u": "https://preview.redd.it/61kq9by350zb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=142223fc3d8c76fb7328b9615352a0d2a18c90dc"}, {"y": 477, "x": 1080, "u": "https://preview.redd.it/61kq9by350zb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f838ae8f1763e3a524c39b58aa1045a9dd6c2960"}], "s": {"y": 487, "x": 1101, "u": "https://preview.redd.it/61kq9by350zb1.png?width=1101&amp;format=png&amp;auto=webp&amp;s=8196f248d9d918a968d4c659c30227bf27304f10"}, "id": "61kq9by350zb1"}}, "name": "t3_17q6fdd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5To5zgeT0eTM9QrGmxJWDDWP54kWELIQIIiPXxW2lAo.jpg", "edited": 1699396272.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699396038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in a weird spot, starting a little side project to try and visually represent an orchestration piece built in ADF. A standard flowchart doesn&amp;#39;t really work because of depth of nesting, so you effectively end up with boxes in boxes in boxes that are hard to decipher at a glance.&lt;/p&gt;\n\n&lt;p&gt;Ideally what I&amp;#39;d be able to do is have the top level pipeline view represented, including the activity to execute a pipeline, in a simple flowchart style. No nesting. However, if you do want to see the activities inside a pipeline you can expand it to show the contents inside the overall flow in a larger container. Inside the container, you&amp;#39;d have the same simple view, with the option to expand those stages as well.&lt;/p&gt;\n\n&lt;p&gt;My current version is looking relatively good, but collapsing boxes is finicky at best and it&amp;#39;s already large enough to make it hard to decipher and I am NOT done yet.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Image 1 is basically just a flowchart the same as what ADF looks like: way too simple, nowhere near enough info, especially for what&amp;#39;s in that pipeline.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m38p85z050zb1.png?width=641&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7da4a47455a4c2a362855bb35418405091e38b91\"&gt;Image 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Image 2 shows how nesting starts to look early on, but with branching paths and pipelines nested several layers deep, this bloats exceptionally quick. Add another few pipelines in and very quickly things are DENSE. &lt;a href=\"https://draw.io\"&gt;draw.io&lt;/a&gt; does let you collapse containers, but the functionality is very limited.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/61kq9by350zb1.png?width=1101&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8196f248d9d918a968d4c659c30227bf27304f10\"&gt;Image 2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ideally, clicking on a pipeline here would expand out to show a similar flowchart inside containing that pipeline&amp;#39;s activities, etc.Anyone know of a tool that could enable that kind of functionallity? Anyone had experience charting a complex pipeline like this before?&lt;/p&gt;\n\n&lt;p&gt;Any input is valuable!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17q6fdd", "is_robot_indexable": true, "report_reasons": null, "author": "Whompratt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q6fdd/visualizing_orchestration_is_there_a_good_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q6fdd/visualizing_orchestration_is_there_a_good_tool/", "subreddit_subscribers": 138629, "created_utc": 1699396038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.min.io/mosip/?utm\\_source=reddit+&amp;utm\\_medium=organic-social+&amp;utm\\_campaign=mosip+](https://blog.min.io/mosip/?utm_source=reddit+&amp;utm_medium=organic-social+&amp;utm_campaign=mosip+)\n\nhttps://preview.redd.it/w1ijsgndmzyb1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=e52c81ef479bc7aae9baf83faae946ff4087059a", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Scalable, Data Sovereign National ID System", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w1ijsgndmzyb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 103, "x": 108, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=18c3864f39c91d8bd9758ed0fbf5a3fe6c8d556d"}, {"y": 206, "x": 216, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6169d9253db5d093bc7c90db6c35eb9f80afe9f4"}, {"y": 306, "x": 320, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a6b5911930c37dc00bcec08abd24713e0c2e5bcc"}, {"y": 612, "x": 640, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f518bb3efa4e62c8b6d807a8935992fe2fcceb22"}, {"y": 919, "x": 960, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3c377151c1d9f3989144d715b65ecd4d544d21a7"}, {"y": 1033, "x": 1080, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=431ab658a7be7e82b9846482e4b062c4557c44db"}], "s": {"y": 1101, "x": 1150, "u": "https://preview.redd.it/w1ijsgndmzyb1.png?width=1150&amp;format=png&amp;auto=webp&amp;s=e52c81ef479bc7aae9baf83faae946ff4087059a"}, "id": "w1ijsgndmzyb1"}}, "name": "t3_17q3yu0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ywd5h8yahmYOXSxACMz5OgEBBXcoOnkQWZ1ZQTQ18iU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1699389850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.min.io/mosip/?utm_source=reddit+&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=mosip+\"&gt;https://blog.min.io/mosip/?utm_source=reddit+&amp;amp;utm_medium=organic-social+&amp;amp;utm_campaign=mosip+&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w1ijsgndmzyb1.png?width=1150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e52c81ef479bc7aae9baf83faae946ff4087059a\"&gt;https://preview.redd.it/w1ijsgndmzyb1.png?width=1150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e52c81ef479bc7aae9baf83faae946ff4087059a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?auto=webp&amp;s=4b4f9a465ab68b351827ae2b443cb3631821c12d", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b044d18f465a7fd369da93ee5c41e3ec8195346", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b712b9ca239132ce53928ad1e2edb6d555fcb82", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=01f1dd841ddcaf369b5ab3a725813365cd7ffe32", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=355b18d8cdccdd944b0f04136aeb6a0b080a374d", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c8f03b14182e13a90fa05b45031143ba41cb08cf", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/Kbna3Wgu93HjbyEmNltDqR0yZFuO80TPX18TG1hZOAk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3beb04e91b3ba22fd11c6cc4c1a1e8b10b3ccb51", "width": 1080, "height": 322}], "variants": {}, "id": "6M8t26NfqNdDckyNMJyKB-3CyJM37h8iSo4K8gMxy1s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17q3yu0", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q3yu0/building_a_scalable_data_sovereign_national_id/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q3yu0/building_a_scalable_data_sovereign_national_id/", "subreddit_subscribers": 138629, "created_utc": 1699389850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need advice on an ingestion pattern to follow. Our company currently utilizes kafka for database replication against mssql and postgres. We are wanting to get the data from the mssql and postgres tables into databricks.\n\n**The company's recommended approach:**\n\nKafka topic streams changes from database into S3 -&gt; databricks DLT to ingest the data\n\nThis has proven to be a pain for us when initially trying to load the data, not every table has a UID, some are debezium packages, others are not. Its more complex, harder to troubleshoot, prone to failure, and not cheap.\n\n**Data eng approach:**\n\nSetup federated query against postgres and mssql to query the tables directly.\n\nWhat are some things to consider here, what are some pros and cons of each? With federated CDC coming out soon I see it being even more advantageous.", "author_fullname": "t2_81ywblydd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks: Federated Query vs Kafka cdc ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17q1vml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699384373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need advice on an ingestion pattern to follow. Our company currently utilizes kafka for database replication against mssql and postgres. We are wanting to get the data from the mssql and postgres tables into databricks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The company&amp;#39;s recommended approach:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Kafka topic streams changes from database into S3 -&amp;gt; databricks DLT to ingest the data&lt;/p&gt;\n\n&lt;p&gt;This has proven to be a pain for us when initially trying to load the data, not every table has a UID, some are debezium packages, others are not. Its more complex, harder to troubleshoot, prone to failure, and not cheap.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data eng approach:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Setup federated query against postgres and mssql to query the tables directly.&lt;/p&gt;\n\n&lt;p&gt;What are some things to consider here, what are some pros and cons of each? With federated CDC coming out soon I see it being even more advantageous.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17q1vml", "is_robot_indexable": true, "report_reasons": null, "author": "DataDoyle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17q1vml/databricks_federated_query_vs_kafka_cdc_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17q1vml/databricks_federated_query_vs_kafka_cdc_ingestion/", "subreddit_subscribers": 138629, "created_utc": 1699384373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm not sure this is within the rules but I'll try.\n\nI'm a high school student in a college-level course. We are having a career-choice assignment where we interview people in our future interests. One of mine is data engineering/science. So if anyone could answer like ten questions in dms that would be great. I don't need anything identifiable. I may not be able to get to questions in the next few hours but I'll try my best.", "author_fullname": "t2_a87umie9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Q/A interview for a school project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17pzepa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699377918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure this is within the rules but I&amp;#39;ll try.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a high school student in a college-level course. We are having a career-choice assignment where we interview people in our future interests. One of mine is data engineering/science. So if anyone could answer like ten questions in dms that would be great. I don&amp;#39;t need anything identifiable. I may not be able to get to questions in the next few hours but I&amp;#39;ll try my best.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17pzepa", "is_robot_indexable": true, "report_reasons": null, "author": "AssumptionNo5436", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17pzepa/qa_interview_for_a_school_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17pzepa/qa_interview_for_a_school_project/", "subreddit_subscribers": 138629, "created_utc": 1699377918.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}