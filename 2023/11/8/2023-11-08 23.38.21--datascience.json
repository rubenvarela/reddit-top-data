{"kind": "Listing", "data": {"after": null, "dist": 4, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I gave this talk at PyData NYC last week. It was fun working with devs from various projects (Dask, Arrow, Polars, Spark) in the week leading up to the event. Thought I'd share a re-recording of it here\n\n[https://youtu.be/wKH0-zs2g\\_U](https://youtu.be/wKH0-zs2g_U)\n\nThis is the result of a couple weeks of work comparing large data frameworks on benchmarks ranging in size 10GB to 10TB. No project wins. It's really interesting analyzing results though.\n\nDuckDB and Dask are the only projects that reliably finish things (although possibly Dask's success here has to do with me knowing Dask better than the others). DuckDB is way faster at small scale (along with Polars). Dask and Spark are generally more robust and performant at large scale, mostly because they're able to parallelize S3 access. Really-good-S3 access seems to be the way you win at real-world cloud performance.\n\nLooking more deeply at Dask results, we're wildly inefficient. There's at least a 2x-5x performance increase to be had here. Given that Dask does about as well as any other project on cloud this really means that \\*no one\\* has optimized cloud well yet.\n\nThis talk also goes into how we attempted to address bias (super hard to do in benchmarks). We had active collaborations with Polars and Spark people (made Polars quite a bit faster during this process actually). See [https://matthewrocklin.com/biased-benchmarks.html](https://matthewrocklin.com/biased-benchmarks.html) for more thoughts.\n\nThis also shows the improvement Dask made in the last six months. Dask used to suck at benchmarks. Now it doesn't win, but reliably places among the top. This is due to ...\n\n1. Arrow strings\n2. New shuffling algorithms\n3. Query optimization\n\nThere's a lot of work for projects like Dask and Polars to fix themselves up in this space. They're both moving pretty fast right now. I'm curious to see how they progress in the next few months.\n\nFor future work I'd like to expand this out a bit beyond TPC-H. TPC-H is great because they're fairly serious queries (lots of tables, lots of joins) and not micro-benchmarks. We could use broader coverage though. Any ideas?", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark, Dask, DuckDB, Polars: TPC-H Benchmarks at Scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qm6ob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699451814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I gave this talk at PyData NYC last week. It was fun working with devs from various projects (Dask, Arrow, Polars, Spark) in the week leading up to the event. Thought I&amp;#39;d share a re-recording of it here&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/wKH0-zs2g_U\"&gt;https://youtu.be/wKH0-zs2g_U&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is the result of a couple weeks of work comparing large data frameworks on benchmarks ranging in size 10GB to 10TB. No project wins. It&amp;#39;s really interesting analyzing results though.&lt;/p&gt;\n\n&lt;p&gt;DuckDB and Dask are the only projects that reliably finish things (although possibly Dask&amp;#39;s success here has to do with me knowing Dask better than the others). DuckDB is way faster at small scale (along with Polars). Dask and Spark are generally more robust and performant at large scale, mostly because they&amp;#39;re able to parallelize S3 access. Really-good-S3 access seems to be the way you win at real-world cloud performance.&lt;/p&gt;\n\n&lt;p&gt;Looking more deeply at Dask results, we&amp;#39;re wildly inefficient. There&amp;#39;s at least a 2x-5x performance increase to be had here. Given that Dask does about as well as any other project on cloud this really means that *no one* has optimized cloud well yet.&lt;/p&gt;\n\n&lt;p&gt;This talk also goes into how we attempted to address bias (super hard to do in benchmarks). We had active collaborations with Polars and Spark people (made Polars quite a bit faster during this process actually). See &lt;a href=\"https://matthewrocklin.com/biased-benchmarks.html\"&gt;https://matthewrocklin.com/biased-benchmarks.html&lt;/a&gt; for more thoughts.&lt;/p&gt;\n\n&lt;p&gt;This also shows the improvement Dask made in the last six months. Dask used to suck at benchmarks. Now it doesn&amp;#39;t win, but reliably places among the top. This is due to ...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Arrow strings&lt;/li&gt;\n&lt;li&gt;New shuffling algorithms&lt;/li&gt;\n&lt;li&gt;Query optimization&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There&amp;#39;s a lot of work for projects like Dask and Polars to fix themselves up in this space. They&amp;#39;re both moving pretty fast right now. I&amp;#39;m curious to see how they progress in the next few months.&lt;/p&gt;\n\n&lt;p&gt;For future work I&amp;#39;d like to expand this out a bit beyond TPC-H. TPC-H is great because they&amp;#39;re fairly serious queries (lots of tables, lots of joins) and not micro-benchmarks. We could use broader coverage though. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?auto=webp&amp;s=da7d0b2e1dddb9a541c5e00e32b0c0febbc324d4", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=599f0b55752f80a746571a6d0466f0cdf6c55888", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c171018f1df6b821ac69934e98ca441dddb8e196", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/GKIJFAXC5MxDvqoiFAe_JuBjYW_-SN5PG5BvuQzJVFc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f10e3936368e5aa15f9ccbf80970e40ff6a6857", "width": 320, "height": 240}], "variants": {}, "id": "NXJ6LdhKF_lKsbQSg6ourXQ88ir9X8cDbT37Oe33T6o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17qm6ob", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17qm6ob/spark_dask_duckdb_polars_tpch_benchmarks_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17qm6ob/spark_dask_duckdb_polars_tpch_benchmarks_at_scale/", "subreddit_subscribers": 1118633, "created_utc": 1699451814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys\nIs there anyone already working in the Data Science space in the sustainability/ climate change / improving agriculture in underprivileged countries.\n- If yes, how did you get it?\n- Is it actually making some positive change\n- How is the pay\n- What are skillsets other than traditional DS skillsets\n\nPS. I case across a few consulting companies like BCG, McKinsey, etc.", "author_fullname": "t2_4by5u4cw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody in Sustainability DS, how did you get?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qdw3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699418083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys\nIs there anyone already working in the Data Science space in the sustainability/ climate change / improving agriculture in underprivileged countries.\n- If yes, how did you get it?\n- Is it actually making some positive change\n- How is the pay\n- What are skillsets other than traditional DS skillsets&lt;/p&gt;\n\n&lt;p&gt;PS. I case across a few consulting companies like BCG, McKinsey, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17qdw3a", "is_robot_indexable": true, "report_reasons": null, "author": "exploring_lifenow", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17qdw3a/anybody_in_sustainability_ds_how_did_you_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17qdw3a/anybody_in_sustainability_ds_how_did_you_get/", "subreddit_subscribers": 1118633, "created_utc": 1699418083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How   important are computer science (CS) fundamentals to data science roles   at tech companies? And how central are they to the application  process?\n\nTech  companies like  Google, Meta, and Amazon offer public resources to help  job candidates  understand work life and required skills. These resources  often  describe cross-functional teams of engineers, data scientists,  etc.  Advertised roles like \"machine learning engineer\" also seem to  inhabit  the gray area between software development engineer (SDE) and  data  scientist. Of course, these companies offer tech products at huge scale, and at least for SDEs, CS knowledge is a focus.\n\nHowever,   many data science learning materials focus on the math and techniques for analyzing data and building models, with programming as essentially a  means to those ends.\n\nAs  someone  interested in exploring tech, I am wondering if formal study of  data  structures, algorithms, computational complexity, etc., should be  a  bigger part of my diet.\n\nI appreciate your answers. It's helpful to know your connection to this topic too (e.g., recruiter, fellow candidate).\n\n**EDIT:** I take it for granted that folks need to know how to write maintainable code and use programing tools like git, unit tests, etc. By CS fundamentals I am thinking of concepts or design patterns that enable software to scale efficiently. Thanks for clarifying questions.", "author_fullname": "t2_s27ul7aa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Importance of CS fundamentals for data science roles in tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qql6b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699467239.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699464103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How   important are computer science (CS) fundamentals to data science roles   at tech companies? And how central are they to the application  process?&lt;/p&gt;\n\n&lt;p&gt;Tech  companies like  Google, Meta, and Amazon offer public resources to help  job candidates  understand work life and required skills. These resources  often  describe cross-functional teams of engineers, data scientists,  etc.  Advertised roles like &amp;quot;machine learning engineer&amp;quot; also seem to  inhabit  the gray area between software development engineer (SDE) and  data  scientist. Of course, these companies offer tech products at huge scale, and at least for SDEs, CS knowledge is a focus.&lt;/p&gt;\n\n&lt;p&gt;However,   many data science learning materials focus on the math and techniques for analyzing data and building models, with programming as essentially a  means to those ends.&lt;/p&gt;\n\n&lt;p&gt;As  someone  interested in exploring tech, I am wondering if formal study of  data  structures, algorithms, computational complexity, etc., should be  a  bigger part of my diet.&lt;/p&gt;\n\n&lt;p&gt;I appreciate your answers. It&amp;#39;s helpful to know your connection to this topic too (e.g., recruiter, fellow candidate).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; I take it for granted that folks need to know how to write maintainable code and use programing tools like git, unit tests, etc. By CS fundamentals I am thinking of concepts or design patterns that enable software to scale efficiently. Thanks for clarifying questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17qql6b", "is_robot_indexable": true, "report_reasons": null, "author": "chiqui-bee", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17qql6b/importance_of_cs_fundamentals_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17qql6b/importance_of_cs_fundamentals_for_data_science/", "subreddit_subscribers": 1118633, "created_utc": 1699464103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nTLDR: stakeholders push for rapid ML development and I am going nuts keeping up.\n\nDoes anyone else have to deal with situations where you have some stakeholders that are very enthusiastic and optimistic but also want to get shit done super quickly and cheaply? Because I quit DS on this.\n\nNormally I am a DE now, but received this project where I had to take over a model. The model was completely broken. I am talking severe issues with the data, completely wrong labels and leakage between train and test sets. Regardless, this is part of their main offering and had this thing in production which unavoidably prompted clients to doubt its reliability. Lol\n\nI told them this won't fly and that we have to redo everything. Less than a month into this, I am now being pushed to at the same time add new features, train for separate labels, improve model, put it in production and so on. And I keep getting asked when x and y will happen. We are still far from a decent model but they want to make the current version inference for their clients. Smh.\n\nI have made it evident that the reason they are in this mess in the first place was because they rushed, stressed and stretched thinly the previous developer. I thought they understood the importance of doing things right but of course I see the company won't easily change its ways. On top of all this, I am dealing with execs who keep bringing new ideas...\n\nI am already with a foot out of this situation. I just wanted to ask how do you deal with this. I don't like bullshiting clients and I am also not good at giving time estimates with data science tasks. Am I just bad at this skill? Or does everyone feel like that. I feel like daily updates in this line of work are not entirely waranted. It doesn't fit Agile. I can't just tell you when (if) we will have a good model. Because of this stuff, I became completely disinterested in data science. I don't know what's considered slow or fast but I don't think in these conditions a few weeks to deliver a working ML product is enough. Besides that, I am now supposed to be DS, DS and ML at least at the same time. It is way too much... thoughts?", "author_fullname": "t2_genrcwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pushy Stakeholders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qrbcy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699466029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;TLDR: stakeholders push for rapid ML development and I am going nuts keeping up.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have to deal with situations where you have some stakeholders that are very enthusiastic and optimistic but also want to get shit done super quickly and cheaply? Because I quit DS on this.&lt;/p&gt;\n\n&lt;p&gt;Normally I am a DE now, but received this project where I had to take over a model. The model was completely broken. I am talking severe issues with the data, completely wrong labels and leakage between train and test sets. Regardless, this is part of their main offering and had this thing in production which unavoidably prompted clients to doubt its reliability. Lol&lt;/p&gt;\n\n&lt;p&gt;I told them this won&amp;#39;t fly and that we have to redo everything. Less than a month into this, I am now being pushed to at the same time add new features, train for separate labels, improve model, put it in production and so on. And I keep getting asked when x and y will happen. We are still far from a decent model but they want to make the current version inference for their clients. Smh.&lt;/p&gt;\n\n&lt;p&gt;I have made it evident that the reason they are in this mess in the first place was because they rushed, stressed and stretched thinly the previous developer. I thought they understood the importance of doing things right but of course I see the company won&amp;#39;t easily change its ways. On top of all this, I am dealing with execs who keep bringing new ideas...&lt;/p&gt;\n\n&lt;p&gt;I am already with a foot out of this situation. I just wanted to ask how do you deal with this. I don&amp;#39;t like bullshiting clients and I am also not good at giving time estimates with data science tasks. Am I just bad at this skill? Or does everyone feel like that. I feel like daily updates in this line of work are not entirely waranted. It doesn&amp;#39;t fit Agile. I can&amp;#39;t just tell you when (if) we will have a good model. Because of this stuff, I became completely disinterested in data science. I don&amp;#39;t know what&amp;#39;s considered slow or fast but I don&amp;#39;t think in these conditions a few weeks to deliver a working ML product is enough. Besides that, I am now supposed to be DS, DS and ML at least at the same time. It is way too much... thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17qrbcy", "is_robot_indexable": true, "report_reasons": null, "author": "nacho_biznis", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17qrbcy/pushy_stakeholders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17qrbcy/pushy_stakeholders/", "subreddit_subscribers": 1118633, "created_utc": 1699466029.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}