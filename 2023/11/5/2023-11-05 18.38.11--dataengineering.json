{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks! \n\nI\u2019m tasked to build a data warehouse in my company and I have two options: \n\n1- Google bigquery \n2- Postgres as a data warehouse\n\nBoth are good and will do the job for me, but not sure what to go with? (We\u2019ll only use it for analysis and reporting). \n\nAlso, I\u2019m trying to build an ecosystem around it,  any suggestions for a good practices and ETL tools is highly appreciated.\n\nThanks,", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data warehouse to pick?!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nrc7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699121039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m tasked to build a data warehouse in my company and I have two options: &lt;/p&gt;\n\n&lt;p&gt;1- Google bigquery \n2- Postgres as a data warehouse&lt;/p&gt;\n\n&lt;p&gt;Both are good and will do the job for me, but not sure what to go with? (We\u2019ll only use it for analysis and reporting). &lt;/p&gt;\n\n&lt;p&gt;Also, I\u2019m trying to build an ecosystem around it,  any suggestions for a good practices and ETL tools is highly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17nrc7o", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nrc7o/what_data_warehouse_to_pick/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nrc7o/what_data_warehouse_to_pick/", "subreddit_subscribers": 138032, "created_utc": 1699121039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was tasked with finding a solution to the following problem:\n\nThe company uses excel for everything and each department has its own set of excel files with data that might overlap. I need to put everything \"into a database\" and the end users are of course supposed to still be able to input data, but none of them know sql. There also needs to be some data validation before the data is persisted.\n\nLater only I need to be able to get that data out into a datalake.\n\nI am considering using airtables for this, but I wanted to hear whether somebody here has a different idea, be that another tool that does the same or a completely different approach.\n\nThanks!", "author_fullname": "t2_f3x6oc10q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to get rid of excel sheets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o83kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699175550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was tasked with finding a solution to the following problem:&lt;/p&gt;\n\n&lt;p&gt;The company uses excel for everything and each department has its own set of excel files with data that might overlap. I need to put everything &amp;quot;into a database&amp;quot; and the end users are of course supposed to still be able to input data, but none of them know sql. There also needs to be some data validation before the data is persisted.&lt;/p&gt;\n\n&lt;p&gt;Later only I need to be able to get that data out into a datalake.&lt;/p&gt;\n\n&lt;p&gt;I am considering using airtables for this, but I wanted to hear whether somebody here has a different idea, be that another tool that does the same or a completely different approach.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17o83kd", "is_robot_indexable": true, "report_reasons": null, "author": "RydRychards", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o83kd/tool_to_get_rid_of_excel_sheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o83kd/tool_to_get_rid_of_excel_sheets/", "subreddit_subscribers": 138032, "created_utc": 1699175550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DEs of Reddit,\n\nI am excited to share a project I have been working on in the past couple of weeks and just finished it today. I decided to build this project to better practice my recently learned skills in AWS and Apache Kafka.\n\nThe project is an end-to-end pipeline that gets flights over a region (London is the region by default) every 15 minutes from Flight Radar API, then pushes it using Lambda to a Kafka broker. Every hour, another lambda function consumes the data from Kafka (in this case, Kafka is used as both a streaming and buffering technology) and uploads the data to an S3 bucket.\n\nEach flight is recorded as a JSON file, and every hour, the consumer lambda function retrieves the data and creates a new folder in S3 that is used as a partitioning mechanism for AWS Athena which is employed to run analytics queries on the S3 bucket that holds the data (A very basic data lake). I decided to update the partitions in Athena manually because this reduces costs by 60%  compared to using AWS Glue. (Since this is a hobby project for my portfolio, my goal is to keep the costs under 8$/month).\n\n[**Github repo**](https://github.com/annis-souames/flights-metrics) with more details, if you liked the project, please give it a star!\n\nYou can also check the dashboard built using Metabase: [Dashboard](https://metabase.anniscodes.com/public/dashboard/a4247cfe-df70-4dde-8070-538eba35fd84)", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Data Engineering Project - Real Time Flights Analytics with AWS, Kafka and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nyeox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699140095.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699139891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DEs of Reddit,&lt;/p&gt;\n\n&lt;p&gt;I am excited to share a project I have been working on in the past couple of weeks and just finished it today. I decided to build this project to better practice my recently learned skills in AWS and Apache Kafka.&lt;/p&gt;\n\n&lt;p&gt;The project is an end-to-end pipeline that gets flights over a region (London is the region by default) every 15 minutes from Flight Radar API, then pushes it using Lambda to a Kafka broker. Every hour, another lambda function consumes the data from Kafka (in this case, Kafka is used as both a streaming and buffering technology) and uploads the data to an S3 bucket.&lt;/p&gt;\n\n&lt;p&gt;Each flight is recorded as a JSON file, and every hour, the consumer lambda function retrieves the data and creates a new folder in S3 that is used as a partitioning mechanism for AWS Athena which is employed to run analytics queries on the S3 bucket that holds the data (A very basic data lake). I decided to update the partitions in Athena manually because this reduces costs by 60%  compared to using AWS Glue. (Since this is a hobby project for my portfolio, my goal is to keep the costs under 8$/month).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/annis-souames/flights-metrics\"&gt;&lt;strong&gt;Github repo&lt;/strong&gt;&lt;/a&gt; with more details, if you liked the project, please give it a star!&lt;/p&gt;\n\n&lt;p&gt;You can also check the dashboard built using Metabase: &lt;a href=\"https://metabase.anniscodes.com/public/dashboard/a4247cfe-df70-4dde-8070-538eba35fd84\"&gt;Dashboard&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?auto=webp&amp;s=5e861f1c759c13f51f4c3fb0a3a67a6ad4067d16", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=719bebd956c2a042e2b14d178f165366bf1384e5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b582176efe51457be7d9cfded0093e0f7e79fcd1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f087144784d281542dc91ca23c27f5c9a1e8ccd9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=266e4c068006284b3f410c9d2a28cf1935ab7e65", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d8cdb8d2c56eafbd746fd47f4ac786a9e3be6039", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/39c2Q3dDRL1VI5Qsm88sT6eO-d_CxZHA1NB20513vHQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d14a291f3112468cedf51f67ed42c7a657fb416c", "width": 1080, "height": 540}], "variants": {}, "id": "dH2qnN4-inOKiK5ZfMtFXSodUHNNrwHJi-mNU8AKUFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17nyeox", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nyeox/first_data_engineering_project_real_time_flights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nyeox/first_data_engineering_project_real_time_flights/", "subreddit_subscribers": 138032, "created_utc": 1699139891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve always wanted to participate in hackathons, but find it difficult to imagine how I\u2019d help, considering most of my skills are in building infrastructure to process large amounts of data\n\nHackathons seem to be mostly machine learning (I have little knowledge) or frontend engineering with what I imagine to be very simple APIs in the background (that often are just wrappers for ML models lol)\n\nGiven that info, I don\u2019t know how I (or other DEs) can participate in hackathons", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can a data engineer contribute at a hackathon?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nv4xv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699130992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve always wanted to participate in hackathons, but find it difficult to imagine how I\u2019d help, considering most of my skills are in building infrastructure to process large amounts of data&lt;/p&gt;\n\n&lt;p&gt;Hackathons seem to be mostly machine learning (I have little knowledge) or frontend engineering with what I imagine to be very simple APIs in the background (that often are just wrappers for ML models lol)&lt;/p&gt;\n\n&lt;p&gt;Given that info, I don\u2019t know how I (or other DEs) can participate in hackathons&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17nv4xv", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nv4xv/how_can_a_data_engineer_contribute_at_a_hackathon/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nv4xv/how_can_a_data_engineer_contribute_at_a_hackathon/", "subreddit_subscribers": 138032, "created_utc": 1699130992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After working in this industry for 10+ years, I strongly feel like the data engineering space has a title problem. Data Science also has this issue, but I believe in Data Engineering it is even worse. Companies release vacancies for \"data engineer\" when the role can mean so many different things.\n\nI feel like a new set of titles is required to make the industry more mature. Such as:\n\n1. **Analytics Engineer (AE)**: Previously the data warehouse developer. Mainly works with SQL, Airflow, Python to transform data within the data warehouse. Person building analytics pipelines. A lot of DE work falls here.\n2. **Data Platform Engineer (DPE)**: An engineer who works on the platform, but not the pipelines. Cross-over with cloud engineer and dev/ops.\n3. **Data Streaming Engineer (DSE):** Specialized in data streaming, specifically; coding and patterns here are an entirely different ballgame from all of the above.\n\nToo many times I see companies ask for \"Data Engineer\" - expecting an analytics engineer with enough experience to do what the DPE does. Or companies who mainly to DSE, and end up with too many AEs in the pipeline.\n\nSome companies get this right by specifying that there is a \"focus\" area for a DE role. For example, Data Engineers with a heavy cloud focus, or Data Engineers focused on streaming (sometimes also called Big Data Engineer).\n\nMore specific DE roles would help both candidates and companies. Ideally the DE title should disappear completely and have several different roles falling under it.\n\n&amp;#x200B;\n\nWhat is your opinion? What titles would you propose?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_j3gqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion: Data Engineering has a title problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17oe4z2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699197627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After working in this industry for 10+ years, I strongly feel like the data engineering space has a title problem. Data Science also has this issue, but I believe in Data Engineering it is even worse. Companies release vacancies for &amp;quot;data engineer&amp;quot; when the role can mean so many different things.&lt;/p&gt;\n\n&lt;p&gt;I feel like a new set of titles is required to make the industry more mature. Such as:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Analytics Engineer (AE)&lt;/strong&gt;: Previously the data warehouse developer. Mainly works with SQL, Airflow, Python to transform data within the data warehouse. Person building analytics pipelines. A lot of DE work falls here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Platform Engineer (DPE)&lt;/strong&gt;: An engineer who works on the platform, but not the pipelines. Cross-over with cloud engineer and dev/ops.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Streaming Engineer (DSE):&lt;/strong&gt; Specialized in data streaming, specifically; coding and patterns here are an entirely different ballgame from all of the above.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Too many times I see companies ask for &amp;quot;Data Engineer&amp;quot; - expecting an analytics engineer with enough experience to do what the DPE does. Or companies who mainly to DSE, and end up with too many AEs in the pipeline.&lt;/p&gt;\n\n&lt;p&gt;Some companies get this right by specifying that there is a &amp;quot;focus&amp;quot; area for a DE role. For example, Data Engineers with a heavy cloud focus, or Data Engineers focused on streaming (sometimes also called Big Data Engineer).&lt;/p&gt;\n\n&lt;p&gt;More specific DE roles would help both candidates and companies. Ideally the DE title should disappear completely and have several different roles falling under it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is your opinion? What titles would you propose?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17oe4z2", "is_robot_indexable": true, "report_reasons": null, "author": "exact-approximate", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17oe4z2/discussion_data_engineering_has_a_title_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17oe4z2/discussion_data_engineering_has_a_title_problem/", "subreddit_subscribers": 138032, "created_utc": 1699197627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, relatively new to data engineering and our orgs data maturity is still pretty low. We use Snowflake and have views set up for our use case. We\u2019re not mature enough to use anything like dbt, spark or airflow so we handle all transformations in the view (it\u2019s not a ton of data). These are usually maintained by shared worksheets, but I\u2019ve been reading here that we should really version control these and introduce git into our workflow.\n\nMy question is how do we really get started with this? I understand git, but what should an ideal workflow look like?", "author_fullname": "t2_6pkcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you version control Snowflake queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o9yss", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699183987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, relatively new to data engineering and our orgs data maturity is still pretty low. We use Snowflake and have views set up for our use case. We\u2019re not mature enough to use anything like dbt, spark or airflow so we handle all transformations in the view (it\u2019s not a ton of data). These are usually maintained by shared worksheets, but I\u2019ve been reading here that we should really version control these and introduce git into our workflow.&lt;/p&gt;\n\n&lt;p&gt;My question is how do we really get started with this? I understand git, but what should an ideal workflow look like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17o9yss", "is_robot_indexable": true, "report_reasons": null, "author": "PablanoPato", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o9yss/how_do_you_version_control_snowflake_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o9yss/how_do_you_version_control_snowflake_queries/", "subreddit_subscribers": 138032, "created_utc": 1699183987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering other peoples work development environment for using Spark. \n\nMy team is using VSCode and just python script. (Not using Jupyter Notebook)\n\nAnyone there who can share your development environment?", "author_fullname": "t2_exfd2a9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your actual work, what is your development environment? for data engineers who use Spark in work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nxuhc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699138293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering other peoples work development environment for using Spark. &lt;/p&gt;\n\n&lt;p&gt;My team is using VSCode and just python script. (Not using Jupyter Notebook)&lt;/p&gt;\n\n&lt;p&gt;Anyone there who can share your development environment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17nxuhc", "is_robot_indexable": true, "report_reasons": null, "author": "GiantEarnings", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nxuhc/in_your_actual_work_what_is_your_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nxuhc/in_your_actual_work_what_is_your_development/", "subreddit_subscribers": 138032, "created_utc": 1699138293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi everyone,\n\nI'm working with a large dataset (around 20GB) and need to perform data wrangling, transformation, and hypothesis testing using Python. However, the dataset is too large to load into memory all at once.\n\nI'm looking for a straightforward way to host this dataset in the cloud and run Python analysis without having to download anything, as I can't install software on my laptop. Ideally, I'd like to manage and analyze the data entirely through a browser-based interface.\n\nI thought hosting it as a database and connecting via Python would be simple, but I'm finding the multitude of cloud services to be quite overwhelming. Does anyone have experience with a similar situation or know of the best approach for this kind of task? I'm not tied to any specific technology as long as it gets the job done.\n\nAdditionally, if anyone has tutorials or resources on handling and analyzing big datasets in the cloud using Python, I would greatly appreciate it.\n\nThanks in advance for your guidance!", "author_fullname": "t2_34i32fyl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help: How to work with large datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o9xo5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699183857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with a large dataset (around 20GB) and need to perform data wrangling, transformation, and hypothesis testing using Python. However, the dataset is too large to load into memory all at once.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a straightforward way to host this dataset in the cloud and run Python analysis without having to download anything, as I can&amp;#39;t install software on my laptop. Ideally, I&amp;#39;d like to manage and analyze the data entirely through a browser-based interface.&lt;/p&gt;\n\n&lt;p&gt;I thought hosting it as a database and connecting via Python would be simple, but I&amp;#39;m finding the multitude of cloud services to be quite overwhelming. Does anyone have experience with a similar situation or know of the best approach for this kind of task? I&amp;#39;m not tied to any specific technology as long as it gets the job done.&lt;/p&gt;\n\n&lt;p&gt;Additionally, if anyone has tutorials or resources on handling and analyzing big datasets in the cloud using Python, I would greatly appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17o9xo5", "is_robot_indexable": true, "report_reasons": null, "author": "SaluteOrbis", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o9xo5/help_how_to_work_with_large_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o9xo5/help_how_to_work_with_large_datasets/", "subreddit_subscribers": 138032, "created_utc": 1699183857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Reading through [dbt best practices](https://docs.getdbt.com/guides/best-practices) the examples given focus almost entirely on transformations from raw source to marts. I couldn't find examples of transformations beginning at marts and feeding into a BI tool (e.g. PowerBI). \n\nI found their Semantic Layer and MetricFLow, but these seemed to just be concerned with creating relatively minimal metrics configured in YAML. At my company, the complexity of transformations downstream of the data marts is at least as large if not larger than those upstream, and I can't believe they could be reduced to a tool like MetricFlow. Using dbt for mart -&gt; BI seems like an obvious win in terms of removing duplicated effort in our analytics team, encouraging best practices, etc. I should clarify, I want to do all the heavy lifting in dbt and just use PowerBI as a relatively dumb client that does simple filtering and aggregation etc, without performing any complex logic.\n\nAre there any good resources on using dbt in the mart -&gt; BI transformations? Or is this just not as common a use case for dbt as I would have thought?", "author_fullname": "t2_1ea869g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt best practices for data pipelines from the mart to a BI tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nx97s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699136623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Reading through &lt;a href=\"https://docs.getdbt.com/guides/best-practices\"&gt;dbt best practices&lt;/a&gt; the examples given focus almost entirely on transformations from raw source to marts. I couldn&amp;#39;t find examples of transformations beginning at marts and feeding into a BI tool (e.g. PowerBI). &lt;/p&gt;\n\n&lt;p&gt;I found their Semantic Layer and MetricFLow, but these seemed to just be concerned with creating relatively minimal metrics configured in YAML. At my company, the complexity of transformations downstream of the data marts is at least as large if not larger than those upstream, and I can&amp;#39;t believe they could be reduced to a tool like MetricFlow. Using dbt for mart -&amp;gt; BI seems like an obvious win in terms of removing duplicated effort in our analytics team, encouraging best practices, etc. I should clarify, I want to do all the heavy lifting in dbt and just use PowerBI as a relatively dumb client that does simple filtering and aggregation etc, without performing any complex logic.&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources on using dbt in the mart -&amp;gt; BI transformations? Or is this just not as common a use case for dbt as I would have thought?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?auto=webp&amp;s=2a89f01968bbb7160773570a5739ba364e017ebf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e39c972215449e24ba187a3b3e6d0289aad02d1b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e48b5b0440098be5b7b54dcdd6d78e80f77e948", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c583ec988ffb5d6d8292b88b38a2a7ac9fc2b799", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a97be3626c69aab79c2204db47f040a6a8bb9820", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ba90b674ccf1906f5a13abd09b27db16d203bd0", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fIOL2kGYaMHNDhtmKe3L_aTjYOpHYh-54HVZsGgnZtE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=197f95d4689989cecbdb537c3aa18035536b0c50", "width": 1080, "height": 567}], "variants": {}, "id": "KBohsdqrfvkRxfqADmI_uqtotFtqgZjYu8NQbRpJlaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17nx97s", "is_robot_indexable": true, "report_reasons": null, "author": "pythonhobbit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nx97s/dbt_best_practices_for_data_pipelines_from_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nx97s/dbt_best_practices_for_data_pipelines_from_the/", "subreddit_subscribers": 138032, "created_utc": 1699136623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best books people have read regarding both the DE role as well as the overall data platform?", "author_fullname": "t2_jvtay3bqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "good data platform books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nsr2z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699124760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best books people have read regarding both the DE role as well as the overall data platform?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17nsr2z", "is_robot_indexable": true, "report_reasons": null, "author": "Southern_Version2681", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nsr2z/good_data_platform_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nsr2z/good_data_platform_books/", "subreddit_subscribers": 138032, "created_utc": 1699124760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a data architect (working on cloud) with more then a decade of data experience, what are side hustle I can explore to have additional side income, things that I can do on weekends or evenings, spending few hours, teaching tech can be one of them what are other relatively less effort areas.", "author_fullname": "t2_kyct9miiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "side hustles for additional income for data engineering/architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nuvlc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699130303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data architect (working on cloud) with more then a decade of data experience, what are side hustle I can explore to have additional side income, things that I can do on weekends or evenings, spending few hours, teaching tech can be one of them what are other relatively less effort areas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17nuvlc", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Class4024", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nuvlc/side_hustles_for_additional_income_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nuvlc/side_hustles_for_additional_income_for_data/", "subreddit_subscribers": 138032, "created_utc": 1699130303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is better, an RPA or Integration software for mass CRUD operation from externation application and source (csv, excel, xml) to main ERP system (Oracle)?\n\nI feel llike integration tool can handle easily this task where as through RPA you need to do everything as human would do (click mouse, select options in drop down list, click save, close and open window). \n\nWhich is better for this simple scenario?", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between Data Integration Platform and RPA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ntzki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699127983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is better, an RPA or Integration software for mass CRUD operation from externation application and source (csv, excel, xml) to main ERP system (Oracle)?&lt;/p&gt;\n\n&lt;p&gt;I feel llike integration tool can handle easily this task where as through RPA you need to do everything as human would do (click mouse, select options in drop down list, click save, close and open window). &lt;/p&gt;\n\n&lt;p&gt;Which is better for this simple scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ntzki", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ntzki/difference_between_data_integration_platform_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ntzki/difference_between_data_integration_platform_and/", "subreddit_subscribers": 138032, "created_utc": 1699127983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Engineers,\n\nI have a simple question, which Data Integration system do you use and which you find the most useful/verstile/easy to use.  \n\n\nCan a data integration software be used as some kind of Data Loader (similar to Salesforce Data Loader, which allows CRUD operation)?  Or it's just about moving data from A to B without any UPSERT/MERGE?\n\nI heard about Dell Boomi, Jitterbit as good platform, which is your favorite and how it differes from SSIS or Informatica Data Integration or Talend? Are they superior?\n\n&amp;#x200B;\n\nAny open source alternatives?", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which Data Integration Platform do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ntusf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699127641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Engineers,&lt;/p&gt;\n\n&lt;p&gt;I have a simple question, which Data Integration system do you use and which you find the most useful/verstile/easy to use.  &lt;/p&gt;\n\n&lt;p&gt;Can a data integration software be used as some kind of Data Loader (similar to Salesforce Data Loader, which allows CRUD operation)?  Or it&amp;#39;s just about moving data from A to B without any UPSERT/MERGE?&lt;/p&gt;\n\n&lt;p&gt;I heard about Dell Boomi, Jitterbit as good platform, which is your favorite and how it differes from SSIS or Informatica Data Integration or Talend? Are they superior?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any open source alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ntusf", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ntusf/which_data_integration_platform_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ntusf/which_data_integration_platform_do_you_use/", "subreddit_subscribers": 138032, "created_utc": 1699127641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, feeling a little lost and looking for some guidance. I work for a small financial firm as a \u201cData Analyst\u201d. I\u2019m the only data professional in the organization and directly support 4-5 teams at any one time. \n\nWe ingest some pretty niche financial data from 5-10 different sources and I was hired to help manage this process. My background is working for one of these data vendors so I\u2019m also the subject matter expert. \n\nI\u2019m responsible for all parts of the data pipeline. I source new data sets, create/manage the pipelines in airflow and Databricks, build the transformations in pyspark &amp; SQL, and deliver analytics through Tableau dashboards and other similar reports. \n\nAm I data analyst? Data engineer? Some combination? Also for future career growth is there a certain part of the above pipeline I should focus on? Thanks for your help.", "author_fullname": "t2_a87sm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is my job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ognov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699204719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, feeling a little lost and looking for some guidance. I work for a small financial firm as a \u201cData Analyst\u201d. I\u2019m the only data professional in the organization and directly support 4-5 teams at any one time. &lt;/p&gt;\n\n&lt;p&gt;We ingest some pretty niche financial data from 5-10 different sources and I was hired to help manage this process. My background is working for one of these data vendors so I\u2019m also the subject matter expert. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m responsible for all parts of the data pipeline. I source new data sets, create/manage the pipelines in airflow and Databricks, build the transformations in pyspark &amp;amp; SQL, and deliver analytics through Tableau dashboards and other similar reports. &lt;/p&gt;\n\n&lt;p&gt;Am I data analyst? Data engineer? Some combination? Also for future career growth is there a certain part of the above pipeline I should focus on? Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ognov", "is_robot_indexable": true, "report_reasons": null, "author": "Mackydude", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ognov/what_is_my_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ognov/what_is_my_job/", "subreddit_subscribers": 138032, "created_utc": 1699204719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm writing a pipeline to download and process some data. The data are monthly and I need to process them from 1980-now on a frequent basis.\n\nCurrently, I fan out the download tasks per month from 1980 to now, so the graph looks like this the following image: [https://i.stack.imgur.com/iWRxh.png](https://i.stack.imgur.com/iWRxh.png). \n\nBasically, a many-to-one graph. I'm generating all of the download tasks inside of a for loop in airflow with the code below (the code is just an example that reads and writes files, simulating the real behavior so I can run it locally). I'm relying on airflow's parallel process limits to keep from overloading the download APIs.\n\nI was wondering if the extreme fan-out of API calls is a common airflow design pattern. Are there different better design patterns?\n\nExample code for reference (the multiple\\_outputs tasks replicate the actual functionality even though there's only one output)\n\n    with DAG(\n            'download_and_transform_data',\n            default_args=default_args,\n            description='Download monthly data from JRA and ERA',\n            schedule=timedelta(days=30),\n            catchup=False,\n    ) as dag:\n    @task(multiple_outputs=True,\n              retries=3)\n        def download_jra_data_task(month, year, output_directory):\n            outf = os.path.join(output_directory, f\"jra_{month}_{year}\")\n            with open(outf, \"w\") as dst:\n                dst.write(f\"{month}, {year} {time.time()}\")\n            return {\"file\": outf}\n    \n    \n    \n        @task(\n            multiple_outputs=True,\n            retries=3,\n        )\n        def download_era_data_task(month, year, output_directory):\n            outf = os.path.join(output_directory, f\"era_{month}_{year}\")\n            with open(outf, \"w\") as dst:\n                dst.write(f\"{month}, {year} {time.time()}\")\n            return {\"file\": outf}\n    \n        @task\n        def transform_task(file, output_dir):\n            print(f\"processing {file}\")\n            file = file[\"file\"]\n            with open(file, \"r\") as src:\n                buf = src.read()\n    \n            with open(os.path.join(output_dir, os.path.basename(file)), \"w\") as dst:\n                dst.write(f\"{buf} {time.time()}\\n\")\n    \n            return file\n    \n    \n        @task\n        def merge_and_remap_file(filelist, output_dir):\n            with open(os.path.join(output_dir, os.path.basename(filelist[0]) + \"_merged\"), \"w\") as dst:\n                for f in filelist:\n                    with open(f, \"r\") as src:\n                        buf = src.read()\n                    dst.write(f\"{buf} \\n\")\n    era_files = []\n        jra_files = []\n        for year in range(1980, 2022):\n            for month in range(1, 13):\n                jra_files.append(download_jra_data_task(month, year, os.path.join(STAGING_DIR, \"jra\")))\n                era_files.append(download_era_data_task(month, year, os.path.join(STAGING_DIR, \"era\")))\n    \n        jra_transform = []\n        for jra_file in jra_files:\n            # transform task also checks the data\n            f = transform_task(jra_file, os.path.join(WAREHOUSE_DIR, \"jra\"))\n            jra_transform.append(f)\n    \n        era_transform = []\n        for era_file in era_files:\n            # transform task also checks the data\n            transform_task(era_file, os.path.join(WAREHOUSE_DIR, \"era\"))\n            era_transform.append(f)\n    \n        merged_era = merge_and_remap_file(era_transform, os.path.join(PROD_DIR, \"era\"))\n        merged_jra = merge_and_remap_file(jra_transform, os.path.join(PROD_DIR, \"jra\"))\n\n&amp;#x200B;", "author_fullname": "t2_80aq2vu3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow design advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17of7x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699200704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m writing a pipeline to download and process some data. The data are monthly and I need to process them from 1980-now on a frequent basis.&lt;/p&gt;\n\n&lt;p&gt;Currently, I fan out the download tasks per month from 1980 to now, so the graph looks like this the following image: &lt;a href=\"https://i.stack.imgur.com/iWRxh.png\"&gt;https://i.stack.imgur.com/iWRxh.png&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;Basically, a many-to-one graph. I&amp;#39;m generating all of the download tasks inside of a for loop in airflow with the code below (the code is just an example that reads and writes files, simulating the real behavior so I can run it locally). I&amp;#39;m relying on airflow&amp;#39;s parallel process limits to keep from overloading the download APIs.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if the extreme fan-out of API calls is a common airflow design pattern. Are there different better design patterns?&lt;/p&gt;\n\n&lt;p&gt;Example code for reference (the multiple_outputs tasks replicate the actual functionality even though there&amp;#39;s only one output)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;with DAG(\n        &amp;#39;download_and_transform_data&amp;#39;,\n        default_args=default_args,\n        description=&amp;#39;Download monthly data from JRA and ERA&amp;#39;,\n        schedule=timedelta(days=30),\n        catchup=False,\n) as dag:\n@task(multiple_outputs=True,\n          retries=3)\n    def download_jra_data_task(month, year, output_directory):\n        outf = os.path.join(output_directory, f&amp;quot;jra_{month}_{year}&amp;quot;)\n        with open(outf, &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{month}, {year} {time.time()}&amp;quot;)\n        return {&amp;quot;file&amp;quot;: outf}\n\n\n\n    @task(\n        multiple_outputs=True,\n        retries=3,\n    )\n    def download_era_data_task(month, year, output_directory):\n        outf = os.path.join(output_directory, f&amp;quot;era_{month}_{year}&amp;quot;)\n        with open(outf, &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{month}, {year} {time.time()}&amp;quot;)\n        return {&amp;quot;file&amp;quot;: outf}\n\n    @task\n    def transform_task(file, output_dir):\n        print(f&amp;quot;processing {file}&amp;quot;)\n        file = file[&amp;quot;file&amp;quot;]\n        with open(file, &amp;quot;r&amp;quot;) as src:\n            buf = src.read()\n\n        with open(os.path.join(output_dir, os.path.basename(file)), &amp;quot;w&amp;quot;) as dst:\n            dst.write(f&amp;quot;{buf} {time.time()}\\n&amp;quot;)\n\n        return file\n\n\n    @task\n    def merge_and_remap_file(filelist, output_dir):\n        with open(os.path.join(output_dir, os.path.basename(filelist[0]) + &amp;quot;_merged&amp;quot;), &amp;quot;w&amp;quot;) as dst:\n            for f in filelist:\n                with open(f, &amp;quot;r&amp;quot;) as src:\n                    buf = src.read()\n                dst.write(f&amp;quot;{buf} \\n&amp;quot;)\nera_files = []\n    jra_files = []\n    for year in range(1980, 2022):\n        for month in range(1, 13):\n            jra_files.append(download_jra_data_task(month, year, os.path.join(STAGING_DIR, &amp;quot;jra&amp;quot;)))\n            era_files.append(download_era_data_task(month, year, os.path.join(STAGING_DIR, &amp;quot;era&amp;quot;)))\n\n    jra_transform = []\n    for jra_file in jra_files:\n        # transform task also checks the data\n        f = transform_task(jra_file, os.path.join(WAREHOUSE_DIR, &amp;quot;jra&amp;quot;))\n        jra_transform.append(f)\n\n    era_transform = []\n    for era_file in era_files:\n        # transform task also checks the data\n        transform_task(era_file, os.path.join(WAREHOUSE_DIR, &amp;quot;era&amp;quot;))\n        era_transform.append(f)\n\n    merged_era = merge_and_remap_file(era_transform, os.path.join(PROD_DIR, &amp;quot;era&amp;quot;))\n    merged_jra = merge_and_remap_file(jra_transform, os.path.join(PROD_DIR, &amp;quot;jra&amp;quot;))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?auto=webp&amp;s=6cc3016f5696949bff654c85174e62630dd7f171", "width": 503, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c0193b7765a80eb2ed5f3b55ac981f6f017c01c", "width": 108, "height": 175}, {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f819052b32b0156730c2c2ff9cee9cbb367013b", "width": 216, "height": 351}, {"url": "https://external-preview.redd.it/UXqMIfIARNC0Loq56X2Wa5_aB-5kJ3MjNUnigYXoIGU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e5c8979935001824e02a136d136b309c45bf97ec", "width": 320, "height": 520}], "variants": {}, "id": "8lBmeB85vuRIh8VU2soN7B9xheCfiYfJuAKjQdZi9O4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17of7x7", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous_Spring_7708", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17of7x7/airflow_design_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17of7x7/airflow_design_advice/", "subreddit_subscribers": 138032, "created_utc": 1699200704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been working in the data analysis field for a while. I enjoy creating automations that make things easier for others. Examples: Reports, calculations, programs.\n\nWondering, do DEs do any sort of automation? If so, what is there as a data engineer?", "author_fullname": "t2_7x2alm42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automations in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o6cx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699167426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been working in the data analysis field for a while. I enjoy creating automations that make things easier for others. Examples: Reports, calculations, programs.&lt;/p&gt;\n\n&lt;p&gt;Wondering, do DEs do any sort of automation? If so, what is there as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17o6cx1", "is_robot_indexable": true, "report_reasons": null, "author": "InstaMastery", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o6cx1/automations_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o6cx1/automations_in_data_engineering/", "subreddit_subscribers": 138032, "created_utc": 1699167426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, lately in my team we have been discussing about converting the massive amount of bash scripts to scala scripts. The majority of programs we use for data engineering are written in scala/spark and java. I\u2019m very happy about bash scripting cause it\u2019s easy to read and I\u2019m not sure what would be the advantages of scala scripting .Any comments about it?", "author_fullname": "t2_e6fhegyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting bash script to scala", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17nttj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699127552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, lately in my team we have been discussing about converting the massive amount of bash scripts to scala scripts. The majority of programs we use for data engineering are written in scala/spark and java. I\u2019m very happy about bash scripting cause it\u2019s easy to read and I\u2019m not sure what would be the advantages of scala scripting .Any comments about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17nttj8", "is_robot_indexable": true, "report_reasons": null, "author": "Mat_FI", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17nttj8/converting_bash_script_to_scala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17nttj8/converting_bash_script_to_scala/", "subreddit_subscribers": 138032, "created_utc": 1699127552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need solution architectures for Cloudera / Databricks / Pure Cloud Services on MSFT AZ/AWS that include:\n\n\\- staging environments\n\n\\- CI/CD components and processes, also with respect to staging. (Usually its never the same in all stages)\n\n&amp;#x200B;\n\nI can only find solution architectures that show which core service components are stichted together. Sometimes CI/CD is included when serverless Cloud tools are used, but that not comprehensive enough (I.e. [https://aws.amazon.com/solutions/implementations/data-lake-solution/](https://aws.amazon.com/solutions/implementations/data-lake-solution/)) Staging environments are also rarely considered, especially \n\n&amp;#x200B;\n\nDo you know any sources?", "author_fullname": "t2_ag17bkmz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Lakehouse Solution architectures that include CI/CD and staging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17og29m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699203063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need solution architectures for Cloudera / Databricks / Pure Cloud Services on MSFT AZ/AWS that include:&lt;/p&gt;\n\n&lt;p&gt;- staging environments&lt;/p&gt;\n\n&lt;p&gt;- CI/CD components and processes, also with respect to staging. (Usually its never the same in all stages)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can only find solution architectures that show which core service components are stichted together. Sometimes CI/CD is included when serverless Cloud tools are used, but that not comprehensive enough (I.e. &lt;a href=\"https://aws.amazon.com/solutions/implementations/data-lake-solution/\"&gt;https://aws.amazon.com/solutions/implementations/data-lake-solution/&lt;/a&gt;) Staging environments are also rarely considered, especially &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you know any sources?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?auto=webp&amp;s=8afacfc14dfed09cec0415cac7d36db9c3374c61", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=64a1b1322ed94c559cb213e6a08f3eb426a3fb0b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9edddfdb28bb0e92ceb041859aacef81ab9ed42e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=de73cdc9da2d0b04938bb7d051ab1a3ceb783323", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60037829d2ce04de0705a2b45123d8ab7c12d41c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5a8f0da08b9281c578a8ab6f49a5b3f577ec9b8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Q6q5DgwzcfU6chKw4uevixQcBq1Ipi2NYLheQ4lv0Vk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a9a9c1c38bd543a7ea6b718e139a9c1e6b62d18", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17og29m", "is_robot_indexable": true, "report_reasons": null, "author": "Velocity911911", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17og29m/data_lakehouse_solution_architectures_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17og29m/data_lakehouse_solution_architectures_that/", "subreddit_subscribers": 138032, "created_utc": 1699203063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\n\nI'm a data engineer in a startup for more than 2 years. I have some questions and your feedback are much appreciated:\n1. Best tips for landing a Data Engineer job at big companies (not necessarily tech, TC more than 120k)\n2. What kind of sources you use for interview preparation? \n\nThanks,", "author_fullname": "t2_bfz4zq58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Canada Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17o309a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699153840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineer in a startup for more than 2 years. I have some questions and your feedback are much appreciated:\n1. Best tips for landing a Data Engineer job at big companies (not necessarily tech, TC more than 120k)\n2. What kind of sources you use for interview preparation? &lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17o309a", "is_robot_indexable": true, "report_reasons": null, "author": "Sharp_Ad_8085", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17o309a/canada_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17o309a/canada_job_market/", "subreddit_subscribers": 138032, "created_utc": 1699153840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8rjw51ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn PySpark for Free, better than Paid courses", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17ns54u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "domain": "youtube.com", "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FwNRjR6Cds5s%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q%26days_since_epoch%3D19665&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen; encrypted-media; picture-in-picture;\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 450}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "http://youtube.com", "description": "PySpark tutorials for Beginners. PySpark Zero to Hero is a comprehensive series of videos that provides a step-by-step guide to learning PySpark, a popular o...", "title": "PySpark - Zero to Hero | PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 168, "height": 450, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FwNRjR6Cds5s%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q%26days_since_epoch%3D19665&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen; encrypted-media; picture-in-picture;\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wNRjR6Cds5s/hqdefault.jpg?sqp=-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ==&amp;rs=AOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q&amp;days_since_epoch=19665", "thumbnail_height": 94}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FwNRjR6Cds5s%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q%26days_since_epoch%3D19665&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen; encrypted-media; picture-in-picture;\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17ns54u", "height": 450}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QP4ZVHVNfgAxj_dZH7Hf4z29VwWC_aqo8HAW33RMRbE.jpg", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699123169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/playlist?list=PL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7CL9NJ4BY7ybUtJYYdLSO3qzlfLSHcQK88ZiK1EAy6w.jpg?auto=webp&amp;s=2f27e87b329abeda2341ea9f6a38ddcecf9bff46", "width": 168, "height": 94}, "resolutions": [{"url": "https://external-preview.redd.it/7CL9NJ4BY7ybUtJYYdLSO3qzlfLSHcQK88ZiK1EAy6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e70a7f30d0a7f632d026b167337ce264be3c537d", "width": 108, "height": 60}], "variants": {}, "id": "o8j_nmDRVNSXAeWzG2ujVdLXIXeTdSsPIcNZwvoxhZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17ns54u", "is_robot_indexable": true, "report_reasons": null, "author": "Complex_Revolution67", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ns54u/learn_pyspark_for_free_better_than_paid_courses/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/playlist?list=PL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm", "subreddit_subscribers": 138032, "created_utc": 1699123169.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "http://youtube.com", "description": "PySpark tutorials for Beginners. PySpark Zero to Hero is a comprehensive series of videos that provides a step-by-step guide to learning PySpark, a popular o...", "title": "PySpark - Zero to Hero | PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 168, "height": 450, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fplaylist%3Flist%3DPL2IsFZBGM_IHCl9zhRVC1EXTomkEp_1zm&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FwNRjR6Cds5s%2Fhqdefault.jpg%3Fsqp%3D-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ%3D%3D%26rs%3DAOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q%26days_since_epoch%3D19665&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"600\" height=\"450\" scrolling=\"no\" title=\"YouTube embed\" frameborder=\"0\" allow=\"autoplay; fullscreen; encrypted-media; picture-in-picture;\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/wNRjR6Cds5s/hqdefault.jpg?sqp=-oaymwEWCKgBEF5IWvKriqkDCQgBFQAAiEIYAQ==&amp;rs=AOn4CLCuZVeub8FGBYVY00e0WHQkG9Ki6Q&amp;days_since_epoch=19665", "thumbnail_height": 94}}, "is_video": false}}], "before": null}}