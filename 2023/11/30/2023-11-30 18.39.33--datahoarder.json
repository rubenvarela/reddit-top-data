{"kind": "Listing", "data": {"after": "t3_187eiq4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1cjqfkwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update on the Tokyo Lab Film situation: \"Tokyo Lab orphaned film update! Toho has announced they will be taking over management of the remaining archive. No films will be thrown away!\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_187iixe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 136, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Tokyo Lab orphaned film update! Toho has announced they will be taking over management of the remaining archive. No films will be thrown away! &lt;a href=\"https://t.co/YBZ4VDupty\"&gt;https://t.co/YBZ4VDupty&lt;/a&gt;&lt;/p&gt;&amp;mdash; Go\u2605Tanks (@tanks404) &lt;a href=\"https://twitter.com/tanks404/status/1730202703102353526?ref_src=twsrc%5Etfw\"&gt;November 30, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/tanks404/status/1730202703102353526", "author_name": "Go\u2605Tanks", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Tokyo Lab orphaned film update! Toho has announced they will be taking over management of the remaining archive. No films will be thrown away! &lt;a href=\"https://t.co/YBZ4VDupty\"&gt;https://t.co/YBZ4VDupty&lt;/a&gt;&lt;/p&gt;&amp;mdash; Go\u2605Tanks (@tanks404) &lt;a href=\"https://twitter.com/tanks404/status/1730202703102353526?ref_src=twsrc%5Etfw\"&gt;November 30, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/tanks404", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Tokyo Lab orphaned film update! Toho has announced they will be taking over management of the remaining archive. No films will be thrown away! &lt;a href=\"https://t.co/YBZ4VDupty\"&gt;https://t.co/YBZ4VDupty&lt;/a&gt;&lt;/p&gt;&amp;mdash; Go\u2605Tanks (@tanks404) &lt;a href=\"https://twitter.com/tanks404/status/1730202703102353526?ref_src=twsrc%5Etfw\"&gt;November 30, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/187iixe", "height": 200}, "link_flair_text": "News", "can_mod_post": false, "score": 136, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HUDdx7lLHSkxWJN_9IefbOV1AOXLfy7P9VdaDSQ2vCk.jpg", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701350903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/tanks404/status/1730202703102353526", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DwnJo79WeQcmI1ZPa9wXr-ul5WOo3hJFRGHqWQZ1x0k.jpg?auto=webp&amp;s=df5ff545e212b3ceab86560758132b52efec12ac", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/DwnJo79WeQcmI1ZPa9wXr-ul5WOo3hJFRGHqWQZ1x0k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cde168eca60c12c204f34ca931507c07ebd143c1", "width": 108, "height": 108}], "variants": {}, "id": "_SMiF5GKmYLGf4y56QLZ9rC9av05q7OKN2PNbSg4Zg0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DVD", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187iixe", "is_robot_indexable": true, "report_reasons": null, "author": "koempleh", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/187iixe/update_on_the_tokyo_lab_film_situation_tokyo_lab/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/tanks404/status/1730202703102353526", "subreddit_subscribers": 715321, "created_utc": 1701350903.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/tanks404/status/1730202703102353526", "author_name": "Go\u2605Tanks", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;Tokyo Lab orphaned film update! Toho has announced they will be taking over management of the remaining archive. No films will be thrown away! &lt;a href=\"https://t.co/YBZ4VDupty\"&gt;https://t.co/YBZ4VDupty&lt;/a&gt;&lt;/p&gt;&amp;mdash; Go\u2605Tanks (@tanks404) &lt;a href=\"https://twitter.com/tanks404/status/1730202703102353526?ref_src=twsrc%5Etfw\"&gt;November 30, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n\n", "author_url": "https://twitter.com/tanks404", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I run a video production company. We have 300TB of archived projects (and growing daily).\n\nMany years ago, our old solution for archiving was simply to dump old projects off onto an external drive, duplicate that, and have one drive at the office, one offsite elsewhere. This was ok, but not ideal. Relatively expensive per TB, and just a shit ton of physical drives.\n\nA few years ago, we had an unlimited Google Drive and 1000/1000 fibre internet. So we moved to a system where we would drop a project onto an external drive, keep that offsite, and have a duplicate of it uploaded to Google Drive. This worked ok until we reached a hidden file number limit on Google Drive. Then they removed the unlimited sizing of Google Drive accounts completely. So that was a dead end.\n\nSo then we moved that system to Dropbox a couple of years ago, as they were offering an unlimited account. This was the perfect situation. Dropbox was feature rich, fast, integrated beautifully into finder/explorer and just a great solution all round. It meant it was easy to give clients access to old data directly if they needed, etc. Anyway, as you all know, that gravy train has come to an end recently, and we now have 12 months grace with out storage on there before we have to have this sorted back to another sytem.\n\nOur options seem to be:\n\n* Go back to our old system of duplicated external drives, with one living offsite. We'd need \\~$7500AUD worth of new drives to duplicate what we currently have.\n* Buy a couple of LTO-9 tape drives (2 offices in different cities) and keep one copy on an external drive and one copy on a tape archive. This would be \\~$20000AUD of hardware upfront + media costs of \\~$2000AUD (assuming we'd get maybe 30TB per tape on the 18TB raw LTO 9 tapes). So more expensive upfront but would maybe pay off eventually?\n* Build a linustechtips style beast of a NAS. Raw drive cost would be similar to the external drives, but would have the advantage of being accessible remotely. Would then need to spend $5000-10000AUD on the actual hardware on top of the drives. Also have the problem of ever growing storage needs. This solution we could potentially not duplicate the data to external drives though and live with RAID as only form of redundancy...\n* Another clour storage service? Anything fast and decent enough that comes at a reasonable cost?\n\nAny advice here would be appreciated!", "author_fullname": "t2_8o00p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "300TB of data. Dropbox and Google are dead to me. Next options. Cloud? Tape? NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187b44e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 70, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 70, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701322947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I run a video production company. We have 300TB of archived projects (and growing daily).&lt;/p&gt;\n\n&lt;p&gt;Many years ago, our old solution for archiving was simply to dump old projects off onto an external drive, duplicate that, and have one drive at the office, one offsite elsewhere. This was ok, but not ideal. Relatively expensive per TB, and just a shit ton of physical drives.&lt;/p&gt;\n\n&lt;p&gt;A few years ago, we had an unlimited Google Drive and 1000/1000 fibre internet. So we moved to a system where we would drop a project onto an external drive, keep that offsite, and have a duplicate of it uploaded to Google Drive. This worked ok until we reached a hidden file number limit on Google Drive. Then they removed the unlimited sizing of Google Drive accounts completely. So that was a dead end.&lt;/p&gt;\n\n&lt;p&gt;So then we moved that system to Dropbox a couple of years ago, as they were offering an unlimited account. This was the perfect situation. Dropbox was feature rich, fast, integrated beautifully into finder/explorer and just a great solution all round. It meant it was easy to give clients access to old data directly if they needed, etc. Anyway, as you all know, that gravy train has come to an end recently, and we now have 12 months grace with out storage on there before we have to have this sorted back to another sytem.&lt;/p&gt;\n\n&lt;p&gt;Our options seem to be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Go back to our old system of duplicated external drives, with one living offsite. We&amp;#39;d need ~$7500AUD worth of new drives to duplicate what we currently have.&lt;/li&gt;\n&lt;li&gt;Buy a couple of LTO-9 tape drives (2 offices in different cities) and keep one copy on an external drive and one copy on a tape archive. This would be ~$20000AUD of hardware upfront + media costs of ~$2000AUD (assuming we&amp;#39;d get maybe 30TB per tape on the 18TB raw LTO 9 tapes). So more expensive upfront but would maybe pay off eventually?&lt;/li&gt;\n&lt;li&gt;Build a linustechtips style beast of a NAS. Raw drive cost would be similar to the external drives, but would have the advantage of being accessible remotely. Would then need to spend $5000-10000AUD on the actual hardware on top of the drives. Also have the problem of ever growing storage needs. This solution we could potentially not duplicate the data to external drives though and live with RAID as only form of redundancy...&lt;/li&gt;\n&lt;li&gt;Another clour storage service? Anything fast and decent enough that comes at a reasonable cost?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any advice here would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187b44e", "is_robot_indexable": true, "report_reasons": null, "author": "campster123", "discussion_type": null, "num_comments": 115, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187b44e/300tb_of_data_dropbox_and_google_are_dead_to_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187b44e/300tb_of_data_dropbox_and_google_are_dead_to_me/", "subreddit_subscribers": 715321, "created_utc": 1701322947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "HAs anyone shucked the 14TB drives Costco had on sale recently? what did you find?", "author_fullname": "t2_1fhm1svf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "$150 14TB Costco Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186za14", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701289933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;HAs anyone shucked the 14TB drives Costco had on sale recently? what did you find?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "186za14", "is_robot_indexable": true, "report_reasons": null, "author": "knave1906", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/186za14/150_14tb_costco_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/186za14/150_14tb_costco_drives/", "subreddit_subscribers": 715321, "created_utc": 1701289933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_j3gnkmjz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "How are brand new Exos drives sold/packaged/shipped?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xty7zed4ke3c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc7072302c9ec2e50e510e00dd8d1cd2f1dbdea6"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=791dc7f346b67530489e41ea7213ec73f9935166"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4446b98d0a733eafefbbb560a2225b33ccad08cb"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=95e83f25056e378fb6ceeaf6da1dc5a09d03f6db"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4b4561d8fb8da894588caf6f7165f5492e53555d"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=53e106910754645283697690edb112dc0ba6af58"}], "s": {"y": 2048, "x": 1536, "u": "https://preview.redd.it/xty7zed4ke3c1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=794abdbd98fcd4bfd5c1100f07f179a1ab4b9163"}, "id": "xty7zed4ke3c1"}, "wo9zmed4ke3c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=49d73203d31257417e29ef2fc8bc9edc58a1b8d1"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=569b760a31f806735b0a203f6a2a87fc272ecf83"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf262c59ef94b39aab7403f38c831b28987ae352"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=58bf50eadd3b95875fc429003a96d3fd785a2859"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=20d279b966500b8f0e30853ada10999f8dd8e498"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8a695193354a2af613266db1f9fa1067db02c978"}], "s": {"y": 1536, "x": 2048, "u": "https://preview.redd.it/wo9zmed4ke3c1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=4d7daf1d0ae6e4b087785c1722e5293295a66532"}, "id": "wo9zmed4ke3c1"}, "3xciicd4ke3c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=291368d98f26198b8bb113b4dde391246ecb2e74"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9cbd32359b8e7e37dd01738583df9fd9643c38dc"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=564cebd23e489eb2fd907ed337934aa53f8012fe"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4975c3e74602e654c048b386ae9e9f018111b54c"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d6d638d45ef9f6058bf1f75d633aff293a5b7f7"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=13f6b5066399af14ab6749ce1bbc6ce7d0ce4d18"}], "s": {"y": 2048, "x": 1536, "u": "https://preview.redd.it/3xciicd4ke3c1.jpg?width=1536&amp;format=pjpg&amp;auto=webp&amp;s=6105c8ecc773176d23050a190a3502ec1f1748e3"}, "id": "3xciicd4ke3c1"}}, "name": "t3_1878c2k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 36, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "picture 1: two boxes like this in a bigger box with lots of bubble wrap.", "media_id": "xty7zed4ke3c1", "id": 367352063}, {"caption": "picture 2: inside the box, was the hard drive in fat bubble wrap", "media_id": "wo9zmed4ke3c1", "id": 367352064}, {"caption": "picture 3: out of the fat bubble wrap is the hard drive in a sealed anti-static bag.", "media_id": "3xciicd4ke3c1", "id": 367352065}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/i8fhV29y5mREvkgFUjhaNZluFujvs6eOKjcb0h8dYD0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701314109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1878c2k", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1878c2k", "is_robot_indexable": true, "report_reasons": null, "author": "fatboycraig", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1878c2k/how_are_brand_new_exos_drives_soldpackagedshipped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1878c2k", "subreddit_subscribers": 715321, "created_utc": 1701314109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got my 10x HDDs delivered from ServerPartDeals, they're Dell branded Exos drives, Seller Refurbished\n\n&amp;#x200B;\n\nI know one of the first things I'm supposed to do is make sure they're configured to run at 4K, not 512, so I'll be checking that.\n\n&amp;#x200B;\n\nI'll also plug them all into a HDD dock and read the SMART data off them.\n\n&amp;#x200B;\n\n Afterwards, I remember reading a guide (here I believe) about how to test all the drives. There was a command line tool to check the drive for errors.\n\nDoes anyone know what I'm talking about? I remember I had to run a plugin on the computer to make sure I could run multiple instances of it.\n\n&amp;#x200B;\n\nAlternately, I intend to spin up a TrueNAS instance for this, does TrueNAS have any built in tool to fully check the drives before I create any pools?", "author_fullname": "t2_iuj0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got my HDDs delivered. How can I test them all before putting real data on them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186x50s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701284329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got my 10x HDDs delivered from ServerPartDeals, they&amp;#39;re Dell branded Exos drives, Seller Refurbished&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know one of the first things I&amp;#39;m supposed to do is make sure they&amp;#39;re configured to run at 4K, not 512, so I&amp;#39;ll be checking that.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll also plug them all into a HDD dock and read the SMART data off them.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Afterwards, I remember reading a guide (here I believe) about how to test all the drives. There was a command line tool to check the drive for errors.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know what I&amp;#39;m talking about? I remember I had to run a plugin on the computer to make sure I could run multiple instances of it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Alternately, I intend to spin up a TrueNAS instance for this, does TrueNAS have any built in tool to fully check the drives before I create any pools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "186x50s", "is_robot_indexable": true, "report_reasons": null, "author": "kick_me88", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/186x50s/got_my_hdds_delivered_how_can_i_test_them_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/186x50s/got_my_hdds_delivered_how_can_i_test_them_all/", "subreddit_subscribers": 715321, "created_utc": 1701284329.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Here is a fairly robust way to ensure a drive safe to put into service. I have tested this before and caught drives that would have failed shortly after put into prod, and some that would of after it was more than half full.\n\n1) Check S.M.A.R.T Info: Confirm no (0) Seek Error Rate, Read Error Rate, Reallocated Sector Count, Uncorrectable Sector Count\n\n2) Run Short S.M.A.R.T test\n\n3) Repeat Step 1\n\n4) Run Conveyance S.M.A.R.T test\n\n5) Repeat Step 1\n\n6) Run Destructive Badblocks test (read and write)\n\n7) Repeat Step 1\n\n8) Perform a FULL Format (Overwrite with Zeros)\n\n9) Repeat Step 1\n\n10) Run Extended S.M.A.R.T test\n\n11)  Repeat Step 1\n\nReturn the drive if either of the following is true:\n\nA) The formatting speed drops below 80MB/s by more than 10MB/s (my defective one was ~40MB/s from first power-on)\n\nB) The S.M.A.R.T tests show error count increasing at any step\n\n\n\nIt is also highly advisable to stagger the testing (and repeat some) if you plan on using multiple drives in a pool/raid config. This way the wear on the drives differ, to reduce the likelihood of them failing at the same time. For example, I re-ran either the Full format or badblocks test on some of the drives so some drives have 48 hours of testing, some have 72, some have 96. This way, the chances of a multiple drive failures during rebuild is lower.", "author_fullname": "t2_8oh1uiuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Must do's for a new hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1873un5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701301666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is a fairly robust way to ensure a drive safe to put into service. I have tested this before and caught drives that would have failed shortly after put into prod, and some that would of after it was more than half full.&lt;/p&gt;\n\n&lt;p&gt;1) Check S.M.A.R.T Info: Confirm no (0) Seek Error Rate, Read Error Rate, Reallocated Sector Count, Uncorrectable Sector Count&lt;/p&gt;\n\n&lt;p&gt;2) Run Short S.M.A.R.T test&lt;/p&gt;\n\n&lt;p&gt;3) Repeat Step 1&lt;/p&gt;\n\n&lt;p&gt;4) Run Conveyance S.M.A.R.T test&lt;/p&gt;\n\n&lt;p&gt;5) Repeat Step 1&lt;/p&gt;\n\n&lt;p&gt;6) Run Destructive Badblocks test (read and write)&lt;/p&gt;\n\n&lt;p&gt;7) Repeat Step 1&lt;/p&gt;\n\n&lt;p&gt;8) Perform a FULL Format (Overwrite with Zeros)&lt;/p&gt;\n\n&lt;p&gt;9) Repeat Step 1&lt;/p&gt;\n\n&lt;p&gt;10) Run Extended S.M.A.R.T test&lt;/p&gt;\n\n&lt;p&gt;11)  Repeat Step 1&lt;/p&gt;\n\n&lt;p&gt;Return the drive if either of the following is true:&lt;/p&gt;\n\n&lt;p&gt;A) The formatting speed drops below 80MB/s by more than 10MB/s (my defective one was ~40MB/s from first power-on)&lt;/p&gt;\n\n&lt;p&gt;B) The S.M.A.R.T tests show error count increasing at any step&lt;/p&gt;\n\n&lt;p&gt;It is also highly advisable to stagger the testing (and repeat some) if you plan on using multiple drives in a pool/raid config. This way the wear on the drives differ, to reduce the likelihood of them failing at the same time. For example, I re-ran either the Full format or badblocks test on some of the drives so some drives have 48 hours of testing, some have 72, some have 96. This way, the chances of a multiple drive failures during rebuild is lower.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1873un5", "is_robot_indexable": true, "report_reasons": null, "author": "EMC2DATA592", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1873un5/must_dos_for_a_new_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1873un5/must_dos_for_a_new_hard_drive/", "subreddit_subscribers": 715321, "created_utc": 1701301666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Im wondering if anyone has ever scraped pricing data for the major supermarkets?\n\nWith the cost of living crisis currently im interested to see which products have increased dramatically and if theres any correlation across brands or sectors.\n\nThanks!", "author_fullname": "t2_eq196", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UK Datahoarders - Has anyone ever scraped supermarket price files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187ivbk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701351907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im wondering if anyone has ever scraped pricing data for the major supermarkets?&lt;/p&gt;\n\n&lt;p&gt;With the cost of living crisis currently im interested to see which products have increased dramatically and if theres any correlation across brands or sectors.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187ivbk", "is_robot_indexable": true, "report_reasons": null, "author": "jpjapers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187ivbk/uk_datahoarders_has_anyone_ever_scraped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187ivbk/uk_datahoarders_has_anyone_ever_scraped/", "subreddit_subscribers": 715321, "created_utc": 1701351907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_32ywoabe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How often does server part deals restock / does it restock on recertified drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_187bar0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iwCBiRezStZy1nV0nrfwes-tcwpuobFCoagbHyQe4kw.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701323579.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ebuzyuw8cf3c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?auto=webp&amp;s=0effe9c41dc3e4ae189bab531c0d23d4ef7f21d3", "width": 1892, "height": 848}, "resolutions": [{"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6a0584255087489f9c1fb9b7dd91cae942c93b8c", "width": 108, "height": 48}, {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c787f1c3ea4535aba5eacc760512f31be6189260", "width": 216, "height": 96}, {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b098bc52e3afdb699f739b6c4c44bbd2c70ce50", "width": 320, "height": 143}, {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8be3668603d7fe909e7253220bd484fd5e7e7799", "width": 640, "height": 286}, {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9b374578fa8f6620e443c94603391ac8f9c2a3e4", "width": 960, "height": 430}, {"url": "https://preview.redd.it/ebuzyuw8cf3c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2ee083859db6095bf2d13a935dbbe0830534e72c", "width": 1080, "height": 484}], "variants": {}, "id": "pL5FDZKw5hYWcV0CxlhT5h9J4amN0SyKGWZLUdLT0H0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "14TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187bar0", "is_robot_indexable": true, "report_reasons": null, "author": "Beanconscriptog", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/187bar0/how_often_does_server_part_deals_restock_does_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ebuzyuw8cf3c1.png", "subreddit_subscribers": 715321, "created_utc": 1701323579.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My HDD is failing and manually copying files to an external HDD is taking forever. We're talking about KB/s transfer speeds. I have around 1.3TB in it, but only really need around 400-500gb. I'm afraid this method is only hastening its death.\n\nI used to use a dos program, Norton Ghost, to clone partitions. Would a similar program be better for backing up my files vs copy/pasting? I feel like the manual copying is wearing the drive out faster. On the other hand, cloning might just copy over corrupted files on bad sectors and all (I know nothing about this so I could be wrong).\n\nThanks in advance.", "author_fullname": "t2_bgpdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it better to clone a failing HDD than manually backing it up via copy/paste?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187aus1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701322095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My HDD is failing and manually copying files to an external HDD is taking forever. We&amp;#39;re talking about KB/s transfer speeds. I have around 1.3TB in it, but only really need around 400-500gb. I&amp;#39;m afraid this method is only hastening its death.&lt;/p&gt;\n\n&lt;p&gt;I used to use a dos program, Norton Ghost, to clone partitions. Would a similar program be better for backing up my files vs copy/pasting? I feel like the manual copying is wearing the drive out faster. On the other hand, cloning might just copy over corrupted files on bad sectors and all (I know nothing about this so I could be wrong).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187aus1", "is_robot_indexable": true, "report_reasons": null, "author": "imanol1898", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187aus1/is_it_better_to_clone_a_failing_hdd_than_manually/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187aus1/is_it_better_to_clone_a_failing_hdd_than_manually/", "subreddit_subscribers": 715321, "created_utc": 1701322095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nSo I've had this janky QNAP NAS for years. It's janky because my apartment got hit by lightning a few years ago and fried one of the ethernet ports.\n\nEver since then, I had been using it (against my better judgment) because the other ethernet port still worked so I was able to keep using it.\n\nI finally got a new NAS (Synology) and two new drives and migrated all my data over. Whew!\n\nBut now I've got two empty slots so I figured I would move over the newer of 2 of the 4 drives from my old QNAP NAS.\n\nBut the QNAP has a weird issue... it never shuts down properly, possibly related to the lightning. Any time you tell it to shut down, it just reboots. So I basically told it to shut down and once it seemed close to rebooting, I just pulled the power cord.\n\nThen I moved those two newer drives over to the Synology NAS which is when it told me that one drive has *six* bad sectors. The drives are encrypted by QNAP's OS if that matters. So I was planning to wipe them anyway.\n\n1. Is it likely that the improper shutdowns contributed to the bad sectors?\n2. Is it likely that wiping the drives could solve this somehow?\n3. Should I not use that drive?\n\nThanks", "author_fullname": "t2_1ppymy6t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drive reports *6* bad sectors after moving from old NAS to new NAS.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187abcp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701320306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve had this janky QNAP NAS for years. It&amp;#39;s janky because my apartment got hit by lightning a few years ago and fried one of the ethernet ports.&lt;/p&gt;\n\n&lt;p&gt;Ever since then, I had been using it (against my better judgment) because the other ethernet port still worked so I was able to keep using it.&lt;/p&gt;\n\n&lt;p&gt;I finally got a new NAS (Synology) and two new drives and migrated all my data over. Whew!&lt;/p&gt;\n\n&lt;p&gt;But now I&amp;#39;ve got two empty slots so I figured I would move over the newer of 2 of the 4 drives from my old QNAP NAS.&lt;/p&gt;\n\n&lt;p&gt;But the QNAP has a weird issue... it never shuts down properly, possibly related to the lightning. Any time you tell it to shut down, it just reboots. So I basically told it to shut down and once it seemed close to rebooting, I just pulled the power cord.&lt;/p&gt;\n\n&lt;p&gt;Then I moved those two newer drives over to the Synology NAS which is when it told me that one drive has &lt;em&gt;six&lt;/em&gt; bad sectors. The drives are encrypted by QNAP&amp;#39;s OS if that matters. So I was planning to wipe them anyway.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is it likely that the improper shutdowns contributed to the bad sectors?&lt;/li&gt;\n&lt;li&gt;Is it likely that wiping the drives could solve this somehow?&lt;/li&gt;\n&lt;li&gt;Should I not use that drive?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187abcp", "is_robot_indexable": true, "report_reasons": null, "author": "CactusBoyScout", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187abcp/drive_reports_6_bad_sectors_after_moving_from_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187abcp/drive_reports_6_bad_sectors_after_moving_from_old/", "subreddit_subscribers": 715321, "created_utc": 1701320306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an Unraid system with 14 drives in the NAS, and a DAS with 8 drives connected.\n\nCurrently I have 6 drives in NAS connected via motherboard sata, and the other 8 via a pcie to sata card.\n\nI then have an 8e HBA in IT mode connected to a SFF-8087 to SFF-8088 adapter in the DAS, connecting to the 8 drives.\n\nI am changing the motherboard and CPU, and stupidly brought a motherboard with only 4 sata, 1 x pcie x16, and 1 pcie x4.\n\nIs there a SAS expander I could get, along with an internal HBA, that could connect to the internal drives of the NAS, and then have external ports to go to the DAS? I looked at the Adaptec 82885T, and apparently the 2 external ports are input only. Would it maybe better to get 2 of those, 1 in NAS, and 1 in the DAS, and use my current HBA 8e to connect to them both?", "author_fullname": "t2_aodccc8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAS expander options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187br0y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701325077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an Unraid system with 14 drives in the NAS, and a DAS with 8 drives connected.&lt;/p&gt;\n\n&lt;p&gt;Currently I have 6 drives in NAS connected via motherboard sata, and the other 8 via a pcie to sata card.&lt;/p&gt;\n\n&lt;p&gt;I then have an 8e HBA in IT mode connected to a SFF-8087 to SFF-8088 adapter in the DAS, connecting to the 8 drives.&lt;/p&gt;\n\n&lt;p&gt;I am changing the motherboard and CPU, and stupidly brought a motherboard with only 4 sata, 1 x pcie x16, and 1 pcie x4.&lt;/p&gt;\n\n&lt;p&gt;Is there a SAS expander I could get, along with an internal HBA, that could connect to the internal drives of the NAS, and then have external ports to go to the DAS? I looked at the Adaptec 82885T, and apparently the 2 external ports are input only. Would it maybe better to get 2 of those, 1 in NAS, and 1 in the DAS, and use my current HBA 8e to connect to them both?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "To the Cloud!", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187br0y", "is_robot_indexable": true, "report_reasons": null, "author": "minimaddnz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/187br0y/sas_expander_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187br0y/sas_expander_options/", "subreddit_subscribers": 715321, "created_utc": 1701325077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m trying to expand my ZFS pool on the cheap, and am torn between shucking the $150 dollar Seagate 14TB externals vs buying a manufactured refurbished Seagate 16TB from ServerPartsDeals for the same price. What would y\u2019all\u2019s recommendation be based on experience or longevity data? \n\nThanks for your help!", "author_fullname": "t2_2mooplap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucked vs Refurbished", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187lveh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701359934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to expand my ZFS pool on the cheap, and am torn between shucking the $150 dollar Seagate 14TB externals vs buying a manufactured refurbished Seagate 16TB from ServerPartsDeals for the same price. What would y\u2019all\u2019s recommendation be based on experience or longevity data? &lt;/p&gt;\n\n&lt;p&gt;Thanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187lveh", "is_robot_indexable": true, "report_reasons": null, "author": "techromancer1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187lveh/shucked_vs_refurbished/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187lveh/shucked_vs_refurbished/", "subreddit_subscribers": 715321, "created_utc": 1701359934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\n&amp;#x200B;\n\nI would like some advice on how to archive a large number of download links from the [https://uloz.to](https://uloz.to) website.\n\n&amp;#x200B;\n\nIt's a public file sharing website which unfortunately disables searching between their files and then it should only be possible to download if you have a link to the file you want to download.\n\nIs there any way to back up the links to the files that are in their database? Is there a script that can go through it one by one and write them to an excel file?\n\n&amp;#x200B;\n\nThank you for your help.", "author_fullname": "t2_f6ydydphm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to backup links to files on uloz.to", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187epf1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701340394.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701336801.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would like some advice on how to archive a large number of download links from the &lt;a href=\"https://uloz.to\"&gt;https://uloz.to&lt;/a&gt; website.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a public file sharing website which unfortunately disables searching between their files and then it should only be possible to download if you have a link to the file you want to download.&lt;/p&gt;\n\n&lt;p&gt;Is there any way to back up the links to the files that are in their database? Is there a script that can go through it one by one and write them to an excel file?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3Q97mNEkTbNb6kLsRXcZnSnjZDfXCltsjWeb7wsPKMs.jpg?auto=webp&amp;s=1c3764a4072f31b6ea14d42c813aee98e03f8c6a", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/3Q97mNEkTbNb6kLsRXcZnSnjZDfXCltsjWeb7wsPKMs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0c3c1ed6e2d39c413f1fc4a7628138ad38863d3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/3Q97mNEkTbNb6kLsRXcZnSnjZDfXCltsjWeb7wsPKMs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7094c96b5ad9a7c958820029341084039e88097e", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/3Q97mNEkTbNb6kLsRXcZnSnjZDfXCltsjWeb7wsPKMs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24bc78655d394adaba1e32e7faad7399bed4dbf6", "width": 320, "height": 320}], "variants": {}, "id": "pRqK59bWm7VS-3qKQR_j8gMutFJRCzJjMa9gYDelECk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187epf1", "is_robot_indexable": true, "report_reasons": null, "author": "FeelsGoodBlok", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187epf1/how_to_backup_links_to_files_on_ulozto/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187epf1/how_to_backup_links_to_files_on_ulozto/", "subreddit_subscribers": 715321, "created_utc": 1701336801.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone shucked one of these?\n\nAre you able to use the drive or is it encrypted?\n\nWhat drive is inside? One site says it's an Exos X20z which is HSMR.\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_3t236", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20TB Seagate One Touch Hub shuck", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18715ux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701294754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone shucked one of these?&lt;/p&gt;\n\n&lt;p&gt;Are you able to use the drive or is it encrypted?&lt;/p&gt;\n\n&lt;p&gt;What drive is inside? One site says it&amp;#39;s an Exos X20z which is HSMR.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "18715ux", "is_robot_indexable": true, "report_reasons": null, "author": "xkegsx", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/18715ux/20tb_seagate_one_touch_hub_shuck/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/18715ux/20tb_seagate_one_touch_hub_shuck/", "subreddit_subscribers": 715321, "created_utc": 1701294754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't know of a repair tool for an imgc file and here is the error message I'm getting when trying to write with the HDD Raw Copy Tool  Access violation at address 0040608 in module \"HDDRawCopy1.20Portable.exe\". Read of address 8591F84A. My question is how do I find that and repair it so it can get past the 74% mark when writing?\n\nFor more context [https://www.reddit.com/r/datarecovery/comments/186yhtt/how\\_do\\_i\\_repair\\_this\\_corrupted\\_chunk\\_of\\_data/](https://www.reddit.com/r/datarecovery/comments/186yhtt/how_do_i_repair_this_corrupted_chunk_of_data/)", "author_fullname": "t2_bkin1n0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I use WinHex to repair a corrupted chunk of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1870k9a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701293226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know of a repair tool for an imgc file and here is the error message I&amp;#39;m getting when trying to write with the HDD Raw Copy Tool  Access violation at address 0040608 in module &amp;quot;HDDRawCopy1.20Portable.exe&amp;quot;. Read of address 8591F84A. My question is how do I find that and repair it so it can get past the 74% mark when writing?&lt;/p&gt;\n\n&lt;p&gt;For more context &lt;a href=\"https://www.reddit.com/r/datarecovery/comments/186yhtt/how_do_i_repair_this_corrupted_chunk_of_data/\"&gt;https://www.reddit.com/r/datarecovery/comments/186yhtt/how_do_i_repair_this_corrupted_chunk_of_data/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1870k9a", "is_robot_indexable": true, "report_reasons": null, "author": "BikesOnDykes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1870k9a/how_do_i_use_winhex_to_repair_a_corrupted_chunk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1870k9a/how_do_i_use_winhex_to_repair_a_corrupted_chunk/", "subreddit_subscribers": 715321, "created_utc": 1701293226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Thunderbolt 3 G-Raid with two 4TB Ultrastars. I ordered two 14TB Seagate Expansions from Costco on Black Friday to shuck and upgrade the G-Raid.\n\nI was expecting Ironwolf Pro or Exos x14 but am seeing some of the recently shucked drives are actually Exos 2x14.\n\nDoes anyone have experience using 2x SATA drives in a G-Raid enclosure?\n\nI\u2019ve read SAS drives will appear as half or separate drives but couldn\u2019t find much about SATA.\n\nAm I the Guinea pig? Should I back out before I start?", "author_fullname": "t2_ivxyt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos 2x14 + G-Raid", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_187oofg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701367051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Thunderbolt 3 G-Raid with two 4TB Ultrastars. I ordered two 14TB Seagate Expansions from Costco on Black Friday to shuck and upgrade the G-Raid.&lt;/p&gt;\n\n&lt;p&gt;I was expecting Ironwolf Pro or Exos x14 but am seeing some of the recently shucked drives are actually Exos 2x14.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience using 2x SATA drives in a G-Raid enclosure?&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve read SAS drives will appear as half or separate drives but couldn\u2019t find much about SATA.&lt;/p&gt;\n\n&lt;p&gt;Am I the Guinea pig? Should I back out before I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187oofg", "is_robot_indexable": true, "report_reasons": null, "author": "V7KTR", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187oofg/seagate_exos_2x14_graid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187oofg/seagate_exos_2x14_graid/", "subreddit_subscribers": 715321, "created_utc": 1701367051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, in purchasing or re-purposing used drives to add to a large veeam repository, I've run into various ways that drives have been locked. So far, I've seen three different ways that sas drives have been locked in a way that I could not initially use them in my KTL3 shelves attached to TrueNAS SCALE servers.\n\n&amp;nbsp;\n\n**1. SED locking:**\nI have disks from retired tegile disk arrays. I went to spin these drives up, and they were basically unreadable, and dmesg was spitting out a bunch of errors. You can identify these disks physically because they have a PSID printed on the top of them.\nTo clear these locks, you can use the sedutil-cli utility to wipe the disk and clear the lock:\n\n    sedutil-cli --yesIreallywanttoERASEALLmydatausingthePSID &lt;PSID key goes here&gt; /dev/sdr\n\nThis process ran in seconds, and access was gained to the drive.\n\n&amp;nbsp;\n\n**2. T10-DIF:**\nThis wasn't obvious to me, as I've seen netapp formatted drives that won't read because linux won't read 520 byte block size drives. These drives, tho, reported as 512B formatted drives, but I couldn't read/write them. Upon further inspection, I found that they were indeed formatted at 512B blocks, but then there was another 8 bits of data, resulting in 520B blocks. I was able to reformat them with:\n\n    sg_format --format --size=512 /dev/sdl\n\nThis process takes time, nearly 12-24 hours, per drive (12TB disks). After the format was complete, i pulled and reinserted the drives into the shelf and was able to access them successfully. tmux was helpful in formatting the disks in parallel so i didn't have to wait for each one to finish before starting the next.\n\n&amp;nbsp;\n\n**3. SCSI reservation:**\nThis was even more obscure. I popped a drive in the shelf, and unlike the other drives that spun up and the activity light went out, these drives out of another tegile array came up and the activity light came on, blinked a few times as linux identified it, and then remained on. I was seeing the following in dmesg:\n\n    [174050.317023]  sdt: unable to read partition table\n    [174050.318401] sd 8:0:25:0: [sdt] Attached SCSI disk\n    [174050.899555] hpsa 0000:05:00.0: cp 0000000004843087 has status 0x18 Sense: 0xff, ASC: 0xff, ASCQ: 0xff, Returning result: 0x18\n    [174050.901621] sd 8:0:25:0: reservation conflict\n\nThese were locked in a way that the disk was inaccessible because the access was reserved at a SCSI command level by the firmware of the drive, so this wasn't about the format of the disk, or an encryption key, but at a lower level where the host simply is denied access to the drive because another host as some time set a reservation, and the current host can't automatically clear it to gain access. I was able to gain access by using sg_persist to set a new reservation, and then clear all reservations with it:\n\n    sg_persist --out --register-ignore  --param-sark=abc1234 /dev/sdr\n    sg_persist /dev/sdr\n    No service action given; assume Persistent Reserve In command\n    with Read Keys service action\n      HGST      HUS726040ALS211   BD05\n      Peripheral device type: disk\n      PR generation=0x2, 2 registered reservation keys follow:\n        0xabc1234\n        0x5bf43c4200000001\n    sg_persist --out -C --param-rk=abc1234 /dev/sdr\n\n&amp;nbsp;&amp;nbsp;\n\nFor the tegile drives, they were ALL sed locked, but three disk out of each system had scsi reservations set. I had to clear the scsi reservation, then clear the disk with SED PSID, and then the drives were accessable. I could not see, via sedutil-cli, that they were SED locked until the scsi reservation was cleared.\n\n&amp;nbsp;&amp;nbsp;\n\nI don't know who this will help, but thought I'd throw it out there for us folks not paying for new drives.", "author_fullname": "t2_16lp28n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "read only / locked hard drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187lcm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701360530.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701358571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, in purchasing or re-purposing used drives to add to a large veeam repository, I&amp;#39;ve run into various ways that drives have been locked. So far, I&amp;#39;ve seen three different ways that sas drives have been locked in a way that I could not initially use them in my KTL3 shelves attached to TrueNAS SCALE servers.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. SED locking:&lt;/strong&gt;\nI have disks from retired tegile disk arrays. I went to spin these drives up, and they were basically unreadable, and dmesg was spitting out a bunch of errors. You can identify these disks physically because they have a PSID printed on the top of them.\nTo clear these locks, you can use the sedutil-cli utility to wipe the disk and clear the lock:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sedutil-cli --yesIreallywanttoERASEALLmydatausingthePSID &amp;lt;PSID key goes here&amp;gt; /dev/sdr\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This process ran in seconds, and access was gained to the drive.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. T10-DIF:&lt;/strong&gt;\nThis wasn&amp;#39;t obvious to me, as I&amp;#39;ve seen netapp formatted drives that won&amp;#39;t read because linux won&amp;#39;t read 520 byte block size drives. These drives, tho, reported as 512B formatted drives, but I couldn&amp;#39;t read/write them. Upon further inspection, I found that they were indeed formatted at 512B blocks, but then there was another 8 bits of data, resulting in 520B blocks. I was able to reformat them with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sg_format --format --size=512 /dev/sdl\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This process takes time, nearly 12-24 hours, per drive (12TB disks). After the format was complete, i pulled and reinserted the drives into the shelf and was able to access them successfully. tmux was helpful in formatting the disks in parallel so i didn&amp;#39;t have to wait for each one to finish before starting the next.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3. SCSI reservation:&lt;/strong&gt;\nThis was even more obscure. I popped a drive in the shelf, and unlike the other drives that spun up and the activity light went out, these drives out of another tegile array came up and the activity light came on, blinked a few times as linux identified it, and then remained on. I was seeing the following in dmesg:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[174050.317023]  sdt: unable to read partition table\n[174050.318401] sd 8:0:25:0: [sdt] Attached SCSI disk\n[174050.899555] hpsa 0000:05:00.0: cp 0000000004843087 has status 0x18 Sense: 0xff, ASC: 0xff, ASCQ: 0xff, Returning result: 0x18\n[174050.901621] sd 8:0:25:0: reservation conflict\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;These were locked in a way that the disk was inaccessible because the access was reserved at a SCSI command level by the firmware of the drive, so this wasn&amp;#39;t about the format of the disk, or an encryption key, but at a lower level where the host simply is denied access to the drive because another host as some time set a reservation, and the current host can&amp;#39;t automatically clear it to gain access. I was able to gain access by using sg_persist to set a new reservation, and then clear all reservations with it:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sg_persist --out --register-ignore  --param-sark=abc1234 /dev/sdr\nsg_persist /dev/sdr\nNo service action given; assume Persistent Reserve In command\nwith Read Keys service action\n  HGST      HUS726040ALS211   BD05\n  Peripheral device type: disk\n  PR generation=0x2, 2 registered reservation keys follow:\n    0xabc1234\n    0x5bf43c4200000001\nsg_persist --out -C --param-rk=abc1234 /dev/sdr\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;For the tegile drives, they were ALL sed locked, but three disk out of each system had scsi reservations set. I had to clear the scsi reservation, then clear the disk with SED PSID, and then the drives were accessable. I could not see, via sedutil-cli, that they were SED locked until the scsi reservation was cleared.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know who this will help, but thought I&amp;#39;d throw it out there for us folks not paying for new drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187lcm0", "is_robot_indexable": true, "report_reasons": null, "author": "gmc_5303", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187lcm0/read_only_locked_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187lcm0/read_only_locked_hard_drives/", "subreddit_subscribers": 715321, "created_utc": 1701358571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've read quite a few threads here and on [digitalfaq.com](https://digitalfaq.com), but it seems that people often comment under the assumption that everyone uses the same operating system as them (whichever that may be). \n\nI use a Mac (apple silicon) and am trying to digitize some Video8 tapes. I have a camera that can output S-Video but need a capture card. I've seen this card linked [https://streameez.com/product/610/](https://streameez.com/product/610/) but the software does not support Mac. I've seen people recommend open source software such as FFmpeg which work on Mac, but I'm not sure if I'll run into compatibility issues between the card and software.\n\nI've seen the blackmagic cards recommended, but they're out of my price range. I'd like to stay under $150 for this link in the chain. \n\nDoes anyone here have experience with S-Video digitization on Mac? Any advice will be appreciated!", "author_fullname": "t2_5hwbmov1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video8 tapes via S-Video to Mac. Which capture card can I use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187ihgc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701350778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read quite a few threads here and on &lt;a href=\"https://digitalfaq.com\"&gt;digitalfaq.com&lt;/a&gt;, but it seems that people often comment under the assumption that everyone uses the same operating system as them (whichever that may be). &lt;/p&gt;\n\n&lt;p&gt;I use a Mac (apple silicon) and am trying to digitize some Video8 tapes. I have a camera that can output S-Video but need a capture card. I&amp;#39;ve seen this card linked &lt;a href=\"https://streameez.com/product/610/\"&gt;https://streameez.com/product/610/&lt;/a&gt; but the software does not support Mac. I&amp;#39;ve seen people recommend open source software such as FFmpeg which work on Mac, but I&amp;#39;m not sure if I&amp;#39;ll run into compatibility issues between the card and software.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen the blackmagic cards recommended, but they&amp;#39;re out of my price range. I&amp;#39;d like to stay under $150 for this link in the chain. &lt;/p&gt;\n\n&lt;p&gt;Does anyone here have experience with S-Video digitization on Mac? Any advice will be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187ihgc", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Childhood", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187ihgc/video8_tapes_via_svideo_to_mac_which_capture_card/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187ihgc/video8_tapes_via_svideo_to_mac_which_capture_card/", "subreddit_subscribers": 715321, "created_utc": 1701350778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4ohl4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thinking of a simple upgrade for cheap, what do y'all think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187hke4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1701347852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "govdeals.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.govdeals.com/asset/341/12217", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187hke4", "is_robot_indexable": true, "report_reasons": null, "author": "Nicker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187hke4/thinking_of_a_simple_upgrade_for_cheap_what_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.govdeals.com/asset/341/12217", "subreddit_subscribers": 715321, "created_utc": 1701347852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a bunch of older 2.5\" SSDs and would like to use those. I already have a SAS capable Debian Linux host and would like to attach a disk shelf / jbod case to it. A SAS2 solution would be fine since bandwidth is not critical for my application. I'm not sure whether an older used EMC or NetApp case would be a good option since those (imho) tend to be setup with proprietary hardware?\n\nOptions I'm considering:\n\n[HP 19\\\\\" Storserv 8000 Storage 24x 2,5\\\\\"](https://preview.redd.it/kevj5oucqf3c1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=ef4b94d7b4bf0516c0077340789ca1c8f19f3c67)\n\n&amp;#x200B;\n\n[DELL PowerVault MD1200](https://preview.redd.it/vai47l8jqf3c1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=c5e9b07d1f14070424c9330b7b8dcde4cc4c785d)\n\nFeedback and suggestions are welcome.\n\n  \n\n\n&amp;#x200B;", "author_fullname": "t2_xsvaa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2.5\" Storage POD / JBOD / Disk Shelf suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vai47l8jqf3c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 58, "x": 108, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2e52b14af5ec0075b871d1a312bb29004075234"}, {"y": 116, "x": 216, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a8873a74a8133ec1286f11349cc1e511e3faefb"}, {"y": 172, "x": 320, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3770cbb0b9a5382e9e5ec6e6ab321284a54bf878"}, {"y": 344, "x": 640, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8989c897a66944949a81d53fb6a075c7e01ec87"}, {"y": 516, "x": 960, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=faf976b43b459d61167ab44413ad58b73375b1fa"}, {"y": 580, "x": 1080, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b7adf02f2a94748bee2e9d245d0b7dd34d6af5a"}], "s": {"y": 645, "x": 1200, "u": "https://preview.redd.it/vai47l8jqf3c1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=c5e9b07d1f14070424c9330b7b8dcde4cc4c785d"}, "id": "vai47l8jqf3c1"}, "kevj5oucqf3c1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 62, "x": 108, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e495b1bd5a73d1bdeb6b4db55bfe0dbadd7f1a60"}, {"y": 124, "x": 216, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb749e368a775a2767c147ff48b851fe5d699f66"}, {"y": 184, "x": 320, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a4514b7161c537955521011d06a1828ea1cc58eb"}, {"y": 368, "x": 640, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b9ace8d7e899dae60da8c649b35bfe3ab6cbd39"}, {"y": 552, "x": 960, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa64968d2d4b66889ee8393d2516d4803052d7bb"}, {"y": 621, "x": 1080, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05f185d824fc9104c7799de24d151dc236454080"}], "s": {"y": 691, "x": 1200, "u": "https://preview.redd.it/kevj5oucqf3c1.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=ef4b94d7b4bf0516c0077340789ca1c8f19f3c67"}, "id": "kevj5oucqf3c1"}}, "name": "t3_187cnf4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kfomtneHSzQxDUljcaTesgMJe3i2WlVgDb38Qgu095E.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701328462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of older 2.5&amp;quot; SSDs and would like to use those. I already have a SAS capable Debian Linux host and would like to attach a disk shelf / jbod case to it. A SAS2 solution would be fine since bandwidth is not critical for my application. I&amp;#39;m not sure whether an older used EMC or NetApp case would be a good option since those (imho) tend to be setup with proprietary hardware?&lt;/p&gt;\n\n&lt;p&gt;Options I&amp;#39;m considering:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kevj5oucqf3c1.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ef4b94d7b4bf0516c0077340789ca1c8f19f3c67\"&gt;HP 19\\&amp;quot; Storserv 8000 Storage 24x 2,5\\&amp;quot;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vai47l8jqf3c1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c5e9b07d1f14070424c9330b7b8dcde4cc4c785d\"&gt;DELL PowerVault MD1200&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feedback and suggestions are welcome.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187cnf4", "is_robot_indexable": true, "report_reasons": null, "author": "Jotschi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/187cnf4/25_storage_pod_jbod_disk_shelf_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187cnf4/25_storage_pod_jbod_disk_shelf_suggestions/", "subreddit_subscribers": 715321, "created_utc": 1701328462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Originally I had one 16 TB hard drive that I used to store my media, from a Synology NAS. I recently got 7 more hard drives with 4tb of capacity each for super cheap to put in an old desktop case. What would be the best way to set this up with pools and vDevs? (currently have TrueNAS) I keep all of my essential data backed up separately so while it is not critical to have redundancy it would be extremely inconvenient and time consuming to replace the current 10 TB I have. I'm new to this and would like to do it correctly the first time. \n\nHopefully I am using these terms correctly, if not let me know.", "author_fullname": "t2_ui7yc7hu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pools and vDevs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1872v16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701299103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Originally I had one 16 TB hard drive that I used to store my media, from a Synology NAS. I recently got 7 more hard drives with 4tb of capacity each for super cheap to put in an old desktop case. What would be the best way to set this up with pools and vDevs? (currently have TrueNAS) I keep all of my essential data backed up separately so while it is not critical to have redundancy it would be extremely inconvenient and time consuming to replace the current 10 TB I have. I&amp;#39;m new to this and would like to do it correctly the first time. &lt;/p&gt;\n\n&lt;p&gt;Hopefully I am using these terms correctly, if not let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1872v16", "is_robot_indexable": true, "report_reasons": null, "author": "TheKingMongo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1872v16/pools_and_vdevs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1872v16/pools_and_vdevs/", "subreddit_subscribers": 715321, "created_utc": 1701299103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've just set up my first drive pool of HDD connected to a 4 bay docking station to my laptop, but I'm running into issue trying to disconnect my docking station.\n\nWhen I try to use the windows native eject feature, I get this error:  \nThis device is currently in use. Close any programs or windows that might be using the device, then try again.\n\nI've tried disabling drive pool service but it doesn't work.\n\nThere's no option to offline the disk in disk management.\n\nHow do I safely disconnect my HDD?", "author_fullname": "t2_8d7mlep8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Safely Disconnect Disk With Drive Pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1870sy2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701293851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just set up my first drive pool of HDD connected to a 4 bay docking station to my laptop, but I&amp;#39;m running into issue trying to disconnect my docking station.&lt;/p&gt;\n\n&lt;p&gt;When I try to use the windows native eject feature, I get this error:&lt;br/&gt;\nThis device is currently in use. Close any programs or windows that might be using the device, then try again.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried disabling drive pool service but it doesn&amp;#39;t work.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no option to offline the disk in disk management.&lt;/p&gt;\n\n&lt;p&gt;How do I safely disconnect my HDD?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1870sy2", "is_robot_indexable": true, "report_reasons": null, "author": "Far_Purple847", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1870sy2/how_to_safely_disconnect_disk_with_drive_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1870sy2/how_to_safely_disconnect_disk_with_drive_pool/", "subreddit_subscribers": 715321, "created_utc": 1701293851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,  \n\nAbout one month ago, I got a new PC with only SSDs and I have been watching closely how much data has been written. Twice so far, I have noticed in SeaTools that when Windows performs its automatic drive optimization (I left it on the default \u201cWeekly\u201d setting), a lot of writes were added to the SSD : a few days after installing Windows, about 36 GB, and today, over 20 GB suddenly. I am sure that it\u2019s not because of another program or Windows updates. I have been getting few writes in general in the past days and didn\u2019t install any new program either. That\u2019s the SSD Windows is installed on ; I have another one that only got much smaller TBW increases because of Windows\u2019s optimization.  \n\nMy question is : is this normal, especially considering that my SSD only has 71.5 GiB of space used (2 TB total)? I know that Windows may sometimes have to defragment an SSD ([https://www.hanselman.com/blog/the-real-and-complete-story-does-windows-defragment-your-ssd](https://www.hanselman.com/blog/the-real-and-complete-story-does-windows-defragment-your-ssd)), but this is supposed to be once a month only.  \n\nI couldn\u2019t find anything else about this question on the web, besides people saying that re-trim shouldn\u2019t do anything if TRIM could happen normally in the first place and that it shouldn\u2019t cause additional wear on the drive, but maybe that\u2019s wrong\u202f?  \n\nCould a reason this is happening be that after Windows re-trims it, the drive decides to move data around because of wear-levelling\u202f?  \n\nThank you", "author_fullname": "t2_fy3qqpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal that Windows\u2019s automatic SSD optimisation / re-trim sometimes generates a lot of writes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187km9b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701357706.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701356633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;About one month ago, I got a new PC with only SSDs and I have been watching closely how much data has been written. Twice so far, I have noticed in SeaTools that when Windows performs its automatic drive optimization (I left it on the default \u201cWeekly\u201d setting), a lot of writes were added to the SSD : a few days after installing Windows, about 36 GB, and today, over 20 GB suddenly. I am sure that it\u2019s not because of another program or Windows updates. I have been getting few writes in general in the past days and didn\u2019t install any new program either. That\u2019s the SSD Windows is installed on ; I have another one that only got much smaller TBW increases because of Windows\u2019s optimization.  &lt;/p&gt;\n\n&lt;p&gt;My question is : is this normal, especially considering that my SSD only has 71.5 GiB of space used (2 TB total)? I know that Windows may sometimes have to defragment an SSD (&lt;a href=\"https://www.hanselman.com/blog/the-real-and-complete-story-does-windows-defragment-your-ssd\"&gt;https://www.hanselman.com/blog/the-real-and-complete-story-does-windows-defragment-your-ssd&lt;/a&gt;), but this is supposed to be once a month only.  &lt;/p&gt;\n\n&lt;p&gt;I couldn\u2019t find anything else about this question on the web, besides people saying that re-trim shouldn\u2019t do anything if TRIM could happen normally in the first place and that it shouldn\u2019t cause additional wear on the drive, but maybe that\u2019s wrong\u202f?  &lt;/p&gt;\n\n&lt;p&gt;Could a reason this is happening be that after Windows re-trims it, the drive decides to move data around because of wear-levelling\u202f?  &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HaDTcWZbMjg0vdBEcjTl_lgBjnpfyGRVthc8qHECtlw.jpg?auto=webp&amp;s=e08314b987f745620a8fc4ae0d2825b50216db59", "width": 817, "height": 678}, "resolutions": [{"url": "https://external-preview.redd.it/HaDTcWZbMjg0vdBEcjTl_lgBjnpfyGRVthc8qHECtlw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=764a9439c351f8ea6d40fd8e364a9dc766422e50", "width": 108, "height": 89}, {"url": "https://external-preview.redd.it/HaDTcWZbMjg0vdBEcjTl_lgBjnpfyGRVthc8qHECtlw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=01b6ae9588fc9a3140f7fc3b1c1b0de291dfce84", "width": 216, "height": 179}, {"url": "https://external-preview.redd.it/HaDTcWZbMjg0vdBEcjTl_lgBjnpfyGRVthc8qHECtlw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=97bf45b2aea6ddd0029f88cdddd15a9164d5d278", "width": 320, "height": 265}, {"url": "https://external-preview.redd.it/HaDTcWZbMjg0vdBEcjTl_lgBjnpfyGRVthc8qHECtlw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=89a2afa5777775ca73badb3a865af936e3201f19", "width": 640, "height": 531}], "variants": {}, "id": "1M50YzLY4nZbBlqOmoLHMDyDiLH3QoEw8CgkqQ6LHcM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187km9b", "is_robot_indexable": true, "report_reasons": null, "author": "1wvy9x", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187km9b/is_it_normal_that_windowss_automatic_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187km9b/is_it_normal_that_windowss_automatic_ssd/", "subreddit_subscribers": 715321, "created_utc": 1701356633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Are there any downsides to using say an Ultrastar or Exos hard drive for surveillance. Apparently the purples and skyhawks have firmware to not wait on writes but from what I understand enterprise drives have that too.", "author_fullname": "t2_6qlnjwcg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are enterprise hard drives good for NVR/DVR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187k35v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701355250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any downsides to using say an Ultrastar or Exos hard drive for surveillance. Apparently the purples and skyhawks have firmware to not wait on writes but from what I understand enterprise drives have that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "27,939 GiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "187k35v", "is_robot_indexable": true, "report_reasons": null, "author": "ZestyPotatoe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/187k35v/are_enterprise_hard_drives_good_for_nvrdvr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187k35v/are_enterprise_hard_drives_good_for_nvrdvr/", "subreddit_subscribers": 715321, "created_utc": 1701355250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI have a lacie 2tb rugged HDD. The last couple of days I've had some issues. While editing, all the sudden my files can't be found, and when I go on my hard drive, my computer recognizes it, and it says the drive is almost full when I check the storage, but the files are not there. I restart my computer and it is back to normal, it has done this twice. I have backed up the drive of course, but is the drive failing?\n\nLooking at a replacement SSD, any recommendations for SSDs for sandisk vs samsung? I travel a lot and like robust drives", "author_fullname": "t2_s8j5ghv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my hard drive failing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_187eiq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701336044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have a lacie 2tb rugged HDD. The last couple of days I&amp;#39;ve had some issues. While editing, all the sudden my files can&amp;#39;t be found, and when I go on my hard drive, my computer recognizes it, and it says the drive is almost full when I check the storage, but the files are not there. I restart my computer and it is back to normal, it has done this twice. I have backed up the drive of course, but is the drive failing?&lt;/p&gt;\n\n&lt;p&gt;Looking at a replacement SSD, any recommendations for SSDs for sandisk vs samsung? I travel a lot and like robust drives&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "187eiq4", "is_robot_indexable": true, "report_reasons": null, "author": "longemail_ilai", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/187eiq4/is_my_hard_drive_failing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/187eiq4/is_my_hard_drive_failing/", "subreddit_subscribers": 715321, "created_utc": 1701336044.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}