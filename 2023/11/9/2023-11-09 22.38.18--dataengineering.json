{"kind": "Listing", "data": {"after": "t3_17raw1l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm looking for learning and  training for data engineers based around docker? I'm trying to understand best practices and use cases? The tools I've seen seem kind of straight forward? I scoured the wiki within this group and only found one article dbt and docker so not really what I'm looking for. How pertinent is it to know and be familiar with? Being within the space I've never touched it since we primarily work in the cloud and our tools have never required it. How much weight does it carry within the space as a skill and are there any SMEs I should follow? Thanks", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Struggling with Docker? Best Practices and Info?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17qzmfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699487865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m looking for learning and  training for data engineers based around docker? I&amp;#39;m trying to understand best practices and use cases? The tools I&amp;#39;ve seen seem kind of straight forward? I scoured the wiki within this group and only found one article dbt and docker so not really what I&amp;#39;m looking for. How pertinent is it to know and be familiar with? Being within the space I&amp;#39;ve never touched it since we primarily work in the cloud and our tools have never required it. How much weight does it carry within the space as a skill and are there any SMEs I should follow? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17qzmfw", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17qzmfw/data_engineer_struggling_with_docker_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17qzmfw/data_engineer_struggling_with_docker_best/", "subreddit_subscribers": 138847, "created_utc": 1699487865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hear about big data all the time but what about pulling small amounts of data hourly. I recently started a new job as a jr data eng and I have to automate a csv to azure to power bi process.\n\nIf you are pulling small amounts of data, such as a single row from a csv file, what etl tools/ data stacks could I use?\n\nI was just going to use spark but I feel like that a powerful tool for gigabytes of data haha.", "author_fullname": "t2_x2wmh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are Some Small Data ETL Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17r57f2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699504899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hear about big data all the time but what about pulling small amounts of data hourly. I recently started a new job as a jr data eng and I have to automate a csv to azure to power bi process.&lt;/p&gt;\n\n&lt;p&gt;If you are pulling small amounts of data, such as a single row from a csv file, what etl tools/ data stacks could I use?&lt;/p&gt;\n\n&lt;p&gt;I was just going to use spark but I feel like that a powerful tool for gigabytes of data haha.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17r57f2", "is_robot_indexable": true, "report_reasons": null, "author": "bonzerspider5", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r57f2/what_are_some_small_data_etl_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17r57f2/what_are_some_small_data_etl_tools/", "subreddit_subscribers": 138847, "created_utc": 1699504899.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\udc4bHey, folks! Exciting news - I am starting a new tutorial series \"Dagster Tutorial for Beginners\". \n\nI've just dropped the first video on \"Dagster Installation and Getting Started with Asset\"! \ud83d\ude80\n\nLet me know what part of dagster you want to see in the next video. \ud83d\udcf7", "author_fullname": "t2_h4j43yry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Tutorial: Dagster Installation and Getting Started with Asset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17r8kcw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/i9ay8ddOqX0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Dagster Installation and Getting Started with Asset\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Dagster Tutorial: Dagster Installation and Getting Started with Asset", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/i9ay8ddOqX0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Dagster Installation and Getting Started with Asset\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/i9ay8ddOqX0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/i9ay8ddOqX0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Dagster Installation and Getting Started with Asset\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17r8kcw", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/F_yOTzQX375-46eNIXZtPCusoBXo_i8dP4qYPn9NpsA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699518901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\udc4bHey, folks! Exciting news - I am starting a new tutorial series &amp;quot;Dagster Tutorial for Beginners&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just dropped the first video on &amp;quot;Dagster Installation and Getting Started with Asset&amp;quot;! \ud83d\ude80&lt;/p&gt;\n\n&lt;p&gt;Let me know what part of dagster you want to see in the next video. \ud83d\udcf7&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/i9ay8ddOqX0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LF2J8Rs98VsNf6ocTQL7wg9cCS9-1Em4bADaFfdS-B8.jpg?auto=webp&amp;s=2bdecfdf1df7bc5f7b7394e76c44ef0a5f3cf53b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/LF2J8Rs98VsNf6ocTQL7wg9cCS9-1Em4bADaFfdS-B8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8f955063da856b4b191551165fc29620cb1043c", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/LF2J8Rs98VsNf6ocTQL7wg9cCS9-1Em4bADaFfdS-B8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8ec339cc8afde85b954d47375c27b9e0cafdcbe7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/LF2J8Rs98VsNf6ocTQL7wg9cCS9-1Em4bADaFfdS-B8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ed7239380ef4f4ccc89d53c7cb2e7979a5b34a6", "width": 320, "height": 240}], "variants": {}, "id": "BWm_zV0APXV0fPmOqQBZsEytQjxAJ_GlpjfaxmHLgXA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17r8kcw", "is_robot_indexable": true, "report_reasons": null, "author": "Coder2j", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r8kcw/dagster_tutorial_dagster_installation_and_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/i9ay8ddOqX0", "subreddit_subscribers": 138847, "created_utc": 1699518901.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Dagster Tutorial: Dagster Installation and Getting Started with Asset", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/i9ay8ddOqX0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Dagster Tutorial: Dagster Installation and Getting Started with Asset\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/i9ay8ddOqX0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow engineers, I was wondering what the best database system is for storing and querying metadata?\n\nThe two solutions I have in mind are a document database or a graph database.\n\nA document database seems to be a good fit for this problem as it allow us to drop files/documents into collections without having to worry about schema differences etc that you would get with a RDMS. However, I am slightly concerned this will become a mess and querying it will be challenging. The document database we\u2019ve looked at so far is Mongodb which has worked so far with a bit of test data.\n\nI am also looking into a graph databases as it would make the querying of metadata a lot simpler and more intuitive for the users and the modelling part seems to fit quite well. However, similar to the document database, I don\u2019t have a lot of experience with this system.\n\nHave any of you worked with the systems mentioned above?\n\nWhat challenges and problems have you run into while using these systems?\n\nAre the systems mentioned above sensible suggestions for solving this problem? If not what would you suggest?\n\nThanks in advance for any that provide suggestions/feedback.", "author_fullname": "t2_1drdwjiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What database system is best for storing and querying metadata?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rg1t7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699545284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow engineers, I was wondering what the best database system is for storing and querying metadata?&lt;/p&gt;\n\n&lt;p&gt;The two solutions I have in mind are a document database or a graph database.&lt;/p&gt;\n\n&lt;p&gt;A document database seems to be a good fit for this problem as it allow us to drop files/documents into collections without having to worry about schema differences etc that you would get with a RDMS. However, I am slightly concerned this will become a mess and querying it will be challenging. The document database we\u2019ve looked at so far is Mongodb which has worked so far with a bit of test data.&lt;/p&gt;\n\n&lt;p&gt;I am also looking into a graph databases as it would make the querying of metadata a lot simpler and more intuitive for the users and the modelling part seems to fit quite well. However, similar to the document database, I don\u2019t have a lot of experience with this system.&lt;/p&gt;\n\n&lt;p&gt;Have any of you worked with the systems mentioned above?&lt;/p&gt;\n\n&lt;p&gt;What challenges and problems have you run into while using these systems?&lt;/p&gt;\n\n&lt;p&gt;Are the systems mentioned above sensible suggestions for solving this problem? If not what would you suggest?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any that provide suggestions/feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17rg1t7", "is_robot_indexable": true, "report_reasons": null, "author": "yorkshireSpud12", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rg1t7/what_database_system_is_best_for_storing_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rg1t7/what_database_system_is_best_for_storing_and/", "subreddit_subscribers": 138847, "created_utc": 1699545284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're a small company and try to keep our stack simple. We are loading updated rows in a Postgres DB and now I'm trying to build a star schema on top with SQL-queries. \n\nImplementing an incremental load of the dimensions while accounting for multiple SCD type 2 columns in one dimension requires *a lot* of custom logic, e.g. one updated rows in source data can lead to multiple new rows in the target, or multiple rows changing.\n\nIs this normal or are we missing some sql-patterns or tools? When googling or reading about SCD type 2s in SQL I only see quite simple examples covering only one SCD-column in a table or ignoring late-arriving data, retroactive corrections etc.\n\nWhat are the best resources to deal with these problems? \nThanks.", "author_fullname": "t2_13vt63", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is ELT with SCDs supposed to be that hard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rf30m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699542679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re a small company and try to keep our stack simple. We are loading updated rows in a Postgres DB and now I&amp;#39;m trying to build a star schema on top with SQL-queries. &lt;/p&gt;\n\n&lt;p&gt;Implementing an incremental load of the dimensions while accounting for multiple SCD type 2 columns in one dimension requires &lt;em&gt;a lot&lt;/em&gt; of custom logic, e.g. one updated rows in source data can lead to multiple new rows in the target, or multiple rows changing.&lt;/p&gt;\n\n&lt;p&gt;Is this normal or are we missing some sql-patterns or tools? When googling or reading about SCD type 2s in SQL I only see quite simple examples covering only one SCD-column in a table or ignoring late-arriving data, retroactive corrections etc.&lt;/p&gt;\n\n&lt;p&gt;What are the best resources to deal with these problems? \nThanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17rf30m", "is_robot_indexable": true, "report_reasons": null, "author": "GelmansDog", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rf30m/is_elt_with_scds_supposed_to_be_that_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rf30m/is_elt_with_scds_supposed_to_be_that_hard/", "subreddit_subscribers": 138847, "created_utc": 1699542679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apache Iceberg co-founder Ryan Blue recently published [a post](https://tabular.io/blog/iceberg-hudi-acid-guarantees/) in which he made a case that \"Iceberg is reliable and Apache Hudi is not\". \n\nVinoth Chandar responded with his [own take](https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees) bringing receipts and demonstrated Iceberg's own set of problems.\n\nThere are a lot of technicalities in both posts, but the biggest focus is on ACID guarantees in both systems and the difference in approaches to fulfill them.\n\nPersonally I think that transaction guarantees aren't as important in modern data lakes (will be happy to see examples of the opposite). \n\nWho is more convincing in your opinion?  ", "author_fullname": "t2_ntpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg vs Hudi beef over ACID guarantees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rm18a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699561206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apache Iceberg co-founder Ryan Blue recently published &lt;a href=\"https://tabular.io/blog/iceberg-hudi-acid-guarantees/\"&gt;a post&lt;/a&gt; in which he made a case that &amp;quot;Iceberg is reliable and Apache Hudi is not&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;Vinoth Chandar responded with his &lt;a href=\"https://www.onehouse.ai/blog/on-iceberg-and-hudi-acid-guarantees\"&gt;own take&lt;/a&gt; bringing receipts and demonstrated Iceberg&amp;#39;s own set of problems.&lt;/p&gt;\n\n&lt;p&gt;There are a lot of technicalities in both posts, but the biggest focus is on ACID guarantees in both systems and the difference in approaches to fulfill them.&lt;/p&gt;\n\n&lt;p&gt;Personally I think that transaction guarantees aren&amp;#39;t as important in modern data lakes (will be happy to see examples of the opposite). &lt;/p&gt;\n\n&lt;p&gt;Who is more convincing in your opinion?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?auto=webp&amp;s=b755d01d8028b7816e27daac9da363452b503031", "width": 1461, "height": 995}, "resolutions": [{"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3570e62f22eefab1224d9f2cdf43e9e1def4d2dc", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1719655f5ef922b6f39c8f111ae35eb06f7448a", "width": 216, "height": 147}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=818f132476f9f5f66cbea96b5e4b202947df1102", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a328cf34aa67b94d5d871250161a73d2d2080efb", "width": 640, "height": 435}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=076014ca1167676c6cff73b5448acab4f6a95b7f", "width": 960, "height": 653}, {"url": "https://external-preview.redd.it/_MCWq6i2FLpkWeypFiU4Z32goauxfJbhY2tfiC4lurY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=63331e9ddc9fe0af81c573e159bb192a34b3ccef", "width": 1080, "height": 735}], "variants": {}, "id": "E9d225te2hmOoFPeBhFoVU_8KtIwcxJK6c1pQ0OSsAQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rm18a", "is_robot_indexable": true, "report_reasons": null, "author": "DCman1993", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rm18a/iceberg_vs_hudi_beef_over_acid_guarantees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rm18a/iceberg_vs_hudi_beef_over_acid_guarantees/", "subreddit_subscribers": 138847, "created_utc": 1699561206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We use data in  long format, but PowerBI seems to me to feel better with wide", "author_fullname": "t2_xnkh1lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is better to use data in wide format or long format, when using Powert BI?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rajx1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699527907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We use data in  long format, but PowerBI seems to me to feel better with wide&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rajx1", "is_robot_indexable": true, "report_reasons": null, "author": "rlopez7", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rajx1/is_better_to_use_data_in_wide_format_or_long/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rajx1/is_better_to_use_data_in_wide_format_or_long/", "subreddit_subscribers": 138847, "created_utc": 1699527907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nLooking for some career advice on next steps. I was recently laid off and am looking for a new role but trying to find a better fit somewhere else. I don't know if full technical DE is my thing.\n\nBackground: I was previously a supply chain analyst -&gt; business analyst -&gt; Data engineer. I spent about a year being a data engineer before being laid off. Most of my DE time was fairly technical. It was taking a ticket, trying to solve it and move to the next one. My team were standard introverted engineers and barely interacted with other members. \n\nI'm a bit more social than the standard engineers, so I was missing a bit of the people side of things. I still enjoy the technical problem solve and working within systems, but just not independently on my own. I enjoy building things and creating processes, but not much maintaining them on business as usual basis. I worked mostly with gcp, bq, airflow, a bit of docker and dbt. I was wondering what roles are out there that is 50/50 business and technical, if possible leveraging the current skill set to be a bit more transferable.\n\nI've done a bit of researching and came to some of these thoughts:\n\n1. Lead/manager roles - more people oriented but I don't have management experience is less likely to get a role out of this. I have the soft skills but experience outweighs potential hard.\n\n2. Product owner roles - but sadly no po experience.\n\n3. Back to BI/data analyst-- I wasn't much of a fan for doing numerical analysis. I enjoy the build out but not really the analytical piece of the numbers.", "author_fullname": "t2_6o6sl8n7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyst to DE to 50/50 bus-tech role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17r8iii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699518671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Looking for some career advice on next steps. I was recently laid off and am looking for a new role but trying to find a better fit somewhere else. I don&amp;#39;t know if full technical DE is my thing.&lt;/p&gt;\n\n&lt;p&gt;Background: I was previously a supply chain analyst -&amp;gt; business analyst -&amp;gt; Data engineer. I spent about a year being a data engineer before being laid off. Most of my DE time was fairly technical. It was taking a ticket, trying to solve it and move to the next one. My team were standard introverted engineers and barely interacted with other members. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit more social than the standard engineers, so I was missing a bit of the people side of things. I still enjoy the technical problem solve and working within systems, but just not independently on my own. I enjoy building things and creating processes, but not much maintaining them on business as usual basis. I worked mostly with gcp, bq, airflow, a bit of docker and dbt. I was wondering what roles are out there that is 50/50 business and technical, if possible leveraging the current skill set to be a bit more transferable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a bit of researching and came to some of these thoughts:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Lead/manager roles - more people oriented but I don&amp;#39;t have management experience is less likely to get a role out of this. I have the soft skills but experience outweighs potential hard.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Product owner roles - but sadly no po experience.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Back to BI/data analyst-- I wasn&amp;#39;t much of a fan for doing numerical analysis. I enjoy the build out but not really the analytical piece of the numbers.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17r8iii", "is_robot_indexable": true, "report_reasons": null, "author": "Tasty_Fold3012", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r8iii/analyst_to_de_to_5050_bustech_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17r8iii/analyst_to_de_to_5050_bustech_role/", "subreddit_subscribers": 138847, "created_utc": 1699518671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work somewhere that has 13 ERPs and a dozen CRMs.  There is a bunch of IoT and a bunch of industrial stuff.\n\nI don't want to talk about the current setup, just a big mess...this industry with all its hype and plethora of tools has really fucked things up.\n\nTime to move on. What middle integration tool, data warehouse tool, and master data tools would you pick? \n\nPlease don't recommend a pattern that looks like spaghetti architecture.", "author_fullname": "t2_59fd6989", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Ultimate Situation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17r3upr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699500294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work somewhere that has 13 ERPs and a dozen CRMs.  There is a bunch of IoT and a bunch of industrial stuff.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to talk about the current setup, just a big mess...this industry with all its hype and plethora of tools has really fucked things up.&lt;/p&gt;\n\n&lt;p&gt;Time to move on. What middle integration tool, data warehouse tool, and master data tools would you pick? &lt;/p&gt;\n\n&lt;p&gt;Please don&amp;#39;t recommend a pattern that looks like spaghetti architecture.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17r3upr", "is_robot_indexable": true, "report_reasons": null, "author": "dongdesk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r3upr/the_ultimate_situation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17r3upr/the_ultimate_situation/", "subreddit_subscribers": 138847, "created_utc": 1699500294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark vs Polars. Real-life Test Case.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_17rgqew", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kkp2IHV-d9K4qxCreRUBHRMpxDbQja8zm2uy4ir_t9s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699547114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/spark-vs-polars-real-life-test-case", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?auto=webp&amp;s=05070bacd4a0da79f6046605095ac21e2a412110", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9dcefe80c15cbc886d27599c0d78b64bb3437c76", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9da237db45150d1845251e30e77574111f522029", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2722ebccff0065a23e3f25cf6ee802a5d24d1780", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eaca7ec4ba648c9e2c0bc16c7609e8673d3ad1a7", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/ZNt3-X9GXrTphSn2FbmPZ-utCkbmL8NA3GiWQ3xEBZw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bdecdac1c48e05a76f952f3436505bad61c4ac38", "width": 960, "height": 562}], "variants": {}, "id": "Q-RjjX_SqLLA22Omd29gCQitPbQgOOnRbDnPdTf_vuk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rgqew", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rgqew/spark_vs_polars_reallife_test_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/spark-vs-polars-real-life-test-case", "subreddit_subscribers": 138847, "created_utc": 1699547114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Video! Get a tour of the Airflow UI and the most helpful views \ud83e\udd29", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17rdim4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GrEskQFqQE0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The New Airflow UI Explained\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The New Airflow UI Explained", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GrEskQFqQE0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The New Airflow UI Explained\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/GrEskQFqQE0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GrEskQFqQE0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The New Airflow UI Explained\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17rdim4", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KTeO1M6Gqy9mGonhXKiPhKH_tKf_ccRO2Q1pFomfawA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699538294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/GrEskQFqQE0", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5ZWc_me23kM_ZqLZtmi8kTiq_H8nBFU20I1tUC7C3E0.jpg?auto=webp&amp;s=41b4507922e0bc9df2647ab08e018e87bb227f9f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/5ZWc_me23kM_ZqLZtmi8kTiq_H8nBFU20I1tUC7C3E0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7698a106d41c0bdf89ea10e724eb05d4bc81e12", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/5ZWc_me23kM_ZqLZtmi8kTiq_H8nBFU20I1tUC7C3E0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=484bcf482228184b56fa9ce0bb2e812158d8b99d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/5ZWc_me23kM_ZqLZtmi8kTiq_H8nBFU20I1tUC7C3E0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16a74f1aa183bb552b08f32e7abdf3f16fbfd9a3", "width": 320, "height": 240}], "variants": {}, "id": "EIfHR9hlAjlgYc0zOZS_Arce1LJKXPuzTm9goAOgvuY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rdim4", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rdim4/new_video_get_a_tour_of_the_airflow_ui_and_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/GrEskQFqQE0", "subreddit_subscribers": 138847, "created_utc": 1699538294.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The New Airflow UI Explained", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GrEskQFqQE0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The New Airflow UI Explained\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/GrEskQFqQE0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.bytebase.com/changelog/bytebase-2-11-0/](https://www.bytebase.com/changelog/bytebase-2-11-0/)", "author_fullname": "t2_gxesw7ji", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 Bytebase v2.11.0 released, Database DevOps &amp; CI/CD tool for engineering teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17r940u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699521421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.bytebase.com/changelog/bytebase-2-11-0/\"&gt;https://www.bytebase.com/changelog/bytebase-2-11-0/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?auto=webp&amp;s=eb9a42bd7e724a7cc9a2301edc45a1ffc597c11e", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=259265976367f960075c1ef7a1ddb325c6cab91a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c1491e18ecc361f17fa1be446ce3cabb361ee90", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=efcb16c7e087ddec4c8a285422ec70a5902ca2c8", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c1f35599af5117fa5707a4d1e7d2d00a68962f9b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b55c0014804f2566862680e922755dc351df6e1f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/AimTpHI3pKdJoFKgVYrsW9rdUejWgX6Nx0M-Gnw2kaI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f4d0e90f361a733026eff3ce45acbbc05bd3629e", "width": 1080, "height": 607}], "variants": {}, "id": "eGOueLLJuJfvC627ibHwZI1Mu0ZrpesGLJ6o3MhCNMo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17r940u", "is_robot_indexable": true, "report_reasons": null, "author": "Adela_freedom", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r940u/bytebase_v2110_released_database_devops_cicd_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17r940u/bytebase_v2110_released_database_devops_cicd_tool/", "subreddit_subscribers": 138847, "created_utc": 1699521421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m out in the market post layoff, and have interviews with Snowflake and Databricks for SE/SA roles. I was wondering if anyone here had made the transition and how y\u2019all like it (or dont)", "author_fullname": "t2_fv8iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Shift from DE to sales engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17r5m4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699506391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m out in the market post layoff, and have interviews with Snowflake and Databricks for SE/SA roles. I was wondering if anyone here had made the transition and how y\u2019all like it (or dont)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17r5m4d", "is_robot_indexable": true, "report_reasons": null, "author": "Sp00ky_6", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17r5m4d/career_shift_from_de_to_sales_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17r5m4d/career_shift_from_de_to_sales_engineer/", "subreddit_subscribers": 138847, "created_utc": 1699506391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am new to Airflow and I have a question. We have an existing DAG(a&gt;b&gt;c&gt;d&gt;e&gt;f) consisting of Glue jobs(the Glue jobs have date as their input), that processes data for a given date and writes it to an S3 bucket with the partition dataset\\_date=$date. The team has asked me to create a backfill DAG that is different from the original DAG in two ways:\n\n1. The task sequence will be different:Original DAG: a&gt;b&gt;c&gt;d&gt;e&gt;fBackfill DAG: a&gt;b&gt;c&gt;d\n2. The backfill DAG will have two date parameters, start\\_dateand end\\_date, instead of one. The DAG needs to run individually for all dates in the specified range.\n\nHere are my specific questions:\n\n1. Is there a better way to create the backfill DAG than copying and pasting the code from the original DAG and removing the last two steps?\n2. How do I add the start\\_dateand end\\_dateparameters to the backfill DAG and make it run individually for all dates in the specified range?\n\nThanks in advance for your help!", "author_fullname": "t2_43bvcl6s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Airflow: How to create a backfill DAG with a different task sequence and start/end date parameters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ro2oo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1699566939.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699566691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am new to Airflow and I have a question. We have an existing DAG(a&amp;gt;b&amp;gt;c&amp;gt;d&amp;gt;e&amp;gt;f) consisting of Glue jobs(the Glue jobs have date as their input), that processes data for a given date and writes it to an S3 bucket with the partition dataset_date=$date. The team has asked me to create a backfill DAG that is different from the original DAG in two ways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The task sequence will be different:Original DAG: a&amp;gt;b&amp;gt;c&amp;gt;d&amp;gt;e&amp;gt;fBackfill DAG: a&amp;gt;b&amp;gt;c&amp;gt;d&lt;/li&gt;\n&lt;li&gt;The backfill DAG will have two date parameters, start_dateand end_date, instead of one. The DAG needs to run individually for all dates in the specified range.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here are my specific questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is there a better way to create the backfill DAG than copying and pasting the code from the original DAG and removing the last two steps?&lt;/li&gt;\n&lt;li&gt;How do I add the start_dateand end_dateparameters to the backfill DAG and make it run individually for all dates in the specified range?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ro2oo", "is_robot_indexable": true, "report_reasons": null, "author": "therobot20", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ro2oo/new_to_airflow_how_to_create_a_backfill_dag_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ro2oo/new_to_airflow_how_to_create_a_backfill_dag_with/", "subreddit_subscribers": 138847, "created_utc": 1699566691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI\u2019ve been thinking a lot lately with different data warehousing projects I\u2019ve worked on, and have frequently come back to the idea that it feels like the current warehousing approach of syncing a source database, applying business logic to source data, then loading it to dimension and fact tables feels\u2026 wrong. As software engineers, what we are inherently doing is creating strong coupling between the data source and our system\u2019s representation of data, THEN also duplicating every single piece of relevant business logic the source application defines.\n\nI\u2019d love to have a discussion on the thought of having source applications publish domain events specifically for data warehouse consumption (they\u2019re a monolithic architecture). The problems that I see with this approach aren\u2019t particularly around an internal application / data source, but the 3rd party source that allows database access to a read replica but won\u2019t change their application logic for us. Can anyone think of any other organizational or architectural reasons why you wouldn\u2019t want to move to this approach?\n\nThe reason this has been top of mind has been that a mobile client was the primary data source for a previous warehousing project, where every notable action / user journey was captured as an event and series of events. That was, by far, the most successful data project I\u2019ve been a part of, and I\u2019ve been trying to deconstruct the reasons why it was so successful. I primarily see it as a result of a strong separation of concerns across systems and the developers of the data source being forced to think about how they represent data during the development cycle, but would love to get others thoughts.", "author_fullname": "t2_9zvt3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event Based Data Warehousing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17rmv0b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699563510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been thinking a lot lately with different data warehousing projects I\u2019ve worked on, and have frequently come back to the idea that it feels like the current warehousing approach of syncing a source database, applying business logic to source data, then loading it to dimension and fact tables feels\u2026 wrong. As software engineers, what we are inherently doing is creating strong coupling between the data source and our system\u2019s representation of data, THEN also duplicating every single piece of relevant business logic the source application defines.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to have a discussion on the thought of having source applications publish domain events specifically for data warehouse consumption (they\u2019re a monolithic architecture). The problems that I see with this approach aren\u2019t particularly around an internal application / data source, but the 3rd party source that allows database access to a read replica but won\u2019t change their application logic for us. Can anyone think of any other organizational or architectural reasons why you wouldn\u2019t want to move to this approach?&lt;/p&gt;\n\n&lt;p&gt;The reason this has been top of mind has been that a mobile client was the primary data source for a previous warehousing project, where every notable action / user journey was captured as an event and series of events. That was, by far, the most successful data project I\u2019ve been a part of, and I\u2019ve been trying to deconstruct the reasons why it was so successful. I primarily see it as a result of a strong separation of concerns across systems and the developers of the data source being forced to think about how they represent data during the development cycle, but would love to get others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rmv0b", "is_robot_indexable": true, "report_reasons": null, "author": "alexisprince", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rmv0b/event_based_data_warehousing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rmv0b/event_based_data_warehousing/", "subreddit_subscribers": 138847, "created_utc": 1699563510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Powering the Shift Left movement: Git-based systems as a catalyst for democratized data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17rlhuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ztA62vk0iHwC9KGEWZLzl1zuALJkN2-2Kb-Zfeb4KpY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699559722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/analytics-engineering-data-democratization/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?auto=webp&amp;s=cc4a14c9b4751d940ec160c32779c4715cc5a2f7", "width": 1456, "height": 816}, "resolutions": [{"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69b7c4d5855b32c128d0e635059a053dc2080357", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c2f5b7f0c69655c49e2e0bc6cd4935abb87f102", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2f157423200a9ff8391c14e523df87facb03b3f", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=70ed293048deaa7535ae966a39b9d73a6eadf65e", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=74658f8119d8671c9e1fe1074804af1e7908e1f3", "width": 960, "height": 538}, {"url": "https://external-preview.redd.it/11sR-vViq5P_kR3wTDTlGSRA3q7gb_C8qPLiu518t0Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c71f4efed5e3e4c44de939a814805471730ab362", "width": 1080, "height": 605}], "variants": {}, "id": "JGSou7MMFeVJk4xEFHlT_ziXQH7NzKiDwRJsFZMgJgI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rlhuz", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rlhuz/powering_the_shift_left_movement_gitbased_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/analytics-engineering-data-democratization/", "subreddit_subscribers": 138847, "created_utc": 1699559722.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_32t9jtw4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "new dbt adapter: dbt-timescaledb by github.com/sdebruyn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17rf1w9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/EhK8McDK7LnjeKXr_urQIcO3bnNrHiJo5FanWEHIq90.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1699542596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/sdebruyn/dbt-timescaledb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?auto=webp&amp;s=ca6e0eb6c1236f750a1cc38b3377e17214008b2d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd283e32efec2b4e31968d7798e363f10514eab3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3cc20e2bdc28d5098bbc784370918fbcdc39612d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1776b50e5f6afa10b7d1ff368032264b24b16c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=422d0b4fd43e1532aa4b9c3a76bfc6b595a3fb09", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d4ead3bb9863f0bee9efd02f7187b1015ac1a8cb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/W1lj0hXYiEJf4QmkXnYnUf0NoSujmIvpMsqXElvj7XI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da66c47430887a5d6e502af41028fec4a6f89882", "width": 1080, "height": 540}], "variants": {}, "id": "ra5jVSyGRIga_OoUmuMjY64ben2O6objfprMsBk8Xjo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17rf1w9", "is_robot_indexable": true, "report_reasons": null, "author": "bart-dataroots", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rf1w9/new_dbt_adapter_dbttimescaledb_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/sdebruyn/dbt-timescaledb", "subreddit_subscribers": 138847, "created_utc": 1699542596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I'm in the DE since 5 year and I've been working always within the python stack (spark, pandas, polars, duckDB etc.), and i never ever worked/written with tests or unit tests in data engineering field (Data quality, integrity, testing pipelines etc..).\n\nWhat are your thoughts about this? Did you ever developed or used these kind of tests?", "author_fullname": "t2_jpa33w9qj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts about Tests in Data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rd3su", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699537049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m in the DE since 5 year and I&amp;#39;ve been working always within the python stack (spark, pandas, polars, duckDB etc.), and i never ever worked/written with tests or unit tests in data engineering field (Data quality, integrity, testing pipelines etc..).&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts about this? Did you ever developed or used these kind of tests?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17rd3su", "is_robot_indexable": true, "report_reasons": null, "author": "mk8862", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rd3su/what_are_your_thoughts_about_tests_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rd3su/what_are_your_thoughts_about_tests_in_data/", "subreddit_subscribers": 138847, "created_utc": 1699537049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am looking for some advice on whether I am missing something simple. I want to add a dataframe as a new table into a database (say IBM or SQL Server) using Python. Do I need to create a blank table and define all the fields first or is there a way I can transfer the schema of my dataframe directly to a table?\n\nThank you in advance!", "author_fullname": "t2_lr9zwi4b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ro6jg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699566975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am looking for some advice on whether I am missing something simple. I want to add a dataframe as a new table into a database (say IBM or SQL Server) using Python. Do I need to create a blank table and define all the fields first or is there a way I can transfer the schema of my dataframe directly to a table?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ro6jg", "is_robot_indexable": true, "report_reasons": null, "author": "dphigravity", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ro6jg/newbie_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ro6jg/newbie_help/", "subreddit_subscribers": 138847, "created_utc": 1699566975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://blog.peerdb.io/native-replication-of-postgres-geospatial-data](https://blog.peerdb.io/native-replication-of-postgres-geospatial-data)", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Native Replication of Postgres Geospatial Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17rn87p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1699564484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.peerdb.io/native-replication-of-postgres-geospatial-data\"&gt;https://blog.peerdb.io/native-replication-of-postgres-geospatial-data&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?auto=webp&amp;s=d23929f247c5e1fb35a1485798727e3d3d519735", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=26736fc815b2580130bbb3b6e0f8a20c26620424", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69194c904331a10056c89afb2147bd1b63dd7c49", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea52d3902b83579efec42f52897796c124ddeafc", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=368a077b95047f943357a5fd215fd1d1c134b53a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26b2ca1d290eb837830e7b0b99d32d349e89924c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/lc8i3ckszhTjZOzFeusyflGgBTKcg-jAxouQx8U2pMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f69ee53ca0887e26983eb0ef6d1511c51d52e6de", "width": 1080, "height": 567}], "variants": {}, "id": "ZerwyrF0ybcXZabX2KGbXaTHPCdY_5eeTVJrk5XgY5U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17rn87p", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rn87p/native_replication_of_postgres_geospatial_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rn87p/native_replication_of_postgres_geospatial_data/", "subreddit_subscribers": 138847, "created_utc": 1699564484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Three years ago - I made a benchmark of the data catalog landscape. The market has evolved so much that I decided to update it. \n\nDo you feel like any feature/tool is missing? I'm trying to make this resource as accurate as possible so if you have suggestions - don't hesitate to shoot them my way. \n\nFull benchmark here: [https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0](https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0)\n\n&amp;#x200B;\n\n[Full benchmark](https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;format=png&amp;auto=webp&amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4)", "author_fullname": "t2_9blh4yzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data Catalog tools benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": true, "media_metadata": {"fkk9xfs30ezb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac41babea0a10264514231f929a806294477aff"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=914212ea847e3de776133ab1ff84ab447e14581f"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f223c3c14eda9e720c886392a10086901ce15112"}, {"y": 356, "x": 640, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9b480c52a69c49b1fbc03dde4bb1cec8de184f2"}, {"y": 535, "x": 960, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d7aa2ded635f5af05fc433a3723af77300f9acbf"}, {"y": 601, "x": 1080, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eeeb142f21772b252f69fc0b33bac122436bad36"}], "s": {"y": 1342, "x": 2408, "u": "https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;format=png&amp;auto=webp&amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4"}, "id": "fkk9xfs30ezb1"}}, "name": "t3_17rn2mn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aVVB55qsUCH-TIHHq_7dO0tJhNbhz7MAc159Ecii_dA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1699564076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Three years ago - I made a benchmark of the data catalog landscape. The market has evolved so much that I decided to update it. &lt;/p&gt;\n\n&lt;p&gt;Do you feel like any feature/tool is missing? I&amp;#39;m trying to make this resource as accurate as possible so if you have suggestions - don&amp;#39;t hesitate to shoot them my way. &lt;/p&gt;\n\n&lt;p&gt;Full benchmark here: &lt;a href=\"https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0\"&gt;https://www.notion.so/Data-Catalog-Tools-Benchmark-4bcbee621de243b6a34deaebd28180d0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fkk9xfs30ezb1.png?width=2408&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e9ecdb6c7041bdbd006ced49a28062c4a82cacd4\"&gt;Full benchmark&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?auto=webp&amp;s=874e1ed6dc2a7b4597c3433ddc627667e3c784a4", "width": 2000, "height": 533}, "resolutions": [{"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8739deea072d2eeef24f483c36e0daf1f28a5fec", "width": 108, "height": 28}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cde91b7f4bc2affd28d0df5216cf38dc2d196e2", "width": 216, "height": 57}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0bc14863c466929cb3844107eb321aab8829fc3", "width": 320, "height": 85}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a11bee81df46bf65d6b402c7c55cfcb4887ce1e", "width": 640, "height": 170}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87dc926d373fb50e35ecf0d303ffdb10b44b8db2", "width": 960, "height": 255}, {"url": "https://external-preview.redd.it/bKepw5FksUqvFtunkXvWYJj7aa1hSDlgCRRdAktkqEs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=25101900e35ac2d38d0d1340f33a8255881ad6da", "width": 1080, "height": 287}], "variants": {}, "id": "coOYg5Xd4CLO-xHaYB_9pwauwVHF8Mte1l6ZoFyD3eA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17rn2mn", "is_robot_indexable": true, "report_reasons": null, "author": "Strict_Algae3766", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rn2mn/data_catalog_tools_benchmark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rn2mn/data_catalog_tools_benchmark/", "subreddit_subscribers": 138847, "created_utc": 1699564076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a final round interview with the hiring manager for a data engineer intern position. I\u2019m not sure what kind of question I should have prepared to ask them during the interview. Does anyone have any suggestions or advice about what to ask.", "author_fullname": "t2_3xmv0yu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions to ask hiring manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rky00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699558262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a final round interview with the hiring manager for a data engineer intern position. I\u2019m not sure what kind of question I should have prepared to ask them during the interview. Does anyone have any suggestions or advice about what to ask.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17rky00", "is_robot_indexable": true, "report_reasons": null, "author": "ChubbyFruit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rky00/questions_to_ask_hiring_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rky00/questions_to_ask_hiring_manager/", "subreddit_subscribers": 138847, "created_utc": 1699558262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone answer this for me in lamence terms:\n\nLarge large large volume of data is stored in HDFS. I believe they\u2019re parquet, but there are discussions about creating Iceberg tables at some point.  Compute is Spark. I need to read in the data, create some very complex derived datasets with business logic, then write those datasets back to HDFS.\n\nGiven the complexity of the logic I need to apply, do I just use Spark SQL? I come from a heavy SQL background, so that is what I immediately gravitate towards. But I also know very little about DE and Spark (newbie coming from BI), so I\u2019m probably missing something obvious here.", "author_fullname": "t2_dqgz8w63", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic question: Applying complex business logic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17rfmvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699544189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone answer this for me in lamence terms:&lt;/p&gt;\n\n&lt;p&gt;Large large large volume of data is stored in HDFS. I believe they\u2019re parquet, but there are discussions about creating Iceberg tables at some point.  Compute is Spark. I need to read in the data, create some very complex derived datasets with business logic, then write those datasets back to HDFS.&lt;/p&gt;\n\n&lt;p&gt;Given the complexity of the logic I need to apply, do I just use Spark SQL? I come from a heavy SQL background, so that is what I immediately gravitate towards. But I also know very little about DE and Spark (newbie coming from BI), so I\u2019m probably missing something obvious here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17rfmvz", "is_robot_indexable": true, "report_reasons": null, "author": "sponkoney", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17rfmvz/basic_question_applying_complex_business_logic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17rfmvz/basic_question_applying_complex_business_logic/", "subreddit_subscribers": 138847, "created_utc": 1699544189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering what the community's opinion on estuary is? Are they a competitor to databricks and synapse analytics? Has anybody used them with Azure before? I reached out to the company like a month ago but I never heard anything back, normally I'd move on but I figured I'd ask the rest of the community what their experience is with it. Thanks.", "author_fullname": "t2_4d7ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used estuary before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17reaxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699540536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering what the community&amp;#39;s opinion on estuary is? Are they a competitor to databricks and synapse analytics? Has anybody used them with Azure before? I reached out to the company like a month ago but I never heard anything back, normally I&amp;#39;d move on but I figured I&amp;#39;d ask the rest of the community what their experience is with it. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17reaxr", "is_robot_indexable": true, "report_reasons": null, "author": "jorel43", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17reaxr/has_anyone_used_estuary_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17reaxr/has_anyone_used_estuary_before/", "subreddit_subscribers": 138847, "created_utc": 1699540536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello!\n\nI'm actually building a project that will use data form different sources at different frenquencies.\n\nDimension tables : load every 4 hours\n\nFact table : load every 30 minutes\n\nFact tables can reference dimension data that haven't been pushed to our silver/gold delta tables\n\nIn the exposition layer (powerbi) we will build a star schema that will link the fact and dimension tables\n\nHow do we deal with foreign keys in the fact tables ?\n\nis it a good pratise to build them when loading data in the gold layer ?\n\nhow to deal with fact tables that have data not referenced in the dimension yet ?\n\ntables are built in delta lake using azure databricks \n\nthanks !", "author_fullname": "t2_gprs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a good pracise to build foreign key reference in delta lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17raw1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1699529280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m actually building a project that will use data form different sources at different frenquencies.&lt;/p&gt;\n\n&lt;p&gt;Dimension tables : load every 4 hours&lt;/p&gt;\n\n&lt;p&gt;Fact table : load every 30 minutes&lt;/p&gt;\n\n&lt;p&gt;Fact tables can reference dimension data that haven&amp;#39;t been pushed to our silver/gold delta tables&lt;/p&gt;\n\n&lt;p&gt;In the exposition layer (powerbi) we will build a star schema that will link the fact and dimension tables&lt;/p&gt;\n\n&lt;p&gt;How do we deal with foreign keys in the fact tables ?&lt;/p&gt;\n\n&lt;p&gt;is it a good pratise to build them when loading data in the gold layer ?&lt;/p&gt;\n\n&lt;p&gt;how to deal with fact tables that have data not referenced in the dimension yet ?&lt;/p&gt;\n\n&lt;p&gt;tables are built in delta lake using azure databricks &lt;/p&gt;\n\n&lt;p&gt;thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17raw1l", "is_robot_indexable": true, "report_reasons": null, "author": "qintarra", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17raw1l/is_it_a_good_pracise_to_build_foreign_key/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17raw1l/is_it_a_good_pracise_to_build_foreign_key/", "subreddit_subscribers": 138847, "created_utc": 1699529280.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}