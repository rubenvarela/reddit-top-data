{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_u94ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Every AI startup right now", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1857f7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 334, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Monday Meme", "can_mod_post": false, "score": 334, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jR-EDiHkKELCP0nYqnG1OxwijWes_O6qFvJM2cgW9zc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701103781.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/t08yextu6x2c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/t08yextu6x2c1.png?auto=webp&amp;s=03f8b9dd3efb868d04165657e362aff6069508ad", "width": 1035, "height": 1227}, "resolutions": [{"url": "https://preview.redd.it/t08yextu6x2c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5424cf838ef0bc88ffb5539dc4eb47a85ce5323", "width": 108, "height": 128}, {"url": "https://preview.redd.it/t08yextu6x2c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1953e0521bfc7e7c23d493be738d704d7011ca74", "width": 216, "height": 256}, {"url": "https://preview.redd.it/t08yextu6x2c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=48abf8234c3bca51d1638c6c513db0b4b4f1aa10", "width": 320, "height": 379}, {"url": "https://preview.redd.it/t08yextu6x2c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=85d7767852a7f89193825437f3c10ac3e40f7e8d", "width": 640, "height": 758}, {"url": "https://preview.redd.it/t08yextu6x2c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=caa63341dbd69bf154edb32519dc2d6c8dae561c", "width": 960, "height": 1138}], "variants": {}, "id": "ivSfmSdVjZINJutQXfRNM90djvQaj2fqoD97dhxZpdo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "6e90f572-70ec-11ee-9bd6-2692ba006635", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff8717", "id": "1857f7t", "is_robot_indexable": true, "report_reasons": null, "author": "brendanmartin", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1857f7t/every_ai_startup_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/t08yextu6x2c1.png", "subreddit_subscribers": 1152882, "created_utc": 1701103781.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My train recall and precision are 0.68 each but my test recall is 0.24 and test precision is 0.75. What am I doing wrong and what can I do to fix this?", "author_fullname": "t2_jrhff4f29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does my PR curve look like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 111, "top_awarded_type": null, "hide_score": false, "name": "t3_1857bao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i6BczB22NKygC_FpE_4KkHRNjSlKYUfSPZTDE7m_D8o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701103515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My train recall and precision are 0.68 each but my test recall is 0.24 and test precision is 0.75. What am I doing wrong and what can I do to fix this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ky50y4l46x2c1.jpeg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ky50y4l46x2c1.jpeg?auto=webp&amp;s=249e4b66ca08fc566d1139931b77a6c8f0584c3c", "width": 710, "height": 565}, "resolutions": [{"url": "https://preview.redd.it/ky50y4l46x2c1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=92b0047f6ef7b01b4d1ced32a83df402f2d8b773", "width": 108, "height": 85}, {"url": "https://preview.redd.it/ky50y4l46x2c1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3de804fb754e3d56eaa27f34e52e9f1c183c4b2f", "width": 216, "height": 171}, {"url": "https://preview.redd.it/ky50y4l46x2c1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9ebf5ca2e2a34b414af7645c0993c69c6be20fa9", "width": 320, "height": 254}, {"url": "https://preview.redd.it/ky50y4l46x2c1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3437a50d228cef3a7dc4a089667c19cc5d33909c", "width": 640, "height": 509}], "variants": {}, "id": "O7tlZEB8KWK94hktT3GtUcL2X1bT6zxRWAzrngAylgI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "1857bao", "is_robot_indexable": true, "report_reasons": null, "author": "Terrible-Hamster-342", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1857bao/why_does_my_pr_curve_look_like_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ky50y4l46x2c1.jpeg", "subreddit_subscribers": 1152882, "created_utc": 1701103515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "At some point, certainly by the time you approach the big four-oh, you will come to a fork in your career path. Which branch will you/ did you choose, and why? Stay technical, even though your job opportunities and earnings growth could flatline as you pass the big five- oh.  Transition to a management role. That would be more lucrative and impactful, if you can master the bureaucratic BS and knife in the back politics. Or would you rather leave corporate life behind and become an independent consultant.", "author_fullname": "t2_lkjsx0aw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stay technical, go management, or consult?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185fya9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701124514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At some point, certainly by the time you approach the big four-oh, you will come to a fork in your career path. Which branch will you/ did you choose, and why? Stay technical, even though your job opportunities and earnings growth could flatline as you pass the big five- oh.  Transition to a management role. That would be more lucrative and impactful, if you can master the bureaucratic BS and knife in the back politics. Or would you rather leave corporate life behind and become an independent consultant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "185fya9", "is_robot_indexable": true, "report_reasons": null, "author": "AdParticular6193", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185fya9/stay_technical_go_management_or_consult/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185fya9/stay_technical_go_management_or_consult/", "subreddit_subscribers": 1152882, "created_utc": 1701124514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In a DA role and my boss told me I should setup a monthly meeting in an \u201coffice hours\u201d format where people can chat and ask questions about the work I do and what kind of information I can provide. \n\nI\u2019m baffled on what this looks like - do I just sit in a room for an hour or so while people come and go? It seems like such a waste of time.", "author_fullname": "t2_nya9l4wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you do an \u201coffice hours\u201d style meeting/presentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18582lr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701105401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In a DA role and my boss told me I should setup a monthly meeting in an \u201coffice hours\u201d format where people can chat and ask questions about the work I do and what kind of information I can provide. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m baffled on what this looks like - do I just sit in a room for an hour or so while people come and go? It seems like such a waste of time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "18582lr", "is_robot_indexable": true, "report_reasons": null, "author": "TheUserAboveFarted", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/18582lr/how_do_you_do_an_office_hours_style/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/18582lr/how_do_you_do_an_office_hours_style/", "subreddit_subscribers": 1152882, "created_utc": 1701105401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone else feel like their management blocks them from actually implementing \"data science\"? Whether for lack of understanding or fear of trying something that may not work?\n\nLet me elaborate. I have worked as a DS at several companies small companies. What I have found in my experience is that there is always a hurdle to actually implementing data science by building models, testing hypothesis, etc. Sometimes it's data, sometimes badly defined business processes, but the most frustrating for me is when I get the feeling that my manager just isn't creative enough to see how DS could be used to solve the problem. Instead, handwaving and feeding you blanket statements like \"that's too hard\" or \"too complex\".\n\nIf I were a more motivated employee I would probably build out a POC on my own time to prove my point, but I have a family and better things to do than put in extra effort at work for stuff that will probably sit on a shelf.", "author_fullname": "t2_h09oj56", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Venting about management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185ele0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701121259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone else feel like their management blocks them from actually implementing &amp;quot;data science&amp;quot;? Whether for lack of understanding or fear of trying something that may not work?&lt;/p&gt;\n\n&lt;p&gt;Let me elaborate. I have worked as a DS at several companies small companies. What I have found in my experience is that there is always a hurdle to actually implementing data science by building models, testing hypothesis, etc. Sometimes it&amp;#39;s data, sometimes badly defined business processes, but the most frustrating for me is when I get the feeling that my manager just isn&amp;#39;t creative enough to see how DS could be used to solve the problem. Instead, handwaving and feeding you blanket statements like &amp;quot;that&amp;#39;s too hard&amp;quot; or &amp;quot;too complex&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;If I were a more motivated employee I would probably build out a POC on my own time to prove my point, but I have a family and better things to do than put in extra effort at work for stuff that will probably sit on a shelf.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "185ele0", "is_robot_indexable": true, "report_reasons": null, "author": "clashofphish", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185ele0/venting_about_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185ele0/venting_about_management/", "subreddit_subscribers": 1152882, "created_utc": 1701121259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I ran into an intersting case today, which I would like to discuss. I have changed some details to keep the companies involved anonymous.\n\nThe shopping portal GoGreen\ud83c\udf4f allows customers to view the carbon footprint of each item they shop, enabling them to make informed decisions that could minimize their environmental impact. While shopping, the customer sees a bar chart that shows both the stacked CO2 emisions from all the items they have selected so far, and a second bar that that shows the stacked CO2 emisions for alternative items with a smaller footprint.\n\n[An illustration of the described bar chart](https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;format=png&amp;auto=webp&amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9)\n\nUnfortunatelt, not all sub-vendors are able to provide an CO2 estimate for all their items. When this happens, GoGreen\ud83c\udf4f instead relys on an official rapport that have calculated the average carbon footprint for a huge amount of items. This will be an average value based on similar products.\n\nThe problem is this: Vendors who are spending their ressources on providing good CO2 estiamates naturally wants to be rewarded for this effort. However, it is not clear how this should be done in a fair way. I see several solutions, but neither are good:\n\n1. If we fill the nan-values based on the averages from the rapport, the averages will sometimes comes out better. This would create an incentive to not rapport the carbon footprint if the vendors suspects they will come out worse than the average\n2. If we exclude the nan-values, this will essentailly be the same as saying the footprint is zero, which would insentivice the previous behaviour even more\n3. If we penalise the vendors who don't report a CO2 estimate with a \"bad data quality tax\", this will be seen unfair by the user's who don't rapport such estimates (who in many cases have legitimate reasons why they are not able to). And we simply do not have enough data to create a fair penalty.\n\nThis whole thing would not be a problem if all vendors either did or did not offer CO2 estimates. However, it becomes a huge fairness-issue when there is a mix. We want to reward good data quality, but is has to be done fairly. We also need to present this in a way that enables customers to make well-informed decisions.\n\nAnyone with relevant tips or experiences? \ud83e\udd13", "author_fullname": "t2_2boatuxv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to reward good data quality in decision making?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 134, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fzl2lt2ud23c1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 103, "x": 108, "u": "https://preview.redd.it/fzl2lt2ud23c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ddab52c1c22e111c6f08137feaceebc1492301c"}, {"y": 207, "x": 216, "u": "https://preview.redd.it/fzl2lt2ud23c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7512f8d09eb05df991b979e804e8b1cf6a0757c2"}, {"y": 307, "x": 320, "u": "https://preview.redd.it/fzl2lt2ud23c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=977eac0ed475303e85da1cc874f4bda4661bd64a"}], "s": {"y": 384, "x": 400, "u": "https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;format=png&amp;auto=webp&amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9"}, "id": "fzl2lt2ud23c1"}}, "name": "t3_185su4m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Am6pP6EHxv93XV6vCaENJAVGFjzC-xt-8cB2jGJEK-Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701166672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran into an intersting case today, which I would like to discuss. I have changed some details to keep the companies involved anonymous.&lt;/p&gt;\n\n&lt;p&gt;The shopping portal GoGreen\ud83c\udf4f allows customers to view the carbon footprint of each item they shop, enabling them to make informed decisions that could minimize their environmental impact. While shopping, the customer sees a bar chart that shows both the stacked CO2 emisions from all the items they have selected so far, and a second bar that that shows the stacked CO2 emisions for alternative items with a smaller footprint.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fzl2lt2ud23c1.png?width=400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85cae8280eb2fc32cf5c385af3760efd485f02c9\"&gt;An illustration of the described bar chart&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Unfortunatelt, not all sub-vendors are able to provide an CO2 estimate for all their items. When this happens, GoGreen\ud83c\udf4f instead relys on an official rapport that have calculated the average carbon footprint for a huge amount of items. This will be an average value based on similar products.&lt;/p&gt;\n\n&lt;p&gt;The problem is this: Vendors who are spending their ressources on providing good CO2 estiamates naturally wants to be rewarded for this effort. However, it is not clear how this should be done in a fair way. I see several solutions, but neither are good:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If we fill the nan-values based on the averages from the rapport, the averages will sometimes comes out better. This would create an incentive to not rapport the carbon footprint if the vendors suspects they will come out worse than the average&lt;/li&gt;\n&lt;li&gt;If we exclude the nan-values, this will essentailly be the same as saying the footprint is zero, which would insentivice the previous behaviour even more&lt;/li&gt;\n&lt;li&gt;If we penalise the vendors who don&amp;#39;t report a CO2 estimate with a &amp;quot;bad data quality tax&amp;quot;, this will be seen unfair by the user&amp;#39;s who don&amp;#39;t rapport such estimates (who in many cases have legitimate reasons why they are not able to). And we simply do not have enough data to create a fair penalty.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This whole thing would not be a problem if all vendors either did or did not offer CO2 estimates. However, it becomes a huge fairness-issue when there is a mix. We want to reward good data quality, but is has to be done fairly. We also need to present this in a way that enables customers to make well-informed decisions.&lt;/p&gt;\n\n&lt;p&gt;Anyone with relevant tips or experiences? \ud83e\udd13&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "185su4m", "is_robot_indexable": true, "report_reasons": null, "author": "PostponeIdiocracy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185su4m/how_to_reward_good_data_quality_in_decision_making/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185su4m/how_to_reward_good_data_quality_in_decision_making/", "subreddit_subscribers": 1152882, "created_utc": 1701166672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sharing this interesting blogpost: [https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261](https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261)", "author_fullname": "t2_54ka7fmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get started with exploratory data analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185jd31", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701133294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing this interesting blogpost: &lt;a href=\"https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261\"&gt;https://medium.com/@seckindinc/data-profiling-with-python-36497d3a1261&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?auto=webp&amp;s=288a87a604d4eca8bca5a3324528b5725ea683ca", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e18d80e187e0dcc73cace254310d8375afd9ab2", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07cdabf745d28b06d27b2b8149b73e472ab43d4a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5418b1b92157e5374e998e775a136e3da513c399", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db39befb9a66b32968df449bc6681265853aa843", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e62285c4b8e0feff48457c4447597899470c896", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/BJPKGjvSpNyC9qC1SRRngNJUoKVHtS9n0TtS0tQVuIE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02ad4c4d32b126427298206f6ccba48fd45b2ebe", "width": 1080, "height": 720}], "variants": {}, "id": "a1JplVCh5uF_FCo04tibM83p1AmIBdf0mruuMa1R8Ys"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "185jd31", "is_robot_indexable": true, "report_reasons": null, "author": "Dry_Cattle9399", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185jd31/get_started_with_exploratory_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185jd31/get_started_with_exploratory_data_analysis/", "subreddit_subscribers": 1152882, "created_utc": 1701133294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are some useful relationships/graphs you guys use with independent variables and the target variable when doing the initial EDA? Assuming most of your variables are categorical.", "author_fullname": "t2_495cn7pm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EDA With Binary Classification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185sk3d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701165553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some useful relationships/graphs you guys use with independent variables and the target variable when doing the initial EDA? Assuming most of your variables are categorical.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "185sk3d", "is_robot_indexable": true, "report_reasons": null, "author": "Throwawayforgainz99", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185sk3d/eda_with_binary_classification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185sk3d/eda_with_binary_classification/", "subreddit_subscribers": 1152882, "created_utc": 1701165553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you ever embed sanity checks in your reporting?\n\nHow thorough are you, what kind do you use, etc?\n\nDo you make it part of the reporting query, or do you trust a separate query with the task?", "author_fullname": "t2_a1m88yyw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Losing my sanity (checks)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185r2od", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701159215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you ever embed sanity checks in your reporting?&lt;/p&gt;\n\n&lt;p&gt;How thorough are you, what kind do you use, etc?&lt;/p&gt;\n\n&lt;p&gt;Do you make it part of the reporting query, or do you trust a separate query with the task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "185r2od", "is_robot_indexable": true, "report_reasons": null, "author": "Status-Efficiency851", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185r2od/losing_my_sanity_checks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185r2od/losing_my_sanity_checks/", "subreddit_subscribers": 1152882, "created_utc": 1701159215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious if anyone has dared putting a solution that uses an LLM (e.g. ChatGPT) to parse unstructured text into e.g. JSON?\n\nI've only tested this with ChatGPT and it works surprisingly well. But I'm still not convinced I could trust it to go through large scales of text in production.", "author_fullname": "t2_2boatuxv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experiences using ChatGPT to structure unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185sq4v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701166220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious if anyone has dared putting a solution that uses an LLM (e.g. ChatGPT) to parse unstructured text into e.g. JSON?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only tested this with ChatGPT and it works surprisingly well. But I&amp;#39;m still not convinced I could trust it to go through large scales of text in production.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "185sq4v", "is_robot_indexable": true, "report_reasons": null, "author": "PostponeIdiocracy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185sq4v/experiences_using_chatgpt_to_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185sq4v/experiences_using_chatgpt_to_structure/", "subreddit_subscribers": 1152882, "created_utc": 1701166220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello!\n\nAll my data wrangling is currently done. I have 4 (2 in each pair) sets of data each with 500 \"baskets\" of groceries . The data contains all the item descriptions, together with the target variable of interest, the subdepartment the item is in. (think carrots--&gt;produce). Each data pair contains the first bought and then second bought basket in different files. I am trying to predict, given a bought basket of groceries, what is the mostly likely sub department a customer would buy from on their next visit.\n\nI am still just a Computer Science student so I lack the experience here to pick a good predictive model for my situation. I was thinking of doing a Hollistic Linear Regression, or a simple KNN, but I thought about asking here first to see if anyone had any recommendations for me. Unfortunately I cannot use any models that involve hypothesis testing.\n\nI apologize if I missed a rule before posting this. Thanks in advance!", "author_fullname": "t2_1713jl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendations for a Prediction Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185qkmm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701157143.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;All my data wrangling is currently done. I have 4 (2 in each pair) sets of data each with 500 &amp;quot;baskets&amp;quot; of groceries . The data contains all the item descriptions, together with the target variable of interest, the subdepartment the item is in. (think carrots--&amp;gt;produce). Each data pair contains the first bought and then second bought basket in different files. I am trying to predict, given a bought basket of groceries, what is the mostly likely sub department a customer would buy from on their next visit.&lt;/p&gt;\n\n&lt;p&gt;I am still just a Computer Science student so I lack the experience here to pick a good predictive model for my situation. I was thinking of doing a Hollistic Linear Regression, or a simple KNN, but I thought about asking here first to see if anyone had any recommendations for me. Unfortunately I cannot use any models that involve hypothesis testing.&lt;/p&gt;\n\n&lt;p&gt;I apologize if I missed a rule before posting this. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "185qkmm", "is_robot_indexable": true, "report_reasons": null, "author": "Akavire", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185qkmm/recommendations_for_a_prediction_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185qkmm/recommendations_for_a_prediction_model/", "subreddit_subscribers": 1152882, "created_utc": 1701157143.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How would you identify them? How do you think they get in? \n\nDo you think they enjoy an unfair advantage of calling the shots, higher salary, etc. in your org?\n\nEDIT: [Same question. Different Sub. Interesting responses. Does region influence how data science is perceived as a profession?\n](https://www.reddit.com/r/developersIndia/s/xfCukCZg0O)", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think there are too many frauds masquerading as data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185kril", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.35, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701152428.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701137268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How would you identify them? How do you think they get in? &lt;/p&gt;\n\n&lt;p&gt;Do you think they enjoy an unfair advantage of calling the shots, higher salary, etc. in your org?&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;a href=\"https://www.reddit.com/r/developersIndia/s/xfCukCZg0O\"&gt;Same question. Different Sub. Interesting responses. Does region influence how data science is perceived as a profession?\n&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "185kril", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/185kril/do_you_think_there_are_too_many_frauds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/185kril/do_you_think_there_are_too_many_frauds/", "subreddit_subscribers": 1152882, "created_utc": 1701137268.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}