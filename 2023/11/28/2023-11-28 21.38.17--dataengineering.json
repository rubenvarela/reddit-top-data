{"kind": "Listing", "data": {"after": "t3_185z98k", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do data engineers want for christmas? ", "author_fullname": "t2_i9gj7554a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do data engineers want for christmas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1860n25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701190337.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do data engineers want for christmas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1860n25", "is_robot_indexable": true, "report_reasons": null, "author": "RadioDramatic3040", "discussion_type": null, "num_comments": 68, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1860n25/what_do_data_engineers_want_for_christmas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1860n25/what_do_data_engineers_want_for_christmas/", "subreddit_subscribers": 142372, "created_utc": 1701190337.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After some holiday reporting, I noticed my reports were off. This is basically worst fear of mine and I sent the report to leadership! The root cause was ultimately a dataset issue, don't want to get into the complexity but some customers trade with each other and this was causing some duplicates when suming values. \n\nNoone has said anything but I feel like a big dumb dumb. I want to avoid this in the future... How are you all validating your datasets? The reporting team is just yours truly so I open to any ideas I can implement in an automated fashion. If it matters I do most of my reports in SQL views then bring them into powerbi and add the relationships. The view is what was wrong.", "author_fullname": "t2_jrmn04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you test your data and reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185gxaj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701126900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After some holiday reporting, I noticed my reports were off. This is basically worst fear of mine and I sent the report to leadership! The root cause was ultimately a dataset issue, don&amp;#39;t want to get into the complexity but some customers trade with each other and this was causing some duplicates when suming values. &lt;/p&gt;\n\n&lt;p&gt;Noone has said anything but I feel like a big dumb dumb. I want to avoid this in the future... How are you all validating your datasets? The reporting team is just yours truly so I open to any ideas I can implement in an automated fashion. If it matters I do most of my reports in SQL views then bring them into powerbi and add the relationships. The view is what was wrong.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185gxaj", "is_robot_indexable": true, "report_reasons": null, "author": "soricellia", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185gxaj/how_do_you_test_your_data_and_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185gxaj/how_do_you_test_your_data_and_reports/", "subreddit_subscribers": 142372, "created_utc": 1701126900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are data warehouses a bad choice for data apps because they lack freshness, latency, and query concurrency needs?  \n\nOr if we're able to improve ingestion latency, query response time, and concurrency/scaleability, maybe it can be a good choice?  ", "author_fullname": "t2_jg3w8gbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data warehouses serve as application backends?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185uz7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701174754.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are data warehouses a bad choice for data apps because they lack freshness, latency, and query concurrency needs?  &lt;/p&gt;\n\n&lt;p&gt;Or if we&amp;#39;re able to improve ingestion latency, query response time, and concurrency/scaleability, maybe it can be a good choice?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185uz7j", "is_robot_indexable": true, "report_reasons": null, "author": "tamargal91", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185uz7j/should_data_warehouses_serve_as_application/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185uz7j/should_data_warehouses_serve_as_application/", "subreddit_subscribers": 142372, "created_utc": 1701174754.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As in title, I am wondering what people are seeing/charging for contracting rates as Senior Data Engineers in the UK currently. From the looks of things I am seeing rates advertised between \u00a3500 - \u00a3600, but I am wondering if this is the normal going rate or if people are charging more.\n\n&amp;#x200B;\n\nContext I currently work for Amazon as a Senior DE earning 130k total comp but want to move into contracting to maximise my income however I want to ensure that I am not leaving money on the table so to speak in any rate negotiations.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_75if3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UK Senior Data Engineer Contracting Rates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185pyzm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701154678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in title, I am wondering what people are seeing/charging for contracting rates as Senior Data Engineers in the UK currently. From the looks of things I am seeing rates advertised between \u00a3500 - \u00a3600, but I am wondering if this is the normal going rate or if people are charging more.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Context I currently work for Amazon as a Senior DE earning 130k total comp but want to move into contracting to maximise my income however I want to ensure that I am not leaving money on the table so to speak in any rate negotiations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "185pyzm", "is_robot_indexable": true, "report_reasons": null, "author": "Wtf_Pinkelephants", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185pyzm/uk_senior_data_engineer_contracting_rates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185pyzm/uk_senior_data_engineer_contracting_rates/", "subreddit_subscribers": 142372, "created_utc": 1701154678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! Don't know if this is the best sub to ask but here we go.  \n\n\nI work at a medium sized company (200 office employees, 750 on site) as a Business Analyst, I have around 5/6 years experience as a Data Analyst but well the transition is a long story for another day.  \n\n\nCurrently I'm alone here basically with my boss, and we want to deploy a Datawarehouse, I've worked with those before many times, but never implemented one. We will probably go with Azure since the company is very Microsoft-y and such.   \n\n\nThe thing is that my boss recommended me to learn to do this stuff by myself, instead of hiring a consultor to do it for is. It's not that the company doesn't want to pay, they are very keen, but my boss is a great dude and he had the idea that it would be an awesome learning experience if we try to do it ourselves and, before investing too much time or going to production, only then hire a consultor to basically make sure we did everything fine.  \n\n\nOur data comes from different (but not too many) sources: an HSE system with which we connect through an API, an operational (we use it to schedule shifts and all that, basically our main) system with which we connect directly to their data blob, a finance system (Pronto XI) and then some other random stuff.  \n\n\nCan you guys recommend any learning path that may help me with this? I'm very excited to do this and want to get it right, we have access to LinkedIn learn so I thought about starting a Data Engineering course or something like that...  \n\n\nThanks a lot!!", "author_fullname": "t2_66n34smm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help a dude install a DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185jbtq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701133209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! Don&amp;#39;t know if this is the best sub to ask but here we go.  &lt;/p&gt;\n\n&lt;p&gt;I work at a medium sized company (200 office employees, 750 on site) as a Business Analyst, I have around 5/6 years experience as a Data Analyst but well the transition is a long story for another day.  &lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m alone here basically with my boss, and we want to deploy a Datawarehouse, I&amp;#39;ve worked with those before many times, but never implemented one. We will probably go with Azure since the company is very Microsoft-y and such.   &lt;/p&gt;\n\n&lt;p&gt;The thing is that my boss recommended me to learn to do this stuff by myself, instead of hiring a consultor to do it for is. It&amp;#39;s not that the company doesn&amp;#39;t want to pay, they are very keen, but my boss is a great dude and he had the idea that it would be an awesome learning experience if we try to do it ourselves and, before investing too much time or going to production, only then hire a consultor to basically make sure we did everything fine.  &lt;/p&gt;\n\n&lt;p&gt;Our data comes from different (but not too many) sources: an HSE system with which we connect through an API, an operational (we use it to schedule shifts and all that, basically our main) system with which we connect directly to their data blob, a finance system (Pronto XI) and then some other random stuff.  &lt;/p&gt;\n\n&lt;p&gt;Can you guys recommend any learning path that may help me with this? I&amp;#39;m very excited to do this and want to get it right, we have access to LinkedIn learn so I thought about starting a Data Engineering course or something like that...  &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185jbtq", "is_robot_indexable": true, "report_reasons": null, "author": "Palpitation-Itchy", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185jbtq/help_a_dude_install_a_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185jbtq/help_a_dude_install_a_dwh/", "subreddit_subscribers": 142372, "created_utc": 1701133209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How does one,  effectively clean dates and timestamps of different format to one format?? There are so many combinations and feels like the type of formats are endless.", "author_fullname": "t2_76x4aitl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WTF date formats.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185yh0m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701184855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does one,  effectively clean dates and timestamps of different format to one format?? There are so many combinations and feels like the type of formats are endless.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185yh0m", "is_robot_indexable": true, "report_reasons": null, "author": "Scratch_that_Iich", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185yh0m/wtf_date_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185yh0m/wtf_date_formats/", "subreddit_subscribers": 142372, "created_utc": 1701184855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_e5fjdth0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboard: The state of Data Stack 2023 (Metabase community)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_1862o6u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kPzBYrXb59x4jO-68CuAN4T6iqF7yj8Tw9N4NQR2uSw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1701195466.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/p6ivlpjgr43c1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?auto=webp&amp;s=61aa62378b4cc3ef92a8d08d8b2340c85bc0f8c5", "width": 2852, "height": 1582}, "resolutions": [{"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d7cb1ef842e75775ec0b62f3453d254a315fca1", "width": 108, "height": 59}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=20a2c3bfe27477dc6daf834fb5b5d2b163fc6fb7", "width": 216, "height": 119}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c3415f8478bfd6c2055fa93de0e041275db50cb", "width": 320, "height": 177}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=01819bbc2ad43db644f3bf3ac582f690537be6a1", "width": 640, "height": 355}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e801796352fe033aa5ef4d89a710af6d68a8510", "width": 960, "height": 532}, {"url": "https://preview.redd.it/p6ivlpjgr43c1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=57858bb45a5ffd4798a30a0bd2383906f7bd707e", "width": 1080, "height": 599}], "variants": {}, "id": "1TaasZfLhsEDECE6-HaJk1rr8UgmjMWpjhLEMMj8Usc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1862o6u", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable_Fold4086", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1862o6u/dashboard_the_state_of_data_stack_2023_metabase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/p6ivlpjgr43c1.png", "subreddit_subscribers": 142372, "created_utc": 1701195466.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We built an ML-powered Databricks cluster optimization tool to help remove the tedious work of tuning Jobs clusters to lower costs.\n\nWe recently shipped a huge upgrade to our product, Gradient, that can automatically improve your job cluster settings to hit your business goals.\n\nThis just came out of private preview where we had awesome results with early testers.  We're looking for more feedback and would love to have folks here give it a spin!\n\nCheck out our demo video here:  [https://www.youtube.com/watch?v=i09x6B6mtjg](https://www.youtube.com/watch?v=i09x6B6mtjg)\n\nTo get started and try for yourself, [see our docs](https://docs.synccomputing.com/sync-gradient/readme)!", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-Improving Databricks Jobs Clusters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185wvhp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1701180489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We built an ML-powered Databricks cluster optimization tool to help remove the tedious work of tuning Jobs clusters to lower costs.&lt;/p&gt;\n\n&lt;p&gt;We recently shipped a huge upgrade to our product, Gradient, that can automatically improve your job cluster settings to hit your business goals.&lt;/p&gt;\n\n&lt;p&gt;This just came out of private preview where we had awesome results with early testers.  We&amp;#39;re looking for more feedback and would love to have folks here give it a spin!&lt;/p&gt;\n\n&lt;p&gt;Check out our demo video here:  &lt;a href=\"https://www.youtube.com/watch?v=i09x6B6mtjg\"&gt;https://www.youtube.com/watch?v=i09x6B6mtjg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;To get started and try for yourself, &lt;a href=\"https://docs.synccomputing.com/sync-gradient/readme\"&gt;see our docs&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?auto=webp&amp;s=05ffd69102d5dddccb997f8ca93ac9307db11e9e", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7c7aa6eabf1b072b8fef656206ca7554e6d221dd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2743e0abe3a30633e2e4eada7906ea4ea6b32ae", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/RcWOQxguZtmLJpDr7Fm9YTFW4oNLMFpGdN7dq8vO2v4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4aa313b38afb9b8f729582bea89d46839845428b", "width": 320, "height": 240}], "variants": {}, "id": "YONw8Gtri81AzcPYVOVfaJY6Sqx6CR_2aqpiGSQiky0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "185wvhp", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185wvhp/selfimproving_databricks_jobs_clusters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185wvhp/selfimproving_databricks_jobs_clusters/", "subreddit_subscribers": 142372, "created_utc": 1701180489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working as a data engineer for a company that after a merger operates in three countries with different currencies. We need to support local currency reporting, and reporting across the company using all three currencies.\n\nI'm thinking a bit about how to model this in an effective way in the data platform, and there are some options, to which I wanted to see if anyone has good/bad experiences working with multiple currencies. For the record our tech stack is dbt, Databricks and Power BI.\n\nI found this data modelling option from [Kimball](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/multiple-currencies/) that says to store the local unconverted currency (what's coming from the source) along with a chosen single \"main\" currency. Then we provide an exchange rate table and let users/analysts convert currencies in queries/notebooks/Power BI reports when needed. \n\nI imagine to prevent creating a mess of conversions in the platform I would suggest users to use the \"main\" currency in their work and only convert to local currencies in their presentation layers. That way we don't have to convert numbers back and forwards, and it's easy to know when to convert the currency.\n\nDoes anyone here have any experience modelling multiple currencies in this way? Any good or bad experiences? Or are there any other options we should consider?", "author_fullname": "t2_11b4ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle reporting in multiple currencies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185sl1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701165652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working as a data engineer for a company that after a merger operates in three countries with different currencies. We need to support local currency reporting, and reporting across the company using all three currencies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking a bit about how to model this in an effective way in the data platform, and there are some options, to which I wanted to see if anyone has good/bad experiences working with multiple currencies. For the record our tech stack is dbt, Databricks and Power BI.&lt;/p&gt;\n\n&lt;p&gt;I found this data modelling option from &lt;a href=\"https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/multiple-currencies/\"&gt;Kimball&lt;/a&gt; that says to store the local unconverted currency (what&amp;#39;s coming from the source) along with a chosen single &amp;quot;main&amp;quot; currency. Then we provide an exchange rate table and let users/analysts convert currencies in queries/notebooks/Power BI reports when needed. &lt;/p&gt;\n\n&lt;p&gt;I imagine to prevent creating a mess of conversions in the platform I would suggest users to use the &amp;quot;main&amp;quot; currency in their work and only convert to local currencies in their presentation layers. That way we don&amp;#39;t have to convert numbers back and forwards, and it&amp;#39;s easy to know when to convert the currency.&lt;/p&gt;\n\n&lt;p&gt;Does anyone here have any experience modelling multiple currencies in this way? Any good or bad experiences? Or are there any other options we should consider?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185sl1j", "is_robot_indexable": true, "report_reasons": null, "author": "mmammies", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185sl1j/how_do_you_handle_reporting_in_multiple_currencies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185sl1j/how_do_you_handle_reporting_in_multiple_currencies/", "subreddit_subscribers": 142372, "created_utc": 1701165652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got an interview scheduled for the coming 2 weeks, and I'm slightly confused regarding the platform I should use to practice my technical skills. The role hovers around AWS, Python, SQL, and ETL.   \nI'm familiar with Leetcode, but have noticed that the questions over there are much more generic and designed for the software engineers. \n\nSo here am I to ask the r/dataengineering peers, which platform would you suggest while preparing for the data engineering interview? LeetCode or StrataScratch? ", "author_fullname": "t2_5u73tpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best medium to prepare for Data Engineer Interviews? LeetCode or StrataScratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1863lbi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701197757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got an interview scheduled for the coming 2 weeks, and I&amp;#39;m slightly confused regarding the platform I should use to practice my technical skills. The role hovers around AWS, Python, SQL, and ETL.&lt;br/&gt;\nI&amp;#39;m familiar with Leetcode, but have noticed that the questions over there are much more generic and designed for the software engineers. &lt;/p&gt;\n\n&lt;p&gt;So here am I to ask the &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; peers, which platform would you suggest while preparing for the data engineering interview? LeetCode or StrataScratch? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1863lbi", "is_robot_indexable": true, "report_reasons": null, "author": "arcofiero", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1863lbi/whats_the_best_medium_to_prepare_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1863lbi/whats_the_best_medium_to_prepare_for_data/", "subreddit_subscribers": 142372, "created_utc": 1701197757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Community Folks, \n\nI have been reading up on differential privacy, k-anonymity, etc. What is their usecases in large organisations who are not really sharing data for public use however their use cases for data shares internally within the org might be high. This is based on the assumption that directly identifiable attributes like name, email, SSN are masked, are there any further steps being taken to protect quasi identifiers.   \nI'm working in an org which has adopted data mesh approach with multiple dbt projects across various use cases running on Snowflake. All production datasets have to be column level tagged as a requirement for Immuta to take care of cataloging and security.   \nI'm keen to understand any frameworks or patterns being used to enable data privacy beyond masking. ", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use Cases for Data Privacy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185ktgw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701137431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Community Folks, &lt;/p&gt;\n\n&lt;p&gt;I have been reading up on differential privacy, k-anonymity, etc. What is their usecases in large organisations who are not really sharing data for public use however their use cases for data shares internally within the org might be high. This is based on the assumption that directly identifiable attributes like name, email, SSN are masked, are there any further steps being taken to protect quasi identifiers.&lt;br/&gt;\nI&amp;#39;m working in an org which has adopted data mesh approach with multiple dbt projects across various use cases running on Snowflake. All production datasets have to be column level tagged as a requirement for Immuta to take care of cataloging and security.&lt;br/&gt;\nI&amp;#39;m keen to understand any frameworks or patterns being used to enable data privacy beyond masking. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185ktgw", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185ktgw/use_cases_for_data_privacy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185ktgw/use_cases_for_data_privacy/", "subreddit_subscribers": 142372, "created_utc": 1701137431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I put together an ETL recently for my work on a chron job API pull that has amassed something like 70,000 rows of data, 100mb of entries a month into a BigQuery dataset for downstream reporting and BI analysis. I expressed concern about aggregation of duplicate entries and entries over time to my manager, suggesting that to save some money I could switch it to a cloud-hosted traditional GCP database (Postgres or similar) with cold storage options for old data that could easily be pumped into Bigquery. They did not seem concerned enough to let me do this. \n\nI have just found out that we have a 13GB dataset for similar reasons, millions of rows of columnar data that get hit with queries frequently and those queries use at least 1GB of data each to process. That puts my smaller dataset costs into context, I suppose. \n\nI am reasonably certain I can at minimum use Dataform to create a secondary dataset adding 100 entries a month instead of 70k, since many pseudo-duplicates are created with no difference other than dates (this is a dataset to catch changes to certain things). I did this actually, because I had to know. It's just not implemented and worried proposing it will seem foolish. \n\nAt what point is it actually smart to worry about these things? Manager seems unworried. I am baby. Please help me look smart.", "author_fullname": "t2_dbmvkyyq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How big is too big for a BigQuery Dataset getting frequent queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1865u8u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701203342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I put together an ETL recently for my work on a chron job API pull that has amassed something like 70,000 rows of data, 100mb of entries a month into a BigQuery dataset for downstream reporting and BI analysis. I expressed concern about aggregation of duplicate entries and entries over time to my manager, suggesting that to save some money I could switch it to a cloud-hosted traditional GCP database (Postgres or similar) with cold storage options for old data that could easily be pumped into Bigquery. They did not seem concerned enough to let me do this. &lt;/p&gt;\n\n&lt;p&gt;I have just found out that we have a 13GB dataset for similar reasons, millions of rows of columnar data that get hit with queries frequently and those queries use at least 1GB of data each to process. That puts my smaller dataset costs into context, I suppose. &lt;/p&gt;\n\n&lt;p&gt;I am reasonably certain I can at minimum use Dataform to create a secondary dataset adding 100 entries a month instead of 70k, since many pseudo-duplicates are created with no difference other than dates (this is a dataset to catch changes to certain things). I did this actually, because I had to know. It&amp;#39;s just not implemented and worried proposing it will seem foolish. &lt;/p&gt;\n\n&lt;p&gt;At what point is it actually smart to worry about these things? Manager seems unworried. I am baby. Please help me look smart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1865u8u", "is_robot_indexable": true, "report_reasons": null, "author": "artfully_rearranged", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1865u8u/how_big_is_too_big_for_a_bigquery_dataset_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1865u8u/how_big_is_too_big_for_a_bigquery_dataset_getting/", "subreddit_subscribers": 142372, "created_utc": 1701203342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineering manager working in data science for a Fortune 500 financial company. I've been asked to take over leading a monthly meeting of the data engineers across data science. This is a broader audience of collective sub-teams supporting different parts of the business -  engineers who do not work with each other regularly, or even neccessarily know one another.\n\nI've been a participant of these meanings for some time and they have not been the most enjoyable or value-add. The content is usually a data engineer presenting a topic of interest i.e.  a new technology or an innovative way they solved the problem, etc..\n\nI work for a large company, so there are many of these communities. I question whether we need this community in the first place, but not sure if that's my choice to make. Regardless, it's an opportunity for me, but it definitely needs some love.\n\nSome challenges are:\n\n1. Participation. I feel the organizers have a hard time getting folks to present material. Curating fresh content is probably challenging. Often the monthly occurrences are canceled last minute due to this.\n2. Engagement. People are not on camera, not asking questions. Just feel lack of connection.\n\nMy initial thoughts are:\n\n1. We're engineers. We should not be lecturing or presenting PowerPoint decks. Instead there should be code on the screen and we should be coding, demoing etc.\n2. Use the time for discussion. I'm sure many of our sub departments have similar problems to solve.\n3. Get a return on the hour time investment - what this looks like, I'm not sure yet.\n\nFor those of you who work at companies, big or small, do you have similar engineering communities of practice? What goes on, and how do you organize? What would you like to see in a data engineering community at work?", "author_fullname": "t2_16he60", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Establishing a Data Engineering Community at Work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1861s9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701193245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineering manager working in data science for a Fortune 500 financial company. I&amp;#39;ve been asked to take over leading a monthly meeting of the data engineers across data science. This is a broader audience of collective sub-teams supporting different parts of the business -  engineers who do not work with each other regularly, or even neccessarily know one another.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a participant of these meanings for some time and they have not been the most enjoyable or value-add. The content is usually a data engineer presenting a topic of interest i.e.  a new technology or an innovative way they solved the problem, etc..&lt;/p&gt;\n\n&lt;p&gt;I work for a large company, so there are many of these communities. I question whether we need this community in the first place, but not sure if that&amp;#39;s my choice to make. Regardless, it&amp;#39;s an opportunity for me, but it definitely needs some love.&lt;/p&gt;\n\n&lt;p&gt;Some challenges are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Participation. I feel the organizers have a hard time getting folks to present material. Curating fresh content is probably challenging. Often the monthly occurrences are canceled last minute due to this.&lt;/li&gt;\n&lt;li&gt;Engagement. People are not on camera, not asking questions. Just feel lack of connection.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My initial thoughts are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We&amp;#39;re engineers. We should not be lecturing or presenting PowerPoint decks. Instead there should be code on the screen and we should be coding, demoing etc.&lt;/li&gt;\n&lt;li&gt;Use the time for discussion. I&amp;#39;m sure many of our sub departments have similar problems to solve.&lt;/li&gt;\n&lt;li&gt;Get a return on the hour time investment - what this looks like, I&amp;#39;m not sure yet.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For those of you who work at companies, big or small, do you have similar engineering communities of practice? What goes on, and how do you organize? What would you like to see in a data engineering community at work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1861s9f", "is_robot_indexable": true, "report_reasons": null, "author": "thefreakypeople", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1861s9f/establishing_a_data_engineering_community_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1861s9f/establishing_a_data_engineering_community_at_work/", "subreddit_subscribers": 142372, "created_utc": 1701193245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Team is heavily dependent on ES and it\u2019s expensive.\n\nI\u2019ve seen OpenSearch being suggested but have no experience running it. I\u2019ve also seen Grafana Loki as an option for logs\n\nUse. Are: full text search on logs\nDeployment: Single tenant ES deployment per customer for search.\n\nAny suggestions or recommendations to move out of this into an alternative solution that is effective and maybe cheaper? Any blogs or migration stories that you can share?", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to ElasticSearch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185zu9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1701193353.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701188328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Team is heavily dependent on ES and it\u2019s expensive.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen OpenSearch being suggested but have no experience running it. I\u2019ve also seen Grafana Loki as an option for logs&lt;/p&gt;\n\n&lt;p&gt;Use. Are: full text search on logs\nDeployment: Single tenant ES deployment per customer for search.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or recommendations to move out of this into an alternative solution that is effective and maybe cheaper? Any blogs or migration stories that you can share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185zu9b", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185zu9b/alternative_to_elasticsearch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185zu9b/alternative_to_elasticsearch/", "subreddit_subscribers": 142372, "created_utc": 1701188328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anybody else had recruiters ask for every damn think in their mental toolbox, when all the client actually wants is somebody to hold their hand and tell them what data is? AWS, GCP, Python, Redshift,SQL, TSQL, PSQL, cloud infrastructure, terraform etc.... come on give us a chance. Give us a use case and we will go to work.", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Knobhead recruiters", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185tdkb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701168849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody else had recruiters ask for every damn think in their mental toolbox, when all the client actually wants is somebody to hold their hand and tell them what data is? AWS, GCP, Python, Redshift,SQL, TSQL, PSQL, cloud infrastructure, terraform etc.... come on give us a chance. Give us a use case and we will go to work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "185tdkb", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185tdkb/knobhead_recruiters/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185tdkb/knobhead_recruiters/", "subreddit_subscribers": 142372, "created_utc": 1701168849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys\u2026 hope you doing great.\nI\u2019ve this certification exam soon and I am studying with some past questions materials. If you\u2019ve had this exam before, how often are questions repeated on a scale of 1 - 10 (lowest to highest)\n\nLooking forward to your responses \ud83d\ude4f", "author_fullname": "t2_n5qii71ai", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP professional data engineer exam question repetition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185mfcp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701142104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys\u2026 hope you doing great.\nI\u2019ve this certification exam soon and I am studying with some past questions materials. If you\u2019ve had this exam before, how often are questions repeated on a scale of 1 - 10 (lowest to highest)&lt;/p&gt;\n\n&lt;p&gt;Looking forward to your responses \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185mfcp", "is_robot_indexable": true, "report_reasons": null, "author": "ImaginationOdd3610", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185mfcp/gcp_professional_data_engineer_exam_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185mfcp/gcp_professional_data_engineer_exam_question/", "subreddit_subscribers": 142372, "created_utc": 1701142104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to use TableauOperator to refresh our workbook at the end of my pipeline but it fails. I get an error saying I have a connection issue - too many retries. Anyone came across this issue?\nI\u2019m also open to suggestions using other type of operators", "author_fullname": "t2_8dnn00ks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone ever used airflow to refresh a tableau workbook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185flgh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701123631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to use TableauOperator to refresh our workbook at the end of my pipeline but it fails. I get an error saying I have a connection issue - too many retries. Anyone came across this issue?\nI\u2019m also open to suggestions using other type of operators&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185flgh", "is_robot_indexable": true, "report_reasons": null, "author": "Se7enEl11ven", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185flgh/anyone_ever_used_airflow_to_refresh_a_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185flgh/anyone_ever_used_airflow_to_refresh_a_tableau/", "subreddit_subscribers": 142372, "created_utc": 1701123631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nNot sure if I'm in the right place for this. Please let me know if I should go elsewhere. I'm working on extracting data from an external cloud-based source via a DataDirect Hybrid Data Pipeline ODBC Driver. The actual extraction is run through an AWS Lambda function that is invoked via step functions. **Full disclosure - I'm punching a bit above my weight here in terms of expertise. I'm a data analyst by title and a software engineer by hobby.**\n\n&amp;#x200B;\n\nWe're using Python for the connection and Docker to develop the extraction script in a runtime environment that mimics the Lambda runtime environment. I'm getting the following error in the `pyodbc.connect()` line before any other queries or connections are made:\n\n`[ERROR] Error: ('HY000', 'The driver did not supply an error!')`\n\nSearches online show that this could be any number of issues, but the error isn't descriptive enough for me to figure out what to do next.\n\n&amp;#x200B;\n\n**What troubleshooting steps can I take to either work to solve this, or try to get a more descriptive error to point me in the right direction?**\n\nTIA\n\n\u200b **Notes that may be helpful:**\n\n* unixODBC is installed\n* pyodbc successfully imports\n* The 64-bit DataDirect ODBC driver is installed in the environment\n* The pyodbc connection string I'm using in the Linux environment works when the process is done on a windows machine (with the windows driver)", "author_fullname": "t2_8amj02bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Troubleshooting Help: [ERROR] Error: ('HY000', 'The driver did not supply an error!')", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_186600s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701203751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Not sure if I&amp;#39;m in the right place for this. Please let me know if I should go elsewhere. I&amp;#39;m working on extracting data from an external cloud-based source via a DataDirect Hybrid Data Pipeline ODBC Driver. The actual extraction is run through an AWS Lambda function that is invoked via step functions. &lt;strong&gt;Full disclosure - I&amp;#39;m punching a bit above my weight here in terms of expertise. I&amp;#39;m a data analyst by title and a software engineer by hobby.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Python for the connection and Docker to develop the extraction script in a runtime environment that mimics the Lambda runtime environment. I&amp;#39;m getting the following error in the &lt;code&gt;pyodbc.connect()&lt;/code&gt; line before any other queries or connections are made:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;[ERROR] Error: (&amp;#39;HY000&amp;#39;, &amp;#39;The driver did not supply an error!&amp;#39;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Searches online show that this could be any number of issues, but the error isn&amp;#39;t descriptive enough for me to figure out what to do next.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What troubleshooting steps can I take to either work to solve this, or try to get a more descriptive error to point me in the right direction?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n\n&lt;p&gt;\u200b &lt;strong&gt;Notes that may be helpful:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;unixODBC is installed&lt;/li&gt;\n&lt;li&gt;pyodbc successfully imports&lt;/li&gt;\n&lt;li&gt;The 64-bit DataDirect ODBC driver is installed in the environment&lt;/li&gt;\n&lt;li&gt;The pyodbc connection string I&amp;#39;m using in the Linux environment works when the process is done on a windows machine (with the windows driver)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "186600s", "is_robot_indexable": true, "report_reasons": null, "author": "FirmDolphin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186600s/troubleshooting_help_error_error_hy000_the_driver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186600s/troubleshooting_help_error_error_hy000_the_driver/", "subreddit_subscribers": 142372, "created_utc": 1701203751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there! I hope this question is appropriate and if not i am deeply sorry!\n\nI am currently working as a Senior Data Analyst and i am looking to switch to a Data Engineer role in the future.\n\n I have work experience with python, sql, xls, pbi. I also did some ETL work at a past job. (Batch files, automatization of work flows, extracting from oracle, processing data in sql and loading into tables/ data visualization tools all automatically done in batch files). \n\nWhat do you guys think i should focus on learning next to maybe venture into a Data Engineering role? I was thinking of taking a course on coursera/ udemy / etc. Have any tips of a good one that is worth taking?\n\nAny tips or insight is welcome! \n\nThank you and sorry for the long  post!", "author_fullname": "t2_8pwcg4vgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1865w1k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701203464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there! I hope this question is appropriate and if not i am deeply sorry!&lt;/p&gt;\n\n&lt;p&gt;I am currently working as a Senior Data Analyst and i am looking to switch to a Data Engineer role in the future.&lt;/p&gt;\n\n&lt;p&gt;I have work experience with python, sql, xls, pbi. I also did some ETL work at a past job. (Batch files, automatization of work flows, extracting from oracle, processing data in sql and loading into tables/ data visualization tools all automatically done in batch files). &lt;/p&gt;\n\n&lt;p&gt;What do you guys think i should focus on learning next to maybe venture into a Data Engineering role? I was thinking of taking a course on coursera/ udemy / etc. Have any tips of a good one that is worth taking?&lt;/p&gt;\n\n&lt;p&gt;Any tips or insight is welcome! &lt;/p&gt;\n\n&lt;p&gt;Thank you and sorry for the long  post!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1865w1k", "is_robot_indexable": true, "report_reasons": null, "author": "Denzor19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1865w1k/data_analysis_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1865w1k/data_analysis_to_data_engineering/", "subreddit_subscribers": 142372, "created_utc": 1701203464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to ask anyone finished MIT MicroMaster program of Data Science (via edx), how is it useful or not at Job Market? may have your experience shared? Does hiring company recognize it and give it a credit? Sorry I intend to ask this question but can't change post subject after submitted.\n\n'm afraid a little bit for it's 'not a formal Master Degree, so employer won't take it seriously as much as MIT regular on-campus students.   FYI, I finished one of its Course 'MIT x6.431 - Probability and Data Uncertainty', get good score 92/100,  have 3 remains, but I'm working full-time, progress Very slowly, by time I graduate I'll be over 50...   see my certificate in attached Image", "author_fullname": "t2_bt52hv18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My MIT course certificate in Data Science MicroMaster program", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_186456j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701199107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to ask anyone finished MIT MicroMaster program of Data Science (via edx), how is it useful or not at Job Market? may have your experience shared? Does hiring company recognize it and give it a credit? Sorry I intend to ask this question but can&amp;#39;t change post subject after submitted.&lt;/p&gt;\n\n&lt;p&gt;&amp;#39;m afraid a little bit for it&amp;#39;s &amp;#39;not a formal Master Degree, so employer won&amp;#39;t take it seriously as much as MIT regular on-campus students.   FYI, I finished one of its Course &amp;#39;MIT x6.431 - Probability and Data Uncertainty&amp;#39;, get good score 92/100,  have 3 remains, but I&amp;#39;m working full-time, progress Very slowly, by time I graduate I&amp;#39;ll be over 50...   see my certificate in attached Image&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "186456j", "is_robot_indexable": true, "report_reasons": null, "author": "SG-Dani20", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/186456j/my_mit_course_certificate_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/186456j/my_mit_course_certificate_in_data_science/", "subreddit_subscribers": 142372, "created_utc": 1701199107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\nOur team was tasked with creating a new reporting solution after our backend team migrated from a legacy Oracle system to a pure Mongo-based cluster for OLTP. However, they overlooked the challenges of running analytical queries on this setup. My team was then given responsibility for our new OLAP platform and sincet the team consists solely of data analysts and ML engineers, we quickly decided to build a platform using mostly AWS services.\n\nHere's the structure of our tools and services:\n\n* **Ingestion:** Kafka/Firehouse for streaming and Airbyte for batch.\n* **ETL/ELT:** Glue/Lambda.\n* **Orchestration:** AWS Step Functions.\n* **Lakehouse:** S3 + Athena (Trino) with Iceberg tables.\n* **Governance:** AWS Lake Formation.\n* **Visualization:** QuickSight.\n* **MLOps:** Metaflow.\n\nBefore committing too deeply to AWS and accumulating tech debt, I'd like to hear if anyone has started with these tools but later decided to change for any reason.\n\nSome concerns I have:\n\n1. Athena's consumption-based cost model might become expensive over time. Also, team members may not be reusing models or metrics definitions simply because they aren't aware they already exist. (Would a tool like DBT fix this?)\n2. QuickSight integrates well with AWS services but is costly and doesn't support data modeling directly.\n3. Although Step Functions work well for our data and ML pipelines, I've noticed many companies use Airflow, Prefect, or Dagster. Have I overlooked something?\n4. Being heavily tied to AWS means we have significant vendor lock-in. If they drastically increase prices, we may have no choice but to accept it.\n5. Integrating tools like DBT, Great Expectations, or other tools from the modern data stack in this stack seems challenging.  \n\n\nKeen to hear your thoughts", "author_fullname": "t2_2nhoc35w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stack recommendation/critique", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18623m3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701194049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;Our team was tasked with creating a new reporting solution after our backend team migrated from a legacy Oracle system to a pure Mongo-based cluster for OLTP. However, they overlooked the challenges of running analytical queries on this setup. My team was then given responsibility for our new OLAP platform and sincet the team consists solely of data analysts and ML engineers, we quickly decided to build a platform using mostly AWS services.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the structure of our tools and services:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Ingestion:&lt;/strong&gt; Kafka/Firehouse for streaming and Airbyte for batch.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ETL/ELT:&lt;/strong&gt; Glue/Lambda.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Orchestration:&lt;/strong&gt; AWS Step Functions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Lakehouse:&lt;/strong&gt; S3 + Athena (Trino) with Iceberg tables.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Governance:&lt;/strong&gt; AWS Lake Formation.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Visualization:&lt;/strong&gt; QuickSight.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;MLOps:&lt;/strong&gt; Metaflow.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Before committing too deeply to AWS and accumulating tech debt, I&amp;#39;d like to hear if anyone has started with these tools but later decided to change for any reason.&lt;/p&gt;\n\n&lt;p&gt;Some concerns I have:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Athena&amp;#39;s consumption-based cost model might become expensive over time. Also, team members may not be reusing models or metrics definitions simply because they aren&amp;#39;t aware they already exist. (Would a tool like DBT fix this?)&lt;/li&gt;\n&lt;li&gt;QuickSight integrates well with AWS services but is costly and doesn&amp;#39;t support data modeling directly.&lt;/li&gt;\n&lt;li&gt;Although Step Functions work well for our data and ML pipelines, I&amp;#39;ve noticed many companies use Airflow, Prefect, or Dagster. Have I overlooked something?&lt;/li&gt;\n&lt;li&gt;Being heavily tied to AWS means we have significant vendor lock-in. If they drastically increase prices, we may have no choice but to accept it.&lt;/li&gt;\n&lt;li&gt;Integrating tools like DBT, Great Expectations, or other tools from the modern data stack in this stack seems challenging.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Keen to hear your thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "18623m3", "is_robot_indexable": true, "report_reasons": null, "author": "UpperEfficiency", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18623m3/stack_recommendationcritique/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18623m3/stack_recommendationcritique/", "subreddit_subscribers": 142372, "created_utc": 1701194049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good morning!\n\nLong story, but please hear me out as I am genuinely curious about the field of data engineering.\n\nI am currently working for a corporation in Business Operations and will be taking an exam in December to become a Certified HR Professional through SHRM. The company has only been around a year and a half and is growing slowly, but we should begin to see growth within the next year or so.\n\nI received a call from a recruiter who was interested in hiring me on as a Data Associate due to my job description containing the term Integration Specialist. However, the type of integration we are doing is not based in systems, but in moving personnel over after an acquisition. I told the recruiter that I did not have the technical experience required, but that I would be willing to learn if they wanted to pay me less, but maybe train me and that I could assist with Administrative/HR/Operations duties while I get educated in coding/programming.\n\nObviously, the company isn't going to waste their time on training someone without a degree in any type of computer science, so it got me wondering if there was a way that I could get some type of certification for coding/data engineering/programming. I absorb information at a ridiculous rate and have amazing retention when it comes to something I love, it's really the only thing I'm great at, and I love statistics. I love them in sports, I love them in finances, and I really just love numbers.\n\nMy dream job is to work for a professional hockey franchise and with the way analytics has taken hold of everything and is ushering forth a purely data-driven era, I would like to expand my knowledge base and skills so that I can become an asset to an organization. I don't have the time or money to go back to school as I have a full-time job and a toddler, but I still want to try and get started on this before I get stuck in one particular field and lose the ability to grow. I just turned 34 so I'm young-ish, but I don't want to be pushing 40 without some experience or knowledge in data engineering.\n\nIf anyone could provide any advice or point me in the direction of some resources where I could get started, it would be greatly appreciated!\n\n&amp;#x200B;\n\nTL;DR: I would like some advice on where to go, outside of going back to a university, to learn about data engineering.\n\nEdit: Typo.", "author_fullname": "t2_f09h4fwwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1861ubh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701193391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good morning!&lt;/p&gt;\n\n&lt;p&gt;Long story, but please hear me out as I am genuinely curious about the field of data engineering.&lt;/p&gt;\n\n&lt;p&gt;I am currently working for a corporation in Business Operations and will be taking an exam in December to become a Certified HR Professional through SHRM. The company has only been around a year and a half and is growing slowly, but we should begin to see growth within the next year or so.&lt;/p&gt;\n\n&lt;p&gt;I received a call from a recruiter who was interested in hiring me on as a Data Associate due to my job description containing the term Integration Specialist. However, the type of integration we are doing is not based in systems, but in moving personnel over after an acquisition. I told the recruiter that I did not have the technical experience required, but that I would be willing to learn if they wanted to pay me less, but maybe train me and that I could assist with Administrative/HR/Operations duties while I get educated in coding/programming.&lt;/p&gt;\n\n&lt;p&gt;Obviously, the company isn&amp;#39;t going to waste their time on training someone without a degree in any type of computer science, so it got me wondering if there was a way that I could get some type of certification for coding/data engineering/programming. I absorb information at a ridiculous rate and have amazing retention when it comes to something I love, it&amp;#39;s really the only thing I&amp;#39;m great at, and I love statistics. I love them in sports, I love them in finances, and I really just love numbers.&lt;/p&gt;\n\n&lt;p&gt;My dream job is to work for a professional hockey franchise and with the way analytics has taken hold of everything and is ushering forth a purely data-driven era, I would like to expand my knowledge base and skills so that I can become an asset to an organization. I don&amp;#39;t have the time or money to go back to school as I have a full-time job and a toddler, but I still want to try and get started on this before I get stuck in one particular field and lose the ability to grow. I just turned 34 so I&amp;#39;m young-ish, but I don&amp;#39;t want to be pushing 40 without some experience or knowledge in data engineering.&lt;/p&gt;\n\n&lt;p&gt;If anyone could provide any advice or point me in the direction of some resources where I could get started, it would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;TL;DR: I would like some advice on where to go, outside of going back to a university, to learn about data engineering.&lt;/p&gt;\n\n&lt;p&gt;Edit: Typo.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1861ubh", "is_robot_indexable": true, "report_reasons": null, "author": "HomegrownStatistics", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1861ubh/data_engineering_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1861ubh/data_engineering_certifications/", "subreddit_subscribers": 142372, "created_utc": 1701193391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello DE community:\n\nOur data scientist has created a  model and published as lambda service in AWS (written using Microsoft.NET )  This lambda is published as API and consumed by external apps . The challenge is API takes only one input (read as json with location coordinates), computes the logic and returns the output as json format.\n\nOne of business leads, wants to run the model for 250K points efficiently (quicker and cheaper ) and store the results (json) in S3.  The goal is to run for model for various scenarios and generate the output. \n\nThe biggest constraint, model cannot be changed. It takes only one single input , that's by design. \n\nI want to run the model for 250K points efficiently . I am aware I need to run parallelization technique; but looking for some solid guidance for optimal solution (in terms of cost and time) . ", "author_fullname": "t2_h12iimb9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Lambda API calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_18603j3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701188967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello DE community:&lt;/p&gt;\n\n&lt;p&gt;Our data scientist has created a  model and published as lambda service in AWS (written using Microsoft.NET )  This lambda is published as API and consumed by external apps . The challenge is API takes only one input (read as json with location coordinates), computes the logic and returns the output as json format.&lt;/p&gt;\n\n&lt;p&gt;One of business leads, wants to run the model for 250K points efficiently (quicker and cheaper ) and store the results (json) in S3.  The goal is to run for model for various scenarios and generate the output. &lt;/p&gt;\n\n&lt;p&gt;The biggest constraint, model cannot be changed. It takes only one single input , that&amp;#39;s by design. &lt;/p&gt;\n\n&lt;p&gt;I want to run the model for 250K points efficiently . I am aware I need to run parallelization technique; but looking for some solid guidance for optimal solution (in terms of cost and time) . &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "18603j3", "is_robot_indexable": true, "report_reasons": null, "author": "ParticularPlant8978", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/18603j3/bulk_lambda_api_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/18603j3/bulk_lambda_api_calls/", "subreddit_subscribers": 142372, "created_utc": 1701188967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nOur current stack for ELT is Airbyte, dbt, and Snowflake. Orchestrated with Prefect. \n\nWe use this stack to extract data for our customers (we\u2019re an analytics tool that manages the whole ELT from API sources all the way to data warehouse). While Airbyte helped us get started easily we\u2019re looking to rebuild from the ground up and we mainly care about making it easy to handle incremental loading, errors, and either some UI or an easy to integrate API. We\u2019re ready to build everything else for our use case. We\u2019re an AWS shop if that helps. \n\n\nWhat would you recommend for extraction?\n\nThanks!", "author_fullname": "t2_mcyhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EL-stack recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185zvm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1701188421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Our current stack for ELT is Airbyte, dbt, and Snowflake. Orchestrated with Prefect. &lt;/p&gt;\n\n&lt;p&gt;We use this stack to extract data for our customers (we\u2019re an analytics tool that manages the whole ELT from API sources all the way to data warehouse). While Airbyte helped us get started easily we\u2019re looking to rebuild from the ground up and we mainly care about making it easy to handle incremental loading, errors, and either some UI or an easy to integrate API. We\u2019re ready to build everything else for our use case. We\u2019re an AWS shop if that helps. &lt;/p&gt;\n\n&lt;p&gt;What would you recommend for extraction?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "185zvm1", "is_robot_indexable": true, "report_reasons": null, "author": "beemachine", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185zvm1/elstack_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/185zvm1/elstack_recommendations/", "subreddit_subscribers": 142372, "created_utc": 1701188421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for working with dbt and BigQuery - A practitioner's guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_185z98k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1701186894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/dbt-bigquery-best-practices", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "185z98k", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/185z98k/best_practices_for_working_with_dbt_and_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/dbt-bigquery-best-practices", "subreddit_subscribers": 142372, "created_utc": 1701186894.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}