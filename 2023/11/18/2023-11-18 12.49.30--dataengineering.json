{"kind": "Listing", "data": {"after": "t3_17xft3b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came from a company where the data engineer I was working across told me that automation was \u201cnot possible.\u201d \n\nI am of the opinion that automation, at least partial automation, is a possibility in most data warehousing and ETL processes.\n\nCould someone tell me when automation isn\u2019t possible?", "author_fullname": "t2_6mus1in0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When is Automation \u201cNot Possible?\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xuptt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700270307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came from a company where the data engineer I was working across told me that automation was \u201cnot possible.\u201d &lt;/p&gt;\n\n&lt;p&gt;I am of the opinion that automation, at least partial automation, is a possibility in most data warehousing and ETL processes.&lt;/p&gt;\n\n&lt;p&gt;Could someone tell me when automation isn\u2019t possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xuptt", "is_robot_indexable": true, "report_reasons": null, "author": "scarlet_poppies", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xuptt/when_is_automation_not_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xuptt/when_is_automation_not_possible/", "subreddit_subscribers": 140277, "created_utc": 1700270307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there,\n\nI've got a 20Go csv file I need to work with.\n\nInitially I tried to load with DuckDB / DBeaver but it took almost 4 hours* to convert to an SQL table.\nAnd even the most basic queries are way too slow (several minutes)\n\nDo you have any advice on how to tame this file ?\nOpen to SQL or Python, not good enough with Java, Spark or Polar.\n\nThanks!\n\n*My computer is an i9 12th gen with 32G DDR5. Not an old timer (yet)", "author_fullname": "t2_bqy2s6be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20go csv file to SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xrrv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700262127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a 20Go csv file I need to work with.&lt;/p&gt;\n\n&lt;p&gt;Initially I tried to load with DuckDB / DBeaver but it took almost 4 hours* to convert to an SQL table.\nAnd even the most basic queries are way too slow (several minutes)&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice on how to tame this file ?\nOpen to SQL or Python, not good enough with Java, Spark or Polar.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;*My computer is an i9 12th gen with 32G DDR5. Not an old timer (yet)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xrrv5", "is_robot_indexable": true, "report_reasons": null, "author": "reddit_ski", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xrrv5/20go_csv_file_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xrrv5/20go_csv_file_to_sql/", "subreddit_subscribers": 140277, "created_utc": 1700262127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?", "author_fullname": "t2_i7s0h23q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake pay-as-you-go pricing for the business critical edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xlkql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xlkql", "is_robot_indexable": true, "report_reasons": null, "author": "LA_throwaway_one", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "subreddit_subscribers": 140277, "created_utc": 1700245736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently did a course and that is making me hate spark, the instructor really didn't taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.\n\nCan anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.\n\nSo if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.", "author_fullname": "t2_3xcrjr5n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please share the course or resource which helped you learned pyspark as a beginner to a professional and how did you practiced spark afterwards outside job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xhqs4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently did a course and that is making me hate spark, the instructor really didn&amp;#39;t taught spark in a beginner friendly manner and everyhting felt very highlevel, no code line was explained in depth and how are things working, I thought it would get better as I will learn more but got burned out by that.&lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a course that helped them learn pyspark. Also my tech stack is mainly aws-glue-pyspark and snowflake.&lt;/p&gt;\n\n&lt;p&gt;So if you have got any reccommedation for python,sql,snowflake too as a data engineer resource then please share it too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xhqs4", "is_robot_indexable": true, "report_reasons": null, "author": "ImpressionOwn137", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqs4/please_share_the_course_or_resource_which_helped/", "subreddit_subscribers": 140277, "created_utc": 1700235405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I (45M) have been working on customer dashboards for my most recent job.  Its boring AF, you can only make so many Tableau dashboards before wanting to punch yourself in the face.  I can continue to do this, make decent $ at it, but man, work has to have something more fun than just the $ that I make.  \n\n\nI want to get back into data engineering - but I am not sure which types of jobs I should apply to, I don't have luck getting interviews.  \n\n\nMy background is in RDBMS data warehousing, and building data warehouse applications (series of stored procedures that accomplished a very complicated and data intensive accounting process with slowly changing rules).  Creating logical and physical data models is something I am good at.  I understand, write, and tune SQL quite well, and have many years job experience doing these tasks.  I ran and operated things on Teradata, and can tune their sharded MPP pretty well.  All of these were orchestrated in UC4, I haven't used tools like Airflow, but aren't they the same?  \n\n\nI was a user of Impala, but never engineered anything on Hadoop - only consumed data there.  \n\n\nI've built a Snowflake Data Warehouse on top of AWS S3, and was minimally involved in creating data pipelines to those AWS buckets (I built firehose jobs that partitioned our data).  Parsing JSON events and creating a real-time ETL - I have done this stuff pretty well.  \n\n\nWhere I feel I lack, and interviewers know it:\n\nI have NO on the job experience with Python, Spark, Databricks, Azure.  People look for my experience with SQL Server, and I'm like... Isn't it the same as these others?  I've not configured RedShift before, I've only consumed data there, so no experience standing up files as a datalake via Redshift - I've only ingested files into Snowflake (not even used files as external tables).  \n\n\nI have built fairly complicated for-fun Python projects at home, but otherwise I have NO on the job experience there.  I downloaded a local instance of Spark, and did some stupid stuff with it (weeee!!!!), but I've never seen jobs in production on Spark.  \n\n\nWhat types of jobs should I be applying for?  How do I go about get practical (preferably on the job) experience in the things I am lacking?  I feel my skills are atrophied, no longer relevant to jobs people are hiring for, and am struggling figuring out how to bridge the gap to these newer technologies.", "author_fullname": "t2_ncssul4iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kind of DE job to apply to", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xt48f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700265772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (45M) have been working on customer dashboards for my most recent job.  Its boring AF, you can only make so many Tableau dashboards before wanting to punch yourself in the face.  I can continue to do this, make decent $ at it, but man, work has to have something more fun than just the $ that I make.  &lt;/p&gt;\n\n&lt;p&gt;I want to get back into data engineering - but I am not sure which types of jobs I should apply to, I don&amp;#39;t have luck getting interviews.  &lt;/p&gt;\n\n&lt;p&gt;My background is in RDBMS data warehousing, and building data warehouse applications (series of stored procedures that accomplished a very complicated and data intensive accounting process with slowly changing rules).  Creating logical and physical data models is something I am good at.  I understand, write, and tune SQL quite well, and have many years job experience doing these tasks.  I ran and operated things on Teradata, and can tune their sharded MPP pretty well.  All of these were orchestrated in UC4, I haven&amp;#39;t used tools like Airflow, but aren&amp;#39;t they the same?  &lt;/p&gt;\n\n&lt;p&gt;I was a user of Impala, but never engineered anything on Hadoop - only consumed data there.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a Snowflake Data Warehouse on top of AWS S3, and was minimally involved in creating data pipelines to those AWS buckets (I built firehose jobs that partitioned our data).  Parsing JSON events and creating a real-time ETL - I have done this stuff pretty well.  &lt;/p&gt;\n\n&lt;p&gt;Where I feel I lack, and interviewers know it:&lt;/p&gt;\n\n&lt;p&gt;I have NO on the job experience with Python, Spark, Databricks, Azure.  People look for my experience with SQL Server, and I&amp;#39;m like... Isn&amp;#39;t it the same as these others?  I&amp;#39;ve not configured RedShift before, I&amp;#39;ve only consumed data there, so no experience standing up files as a datalake via Redshift - I&amp;#39;ve only ingested files into Snowflake (not even used files as external tables).  &lt;/p&gt;\n\n&lt;p&gt;I have built fairly complicated for-fun Python projects at home, but otherwise I have NO on the job experience there.  I downloaded a local instance of Spark, and did some stupid stuff with it (weeee!!!!), but I&amp;#39;ve never seen jobs in production on Spark.  &lt;/p&gt;\n\n&lt;p&gt;What types of jobs should I be applying for?  How do I go about get practical (preferably on the job) experience in the things I am lacking?  I feel my skills are atrophied, no longer relevant to jobs people are hiring for, and am struggling figuring out how to bridge the gap to these newer technologies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xt48f", "is_robot_indexable": true, "report_reasons": null, "author": "IllustriousCorgi9877", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xt48f/kind_of_de_job_to_apply_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xt48f/kind_of_de_job_to_apply_to/", "subreddit_subscribers": 140277, "created_utc": 1700265772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi y\u2019all! \n\nI\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. \n\n1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? \n\n2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) \n\n3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? \n\n\ni\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. \n\nAlso, please if you know any good YT channels that explains this process from the very beginning, share it with me. \n\nThank you in advance,\nBest,", "author_fullname": "t2_flu4lsm6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schemas and data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xi4ru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700236495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi y\u2019all! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not a data engineer and I\u2019d like to ask few questions to follow with the team because i want to understand the process and if their plans logical or not. I\u2019ve tried to google it but i couldn\u2019t understand it cause again.. i\u2019m not a data engineer. &lt;/p&gt;\n\n&lt;p&gt;1/ in which phase of building a data warehouse you\u2019ll start designing the schemas and do the data modelling? &lt;/p&gt;\n\n&lt;p&gt;2/ can you start designing the schemas before you setup your cloud and dw? (some delays here and would like to know if we can start something else instead of waiting) &lt;/p&gt;\n\n&lt;p&gt;3/ team decided to go with dbt (data building tool) does this tool have advanced features like building the schemas automatically for example or is there any sort of built ins\u2026 or the only way to create your facts and dimensions is by coding? &lt;/p&gt;\n\n&lt;p&gt;i\u2019m in a startup and we don\u2019t have much expertise in this field, and I would like to know a bit more. &lt;/p&gt;\n\n&lt;p&gt;Also, please if you know any good YT channels that explains this process from the very beginning, share it with me. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance,\nBest,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xi4ru", "is_robot_indexable": true, "report_reasons": null, "author": "Fuzzy-Example-7326", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xi4ru/schemas_and_data_modelling/", "subreddit_subscribers": 140277, "created_utc": 1700236495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some people recommend zoomcamp course and i saw couple of posts say good words on it \n\n\nI feel it's good one because it's free as i can't afford certs and you make a project at the end so what stuff i have to know before studying the course\n\n\nI know python", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you recommend zoomcamp course ? ( Iam a beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y04k5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700288121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some people recommend zoomcamp course and i saw couple of posts say good words on it &lt;/p&gt;\n\n&lt;p&gt;I feel it&amp;#39;s good one because it&amp;#39;s free as i can&amp;#39;t afford certs and you make a project at the end so what stuff i have to know before studying the course&lt;/p&gt;\n\n&lt;p&gt;I know python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17y04k5", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y04k5/would_you_recommend_zoomcamp_course_iam_a_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y04k5/would_you_recommend_zoomcamp_course_iam_a_beginner/", "subreddit_subscribers": 140277, "created_utc": 1700288121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow data engineers,\n\nI am currently working on a project where I\u2019m ingesting data from two different sources, each with its own API. The data sources have 20 and 10 tables, respectively. I am facing a few challenges and would appreciate your insights on the following aspects:\n\n\t1.\tAutomating Table Creation in PostgreSQL:\n\t\u2022\tMy approach so far has been to use Python scripts to generate SQL queries for table creation, based on the keys from JSON responses provided by the APIs. These tables are then manually created in an initially empty PostgreSQL database. Is this a standard approach, or are there more efficient methods to automate this process?\n\t2.\tData Import Methodology:\n\t\u2022\tAfter creating the tables, I am converting the JSON response dictionaries into CSV files and then using PostgreSQL\u2019s COPY FROM command to import the data into the corresponding tables. Is this a recommended practice, or are there better alternatives for importing JSON data directly into PostgreSQL?\n\t3.\tHandling Schema Changes:\n\t\u2022\tA concern I have for future operations is how to efficiently manage potential schema changes, such as alterations in column names or the order of keys in JSON responses, which could impact the CSV file structure and consequently the database import process. What strategies or best practices can be employed to handle such dynamic schema changes? \n\n      4. Big data vs small data \n           What changes in the process if for example the data is 1GB vs 10GB vs 100GB per source? Because right now I am making multiple calls to 1 API to not overload the memory. I am thus appending the data onto the csv file in batches. Or is there another more favourable way to load the data?\n\nAny advice or experiences you could share on these topics would be greatly appreciated, as I\u2019m aiming to optimize the process and ensure long-term maintainability.\n\nThank you in advance for your insights!", "author_fullname": "t2_ebebn3prf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on data ingestion into postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xv74t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700271684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project where I\u2019m ingesting data from two different sources, each with its own API. The data sources have 20 and 10 tables, respectively. I am facing a few challenges and would appreciate your insights on the following aspects:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;1.  Automating Table Creation in PostgreSQL:\n\u2022 My approach so far has been to use Python scripts to generate SQL queries for table creation, based on the keys from JSON responses provided by the APIs. These tables are then manually created in an initially empty PostgreSQL database. Is this a standard approach, or are there more efficient methods to automate this process?\n2.  Data Import Methodology:\n\u2022 After creating the tables, I am converting the JSON response dictionaries into CSV files and then using PostgreSQL\u2019s COPY FROM command to import the data into the corresponding tables. Is this a recommended practice, or are there better alternatives for importing JSON data directly into PostgreSQL?\n3.  Handling Schema Changes:\n\u2022 A concern I have for future operations is how to efficiently manage potential schema changes, such as alterations in column names or the order of keys in JSON responses, which could impact the CSV file structure and consequently the database import process. What strategies or best practices can be employed to handle such dynamic schema changes? \n\n  4. Big data vs small data \n       What changes in the process if for example the data is 1GB vs 10GB vs 100GB per source? Because right now I am making multiple calls to 1 API to not overload the memory. I am thus appending the data onto the csv file in batches. Or is there another more favourable way to load the data?\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Any advice or experiences you could share on these topics would be greatly appreciated, as I\u2019m aiming to optimize the process and ensure long-term maintainability.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xv74t", "is_robot_indexable": true, "report_reasons": null, "author": "mtn331", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xv74t/seeking_advice_on_data_ingestion_into_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xv74t/seeking_advice_on_data_ingestion_into_postgresql/", "subreddit_subscribers": 140277, "created_utc": 1700271684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I'm part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn't a part of my daily tasks, I do possess some familiarity with writing SQL queries.\n\nOur team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn't just in running numbers and building models and tools - I came in with a strategic education and strategic experience.\n\nI strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.\n\nMy questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don't want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.\n\nI looked into Coursera for BigQuery courses, there are 100s of courses. I don't know what I should pick.\n\nPlease drop your thoughts/suggestions.", "author_fullname": "t2_p2qjz042", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning to 'Analytics Engineering' by blending my existing Analytics and acquiring Data Engineering skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xl0r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700244249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I&amp;#39;m part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn&amp;#39;t a part of my daily tasks, I do possess some familiarity with writing SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn&amp;#39;t just in running numbers and building models and tools - I came in with a strategic education and strategic experience.&lt;/p&gt;\n\n&lt;p&gt;I strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.&lt;/p&gt;\n\n&lt;p&gt;My questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don&amp;#39;t want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.&lt;/p&gt;\n\n&lt;p&gt;I looked into Coursera for BigQuery courses, there are 100s of courses. I don&amp;#39;t know what I should pick.&lt;/p&gt;\n\n&lt;p&gt;Please drop your thoughts/suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xl0r8", "is_robot_indexable": true, "report_reasons": null, "author": "NumbTheFather", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "subreddit_subscribers": 140277, "created_utc": 1700244249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to use dbt Cloud with Azure DevOps GIT without the enterprise license of dbt Cloud somehow? \n\nIt would be much easier for us to have dbt Cloud and all our Azure resources in Azure DevOps GIT and pipelines. I really don't want to be forced to use Github for dbt Cloud and have two GIT repos. But it's a tiny project and it doesn't justify an expensive dbt Cloud enterprise account.", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud + Azure DevOps GIT without enterprise license?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xo1w2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700252384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use dbt Cloud with Azure DevOps GIT without the enterprise license of dbt Cloud somehow? &lt;/p&gt;\n\n&lt;p&gt;It would be much easier for us to have dbt Cloud and all our Azure resources in Azure DevOps GIT and pipelines. I really don&amp;#39;t want to be forced to use Github for dbt Cloud and have two GIT repos. But it&amp;#39;s a tiny project and it doesn&amp;#39;t justify an expensive dbt Cloud enterprise account.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xo1w2", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xo1w2/dbt_cloud_azure_devops_git_without_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xo1w2/dbt_cloud_azure_devops_git_without_enterprise/", "subreddit_subscribers": 140277, "created_utc": 1700252384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll try to keep this short.  I work at a Fortune 100 company with a \"senior engineer consultant\" title, although that doesn't really describe what I do.  I'm a business employee (not IT) and my day-to-day is:\n\n* Run validations to ensure IT data replication worked (Python &amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.\n* Pull tables from disparate data sources and compare to find differences (MS Power Query)\n* Tell IT what changes they need to make to the tables \n* Write adhoc SQL reports\n\nI spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.\n\n* 10 years strong SQL (CTE, multi joins, window/analytic functions)\n* 5 years moderate Python, Java, AppsScript\n* 5 years Tableau, Cognos\n* 5 years Talend (ETL)\n\nAm I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?", "author_fullname": "t2_1e1kvt8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I qualified to jump to a mid/senior data engineer position from a business data analyst role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xj3we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700239638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700239146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try to keep this short.  I work at a Fortune 100 company with a &amp;quot;senior engineer consultant&amp;quot; title, although that doesn&amp;#39;t really describe what I do.  I&amp;#39;m a business employee (not IT) and my day-to-day is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run validations to ensure IT data replication worked (Python &amp;amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.&lt;/li&gt;\n&lt;li&gt;Pull tables from disparate data sources and compare to find differences (MS Power Query)&lt;/li&gt;\n&lt;li&gt;Tell IT what changes they need to make to the tables &lt;/li&gt;\n&lt;li&gt;Write adhoc SQL reports&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;10 years strong SQL (CTE, multi joins, window/analytic functions)&lt;/li&gt;\n&lt;li&gt;5 years moderate Python, Java, AppsScript&lt;/li&gt;\n&lt;li&gt;5 years Tableau, Cognos&lt;/li&gt;\n&lt;li&gt;5 years Talend (ETL)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Am I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xj3we", "is_robot_indexable": true, "report_reasons": null, "author": "IT-Banker", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "subreddit_subscribers": 140277, "created_utc": 1700239146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : [https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc](https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc)  \n i could really use your help thank you", "author_fullname": "t2_6lzy3mq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "spark streaming data from kafka topic to elasticsearch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xh6lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700233856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys i am having a problem to submit my script code into kafka due to dependencies issues , in the same script i read data and send it to elasticsearch . this is the link to my stackoverflow question : &lt;a href=\"https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc\"&gt;https://stackoverflow.com/questions/77501116/getting-some-logs-from-kafka-topic-into-spark-and-the-sending-it-to-elasticsearc&lt;/a&gt;&lt;br/&gt;\n i could really use your help thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xh6lu", "is_robot_indexable": true, "report_reasons": null, "author": "ekkoogod", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xh6lu/spark_streaming_data_from_kafka_topic_to/", "subreddit_subscribers": 140277, "created_utc": 1700233856.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, i'm a web dev (2 years of experience) who got a interest in the Data world. I want to solve some data problems usign my programming skills. Example:\n\n\"A X company has 5 apis that bring some huge data in JSON. The salles by customer data is spread across those 5 apis. Your job would be to organize and filter it (using arrays and stuff) in this and that manner.\"\n\nNow, i don't know if this fits here, but i think it kinda does. I'm having a hard time trying to find exercises like that, but i found the closer to be this one:\n\n[https://nyu-cds.github.io/courses/exercises/Basic-python-1/](https://nyu-cds.github.io/courses/exercises/Basic-python-1/)\n\nIs really in the direction that i want it. If anyone has more online exercises like that for me, i would be grateful.\n\nObs: I just want to pratice some data stuff with programming. Looking to learn something. \n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_ul5cbil9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data exercises for a web dev", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17y4wmi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700308655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700308410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i&amp;#39;m a web dev (2 years of experience) who got a interest in the Data world. I want to solve some data problems usign my programming skills. Example:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;A X company has 5 apis that bring some huge data in JSON. The salles by customer data is spread across those 5 apis. Your job would be to organize and filter it (using arrays and stuff) in this and that manner.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Now, i don&amp;#39;t know if this fits here, but i think it kinda does. I&amp;#39;m having a hard time trying to find exercises like that, but i found the closer to be this one:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nyu-cds.github.io/courses/exercises/Basic-python-1/\"&gt;https://nyu-cds.github.io/courses/exercises/Basic-python-1/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is really in the direction that i want it. If anyone has more online exercises like that for me, i would be grateful.&lt;/p&gt;\n\n&lt;p&gt;Obs: I just want to pratice some data stuff with programming. Looking to learn something. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y4wmi", "is_robot_indexable": true, "report_reasons": null, "author": "Usual-Dragonfly3117", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y4wmi/data_exercises_for_a_web_dev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y4wmi/data_exercises_for_a_web_dev/", "subreddit_subscribers": 140277, "created_utc": 1700308410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm currently working on extracting metadata on a management group level from Microsoft Azure for analysis purposes. However, the API calls I'm using limit me to fetching only 1000 records at a time. I have a substantial dataset of around 100-120k records to extract, and this limitation significantly slows down the process.\n\nI'm curious if anyone has encountered a similar situation and found a way to increase the maximum number of records that can be extracted in a single call. Ideally, I'd like to fetch around 10k records per call to expedite the extraction process. \n\nDoes Azure allow users to modify pagination settings for API calls, or is this limitation fixed within the system?\n\nI'd appreciate any insights or experiences you've had in dealing with this issue. Thanks!", "author_fullname": "t2_8yfxu6me", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Azure API Calls for Larger Data Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17y4qd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700307702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on extracting metadata on a management group level from Microsoft Azure for analysis purposes. However, the API calls I&amp;#39;m using limit me to fetching only 1000 records at a time. I have a substantial dataset of around 100-120k records to extract, and this limitation significantly slows down the process.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious if anyone has encountered a similar situation and found a way to increase the maximum number of records that can be extracted in a single call. Ideally, I&amp;#39;d like to fetch around 10k records per call to expedite the extraction process. &lt;/p&gt;\n\n&lt;p&gt;Does Azure allow users to modify pagination settings for API calls, or is this limitation fixed within the system?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights or experiences you&amp;#39;ve had in dealing with this issue. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y4qd4", "is_robot_indexable": true, "report_reasons": null, "author": "chickennuggiiiiissss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y4qd4/optimizing_azure_api_calls_for_larger_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y4qd4/optimizing_azure_api_calls_for_larger_data/", "subreddit_subscribers": 140277, "created_utc": 1700307702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI have practical questions about silver layer.\n\nHere is an example:\n\nSource type: SQL server database\nSources : 3 tables :\n-customer(id,customerBK,name)\n-contract(id,contractBK,start_date)\n-customer_contract (id_customer,id_contract)\n--&gt;3 bronze folders\n\nQuestion:\nHow to handle that case on silver layer ?\nI.e. What to do with the Join source table (customer_contract), especially with surrogate keys which are purely technicals (auto-increments)\n\nDo we have to Join bronze folders to get associated business keys ?? And exclude ids from silver layer tables?\nDo we have to handle data quality , Like Ghost records ? I.e if an entry does not match with the entity table ?\n3NF ??\n\nI am pretty confused with the silver layer \nWhat we Can do or not.\n\"Data quality\" , \"minimum transformations\" \nThats not clear at all....\n\nWhat would be your advises?\n\nThanks a lot", "author_fullname": "t2_ay88xr2vg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medaillon architecture - silver layer rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y2zf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700300361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI have practical questions about silver layer.&lt;/p&gt;\n\n&lt;p&gt;Here is an example:&lt;/p&gt;\n\n&lt;p&gt;Source type: SQL server database\nSources : 3 tables :\n-customer(id,customerBK,name)\n-contract(id,contractBK,start_date)\n-customer_contract (id_customer,id_contract)\n--&amp;gt;3 bronze folders&lt;/p&gt;\n\n&lt;p&gt;Question:\nHow to handle that case on silver layer ?\nI.e. What to do with the Join source table (customer_contract), especially with surrogate keys which are purely technicals (auto-increments)&lt;/p&gt;\n\n&lt;p&gt;Do we have to Join bronze folders to get associated business keys ?? And exclude ids from silver layer tables?\nDo we have to handle data quality , Like Ghost records ? I.e if an entry does not match with the entity table ?\n3NF ??&lt;/p&gt;\n\n&lt;p&gt;I am pretty confused with the silver layer \nWhat we Can do or not.\n&amp;quot;Data quality&amp;quot; , &amp;quot;minimum transformations&amp;quot; \nThats not clear at all....&lt;/p&gt;\n\n&lt;p&gt;What would be your advises?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y2zf7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Seesaw_2152", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y2zf7/medaillon_architecture_silver_layer_rules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y2zf7/medaillon_architecture_silver_layer_rules/", "subreddit_subscribers": 140277, "created_utc": 1700300361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\nI read a lot of bad things about DE at Meta as it's more like an analytics job where they are just writing SQL queries. Does anyone here has more idea or can elaborate on the role? Thank you", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is DE at Meta/Facebook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y0dyx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700289141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;I read a lot of bad things about DE at Meta as it&amp;#39;s more like an analytics job where they are just writing SQL queries. Does anyone here has more idea or can elaborate on the role? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17y0dyx", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17y0dyx/how_is_de_at_metafacebook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y0dyx/how_is_de_at_metafacebook/", "subreddit_subscribers": 140277, "created_utc": 1700289141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 years experience in data engineering and 2 years platform engineering \n\nData engineering: spark , hudi, airflow, aws S3\n\nPlatform engineering: k8s, istio, terraform, linux troubleshooting \n\nI am now planning to change my job but I am wondering which position should I continue, could some experienced ppl give some advices?", "author_fullname": "t2_87qlncns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Platform engineer, which should I choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xyqdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700300261.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700282928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 years experience in data engineering and 2 years platform engineering &lt;/p&gt;\n\n&lt;p&gt;Data engineering: spark , hudi, airflow, aws S3&lt;/p&gt;\n\n&lt;p&gt;Platform engineering: k8s, istio, terraform, linux troubleshooting &lt;/p&gt;\n\n&lt;p&gt;I am now planning to change my job but I am wondering which position should I continue, could some experienced ppl give some advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xyqdw", "is_robot_indexable": true, "report_reasons": null, "author": "f91og", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xyqdw/data_engineer_vs_platform_engineer_which_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xyqdw/data_engineer_vs_platform_engineer_which_should_i/", "subreddit_subscribers": 140277, "created_utc": 1700282928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi reddit,I'm trying to implement a lakehous with hive 4 and iceberg and i think i'm almost there but...When I create a table like:\n\n    CREATE TABLE ice (id INT, name STRING) STORED BY ICEBERG;\n\nAnd then insert some data\n\n    INSERT INTO ice VALUES (1, 'one');\n\nAnd then select\n\n    SELECT * FROM ice;\n\nI don't see the inserted record.  \n\n\nEDIT: I do see the parquet files on storage, and see the folder and file of the metadata, as if the table was created as location\\_based\\_table, But documentation says that if no specific icber.catalog is set, it will use the defaul hive catalog.\n\nWhat am I missing?I suspect that is something related to the metastore, but can't find what...Thanks in advance, cheers.", "author_fullname": "t2_aytgj0xr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Created Hive tables STORED BY ICEBER; SELECT * returns empty", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xtb5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700266559.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700266293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi reddit,I&amp;#39;m trying to implement a lakehous with hive 4 and iceberg and i think i&amp;#39;m almost there but...When I create a table like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE TABLE ice (id INT, name STRING) STORED BY ICEBERG;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And then insert some data&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT INTO ice VALUES (1, &amp;#39;one&amp;#39;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And then select&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT * FROM ice;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I don&amp;#39;t see the inserted record.  &lt;/p&gt;\n\n&lt;p&gt;EDIT: I do see the parquet files on storage, and see the folder and file of the metadata, as if the table was created as location_based_table, But documentation says that if no specific icber.catalog is set, it will use the defaul hive catalog.&lt;/p&gt;\n\n&lt;p&gt;What am I missing?I suspect that is something related to the metastore, but can&amp;#39;t find what...Thanks in advance, cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xtb5i", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant-Adward", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xtb5i/created_hive_tables_stored_by_iceber_select/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xtb5i/created_hive_tables_stored_by_iceber_select/", "subreddit_subscribers": 140277, "created_utc": 1700266293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,  \nI'm interested in resource allocation for training deep learning models in clusters. Previously I have worked with Open source serverless frameworks such as OpenWhisk for other projects (Not on ML/DL). I'm looking for open source frameworks that manage resource allocation for deep learning models. I came across Ray while doing some searches. My goal is to modify some core parts of the framework and evaluate my ideas. Has anyone tried doing the same thing before? I welcome any suggestions since I haven't previously worked on this topic. \n\nThanks!", "author_fullname": "t2_5worb5ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Open Source Frameworks for Resource Allocation in Deep Learning Model Training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xqoo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700259325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;br/&gt;\nI&amp;#39;m interested in resource allocation for training deep learning models in clusters. Previously I have worked with Open source serverless frameworks such as OpenWhisk for other projects (Not on ML/DL). I&amp;#39;m looking for open source frameworks that manage resource allocation for deep learning models. I came across Ray while doing some searches. My goal is to modify some core parts of the framework and evaluate my ideas. Has anyone tried doing the same thing before? I welcome any suggestions since I haven&amp;#39;t previously worked on this topic. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xqoo0", "is_robot_indexable": true, "report_reasons": null, "author": "ahmadreza_hadi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xqoo0/seeking_advice_on_open_source_frameworks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xqoo0/seeking_advice_on_open_source_frameworks_for/", "subreddit_subscribers": 140277, "created_utc": 1700259325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With a medallion architecture, what would be the best practice to deal with tables that have the same subject?\n\nIf I have for example sales orders or customer information from the same business, but they come from different source systems, and these tables dosent have the same schema.\n\nShould I keep the 3NF in the silver layer and only combine these informations in my final gold table? Or the silver layer would be the place to create these final models by subject with business logic?  \nI come from a DW/BI background, but these layers still confuse me", "author_fullname": "t2_2t4hdsut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with different sources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xoo22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700254091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With a medallion architecture, what would be the best practice to deal with tables that have the same subject?&lt;/p&gt;\n\n&lt;p&gt;If I have for example sales orders or customer information from the same business, but they come from different source systems, and these tables dosent have the same schema.&lt;/p&gt;\n\n&lt;p&gt;Should I keep the 3NF in the silver layer and only combine these informations in my final gold table? Or the silver layer would be the place to create these final models by subject with business logic?&lt;br/&gt;\nI come from a DW/BI background, but these layers still confuse me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xoo22", "is_robot_indexable": true, "report_reasons": null, "author": "ltofanelli", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xoo22/how_to_deal_with_different_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xoo22/how_to_deal_with_different_sources/", "subreddit_subscribers": 140277, "created_utc": 1700254091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nWe have data coming from rest apis that need to get loaded in Snowflake. We are keeping costs to a minimum but have potentially a lot of requests coming through this so needs to scale.\n\nI was thinking ELT\n\nAPI -&gt; blob using azure functions then to snowflake and use dbt in snowflake.\n\nAny other ideas? I also looked at some previous posts and they said something similar but mentioned \u201cairflow to manage it all\u201d. Where would airflow fit into this?\n\nShould we use a tool instead of azure functions", "author_fullname": "t2_o1vjl2jil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT API to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xni9x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700251871.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700250914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;We have data coming from rest apis that need to get loaded in Snowflake. We are keeping costs to a minimum but have potentially a lot of requests coming through this so needs to scale.&lt;/p&gt;\n\n&lt;p&gt;I was thinking ELT&lt;/p&gt;\n\n&lt;p&gt;API -&amp;gt; blob using azure functions then to snowflake and use dbt in snowflake.&lt;/p&gt;\n\n&lt;p&gt;Any other ideas? I also looked at some previous posts and they said something similar but mentioned \u201cairflow to manage it all\u201d. Where would airflow fit into this?&lt;/p&gt;\n\n&lt;p&gt;Should we use a tool instead of azure functions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xni9x", "is_robot_indexable": true, "report_reasons": null, "author": "Distinct-Mention4792", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xni9x/elt_api_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xni9x/elt_api_to_snowflake/", "subreddit_subscribers": 140277, "created_utc": 1700250914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nWe have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor's (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor's AWS SQL instance over the VPN using a linked service. \n\nWe are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.\n\nOne suggestion we've received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. \n\nThis is less than ideal because adding another VM adds cost. \n\nCan we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?", "author_fullname": "t2_66hzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble connecting Modmed with Azure. Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xldc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor&amp;#39;s (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor&amp;#39;s AWS SQL instance over the VPN using a linked service. &lt;/p&gt;\n\n&lt;p&gt;We are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.&lt;/p&gt;\n\n&lt;p&gt;One suggestion we&amp;#39;ve received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. &lt;/p&gt;\n\n&lt;p&gt;This is less than ideal because adding another VM adds cost. &lt;/p&gt;\n\n&lt;p&gt;Can we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xldc1", "is_robot_indexable": true, "report_reasons": null, "author": "traft00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "subreddit_subscribers": 140277, "created_utc": 1700245193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Full disclosure: A contributor to the project here.\n\nI have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.\n\nI'm excited to share that the project is now live and I wanted to thank the project's early contributors. You can learn more by visiting the repo: [https://github.com/onetable-io/onetable](https://github.com/onetable-io/onetable)\n\nI'll keep an eye out on this subreddit and the post to answer any questions you may have.", "author_fullname": "t2_o3fw52ash", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OneTable is now live | Table format interoperability is not a dream anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xjs0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700240920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Full disclosure: A contributor to the project here.&lt;/p&gt;\n\n&lt;p&gt;I have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share that the project is now live and I wanted to thank the project&amp;#39;s early contributors. You can learn more by visiting the repo: &lt;a href=\"https://github.com/onetable-io/onetable\"&gt;https://github.com/onetable-io/onetable&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll keep an eye out on this subreddit and the post to answer any questions you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?auto=webp&amp;s=ca8ca18a4768b89f950527c931e5eaa3395cb2cc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3beadbc1b340de0a682d509c2a7cd53cfeff27f7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=adc48402b2652b6a0c110b20f67388030e9ae6b3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ae1ff18f1579e9d9eb9633cfae7e8ff78557eca", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=78f6366155828de3caab54c68df36f92693b047b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=955fac3869882d57292ae00f401b8e3379d5ae4a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cddba46e668b1955c4ec65830b7cf6ea09642eb7", "width": 1080, "height": 540}], "variants": {}, "id": "ZF0kwxmuX9UVT7upWOjDojrXLQQTrxSIm-50k-mSUxg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17xjs0q", "is_robot_indexable": true, "report_reasons": null, "author": "DataRepeatRinse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "subreddit_subscribers": 140277, "created_utc": 1700240920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?", "author_fullname": "t2_6fccledv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt incremental models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xhqj2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700235385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to incorporate dbt and was reading on incremental models. In my case, the past data of the source frequently gets changed without notification. How to ensure that my downstream models have the correct data? Is manual backfilling the only option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xhqj2", "is_robot_indexable": true, "report_reasons": null, "author": "deadlypiranha", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xhqj2/dbt_incremental_models/", "subreddit_subscribers": 140277, "created_utc": 1700235385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Reddit Family, I have a request\u2026\n\nWe\u2019ve just launched Lassoo Headless Analytics to the public.\n\n[Lassoo](https://lassoo.io?ref=reddit_de) Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. \n\nWe\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.\n\nWe\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.\n\nIf you\u2019re interested, please DM me.\n\nP.S. It would be great if you could please share this with any colleagues you think could benefit from this offer", "author_fullname": "t2_m53gg9re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Headless Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xft3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700229984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Reddit Family, I have a request\u2026&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve just launched Lassoo Headless Analytics to the public.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lassoo.io?ref=reddit_de\"&gt;Lassoo&lt;/a&gt; Headless Analytics collects, organizes, enriches, and reconciles first-party behavioral customer data from your website or SaaS app. Then, it lets you report or activate your data for Customer360, advanced analytics, and AI/ML use cases through direct PostgreSQL access via the tools you already use. &lt;/p&gt;\n\n&lt;p&gt;We\u2019re offering 3-4 companies an extended trial to kick the tires of our technology. The goal is to work closely with you - providing white glove service - to generate a compelling success story by helping you put your customer data to use.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ll help you get the most value from your data by guiding you through analysis and activation, leveraging our experience with brands ranging from Volkswagen to growing e-commerce shops.&lt;/p&gt;\n\n&lt;p&gt;If you\u2019re interested, please DM me.&lt;/p&gt;\n\n&lt;p&gt;P.S. It would be great if you could please share this with any colleagues you think could benefit from this offer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xft3b", "is_robot_indexable": true, "report_reasons": null, "author": "Euphoric-Let-8960", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xft3b/headless_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xft3b/headless_analytics/", "subreddit_subscribers": 140277, "created_utc": 1700229984.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}