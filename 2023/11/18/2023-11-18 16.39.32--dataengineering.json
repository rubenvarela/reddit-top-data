{"kind": "Listing", "data": {"after": "t3_17xtb5i", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I came from a company where the data engineer I was working across told me that automation was \u201cnot possible.\u201d \n\nI am of the opinion that automation, at least partial automation, is a possibility in most data warehousing and ETL processes.\n\nCould someone tell me when automation isn\u2019t possible?", "author_fullname": "t2_6mus1in0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When is Automation \u201cNot Possible?\u201d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xuptt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700270307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came from a company where the data engineer I was working across told me that automation was \u201cnot possible.\u201d &lt;/p&gt;\n\n&lt;p&gt;I am of the opinion that automation, at least partial automation, is a possibility in most data warehousing and ETL processes.&lt;/p&gt;\n\n&lt;p&gt;Could someone tell me when automation isn\u2019t possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xuptt", "is_robot_indexable": true, "report_reasons": null, "author": "scarlet_poppies", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xuptt/when_is_automation_not_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xuptt/when_is_automation_not_possible/", "subreddit_subscribers": 140316, "created_utc": 1700270307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there,\n\nI've got a 20Go csv file I need to work with.\n\nInitially I tried to load with DuckDB / DBeaver but it took almost 4 hours* to convert to an SQL table.\nAnd even the most basic queries are way too slow (several minutes)\n\nDo you have any advice on how to tame this file ?\nOpen to SQL or Python, not good enough with Java, Spark or Polar.\n\nThanks!\n\n*My computer is an i9 12th gen with 32G DDR5. Not an old timer (yet)", "author_fullname": "t2_bqy2s6be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20go csv file to SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xrrv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700262127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a 20Go csv file I need to work with.&lt;/p&gt;\n\n&lt;p&gt;Initially I tried to load with DuckDB / DBeaver but it took almost 4 hours* to convert to an SQL table.\nAnd even the most basic queries are way too slow (several minutes)&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice on how to tame this file ?\nOpen to SQL or Python, not good enough with Java, Spark or Polar.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;*My computer is an i9 12th gen with 32G DDR5. Not an old timer (yet)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xrrv5", "is_robot_indexable": true, "report_reasons": null, "author": "reddit_ski", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xrrv5/20go_csv_file_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xrrv5/20go_csv_file_to_sql/", "subreddit_subscribers": 140316, "created_utc": 1700262127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone,\n\nI read a lot of bad things about DE at Meta as it's more like an analytics job where they are just writing SQL queries. Does anyone here has more idea or can elaborate on the role? Thank you", "author_fullname": "t2_3tsn4xyv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is DE at Meta/Facebook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y0dyx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700289141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone,&lt;/p&gt;\n\n&lt;p&gt;I read a lot of bad things about DE at Meta as it&amp;#39;s more like an analytics job where they are just writing SQL queries. Does anyone here has more idea or can elaborate on the role? Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17y0dyx", "is_robot_indexable": true, "report_reasons": null, "author": "brownstrom", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17y0dyx/how_is_de_at_metafacebook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y0dyx/how_is_de_at_metafacebook/", "subreddit_subscribers": 140316, "created_utc": 1700289141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?", "author_fullname": "t2_i7s0h23q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake pay-as-you-go pricing for the business critical edition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xlkql", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use Snowflake with pay-as-you-go pricing for the business critical edition? Is anyone doing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xlkql", "is_robot_indexable": true, "report_reasons": null, "author": "LA_throwaway_one", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xlkql/snowflake_payasyougo_pricing_for_the_business/", "subreddit_subscribers": 140316, "created_utc": 1700245736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was recently moved into a role for \"Data Engineering on Azure\" and I feel like it's just some sort of testing.\n\nA separate external team has created a framework using Azure Data Factory, Azure Databricks, Azure Synapse etc.\n\nOur task is to migrate on-prem onto this framework.\n\nWe push custom scripts into an Azure DevOps and run the pipeline. It executes SQL scripts (SQL create table same as existing, custom stored procedures to transform same as existing), some json files which has an \"ID\" and some paths.\n\nThis creates empty tables.\n\nAnother team places parquet files on an ADLS gen2 location as the path mention in json.\n\nWe use Apache Postman or another scheduling tool where we enter the ID and date and that triggers the ADF run to populate empty table. Same for all the tasks.\n\nIs this any part of data engineering?\nAnd is it really possible for me to move into data engineering with this experience and be a good data engineer?\nI am building my own proof of concepts to learn a thing or two, but seems like a far cry.\n\nThank you for your responses in advance.", "author_fullname": "t2_9q485fxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moved internally to Data Engineering role. But doesn't feel like Data Engineering at all. Is it really one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y6vz8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700315450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was recently moved into a role for &amp;quot;Data Engineering on Azure&amp;quot; and I feel like it&amp;#39;s just some sort of testing.&lt;/p&gt;\n\n&lt;p&gt;A separate external team has created a framework using Azure Data Factory, Azure Databricks, Azure Synapse etc.&lt;/p&gt;\n\n&lt;p&gt;Our task is to migrate on-prem onto this framework.&lt;/p&gt;\n\n&lt;p&gt;We push custom scripts into an Azure DevOps and run the pipeline. It executes SQL scripts (SQL create table same as existing, custom stored procedures to transform same as existing), some json files which has an &amp;quot;ID&amp;quot; and some paths.&lt;/p&gt;\n\n&lt;p&gt;This creates empty tables.&lt;/p&gt;\n\n&lt;p&gt;Another team places parquet files on an ADLS gen2 location as the path mention in json.&lt;/p&gt;\n\n&lt;p&gt;We use Apache Postman or another scheduling tool where we enter the ID and date and that triggers the ADF run to populate empty table. Same for all the tasks.&lt;/p&gt;\n\n&lt;p&gt;Is this any part of data engineering?\nAnd is it really possible for me to move into data engineering with this experience and be a good data engineer?\nI am building my own proof of concepts to learn a thing or two, but seems like a far cry.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your responses in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17y6vz8", "is_robot_indexable": true, "report_reasons": null, "author": "Responsible_Ruin2310", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y6vz8/moved_internally_to_data_engineering_role_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y6vz8/moved_internally_to_data_engineering_role_but/", "subreddit_subscribers": 140316, "created_utc": 1700315450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I (45M) have been working on customer dashboards for my most recent job.  Its boring AF, you can only make so many Tableau dashboards before wanting to punch yourself in the face.  I can continue to do this, make decent $ at it, but man, work has to have something more fun than just the $ that I make.  \n\n\nI want to get back into data engineering - but I am not sure which types of jobs I should apply to, I don't have luck getting interviews.  \n\n\nMy background is in RDBMS data warehousing, and building data warehouse applications (series of stored procedures that accomplished a very complicated and data intensive accounting process with slowly changing rules).  Creating logical and physical data models is something I am good at.  I understand, write, and tune SQL quite well, and have many years job experience doing these tasks.  I ran and operated things on Teradata, and can tune their sharded MPP pretty well.  All of these were orchestrated in UC4, I haven't used tools like Airflow, but aren't they the same?  \n\n\nI was a user of Impala, but never engineered anything on Hadoop - only consumed data there.  \n\n\nI've built a Snowflake Data Warehouse on top of AWS S3, and was minimally involved in creating data pipelines to those AWS buckets (I built firehose jobs that partitioned our data).  Parsing JSON events and creating a real-time ETL - I have done this stuff pretty well.  \n\n\nWhere I feel I lack, and interviewers know it:\n\nI have NO on the job experience with Python, Spark, Databricks, Azure.  People look for my experience with SQL Server, and I'm like... Isn't it the same as these others?  I've not configured RedShift before, I've only consumed data there, so no experience standing up files as a datalake via Redshift - I've only ingested files into Snowflake (not even used files as external tables).  \n\n\nI have built fairly complicated for-fun Python projects at home, but otherwise I have NO on the job experience there.  I downloaded a local instance of Spark, and did some stupid stuff with it (weeee!!!!), but I've never seen jobs in production on Spark.  \n\n\nWhat types of jobs should I be applying for?  How do I go about get practical (preferably on the job) experience in the things I am lacking?  I feel my skills are atrophied, no longer relevant to jobs people are hiring for, and am struggling figuring out how to bridge the gap to these newer technologies.", "author_fullname": "t2_ncssul4iz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kind of DE job to apply to", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xt48f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700265772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (45M) have been working on customer dashboards for my most recent job.  Its boring AF, you can only make so many Tableau dashboards before wanting to punch yourself in the face.  I can continue to do this, make decent $ at it, but man, work has to have something more fun than just the $ that I make.  &lt;/p&gt;\n\n&lt;p&gt;I want to get back into data engineering - but I am not sure which types of jobs I should apply to, I don&amp;#39;t have luck getting interviews.  &lt;/p&gt;\n\n&lt;p&gt;My background is in RDBMS data warehousing, and building data warehouse applications (series of stored procedures that accomplished a very complicated and data intensive accounting process with slowly changing rules).  Creating logical and physical data models is something I am good at.  I understand, write, and tune SQL quite well, and have many years job experience doing these tasks.  I ran and operated things on Teradata, and can tune their sharded MPP pretty well.  All of these were orchestrated in UC4, I haven&amp;#39;t used tools like Airflow, but aren&amp;#39;t they the same?  &lt;/p&gt;\n\n&lt;p&gt;I was a user of Impala, but never engineered anything on Hadoop - only consumed data there.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a Snowflake Data Warehouse on top of AWS S3, and was minimally involved in creating data pipelines to those AWS buckets (I built firehose jobs that partitioned our data).  Parsing JSON events and creating a real-time ETL - I have done this stuff pretty well.  &lt;/p&gt;\n\n&lt;p&gt;Where I feel I lack, and interviewers know it:&lt;/p&gt;\n\n&lt;p&gt;I have NO on the job experience with Python, Spark, Databricks, Azure.  People look for my experience with SQL Server, and I&amp;#39;m like... Isn&amp;#39;t it the same as these others?  I&amp;#39;ve not configured RedShift before, I&amp;#39;ve only consumed data there, so no experience standing up files as a datalake via Redshift - I&amp;#39;ve only ingested files into Snowflake (not even used files as external tables).  &lt;/p&gt;\n\n&lt;p&gt;I have built fairly complicated for-fun Python projects at home, but otherwise I have NO on the job experience there.  I downloaded a local instance of Spark, and did some stupid stuff with it (weeee!!!!), but I&amp;#39;ve never seen jobs in production on Spark.  &lt;/p&gt;\n\n&lt;p&gt;What types of jobs should I be applying for?  How do I go about get practical (preferably on the job) experience in the things I am lacking?  I feel my skills are atrophied, no longer relevant to jobs people are hiring for, and am struggling figuring out how to bridge the gap to these newer technologies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xt48f", "is_robot_indexable": true, "report_reasons": null, "author": "IllustriousCorgi9877", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xt48f/kind_of_de_job_to_apply_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xt48f/kind_of_de_job_to_apply_to/", "subreddit_subscribers": 140316, "created_utc": 1700265772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some people recommend zoomcamp course and i saw couple of posts say good words on it \n\n\nI feel it's good one because it's free as i can't afford certs and you make a project at the end so what stuff i have to know before studying the course\n\n\nI know python", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you recommend zoomcamp course ? ( Iam a beginner)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y04k5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700288121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some people recommend zoomcamp course and i saw couple of posts say good words on it &lt;/p&gt;\n\n&lt;p&gt;I feel it&amp;#39;s good one because it&amp;#39;s free as i can&amp;#39;t afford certs and you make a project at the end so what stuff i have to know before studying the course&lt;/p&gt;\n\n&lt;p&gt;I know python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17y04k5", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y04k5/would_you_recommend_zoomcamp_course_iam_a_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y04k5/would_you_recommend_zoomcamp_course_iam_a_beginner/", "subreddit_subscribers": 140316, "created_utc": 1700288121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow data engineers,\n\nI am currently working on a project where I\u2019m ingesting data from two different sources, each with its own API. The data sources have 20 and 10 tables, respectively. I am facing a few challenges and would appreciate your insights on the following aspects:\n\n1 Automating Table Creation in PostgreSQL:\n\nMy approach so far has been to use Python scripts to generate SQL queries for table creation, based on the keys from JSON responses provided by the APIs. These tables are then manually created in an initially empty PostgreSQL database. Is this a standard approach, or are there more efficient methods to automate this process?\n\n2 Data Import Methodology:\n\nAfter creating the tables, I am converting the JSON response dictionaries into CSV files and then using PostgreSQL\u2019s COPY FROM command to import the data into the corresponding tables. Is this a recommended practice, or are there better alternatives for importing JSON data directly into PostgreSQL?\n\n3 Handling Schema Changes:\n\nA concern I have for future operations is how to efficiently manage potential schema changes, such as alterations in column names or the order of keys in JSON responses, which could impact the CSV file structure and consequently the database import process. What strategies or best practices can be employed to handle such dynamic schema changes? \n\n&amp;#x200B;\n\n4 Big data vs small data \n\nWhat changes in the process if for example the data is 1GB vs 10GB vs 100GB per source? Because right now I am making multiple calls to 1 API to not overload the memory. I am thus appending the data onto the csv file in batches. Or is there another more favourable way to load the data?\n\n&amp;#x200B;\n\nAny advice or experiences you could share on these topics would be greatly appreciated, as I\u2019m aiming to optimize the process and ensure long-term maintainability.\n\nThank you in advance for your insights!\n\n&amp;#x200B;\n\nEDIT: sample data below\n\n    [{'name': 'Lisa Woodward',\n      'address': '9156 Brittany Creek\\nNew Steven, MP 38897',\n      'email': 'xsoto@example.com'},\n     {'name': 'Amanda Rogers',\n      'address': '9252 Krista Centers\\nWest Nicole, VT 46708',\n      'email': 'ymitchell@example.com'},\n     {'name': 'Lisa Smith',\n      'address': '1820 Chandler Gateway\\nLake Tamaratown, MS 30482',\n      'email': 'mthomas@example.com'},\n     {'name': 'Eric Baker',\n      'address': 'Unit 3545 Box 9648\\nDPO AP 47454',\n      'email': 'timothy75@example.com'},\n     {'name': 'Olivia Hayes',\n      'address': 'USS Moon\\nFPO AE 96035',\n      'email': 'dixondonald@example.org'}\n    ]\n\n&amp;#x200B;", "author_fullname": "t2_ebebn3prf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on data ingestion into postgresql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xv74t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700315349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700271684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow data engineers,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on a project where I\u2019m ingesting data from two different sources, each with its own API. The data sources have 20 and 10 tables, respectively. I am facing a few challenges and would appreciate your insights on the following aspects:&lt;/p&gt;\n\n&lt;p&gt;1 Automating Table Creation in PostgreSQL:&lt;/p&gt;\n\n&lt;p&gt;My approach so far has been to use Python scripts to generate SQL queries for table creation, based on the keys from JSON responses provided by the APIs. These tables are then manually created in an initially empty PostgreSQL database. Is this a standard approach, or are there more efficient methods to automate this process?&lt;/p&gt;\n\n&lt;p&gt;2 Data Import Methodology:&lt;/p&gt;\n\n&lt;p&gt;After creating the tables, I am converting the JSON response dictionaries into CSV files and then using PostgreSQL\u2019s COPY FROM command to import the data into the corresponding tables. Is this a recommended practice, or are there better alternatives for importing JSON data directly into PostgreSQL?&lt;/p&gt;\n\n&lt;p&gt;3 Handling Schema Changes:&lt;/p&gt;\n\n&lt;p&gt;A concern I have for future operations is how to efficiently manage potential schema changes, such as alterations in column names or the order of keys in JSON responses, which could impact the CSV file structure and consequently the database import process. What strategies or best practices can be employed to handle such dynamic schema changes? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;4 Big data vs small data &lt;/p&gt;\n\n&lt;p&gt;What changes in the process if for example the data is 1GB vs 10GB vs 100GB per source? Because right now I am making multiple calls to 1 API to not overload the memory. I am thus appending the data onto the csv file in batches. Or is there another more favourable way to load the data?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any advice or experiences you could share on these topics would be greatly appreciated, as I\u2019m aiming to optimize the process and ensure long-term maintainability.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your insights!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: sample data below&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[{&amp;#39;name&amp;#39;: &amp;#39;Lisa Woodward&amp;#39;,\n  &amp;#39;address&amp;#39;: &amp;#39;9156 Brittany Creek\\nNew Steven, MP 38897&amp;#39;,\n  &amp;#39;email&amp;#39;: &amp;#39;xsoto@example.com&amp;#39;},\n {&amp;#39;name&amp;#39;: &amp;#39;Amanda Rogers&amp;#39;,\n  &amp;#39;address&amp;#39;: &amp;#39;9252 Krista Centers\\nWest Nicole, VT 46708&amp;#39;,\n  &amp;#39;email&amp;#39;: &amp;#39;ymitchell@example.com&amp;#39;},\n {&amp;#39;name&amp;#39;: &amp;#39;Lisa Smith&amp;#39;,\n  &amp;#39;address&amp;#39;: &amp;#39;1820 Chandler Gateway\\nLake Tamaratown, MS 30482&amp;#39;,\n  &amp;#39;email&amp;#39;: &amp;#39;mthomas@example.com&amp;#39;},\n {&amp;#39;name&amp;#39;: &amp;#39;Eric Baker&amp;#39;,\n  &amp;#39;address&amp;#39;: &amp;#39;Unit 3545 Box 9648\\nDPO AP 47454&amp;#39;,\n  &amp;#39;email&amp;#39;: &amp;#39;timothy75@example.com&amp;#39;},\n {&amp;#39;name&amp;#39;: &amp;#39;Olivia Hayes&amp;#39;,\n  &amp;#39;address&amp;#39;: &amp;#39;USS Moon\\nFPO AE 96035&amp;#39;,\n  &amp;#39;email&amp;#39;: &amp;#39;dixondonald@example.org&amp;#39;}\n]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xv74t", "is_robot_indexable": true, "report_reasons": null, "author": "mtn331", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xv74t/seeking_advice_on_data_ingestion_into_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xv74t/seeking_advice_on_data_ingestion_into_postgresql/", "subreddit_subscribers": 140316, "created_utc": 1700271684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, i'm a web dev (2 years of experience) who got a interest in the Data world. I want to solve some data problems usign my programming skills. Example:\n\n\"A X company has 5 apis that bring some huge data in JSON. The salles by customer data is spread across those 5 apis. Your job would be to organize and filter it (using arrays and stuff) in this and that manner.\"\n\nNow, i don't know if this fits here, but i think it kinda does. I'm having a hard time trying to find exercises like that, but i found the closer to be this one:\n\n[https://nyu-cds.github.io/courses/exercises/Basic-python-1/](https://nyu-cds.github.io/courses/exercises/Basic-python-1/)\n\nIs really in the direction that i want it. If anyone has more online exercises like that for me, i would be grateful.\n\nObs: I just want to pratice some data stuff with programming. Looking to learn something. \n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_ul5cbil9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data exercises for a web dev", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y4wmi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700308655.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700308410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, i&amp;#39;m a web dev (2 years of experience) who got a interest in the Data world. I want to solve some data problems usign my programming skills. Example:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;A X company has 5 apis that bring some huge data in JSON. The salles by customer data is spread across those 5 apis. Your job would be to organize and filter it (using arrays and stuff) in this and that manner.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Now, i don&amp;#39;t know if this fits here, but i think it kinda does. I&amp;#39;m having a hard time trying to find exercises like that, but i found the closer to be this one:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nyu-cds.github.io/courses/exercises/Basic-python-1/\"&gt;https://nyu-cds.github.io/courses/exercises/Basic-python-1/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is really in the direction that i want it. If anyone has more online exercises like that for me, i would be grateful.&lt;/p&gt;\n\n&lt;p&gt;Obs: I just want to pratice some data stuff with programming. Looking to learn something. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y4wmi", "is_robot_indexable": true, "report_reasons": null, "author": "Usual-Dragonfly3117", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y4wmi/data_exercises_for_a_web_dev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y4wmi/data_exercises_for_a_web_dev/", "subreddit_subscribers": 140316, "created_utc": 1700308410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I'm part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn't a part of my daily tasks, I do possess some familiarity with writing SQL queries.\n\nOur team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn't just in running numbers and building models and tools - I came in with a strategic education and strategic experience.\n\nI strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.\n\nMy questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don't want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.\n\nI looked into Coursera for BigQuery courses, there are 100s of courses. I don't know what I should pick.\n\nPlease drop your thoughts/suggestions.", "author_fullname": "t2_p2qjz042", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning to 'Analytics Engineering' by blending my existing Analytics and acquiring Data Engineering skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xl0r8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700244249.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I&amp;#39;m part of the SEM Team at a large Fortune company, where I work as a marketing analyst. My primary tools are MS Excel and Power BI. While SQL isn&amp;#39;t a part of my daily tasks, I do possess some familiarity with writing SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our team is transitioning to Bigquery in 2024 with the help of the IT team. I want to use this opportunity to make a move to Data Engineering. being in analytics helped me solidify the business side of things. I came from marketing anyway, so my expertise wasn&amp;#39;t just in running numbers and building models and tools - I came in with a strategic education and strategic experience.&lt;/p&gt;\n\n&lt;p&gt;I strongly believe gaining the D.E. experience while still being heavily involved in Analytics gives me the edge and makes me indispensable for my team.&lt;/p&gt;\n\n&lt;p&gt;My questions: Given my background and future requirements, what should I consider in a BigQuery course before paying for it? I just don&amp;#39;t want to learn the querying/SQL side of big query rather I want to be actively involved in the data engineering side of Big Query so I can liaison between my team and IT.&lt;/p&gt;\n\n&lt;p&gt;I looked into Coursera for BigQuery courses, there are 100s of courses. I don&amp;#39;t know what I should pick.&lt;/p&gt;\n\n&lt;p&gt;Please drop your thoughts/suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xl0r8", "is_robot_indexable": true, "report_reasons": null, "author": "NumbTheFather", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xl0r8/transitioning_to_analytics_engineering_by/", "subreddit_subscribers": 140316, "created_utc": 1700244249.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am not a data engineer. But I am doing the needful, and setting up a professional environment is beyond me. I have more than enough experience doing everything really badly - building APIs, my ML is actually pretty decent, my MLOPs is.... ok, that's about it. And I have no real experience. I'm far more comfortable in my local environment, and I struggle when I move to using docker and the cloud. \n\n**My Problem**\n\nCurrently, I am the entire DS department for an app (for sake of example, I compile a list of the top luxury clothes brands, and then gather reviews of the brand from 6 review sites). I run everything locally, and I have cleaned it into 3 layers, and 1 DB:\n\n- Layer 1: Sourcing scrape - extract data from an esoteric tracker I like, send to postgres. This generates a list of luxury brands for me. \n- Layer 2: Review sites link sourcing: Based on results of layer 1, the script finds the reference to that brand across 6 different review sites. Each review site may or may not have a link for the reference brand, but every brand has at least one reference link. Another postgres table. \n- Layer 3: Review data: I run scripts for each review site of that brand, and push data to a table.\n\nI need to move this all to the cloud and get it running on a chron job, so I can just grab the data for prediction and other modeling. \n\nWe don't have that much data, \n\n**My Plan**\n\n- Data, scripts go into s3 bucket\n- EC2 runs scripts because they are long\n- I use lambda to manage ec2s (?? magic -&gt; profit?)\n- push data to redis\n\n**Please offer feedback**\n\nQ1: Is what i'm doing making sense? Should I do something different?\n\nQ2: I see no need for warehousing or lakes. There's no rush to update live data, and i don't have a lot of data. SQL queries should be just fine?", "author_fullname": "t2_aefxxhc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design Advice Requested: First time building corporate project (DS pipeline) ground up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y69pb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700313374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am not a data engineer. But I am doing the needful, and setting up a professional environment is beyond me. I have more than enough experience doing everything really badly - building APIs, my ML is actually pretty decent, my MLOPs is.... ok, that&amp;#39;s about it. And I have no real experience. I&amp;#39;m far more comfortable in my local environment, and I struggle when I move to using docker and the cloud. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Problem&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently, I am the entire DS department for an app (for sake of example, I compile a list of the top luxury clothes brands, and then gather reviews of the brand from 6 review sites). I run everything locally, and I have cleaned it into 3 layers, and 1 DB:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Layer 1: Sourcing scrape - extract data from an esoteric tracker I like, send to postgres. This generates a list of luxury brands for me. &lt;/li&gt;\n&lt;li&gt;Layer 2: Review sites link sourcing: Based on results of layer 1, the script finds the reference to that brand across 6 different review sites. Each review site may or may not have a link for the reference brand, but every brand has at least one reference link. Another postgres table. &lt;/li&gt;\n&lt;li&gt;Layer 3: Review data: I run scripts for each review site of that brand, and push data to a table.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I need to move this all to the cloud and get it running on a chron job, so I can just grab the data for prediction and other modeling. &lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t have that much data, &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My Plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data, scripts go into s3 bucket&lt;/li&gt;\n&lt;li&gt;EC2 runs scripts because they are long&lt;/li&gt;\n&lt;li&gt;I use lambda to manage ec2s (?? magic -&amp;gt; profit?)&lt;/li&gt;\n&lt;li&gt;push data to redis&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Please offer feedback&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Q1: Is what i&amp;#39;m doing making sense? Should I do something different?&lt;/p&gt;\n\n&lt;p&gt;Q2: I see no need for warehousing or lakes. There&amp;#39;s no rush to update live data, and i don&amp;#39;t have a lot of data. SQL queries should be just fine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y69pb", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayrandomvowel", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y69pb/design_advice_requested_first_time_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y69pb/design_advice_requested_first_time_building/", "subreddit_subscribers": 140316, "created_utc": 1700313374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 years experience in data engineering and 2 years platform engineering \n\nData engineering: spark , hudi, airflow, aws S3\n\nPlatform engineering: k8s, istio, terraform, linux troubleshooting \n\nI am now planning to change my job but I am wondering which position should I continue, could some experienced ppl give some advices?", "author_fullname": "t2_87qlncns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Platform engineer, which should I choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xyqdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700300261.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700282928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 years experience in data engineering and 2 years platform engineering &lt;/p&gt;\n\n&lt;p&gt;Data engineering: spark , hudi, airflow, aws S3&lt;/p&gt;\n\n&lt;p&gt;Platform engineering: k8s, istio, terraform, linux troubleshooting &lt;/p&gt;\n\n&lt;p&gt;I am now planning to change my job but I am wondering which position should I continue, could some experienced ppl give some advices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xyqdw", "is_robot_indexable": true, "report_reasons": null, "author": "f91og", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xyqdw/data_engineer_vs_platform_engineer_which_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xyqdw/data_engineer_vs_platform_engineer_which_should_i/", "subreddit_subscribers": 140316, "created_utc": 1700282928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to use dbt Cloud with Azure DevOps GIT without the enterprise license of dbt Cloud somehow? \n\nIt would be much easier for us to have dbt Cloud and all our Azure resources in Azure DevOps GIT and pipelines. I really don't want to be forced to use Github for dbt Cloud and have two GIT repos. But it's a tiny project and it doesn't justify an expensive dbt Cloud enterprise account.", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud + Azure DevOps GIT without enterprise license?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xo1w2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700252384.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to use dbt Cloud with Azure DevOps GIT without the enterprise license of dbt Cloud somehow? &lt;/p&gt;\n\n&lt;p&gt;It would be much easier for us to have dbt Cloud and all our Azure resources in Azure DevOps GIT and pipelines. I really don&amp;#39;t want to be forced to use Github for dbt Cloud and have two GIT repos. But it&amp;#39;s a tiny project and it doesn&amp;#39;t justify an expensive dbt Cloud enterprise account.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xo1w2", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xo1w2/dbt_cloud_azure_devops_git_without_enterprise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xo1w2/dbt_cloud_azure_devops_git_without_enterprise/", "subreddit_subscribers": 140316, "created_utc": 1700252384.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll try to keep this short.  I work at a Fortune 100 company with a \"senior engineer consultant\" title, although that doesn't really describe what I do.  I'm a business employee (not IT) and my day-to-day is:\n\n* Run validations to ensure IT data replication worked (Python &amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.\n* Pull tables from disparate data sources and compare to find differences (MS Power Query)\n* Tell IT what changes they need to make to the tables \n* Write adhoc SQL reports\n\nI spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.\n\n* 10 years strong SQL (CTE, multi joins, window/analytic functions)\n* 5 years moderate Python, Java, AppsScript\n* 5 years Tableau, Cognos\n* 5 years Talend (ETL)\n\nAm I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?", "author_fullname": "t2_1e1kvt8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I qualified to jump to a mid/senior data engineer position from a business data analyst role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xj3we", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700239638.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700239146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll try to keep this short.  I work at a Fortune 100 company with a &amp;quot;senior engineer consultant&amp;quot; title, although that doesn&amp;#39;t really describe what I do.  I&amp;#39;m a business employee (not IT) and my day-to-day is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Run validations to ensure IT data replication worked (Python &amp;amp; SQL) 100+ tables, ~30M daily records.  Hadoop Hive, Oracle, Teradata.&lt;/li&gt;\n&lt;li&gt;Pull tables from disparate data sources and compare to find differences (MS Power Query)&lt;/li&gt;\n&lt;li&gt;Tell IT what changes they need to make to the tables &lt;/li&gt;\n&lt;li&gt;Write adhoc SQL reports&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I spend most of my day in Toad writing SQL.  I make about $130k.  I want to move to an even more tech role (DE) but am concerned I lack qualifications.  My resume looks more like a business user and not a tech employee.  I hate Tableau and creating visualizations - I want to be more back end.  Writing new SQL is the best part of my job.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;10 years strong SQL (CTE, multi joins, window/analytic functions)&lt;/li&gt;\n&lt;li&gt;5 years moderate Python, Java, AppsScript&lt;/li&gt;\n&lt;li&gt;5 years Tableau, Cognos&lt;/li&gt;\n&lt;li&gt;5 years Talend (ETL)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Am I qualified to apply for a mid or senior data engineer position? I can tolerate a modest pay cut but going back to something like $70k would hurt.  What do I need to highlight on my resume to get noticed outside of SQL and Python? A coworker suggested I should be focusing on dbt. Certifications worth obtaining?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17xj3we", "is_robot_indexable": true, "report_reasons": null, "author": "IT-Banker", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xj3we/am_i_qualified_to_jump_to_a_midsenior_data/", "subreddit_subscribers": 140316, "created_utc": 1700239146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been data engineering adjacent for years, primarily working with Oracle and programming data conversions and analytics for a sought out fintech platform. I have a couple of employment opportunities right now. The one I\u2019m in now wants to extend my contract and when the bulk of the project work winds down hire me as a data engineer. I\u2019m getting hands on experience in databricks, python, ADF, Azure, etc. I currently have very strong pl/sql and sql skills. I\u2019m also good at optimizing db code.\n\nThere is a big 3 firm that wants to contract with me doing my old data programming job at 2x my previous pay rate (I\u2019m currently in the middle right now) but it\u2019s doing what I always done - oracle, 2nd Gen Core, limited. After that contract ends I should have enough money to take a few months off and focus on training, but something is telling me staying put leaning to tools I\u2019m learning now would be better for the long run.\n\nWhat is better, staying put getting hands on experience with cloud and data engineering tools or moving, having a big 3 on my resume, getting paid over $100 an hour, but staying in old school oracle land?", "author_fullname": "t2_4dl7aahw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s better Self Study or Hands on Exp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17y9i1u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700323200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been data engineering adjacent for years, primarily working with Oracle and programming data conversions and analytics for a sought out fintech platform. I have a couple of employment opportunities right now. The one I\u2019m in now wants to extend my contract and when the bulk of the project work winds down hire me as a data engineer. I\u2019m getting hands on experience in databricks, python, ADF, Azure, etc. I currently have very strong pl/sql and sql skills. I\u2019m also good at optimizing db code.&lt;/p&gt;\n\n&lt;p&gt;There is a big 3 firm that wants to contract with me doing my old data programming job at 2x my previous pay rate (I\u2019m currently in the middle right now) but it\u2019s doing what I always done - oracle, 2nd Gen Core, limited. After that contract ends I should have enough money to take a few months off and focus on training, but something is telling me staying put leaning to tools I\u2019m learning now would be better for the long run.&lt;/p&gt;\n\n&lt;p&gt;What is better, staying put getting hands on experience with cloud and data engineering tools or moving, having a big 3 on my resume, getting paid over $100 an hour, but staying in old school oracle land?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17y9i1u", "is_robot_indexable": true, "report_reasons": null, "author": "Zestyclose-Height-59", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y9i1u/whats_better_self_study_or_hands_on_exp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y9i1u/whats_better_self_study_or_hands_on_exp/", "subreddit_subscribers": 140316, "created_utc": 1700323200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! With around 1.5 years of experience in the data field, I'm on the journey to carve out a career in data engineering. My educational background lies in Physics engineering.\n\nI've been with a startup for 1.5 years as a JR data ops engineer, taking on various tasks from different roles from Data Analyst to Data Engineering. Despite starting with a low salary (first job), I received an 8.5% annual increase after a year, and after expressing dissatisfaction, a second raise brought it to a total of 16%. However, I still feel undervalued, despite the real high-performance scores I got in the performance review.\n\nRecently, I was offered an Analytics Engineer position at another startup with a 25% higher salary. This has left me torn, especially as I'm navigating my first job change and hesitant to leave my comfort zone.\n\n**PROS:**\n\n1. **Growth:**\n   1. The new company provides regular career and financial growth. Same as mine but the salary increases in mine are really low.\n2. **Ways of Working:**\n   1. A change in the workplace could expose me to different ways of working and tools.\n   2. In my current company, I am working far from the product so there are no super urgent moments, in the new company I will be working in a pipeline where data flows directly to the customer.\n   3. Both companies are using AI to get insights from data and then sell/present the data to the customers.\n\n**CONS:**\n\n1. **Technicality of the Position:**\n   1. Feedback from interviews suggests the Analytics Engineering role might be less challenging, but they assure a potential transition to data engineering in the future. I do not think Data Engineering and Analytics Engineering are super different at the technical level and task-wise. Any help in this point?\n\n1. **Remote/Hybrid:**\n   1. The new company mandates at least 1 or 2 days in the office, unlike my current flexible remote setup with office available to go whenever I want.\n2. **Office Culture:**\n   1. Sometimes I like to go to the office to disconnect and socialize in the new company, the office where I live is not very used and I think, I will be on my own more in this new company, so more loneliness\n\nI'm seeking advice on whether to take this opportunity, considering the potential growth, different ways of working, the drawbacks of the technical aspect, required office presence, and potential change in office culture. Any insights or experiences would be greatly appreciated!", "author_fullname": "t2_5ttln4ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Job Offer Dilemma - Should I Make the Move? (EU) (Analytics Engineering)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y67xj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700321910.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700313202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! With around 1.5 years of experience in the data field, I&amp;#39;m on the journey to carve out a career in data engineering. My educational background lies in Physics engineering.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been with a startup for 1.5 years as a JR data ops engineer, taking on various tasks from different roles from Data Analyst to Data Engineering. Despite starting with a low salary (first job), I received an 8.5% annual increase after a year, and after expressing dissatisfaction, a second raise brought it to a total of 16%. However, I still feel undervalued, despite the real high-performance scores I got in the performance review.&lt;/p&gt;\n\n&lt;p&gt;Recently, I was offered an Analytics Engineer position at another startup with a 25% higher salary. This has left me torn, especially as I&amp;#39;m navigating my first job change and hesitant to leave my comfort zone.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;PROS:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Growth:&lt;/strong&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The new company provides regular career and financial growth. Same as mine but the salary increases in mine are really low.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Ways of Working:&lt;/strong&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A change in the workplace could expose me to different ways of working and tools.&lt;/li&gt;\n&lt;li&gt;In my current company, I am working far from the product so there are no super urgent moments, in the new company I will be working in a pipeline where data flows directly to the customer.&lt;/li&gt;\n&lt;li&gt;Both companies are using AI to get insights from data and then sell/present the data to the customers.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;CONS:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Technicality of the Position:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Feedback from interviews suggests the Analytics Engineering role might be less challenging, but they assure a potential transition to data engineering in the future. I do not think Data Engineering and Analytics Engineering are super different at the technical level and task-wise. Any help in this point?&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Remote/Hybrid:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The new company mandates at least 1 or 2 days in the office, unlike my current flexible remote setup with office available to go whenever I want.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Office Culture:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Sometimes I like to go to the office to disconnect and socialize in the new company, the office where I live is not very used and I think, I will be on my own more in this new company, so more loneliness&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m seeking advice on whether to take this opportunity, considering the potential growth, different ways of working, the drawbacks of the technical aspect, required office presence, and potential change in office culture. Any insights or experiences would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17y67xj", "is_robot_indexable": true, "report_reasons": null, "author": "splashoui", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y67xj/seeking_advice_on_job_offer_dilemma_should_i_make/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y67xj/seeking_advice_on_job_offer_dilemma_should_i_make/", "subreddit_subscribers": 140316, "created_utc": 1700313202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI've been working on data driven visualization projects using realtime data on the topic of climate change or the environment (deforestation, sea levels, icecaps, biodiversity etc) but I can't seem to find actual realtime data sources.\n\nAll the sources I've managed to find (such as NASA, Bloomberg, Theworldcounts etc) all seem to use estimated realtime data based on formulas. I've seen a lot of media art projects that say they used realtime data but they rarely share the source for it.\n\nI was wondering if there are 'actual' realtime data sources that aren't exactly based on prediction formulas, especially regarding climate change?\n\nThe main reason I'm asking is I want to create realtime visuals/installations like the one in the attached link, but I don't want it to be a simple \"one interaction per second\" type of deal.\n\nThe one in the link shows artwork reacting in irregular patterns according to the 'realtime' data, instead of regular interactions per second.\n\n[https://www.youtube.com/watch?v=GCXGGg3DlYw](https://www.youtube.com/watch?v=GCXGGg3DlYw)\n\n\\+ Actually I think I may be mistaken of the concept of 'realtime'. I'm sure topics such as 'weather' or 'currency' can be managed and visualized realtime but when it comes to the topic of realtime I'm not sure if such data can be measured in realtime seconds.\n\n(I'm a complete newbe when it comes to data engineering)", "author_fullname": "t2_gcv6f50g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real Real-time Data related to climate change or the environment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y54qf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700309744.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700309275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on data driven visualization projects using realtime data on the topic of climate change or the environment (deforestation, sea levels, icecaps, biodiversity etc) but I can&amp;#39;t seem to find actual realtime data sources.&lt;/p&gt;\n\n&lt;p&gt;All the sources I&amp;#39;ve managed to find (such as NASA, Bloomberg, Theworldcounts etc) all seem to use estimated realtime data based on formulas. I&amp;#39;ve seen a lot of media art projects that say they used realtime data but they rarely share the source for it.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if there are &amp;#39;actual&amp;#39; realtime data sources that aren&amp;#39;t exactly based on prediction formulas, especially regarding climate change?&lt;/p&gt;\n\n&lt;p&gt;The main reason I&amp;#39;m asking is I want to create realtime visuals/installations like the one in the attached link, but I don&amp;#39;t want it to be a simple &amp;quot;one interaction per second&amp;quot; type of deal.&lt;/p&gt;\n\n&lt;p&gt;The one in the link shows artwork reacting in irregular patterns according to the &amp;#39;realtime&amp;#39; data, instead of regular interactions per second.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=GCXGGg3DlYw\"&gt;https://www.youtube.com/watch?v=GCXGGg3DlYw&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;+ Actually I think I may be mistaken of the concept of &amp;#39;realtime&amp;#39;. I&amp;#39;m sure topics such as &amp;#39;weather&amp;#39; or &amp;#39;currency&amp;#39; can be managed and visualized realtime but when it comes to the topic of realtime I&amp;#39;m not sure if such data can be measured in realtime seconds.&lt;/p&gt;\n\n&lt;p&gt;(I&amp;#39;m a complete newbe when it comes to data engineering)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cITEH7tFMV25gCP8qG8hpU2vxSCXLCgwN7vQL_iUU3Q.jpg?auto=webp&amp;s=fa46daf6ac326ac1420bb8e510bf0b8666a38dfb", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/cITEH7tFMV25gCP8qG8hpU2vxSCXLCgwN7vQL_iUU3Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b56a45a100b5133d654863922d6d22bd930befb", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/cITEH7tFMV25gCP8qG8hpU2vxSCXLCgwN7vQL_iUU3Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e1158b37f78baea783c4c574fa9f9df8d6e9d2fd", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/cITEH7tFMV25gCP8qG8hpU2vxSCXLCgwN7vQL_iUU3Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=75a7bfe778f2b92703fad1ea827991c48e644dfe", "width": 320, "height": 240}], "variants": {}, "id": "t5jJex3fAggFo7iYkQX0nySSJl563exgz4kBaivXHDQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y54qf", "is_robot_indexable": true, "report_reasons": null, "author": "nibbsnibbss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y54qf/real_realtime_data_related_to_climate_change_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y54qf/real_realtime_data_related_to_climate_change_or/", "subreddit_subscribers": 140316, "created_utc": 1700309275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm currently working on extracting metadata on a management group level from Microsoft Azure for analysis purposes. However, the API calls I'm using limit me to fetching only 1000 records at a time. I have a substantial dataset of around 100-120k records to extract, and this limitation significantly slows down the process.\n\nI'm curious if anyone has encountered a similar situation and found a way to increase the maximum number of records that can be extracted in a single call. Ideally, I'd like to fetch around 10k records per call to expedite the extraction process. \n\nDoes Azure allow users to modify pagination settings for API calls, or is this limitation fixed within the system?\n\nI'd appreciate any insights or experiences you've had in dealing with this issue. Thanks!", "author_fullname": "t2_8yfxu6me", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Azure API Calls for Larger Data Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y4qd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700307702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on extracting metadata on a management group level from Microsoft Azure for analysis purposes. However, the API calls I&amp;#39;m using limit me to fetching only 1000 records at a time. I have a substantial dataset of around 100-120k records to extract, and this limitation significantly slows down the process.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious if anyone has encountered a similar situation and found a way to increase the maximum number of records that can be extracted in a single call. Ideally, I&amp;#39;d like to fetch around 10k records per call to expedite the extraction process. &lt;/p&gt;\n\n&lt;p&gt;Does Azure allow users to modify pagination settings for API calls, or is this limitation fixed within the system?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights or experiences you&amp;#39;ve had in dealing with this issue. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y4qd4", "is_robot_indexable": true, "report_reasons": null, "author": "chickennuggiiiiissss", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y4qd4/optimizing_azure_api_calls_for_larger_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y4qd4/optimizing_azure_api_calls_for_larger_data/", "subreddit_subscribers": 140316, "created_utc": 1700307702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI have practical questions about silver layer.\n\nHere is an example:\n\nSource type: SQL server database\nSources : 3 tables :\n-customer(id,customerBK,name)\n-contract(id,contractBK,start_date)\n-customer_contract (id_customer,id_contract)\n--&gt;3 bronze folders\n\nQuestion:\nHow to handle that case on silver layer ?\nI.e. What to do with the Join source table (customer_contract), especially with surrogate keys which are purely technicals (auto-increments)\n\nDo we have to Join bronze folders to get associated business keys ?? And exclude ids from silver layer tables?\nDo we have to handle data quality , Like Ghost records ? I.e if an entry does not match with the entity table ?\n3NF ??\n\nI am pretty confused with the silver layer \nWhat we Can do or not.\n\"Data quality\" , \"minimum transformations\" \nThats not clear at all....\n\nWhat would be your advises?\n\nThanks a lot", "author_fullname": "t2_ay88xr2vg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medaillon architecture - silver layer rules", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17y2zf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700300361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI have practical questions about silver layer.&lt;/p&gt;\n\n&lt;p&gt;Here is an example:&lt;/p&gt;\n\n&lt;p&gt;Source type: SQL server database\nSources : 3 tables :\n-customer(id,customerBK,name)\n-contract(id,contractBK,start_date)\n-customer_contract (id_customer,id_contract)\n--&amp;gt;3 bronze folders&lt;/p&gt;\n\n&lt;p&gt;Question:\nHow to handle that case on silver layer ?\nI.e. What to do with the Join source table (customer_contract), especially with surrogate keys which are purely technicals (auto-increments)&lt;/p&gt;\n\n&lt;p&gt;Do we have to Join bronze folders to get associated business keys ?? And exclude ids from silver layer tables?\nDo we have to handle data quality , Like Ghost records ? I.e if an entry does not match with the entity table ?\n3NF ??&lt;/p&gt;\n\n&lt;p&gt;I am pretty confused with the silver layer \nWhat we Can do or not.\n&amp;quot;Data quality&amp;quot; , &amp;quot;minimum transformations&amp;quot; \nThats not clear at all....&lt;/p&gt;\n\n&lt;p&gt;What would be your advises?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17y2zf7", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Seesaw_2152", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17y2zf7/medaillon_architecture_silver_layer_rules/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17y2zf7/medaillon_architecture_silver_layer_rules/", "subreddit_subscribers": 140316, "created_utc": 1700300361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Everyone,  \nI'm interested in resource allocation for training deep learning models in clusters. Previously I have worked with Open source serverless frameworks such as OpenWhisk for other projects (Not on ML/DL). I'm looking for open source frameworks that manage resource allocation for deep learning models. I came across Ray while doing some searches. My goal is to modify some core parts of the framework and evaluate my ideas. Has anyone tried doing the same thing before? I welcome any suggestions since I haven't previously worked on this topic. \n\nThanks!", "author_fullname": "t2_5worb5ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Open Source Frameworks for Resource Allocation in Deep Learning Model Training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xqoo0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700259325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;br/&gt;\nI&amp;#39;m interested in resource allocation for training deep learning models in clusters. Previously I have worked with Open source serverless frameworks such as OpenWhisk for other projects (Not on ML/DL). I&amp;#39;m looking for open source frameworks that manage resource allocation for deep learning models. I came across Ray while doing some searches. My goal is to modify some core parts of the framework and evaluate my ideas. Has anyone tried doing the same thing before? I welcome any suggestions since I haven&amp;#39;t previously worked on this topic. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xqoo0", "is_robot_indexable": true, "report_reasons": null, "author": "ahmadreza_hadi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xqoo0/seeking_advice_on_open_source_frameworks_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xqoo0/seeking_advice_on_open_source_frameworks_for/", "subreddit_subscribers": 140316, "created_utc": 1700259325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With a medallion architecture, what would be the best practice to deal with tables that have the same subject?\n\nIf I have for example sales orders or customer information from the same business, but they come from different source systems, and these tables dosent have the same schema.\n\nShould I keep the 3NF in the silver layer and only combine these informations in my final gold table? Or the silver layer would be the place to create these final models by subject with business logic?  \nI come from a DW/BI background, but these layers still confuse me", "author_fullname": "t2_2t4hdsut", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with different sources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xoo22", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700254091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With a medallion architecture, what would be the best practice to deal with tables that have the same subject?&lt;/p&gt;\n\n&lt;p&gt;If I have for example sales orders or customer information from the same business, but they come from different source systems, and these tables dosent have the same schema.&lt;/p&gt;\n\n&lt;p&gt;Should I keep the 3NF in the silver layer and only combine these informations in my final gold table? Or the silver layer would be the place to create these final models by subject with business logic?&lt;br/&gt;\nI come from a DW/BI background, but these layers still confuse me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xoo22", "is_robot_indexable": true, "report_reasons": null, "author": "ltofanelli", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xoo22/how_to_deal_with_different_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xoo22/how_to_deal_with_different_sources/", "subreddit_subscribers": 140316, "created_utc": 1700254091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nWe have data coming from rest apis that need to get loaded in Snowflake. We are keeping costs to a minimum but have potentially a lot of requests coming through this so needs to scale.\n\nI was thinking ELT\n\nAPI -&gt; blob using azure functions then to snowflake and use dbt in snowflake.\n\nAny other ideas? I also looked at some previous posts and they said something similar but mentioned \u201cairflow to manage it all\u201d. Where would airflow fit into this?\n\nShould we use a tool instead of azure functions", "author_fullname": "t2_o1vjl2jil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELT API to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xni9x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700251871.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700250914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;We have data coming from rest apis that need to get loaded in Snowflake. We are keeping costs to a minimum but have potentially a lot of requests coming through this so needs to scale.&lt;/p&gt;\n\n&lt;p&gt;I was thinking ELT&lt;/p&gt;\n\n&lt;p&gt;API -&amp;gt; blob using azure functions then to snowflake and use dbt in snowflake.&lt;/p&gt;\n\n&lt;p&gt;Any other ideas? I also looked at some previous posts and they said something similar but mentioned \u201cairflow to manage it all\u201d. Where would airflow fit into this?&lt;/p&gt;\n\n&lt;p&gt;Should we use a tool instead of azure functions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17xni9x", "is_robot_indexable": true, "report_reasons": null, "author": "Distinct-Mention4792", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xni9x/elt_api_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xni9x/elt_api_to_snowflake/", "subreddit_subscribers": 140316, "created_utc": 1700250914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nWe have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor's (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor's AWS SQL instance over the VPN using a linked service. \n\nWe are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.\n\nOne suggestion we've received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. \n\nThis is less than ideal because adding another VM adds cost. \n\nCan we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?", "author_fullname": "t2_66hzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble connecting Modmed with Azure. Suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xldc1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700245193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We have a customer is using azure sql serverices to aggregate data that they feed into powerbi. They are using azure datafactory to intake data from various sources. We have created a site to site vpn between azure and a software  vendor&amp;#39;s (ModMed) AWS SQL instance and the VPN is connected. We are unable to connect the data factory to the vendor&amp;#39;s AWS SQL instance over the VPN using a linked service. &lt;/p&gt;\n\n&lt;p&gt;We are not confident in how the linked service should be configured or if we need to add a service endpoint (IP address) to the data factory.&lt;/p&gt;\n\n&lt;p&gt;One suggestion we&amp;#39;ve received is to create a virtual machine and connect it to the VPN tunnel, setup an Integration runtime agent running on the virtual machine, set the Data factory linked service to \u201cconnect via the integration runtime\u201d. &lt;/p&gt;\n\n&lt;p&gt;This is less than ideal because adding another VM adds cost. &lt;/p&gt;\n\n&lt;p&gt;Can we configure the data factory to connect directly to the AWS instance over the VPN, or is a VM or workstation running the IR agent the only solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xldc1", "is_robot_indexable": true, "report_reasons": null, "author": "traft00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xldc1/trouble_connecting_modmed_with_azure_suggestions/", "subreddit_subscribers": 140316, "created_utc": 1700245193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Full disclosure: A contributor to the project here.\n\nI have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.\n\nI'm excited to share that the project is now live and I wanted to thank the project's early contributors. You can learn more by visiting the repo: [https://github.com/onetable-io/onetable](https://github.com/onetable-io/onetable)\n\nI'll keep an eye out on this subreddit and the post to answer any questions you may have.", "author_fullname": "t2_o3fw52ash", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OneTable is now live | Table format interoperability is not a dream anymore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xjs0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1700240920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Full disclosure: A contributor to the project here.&lt;/p&gt;\n\n&lt;p&gt;I have seen folks discussing about Data Lakehouses and open table formats on this subreddit and even OneTable a couple times.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m excited to share that the project is now live and I wanted to thank the project&amp;#39;s early contributors. You can learn more by visiting the repo: &lt;a href=\"https://github.com/onetable-io/onetable\"&gt;https://github.com/onetable-io/onetable&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll keep an eye out on this subreddit and the post to answer any questions you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?auto=webp&amp;s=ca8ca18a4768b89f950527c931e5eaa3395cb2cc", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3beadbc1b340de0a682d509c2a7cd53cfeff27f7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=adc48402b2652b6a0c110b20f67388030e9ae6b3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ae1ff18f1579e9d9eb9633cfae7e8ff78557eca", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=78f6366155828de3caab54c68df36f92693b047b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=955fac3869882d57292ae00f401b8e3379d5ae4a", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/eN19unEeukVV0wxe4FxTQBFs5b5V8K9oyNnRlXkY5zM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cddba46e668b1955c4ec65830b7cf6ea09642eb7", "width": 1080, "height": 540}], "variants": {}, "id": "ZF0kwxmuX9UVT7upWOjDojrXLQQTrxSIm-50k-mSUxg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17xjs0q", "is_robot_indexable": true, "report_reasons": null, "author": "DataRepeatRinse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xjs0q/onetable_is_now_live_table_format/", "subreddit_subscribers": 140316, "created_utc": 1700240920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi reddit,I'm trying to implement a lakehous with hive 4 and iceberg and i think i'm almost there but...When I create a table like:\n\n    CREATE TABLE ice (id INT, name STRING) STORED BY ICEBERG;\n\nAnd then insert some data\n\n    INSERT INTO ice VALUES (1, 'one');\n\nAnd then select\n\n    SELECT * FROM ice;\n\nI don't see the inserted record.  \n\n\nEDIT: I do see the parquet files on storage, and see the folder and file of the metadata, as if the table was created as location\\_based\\_table, But documentation says that if no specific icber.catalog is set, it will use the defaul hive catalog.\n\nWhat am I missing?I suspect that is something related to the metastore, but can't find what...Thanks in advance, cheers.", "author_fullname": "t2_aytgj0xr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Created Hive tables STORED BY ICEBER; SELECT * returns empty", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17xtb5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700266559.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700266293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi reddit,I&amp;#39;m trying to implement a lakehous with hive 4 and iceberg and i think i&amp;#39;m almost there but...When I create a table like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CREATE TABLE ice (id INT, name STRING) STORED BY ICEBERG;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And then insert some data&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;INSERT INTO ice VALUES (1, &amp;#39;one&amp;#39;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And then select&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT * FROM ice;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I don&amp;#39;t see the inserted record.  &lt;/p&gt;\n\n&lt;p&gt;EDIT: I do see the parquet files on storage, and see the folder and file of the metadata, as if the table was created as location_based_table, But documentation says that if no specific icber.catalog is set, it will use the defaul hive catalog.&lt;/p&gt;\n\n&lt;p&gt;What am I missing?I suspect that is something related to the metastore, but can&amp;#39;t find what...Thanks in advance, cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17xtb5i", "is_robot_indexable": true, "report_reasons": null, "author": "Brilliant-Adward", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17xtb5i/created_hive_tables_stored_by_iceber_select/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17xtb5i/created_hive_tables_stored_by_iceber_select/", "subreddit_subscribers": 140316, "created_utc": 1700266293.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}