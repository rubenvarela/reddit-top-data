{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are starting a new position as data engineering manager, what would be your thought process or actions to be successful in the role?", "author_fullname": "t2_3x0urbjs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering manager", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182pl4i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700823305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are starting a new position as data engineering manager, what would be your thought process or actions to be successful in the role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182pl4i", "is_robot_indexable": true, "report_reasons": null, "author": "educationruinedme1", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182pl4i/data_engineering_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182pl4i/data_engineering_manager/", "subreddit_subscribers": 141507, "created_utc": 1700823305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My workplace makes queries to data in Snowflake, from Databricks, but it seems like Snowflake is working hard to develop their own ETL, ML pipelines using NVIDIA Rapids/GPU computing even.\n\nI have been signing up for online seminars on Snowflake data science/data engineering because I have a problem with Databricks.\n\nI want to use OpenZiti on Databricks so only client machines with a Ziti identity can connect to the Databricks.  The Databricks itself needs an OpenZiti identity so it can connect to an Ziti Edge Router which in turn would connect to Ziti Edge Router on Azure that connects to my web app on Azure.  From here I want to use Azure private link to connect to OpenAI services (natural language -&gt; SQL query) and to my Snowflake on Azure.\n\nSo the Snowflake on Azure can be totally cut off from the internet as well as my web app on Azure.  But Databricks does not have this capability, ie. close of all incoming ports, only outbound to Ziti edge router and have a Ziti identity.\n\n&amp;#x200B;", "author_fullname": "t2_7bmygxmk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Databricks becoming redundant?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182fuyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700788080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My workplace makes queries to data in Snowflake, from Databricks, but it seems like Snowflake is working hard to develop their own ETL, ML pipelines using NVIDIA Rapids/GPU computing even.&lt;/p&gt;\n\n&lt;p&gt;I have been signing up for online seminars on Snowflake data science/data engineering because I have a problem with Databricks.&lt;/p&gt;\n\n&lt;p&gt;I want to use OpenZiti on Databricks so only client machines with a Ziti identity can connect to the Databricks.  The Databricks itself needs an OpenZiti identity so it can connect to an Ziti Edge Router which in turn would connect to Ziti Edge Router on Azure that connects to my web app on Azure.  From here I want to use Azure private link to connect to OpenAI services (natural language -&amp;gt; SQL query) and to my Snowflake on Azure.&lt;/p&gt;\n\n&lt;p&gt;So the Snowflake on Azure can be totally cut off from the internet as well as my web app on Azure.  But Databricks does not have this capability, ie. close of all incoming ports, only outbound to Ziti edge router and have a Ziti identity.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182fuyq", "is_robot_indexable": true, "report_reasons": null, "author": "webNoob13", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182fuyq/is_databricks_becoming_redundant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182fuyq/is_databricks_becoming_redundant/", "subreddit_subscribers": 141507, "created_utc": 1700788080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm interested what were your costliest mistakes in de? Mine was setting up databricks within a vpc, forgetting to set up a S3 endpoint and then working with tb of data. I wasted around 4k.", "author_fullname": "t2_bk0fqe9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Costliest Mistakes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182w1a0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700843617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested what were your costliest mistakes in de? Mine was setting up databricks within a vpc, forgetting to set up a S3 endpoint and then working with tb of data. I wasted around 4k.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182w1a0", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Bake_783", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182w1a0/costliest_mistakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182w1a0/costliest_mistakes/", "subreddit_subscribers": 141507, "created_utc": 1700843617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_crthfc7kd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WebGL Visualizer for dbt DAGs with hundreds or thousands of models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182mb4v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1700809693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "large-dbt-dag-visualizer.whiai.repl.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://large-dbt-dag-visualizer.whiai.repl.co/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "182mb4v", "is_robot_indexable": true, "report_reasons": null, "author": "devschema", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/182mb4v/webgl_visualizer_for_dbt_dags_with_hundreds_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://large-dbt-dag-visualizer.whiai.repl.co/", "subreddit_subscribers": 141507, "created_utc": 1700809693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Dear Data Engineers,**\n\nI wanted to update you on an ongoing project involving the shifting of our ETL load from AWS RDS (Postgres ) to Redshift.\n\nKey points to note :\n\n\\- This would be a 30 minutes scheduled job \\[Not One Time Migration \\]\n\n\\- Change Data Capture is applicable\n\n\\- Raw data in actually on AWS RDS Postgres (Not aurora)\n\n\\- Fact/Dim Table should be in Redshift \n\n&amp;#x200B;\n\nAs of now, our ETL process is facilitated by a Python container running as a AWS Fargate job. My plan is to leverage the existing project and make minimal changes, particularly in the realm of Python libraries, to enable seamless data ingestion into Redshift.\n\n&amp;#x200B;\n\nI have a few questions that I would appreciate your insights on:\n\n* Is the proposed approach of modifying the existing project a sound one?\n* Are there any recommended Python libraries for efficiently ingesting data into Redshift?\n* If PySpark is considered, are there alternative ways to run PySpark projects aside from Glue or EMR? (Currently, budget constraints limit our options in this regard.)\n\nI value your thoughts and any additional input you may have on this matter. If you have any relevant resource materials, kindly share them with me.\n\n&amp;#x200B;\n\nThank you for your time and expertise.", "author_fullname": "t2_7nvr4m4i4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion on ETL infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182mjd0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700814674.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700810568.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Dear Data Engineers,&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I wanted to update you on an ongoing project involving the shifting of our ETL load from AWS RDS (Postgres ) to Redshift.&lt;/p&gt;\n\n&lt;p&gt;Key points to note :&lt;/p&gt;\n\n&lt;p&gt;- This would be a 30 minutes scheduled job [Not One Time Migration ]&lt;/p&gt;\n\n&lt;p&gt;- Change Data Capture is applicable&lt;/p&gt;\n\n&lt;p&gt;- Raw data in actually on AWS RDS Postgres (Not aurora)&lt;/p&gt;\n\n&lt;p&gt;- Fact/Dim Table should be in Redshift &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As of now, our ETL process is facilitated by a Python container running as a AWS Fargate job. My plan is to leverage the existing project and make minimal changes, particularly in the realm of Python libraries, to enable seamless data ingestion into Redshift.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a few questions that I would appreciate your insights on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is the proposed approach of modifying the existing project a sound one?&lt;/li&gt;\n&lt;li&gt;Are there any recommended Python libraries for efficiently ingesting data into Redshift?&lt;/li&gt;\n&lt;li&gt;If PySpark is considered, are there alternative ways to run PySpark projects aside from Glue or EMR? (Currently, budget constraints limit our options in this regard.)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I value your thoughts and any additional input you may have on this matter. If you have any relevant resource materials, kindly share them with me.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and expertise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182mjd0", "is_robot_indexable": true, "report_reasons": null, "author": "Flimsy-Mirror974", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182mjd0/discussion_on_etl_infrastructure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182mjd0/discussion_on_etl_infrastructure/", "subreddit_subscribers": 141507, "created_utc": 1700810568.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi,\n\nI've been applying for different de and analytics engineer roles around mid to senior level.. For the ones that I do get the interview, I seem to never make it past the technical interview. Sometimes it's a case study, sometimes it's a in person coding. Case study questions are sometimes like \"how do you design a dB for gold layer based on xy business case and this schema.\" Analyze the risk and data validation/ qa tests and stuff. \n\nIs there any recommendations on studying material to improve?", "author_fullname": "t2_6o6sl8n7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failing technical interviews. Looking for suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182xcut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700847172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying for different de and analytics engineer roles around mid to senior level.. For the ones that I do get the interview, I seem to never make it past the technical interview. Sometimes it&amp;#39;s a case study, sometimes it&amp;#39;s a in person coding. Case study questions are sometimes like &amp;quot;how do you design a dB for gold layer based on xy business case and this schema.&amp;quot; Analyze the risk and data validation/ qa tests and stuff. &lt;/p&gt;\n\n&lt;p&gt;Is there any recommendations on studying material to improve?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182xcut", "is_robot_indexable": true, "report_reasons": null, "author": "Tasty_Fold3012", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182xcut/failing_technical_interviews_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182xcut/failing_technical_interviews_looking_for/", "subreddit_subscribers": 141507, "created_utc": 1700847172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are trying to match your customers into a master customer id, what fields are you matching on? Our ordering system uses email but you could use different emails to place orders. Any recommendations?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Matching Customer Records", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182k9w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700802559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are trying to match your customers into a master customer id, what fields are you matching on? Our ordering system uses email but you could use different emails to place orders. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182k9w0", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182k9w0/matching_customer_records/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182k9w0/matching_customer_records/", "subreddit_subscribers": 141507, "created_utc": 1700802559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My current DE job doesn't involve much coding at all. I don't program anything more than some occasional simple Python scripts. Feels like a deathblow for my coding skills, and I want to improve it, but there is simply no opportunity for it. Yet I just feel unemployable for the jobs/projects that would require higher proficiency in programming for a daily basis, so I'll need to brush it up on my own afterhours if I want to attain that.\n\nCurrently I feel intermediate. I am comfortable writing basic Python apps and more advanced scripts/data transformations. I also know some technical details and best practices that allow me to enhance my code. But other than that I feel that my current skillset wouldn't bring much value to more advanced projects in data platforms.\n\nI was consider contributing to some open-source libraries, but I really have no idea which and what. Codebases for libs I know are mostly overwhelming, and I don't use any particular one to the extent I would know some bugs, shortcomings that could be fixed. I have no idea for own library and/or extensions. Maybe start with some smaller ones, like some unofficial web scrapers or API clients?\n\nI was already creating some more advanced DE projects and I liked it, but I feel like I have enough of it, won't learn much new stuff anymore coding-wise, and I want to progress with my skills further.\n\nDoing Leetcode and some other stuff like \"resolve X puzzles\" just isn't what I am looking for. I know some companies love it, but I am looking for some real SWE-like experience.\n\nWhat would you suggest? Any other options?", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Improving coding/SWE skills as mid DE.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1834w3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700870246.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700867272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My current DE job doesn&amp;#39;t involve much coding at all. I don&amp;#39;t program anything more than some occasional simple Python scripts. Feels like a deathblow for my coding skills, and I want to improve it, but there is simply no opportunity for it. Yet I just feel unemployable for the jobs/projects that would require higher proficiency in programming for a daily basis, so I&amp;#39;ll need to brush it up on my own afterhours if I want to attain that.&lt;/p&gt;\n\n&lt;p&gt;Currently I feel intermediate. I am comfortable writing basic Python apps and more advanced scripts/data transformations. I also know some technical details and best practices that allow me to enhance my code. But other than that I feel that my current skillset wouldn&amp;#39;t bring much value to more advanced projects in data platforms.&lt;/p&gt;\n\n&lt;p&gt;I was consider contributing to some open-source libraries, but I really have no idea which and what. Codebases for libs I know are mostly overwhelming, and I don&amp;#39;t use any particular one to the extent I would know some bugs, shortcomings that could be fixed. I have no idea for own library and/or extensions. Maybe start with some smaller ones, like some unofficial web scrapers or API clients?&lt;/p&gt;\n\n&lt;p&gt;I was already creating some more advanced DE projects and I liked it, but I feel like I have enough of it, won&amp;#39;t learn much new stuff anymore coding-wise, and I want to progress with my skills further.&lt;/p&gt;\n\n&lt;p&gt;Doing Leetcode and some other stuff like &amp;quot;resolve X puzzles&amp;quot; just isn&amp;#39;t what I am looking for. I know some companies love it, but I am looking for some real SWE-like experience.&lt;/p&gt;\n\n&lt;p&gt;What would you suggest? Any other options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1834w3n", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1834w3n/improving_codingswe_skills_as_mid_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1834w3n/improving_codingswe_skills_as_mid_de/", "subreddit_subscribers": 141507, "created_utc": 1700867272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3 workflow improvements we wish dbt announced at Coalesce 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182vxzq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1700843378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/3-workflow-improvements-we-wish-dbt-announced-at-coalesce-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "182vxzq", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182vxzq/3_workflow_improvements_we_wish_dbt_announced_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/3-workflow-improvements-we-wish-dbt-announced-at-coalesce-2023", "subreddit_subscribers": 141507, "created_utc": 1700843378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for advice in how to move our internal network data analysis dashboard to web-based so that it can be accessed anywhere. I'm primarily asking here to get your suggestions on where to house the data. Here's the context:\n\n* **End Application**: A web-based DA dashboard for shipping tracking. \n* **Consumers**: Less than 100 external customers, 10 internal employees\n* **Data Freshness**: Data being updated every 4 hours is acceptable\n* **Data Security**: This isn't health care or gov't data so extra-ordinary steps aren't required here.\n* **Data**: Basically two datasets - The shipping data (200 million rows (50-100 GB) a year) and the tracking data (1 billion rows (50-100 GB) a year)\n* **Context**: Small company, greenfield, wide latitude for 'learning as we build' mentality, lax timeframe\n* **Current setup**: Streamlit served on internal network on top of local SQL Servers\n\nI'm not married to the idea of moving local data up to a platform but to my neophyte ears that makes sense for ease of access. \n\nWould BigQuery make sense given the small-ish amount of data?\n\nI'm clearly learning as I go here lol but any pointers would be helpful.", "author_fullname": "t2_g4dmf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platforms for Web-Based DA Dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182qj5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700827083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for advice in how to move our internal network data analysis dashboard to web-based so that it can be accessed anywhere. I&amp;#39;m primarily asking here to get your suggestions on where to house the data. Here&amp;#39;s the context:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;End Application&lt;/strong&gt;: A web-based DA dashboard for shipping tracking. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Consumers&lt;/strong&gt;: Less than 100 external customers, 10 internal employees&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Freshness&lt;/strong&gt;: Data being updated every 4 hours is acceptable&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Security&lt;/strong&gt;: This isn&amp;#39;t health care or gov&amp;#39;t data so extra-ordinary steps aren&amp;#39;t required here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: Basically two datasets - The shipping data (200 million rows (50-100 GB) a year) and the tracking data (1 billion rows (50-100 GB) a year)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;: Small company, greenfield, wide latitude for &amp;#39;learning as we build&amp;#39; mentality, lax timeframe&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Current setup&lt;/strong&gt;: Streamlit served on internal network on top of local SQL Servers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not married to the idea of moving local data up to a platform but to my neophyte ears that makes sense for ease of access. &lt;/p&gt;\n\n&lt;p&gt;Would BigQuery make sense given the small-ish amount of data?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m clearly learning as I go here lol but any pointers would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182qj5h", "is_robot_indexable": true, "report_reasons": null, "author": "ace_reporter", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182qj5h/data_platforms_for_webbased_da_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182qj5h/data_platforms_for_webbased_da_dashboard/", "subreddit_subscribers": 141507, "created_utc": 1700827083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was asked to help another team with their code, and some genius put the jsons into a folder structure where both month and minute were abbreviated using the letter m.\n\nIs there a way to load the date that automatically renames one of the two columns?\n\nEdit: We are using Pyspark load. I am not allowed to rename the folders.\n\nEdit2: Sample path: \"/y=2023/m=07/d=04/h=01/m=07/sample.json\"", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I prevent the following error: \"[COLUMN_ALREADY_EXISTS] The column `m` already exists. Consider to choose another name or rename the existing column.\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182od2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1700819039.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700818016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked to help another team with their code, and some genius put the jsons into a folder structure where both month and minute were abbreviated using the letter m.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to load the date that automatically renames one of the two columns?&lt;/p&gt;\n\n&lt;p&gt;Edit: We are using Pyspark load. I am not allowed to rename the folders.&lt;/p&gt;\n\n&lt;p&gt;Edit2: Sample path: &amp;quot;/y=2023/m=07/d=04/h=01/m=07/sample.json&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182od2y", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182od2y/how_can_i_prevent_the_following_error_column/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182od2y/how_can_i_prevent_the_following_error_column/", "subreddit_subscribers": 141507, "created_utc": 1700818016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is looking for an ETL tool (for Reverse ETL specifically, AWS Athena -&gt; HubSpot) and we've stumbled upon Polytomic, which seems to have a lot of integrations and looks promising overall. I couldn't however find any mentions on reddit. Does anyone have any experience with it?", "author_fullname": "t2_tp4bdcyr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with Polytomic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182wgsr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700844778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is looking for an ETL tool (for Reverse ETL specifically, AWS Athena -&amp;gt; HubSpot) and we&amp;#39;ve stumbled upon Polytomic, which seems to have a lot of integrations and looks promising overall. I couldn&amp;#39;t however find any mentions on reddit. Does anyone have any experience with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182wgsr", "is_robot_indexable": true, "report_reasons": null, "author": "ichhabewyjebane", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182wgsr/experience_with_polytomic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182wgsr/experience_with_polytomic/", "subreddit_subscribers": 141507, "created_utc": 1700844778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know the best/safest option to copy a managed  table as a backup would be to use DEEP CLONE. But if it\u2019s not a big table is there any issues with just copying the source folder and renaming it as a quick and dirty solution? So long as your not changing anything within it the timestamps and versioning should remain as at the time of copy?\n\nAm I missing something massive here?", "author_fullname": "t2_scnmi5ys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up Dbx Managed Table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182oayp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700817745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the best/safest option to copy a managed  table as a backup would be to use DEEP CLONE. But if it\u2019s not a big table is there any issues with just copying the source folder and renaming it as a quick and dirty solution? So long as your not changing anything within it the timestamps and versioning should remain as at the time of copy?&lt;/p&gt;\n\n&lt;p&gt;Am I missing something massive here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "182oayp", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Aardvark258", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182oayp/backing_up_dbx_managed_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182oayp/backing_up_dbx_managed_table/", "subreddit_subscribers": 141507, "created_utc": 1700817745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone here work with Oracle WMS data? I started on a new project and it seems the team I'm in doesn't know how to extract data from Oracle WMS. I found their Rest APIs but these are slow. (124 rows per request... sigh).\n\nIs there a cloud database that Oracle WMS clients have access to to extract data quickly etc?", "author_fullname": "t2_a42ncwcn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle Warehouse Management System (WMS) Cloud, how to access the cloud database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_182kyth", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700804897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here work with Oracle WMS data? I started on a new project and it seems the team I&amp;#39;m in doesn&amp;#39;t know how to extract data from Oracle WMS. I found their Rest APIs but these are slow. (124 rows per request... sigh).&lt;/p&gt;\n\n&lt;p&gt;Is there a cloud database that Oracle WMS clients have access to to extract data quickly etc?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "182kyth", "is_robot_indexable": true, "report_reasons": null, "author": "MassiveDefender", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/182kyth/oracle_warehouse_management_system_wms_cloud_how/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/182kyth/oracle_warehouse_management_system_wms_cloud_how/", "subreddit_subscribers": 141507, "created_utc": 1700804897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI'll be joining my first company soon and have the option to choose from these domains. I'll likely be assigned to projects based on my choice.\n\n1. Data Engineering: Apache Kafka, Apache Spark, Hadoop, Airflow, etc.\n2. Frontend: React, Next.js\n3. Backend: Django, Spring Boot\n\nI've dabbled in all these domains with basic knowledge, mainly working as a full-stack developer in college. Which one offers the most scope and long-term benefits? Any input is appreciated!", "author_fullname": "t2_ipbf10dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering, Frontend or Backend? What to choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1834ugp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1700867161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be joining my first company soon and have the option to choose from these domains. I&amp;#39;ll likely be assigned to projects based on my choice.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Engineering: Apache Kafka, Apache Spark, Hadoop, Airflow, etc.&lt;/li&gt;\n&lt;li&gt;Frontend: React, Next.js&lt;/li&gt;\n&lt;li&gt;Backend: Django, Spring Boot&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve dabbled in all these domains with basic knowledge, mainly working as a full-stack developer in college. Which one offers the most scope and long-term benefits? Any input is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1834ugp", "is_robot_indexable": true, "report_reasons": null, "author": "Notalabel_4566", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1834ugp/data_engineering_frontend_or_backend_what_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1834ugp/data_engineering_frontend_or_backend_what_to/", "subreddit_subscribers": 141507, "created_utc": 1700867161.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}