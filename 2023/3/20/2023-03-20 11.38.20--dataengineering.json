{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?", "author_fullname": "t2_h9iom7pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side hustle ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vim1y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679224430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vim1y", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Leader-6040", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "subreddit_subscribers": 93639, "created_utc": 1679224430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.\n\nI am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?", "author_fullname": "t2_1eqrbzj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you who were self taught, what was your path into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vv3jo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679254335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.&lt;/p&gt;\n\n&lt;p&gt;I am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11vv3jo", "is_robot_indexable": true, "report_reasons": null, "author": "xyzabc123410000", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "subreddit_subscribers": 93639, "created_utc": 1679254335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So as the one and only DE in my whole company, i've decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?\n\nI was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.\n\nAny insights are welcome thanks!\n\nEdit: pipeline stack consists mainly of\n\n- BigQuery\n- Airflow\n- Python", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First step to data quality assurance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11w31yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679277676.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679272404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as the one and only DE in my whole company, i&amp;#39;ve decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?&lt;/p&gt;\n\n&lt;p&gt;I was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.&lt;/p&gt;\n\n&lt;p&gt;Any insights are welcome thanks!&lt;/p&gt;\n\n&lt;p&gt;Edit: pipeline stack consists mainly of&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BigQuery&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11w31yo", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "subreddit_subscribers": 93639, "created_utc": 1679272404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.\n\nThe group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.\n\nI'm working on automating this group's work, and the first step is to map out the entire data pipeline (what is everyone doing?)\n\n**How do I do this?**\n\nI've only ever mapped out small data pipelines that have a few data sources and a few processes.\n\nMy group's entire data pipeline has hundreds of different sources and thousands of Excel workbooks.\n\nI've had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.\n\n**Any suggestions?**\n\nThanks!", "author_fullname": "t2_7b3mpu85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to map out data pipeline of 500-person BI Excel team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vwhrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679257348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;The group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on automating this group&amp;#39;s work, and the first step is to map out the entire data pipeline (what is everyone doing?)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How do I do this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only ever mapped out small data pipelines that have a few data sources and a few processes.&lt;/p&gt;\n\n&lt;p&gt;My group&amp;#39;s entire data pipeline has hundreds of different sources and thousands of Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Any suggestions?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vwhrx", "is_robot_indexable": true, "report_reasons": null, "author": "BrilliantCashew", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "subreddit_subscribers": 93639, "created_utc": 1679257348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nall is in the title :)", "author_fullname": "t2_w54e628x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How train my SQL skills with real world data engineering problems ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vyiip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679261678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;all is in the title :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vyiip", "is_robot_indexable": true, "report_reasons": null, "author": "rxmi_bkd_", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "subreddit_subscribers": 93639, "created_utc": 1679261678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for roles and responsibilities of Data Engineering Manager compared Engineering Director.", "author_fullname": "t2_q6tghhmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the roles and responsibilities of Data Engineering Manager in your organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11w830f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679285358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for roles and responsibilities of Data Engineering Manager compared Engineering Director.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11w830f", "is_robot_indexable": true, "report_reasons": null, "author": "jimmy3579", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11w830f/what_is_the_roles_and_responsibilities_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11w830f/what_is_the_roles_and_responsibilities_of_data/", "subreddit_subscribers": 93639, "created_utc": 1679285358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing the Right AWS Storage Service: A Comprehensive Guide to S3, S3N, and S3A", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vzob1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xFDuYtxF05skv0w7zFnEyeJJvkXQxsqqN1g_hNEvQ78.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679264236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?auto=webp&amp;v=enabled&amp;s=411aa08b45b75cc83e1b803e7cbc09fabc35c0aa", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=807af3da372075614dcca8bad3021574ea34f387", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a215d34a4896f8da21f7c75374bb5ba86dc87a54", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2f9f8228fd44da38e37c6ab3e8154892b6def41", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94c695eff7f14025669ba5e6cf1c003a997ef446", "width": 640, "height": 480}], "variants": {}, "id": "NlJY-Ip5F8-M2Nqay9E5tu8KMzr0rk_vWYTLZRLV6YI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vzob1", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vzob1/choosing_the_right_aws_storage_service_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "subreddit_subscribers": 93639, "created_utc": 1679264236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sharing the code to draw comparison between Pandas and Polars (Rust). Results are pretty impressive for Polars.\n\n    import pandas as pd\n    import polars as pl\n    import numpy as np\n    import time\n    \n    # Create a random DataFrame with 500 MB of data\n    n_rows = 250000\n    n_cols = 400\n    df = pd.DataFrame(np.random.randn(n_rows, n_cols), columns=['col_{}'.format(i) for i in range(n_cols)])\n    df_polars = pl.from_pandas(df)\n    \n    # Benchmark Pandas 2.0\n    start_time = time.time()\n    df_filtered = df[df['col_0'] &gt; 0]\n    df_grouped = df.groupby(['col_1', 'col_2']).mean()\n    df_sorted = df.sort_values(by=['col_3'], ascending=False)\n    df_merged = pd.merge(df, df_grouped, on=['col_1', 'col_2'])\n    pandas_time = time.time() - start_time\n    \n    # Benchmark Polars Rust\n    start_time = time.time()\n    df_filtered_polars = df_polars.filter(pl.col('col_0') &gt; 0)\n    df_grouped_polars = df_polars.groupby(['col_1', 'col_2']).mean()\n    df_sorted_polars = df_polars.sort(by=['col_3']).reverse()\n    df_merged_polars = df_polars.join(df_grouped_polars, on=['col_1', 'col_2'])\n    polars_time = time.time() - start_time\n    \n    # Print results\n    print('Pandas 2.0 time: {:.2f} seconds'.format(pandas_time))\n    print('Polars Rust time: {:.2f} seconds'.format(polars_time))\n\nIf you want to increase dataframe size to 1GB:Change`n_rows = 10**6n_cols = 1000`\n\nResults:   \n\n\nPandas : 23.45 sec  \n\n\n[Pola.rs](https://Pola.rs) : 5.66 sec  \n\n\nIf you want to increase dataframe size to 100GB:", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Code]: Comparison between Rust (Polars) and Pandas | Basic Benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wc273", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679301270.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679297751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing the code to draw comparison between Pandas and Polars (Rust). Results are pretty impressive for Polars.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nimport polars as pl\nimport numpy as np\nimport time\n\n# Create a random DataFrame with 500 MB of data\nn_rows = 250000\nn_cols = 400\ndf = pd.DataFrame(np.random.randn(n_rows, n_cols), columns=[&amp;#39;col_{}&amp;#39;.format(i) for i in range(n_cols)])\ndf_polars = pl.from_pandas(df)\n\n# Benchmark Pandas 2.0\nstart_time = time.time()\ndf_filtered = df[df[&amp;#39;col_0&amp;#39;] &amp;gt; 0]\ndf_grouped = df.groupby([&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;]).mean()\ndf_sorted = df.sort_values(by=[&amp;#39;col_3&amp;#39;], ascending=False)\ndf_merged = pd.merge(df, df_grouped, on=[&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;])\npandas_time = time.time() - start_time\n\n# Benchmark Polars Rust\nstart_time = time.time()\ndf_filtered_polars = df_polars.filter(pl.col(&amp;#39;col_0&amp;#39;) &amp;gt; 0)\ndf_grouped_polars = df_polars.groupby([&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;]).mean()\ndf_sorted_polars = df_polars.sort(by=[&amp;#39;col_3&amp;#39;]).reverse()\ndf_merged_polars = df_polars.join(df_grouped_polars, on=[&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;])\npolars_time = time.time() - start_time\n\n# Print results\nprint(&amp;#39;Pandas 2.0 time: {:.2f} seconds&amp;#39;.format(pandas_time))\nprint(&amp;#39;Polars Rust time: {:.2f} seconds&amp;#39;.format(polars_time))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you want to increase dataframe size to 1GB:Change&lt;code&gt;n_rows = 10**6n_cols = 1000&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Results:   &lt;/p&gt;\n\n&lt;p&gt;Pandas : 23.45 sec  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://Pola.rs\"&gt;Pola.rs&lt;/a&gt; : 5.66 sec  &lt;/p&gt;\n\n&lt;p&gt;If you want to increase dataframe size to 100GB:&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?auto=webp&amp;v=enabled&amp;s=8182b8164b2ef2edf05c1673e96e61650ef3f975", "width": 628, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c5ed42ff330568978d8b29b2f67133d1aa7669e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b58ea26aaaca49ea579f3d1a2dad7a86e553498", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d1614fa2d7201162e8014046bb497c8b8ad0245", "width": 320, "height": 320}], "variants": {}, "id": "GQEQ7WaJ43xmaAcrmZznZkixlQ7IFzW9Q8Sw1L0rwqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11wc273", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11wc273/code_comparison_between_rust_polars_and_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11wc273/code_comparison_between_rust_polars_and_pandas/", "subreddit_subscribers": 93639, "created_utc": 1679297751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, \n\nI wrote an article showing how to automatically generate DBT documentation with ChatGPT, check it out\n\n[https://www.nintoracaudio.dev/data-eng/2023/03/18/dbt-generator.html](https://www.nintoracaudio.dev/data-eng/2023/03/18/dbt-generator.html)", "author_fullname": "t2_609jlk7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Documentation Generator w/ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11weshk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679307386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, &lt;/p&gt;\n\n&lt;p&gt;I wrote an article showing how to automatically generate DBT documentation with ChatGPT, check it out&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.nintoracaudio.dev/data-eng/2023/03/18/dbt-generator.html\"&gt;https://www.nintoracaudio.dev/data-eng/2023/03/18/dbt-generator.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11weshk", "is_robot_indexable": true, "report_reasons": null, "author": "nintoracaudio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11weshk/dbt_documentation_generator_wchatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11weshk/dbt_documentation_generator_wchatgpt/", "subreddit_subscribers": 93639, "created_utc": 1679307386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I (22, India) have about 1 year of experience in s/w programming. My current job is data engineering by chance rather than choice. Consider me a newcomer to technology who is out of touch with current events. I've been thinking about my job for the past few weeks and trying to make good decisions about it. I was curious about the future scope of a Data Engineer and the present job market for this role. I have some Snowflake expertise and would like to learn more about it. Any advice, resources, or recommendations are greatly welcomed. Have a wonderful day, everyone. Thank you very much.", "author_fullname": "t2_a2427oio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of Data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11we97u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679305556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (22, India) have about 1 year of experience in s/w programming. My current job is data engineering by chance rather than choice. Consider me a newcomer to technology who is out of touch with current events. I&amp;#39;ve been thinking about my job for the past few weeks and trying to make good decisions about it. I was curious about the future scope of a Data Engineer and the present job market for this role. I have some Snowflake expertise and would like to learn more about it. Any advice, resources, or recommendations are greatly welcomed. Have a wonderful day, everyone. Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11we97u", "is_robot_indexable": true, "report_reasons": null, "author": "No-Rock1172", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11we97u/future_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11we97u/future_of_data/", "subreddit_subscribers": 93639, "created_utc": 1679305556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For an article that I am writing, I would love to hear some thoughts about the challenges in moving from structured data architecture into a combination of structured and unstructured data. What I focused on from my experience is extracting the right metadata to enable the integration, and building the right transformations. I am wondering if there are some other real life challenges that you encountered and may want to share. Thanks!", "author_fullname": "t2_m2ywgliu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining structured and unstructured data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11wdagu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679302160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For an article that I am writing, I would love to hear some thoughts about the challenges in moving from structured data architecture into a combination of structured and unstructured data. What I focused on from my experience is extracting the right metadata to enable the integration, and building the right transformations. I am wondering if there are some other real life challenges that you encountered and may want to share. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11wdagu", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedLion9876", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11wdagu/combining_structured_and_unstructured_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11wdagu/combining_structured_and_unstructured_data/", "subreddit_subscribers": 93639, "created_utc": 1679302160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video - DataOps in action with Nessie, Iceberg and Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vlh9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11vlh9m", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2T2x1v2i6CjP2SscBfbhTk4wVZ5lpwFXzJIQ_rIK-bE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679232616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/UHLu6DXwtuA", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?auto=webp&amp;v=enabled&amp;s=556a9c845a98dfda476ee9a7eaa817a1b0a8a20c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74ba57c57db07ce1ca1a994cc7130844c3e7d76b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f105a4887d1f487fc04f777cdc875e0771e99399", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5211a8ce14953c3048e012b8675765aa24505ac0", "width": 320, "height": 240}], "variants": {}, "id": "ooxf25bw1coNvdUDTMIbE04IHNNWFquvpmAokw8nN0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11vlh9m", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vlh9m/video_dataops_in_action_with_nessie_iceberg_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/UHLu6DXwtuA", "subreddit_subscribers": 93639, "created_utc": 1679232616.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_video": false}}], "before": null}}