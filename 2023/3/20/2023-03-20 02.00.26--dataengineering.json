{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI have been recently moved to project where we are developing application for client using Azure ecosystem. We are 25+ memeber  team where each team takes care of different part. I work with a sub-team of 3 members (manager,senior resource and myself -analyst)  where we do transformation using Azure databricks. Our manager is not from core development background and he was DBA before this project or involved in work around DBA. I have been trying to convince him to use Git for version controlling for reasons which are basic and every developer knows. But he is convincing us to work on same folders ( In databricks we can access same folders / shared access) . I tried my best to  convince him but no luck. Can you guys suggest any other ways to convince him  or has anyone faced similar situation before?", "author_fullname": "t2_tfjxuupf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager denying use of Git", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v9z1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679196368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have been recently moved to project where we are developing application for client using Azure ecosystem. We are 25+ memeber  team where each team takes care of different part. I work with a sub-team of 3 members (manager,senior resource and myself -analyst)  where we do transformation using Azure databricks. Our manager is not from core development background and he was DBA before this project or involved in work around DBA. I have been trying to convince him to use Git for version controlling for reasons which are basic and every developer knows. But he is convincing us to work on same folders ( In databricks we can access same folders / shared access) . I tried my best to  convince him but no luck. Can you guys suggest any other ways to convince him  or has anyone faced similar situation before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11v9z1q", "is_robot_indexable": true, "report_reasons": null, "author": "Aswathama_001", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11v9z1q/manager_denying_use_of_git/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11v9z1q/manager_denying_use_of_git/", "subreddit_subscribers": 93600, "created_utc": 1679196368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?", "author_fullname": "t2_h9iom7pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side hustle ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vim1y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679224430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vim1y", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Leader-6040", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "subreddit_subscribers": 93600, "created_utc": 1679224430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A new team member wants to rewrite all the pipeline logic into a fully OO way. \n\nSo classify everything, object calls, rewrite everything i to methods etc.\n\nAs well as data expectations, unit tests and integration tests. I do see the value and when you read any books it\u2019s all the best practice stuff. \n\nI really like it one way but it has probably tripled the time to deliver a dataset. Some of pipeline logic is simple enough at its heart.\n\nSome of our dataset logic is pretty simple in its core and you could do it within a sprint (2-3 weeks) now it\u2019s pretty challenging to deliver \n\nWe also use unit test and expectations.\n\nOn one side I want to do things the best way but on the other the client doesn\u2019t understand why deliverables are taking so long and he doesn\u2019t really see any of the benefits on the front end (yet)", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much object orienteered do you use in your projects? Bonus points for integration and unit tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vfwse", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679215835.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679215448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new team member wants to rewrite all the pipeline logic into a fully OO way. &lt;/p&gt;\n\n&lt;p&gt;So classify everything, object calls, rewrite everything i to methods etc.&lt;/p&gt;\n\n&lt;p&gt;As well as data expectations, unit tests and integration tests. I do see the value and when you read any books it\u2019s all the best practice stuff. &lt;/p&gt;\n\n&lt;p&gt;I really like it one way but it has probably tripled the time to deliver a dataset. Some of pipeline logic is simple enough at its heart.&lt;/p&gt;\n\n&lt;p&gt;Some of our dataset logic is pretty simple in its core and you could do it within a sprint (2-3 weeks) now it\u2019s pretty challenging to deliver &lt;/p&gt;\n\n&lt;p&gt;We also use unit test and expectations.&lt;/p&gt;\n\n&lt;p&gt;On one side I want to do things the best way but on the other the client doesn\u2019t understand why deliverables are taking so long and he doesn\u2019t really see any of the benefits on the front end (yet)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vfwse", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vfwse/how_much_object_orienteered_do_you_use_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vfwse/how_much_object_orienteered_do_you_use_in_your/", "subreddit_subscribers": 93600, "created_utc": 1679215448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.\n\nI am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?", "author_fullname": "t2_1eqrbzj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you who were self taught, what was your path into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vv3jo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679254335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.&lt;/p&gt;\n\n&lt;p&gt;I am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11vv3jo", "is_robot_indexable": true, "report_reasons": null, "author": "xyzabc123410000", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "subreddit_subscribers": 93600, "created_utc": 1679254335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c7c8zdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse \u2014 A resum\u00e9", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_11vgsq4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xzRqhdW5wdYKrEiLprJjN9BCNvd-Lk838oP_52SJDkQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679218534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/claimsforce/lakehouse-a-resum%C3%A9-750368e57914", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?auto=webp&amp;v=enabled&amp;s=cf462ffdfb5ba5e01fea229680ba6fdb6df361d4", "width": 1200, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a681a307f0bc2ed41237a6321b9c18b9fb20bdc8", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d91b223d3625b4b74141af866446dcd68c1a55e3", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c7bb75fc3194ebf57b6c362715d69f60c5d35ca", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac0990313ea305bf2d4047f67314b15ff0bc4d1a", "width": 640, "height": 419}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c9f0cda945dd435a112c44189de861e9ada4db1", "width": 960, "height": 628}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0186d967fec84a6cec2290fce8dff306f740061", "width": 1080, "height": 707}], "variants": {}, "id": "CR4vm1xt0XmkK7tgZG5CSJJnV_WBTvg9-Jn2XwPTOd4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vgsq4", "is_robot_indexable": true, "report_reasons": null, "author": "heyimsinged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vgsq4/lakehouse_a_resum\u00e9/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/claimsforce/lakehouse-a-resum%C3%A9-750368e57914", "subreddit_subscribers": 93600, "created_utc": 1679218534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can Tableau handle direct connect to a table of this size?", "author_fullname": "t2_4oxdz7yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10B rows or more in a core fact table? What data stack do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vd8mx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679206284.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can Tableau handle direct connect to a table of this size?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vd8mx", "is_robot_indexable": true, "report_reasons": null, "author": "Embarrassed-Pear-160", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vd8mx/10b_rows_or_more_in_a_core_fact_table_what_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vd8mx/10b_rows_or_more_in_a_core_fact_table_what_data/", "subreddit_subscribers": 93600, "created_utc": 1679206284.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nall is in the title :)", "author_fullname": "t2_w54e628x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How train my SQL skills with real world data engineering problems ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vyiip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679261678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;all is in the title :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vyiip", "is_robot_indexable": true, "report_reasons": null, "author": "rxmi_bkd_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "subreddit_subscribers": 93600, "created_utc": 1679261678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.\n\nThe group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.\n\nI'm working on automating this group's work, and the first step is to map out the entire data pipeline (what is everyone doing?)\n\n**How do I do this?**\n\nI've only ever mapped out small data pipelines that have a few data sources and a few processes.\n\nMy group's entire data pipeline has hundreds of different sources and thousands of Excel workbooks.\n\nI've had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.\n\n**Any suggestions?**\n\nThanks!", "author_fullname": "t2_7b3mpu85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to map out data pipeline of 500-person BI Excel team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vwhrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679257348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;The group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on automating this group&amp;#39;s work, and the first step is to map out the entire data pipeline (what is everyone doing?)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How do I do this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only ever mapped out small data pipelines that have a few data sources and a few processes.&lt;/p&gt;\n\n&lt;p&gt;My group&amp;#39;s entire data pipeline has hundreds of different sources and thousands of Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Any suggestions?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vwhrx", "is_robot_indexable": true, "report_reasons": null, "author": "BrilliantCashew", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "subreddit_subscribers": 93600, "created_utc": 1679257348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In all the companies i've been, I never saw DF api being used in production, it's all SQL due to it being easier to read. Anybody who uses DF here in production and what's the reason for doing so?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark DF api", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vfsf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679215015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In all the companies i&amp;#39;ve been, I never saw DF api being used in production, it&amp;#39;s all SQL due to it being easier to read. Anybody who uses DF here in production and what&amp;#39;s the reason for doing so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vfsf5", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vfsf5/spark_df_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vfsf5/spark_df_api/", "subreddit_subscribers": 93600, "created_utc": 1679215015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video - DataOps in action with Nessie, Iceberg and Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vlh9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11vlh9m", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2T2x1v2i6CjP2SscBfbhTk4wVZ5lpwFXzJIQ_rIK-bE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679232616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/UHLu6DXwtuA", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?auto=webp&amp;v=enabled&amp;s=556a9c845a98dfda476ee9a7eaa817a1b0a8a20c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74ba57c57db07ce1ca1a994cc7130844c3e7d76b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f105a4887d1f487fc04f777cdc875e0771e99399", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5211a8ce14953c3048e012b8675765aa24505ac0", "width": 320, "height": 240}], "variants": {}, "id": "ooxf25bw1coNvdUDTMIbE04IHNNWFquvpmAokw8nN0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11vlh9m", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vlh9m/video_dataops_in_action_with_nessie_iceberg_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/UHLu6DXwtuA", "subreddit_subscribers": 93600, "created_utc": 1679232616.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m interested in becoming a DBA but have read negative things about it. If it\u2019s not a good path nowadays, what is the closest alternative? If it\u2019s still worth pursuing DBA, what is the best path to get into the field? \n\nI enjoy SQL and python. I only have work experience in IT desktop support. I\u2019ve taken C, Java, and MySQL college courses. I haven\u2019t finished my degree yet but I am majoring in Interdisciplinary Studies with a Minor in IT. I think my degree would make it hard to get into anything CS related.", "author_fullname": "t2_7b8ka5oe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I pursue becoming a DBA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11v843r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679191367.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m interested in becoming a DBA but have read negative things about it. If it\u2019s not a good path nowadays, what is the closest alternative? If it\u2019s still worth pursuing DBA, what is the best path to get into the field? &lt;/p&gt;\n\n&lt;p&gt;I enjoy SQL and python. I only have work experience in IT desktop support. I\u2019ve taken C, Java, and MySQL college courses. I haven\u2019t finished my degree yet but I am majoring in Interdisciplinary Studies with a Minor in IT. I think my degree would make it hard to get into anything CS related.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11v843r", "is_robot_indexable": true, "report_reasons": null, "author": "FutureCareerIT", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11v843r/should_i_pursue_becoming_a_dba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11v843r/should_i_pursue_becoming_a_dba/", "subreddit_subscribers": 93600, "created_utc": 1679191367.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So as the one and only DE in my whole company, i've decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?\n\nI was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.\n\nAny insights are welcome thanks!", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First step to data quality assurance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11w31yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679272404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as the one and only DE in my whole company, i&amp;#39;ve decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?&lt;/p&gt;\n\n&lt;p&gt;I was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.&lt;/p&gt;\n\n&lt;p&gt;Any insights are welcome thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11w31yo", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "subreddit_subscribers": 93600, "created_utc": 1679272404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing the Right AWS Storage Service: A Comprehensive Guide to S3, S3N, and S3A", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vzob1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xFDuYtxF05skv0w7zFnEyeJJvkXQxsqqN1g_hNEvQ78.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679264236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?auto=webp&amp;v=enabled&amp;s=411aa08b45b75cc83e1b803e7cbc09fabc35c0aa", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=807af3da372075614dcca8bad3021574ea34f387", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a215d34a4896f8da21f7c75374bb5ba86dc87a54", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2f9f8228fd44da38e37c6ab3e8154892b6def41", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94c695eff7f14025669ba5e6cf1c003a997ef446", "width": 640, "height": 480}], "variants": {}, "id": "NlJY-Ip5F8-M2Nqay9E5tu8KMzr0rk_vWYTLZRLV6YI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vzob1", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vzob1/choosing_the_right_aws_storage_service_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "subreddit_subscribers": 93600, "created_utc": 1679264236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing Well: A Data Engineer's Advantage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11vi2mu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/aCKcvnCPr4Nq3qdahxT82Br5a1phh8995ui6m_nBOD4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679222714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@luukmes/writing-well-a-data-engineers-advantage-2fd08efaedb0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?auto=webp&amp;v=enabled&amp;s=7b09a68c46a5f57bb39ab47fff258da64b97bb86", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e595f40665ea40d9accce8abb8f68c7c89248ad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f24024bba5375eddd7c1b0491a9ded2f677c815d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f77533c2aa48d47e24a281caea9aa2d49bc5557", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35fa3cd5400e922a8664aa38178a3a7189f648bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f47c370d786a319e6630ccbac55ec4fa3fd55f21", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af706408918924f21f7a749ab00809b57acce5e4", "width": 1080, "height": 567}], "variants": {}, "id": "g-5k3S5qH_XNcRvjMJkeO_l0uH7DTOxUtt0x8qp4-a8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vi2mu", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vi2mu/writing_well_a_data_engineers_advantage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@luukmes/writing-well-a-data-engineers-advantage-2fd08efaedb0", "subreddit_subscribers": 93600, "created_utc": 1679222714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any tips on creating a script for this?\n\nI\u2019m in the middle of creating a python script that uses regex patterns to translate syntax/reorder blocks of SQL code so that it can run without error in Snowflake\n\nIt\u2019s going pretty well so far and I\u2019m just identifying the translations by attempting to run the sql files in snowflake and seeing what fails. \n\nHave you created something similar? If so it would be great if you shared all the translations you came across or any tips for the dev work! Cheers :D", "author_fullname": "t2_27wfgi26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Translating SQL to Snowflake Compatible syntax", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vel18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679210850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any tips on creating a script for this?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m in the middle of creating a python script that uses regex patterns to translate syntax/reorder blocks of SQL code so that it can run without error in Snowflake&lt;/p&gt;\n\n&lt;p&gt;It\u2019s going pretty well so far and I\u2019m just identifying the translations by attempting to run the sql files in snowflake and seeing what fails. &lt;/p&gt;\n\n&lt;p&gt;Have you created something similar? If so it would be great if you shared all the translations you came across or any tips for the dev work! Cheers :D&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vel18", "is_robot_indexable": true, "report_reasons": null, "author": "eubann", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vel18/translating_sql_to_snowflake_compatible_syntax/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vel18/translating_sql_to_snowflake_compatible_syntax/", "subreddit_subscribers": 93600, "created_utc": 1679210850.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}