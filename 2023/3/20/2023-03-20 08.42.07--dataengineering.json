{"kind": "Listing", "data": {"after": null, "dist": 13, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?", "author_fullname": "t2_h9iom7pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side hustle ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vim1y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679224430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently live in a country where the single salary is not enough for me to buy a house in the next 4 years. I am looking for new income sources. Are there any good ideas for side hustles as a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vim1y", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Leader-6040", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vim1y/side_hustle_ideas/", "subreddit_subscribers": 93625, "created_utc": 1679224430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.\n\nI am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?", "author_fullname": "t2_1eqrbzj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those of you who were self taught, what was your path into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vv3jo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679254335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to get into data engineering myself and come from an analyst background in healthcare.&lt;/p&gt;\n\n&lt;p&gt;I am curious as to what your paths into data engineering were for those who didn\u2019t come from a traditional background. What has your career path been like? How did you decide to get into DE and how did you do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11vv3jo", "is_robot_indexable": true, "report_reasons": null, "author": "xyzabc123410000", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vv3jo/for_those_of_you_who_were_self_taught_what_was/", "subreddit_subscribers": 93625, "created_utc": 1679254335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A new team member wants to rewrite all the pipeline logic into a fully OO way. \n\nSo classify everything, object calls, rewrite everything i to methods etc.\n\nAs well as data expectations, unit tests and integration tests. I do see the value and when you read any books it\u2019s all the best practice stuff. \n\nI really like it one way but it has probably tripled the time to deliver a dataset. Some of pipeline logic is simple enough at its heart.\n\nSome of our dataset logic is pretty simple in its core and you could do it within a sprint (2-3 weeks) now it\u2019s pretty challenging to deliver \n\nWe also use unit test and expectations.\n\nOn one side I want to do things the best way but on the other the client doesn\u2019t understand why deliverables are taking so long and he doesn\u2019t really see any of the benefits on the front end (yet)", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much object orienteered do you use in your projects? Bonus points for integration and unit tests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vfwse", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679215835.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679215448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A new team member wants to rewrite all the pipeline logic into a fully OO way. &lt;/p&gt;\n\n&lt;p&gt;So classify everything, object calls, rewrite everything i to methods etc.&lt;/p&gt;\n\n&lt;p&gt;As well as data expectations, unit tests and integration tests. I do see the value and when you read any books it\u2019s all the best practice stuff. &lt;/p&gt;\n\n&lt;p&gt;I really like it one way but it has probably tripled the time to deliver a dataset. Some of pipeline logic is simple enough at its heart.&lt;/p&gt;\n\n&lt;p&gt;Some of our dataset logic is pretty simple in its core and you could do it within a sprint (2-3 weeks) now it\u2019s pretty challenging to deliver &lt;/p&gt;\n\n&lt;p&gt;We also use unit test and expectations.&lt;/p&gt;\n\n&lt;p&gt;On one side I want to do things the best way but on the other the client doesn\u2019t understand why deliverables are taking so long and he doesn\u2019t really see any of the benefits on the front end (yet)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vfwse", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vfwse/how_much_object_orienteered_do_you_use_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vfwse/how_much_object_orienteered_do_you_use_in_your/", "subreddit_subscribers": 93625, "created_utc": 1679215448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So as the one and only DE in my whole company, i've decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?\n\nI was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.\n\nAny insights are welcome thanks!\n\nEdit: pipeline stack consists mainly of\n\n- BigQuery\n- Airflow\n- Python", "author_fullname": "t2_zjn67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First step to data quality assurance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11w31yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679277676.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679272404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as the one and only DE in my whole company, i&amp;#39;ve decided its time to add some data quality/pipeline checks to our system. What would be a good place to start?&lt;/p&gt;\n\n&lt;p&gt;I was thinking of integrating something like great expectations into our python scripts. Ideally something that can email me whenever something isnt within expectations or constraints.&lt;/p&gt;\n\n&lt;p&gt;Any insights are welcome thanks!&lt;/p&gt;\n\n&lt;p&gt;Edit: pipeline stack consists mainly of&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;BigQuery&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11w31yo", "is_robot_indexable": true, "report_reasons": null, "author": "Propanoate", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11w31yo/first_step_to_data_quality_assurance/", "subreddit_subscribers": 93625, "created_utc": 1679272404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nall is in the title :)", "author_fullname": "t2_w54e628x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How train my SQL skills with real world data engineering problems ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vyiip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679261678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;all is in the title :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vyiip", "is_robot_indexable": true, "report_reasons": null, "author": "rxmi_bkd_", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vyiip/how_train_my_sql_skills_with_real_world_data/", "subreddit_subscribers": 93625, "created_utc": 1679261678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.\n\nThe group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.\n\nI'm working on automating this group's work, and the first step is to map out the entire data pipeline (what is everyone doing?)\n\n**How do I do this?**\n\nI've only ever mapped out small data pipelines that have a few data sources and a few processes.\n\nMy group's entire data pipeline has hundreds of different sources and thousands of Excel workbooks.\n\nI've had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.\n\n**Any suggestions?**\n\nThanks!", "author_fullname": "t2_7b3mpu85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to map out data pipeline of 500-person BI Excel team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vwhrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679257348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a 500-person Business Intelligence and Analytics group at a big company. 90% of the group does all their work with Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;The group itself is effectively a big data pipeline: it takes in data, and outputs reporting and analysis.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on automating this group&amp;#39;s work, and the first step is to map out the entire data pipeline (what is everyone doing?)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How do I do this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only ever mapped out small data pipelines that have a few data sources and a few processes.&lt;/p&gt;\n\n&lt;p&gt;My group&amp;#39;s entire data pipeline has hundreds of different sources and thousands of Excel workbooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a few ideas: look at the business structure of my group (rather than focusing on all the Excel workbooks), and then logically understand the data pipeline based on the business structure. Also send out a survey to everyone in the group and ask about the data work they do every day.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Any suggestions?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11vwhrx", "is_robot_indexable": true, "report_reasons": null, "author": "BrilliantCashew", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vwhrx/how_to_map_out_data_pipeline_of_500person_bi/", "subreddit_subscribers": 93625, "created_utc": 1679257348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_c7c8zdg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lakehouse \u2014 A resum\u00e9", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_11vgsq4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xzRqhdW5wdYKrEiLprJjN9BCNvd-Lk838oP_52SJDkQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679218534.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/claimsforce/lakehouse-a-resum%C3%A9-750368e57914", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?auto=webp&amp;v=enabled&amp;s=cf462ffdfb5ba5e01fea229680ba6fdb6df361d4", "width": 1200, "height": 786}, "resolutions": [{"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a681a307f0bc2ed41237a6321b9c18b9fb20bdc8", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d91b223d3625b4b74141af866446dcd68c1a55e3", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c7bb75fc3194ebf57b6c362715d69f60c5d35ca", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac0990313ea305bf2d4047f67314b15ff0bc4d1a", "width": 640, "height": 419}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c9f0cda945dd435a112c44189de861e9ada4db1", "width": 960, "height": 628}, {"url": "https://external-preview.redd.it/xOVu-PIE0VroxKc3MsBEpOnIGP5ROESr1Cq__1kwuQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0186d967fec84a6cec2290fce8dff306f740061", "width": 1080, "height": 707}], "variants": {}, "id": "CR4vm1xt0XmkK7tgZG5CSJJnV_WBTvg9-Jn2XwPTOd4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vgsq4", "is_robot_indexable": true, "report_reasons": null, "author": "heyimsinged", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vgsq4/lakehouse_a_resum\u00e9/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/claimsforce/lakehouse-a-resum%C3%A9-750368e57914", "subreddit_subscribers": 93625, "created_utc": 1679218534.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for roles and responsibilities of Data Engineering Manager compared Engineering Director.", "author_fullname": "t2_q6tghhmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the roles and responsibilities of Data Engineering Manager in your organization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11w830f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679285358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for roles and responsibilities of Data Engineering Manager compared Engineering Director.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11w830f", "is_robot_indexable": true, "report_reasons": null, "author": "jimmy3579", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11w830f/what_is_the_roles_and_responsibilities_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11w830f/what_is_the_roles_and_responsibilities_of_data/", "subreddit_subscribers": 93625, "created_utc": 1679285358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing the Right AWS Storage Service: A Comprehensive Guide to S3, S3N, and S3A", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vzob1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xFDuYtxF05skv0w7zFnEyeJJvkXQxsqqN1g_hNEvQ78.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679264236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?auto=webp&amp;v=enabled&amp;s=411aa08b45b75cc83e1b803e7cbc09fabc35c0aa", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=807af3da372075614dcca8bad3021574ea34f387", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a215d34a4896f8da21f7c75374bb5ba86dc87a54", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2f9f8228fd44da38e37c6ab3e8154892b6def41", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/M1Toz3Y74CQz2Q9NDPRapLG6Cf2-EUy1ocdY4bUm2PY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94c695eff7f14025669ba5e6cf1c003a997ef446", "width": 640, "height": 480}], "variants": {}, "id": "NlJY-Ip5F8-M2Nqay9E5tu8KMzr0rk_vWYTLZRLV6YI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vzob1", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vzob1/choosing_the_right_aws_storage_service_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/choosing-the-right-aws-storage-service-a-comprehensive-guide-to-s3-s3n-and-s3a", "subreddit_subscribers": 93625, "created_utc": 1679264236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In all the companies i've been, I never saw DF api being used in production, it's all SQL due to it being easier to read. Anybody who uses DF here in production and what's the reason for doing so?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark DF api", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11vfsf5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1679215015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In all the companies i&amp;#39;ve been, I never saw DF api being used in production, it&amp;#39;s all SQL due to it being easier to read. Anybody who uses DF here in production and what&amp;#39;s the reason for doing so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11vfsf5", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vfsf5/spark_df_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11vfsf5/spark_df_api/", "subreddit_subscribers": 93625, "created_utc": 1679215015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sharing the code to draw comparison between Pandas and Polars (Rust). Results are pretty impressive for Polars.\n\n    import pandas as pd\n    import polars as pl\n    import numpy as np\n    import time\n    \n    # Create a random DataFrame with 500 MB of data\n    n_rows = 250000\n    n_cols = 400\n    df = pd.DataFrame(np.random.randn(n_rows, n_cols), columns=['col_{}'.format(i) for i in range(n_cols)])\n    df_polars = pl.from_pandas(df)\n    \n    # Benchmark Pandas 2.0\n    start_time = time.time()\n    df_filtered = df[df['col_0'] &gt; 0]\n    df_grouped = df.groupby(['col_1', 'col_2']).mean()\n    df_sorted = df.sort_values(by=['col_3'], ascending=False)\n    df_merged = pd.merge(df, df_grouped, on=['col_1', 'col_2'])\n    pandas_time = time.time() - start_time\n    \n    # Benchmark Polars Rust\n    start_time = time.time()\n    df_filtered_polars = df_polars.filter(pl.col('col_0') &gt; 0)\n    df_grouped_polars = df_polars.groupby(['col_1', 'col_2']).mean()\n    df_sorted_polars = df_polars.sort(by=['col_3']).reverse()\n    df_merged_polars = df_polars.join(df_grouped_polars, on=['col_1', 'col_2'])\n    polars_time = time.time() - start_time\n    \n    # Print results\n    print('Pandas 2.0 time: {:.2f} seconds'.format(pandas_time))\n    print('Polars Rust time: {:.2f} seconds'.format(polars_time))\n\nIf you want to increase dataframe size to 1GB:Change`n_rows = 10**6n_cols = 1000`\n\nResults:   \n\n\nPandas : 23.45 sec  \n\n\n[Pola.rs](https://Pola.rs) : 5.66 sec  \n\n\nIf you want to increase dataframe size to 100GB:", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Code]: Comparison between Rust (Polars) and Pandas | Basic Benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11wc273", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1679301270.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1679297751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing the code to draw comparison between Pandas and Polars (Rust). Results are pretty impressive for Polars.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nimport polars as pl\nimport numpy as np\nimport time\n\n# Create a random DataFrame with 500 MB of data\nn_rows = 250000\nn_cols = 400\ndf = pd.DataFrame(np.random.randn(n_rows, n_cols), columns=[&amp;#39;col_{}&amp;#39;.format(i) for i in range(n_cols)])\ndf_polars = pl.from_pandas(df)\n\n# Benchmark Pandas 2.0\nstart_time = time.time()\ndf_filtered = df[df[&amp;#39;col_0&amp;#39;] &amp;gt; 0]\ndf_grouped = df.groupby([&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;]).mean()\ndf_sorted = df.sort_values(by=[&amp;#39;col_3&amp;#39;], ascending=False)\ndf_merged = pd.merge(df, df_grouped, on=[&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;])\npandas_time = time.time() - start_time\n\n# Benchmark Polars Rust\nstart_time = time.time()\ndf_filtered_polars = df_polars.filter(pl.col(&amp;#39;col_0&amp;#39;) &amp;gt; 0)\ndf_grouped_polars = df_polars.groupby([&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;]).mean()\ndf_sorted_polars = df_polars.sort(by=[&amp;#39;col_3&amp;#39;]).reverse()\ndf_merged_polars = df_polars.join(df_grouped_polars, on=[&amp;#39;col_1&amp;#39;, &amp;#39;col_2&amp;#39;])\npolars_time = time.time() - start_time\n\n# Print results\nprint(&amp;#39;Pandas 2.0 time: {:.2f} seconds&amp;#39;.format(pandas_time))\nprint(&amp;#39;Polars Rust time: {:.2f} seconds&amp;#39;.format(polars_time))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you want to increase dataframe size to 1GB:Change&lt;code&gt;n_rows = 10**6n_cols = 1000&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Results:   &lt;/p&gt;\n\n&lt;p&gt;Pandas : 23.45 sec  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://Pola.rs\"&gt;Pola.rs&lt;/a&gt; : 5.66 sec  &lt;/p&gt;\n\n&lt;p&gt;If you want to increase dataframe size to 100GB:&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?auto=webp&amp;v=enabled&amp;s=8182b8164b2ef2edf05c1673e96e61650ef3f975", "width": 628, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c5ed42ff330568978d8b29b2f67133d1aa7669e", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b58ea26aaaca49ea579f3d1a2dad7a86e553498", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/1SSqYHD_sA84nZzwre6h8wq5Kic14hF2CZqFprUbh0U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d1614fa2d7201162e8014046bb497c8b8ad0245", "width": 320, "height": 320}], "variants": {}, "id": "GQEQ7WaJ43xmaAcrmZznZkixlQ7IFzW9Q8Sw1L0rwqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11wc273", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11wc273/code_comparison_between_rust_polars_and_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11wc273/code_comparison_between_rust_polars_and_pandas/", "subreddit_subscribers": 93625, "created_utc": 1679297751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video - DataOps in action with Nessie, Iceberg and Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11vlh9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}, "type": "youtube.com"}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11vlh9m", "height": 200}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2T2x1v2i6CjP2SscBfbhTk4wVZ5lpwFXzJIQ_rIK-bE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679232616.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/UHLu6DXwtuA", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?auto=webp&amp;v=enabled&amp;s=556a9c845a98dfda476ee9a7eaa817a1b0a8a20c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74ba57c57db07ce1ca1a994cc7130844c3e7d76b", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f105a4887d1f487fc04f777cdc875e0771e99399", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/2gb5YnT9MqBW46AWh94mdtX2hIhpzcsJuQyJc1iIQx8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5211a8ce14953c3048e012b8675765aa24505ac0", "width": 320, "height": 240}], "variants": {}, "id": "ooxf25bw1coNvdUDTMIbE04IHNNWFquvpmAokw8nN0I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11vlh9m", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vlh9m/video_dataops_in_action_with_nessie_iceberg_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/UHLu6DXwtuA", "subreddit_subscribers": 93625, "created_utc": 1679232616.0, "num_crossposts": 0, "media": {"oembed": {"provider_url": "https://www.youtube.com/", "title": "DataOps in action with Nessie, Iceberg and Great Expectations", "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/UHLu6DXwtuA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"DataOps in action with Nessie, Iceberg and Great Expectations\"&gt;&lt;/iframe&gt;", "thumbnail_width": 480, "height": 200, "width": 356, "version": "1.0", "author_name": "Dremio", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UHLu6DXwtuA/hqdefault.jpg", "type": "video", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Dremio"}, "type": "youtube.com"}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1jkhpl2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing Well: A Data Engineer's Advantage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_11vi2mu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/aCKcvnCPr4Nq3qdahxT82Br5a1phh8995ui6m_nBOD4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1679222714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@luukmes/writing-well-a-data-engineers-advantage-2fd08efaedb0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?auto=webp&amp;v=enabled&amp;s=7b09a68c46a5f57bb39ab47fff258da64b97bb86", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e595f40665ea40d9accce8abb8f68c7c89248ad", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f24024bba5375eddd7c1b0491a9ded2f677c815d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f77533c2aa48d47e24a281caea9aa2d49bc5557", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35fa3cd5400e922a8664aa38178a3a7189f648bc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f47c370d786a319e6630ccbac55ec4fa3fd55f21", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/2pI1_hBVPIFiRp8F5FOO7IcDbz_uhATt4egoWO0q4Sk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af706408918924f21f7a749ab00809b57acce5e4", "width": 1080, "height": 567}], "variants": {}, "id": "g-5k3S5qH_XNcRvjMJkeO_l0uH7DTOxUtt0x8qp4-a8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11vi2mu", "is_robot_indexable": true, "report_reasons": null, "author": "Luxi36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11vi2mu/writing_well_a_data_engineers_advantage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@luukmes/writing-well-a-data-engineers-advantage-2fd08efaedb0", "subreddit_subscribers": 93625, "created_utc": 1679222714.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}