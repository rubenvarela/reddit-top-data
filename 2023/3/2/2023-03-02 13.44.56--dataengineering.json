{"kind": "Listing", "data": {"after": "t3_11fwc7u", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on an API data ingestion project, and I usually use AWS Lambda or Python on Databricks for the whole process, but I was wondering if there are any better options/services for Extract and Load part of the process, like dbt is for data transformation.", "author_fullname": "t2_nmja4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If dbt is the \"T\" part of an \"ELT\", what do you use for \"EL\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fhmqu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677703813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on an API data ingestion project, and I usually use AWS Lambda or Python on Databricks for the whole process, but I was wondering if there are any better options/services for Extract and Load part of the process, like dbt is for data transformation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fhmqu", "is_robot_indexable": true, "report_reasons": null, "author": "we_need_more_lumber", "discussion_type": null, "num_comments": 87, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fhmqu/if_dbt_is_the_t_part_of_an_elt_what_do_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fhmqu/if_dbt_is_the_t_part_of_an_elt_what_do_you_use/", "subreddit_subscribers": 91624, "created_utc": 1677703813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Getting into Data Engineering and more!\n\nHey fellow Devs,\n\nI recently posted in this sub for some advice about a job switch,  but got a lot of queries and DMs about how I got into Data Engineering, how to get better and go from entry level to senior position or from Data Analyst to Data Engineer (DE)\n\nI'm working as a Senior Data Engineer in a Unicorn Startup in India. \n\nTrying to give back to the community from my experience in Data Engineering since 2019. Still surprised that not many are aware about what actually are the roles, the expectations from Data Engineers are. Most of the stuff is available online, videos from many youtubers, still posted it for people who might not be aware! :)\n\nWill answer FAQs about Data Engineering. Feel free to correct or improvise. \n\n**Warning: This is going to be a long post.**\n\n&gt; DE means Data Engineering\n\n\nI. As a fresher, I'm interested in Data Engineering, but how to get a job in this domain?\n\nA. Getting a job directly as a full-time DE is pretty tough. Try to apply for DE internships and maybe it will get converted to full-time or with that experience try to apply for Associate / Junior DE positions. Build a network on Linkedin with many Data Engineers and connect with them about their experience. \n\n\n\n2.  What are the required skill-sets to become a DE?\n\nA. From my experience companies expect you to be good at any one language\n\n* Python, Java or Scala\n* Strong SQL skills\n* Data warehousing\n* Spark\n* Cloud experience - AWS/Azure/GCP \\[good to atleast have an idea on how to spin up a cluster in any cloud vendor, setting up Network rules, firewall, etc.\\]\n\n\n\n3. Is DE in demand, is it better than Data Science?\n\nA. Even though all the hype on the internet is for Data Scientists, the role of Data Engineer is equally crucial and critical for companies to enable Data Scientists. \n\n* Even the pay is lucrative! \n   * Salaries may vary, but mostly ranges look like this in India\n   * Entry level DE - 4 to 10 LPA\n   * 2 - 4 years - 12 to 30 LPA\n   * 4 - 7 years - 25 - 60+ LPA\n\n4. How do the roles differ, Data Engineer vs Data Scientist vs Data Analyst\n\nA. My understanding - In the Data ecosystem\n\n1. Data Engineer - Process starts here, collecting, cleaning and transforming, ingesting data into Data warehouses or datalakes.\n\n2. Data Scientist - With the collected data in DW/DL, understand business logic and build useful data science techniques / ML models to identify key patterns, insights that can drive revenue.\n\n   3. Data Analyst - Final part in process, Visualize the insights from Data Scientists using BI tools like Tableau, Looker, etc. \n\n\n\n3. How to prepare for DE interviews, Most commonly asked interview questions?\n\n\n\n* **NOTE: In most companies, even Data Engineers are expected to be strong in DSA, since first rounds can be OA tests like Hackerrank and F2F Coding rounds before you can enter technical rounds about topics mentioned below. So, still need to Grind Leetcode to some extent!**\n* **That being said, there are still companies that focus mostly on SQL, Spark for interviews and pay lesser attention to coding skills.**\n\n\n\nAfter attending close to 40 interviews in last 4 years, the most asked interview questions for 0-3 years of experience were mostly on the following.\n\n**Must have knowledge on these concepts to crack any DE interview:**\n\nI. SQL\n\n* Aggregate functions - AVG, MIN, MAX, etc.\n* Joins - **important!** types of joins and their output.\n* Window functions - Ranking functions, LAG, LEAD\n* what is &lt;**following**\\&gt; how do they **work**, how to **create** this and why is it used, **pros** and **cons** for the **following:**\n   * CTEs\n   * Views, Materialized views\n   * Index - also types of indexes, index behind the scenes.\n   * Partitioning - types of partitioning\n* Normalization / Denormalization - rarely asked but important\n\n\n\n2. Data Warehousing (DW) and ETL\n\n* Star vs Snowflake Schema\n* DB vs DW vs Data lake, when to use appropriately\n* Choosing Columnar vs row oriented Databases\n* Facts, Dimensions - understanding, examples\n* Steps to implement a Data warehouse (for example in Bigquery)\n* Best practices for DW, reporting\n* Slowly changing dimensions\n* Handling duplicate records, inconsistencies in data.\n* Understanding ETL vs ELT process, data cleaning, ingestion techniques. \n\n\n\n3. Spark\n\n* Understading Architecture\n* YARN basics\n* Sparkcontext, session, worker, task, job, stage, etc\n* Spark dataframes, actions, transformations, reading and writing data, specifying schema options\n* Repartioning vs Coalesce\n* Partioning\n* Handling OOM error in spark\n* Broadcast variables, broadcast joins\n* Best practices of Spark, best tuning practices\n* Different persisting strategies in spark\n\n\nCloud experience\n\n* Not much questions but it is vital to have an idea on different big data tools and services available in any one Cloud platform and their use cases.\n* Most commonly used services in Cloud for Data systems\n   * AWS - S3, Redshift, Glue, RDS\n   * GCP - Cloud Storage, Bigquery, CloudSQL, Dataflow \\[for streaming\\]\n\n**Linux skills - I think this is also a very important skill and a basic requirement**\n\n \n\nOther skills to learn to become a better a niche Data Engineer,  if have the above mentioned topics covered, check these out:\n\n1. Orchestration tool - Airflow \\[slowly becoming a must have skill\\]\n2. Streaming data - Spark Streaming / Flink\n3. Pubsub systems like Kafka\n4. NoSQL databases - MongoDB, Elasticsearch, Cassandra, etc.\n5. System Design for Big Data\n\n\n\nResources: \n\n**Datacamp** is one of my most favorite platforms. It has skill tracks for Data Engineering, Python, SQL, Shell, Spark, etc.\n\nhttps://www.datacamp.com/tracks/data-engineer-with-python](https://www.datacamp.com/tracks/data-engineer-with-python\n\nhttps://www.datacamp.com/tracks/big-data-with-pyspark](https://www.datacamp.com/tracks/big-data-with-pyspark\n\n\n**I would highly recommend this but this is a paid platform though :(\n\nFeel free to explore Youtube, Coursera, Udemy for specific concepts / courses based on the topics mentioned! \n\nif you are a student, use your college ID and activate Github Student developer program, get free access to datacamp for 3 months!\n\n**Other resources I used to prep:**\n\nhttps://dataengineering.wiki/](https://dataengineering.wiki/\n\n\n\n1. **Orielly books -** for any topic, check reviews, most of them are available as PDFs in github.\n2. SQL - [pgexercises.com](https://pgexercises.com), data Lemur, Ankit Bansal on Youtube, hackerrank, Leetcode\n3. Spark - Spark by examples, Datacamp, ChatGPT recently :P,  to understand concepts with amazing analogies. \n4. DWH - Ralph Kimball book\n\nNotable YT channels: Ankit Bansal for SQL\n\nBig data folks on Linkedin : Shashank Mishra, Seattle Data Guy, Zach Wilson\n\n\nData Engineering is gaining more importance everyday. Upskill yourselves and join the ride!\n\nFeel free to correct / add on, ping me for any queries. \n\nCheers!", "author_fullname": "t2_dd74avna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting into Data Engineering and more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f95x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Getting into Data Engineering and more!&lt;/p&gt;\n\n&lt;p&gt;Hey fellow Devs,&lt;/p&gt;\n\n&lt;p&gt;I recently posted in this sub for some advice about a job switch,  but got a lot of queries and DMs about how I got into Data Engineering, how to get better and go from entry level to senior position or from Data Analyst to Data Engineer (DE)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working as a Senior Data Engineer in a Unicorn Startup in India. &lt;/p&gt;\n\n&lt;p&gt;Trying to give back to the community from my experience in Data Engineering since 2019. Still surprised that not many are aware about what actually are the roles, the expectations from Data Engineers are. Most of the stuff is available online, videos from many youtubers, still posted it for people who might not be aware! :)&lt;/p&gt;\n\n&lt;p&gt;Will answer FAQs about Data Engineering. Feel free to correct or improvise. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Warning: This is going to be a long post.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;DE means Data Engineering&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I. As a fresher, I&amp;#39;m interested in Data Engineering, but how to get a job in this domain?&lt;/p&gt;\n\n&lt;p&gt;A. Getting a job directly as a full-time DE is pretty tough. Try to apply for DE internships and maybe it will get converted to full-time or with that experience try to apply for Associate / Junior DE positions. Build a network on Linkedin with many Data Engineers and connect with them about their experience. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; What are the required skill-sets to become a DE?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. From my experience companies expect you to be good at any one language&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Python, Java or Scala&lt;/li&gt;\n&lt;li&gt;Strong SQL skills&lt;/li&gt;\n&lt;li&gt;Data warehousing&lt;/li&gt;\n&lt;li&gt;Spark&lt;/li&gt;\n&lt;li&gt;Cloud experience - AWS/Azure/GCP [good to atleast have an idea on how to spin up a cluster in any cloud vendor, setting up Network rules, firewall, etc.]&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is DE in demand, is it better than Data Science?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. Even though all the hype on the internet is for Data Scientists, the role of Data Engineer is equally crucial and critical for companies to enable Data Scientists. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Even the pay is lucrative! \n\n&lt;ul&gt;\n&lt;li&gt;Salaries may vary, but mostly ranges look like this in India&lt;/li&gt;\n&lt;li&gt;Entry level DE - 4 to 10 LPA&lt;/li&gt;\n&lt;li&gt;2 - 4 years - 12 to 30 LPA&lt;/li&gt;\n&lt;li&gt;4 - 7 years - 25 - 60+ LPA&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How do the roles differ, Data Engineer vs Data Scientist vs Data Analyst&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A. My understanding - In the Data ecosystem&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Data Engineer - Process starts here, collecting, cleaning and transforming, ingesting data into Data warehouses or datalakes.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Scientist - With the collected data in DW/DL, understand business logic and build useful data science techniques / ML models to identify key patterns, insights that can drive revenue.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Analyst - Final part in process, Visualize the insights from Data Scientists using BI tools like Tableau, Looker, etc. &lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How to prepare for DE interviews, Most commonly asked interview questions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;NOTE: In most companies, even Data Engineers are expected to be strong in DSA, since first rounds can be OA tests like Hackerrank and F2F Coding rounds before you can enter technical rounds about topics mentioned below. So, still need to Grind Leetcode to some extent!&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;That being said, there are still companies that focus mostly on SQL, Spark for interviews and pay lesser attention to coding skills.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;After attending close to 40 interviews in last 4 years, the most asked interview questions for 0-3 years of experience were mostly on the following.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Must have knowledge on these concepts to crack any DE interview:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I. SQL&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Aggregate functions - AVG, MIN, MAX, etc.&lt;/li&gt;\n&lt;li&gt;Joins - &lt;strong&gt;important!&lt;/strong&gt; types of joins and their output.&lt;/li&gt;\n&lt;li&gt;Window functions - Ranking functions, LAG, LEAD&lt;/li&gt;\n&lt;li&gt;what is &amp;lt;&lt;strong&gt;following&lt;/strong&gt;&amp;gt; how do they &lt;strong&gt;work&lt;/strong&gt;, how to &lt;strong&gt;create&lt;/strong&gt; this and why is it used, &lt;strong&gt;pros&lt;/strong&gt; and &lt;strong&gt;cons&lt;/strong&gt; for the &lt;strong&gt;following:&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;CTEs&lt;/li&gt;\n&lt;li&gt;Views, Materialized views&lt;/li&gt;\n&lt;li&gt;Index - also types of indexes, index behind the scenes.&lt;/li&gt;\n&lt;li&gt;Partitioning - types of partitioning&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Normalization / Denormalization - rarely asked but important&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Warehousing (DW) and ETL&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Star vs Snowflake Schema&lt;/li&gt;\n&lt;li&gt;DB vs DW vs Data lake, when to use appropriately&lt;/li&gt;\n&lt;li&gt;Choosing Columnar vs row oriented Databases&lt;/li&gt;\n&lt;li&gt;Facts, Dimensions - understanding, examples&lt;/li&gt;\n&lt;li&gt;Steps to implement a Data warehouse (for example in Bigquery)&lt;/li&gt;\n&lt;li&gt;Best practices for DW, reporting&lt;/li&gt;\n&lt;li&gt;Slowly changing dimensions&lt;/li&gt;\n&lt;li&gt;Handling duplicate records, inconsistencies in data.&lt;/li&gt;\n&lt;li&gt;Understanding ETL vs ELT process, data cleaning, ingestion techniques. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Spark&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Understading Architecture&lt;/li&gt;\n&lt;li&gt;YARN basics&lt;/li&gt;\n&lt;li&gt;Sparkcontext, session, worker, task, job, stage, etc&lt;/li&gt;\n&lt;li&gt;Spark dataframes, actions, transformations, reading and writing data, specifying schema options&lt;/li&gt;\n&lt;li&gt;Repartioning vs Coalesce&lt;/li&gt;\n&lt;li&gt;Partioning&lt;/li&gt;\n&lt;li&gt;Handling OOM error in spark&lt;/li&gt;\n&lt;li&gt;Broadcast variables, broadcast joins&lt;/li&gt;\n&lt;li&gt;Best practices of Spark, best tuning practices&lt;/li&gt;\n&lt;li&gt;Different persisting strategies in spark&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Cloud experience&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Not much questions but it is vital to have an idea on different big data tools and services available in any one Cloud platform and their use cases.&lt;/li&gt;\n&lt;li&gt;Most commonly used services in Cloud for Data systems\n\n&lt;ul&gt;\n&lt;li&gt;AWS - S3, Redshift, Glue, RDS&lt;/li&gt;\n&lt;li&gt;GCP - Cloud Storage, Bigquery, CloudSQL, Dataflow [for streaming]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Linux skills - I think this is also a very important skill and a basic requirement&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Other skills to learn to become a better a niche Data Engineer,  if have the above mentioned topics covered, check these out:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Orchestration tool - Airflow [slowly becoming a must have skill]&lt;/li&gt;\n&lt;li&gt;Streaming data - Spark Streaming / Flink&lt;/li&gt;\n&lt;li&gt;Pubsub systems like Kafka&lt;/li&gt;\n&lt;li&gt;NoSQL databases - MongoDB, Elasticsearch, Cassandra, etc.&lt;/li&gt;\n&lt;li&gt;System Design for Big Data&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Resources: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Datacamp&lt;/strong&gt; is one of my most favorite platforms. It has skill tracks for Data Engineering, Python, SQL, Shell, Spark, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/tracks/data-engineer-with-python%5D(https://www.datacamp.com/tracks/data-engineer-with-python\"&gt;https://www.datacamp.com/tracks/data-engineer-with-python](https://www.datacamp.com/tracks/data-engineer-with-python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.datacamp.com/tracks/big-data-with-pyspark%5D(https://www.datacamp.com/tracks/big-data-with-pyspark\"&gt;https://www.datacamp.com/tracks/big-data-with-pyspark](https://www.datacamp.com/tracks/big-data-with-pyspark&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;**I would highly recommend this but this is a paid platform though :(&lt;/p&gt;\n\n&lt;p&gt;Feel free to explore Youtube, Coursera, Udemy for specific concepts / courses based on the topics mentioned! &lt;/p&gt;\n\n&lt;p&gt;if you are a student, use your college ID and activate Github Student developer program, get free access to datacamp for 3 months!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Other resources I used to prep:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dataengineering.wiki/%5D(https://dataengineering.wiki/\"&gt;https://dataengineering.wiki/](https://dataengineering.wiki/&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Orielly books -&lt;/strong&gt; for any topic, check reviews, most of them are available as PDFs in github.&lt;/li&gt;\n&lt;li&gt;SQL - &lt;a href=\"https://pgexercises.com\"&gt;pgexercises.com&lt;/a&gt;, data Lemur, Ankit Bansal on Youtube, hackerrank, Leetcode&lt;/li&gt;\n&lt;li&gt;Spark - Spark by examples, Datacamp, ChatGPT recently :P,  to understand concepts with amazing analogies. &lt;/li&gt;\n&lt;li&gt;DWH - Ralph Kimball book&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Notable YT channels: Ankit Bansal for SQL&lt;/p&gt;\n\n&lt;p&gt;Big data folks on Linkedin : Shashank Mishra, Seattle Data Guy, Zach Wilson&lt;/p&gt;\n\n&lt;p&gt;Data Engineering is gaining more importance everyday. Upskill yourselves and join the ride!&lt;/p&gt;\n\n&lt;p&gt;Feel free to correct / add on, ping me for any queries. &lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f95x7", "is_robot_indexable": true, "report_reasons": null, "author": "Simple_Bunch8526", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f95x7/getting_into_data_engineering_and_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f95x7/getting_into_data_engineering_and_more/", "subreddit_subscribers": 91624, "created_utc": 1677690468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:\n\n1. Current title\n\n2. Years of experience (YOE)\n\n3. Location\n\n4. Base salary &amp; currency (dollars, euro, pesos, etc.)\n\n5. Bonuses/Equity (optional)\n\n6. Industry (optional)\n\n7. Tech stack (optional)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quarterly Salary Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/ef3eb514-328d-4549-a705-94c26963d79b", "link_ids": ["t3_npxcqc", "t3_pfwuyg", "t3_r6jfnm", "t3_t4clep", "t3_v2ka3w", "t3_x3bb11", "t3_z9szj1", "t3_11f8yxo"], "description": "", "title": "Data Engineering Salaries", "created_at_utc": 1621559056.076, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "ef3eb514-328d-4549-a705-94c26963d79b", "author_id": "t2_2tv9i42n", "last_update_utc": 1677690034.814, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8yxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering. Please comment below and include the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Current title&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Years of experience (YOE)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Location&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Base salary &amp;amp; currency (dollars, euro, pesos, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Bonuses/Equity (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Industry (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Tech stack (optional)&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11f8yxo", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 40, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8yxo/quarterly_salary_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/11f8yxo/quarterly_salary_discussion/", "subreddit_subscribers": 91624, "created_utc": 1677690034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company didn't give raises this year, so wanted to survey if that was common. \n\nRaise: 0%  \nYOE: 5  \nIndustry: Healthcare", "author_fullname": "t2_x2qa5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2023 Raise Survey", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fg6vq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677701266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company didn&amp;#39;t give raises this year, so wanted to survey if that was common. &lt;/p&gt;\n\n&lt;p&gt;Raise: 0%&lt;br/&gt;\nYOE: 5&lt;br/&gt;\nIndustry: Healthcare&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fg6vq", "is_robot_indexable": true, "report_reasons": null, "author": "fadeghost12345", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fg6vq/2023_raise_survey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fg6vq/2023_raise_survey/", "subreddit_subscribers": 91624, "created_utc": 1677701266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel sometimes like this sub is a bit of a dbt / snowflake / sql love-in. Nothing wrong with that stack or skillset btw but I thought that stuff was more for analytics engineers?\n\nI am more involved in the platforms &amp; ingestion side of things. Lots of IaC for setting up data infrastructure, maintaining a streaming solution, working with SWE teams to ingest data from their apps and OLTP systems in a transactional and performant manner, and implementing things like data contracts and schema validation to stop upstream breaking changes. Some custom integrations using python and various AWS services to pull external data sources. I'm also pretty good with spark and do some initial validation, transformations &amp; optimizations etc in the warehouse before handing over to the modelers.\n\nGot to be other people like me here but I guess we're in a minority? Curious to hear where the boundary between DE and AE lies in your business?", "author_fullname": "t2_18xb5x05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any other DEs here not involved in data warehousing / data modeling? Where's the love for the infrastructure and ingestion guys?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fyslh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677750450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel sometimes like this sub is a bit of a dbt / snowflake / sql love-in. Nothing wrong with that stack or skillset btw but I thought that stuff was more for analytics engineers?&lt;/p&gt;\n\n&lt;p&gt;I am more involved in the platforms &amp;amp; ingestion side of things. Lots of IaC for setting up data infrastructure, maintaining a streaming solution, working with SWE teams to ingest data from their apps and OLTP systems in a transactional and performant manner, and implementing things like data contracts and schema validation to stop upstream breaking changes. Some custom integrations using python and various AWS services to pull external data sources. I&amp;#39;m also pretty good with spark and do some initial validation, transformations &amp;amp; optimizations etc in the warehouse before handing over to the modelers.&lt;/p&gt;\n\n&lt;p&gt;Got to be other people like me here but I guess we&amp;#39;re in a minority? Curious to hear where the boundary between DE and AE lies in your business?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fyslh", "is_robot_indexable": true, "report_reasons": null, "author": "the-data-scientist", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fyslh/any_other_des_here_not_involved_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fyslh/any_other_des_here_not_involved_in_data/", "subreddit_subscribers": 91624, "created_utc": 1677750450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I went from actuarial consultant pushing Excel dashboards and munging data in R, to a Data Science consultant that played whatever roles that got me billable hours, mostly advanced analytics/dashboard building, and data engineering as it was always in demand. I worked a lot of hours and have been pretty good at keeping up with the cutting edge technology due to my 10 years of consulting experience.  Actuaries are praised for their statistical domain knowledge and (in prior years) their ability to process and analyze data. Insurance industry is huge and Actuaries are the best Excel Monkies you can find.\n\nThough my title has changed over the years, my day to day hasn't changed: someone has a problem and I have to solve it. The tools I use are bound to the stakeholder I'm working with and the timeline is yesterday. Reinforcements are unlikely on the way until I improve the bottom line. It's all about finding the bottlenecks in processes and either fixing it or proving it's not repairable and finding a path forward. It all comes down to money. Save us $200k a year and you can have a developer. If not, work more or sell more.\n\nData industry is constantly changes and best practices have gone out the window. Warehouse is not best practice and now Lakehouse architecture is best. Maybe custom isn't best and we need a platform. Project Managers have entered the industry and SCRUM and Story Grooming are trigger words for veterans. Titles on LinkedIn hardly make sense anymore and you can tell it doesn't make sense to whoever crafted the JD (ChatGPT prolly). \n\nThere's also a lot of merging data engineering with DevOps and companies that do not have a proper analytics practice may have Data Engineers working under Software Engineering. So there's been a lot more demand for people that have breadth instead of depth. How long will it take this new hire to get up to speed until we're not sinking more costs and stressing more people out by having an additional person to explain things to. It's less about the title and more about the person you're hiring. The unicorns are the ones that can adapt to new problems quickly and have enough experience to figure it out on their own with a properly scoped project.\n\nHas anyone else seen similar trends? If we had to recategorize data roles similar to software engineering, what would those titles be?\n\nFor instance, I now work as a Solution Architect which is a sexy ass title for someone in data, but meaningless outside of the industry cause there's no definition to what it means. I think it's very similar to a Software Arcitecht, if not a direct subset specific to data oriented field. Knowing all of the current best practices and technologies and knowing which parts are worth salvaging vs recreating and providing diagraming/documentation of the \"why\". I don't know Java and took a course on CS when a 125MB Flash drive that cost $60 and the school didn't have Wifi lol. But knowing whether we should use Python vs R vs Java vs Scala vs SQL and how much it's going to cost us per month to run all of these reports for a given periodicity is more valuable to a business than being able to create an algorithm that can create a palindrome.", "author_fullname": "t2_rdm9w1f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you consider a full stack data developer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8txm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677689709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I went from actuarial consultant pushing Excel dashboards and munging data in R, to a Data Science consultant that played whatever roles that got me billable hours, mostly advanced analytics/dashboard building, and data engineering as it was always in demand. I worked a lot of hours and have been pretty good at keeping up with the cutting edge technology due to my 10 years of consulting experience.  Actuaries are praised for their statistical domain knowledge and (in prior years) their ability to process and analyze data. Insurance industry is huge and Actuaries are the best Excel Monkies you can find.&lt;/p&gt;\n\n&lt;p&gt;Though my title has changed over the years, my day to day hasn&amp;#39;t changed: someone has a problem and I have to solve it. The tools I use are bound to the stakeholder I&amp;#39;m working with and the timeline is yesterday. Reinforcements are unlikely on the way until I improve the bottom line. It&amp;#39;s all about finding the bottlenecks in processes and either fixing it or proving it&amp;#39;s not repairable and finding a path forward. It all comes down to money. Save us $200k a year and you can have a developer. If not, work more or sell more.&lt;/p&gt;\n\n&lt;p&gt;Data industry is constantly changes and best practices have gone out the window. Warehouse is not best practice and now Lakehouse architecture is best. Maybe custom isn&amp;#39;t best and we need a platform. Project Managers have entered the industry and SCRUM and Story Grooming are trigger words for veterans. Titles on LinkedIn hardly make sense anymore and you can tell it doesn&amp;#39;t make sense to whoever crafted the JD (ChatGPT prolly). &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also a lot of merging data engineering with DevOps and companies that do not have a proper analytics practice may have Data Engineers working under Software Engineering. So there&amp;#39;s been a lot more demand for people that have breadth instead of depth. How long will it take this new hire to get up to speed until we&amp;#39;re not sinking more costs and stressing more people out by having an additional person to explain things to. It&amp;#39;s less about the title and more about the person you&amp;#39;re hiring. The unicorns are the ones that can adapt to new problems quickly and have enough experience to figure it out on their own with a properly scoped project.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else seen similar trends? If we had to recategorize data roles similar to software engineering, what would those titles be?&lt;/p&gt;\n\n&lt;p&gt;For instance, I now work as a Solution Architect which is a sexy ass title for someone in data, but meaningless outside of the industry cause there&amp;#39;s no definition to what it means. I think it&amp;#39;s very similar to a Software Arcitecht, if not a direct subset specific to data oriented field. Knowing all of the current best practices and technologies and knowing which parts are worth salvaging vs recreating and providing diagraming/documentation of the &amp;quot;why&amp;quot;. I don&amp;#39;t know Java and took a course on CS when a 125MB Flash drive that cost $60 and the school didn&amp;#39;t have Wifi lol. But knowing whether we should use Python vs R vs Java vs Scala vs SQL and how much it&amp;#39;s going to cost us per month to run all of these reports for a given periodicity is more valuable to a business than being able to create an algorithm that can create a palindrome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f8txm", "is_robot_indexable": true, "report_reasons": null, "author": "keeney_arcadia", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8txm/what_do_you_consider_a_full_stack_data_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f8txm/what_do_you_consider_a_full_stack_data_developer/", "subreddit_subscribers": 91624, "created_utc": 1677689709.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am loading a large table from Snowflake into Power BI using \"import mode\"\n\nThe table is around 20 million rows and 25 columns and it take around 15 mins to be totally loaded into Power BI\n\nThe query finished executing on Snowflake in less that 2 mins and the remaining time was spent on transferring the data to Power BI\n\nWe tried loading the same table from SQL Server it was ~7x faster\n\nis there anything I can do to decrease the transfer time of the data from Snowflake to Power Bi and still use the \"import mode\"\n\nI am using the latest Snowflake ODBC Driver, version 2.25.9 on Windows", "author_fullname": "t2_a3lkw6g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake is slow with Power BI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f6na7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677684544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am loading a large table from Snowflake into Power BI using &amp;quot;import mode&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The table is around 20 million rows and 25 columns and it take around 15 mins to be totally loaded into Power BI&lt;/p&gt;\n\n&lt;p&gt;The query finished executing on Snowflake in less that 2 mins and the remaining time was spent on transferring the data to Power BI&lt;/p&gt;\n\n&lt;p&gt;We tried loading the same table from SQL Server it was ~7x faster&lt;/p&gt;\n\n&lt;p&gt;is there anything I can do to decrease the transfer time of the data from Snowflake to Power Bi and still use the &amp;quot;import mode&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I am using the latest Snowflake ODBC Driver, version 2.25.9 on Windows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11f6na7", "is_robot_indexable": true, "report_reasons": null, "author": "nobel-001", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f6na7/snowflake_is_slow_with_power_bi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f6na7/snowflake_is_slow_with_power_bi/", "subreddit_subscribers": 91624, "created_utc": 1677684544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now, I'm still focused on getting a good foundation for most of the industry tools. Some things that I'm working to get more exposure to are Spark, Kafka, and datawarehouse management. I have a workable competency for most of the other major tools/concepts. \n\nI'm wondering if I should also prioritize learning a low-mid level language? I sometimes feel like my computer science foundational skills are very lacking. I also have had to look up stuff when certain technologies require things related to computer networking, ports, etc.", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a self taught programmer, is it necessary to learn a low-mid level level language?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fkmvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677710527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now, I&amp;#39;m still focused on getting a good foundation for most of the industry tools. Some things that I&amp;#39;m working to get more exposure to are Spark, Kafka, and datawarehouse management. I have a workable competency for most of the other major tools/concepts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if I should also prioritize learning a low-mid level language? I sometimes feel like my computer science foundational skills are very lacking. I also have had to look up stuff when certain technologies require things related to computer networking, ports, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fkmvz", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11fkmvz/as_a_self_taught_programmer_is_it_necessary_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fkmvz/as_a_self_taught_programmer_is_it_necessary_to/", "subreddit_subscribers": 91624, "created_utc": 1677710527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849](https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing the Top 3 Schema Management Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f3agn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677675922.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849\"&gt;https://medium.com/memphis-dev/comparing-top-3-schema-management-tools-4f3e5561e849&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?auto=webp&amp;v=enabled&amp;s=d5a315406c4b243e16dd97652a66097e6dfe99d8", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40f464226f4706e9d84d5b0dd10a47a43f773281", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83efe3747c9101a68c36469b87cd471901acbc16", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=920d05bcdaa6446581df8bc5e9869331308f6096", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e3e23528c6cc1032b31d31060b48cc8bd3c94ce5", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3654b4712847ba4aac1a8eafd7c4d557ad70c47", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/5xpQd43dPit1KPEqXTy1Aa9AYMQjM_qPsmf0C2tiI1o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2473afe5676df4bd1292081c5f19ac7d7f68ada5", "width": 1080, "height": 607}], "variants": {}, "id": "kvmx4jjWHaJLdHWOmLYo5GeokUifMuiaOh-3__iBVyc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11f3agn", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f3agn/comparing_the_top_3_schema_management_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f3agn/comparing_the_top_3_schema_management_tools/", "subreddit_subscribers": 91624, "created_utc": 1677675922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1677690047.203, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f8z5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677690046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f8z5h", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f8z5h/monthly_general_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/11f8z5h/monthly_general_discussion/", "subreddit_subscribers": 91624, "created_utc": 1677690046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a painful software product that can only drop files in a certain location, including end user, specific generated reports. Currently we have a few bash scripts that move the files out and around to personal drives or shared drives but it seems like this is a risk for turning into a future tangled mess.\n\nIs anyone using orchestration tools, like Prefect, Airflow for file movement or is bash scripts the way to go?", "author_fullname": "t2_ao7u40a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Silly question, but curious how everyone else handles it. How are you orchestrating file movement around your organizations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ff8by", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677700133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a painful software product that can only drop files in a certain location, including end user, specific generated reports. Currently we have a few bash scripts that move the files out and around to personal drives or shared drives but it seems like this is a risk for turning into a future tangled mess.&lt;/p&gt;\n\n&lt;p&gt;Is anyone using orchestration tools, like Prefect, Airflow for file movement or is bash scripts the way to go?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ff8by", "is_robot_indexable": true, "report_reasons": null, "author": "minormisgnomer", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ff8by/silly_question_but_curious_how_everyone_else/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ff8by/silly_question_but_curious_how_everyone_else/", "subreddit_subscribers": 91624, "created_utc": 1677700133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI'm working on an Airflow project where we have 20 parallel pipelines, independent of each other. We currently use YAML configuration files to define the pipelines, and our DAG loops over these pipelines to complete the same tasks for each of them.\n\nWe're facing two challenges that we're trying to solve:\n\n1. We have pipelines with different processing times, and files for these pipelines arrive at different times. We're trying to avoid splitting them into separate DAGs and instead, create a single DAG that checks for files at different times and processes them accordingly. Is this a good approach? How can we avoid failing the tasks if the files are not available at the time when the DAG checks for them?\n2. We want to optimize resource utilization and reduce the load on the scheduler. Currently, we use a single DAG that checks for files every x minutes, even when there are no files to process. We're thinking of grouping pipelines based on the time when the files arrive to create separate DAGs that run only when the files are present. Does this make sense? How significant is the resource use for the OmegaFileSensor poking every 30 minutes?\n\nWe're considering these options, but we're not sure which one is the best approach. I'd love to hear your thoughts and experiences.\n\nThanks in advance for your help!", "author_fullname": "t2_gfx5s46h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage Airflow DAGs and optimize resource utilization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fvvul", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677740399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on an Airflow project where we have 20 parallel pipelines, independent of each other. We currently use YAML configuration files to define the pipelines, and our DAG loops over these pipelines to complete the same tasks for each of them.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re facing two challenges that we&amp;#39;re trying to solve:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We have pipelines with different processing times, and files for these pipelines arrive at different times. We&amp;#39;re trying to avoid splitting them into separate DAGs and instead, create a single DAG that checks for files at different times and processes them accordingly. Is this a good approach? How can we avoid failing the tasks if the files are not available at the time when the DAG checks for them?&lt;/li&gt;\n&lt;li&gt;We want to optimize resource utilization and reduce the load on the scheduler. Currently, we use a single DAG that checks for files every x minutes, even when there are no files to process. We&amp;#39;re thinking of grouping pipelines based on the time when the files arrive to create separate DAGs that run only when the files are present. Does this make sense? How significant is the resource use for the OmegaFileSensor poking every 30 minutes?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We&amp;#39;re considering these options, but we&amp;#39;re not sure which one is the best approach. I&amp;#39;d love to hear your thoughts and experiences.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fvvul", "is_robot_indexable": true, "report_reasons": null, "author": "LeftHelicopter5297", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fvvul/how_to_manage_airflow_dags_and_optimize_resource/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fvvul/how_to_manage_airflow_dags_and_optimize_resource/", "subreddit_subscribers": 91624, "created_utc": 1677740399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I\u2019m just venturing into the Data Engineering world and working towards building my first project which I\u2019m building on GCP. I had a question about the flow and storage of data. Once I extract the raw data \u2014&gt; store it in Google Cloud Storage (GCS) (or Data Lake) \u2014&gt;Pull data from GCS and transform it (change data types, remove nulls etc) \u2014&gt; Load it into Big Query (Data Warehouse); is it ok to also store the transformed data in GCS or would it be considered repetitive and waste of storage space? My main confusion is if this is an acceptable practice or not. TIA", "author_fullname": "t2_6qagmcox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Question about ELT pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fty7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677734430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m just venturing into the Data Engineering world and working towards building my first project which I\u2019m building on GCP. I had a question about the flow and storage of data. Once I extract the raw data \u2014&amp;gt; store it in Google Cloud Storage (GCS) (or Data Lake) \u2014&amp;gt;Pull data from GCS and transform it (change data types, remove nulls etc) \u2014&amp;gt; Load it into Big Query (Data Warehouse); is it ok to also store the transformed data in GCS or would it be considered repetitive and waste of storage space? My main confusion is if this is an acceptable practice or not. TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fty7b", "is_robot_indexable": true, "report_reasons": null, "author": "nomadicjourneys", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fty7b/beginner_question_about_elt_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fty7b/beginner_question_about_elt_pipeline/", "subreddit_subscribers": 91624, "created_utc": 1677734430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, would really like my next career move to be in a senior position and would love feedback on how to best prepare for that. Since graduating a little over 3 years ago I have worked at 2 startups as the first DE hire, which has been great for hands on experience and top to bottom of funnel experience, but hasn't been great for mentorship.  Being startups, I've additionally had to do a lot of platform, ML, and software engineering work. This has made me very much a generalist, and not a specialist at anything. What are the main skillsets that are required to make the jump to Senior Data Engineer? As I've had a very hard time getting that first interview when applying.\n\nmy very high level background for context\n\nDE Architecture: \n\n\\- Full lake house architecture and data warehouse design and build (2x)\n\n\\- Custom blue/green deployment for zero data downtime\n\nTools/Infrastructure: \n\n\\- Pulumi/Terraform to manage resources (databricks, s3, sqs, etc.), permission (rbac), compute, etc.\n\n\\- AWS DMS for data migration\n\n\\- AWS SQS/SNS for streaming notifications\n\n\\- Databricks (DLT), Postgres, aurora, MongoDb, Snowflake,\n\nML Ops:\n\n\\- Integrated models into production code base (javascript)\n\n\\- Custom ML labeling and auto retrain pipelines (logging, label-studio, data collection, etc.)\n\nWeb Scraping:\n\n\\- BFS web crawler (saving har files and parsing responses to reduce dev maintenance time)\n\n\\- Puppeteer html/css manipulation for ML model to handle iframes, css styling, hidden elements, etc.", "author_fullname": "t2_2nfde5yl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to Senior DE Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fs2n0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677729094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, would really like my next career move to be in a senior position and would love feedback on how to best prepare for that. Since graduating a little over 3 years ago I have worked at 2 startups as the first DE hire, which has been great for hands on experience and top to bottom of funnel experience, but hasn&amp;#39;t been great for mentorship.  Being startups, I&amp;#39;ve additionally had to do a lot of platform, ML, and software engineering work. This has made me very much a generalist, and not a specialist at anything. What are the main skillsets that are required to make the jump to Senior Data Engineer? As I&amp;#39;ve had a very hard time getting that first interview when applying.&lt;/p&gt;\n\n&lt;p&gt;my very high level background for context&lt;/p&gt;\n\n&lt;p&gt;DE Architecture: &lt;/p&gt;\n\n&lt;p&gt;- Full lake house architecture and data warehouse design and build (2x)&lt;/p&gt;\n\n&lt;p&gt;- Custom blue/green deployment for zero data downtime&lt;/p&gt;\n\n&lt;p&gt;Tools/Infrastructure: &lt;/p&gt;\n\n&lt;p&gt;- Pulumi/Terraform to manage resources (databricks, s3, sqs, etc.), permission (rbac), compute, etc.&lt;/p&gt;\n\n&lt;p&gt;- AWS DMS for data migration&lt;/p&gt;\n\n&lt;p&gt;- AWS SQS/SNS for streaming notifications&lt;/p&gt;\n\n&lt;p&gt;- Databricks (DLT), Postgres, aurora, MongoDb, Snowflake,&lt;/p&gt;\n\n&lt;p&gt;ML Ops:&lt;/p&gt;\n\n&lt;p&gt;- Integrated models into production code base (javascript)&lt;/p&gt;\n\n&lt;p&gt;- Custom ML labeling and auto retrain pipelines (logging, label-studio, data collection, etc.)&lt;/p&gt;\n\n&lt;p&gt;Web Scraping:&lt;/p&gt;\n\n&lt;p&gt;- BFS web crawler (saving har files and parsing responses to reduce dev maintenance time)&lt;/p&gt;\n\n&lt;p&gt;- Puppeteer html/css manipulation for ML model to handle iframes, css styling, hidden elements, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11fs2n0", "is_robot_indexable": true, "report_reasons": null, "author": "pmarct", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fs2n0/transition_to_senior_de_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fs2n0/transition_to_senior_de_advice/", "subreddit_subscribers": 91624, "created_utc": 1677729094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hope this is the right place to ask.\n\nSo essentially I\u2018ve been trying to remodel our companies data from two separate web shop projects into a star schema for data analysis with PowerBi.\n\n\nThe issue I\u2018ve encountered which I do not seem to get around, even after doing quite a bit of research is: How to model subscriptions/contracts in relation with orders\u2026\n\nSo the business works as follows: Customers can make orders, the first order a customer makes initiates a contract(or subscription) which essentially runs until the end of the year and is renewed(unless cancelled).\n\nSo a contract can be associated with multiple orders.\nNow I am trying to analyze the amount of contracts that have been extended (or not extended) and created a Fact table essentially containing all contracts, with contract_id as a primary key, contract_start, contract end, and surrogate keys for dimensions such as termination reason, contract state.,contract notice date etc.\n\n\nHowever my main issue here would that, that I\u2018d have to link my Contracts Fact table with my dimension fact table through contract_id, if I want to get further information about the contracts\u2026 but that would break the rules of a Kimball star schema. \n\nIs there any correct way to model this?", "author_fullname": "t2_baxqioo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kimball Data Modeling: Problem with two related Fact tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fm7re", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677714215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this is the right place to ask.&lt;/p&gt;\n\n&lt;p&gt;So essentially I\u2018ve been trying to remodel our companies data from two separate web shop projects into a star schema for data analysis with PowerBi.&lt;/p&gt;\n\n&lt;p&gt;The issue I\u2018ve encountered which I do not seem to get around, even after doing quite a bit of research is: How to model subscriptions/contracts in relation with orders\u2026&lt;/p&gt;\n\n&lt;p&gt;So the business works as follows: Customers can make orders, the first order a customer makes initiates a contract(or subscription) which essentially runs until the end of the year and is renewed(unless cancelled).&lt;/p&gt;\n\n&lt;p&gt;So a contract can be associated with multiple orders.\nNow I am trying to analyze the amount of contracts that have been extended (or not extended) and created a Fact table essentially containing all contracts, with contract_id as a primary key, contract_start, contract end, and surrogate keys for dimensions such as termination reason, contract state.,contract notice date etc.&lt;/p&gt;\n\n&lt;p&gt;However my main issue here would that, that I\u2018d have to link my Contracts Fact table with my dimension fact table through contract_id, if I want to get further information about the contracts\u2026 but that would break the rules of a Kimball star schema. &lt;/p&gt;\n\n&lt;p&gt;Is there any correct way to model this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fm7re", "is_robot_indexable": true, "report_reasons": null, "author": "DalaiLamaRood", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fm7re/kimball_data_modeling_problem_with_two_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fm7re/kimball_data_modeling_problem_with_two_related/", "subreddit_subscribers": 91624, "created_utc": 1677714215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does the worker size impact cost and performance for Apache Spark on EMR AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_11ffhtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FW68Rydd6tcxOxmSd4TMCa8HOS_J4LMnaz5IDbe4ufo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677700438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@jeffchousync/how-does-the-worker-size-impact-cost-and-performance-for-apache-spark-on-emr-aws-b47825940bea", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?auto=webp&amp;v=enabled&amp;s=acdbb1d014ef2fa2fe034a71a296df8d91e03ce7", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dec136b5f48a18970f5a0ad53565dd72f571023b", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70caa8959a6fa24d6b112cb6e6f99ae757b0c73a", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5526956b60a4f4f8f26c0348c3c5713777ed3569", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5112bd5530475695da0e56cd4eea0b10c78570a5", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08e8c1cad4d9c0d7daaaea6b615b834be67e59e9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/XK2-pXHPjFloT5Pqf1h_4_A1Ds7lMllOrOD1ayPwL0Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2d553605eb407bac27d2e332fb0dd744ccb6265", "width": 1080, "height": 719}], "variants": {}, "id": "IY8-up0YVxwJorfOejgi2VFe1JTmcTZDmR-HkSyugJA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11ffhtx", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ffhtx/how_does_the_worker_size_impact_cost_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@jeffchousync/how-does-the-worker-size-impact-cost-and-performance-for-apache-spark-on-emr-aws-b47825940bea", "subreddit_subscribers": 91624, "created_utc": 1677700438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw there is \u201chive\u201d partitions format that is like \u201cyear=2023/month=3/day=1\u201d but also \u201c2023/3/1\u201d. What are the benefits/which one is the most common and preferred? I guess the Hive one as Hive metastore is often used for tools like Databricks delta lake, Trino etc.?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lake partitions format", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11f3hpt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677676492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw there is \u201chive\u201d partitions format that is like \u201cyear=2023/month=3/day=1\u201d but also \u201c2023/3/1\u201d. What are the benefits/which one is the most common and preferred? I guess the Hive one as Hive metastore is often used for tools like Databricks delta lake, Trino etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11f3hpt", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11f3hpt/data_lake_partitions_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11f3hpt/data_lake_partitions_format/", "subreddit_subscribers": 91624, "created_utc": 1677676492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_74pfheof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tabular is GA (Iceberg Founders)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fr7wl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677726823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tabular.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tabular.io/blog/announcing-tabular/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11fr7wl", "is_robot_indexable": true, "report_reasons": null, "author": "No_Equivalent5942", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fr7wl/tabular_is_ga_iceberg_founders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tabular.io/blog/announcing-tabular/", "subreddit_subscribers": 91624, "created_utc": 1677726823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a junior computer technician / Junior programmer and I have been working on an inventory management system in C# using dapper and MariaDB , thing is I need to figure out a way to manage items sold in boxes with the particularity being these boxes can be sold by items instead of boxes and I need to keep an accurate track of how many individual items I have as well as said boxes. Im contemplating the idea of just remove X amount of items to the contained product everytime a Box is removed from the inventory but it feels wrongs to do it this way. Would really like the point of view of people with more experience on how to manage this database wise (And or C# wise)", "author_fullname": "t2_qmmqdk5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips regarding product management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fmqcu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677715469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a junior computer technician / Junior programmer and I have been working on an inventory management system in C# using dapper and MariaDB , thing is I need to figure out a way to manage items sold in boxes with the particularity being these boxes can be sold by items instead of boxes and I need to keep an accurate track of how many individual items I have as well as said boxes. Im contemplating the idea of just remove X amount of items to the contained product everytime a Box is removed from the inventory but it feels wrongs to do it this way. Would really like the point of view of people with more experience on how to manage this database wise (And or C# wise)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fmqcu", "is_robot_indexable": true, "report_reasons": null, "author": "Psychot75", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fmqcu/tips_regarding_product_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fmqcu/tips_regarding_product_management/", "subreddit_subscribers": 91624, "created_utc": 1677715469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At mine we have a single central data science server that connects to the data warehouse/databases and has all the credentials. There is a different user on the server for each employee - access is never direct via SSH but through a Jupyter notebook. Each user on the server has their own copies of the git repository that they copy updates to. This is done for security and simplicity - not every employee stores database connection credentials on their computer. One drawback is editing code on a different server than the one you are running on (this makes it difficult to grep, use git, custom IDE's etc.)\n\nSome alternatives I can think of are:\n\nA different data science server for every employee. This way employees can use any OS for their personal computer but run queries on a universal (docker image?) environment so that they don't have to install anything custom. Also the compute is not centered on a single server - everyone can run queries, edit code, login at the same time via SSH.\n\nAllow the employees to store database credentials on their own computer. This allows ultimate flexibility for the employees to edit the queries, run jobs, etc. at the cost of security. Compute could be done really locally (duckdb, pandas, etc) or by running queries on the cloud data warehouse and let that thing worry about concurrency.\n\nWhat do you do?", "author_fullname": "t2_b3n9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do Data Engineers, Scientists, and Analysts run queries at your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11flx0o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677714097.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677713493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At mine we have a single central data science server that connects to the data warehouse/databases and has all the credentials. There is a different user on the server for each employee - access is never direct via SSH but through a Jupyter notebook. Each user on the server has their own copies of the git repository that they copy updates to. This is done for security and simplicity - not every employee stores database connection credentials on their computer. One drawback is editing code on a different server than the one you are running on (this makes it difficult to grep, use git, custom IDE&amp;#39;s etc.)&lt;/p&gt;\n\n&lt;p&gt;Some alternatives I can think of are:&lt;/p&gt;\n\n&lt;p&gt;A different data science server for every employee. This way employees can use any OS for their personal computer but run queries on a universal (docker image?) environment so that they don&amp;#39;t have to install anything custom. Also the compute is not centered on a single server - everyone can run queries, edit code, login at the same time via SSH.&lt;/p&gt;\n\n&lt;p&gt;Allow the employees to store database credentials on their own computer. This allows ultimate flexibility for the employees to edit the queries, run jobs, etc. at the cost of security. Compute could be done really locally (duckdb, pandas, etc) or by running queries on the cloud data warehouse and let that thing worry about concurrency.&lt;/p&gt;\n\n&lt;p&gt;What do you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11flx0o", "is_robot_indexable": true, "report_reasons": null, "author": "third_dude", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11flx0o/how_do_data_engineers_scientists_and_analysts_run/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11flx0o/how_do_data_engineers_scientists_and_analysts_run/", "subreddit_subscribers": 91624, "created_utc": 1677713493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for books and articles about data discovering, modeling and cataloging, more specifically about the part of talking with the business team to map and document their processes and systems. I have encountered many materials about these main topics, but it's been real hard to find content about this initial phase of documenting systems, accountabilities, the data that is being created by them, their schemas etc. \n\nI've read about Data Contracts and they seem like a good format to follow in these documentations, but it's still not clear how can I proceed correctly in extracting these informations from the business teams.\n\nDoes someone have articles, books or even some experience to share?", "author_fullname": "t2_wocux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips on Data Discovering/Cataloging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ff3w2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677699990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for books and articles about data discovering, modeling and cataloging, more specifically about the part of talking with the business team to map and document their processes and systems. I have encountered many materials about these main topics, but it&amp;#39;s been real hard to find content about this initial phase of documenting systems, accountabilities, the data that is being created by them, their schemas etc. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read about Data Contracts and they seem like a good format to follow in these documentations, but it&amp;#39;s still not clear how can I proceed correctly in extracting these informations from the business teams.&lt;/p&gt;\n\n&lt;p&gt;Does someone have articles, books or even some experience to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ff3w2", "is_robot_indexable": true, "report_reasons": null, "author": "Douglas_Reis", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ff3w2/tips_on_data_discoveringcataloging/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ff3w2/tips_on_data_discoveringcataloging/", "subreddit_subscribers": 91624, "created_utc": 1677699990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m working on a project to make sure that our database is always in sync across the 3 environments (DEV, QA, PROD) and I was wondering, if you use snowflake, how do you keep your database in sync across the 3 environments? \n\nDo you just copy all the files from the S3 Bucket for PROD to the S3 buckets for DEV &amp; QA and run your ETL/ELT for each environment every day?", "author_fullname": "t2_8wpw0e1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep DEV, QA, &amp; PROD environments in Sync in Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fa0gx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677692425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a project to make sure that our database is always in sync across the 3 environments (DEV, QA, PROD) and I was wondering, if you use snowflake, how do you keep your database in sync across the 3 environments? &lt;/p&gt;\n\n&lt;p&gt;Do you just copy all the files from the S3 Bucket for PROD to the S3 buckets for DEV &amp;amp; QA and run your ETL/ELT for each environment every day?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fa0gx", "is_robot_indexable": true, "report_reasons": null, "author": "khaili109", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fa0gx/how_to_keep_dev_qa_prod_environments_in_sync_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fa0gx/how_to_keep_dev_qa_prod_environments_in_sync_in/", "subreddit_subscribers": 91624, "created_utc": 1677692425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow Data Engineers,\n\nI sometimes find Analytics Engineers in my company create select statements with group by 1,2,3,4,5,6,7,8,9,10,11\n\nI'd like to help my team avoid this bad practice but I feel I don't have strong-enough arguments yet.\nBesides being hard to read and maintain, I'm sure there are other drawbacks.\n\nWhat are the drawbacks of creating such long group bys? And what is the appropriate way to avoid them?\n\nThanks a lot in advance for your help \ud83d\ude4f", "author_fullname": "t2_75ftbv6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Group by 1,2,3,4,5,6,7,8,9,10,11", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fyyi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677751060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;I sometimes find Analytics Engineers in my company create select statements with group by 1,2,3,4,5,6,7,8,9,10,11&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to help my team avoid this bad practice but I feel I don&amp;#39;t have strong-enough arguments yet.\nBesides being hard to read and maintain, I&amp;#39;m sure there are other drawbacks.&lt;/p&gt;\n\n&lt;p&gt;What are the drawbacks of creating such long group bys? And what is the appropriate way to avoid them?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance for your help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fyyi5", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Falcon_9", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fyyi5/group_by_1234567891011/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fyyi5/group_by_1234567891011/", "subreddit_subscribers": 91624, "created_utc": 1677751060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to implement a data stack for a small business with a low amount of data (at most 10-100k rows). We have to get the data out of a CRM through an API, preferably store it in a data warehouse and then display it in Power BI.\n\nI'm having problems finding a cheap and reliable data stack solution though as there are so many options and I've previously worked with enterprise offerings like Azure but in this case I feel like it is going to be too expensive.\n\nCurrently we have some python scripts scheduled with cron, but we want something better with an actual orchestrator that could monitor the pipelines as the API from which we get most of our data is not entirely reliable.\n\nI've considered using Airflow, but could you suggest any cloud platforms to host this for this small scale?\n\nAnd what about some cheap SQL data warehouse? I've used Azure dedicated SQL but even at the lowest level that's a bit too expensive.", "author_fullname": "t2_elso2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data stack would you use for small use cases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fxhaa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677745749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to implement a data stack for a small business with a low amount of data (at most 10-100k rows). We have to get the data out of a CRM through an API, preferably store it in a data warehouse and then display it in Power BI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m having problems finding a cheap and reliable data stack solution though as there are so many options and I&amp;#39;ve previously worked with enterprise offerings like Azure but in this case I feel like it is going to be too expensive.&lt;/p&gt;\n\n&lt;p&gt;Currently we have some python scripts scheduled with cron, but we want something better with an actual orchestrator that could monitor the pipelines as the API from which we get most of our data is not entirely reliable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve considered using Airflow, but could you suggest any cloud platforms to host this for this small scale?&lt;/p&gt;\n\n&lt;p&gt;And what about some cheap SQL data warehouse? I&amp;#39;ve used Azure dedicated SQL but even at the lowest level that&amp;#39;s a bit too expensive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11fxhaa", "is_robot_indexable": true, "report_reasons": null, "author": "Kardinals", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fxhaa/what_data_stack_would_you_use_for_small_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fxhaa/what_data_stack_would_you_use_for_small_use_cases/", "subreddit_subscribers": 91624, "created_utc": 1677745749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From what I seen, general dataflow/lakehouse stages is: raw data (bronze) - curated data (silver) - aggregations from curated data (gold).\n\nBut what if I need to create aggregations which are based on the gold layer? Or even partly on Silcer and partly on Gold? Should I have another layer or put it again into the gold layer? \n\nLogically, I could have a lot of such dependencies and adding new layer for each follow-up dependency is probably not to reasonable. So that sounds in favor of keeping all aggregations in the gold layer. \n\nBut on the other hand, gold layer would partly be generated from silver layer, partly only from gold and partly from combination of both and I am not sure if that wouldnt cause a mess and confusion. \n\nOr is there any better alternative?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aggregation on top of \u201cgold\u201d layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11fwc7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677741870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From what I seen, general dataflow/lakehouse stages is: raw data (bronze) - curated data (silver) - aggregations from curated data (gold).&lt;/p&gt;\n\n&lt;p&gt;But what if I need to create aggregations which are based on the gold layer? Or even partly on Silcer and partly on Gold? Should I have another layer or put it again into the gold layer? &lt;/p&gt;\n\n&lt;p&gt;Logically, I could have a lot of such dependencies and adding new layer for each follow-up dependency is probably not to reasonable. So that sounds in favor of keeping all aggregations in the gold layer. &lt;/p&gt;\n\n&lt;p&gt;But on the other hand, gold layer would partly be generated from silver layer, partly only from gold and partly from combination of both and I am not sure if that wouldnt cause a mess and confusion. &lt;/p&gt;\n\n&lt;p&gt;Or is there any better alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11fwc7u", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11fwc7u/aggregation_on_top_of_gold_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11fwc7u/aggregation_on_top_of_gold_layer/", "subreddit_subscribers": 91624, "created_utc": 1677741870.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}